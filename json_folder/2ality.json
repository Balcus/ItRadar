[
{"url": "https://2ality.com/2024/05/proposal-promise-with-resolvers.html", "title": "ECMAScript 2024 feature:  Promise.withResolvers()", "content": "ECMAScript 2024 feature:  dev javascript es2024 async promises In this blog post we take a look at the ECMAScript 2024 feature  “ ”  (proposed by Peter Klecha). It provides a new way of directly creating Promises, as an alternative to  . \n   \n      – the revealing constructor pattern \n   \n   \n     \n     \n       \n         An implementation \n       \n     \n   \n   \n     Example: promisifying a callback-based function \n   \n   \n     Example: one-element queue \n   \n   \n     Example: a queue with arbitrary capacity \n   \n   \n     Example: a queue that is asynchronously iterable \n   \n   \n     Frequently asked questions \n     \n       \n         Why not use the name   (or  )? \n       \n       \n         Why use the name “resolvers” and not “settlers”? \n       \n     \n   \n   \n     Conclusion and further reading \n   \n  – the revealing constructor pattern   # Before  , there was only one way to create Promises directly – via the following pattern: Quoting Domenic Denicola , one of the people behind JavaScript’s Promise API: I call this   because the   constructor is   its internal capabilities, but only to the code that constructs the promise in question. The ability to resolve or reject the promise is only revealed to the constructing code, and is crucially   revealed to anyone   the promise. So if we hand off   to another consumer, say then we can be sure that this consumer cannot mess with any of the internals that were revealed to us by the constructor. This is as opposed to, for example, putting   and   methods on  , which anyone could call. As an example, let’s convert a callback-based function into a Promise-based one (note that Node.js does have a complete Promise-based API,  ). The following code shows what using the callback-based function   looks like: Let’s implement a Promise-based version of  :    # One limitation of the revealing constructor pattern is that the settlement functions   and   can’t leave the   constructor callback and be used separately from the Promise. That is fixed via the following static factory method: This is what using that factory method looks like: An implementation   # We can implement   as follows: The proposal points out how many code bases implement this functionality (which is why it is good news that it is now built into the language):  React ,  Vue ,  Axios ,  TypeScript ,  Vite ,  Deno’s standard library . Example: promisifying a callback-based function   # Let’s revisit our previously implemented function  . With the new API, we can write it as follows: That code is still more or less the same as the one where we used the   constructor. Let’s move on to use cases that the constructor can‘t handle. Example: one-element queue   # Example: a queue with arbitrary capacity   #  is a potentially infinite queue: \n  blocks until a value is available. \n  is non-blocking \n The code is a slight rewrite of function   in  package   of  , a distributed secure JavaScript sandbox, based on SES. Check out that package for more code that uses   – which is the equivalent of  . Each queue element is a Promise for  : \n  is the value stored in the queue element. \n  is the next (potentially pending) queue element. \n Front and back of the queue: \n The front is the first queue element (a Promise). \n The back is a   function for the last (pending!) queue element. \n Example: a queue that is asynchronously iterable   # Not much has changed compared to the previous implementation: \n Methods   and   implement  the AsyncIterable interface . \n A queue element is now a Promise for  . \n  lets us close queues, by adding a final element to the queue: \n \n Frequently asked questions   # Why not use the name   (or  )?   # The names “deferred” only make sense to people who are aware of the history of Promises: It was a name that was used in  jQuery’s Promise API . If you are new to JavaScript that name doesn’t mean anything to you. [ Source ] Why use the name “resolvers” and not “settlers”?   # Resolving a Promise via   only means that its fate is determined: \n It may settle the Promise: \n \n But it may also lock the Promise’s state to that of another Promise. And the latter Promise could be forever pending (never settled): \n \n Thus,   and   generally only resolve Promises – they don’t always settle them. [ Source ] Furthermore, the ECMAScript specification uses  the name “resolving functions”  for   and  . Conclusion and further reading   # This concludes our excursion into the world of Promises. If you want to know more about asynchronous programming in JavaScript, you can read the following chapters of my book “JavaScript for impatient programmers”: \n “Asynchronous programming in JavaScript” \n “Promises for asynchronous programming” \n “Async functions” \n “Asynchronous iteration” \n comments powered by Disqus."},
{"url": "https://2ality.com/2024/05/proposal-duplicate-named-capturing-groups.html", "title": "ECMAScript 2025 feature: duplicate named capturing groups for regular expressions", "content": "ECMAScript 2025 feature: duplicate named capturing groups for regular expressions dev javascript es2025 In this blog post, we take a look at the ECMAScript 2025 feature  “Duplicate named capturing groups”  which was proposed by Kevin Gibbons. It’s a feature for regular expressions that enables us to use the same capturing group name more than once. \n   \n     Duplicate named capturing groups \n   \n   \n     Use case: alternative formats with similar parts \n   \n   \n     Use case: reusing regular expression fragments \n   \n   \n     Backreferences \n   \n   \n     Support in JavaScript engines \n   \n   \n     Conclusion and further reading \n   \n Duplicate named capturing groups   # It’s clear why duplicate capturing group names are normally not allowed: A capture can only have a single value and therefore would have to ignore the other groups – e.g.: In a match, group   can capture either   or  , not both. However, if the duplicate names exist in different alternatives, then there is no such conflict. That was previously not allowed either but is allowed now – e.g.: Why is that useful? It lets us reuse regular expression fragments and match-processing code between alternatives. Let’s look at examples next. Use case: alternative formats with similar parts   # Function   uses a regular expression to parse a string with one of two month formats: Use case: reusing regular expression fragments   # The code below demonstrates that duplicate named capturing groups enable us to to reuse regular expression fragments – in this case:   and  . Comments: \n  returns an iterable. \n We use   to convert that iterable to an Array. \n The optional second parameter of   is a callback that is applied to elements before they are put into the returned Array. Think  . \n Backreferences   # Backreferences to duplicate named groups work as expected. The following example is contrived (because we could simply use a single named group) but it illustrates what’s possible: Support in JavaScript engines   # \n The proposal maintains  a list of engines  that already support duplicate named capturing groups. \n I tested the code in this blog post with  Markcheck  and used  a Babel plugin  (because Node’s V8 doesn’t support the feature yet).\n \n Caveat: It only transparently supports regular expression literals; I used  a workaround : \n \n \n Conclusion and further reading   # In practice, duplicate named capturing groups are probably most useful to people who write parsers and tokenizers based on regular expressions. For those, it is a highly welcome addition. Further reading: \n The chapter on JavaScript’s regular expressions  in my book “JavaScript for impatient programmers” \n You may also find  my template tag   for composing regular expressions interesting. \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/11/json-parse-with-source.html", "title": "ECMAScript proposal: source text access for  JSON.parse()  and  JSON.stringify()", "content": "ECMAScript proposal: source text access for   and  dev javascript es proposal In this blog post, we look at  the ECMAScript proposal “  source text access”  by Richard Gibson and Mathias Bynens. It gives access to source text to two kinds of callbacks: \n , callbacks that are passed to   and post-process the data it parses. \n , callbacks that are passed to   and pre-process data before it is stringified. \n We’ll examine how exactly that works and what you can do with this feature. \n   \n     JSON parsing: reading the source text from a reviver \n     \n       \n         Example: faithfully parsing large integers \n       \n     \n   \n   \n     JSON stringification: specifying the source text via replacers and  \n     \n       \n         Example: stringifying bigints \n       \n     \n   \n   \n     A generic approach for stringifying and parsing numeric values \n   \n   \n     Real-world example: Twitter’s ID problem \n   \n   \n     Implementations of the proposal \n   \n   \n     Further reading \n   \n JSON parsing: reading the source text from a reviver   #  can be customized via a  , a callback that post-processes the data that is parsed: The proposal gives revivers access to the source text via the new parameter  . Example: faithfully parsing large integers   # JSON does not support bigints. But its syntax can represent arbitrarily large integers. The following interaction shows a large integer that can be stored as JSON, but when it is parsed as a number value, we lose precision and don’t get an accurate value: If we could parse that string as a bigint, we would not lose precision: We can achieve that by accessing the source text from a reviver: The reviver assumes that properties whose names end with   contain bigints. Let’s use it to parse an object with a bigint property: JSON stringification: specifying the source text via replacers and     #  can be customized via a  , a callback that pre-processes data before it is stringified. Replacers can use   to specify how a value should be stringified: Notes: \n  coerces   to a string. \n If   has leading or trailing whitespace, it throws an exception. \n The function also enforces that  , when JSON-parsed, is a primitive value. \n Example: stringifying bigints   # The following replacer stringifies bigints (for which   normally throws exceptions) as integer numbers: The manual type conversion via   in line A is not strictly needed, but I like to be explicit about conversions. We can use   to convert the object we have previously parsed back to JSON: A generic approach for stringifying and parsing numeric values   # When stringifying, we can distinguish integer numbers and bigints by marking the former with a decimal point and decimal fraction of zero. That is: \n The integer number   is stringified as  . \n The bigint   is stringified as  . \n When parsing, integer literals are always parsed as bigints, all other number literals as numbers: Real-world example: Twitter’s ID problem   # When Twitter switched to 64-bit IDs, these IDs couldn’t be (only) stored as numbers in JSON anymore. Quoting  Twitter’s documentation : Numbers as large as 64-bits can cause issues with programming languages that represent integers with fewer than 64-bits. An example of this is JavaScript, where integers are limited to 53-bits in size. In order to provide a workaround for this, in the original designs of the Twitter API (v1, v1.1), ID values were returned in two formats: both as integers, and as strings. Let’s see what happens if we parse this integer as a number and as a bigint: Implementations of the proposal   # There is  a GitHub issue  that lists the bug tickets for implementing this feature in various JavaScript engines. V8 has an implementation behind the   flag ( V8 v10.9.1+ ). Further reading   # \n \n Chapter “Creating and parsing JSON ( )”  in “JavaScript for impatient programmers” \n \n \n “Bigints and JSON” : serializing bigints as strings to JSON (the only choice you have without access to source text) \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/11/array-from-async.html", "title": "ECMAScript proposal:  Array.fromAsync()", "content": "ECMAScript proposal:  dev javascript es proposal This blog post is about  the ECMAScript proposal “  for JavaScript”  by J. S. Choi. It introduces a static method for converting asynchronous iterables to Arrays. \n   \n     Tools for working with synchronous iterables \n   \n   \n     \n   \n   \n     An implementation of  \n   \n   \n     Example: reading chunks from a readable web stream \n   \n   \n     Further reading \n   \n Tools for working with synchronous iterables   # Currently JavaScript provides several tools for working with synchronous iterables – for example: For working with asynchronous iterables, we currently only have the   loop.    #  is the asynchronous version of  :  accepts up to three arguments: \n  is the asynchronous iterable that is converted to an Array. \n The optional   lets us transform the iterated values before they are added to the Array that is returned. If we provide this argument,   works similarly to the Array method  . \n The optional   lets us specify the value of   for  . \n Given that the values in   can’t be collected synchronously,   works asynchronously and returns a Promise for an Array. Therefore, we   its results in the following example: An implementation of     # We could implement   like this: Example: reading chunks from a readable web stream   # In Node.js,  readable web streams  are asynchronously iterable. Therefore, we can use   to collect all the   (pieces of data) of a ReadableStream in an Array. We’ll read the following file  : This is the code: Further reading   # \n Chapter “Synchronous iteration”  in “JavaScript for impatient programmers” \n Section “Converting iterables and Array-like objects to Arrays via  ”  in “JavaScript for impatient programmers” \n Chapter “Asynchronous iteration”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/12/set-methods.html", "title": "ECMAScript proposal: Set methods", "content": "ECMAScript proposal: Set methods dev javascript es proposal In this blog post, we examine  the ECMAScript proposal “Set methods for JavaScript”  by Michał Wadas, Sathya Gunasekara and Kevin Gibbons. It introduces new methods for  Sets . \n   \n     New Set methods that return Sets \n     \n       \n         \n       \n       \n         \n       \n       \n         \n       \n       \n         \n       \n     \n   \n   \n     New Set methods that return booleans \n     \n       \n         \n       \n       \n         \n       \n       \n         \n       \n     \n   \n   \n     Rules for   and  \n   \n   \n     Infinite Set-like data \n   \n   \n     The rationales behind the API design \n   \n   \n     Implementations \n   \n   \n     Further reading \n   \n New Set methods that return Sets   #    # This method returns a Set that is the union of   and  . Type signature: The type of  ,   is discussed later. It means that   provides all operations that the new methods need for their algorithms. Example:    # This method returns a Set that is the intersection of   and  . Type signature: Example:    # This method returns a Set that is the difference between   and  . Type signature: Example:    # This method returns a Set that is the symmetric difference between   and  . What does that mean? These are equivalent definitions of the symmetric difference: \n  −   ∪   −  \n (  ∪  ) − (  ∩  ) \n  xor   (exclusive OR) \n All elements that only exist in one of the two sets \n Type signature: Example: New Set methods that return booleans   #    # This method returns   if   is a subset of   and   otherwise. Type signature: Example:    # This method returns   if   is a superset of   and   otherwise. Type signature: Example:    # This method returns   if   is disjoint from   and   otherwise. Type signature: Example: Rules for   and     # For all of the new Set methods: \n  must be an instance of  . \n  must implement the interface   shown below.\n \n The full interface is always enforced, even if a method doesn’t use all of its methods. \n \n \n Infinite Set-like data   # The   of   can be  . That means we can work with infinite Sets: Only two methods don’t support   being an infinite Set: \n \n \n The rationales behind the API design   # These are the rationales behind the API design ( source ): \n \n Why does   have to be a  ? \n \n TC39 could have chosen a more flexible interface for   which would have enabled us to use the Set methods generically. However, not doing so makes implementations simpler and faster. \n \n \n \n Why use an interface for  ? \n \n Due to the interface,   can be a data structure other than a Set. It was chosen as a compromise between accepting only Sets and any iterable objects. \n \n \n \n Why is the full interface always enforced for  ? \n \n That makes the API simpler and hides implementation details. \n \n \n \n Why was the method name   chosen for iterating over data structure elements? \n \n That’s due to compatibility with the only Set-like data structure currently in the standard library –  :\n \n The method key   doesn’t work because that Map method returns key-value pairs. \n The method key   doesn’t work because that Map method is not compatible with the Map method   (which accepts keys, not values). \n \n \n \n \n \n Why are the new method names nouns and not verbs like  ? \n \n A rough general rule (with exceptions) is that verb methods mutate  , while noun methods return new data – for example:   and  . \n \n \n Implementations   # I’m aware of the following two polyfills: \n \n \n Further reading   # \n Chapter “Sets”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/11/testing-static-types-typescript.html", "title": "Testing static types in TypeScript", "content": "Testing static types in TypeScript dev typescript When it comes to TypeScript code: \n There are many options for testing its behavior at runtime. \n There are far fewer options for testing its compile-type types. \n In this blog post, we look at the latter. \n   \n     Why would we want to test types? \n   \n   \n     Simple solutions \n   \n   \n     Testing via code \n     \n       \n         \n       \n       \n         \n       \n       \n         \n       \n       \n         How to implement an equality check for types \n       \n     \n   \n   \n     Testing via comments \n     \n       \n         \n       \n       \n         \n       \n     \n   \n   \n     Checking for errors \n     \n       \n         \n       \n       \n         \n       \n       \n         eslint-plugin-expect-type \n       \n       \n         Idea: improving error checking via  \n       \n     \n   \n   \n     Testing via code vs. testing via comments \n   \n   \n     Source of this blog post \n   \n Why would we want to test types?   # Consider a utility type such a the built-in  : The three lines at the end serve two purposes: \n They demonstrate how   works. \n We can also use them to check if the result   is as intended (think manual unit test for types). \n In both cases, we’d profit from an automated check: \n If we demonstrate something, we could be sure that there are no typos. \n If we want to test code, automation is important. \n Type testing can also help us when JavaScript constructs such as functions have complicated types. Simple solutions   # We can test a type by checking if a value is assignable to it (line A) or via the   operator (line B): However, the previous tests only check that   doesn’t have more properties than the ones we are using. It doesn’t prevent   from having fewer properties. For example, TypeScript is fine with the following code: Testing via code   # Some type testing libraries implement type checks in TypeScript and lets us use them in our code.    # The library   lets us check types via the type parameter of a function   (line A):    # Package   has a module   with the generic type   for type checks:    #  is a tool for running tests against   files. It looks similar to the previous two approaches, but performs custom compilation to check its type assertions. : How to implement an equality check for types   # If you want to implement an equality check for types yourself, there is  a StackOverflow question  whose answers have useful information. Testing via comments   # Another approach for testing types is to write expected types in comments and use a tool to compare those types against actual types.    #  is a tool that is part of the DefinitelyTyped-tools. Using it looks like this:    # Using  the ESLint plugin   looks similar to  : This plugin also supports twoslash syntax ( ): Checking for errors   # Sometimes we want to check that the wrong input produces errors. In JavaScript unit testing that is done (e.g.) via  . This section examines the equivalents for type testing.    # With  , we check for errors via the function  . : This approach has two downsides: \n TypeScript shows an error at compile time (e.g. during editing). \n We don’t see what the error is that we are expecting. This makes this approach less useful for explanations (e.g. in documentation). It can also hide errors that we are not expecting. \n    # Checking for errors with   looks like this: Using   has the benefit that TypeScript won’t complain at compile time. Alas, we still don’t see the error message. eslint-plugin-expect-type   # Error checking with  eslint-plugin-expect-type : The downsides are: TypeScript complains at compile time and we don’t see the error message. Idea: improving error checking via     # For my book,  “Tackling TypeScript” , I have written a simple type error checking tool (which, alas, is not ready for public consumption at the moment). It checks if the error message after   matches what TypeScript would report without the annotation. That looks as follows ( source of this example ): This time, TypeScript won’t complain and we see the error message. If anyone is interested: I have created  a Gist  with all examples in “Tackling TypeScript” where I use this kind of error checking. Testing via code vs. testing via comments   # My impression so far: \n \n Code tests work better for testing code: \n \n IDEs complain immediately: No special tool is needed to perform the checks. \n The tests are more robust across TypeScript versions. \n \n \n \n Comment tests work better for testing examples (e.g. embedded in Markdown): \n \n The syntax looks nicer. \n We need a special tool for checking/running the examples anyway. \n The tests being more fragile is less of an issue. I’d even consider it a bonus if a checking tool forced me to update the syntax as TypeScript evolves. \n \n \n Source of this blog post   # Thanks for all the replies in  this Mastodon thread ! They provided crucial information for this blog post. comments powered by Disqus."},
{"url": "https://2ality.com/2022/12/iterator-helpers.html", "title": "ECMAScript proposal: iterator helpers", "content": "ECMAScript proposal: iterator helpers dev javascript es proposal   New section “How will this proposal affect future JavaScript APIs?” In this blog post, we look at  the ECMAScript proposal “Iterator helpers”  by Gus Caplan, Michael Ficarra, Adam Vandolder, Jason Orendorff, Kevin Gibbons, and Yulia Startsev. It introduces utility methods for working with iterable data:  ,  ,  , etc. The style of the proposed API clashes with the style of the current iteration API. We’ll explore how we can fix that. \n   \n     Synchronous versus asynchronous iteration \n   \n   \n     Synchronous iteration \n     \n       \n         Iteration: a protocol for sequential data consumers \n       \n       \n         The interfaces of the iteration protocol \n       \n       \n         Iteration-based data producers \n       \n       \n         Iteration-based data consumers \n       \n       \n         Processing iterables via generators \n       \n     \n   \n   \n     The inheritance of the current iteration API \n     \n       \n         Array iterators \n       \n       \n         Generator objects \n       \n       \n         Why are the built-in iterators iterable? \n       \n       \n         Iteration quirk: two kinds of iterables \n       \n     \n   \n   \n     The new API: synchronous iteration \n     \n       \n         : creating API iterators \n       \n       \n         An overview of the new   methods \n       \n       \n         Iterator methods that return iterators \n       \n       \n         Iterator methods that return non-iterators \n       \n       \n         Looping and conversion \n       \n     \n   \n   \n     Using the new API with legacy iterables \n     \n       \n         Example: a manually implemented iterable \n       \n       \n         Example: Immutable.js \n       \n     \n   \n   \n     How to unify the two clashing iteration styles \n     \n       \n         Fix 1: always use iterable style \n       \n       \n         Fix 2: always use iterator style \n       \n       \n         How will this proposal affect future JavaScript APIs? \n       \n     \n   \n   \n     The new API: asynchronous iteration \n     \n       \n         \n       \n       \n         Prototype methods that return asynchronous iterators \n       \n       \n         Prototype methods that return Promises for values \n       \n     \n   \n   \n     Implementations of the iterator helpers \n   \n   \n     The benefits of the new iterator methods \n     \n       \n         Benefit: more operations for data structures that support iteration \n       \n       \n         Benefit: incremental processing \n       \n     \n   \n   \n     Further reading \n   \n Synchronous versus asynchronous iteration   # JavaScript supports two kinds of iteration modes: \n Synchronous iteration \n Asynchronous iteration  (based on Promises) \n We’ll first explore synchronous iteration in depth and then briefly look at asynchronous iteration – the asynchronous part of the proposal is very similar to the synchronous part. Synchronous iteration   # Iteration: a protocol for sequential data consumers   # In JavaScript, there are several constructs that consume data   – one value at a time – for example, the   loop and spreading into Arrays. A   consists of interfaces and rules for using them. The   is used by JavaScript’s sequential data consumers to access their input. Any data structure that implements this protocol can therefore be consumed by them. The interfaces of the iteration protocol   # The following roles are involved in the synchronous iteration protocol: \n \n Values that support the iteration protocol are called  . They return   via a method  . \n \n \n We get the iterated values by repeatedly invoking method   of the   returned by the iterable. \n \n These are the TypeScript types for these roles: The   method   returns: \n An object   for each iterated value  . \n The object   after the last iterated value. \n In other words: We call   until it returns an object whose property   is  . As an example, let’s use the iteration protocol to access the elements of a Set: Since Sets are iterable, we can use them with iteration-based data consumers such as spreading into Arrays (line A) and   loops (line B): Note that we never saw iterators – those are only used internally by the consumers. The JavaScript standard library has more iteration-based data producers and consumers. We’ll look at these next. Iteration-based data producers   # These data structures are iterable: \n strings \n Arrays \n Sets \n Maps \n The following data structures have the methods  ,  , and   that return iterables that are not Arrays: \n Arrays \n Sets \n Maps \n Synchronous generator functions and methods expose their yielded values via iterable objects that they return: We’ll use the result of   to demonstrate iteration-based data consumers in the next subsection. Iteration-based data consumers   # All of the following constructs access their input via the iteration protocol. The   loop: Spreading: : Array-destructuring: Processing iterables via generators   # Generators produce iterables, but they can also consume them. That makes them a versatile tool for transforming iterables: The inheritance of the current iteration API   # All of the iterators created by JavaScript’s standard library have a common prototype which the ECMAScript specification calls  . Array iterators   # We create an Array iterator like this: This object has a prototype with two properties. Let’s call it  : The prototype of   is  . This object has a method whose key is  . Therefore, all built-in iterators are iterable. The prototype of   is  . This is a diagram for this chain of prototypes: Generator objects   # Roughly, a generator object is an iterator for the values yielded by a generator function  . We create it by calling  : The prototype of   is  : The prototype of   is an object that is shared with all generator objects. In addition to the iterator method  , it has generator-specific methods such as   and  . The ECMAScript specification calls it  : The prototype of   is  : Why are the built-in iterators iterable?   # As we have seen, generator objects are, at their cores, iterators (they have a method  ), not iterables. However, we’d also like to use generators to implement iterables. That’s why generator objects have a method   that returns  . They inherit this method from  . The following code demonstrates that each generator object returns itself when it is asked for an iterator: Iteration quirk: two kinds of iterables   # Alas, iterable iterators mean that there are two kinds of iterables: \n Iterable iterators are  : They always return the same iterator when   is called (iteration continues). \n \n Arrays, Sets, etc. are  : They always return fresh iterators (iteration restarts). \n The new API: synchronous iteration   # We have already seen that   is the prototype of all built-in iterators. The proposal introduces a class  : \n  is a utility method that we’ll explore soon. \n  refers to  . \n  refers to  . \n  contains various methods that are inherited by iterators – for example:\n \n  returns a mapped version of  \n  returns an iterator for the first   values of  . \n  returns an Array with the values of  . \n \n \n : creating API iterators   # The static method   returns an instanceof  : \n If   is a synchronous API iterable, it returns  . \n If   is a synchronous API iterator, it returns   unchanged. \n If   is a synchronous legacy iterator (that doesn’t support the new API), it wraps it so that it supports the new API and returns the result. \n If   is a synchronous legacy iterable, it wraps the result of   and returns it. \n In the following example, we use   to convert a legacy iterator to an API iterator: An overview of the new   methods   # The following subsections give an overview of the new   methods. They will use this function to create a synchronous iterable: Some of the iterator methods keep a counter for the iterated values and pass it on to their callbacks: \n \n \n \n \n \n \n \n \n Iterator methods that return iterators   # # This method returns an iterator with the first   values of  . Type signature: Example: # This method returns an iterator that with all values of  , except for the first   ones. That is, iteration starts when the iteration counter is  . Type signature: Example: # This method returns an iterator whose values are the values of   for which   returns  . Type signature: Example: # This method returns an iterator whose values are the result of applying   to the values of  . Type signature: Example: # This method returns an iterator whose values are the values of the iterables or iterators that are the results of applying   to the values of  . Type signature (simplified): Example: For more information on  , see  the section on the related Array method  in “JavaScript for impatient programmers”. Iterator methods that return non-iterators   # # This method returns   if   returns   for at least one value of  . Otherwise, it returns  . Type signature: Example: # This method returns   if   returns   for every value of  . Otherwise, it returns  . Type signature: Example: # This method uses the function   to combine the values of   into a single value. Type signature: Example – concatenating the strings of an iterator: Example – computing the minimum of a Set of numbers: For more information on  , see  the section on the related Array method  in “JavaScript for impatient programmers”. # This method returns the first value of   for which   returns  . If there is no such value, it returns  . Type signature: Example: Looping and conversion   # # This method applies   to each value in  . Type signature: Example: # This method returns the values of   in an Array. Type signature: Example: # This method returns an asynchronous iterator for the values of the synchronous  . Type signature: Example: Using the new API with legacy iterables   # All built-in iterables automatically support the new API because their iterators already have   as a prototype (and are therefore instances of  ). However, that’s not the case for many iterables in libraries and user code. Example: a manually implemented iterable   # This is an example of a manually implemented iterable: This iterable does not support the new API. We can use   to convert an instance of   to an API iterator: If we want   to support the new API, we have to make its iterators instances of  : This is another option: Example: Immutable.js   # The iterables provided by the library Immutable.js don’t support the new API, either. Their iterators are currently implemented like this ( source ): To support the new API, class   has to be renamed and extend the API’s class  : We can also use   to convert Immutable.js iterables to API iterators. How to unify the two clashing iteration styles   # Before the new API, JavaScript’s iteration had an  : \n The iterable is the dominant iteration role. \n All built-in language constructs operate on iterables. Programmers using these constructs never see iterators. \n This style is also used by Java and Python. \n The new API has an  : \n The iterator is the dominant iteration role. The API never uses iterables (except to support legacy code). \n This style is also used by Rust. \n I see two ways in which we can fix this clash of styles. Fix 1: always use iterable style   # This fix works as follows: \n We pretend that the new API wraps iterables – loosely similar to how Lodash and jQuery work. \n  wraps iterables and starts API method chains. \n Pros and cons: \n \n Pro: compatible with the status quo \n \n \n Con: relatively verbose \n \n \n Con: The illusion of only working with iterables is broken whenever an iterator method has parameters that are iterators. For example, we may get method   in the future: \n \n \n \n Con: The name   doesn’t help, either. \n \n Fix 2: always use iterator style   # \n We pretend there are only iterators and that iterables don’t exist. \n API iterators being iterable means that built-in language constructs can handle them. That is, we can pretend that the constructs accept iterators. \n  means getting a “proper” iterator from a data structure that:\n \n either doesn’t support the new API (such as library data structures) \n or has no convenient method for creating iterators (such as strings). \n Long-term, this static helper method won’t be used anymore. \n \n \n (*) Strings need a method for creating iterators that is more convenient than  . What does that mean for new JavaScript code? \n \n Functions and methods should accept iterators, not iterables – especially in TypeScript. \n \n \n If we return a value that supports the iteration protocol, it should be an iterator, not an iterable. This iterator must be an instance of  . \n \n \n We don’t make data structures iterable anymore, we implement methods that return instances of  . \n \n The most common current names for such methods are:  ,  ,  \n  could also work (due to  ). \n \n \n The following code illustrates iterator-only style: Pros and cons: \n Con: This style is a break with existing practices. \n Pro: This style feels simpler than existing practices (there are only iterators, no iterables). \n Pro: The weird dual nature of generator objects is not an issue anymore:\n \n They are allowed to be mostly iterators. \n It doesn’t matter that there are two kinds of iterables (because we don’t use iterables anymore). \n \n \n How will this proposal affect future JavaScript APIs?   # Assuming we all agree on iterator style: \n \n It looks like upcoming ECMAScript APIs will switch to iterators – for example: The proposed new Set methods have a parameter   and require  method   to return an iterator, not an iterable. \n \n \n Strings need a method for creating iterators that is more convenient than  . Maybe:  . \n \n \n APIs will have to decide what they mean if they require a parameter   to be “an iterator”: \n \n Do they only require that   exists (“core iterator”) or \n do they require that   is an instance of  ? \n \n For  method   mentioned in the previous item, the former approach was chosen. \n Consequences: \n \n APIs that accept core iterators may profit from   and   accepting core iterators. But maybe only ECMAScript APIs will accept core iterators and non-built-in APIs will only accept instances of  . \n To express this distinction, TypeScript may have to introduce a new interface called (e.g.)   that only has method  . \n \n \n \n In TypeScript, interface   may not be needed anymore. It is currently the return type of methods such as   (of Arrays, Maps, etc.), so that their results are accepted by language constructs that require their operands to be iterable. However, with the ECMAScript proposal, every   is iterable. \n \n The new API: asynchronous iteration   # The asynchronous version of the iterator method API is similar to the synchronous version but uses  asynchronous iteration  instead of  synchronous iteration .    # The static method   returns an instance of  : \n If   is an asynchronous API iterable, it returns  . \n If   is an asynchronous API iterator, it returns   unchanged. \n If   is an asynchronous legacy iterator (that doesn’t support the new API), it wraps it so that it supports the new API and returns the result. \n If   is an asynchronous legacy iterable, it wraps the result of   and returns it. \n If   is a synchronous iterable (API or legacy), it returns an asynchronous iterator for its values. \n Prototype methods that return asynchronous iterators   # The API for asynchronous iterators provides asynchronous analogs of the synchronous iterator methods that return iterators – for example: We used these helper functions: As an aside:   is an ECMAScript proposal. # The asynchronous iterator method   is the only case where not only the return type changes, but also the type of the parameter. Its type signature is: In other words: The callback   can return iterables or iterators that are either synchronous or asynchronous. Prototype methods that return Promises for values   # If a synchronous iterator method returns non-iterator values, then its asynchronous version returns Promises for these values. That’s why we use   in line A, B, C and D: For looping over asynchronous iterators we can use   and will often await the empty Promise it returns: We can also use  : Implementations of the iterator helpers   # \n \n The proposal tracks implementations in JavaScript engines. \n \n \n core-js now supports the stage 3 version of the proposal, via  . \n \n \n I have written  a simple polyfill . \n \n The benefits of the new iterator methods   # Benefit: more operations for data structures that support iteration   # With the new iterator methods, any data structure that supports iteration gains more operations. For example, Sets don’t support the operations   and  . Thanks to the new iterator methods, they now do: Note that   accepts iterables and therefore iterable iterators (line A and line B). Benefit: incremental processing   # One important benefit of iteration is that data consumers that also produce iterated data, process data incrementally. As an example, consider code that reads a text file, puts the string   before each line and logs the result. If we use an Array, we have to read the whole file before we can log the first line. If we use iteration, we can log the first line shortly after reading it. With the proposed new API, this could look like this: We have had generators for this kind of incremental processing for a while. Now we also have the iterator methods. Further reading   # \n Chapter “Synchronous iteration”  in “JavaScript for impatient programmers” \n Chapter “Synchronous generators”  in “JavaScript for impatient programmers” \n Chapter “Asynchronous iteration”  in “JavaScript for impatient programmers” \n Section “Asynchronous generators”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2024/05/proposal-symbols-as-weakmap-keys.html", "title": "ECMAScript 2023 feature: symbols as WeakMap keys", "content": "ECMAScript 2023 feature: symbols as WeakMap keys dev javascript es2023 In this blog post, we take a look at the ECMAScript 2023 feature  “Symbols as WeakMap keys”  – which was proposed by Robin Ricard, Rick Button, Daniel Ehrenberg, Leo Balter, Caridy Patiño, Rick Waldron, and Ashley Claymore. \n   \n     What are WeakMaps good for? \n     \n       \n         How is that different from a normal Map? \n       \n       \n         What values can be keys in WeakMaps? \n       \n     \n   \n   \n     Why are symbols as WeakMap keys interesting? \n     \n       \n         Preparation: a module that creates references to objects \n       \n       \n         Use case: references to objects in records and tuples \n       \n       \n         Use case: passing references to objects in and out of ShadowRealms \n       \n     \n   \n   \n     Conclusion and further reading \n   \n What are WeakMaps good for?   # The key ability of a WeakMap is to associate data with a value: \n The value is the key of a WeakMap entry. \n The data is the value of that entry. \n Consider the following code: With a WeakMap, we can attach data without mutating  : This kind of non-mutating attaching has two main use cases: \n We can attach data to value that we don’t own, e.g. to cache computed results ( see example in “JavaScript for impatient programmers” ). \n We can keep part of a value private, by not making the WeakMap public that contains that part ( see example in “JavaScript for impatient programmers” ). \n How is that different from a normal Map?   # The WeakMap holds the key  : If the key is garbage-collected, the whole entry is removed and the data can be garbage-collected, too (unless it is references somewhere else). That means that the illusion of the attached data being part of the value is really good and there won’t be memory leaks. What values can be keys in WeakMaps?   # Which values can be keys in WeakMaps is documented in the ECMAScript specification, via the specification function  : \n Objects \n Symbols which are not registered (created via  ) \n The latter kind of key is new and was added as part of the feature “Symbols as WeakMap keys”. All kinds of keys have one thing in common – they have  : When compared via  , two keys are considered equal if they have the same identity – they are   compared by comparing their contents, their values. That means there are never two or more different keys (“different” meaning “at different locations in memory”) that are all considered equal. Each key is unique. They are garbage-collected. Both conditions are important so that WeakMaps can dispose entries when keys disappear and no memory leaks. Let’s look at examples: \n Non-registered symbols can be used as WeakMap keys: They are primitive but they are compared by identity and they are garbage-collected. \n The following two kinds of values cannot be used as WeakMap keys:\n \n Strings are garbage-collected but they are compared by value. \n Registered symbols are different from normal symbols – they do not have identity semantics ( source ). This is how registered symbols are used: \n \n \n \n Why are symbols as WeakMap keys interesting?   # Symbols as WeakMap keys solve important issues for upcoming JavaScript features: \n We can put references to objects inside  records and tuples . \n We can pass references to objects in and out of  ShadowRealms . \n Preparation: a module that creates references to objects   #  contains an API that lets us use symbols as references to values: This is what using the API looks like: Next, we’ll use this API for the two aforementioned use cases. Use case: references to objects in records and tuples   # records and tuples  are value types (and therefore immutable) that cannot contain objects. Thanks to WeakMaps, we can use symbols as references to objects and put them inside records and tuples (example based on  an idea by Robin Ricard ): Use case: passing references to objects in and out of ShadowRealms   # Values passed into and out of ShadowRealms must be primitive or callable. That rules out objects – which are neither. Once again, we can use symbols as references to objects as a work-around: Conclusion and further reading   # \n Symbols can now be keys in WeakMaps – which enables us to use them as references to arbitrary values. \n That is mainly useful for two upcoming JavaScript features:\n \n We can put references to objects inside  records and tuples . \n We can pass references to objects in and out of  ShadowRealms . \n \n \n If you have other use cases then let us know in the comments! \n Content in “JavaScript for impatient programmers”: \n Chapter on WeakMaps \n Chapter on symbols \n “Primitive values vs. objects” : The former have   (values are compared via their contents), the latter have   (values are compared via their   – think pointers). \n Other material: \n Section on registered symbols  in “Exploring ES6” \n Section on   in the ECMAScript specification \n comments powered by Disqus."},
{"url": "https://2ality.com/2024/06/array-buffers-es2024.html", "title": "ECMAScript 2024 features: resizing and transferring ArrayBuffers", "content": "ECMAScript 2024 features: resizing and transferring ArrayBuffers dev javascript es2024 In this blog post, we examine ArrayBuffer features that were introduced in ECMAScript 2024: \n “In-place resizable ArrayBuffers” , proposed by Shu-yu Guo \n “ArrayBuffer.prototype.transfer and friends”  proposed by Shu-yu Guo, Jordan Harband and Yagiz Nizipli \n \n   \n     What are ArrayBuffers? \n   \n   \n     In-place resizable ArrayBuffers \n     \n       \n         Why would we want to resize ArrayBuffers? \n       \n       \n         New features for ArrayBuffers \n       \n       \n         How Typed Arrays react to changing ArrayBuffer sizes \n       \n       \n         Guidelines given by the ECMAScript specification \n       \n     \n   \n   \n      and friends \n     \n       \n         Preparation: transferring data and detaching \n       \n       \n         New functionality \n       \n       \n         Transferring ArrayBuffers via  \n       \n       \n         Transferring an ArrayBuffer within the same agent \n       \n       \n         How does detaching an ArrayBuffer affect its wrappers? \n       \n       \n         \n       \n     \n   \n   \n     Resizing and transferring SharedArrayBuffers \n   \n   \n     Conclusion and further reading \n   \n What are ArrayBuffers?   # The following classes provide an API for handling binary data (as in not text) in JavaScript: \n  provides storage for binary data and is mostly a black box. \n There are two wrappers around ArrayBuffers that let us access their data by getting and setting numbers:\n \n Typed Arrays are used much like normal Arrays but we can only get and set numbers, whose bit-length is fixed per Typed Array class – e.g.:\n \n With   instances, we can only get and set unsigned 8-bit integers. \n With   instances, we can only get and set unsigned 32-bit floats. \n \n \n DataViews let us get and set numbers at arbitrary byte offsets and with all number formats that the API supports. These are some of its methods:\n \n \n \n \n \n \n \n \n \n Using these classes looks as follows: A more recent addition to this API is   – an ArrayBuffer whose storage can be shared between any set of   (where an agent is either the main thread or a web worker). We’ll mostly ignore SharedArrayBuffers in this blog post and get back to them at the end. In-place resizable ArrayBuffers   # Before  (Shared)ArrayBuffers became resizable , they had fixed sizes. If we wanted one to grow or shrink, we had to allocate a new one and copy the old one over. That costs time and can fragment the address space on 32-bit systems. Why would we want to resize ArrayBuffers?   # \n \n In WebAssembly, memory is held by an (Shared)ArrayBuffer ( more information ). Such memory can grow. Each time it does, a new ArrayBuffer is created and the old one detached. If JavaScript code wraps a Typed Array or a DataView around it, then it can’t use the wrapper without first checking if its ArrayBuffer is still attached. Resizable ArrayBuffers and auto-tracking wrappers would make such code more elegant and more efficient. \n \n \n WebGPU uses ArrayBuffers as wrappers for backing stores. These backing stores change often. That leads to new ArrayBuffers being created and increased garbage collection – which can degrade performance, e.g. during animations. The solution is to “re-point” the same ArrayBuffer to different backing stores. To JavaScript code, this looks like the ArrayBuffer being resized and overwritten. No additional mechanism for re-pointing needs to be introduced ( source ). \n \n New features for ArrayBuffers   # These are the changes introduced by the feature: \n The existing constructor gets one more parameter: \n \n There is one new method and two new getters:\n \n \n \n \n \n \n The existing method   always returns non-resizable ArrayBuffers. \n The   object of the constructor determines whether or not an ArrayBuffer is resizable: How Typed Arrays react to changing ArrayBuffer sizes   # This is what constructors of Typed Arrays look like: If   is   then the   and   of the Typed Array instance automatically tracks the length of a resizable  : If an ArrayBuffer is resized then a wrapper with a fixed length can  : The wrapper’s range isn’t covered by the ArrayBuffer anymore. That is treated by JavaScript as if the ArrayBuffer were detached ( more on detaching later in this blog post ): \n ,   and   are zero. \n Getting elements returns  . \n Setting elements is silently ignored. \n All element-related methods throw errors. \n Guidelines given by the ECMAScript specification   # The ECMAScript specification gives  the following guidelines  for working with resizable ArrayBuffers: \n \n We recommend that programs be tested in their deployment environments where possible. The amount of available physical memory differs greatly between hardware devices. Similarly, virtual memory subsystems also differ greatly between hardware devices as well as operating systems. An application that runs without out-of-memory errors on a 64-bit desktop web browser could run out of memory on a 32-bit mobile web browser. \n \n \n When choosing a value for the   option for resizable ArrayBuffer, we recommend that the smallest possible size for the application be chosen. We recommend that   does not exceed 1,073,741,824 (2^30^ bytes or 1 GiB). \n \n \n Please note that successfully constructing a resizable ArrayBuffer for a particular maximum size does not guarantee that future resizes will succeed. \n \n  and friends   # Preparation: transferring data and detaching   # The web API (not the ECMAScript standard) has long supported   for safely moving values across realms ( , iframes, web workers, etc.). Some objects can also be  : After cloning, the original becomes   (inaccessible) and ownership switches from the original to the clone. Transfering is usually faster than copying, especially if large amounts of memory are involved. These are the most common classes of  : \n \n Streams:\n \n \n \n \n \n \n DOM-related data:\n \n \n \n \n \n Miscellaneous communication:\n \n \n \n \n \n New functionality   # The feature   and friends”  provides the following new functionality: \n Two methods let us explicitly transfer an ArrayBuffer to a new object (we’ll see soon why that is useful):\n \n \n \n \n \n One getter tells us if an ArrayBuffer is detached:\n \n \n \n \n Transferring ArrayBuffers via     # Interestingly, the broadly supported   already lets us transfer (and therefore detach) ArrayBuffers: The ArrayBuffer method   simply gives us a more concise way to detach an ArrayBuffer: Transferring an ArrayBuffer within the same agent   # Transferring is most often used between two agents (main thread or web worker). However, transferring within the same agent can make sense too: If a function gets a (potentially shared) ArrayBuffer as a parameter, it can transfer it so that no external code can interfere with what it does. Example (taken from  the ECMAScript proposal  and slightly edited): How does detaching an ArrayBuffer affect its wrappers?   # # Preparation: Lengths and offsets are all zero: Getting elements returns  ; setting elements fails silently: All element-related methods throw exceptions: # All data-related methods of DataViews throw: #    # This method rounds out the API: It transfers and converts a resizable ArrayBuffer to one with a fixed length. That may free up memory that was held in preparation for growth. Resizing and transferring SharedArrayBuffers   # \n Resizable SharedArrayBuffers can only grow – given that shrinking shared memory is tricky. \n SharedArrayBuffers can’t be transferred. \n Conclusion and further reading   # Resizing and and transferring ArrayBuffers rounds out the Typed Array/DataView/ArrayBuffer API and helps with WebAssembly and other code that uses that API. If you want to read more about Typed Arrays, DataViews and ArrayBuffers: \n Chapter “Typed Arrays: handling binary data”  in “JavaScript for impatient programmers” \n “A cartoon intro to ArrayBuffers and SharedArrayBuffers”  by Lin Clark \n comments powered by Disqus."},
{"url": "https://2ality.com/2024/06/ecmascript-2024.html", "title": "Ecma International approves ECMAScript 2024: What’s new?", "content": "Ecma International approves ECMAScript 2024: What’s new? dev javascript es2024 On 26 June 2024,  the 127th Ecma General Assembly approved the ECMAScript 2024 language specification , which means that it’s officially a standard now. This blog post explains what’s new. \n   \n     The editors of ECMAScript 2024 \n   \n   \n     What’s new in ECMAScript 2024? \n     \n       \n         Grouping synchronous iterables \n       \n       \n         \n       \n       \n         Regular expression flag  \n       \n       \n         New features for ArrayBuffers and SharedArrayBuffers \n       \n       \n         Ensuring that strings are well-formed \n       \n       \n         \n       \n     \n   \n   \n     Free book on ECMAScript 2024 \n   \n The editors of ECMAScript 2024   # The editors of this release are: \n Shu-yu Guo \n Michael Ficarra \n Kevin Gibbons \n What’s new in ECMAScript 2024?   # Grouping synchronous iterables   #  groups the items of an iterable into Map entries whose keys are provided by a callback: There is also   which produces an object instead of a Map: For tips on choosing between these two methods and more examples, see  “Exploring JavaScript” .    #  provides a new way of creating Promises that we want to resolve: Regular expression flag     # The new regular expression flag   ( )  enables these features: \n \n Escapes for Unicode string properties (😵‍💫 consists of three code points): \n \n \n \n String literals via   in character classes: \n \n \n \n Set operations for character classes: \n \n \n \n Improved matching with   if a Unicode property escape is negated via  \n \n New features for ArrayBuffers and SharedArrayBuffers   # ArrayBuffers get two new features: \n They can be  resized  in place: \n \n They get a method   for  transferring  them. \n SharedArrayBuffers can be resized, but they can only grow and never shrink. They are not transferrable and therefore don’t get the method   that   got. Ensuring that strings are well-formed   # Two new methods help us ensure that strings are well-formed (w.r.t.  UTF-16  code units): \n String method   checks if a JavaScript string is   and does not contain any  . \n String method   returns a copy of the receiver where each lone surrogate is replaced with the code unit 0xFFFD (which represents the code point with the same number, whose name is “replacement character”). The result is therefore well-formed. \n    #  lets us wait asynchronously for a change to shared memory. See  the MDN Web Docs  for more information. Free book on ECMAScript 2024   # My book  “Exploring JavaScript (ES2024 Edition)”  is free to read online. Two chapters are especially relevant: \n “History and evolution of JavaScript” : ECMAScript vs. JavaScript, TC39, TC39 process, ECMAScript proposals, etc. \n “New JavaScript features” : What are the new features of each ECMAScript version? \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/09/nodejs-overview.html", "title": "An overview of Node.js: architecture, APIs, event loop, concurrency", "content": "An overview of Node.js: architecture, APIs, event loop, concurrency dev javascript nodejs chapter “An overview of Node.js: architecture, APIs, event loop, concurrency” This blog post gives an overview of how Node.js works: \n What its architecture looks like. \n How its APIs are structured.\n \n A few highlights of its global variables and built-in modules. \n \n \n How it runs JavaScript in a single thread via an  . \n Options for concurrent JavaScript on this platform. \n \n   \n     The Node.js platform \n     \n       \n         Global Node.js variables \n       \n       \n         The built-in Node.js modules \n       \n       \n         The different styles of Node.js functions \n       \n     \n   \n   \n     The Node.js event loop \n     \n       \n         Running to completion makes code simpler \n       \n       \n         Why does Node.js code run in a single thread? \n       \n       \n         The real event loop has multiple phases \n       \n       \n         Next-tick tasks and microtasks \n       \n       \n         Comparing different ways of directly scheduling tasks \n       \n       \n         When does a Node.js app exit? \n       \n     \n   \n   \n     libuv: the cross-platform library that handles asynchronous I/O (and more) for Node.js \n     \n       \n         How libuv handles asynchronous I/O \n       \n       \n         How libuv handles blocking I/O \n       \n       \n         libuv functionality beyond I/O \n       \n     \n   \n   \n     Escaping the main thread with user code \n     \n       \n         Worker threads \n       \n       \n         Clusters \n       \n       \n         Child processes \n       \n     \n   \n   \n     Sources of this blog post \n     \n       \n         Acknowledgement \n       \n     \n   \n The Node.js platform   # The following diagram provides an overview of how Node.js is structured: The APIs available to a Node.js app consist of: \n The ECMAScript standard library (which is part of the language) \n Node.js APIs (which are not part of the language proper):\n \n Some of the APIs are provided via global variables:\n \n Especially cross-platform web APIs such as   and   fall into this category. \n But a few Node.js-only APIs are global, too – for example,  . \n \n \n The remaining Node.js APIs are provided via built-in modules – for example,   (functions and constants for handling file system paths) and   (functionality related to the file system). \n \n \n The Node.js APIs are partially implemented in JavaScript, partially in C++. The latter is needed to interface with the operating system. Node.js runs JavaScript via an embedded V8 JavaScript engine (the same engine used by Google’s Chrome browser). Global Node.js variables   # These are a few highlights of  Node’s global variables : \n \n  gives us access to a web-compatible  crypto API . \n \n \n  has much overlap with the same global variable in browsers (  etc.). \n \n \n  lets us use  the Fetch browser API . \n \n \n  contains an instance of  class   and gives us access to command line arguments, standard input, standard out, and more. \n \n \n  is a browser-compatible function for cloning objects. \n \n \n  is a browser-compatible class for handling URLs. \n \n More global variables are mentioned throughout this blog post. The built-in Node.js modules   # Most of Node’s APIs are provided via modules. These are a few frequently used ones (in alphabetical order): \n \n : Assertions are functions that check if a condition is met and report an error if not. They can be used in application code and for unit testing. This is an example of using this API: \n \n \n \n  is for running native commands synchronously or in separate processes. This module is described in  the blog post “Executing shell commands from Node.js” . \n \n \n  provides file system operations such as reading, writing, copying and deleting files and directories. See  the blog post “Working with the file system on Node.js”  for more information. \n \n \n  contains operating-system-specific constants and utility functions. Some of them are explained in  the blog post “Working with file system paths on Node.js” . \n \n \n  is a cross-platform API for working with file system paths. It is described in  the blog post “Working with file system paths on Node.js” . \n \n \n  contains a Node.js-specific streams API. \n \n Node.js also supports  the cross-platform web streams API  which is the subject of  the blog post “Using web streams on Node.js” . \n \n \n \n  contains various utility functions. \n \n Function   is described in  the blog post “Parsing command line arguments with   on Node.js” . \n \n \n Module   contains function   which returns an Array with the specifiers of all built-in modules: The different styles of Node.js functions   # In this section, we use the following import: Node’s functions come in three different styles. Let’s look at the built-in module   as an example: \n A synchronous style with normal functions – for example:\n \n \n \n \n Two asynchronous styles:\n \n An asynchronous style with callback-based functions – for example:\n \n \n \n \n An asynchronous style with Promise-based functions – for example:\n \n \n \n \n \n \n The three examples we have just seen, demonstrate the naming convention for functions with similar functionality: \n A callback-based function has a base name:  \n Its Promise-based version has the same name, but in a different module:  \n The name of its synchronous version is the base name plus the suffix “Sync”:  \n Let’s take a closer look at how these three styles work. # Synchronous functions are simplest – they immediately return values and throw errors as exceptions: # Promise-based functions return Promises that are fulfilled with results and rejected with errors: Note the module specifier in line A: The Promise-based API is located in a different module. Promises are explained in more detail in  “JavaScript for impatient programmers” . # Callback-based functions pass results and errors to callbacks which are their last parameters: This style is explained in more detail in  the Node.js documentation . The Node.js event loop   # By default, Node.js executes all JavaScript in a single thread, the  . The main thread continuously runs the   – a loop that executes chunks of JavaScript. Each chunk is a callback and can be considered a cooperatively scheduled task. The first task contains the code (coming from a module or standard input) that we start Node.js with. Other tasks are usually added later, due to: \n Code manually adding tasks \n I/O (input or output) with the file system, with network sockets, etc. \n Etc. \n A first approximation of the event loop looks like this: That is, the main thread runs code similar to: The event loop takes callbacks out of a   and executes them in the main thread. Dequeuing   (pauses the main thread) if the task queue is empty. We’ll explore two topics later: \n How to exit from the event loop. \n How to get around the limitation of JavaScript running in a single thread. \n Why is this loop called  ? Many tasks are added in response to events, e.g. ones sent by the operating system when input data is ready to be processed. How are callbacks added to the task queue? These are common possibilities: \n JavaScript code can add tasks to the queue so that they are executed later. \n When an   (a source of events) fires an event, the invocations of the event listeners are added to the task queue. \n Callback-based asynchronous operations in the Node.js API follow this pattern:\n \n We ask for something and give Node.js a callback function with which it can report the result to us. \n Eventually, the operation runs either in the main thread or in an external thread (more on that later). \n When it is done, an invocation of the callback is added to the task queue. \n \n \n The following code shows an asynchronous callback-based operation in action. It reads a text file from the file system: This is the ouput:  executes the code that reads the file in another thread. In this case, the code succeeds and adds this callback to the task queue: Running to completion makes code simpler   # An important rule for how Node.js runs JavaScript code is: Each task finishes (“runs to completion”) before other tasks run. We can see that in the previous example:   in line B is logged before the result is logged in line A because the initial task finishes before the task with the invocation of   runs. Running to completion means that task lifetimes don’t overlap and we don’t have to worry about shared data being changed in the background. That simplifies Node.js code. The next example demonstrates that. It implements a simple HTTP server: We run this code via  . After that, the code starts and waits for HTTP requests. We can send them by using a web browser to go to  . Each time we reload that HTTP resource, Node.js invokes the callback that starts in line A. It serves a message with the current value of variable   (line B) and increments it (line C). Each invocation of the callback is a new task and variable   is shared between tasks. Due to running to completion, it is easy to read and update. There is no need to synchronize with other concurrently running tasks because there aren’t any. Why does Node.js code run in a single thread?   # Why does Node.js code run in a single thread (with an event loop) by default? That has two benefits: \n \n As we have already seen, sharing data between tasks is simpler if there is only a single thread. \n \n \n In traditional multi-threaded code, an operation that takes longer to complete blocks the current thread until the operation is finished. Examples of such operations are reading a file or processing HTTP requests. Performing many of these operations is expensive because we have to create a new thread each time. With an event loop, the per-operation cost is lower, especially if each operation doesn’t do much. That’s why event-loop-based web servers can handle higher loads than thread-based ones. \n \n Given that some of Node’s asynchronous operations run in threads other than the main thread (more on that soon) and report back to JavaScript via the task queue, Node.js is not really single-threaded. Instead, we use a single thread to coordinate operations that run concurrently and asynchronously (in the main thread). This concludes our first look at the event loop.   if a superficial explanation is enough for you. Read on to learn more details. The real event loop has multiple phases   # The real event loop has multiple task queues from which it reads in multiple phases ( you can check out some of the JavaScript code in the GitHub repository  ). The following diagram shows the most important ones of those phases: What do the event loop phases do that are shown in the diagram? \n \n Phase “timers” invokes   that were added to its queue by: \n \n  runs the callback   after   milliseconds. \n  runs the callback   repeatedly, with pauses lasting   milliseconds. \n \n \n \n Phase “poll” retrieves and processes I/O events and runs I/O-related tasks from its queue. \n \n \n Phase “check” (the “immediate phase”) executes tasks scheduled via: \n \n  runs the callback   as soon as possible (“immediately” after phase “poll”). \n \n \n Each phase runs until its queue is empty or until a maximum number of tasks was processed. Except for “poll”, each phase waits until its next turn before it processes tasks that were added during its run. # \n If the poll queue is not empty, the poll phase will go through it and run its tasks. \n Once the poll queue is empty:\n \n If there are   tasks, processing advances to the “check” phase. \n If there are timer tasks that are ready, processing advances to the “timers” phase. \n Otherwise, this phase blocks the whole main thread and waits until new tasks are added to the poll queue (or until this phase ends, see below). These are processed immediately. \n \n \n If this phase takes longer than a system-dependent time limit, it ends and the next phase runs. Next-tick tasks and microtasks   # After each invoked task, a “sub-loop” runs that consists of two phases: The sub-phases handle: \n Next-tick tasks, as enqueued via  . \n Microtasks, as enqueued via  , Promise reactions, etc. \n Next-tick tasks are Node.js-specific, Microtasks are a cross-platform web standard (see  MDN’s support table ). This sub-loop runs until both queues are empty. Tasks added during its run, are processed immediately – the sub-loop does not wait until its next turn. Comparing different ways of directly scheduling tasks   # We can use the following functions and methods to add callbacks to one of the task queues: \n Timed tasks (phase “timers”)\n \n  (web standard) \n  (web standard) \n \n \n Untimed tasks (phase “check”)\n \n  (Node.js-specific) \n \n \n Tasks that run immediately after the current task:\n \n  (Node.js-specific) \n : (web standard) \n \n \n It’s important to note that when timing a task via a delay, we are specifying the earliest possible time that the task will run. Node.js cannot always run them at exactly the scheduled time because it can only check between tasks if any timed tasks are due. Therefore, a long-running task can cause timed tasks to be late. # Consider the following code: We use   to avoid a pecularity of ESM modules: They are executed in microtasks, which means that if we enqueue microtasks at the top level of an ESM module, they run before next-tick tasks. As we’ll see next, that’s different in most other contexts. This is the output of the previous code: Observations: \n \n All next-tick tasks are executed immediately after  . \n \n \n They are followed by all microtasks, including Promise reactions. \n \n \n Phase “timers” comes after the immediate phase. That’s when the timed tasks are executed. \n \n \n We have added immediate tasks during the immediate (“check”) phase (line A and line B). They show up last in the output, which means that they were not executed during the current phase, but during the next immediate phase. \n \n # The next code examines what happens if we enqueue a next-tick task during the next-tick phase and a microtask during the microtask phase: This is the output: Observations: \n \n Next-tick tasks are executed first. \n \n \n “nextTick 2” in enqueued during the next-tick phase and immediately executed. Execution only continues once the next-tick queue is empty. \n \n \n The same is true for microtasks. \n \n \n We enqueue “nextTick 3” during the microtask phase and execution loops back to the next-tick phase. These subphases are repeated until both their queues are empty. Only then does execution move on to the next global phases: First the “timers” phase (“setTimeout 1”). Then the immediate phase (“setImmediate 1”). \n \n # The following code explores which kinds of tasks can   event loop phases (prevent them from running via infinite recursion): The “timers” phase and the immediate phase don’t execute tasks that are enqueued during their phases. That’s why   and   don’t starve out   which reports back during the “poll” phase (there is also a Promise reaction, but let’s ignore that here). Due to how next-tick tasks and microtasks are scheduled, both   and   prevent the output in the last line. When does a Node.js app exit?   # At the end of each iteration of the event loop, Node.js checks if it’s time to exit. It keeps a reference count of pending   (for timed tasks): \n Scheduling a timed task via  ,  , or   increases the reference count. \n Running a timed task decreases the reference count. \n If the reference count is zero at the end of an event loop iteration, Node.js exits. We can see that in the following example: Node.js waits until the Promise returned by   is fulfilled. Why? Because the task we schedule in line A keeps the event loop alive. In contrast, creating Promises does not increase the reference count: In this case, execution temporarily leaves this (main) task during   in line A. At the end of the event loop, the reference count is zero and Node.js exits. However, the exit is not successful. That is, the exit code is not 0, it is 13 ( “Unfinished Top-Level Await” ). We can manually control whether a timeout keeps the event loop alive: By default, tasks scheduled via  ,  , and   keep the event loop alive as long as they are pending. These functions return instances of  class   whose method   changes that default so that the timeout being active won’t prevent Node.js from exiting. Method   restores the default. Tim Perry mentions a use case for  : His library used   to repeatedly run a background task. That task prevented applications from exiting. He fixed the issue via  . libuv: the cross-platform library that handles asynchronous I/O (and more) for Node.js   # libuv is a library written in C that supports many platforms (Windows, macOS, Linux, etc.). Node.js uses it to handle I/O and more. How libuv handles asynchronous I/O   # Network I/O is asynchronous and doesn’t block the current thread. Such I/O includes: \n TCP \n UDP \n Terminal I/O \n Pipes (Unix domain sockets, Windows named pipes, etc.) \n To handle asynchronous I/O, libuv uses native kernel APIs and subscribes to I/O events (epoll on Linux; kqueue on BSD Unix incl. macOS; event ports on SunOS; IOCP on Windows). It then gets notifications when they occur. All of these activities, including the I/O itself, happen on the main thread. How libuv handles blocking I/O   # Some native I/O APIs are blocking (not asynchronous) – for example, file I/O and some DNS services. libuv invokes these APIs from threads in a thread pool (the so-called “worker pool”). That enables the main thread to use these APIs asynchronously. libuv functionality beyond I/O   # libuv helps Node.js with more than just with I/O. Other functionality includes: \n Running tasks in the thread pool \n Signal handling \n High resolution clock \n Threading and synchronization primitives \n As an aside, libuv has its own event loop whose source code you can check out in the GitHub repository   ( function  ). Escaping the main thread with user code   # If we want to keep Node.js responsive to I/O, we should avoid performing long-running computations in main-thread tasks. There are two options for doing so: \n \n Partitioning: We can split up the computation into smaller pieces and run each piece via  . That enables the event loop to perform I/O between the pieces. \n \n An upside is that we can perform I/O in each piece. \n A downside is that we still slow down the event loop. \n \n \n \n Offloading: We can perform our computation in a different thread or process. \n \n Downsides are that we can’t perform I/O from threads other than the main thread and that communicating with outside code becomes more complicated. \n Upsides are that we don’t slow down the event loop, that we can make better use of multiple processor cores, and that errors in other threads don’t affect the main thread. \n \n \n The next subsections cover a few options for offloading. Worker threads   # Worker Threads  implement  the cross-platform Web Workers API  with a few differences – e.g.: \n \n Worker Threads have to be imported from a module, Web Workers are accessed via a global variable. \n \n \n Inside a worker, listening to messages and posting messages is done via methods of the global object in browsers. On Node.js, we import   instead. \n \n \n We can use most Node.js APIs from workers. In browsers, our choice is more limited (we can’t use the DOM, etc.). \n \n \n On Node.js, more objects are transferable ( all objects whose classes extend the internal class  ) than in browsers. \n \n On one hand, Worker Threads really are threads: They are more lightweight than processes and run in the same process as the main thread. On the other hand: \n Each worker runs its own event loop. \n Each worker has its own JavaScript engine instance and its own Node.js instance – including separate global variables.\n \n (Specifically, each worker is an   that has its own JavaScript heap but shares its operating system heap with other threads.) \n \n \n Sharing data between threads is limited:\n \n We can share binary data/numbers via SharedArrayBuffers. \n  offers atomic operations and synchronization primitives that help when using SharedArrayBuffers. \n The Channel Messaging API  lets us send data (“messages”) over two-way channels. The data is either   (copied) or   (moved). The latter is more efficient and only supported by  a few data structures . \n \n \n For more information, see  the Node.js documentation on worker threads . Clusters   # Cluster  is a Node.js-specific API. It lets us run   of Node.js processes that we can use to distribute workloads. The processes are fully isolated but share server ports. They can communicate by passing JSON data over channels. If we don’t need process isolation, we can use Worker Threads which are more lightweight. Child processes   # Child process  is another Node.js-specific API. It lets us spawn new processes that run native commands (often via native shells). This API is covered in  the blog post “Executing shell commands from Node.js” . Sources of this blog post   # Node.js event loop: \n Node.js documentation:  “The Node.js Event Loop, Timers, and  ” \n “What you should know to really understand the Node.js Event Loop”  by Daniel Khan \n “How does Node.js decide whether to exit the event loop or go around again?”  by Mark Meyer \n Videos on the event loop (which refresh some of the background knowledge needed for this blog post): \n “Node’s Event Loop From the Inside Out”  (by Sam Roberts) explains why operating systems added support for asynchronous I/O; which operations are asynchronous and which aren’t (and have to run in the thread pool); etc. \n “The Node.js Event Loop: Not So Single Threaded”  (by Bryan Hughes) contains a brief history of multitasking (cooperative multitasking, preemptive multitasking, symmteric multi-threading, asynchronous multitasking); processes vs. threads; running I/O synchronously vs. in the thread pool; etc. \n libuv: \n libuv documentation:\n \n “Design overview”   \n “Basics of libuv”   \n \n \n “A deep dive into libuv”  by Saúl Ibarra Corretgé \n “I/O multiplexing (select vs. poll vs. epoll/kqueue) - problems and algorithms”  by Nima Aghdaii \n “Developer Initiates I/O Operation. You Won't Believe What Happens Next.”  by Colin J. Ihrig\n \n Traces a JavaScript function call as it goes from JavaScript to Node’s core to libuv and back. \n \n \n JavaScript concurrency: \n Section “Complex calculations without blocking the Event Loop”  in “Don't Block the Event Loop (or the Worker Pool)” in the Node.js documentation \n “Understanding Worker Threads in Node.js”  by Liz Parody \n “The State Of Web Workers In 2021”  by Surma \n Video  “Node.js: The Road to Workers”  by Anna Henningsen \n Acknowledgement   # \n I’m much obliged to  Dominic Elm  for reviewing this blog post and providing important feedback. \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/10/javascript-decorators.html", "title": "JavaScript metaprogramming with the 2022-03 decorators API", "content": "JavaScript metaprogramming with the 2022-03 decorators API dev javascript es proposal JavaScript decorators have finally reached  stage 3 ! Their latest version is already supported by Babel and  will soon be supported by TypeScript . This blog post covers the 2022-03 version (stage 3) of the ECMAScript proposal  “Decorators”  by Daniel Ehrenberg and Chris Garrett. A decorator is a keyword that starts with an   symbol and can be put in front of classes and class members (such as methods). For example,   is a decorator: A decorator changes how the decorated construct works. In this case, every invocation of   will be “traced” (arguments and result will be logged to the console).  We’ll see how   is implemented later. Decorators are mostly an object-oriented feature and popular in OOP frameworks and libraries such as Ember, Angular, Vue, web component frameworks and MobX. There are two stakeholders when it comes to decorators: \n Library authors have to know their API so that they can implement them. \n Library users only have to know how to apply them. \n This blog post is intended for library authors: We’ll learn how decorators work and use our knowledge to implement several of them. \n   \n     The history of decorators (optional section) \n     \n       \n         The history of decorators \n       \n       \n         The history of Babel’s decorator implementation \n       \n     \n   \n   \n     What are decorators? \n     \n       \n         The shape of decorator functions \n       \n       \n         What can decorators do? \n       \n       \n         Summary tables \n       \n     \n   \n   \n     More information on the syntax and semantics of decorators (optional section) \n     \n       \n         The syntax of decorator expressions \n       \n       \n         How are decorators executed? \n       \n       \n         When do decorator initializers run? \n       \n     \n   \n   \n     Techniques for exposing data from decorators \n     \n       \n         Storing exposed data in a surrounding scope \n       \n       \n         Managing exposed data via a factory function \n       \n       \n         Managing exposed data via a class \n       \n     \n   \n   \n     Class decorators \n     \n       \n         Example: collecting instances \n       \n       \n         Making sure that   works \n       \n       \n         Example: freezing instances \n       \n       \n         Example: making classes function-callable \n       \n     \n   \n   \n     Class method decorators \n     \n       \n         Example: tracing method invocations \n       \n       \n         Example: binding methods to instances \n       \n       \n         Example: applying functions to methods \n       \n     \n   \n   \n     Class getter decorators, class setter decorators \n     \n       \n         Example: computing values lazily \n       \n     \n   \n   \n     Class field decorators \n     \n       \n         Example: changing initialization values of fields \n       \n       \n         Example: read-only fields (instance public fields) \n       \n       \n         Example: dependency injection (instance public fields) \n       \n       \n         Example: “friend” visibility (instance private fields) \n       \n       \n         Example: enums (static public fields) \n       \n     \n   \n   \n     Auto-accessors: a new member of class definitions \n     \n       \n         Why are auto-accessors needed? \n       \n     \n   \n   \n     Class auto-accessor decorators \n     \n       \n         Example: read-only auto-accessors \n       \n     \n   \n   \n     Frequently asked questions \n     \n       \n         Why can’t functions be decorated? \n       \n     \n   \n   \n     More decorator-related proposals \n   \n   \n     Resources \n     \n       \n         Implementations \n       \n       \n         Libraries with decorators \n       \n     \n   \n   \n     Acknowledgements \n   \n   \n     Further reading \n   \n The history of decorators (optional section)   # (This section is optional. If you skip it, you can still understand the remaining content.) Let’s start by looking at the history of decorators. Among others, two questions will be answered: \n Why is this proposal taking so long? \n Why does it feel like JavaScript has already had decorators for years? \n The history of decorators   # The following history describes: \n How various groups both worked on their own projects and collaborated on the TC39 proposal. \n How the TC39 proposal advanced through the stages of  the TC39 process  (which start at 0 and end at 4, when the proposal is ready to be added to ECMAScript). Along the way, the proposal changed in numerous ways. \n This is a chronological account of relevant events: \n \n 2014-04-10 : Decorators were proposed to TC39 by Yehuda Katz. The proposal advanced to stage 0. \n \n Katz’s proposal was created in collaboration with Ron Buckton. Discussions about that proposal date back as far as  July 2013 . \n \n \n \n 2014-10-22 (ngEurope conference, Paris): The Angular team announced that Angular 2.0 was being written in AtScript and compiled to JavaScript (via Traceur) and Dart. Plans included basing AtScript on TypeScript while adding: \n \n Three kinds of  :\n \n \n  explicitly declare fields. \n  have the same syntax as decorators but only add metadata and don’t change how annotated constructs work. \n \n \n Runtime type checking \n Type introspection \n \n \n \n 2015-01-28 : Yehuda Katz and Jonathan Turner reported that Katz and the TypeScript team were exchanging ideas. \n \n \n 2015-03-05 (ng-conf, Salt Lake City): The Angular team and the TypeScript team announced that Angular would switch from AtScript to TypeScript and that TypeScript would adopt some of AtScript’s features (especially decorators). \n \n \n 2015-03-24 : The decorator proposal reached stage 1. At that time, they had  a repository on GitHub  (created by Yehuda Katz) that was later moved to  its current location . \n \n \n 2015-07-20:  TypeScript 1.5  came out and supported  stage 1 decorators  behind the flag  . \n Several JavaScript projects (e.g. Angular and MobX) used this TypeScript feature which made it look like JavaScript already had decorators. \n So far, TypeScript has not supported a newer version of the decorators API.  A pull request by Ron Buckton provides support for stage 3 decorators  and will likely ship in the release after v4.9. \n \n \n 2016-07-28 : The proposal reached stage 2, after a presentation by Yehuda Katz and Brian Terlson. \n \n \n 2017-07-27 : Daniel Ehrenberg held his first decorator presentation, after joining the proposal a few months earlier. He drove its evolution for several years. \n \n \n Later, Chris Garrett joined the proposal and helped get it to stage 3, which happened  on 2022-03-28 . Decorator metadata was moved to  a separate proposal  that started at stage 2. \n \n It took a long time to reach stage 3 because it was difficult to get all stakeholders to agree on an API. Concerns included interactions with other features (such as class members and private state) and performance. The history of Babel’s decorator implementation   # Babel closely tracked the evolution of the decorator proposal, thanks to the efforts of Logan Smyth, Nicolò Ribaudo and others: \n \n 2015-03-31 : Babel 5.0.0 supported stage 1 decorators. \n \n \n 2015-11-29  An external plugin by Logan Smyth brought support for stage 1 decorators to Babel 6. \n \n \n 2018-08-27  Babel 7.0.0 supported stage 2 decorators via the official  . \n \n \n The official plugin currently supports  the following versions : \n \n :  stage 1 decorators \n :  stage 2 decorators \n :  an updated version of the original stage 2 decorators \n :  stage 3 decorators \n \n \n What are decorators?   # Decorators let us change how JavaScript constructs (such as classes and methods) work. Let’s revisit our previous example with the decorator  : To implement  , we only have to write a function ( the exact implementation will be shown later ): The class with the decorated method is roughly equivalent to the following code: In other words: A decorator is a function that we can apply to language constructs. We do so by putting   plus its name in front of them. Writing and using decorators is  : \n We don’t write code that processes user data ( ). \n We write code that processes code that processes user data ( ). \n For more information on metaprogramming, see  section “Programming versus metaprogramming”  in “Deep JavaScript”. The shape of decorator functions   # Before we explore examples of decorator functions, I’d like to take a look at their TypeScript type signature: That is, a decorator is a function. Its parameters are: \n The   that the decorator is applied to. \n The object   with:\n \n Additional information on   ( ,  ) \n A small API ( ,  ) with metaprogramming functionality \n \n \n Property   tells the decorator which kind of JavaScript construct it is applied to. We can use the same function for multiple constructs. Currently, decorators can be applied to classes, methods, getters, setters, fields, and   (a new class member that is explained  later ). The values of   reflect that: \n \n \n \n \n \n \n This is the exact type of  : We’ll soon encounter each of these kinds of decorators and its type signature – where only these parts change: \n The type of  \n Some of the properties of  \n The return type \n What can decorators do?   # Each decorator has up to four abilities: \n \n It can change the decorated entity by changing the parameter  . \n \n \n It can replace the decorated entity by returning a compatible value: \n \n “Compatible” means that the returned value must have the same type as the decorated value – e.g., class decorators must return callable values. \n If the decorator doesn’t want to replace the decorated value, it can return   – either explicitly or implicitly, by not returning anything. \n \n \n \n Exposing access to the decorated entity to others.   enables it to do that, via its methods   and  . \n \n \n Processing the decorated entity and its container (if it has one), after both exist: That functionality is provided by  . It lets the decorator register an   – a callback that is invoked when everything is ready (more details are explained  later ). \n \n The next subsections demonstrate these abilities. We initially won’t use   to check which kind of construct a decorator is applied to. We will do that later, though. # In the following example, the decorator   replaces method   (line B) with a function that it returns (line A). # In the next example, the decorator   stores an object in the variable   that lets us access property   of the instances of  . # In the following code, we use the decorator   to store the keys of decorated methods in the instance property  : The initializer function added by the decorator in line A must be an ordinary function because access to the implicit parameter   is needed. Arrow functions don’t provide this access – their   is statically scoped (like any normal variable). Summary tables   # Type signature: Value of   in functions: More information on the syntax and semantics of decorators (optional section)   # (This section is optional. If you skip it, you can still understand the remaining content.) The syntax of decorator expressions   # \n A decorator expression starts with a chain of one or more identifiers, separated by dots. Each identifier except the first one can be private (prefix  ). Square brackets   are not allowed. \n Optional at the end: function call arguments in parentheses. The next subsection explains what that means. \n We can use any expression if we put it in parentheses: \n \n Wherever decorators are allowed, we can use more than one of them. The following code demonstrates decorator syntax: How are decorators executed?   # \n \n Evaluation: The expressions after the   symbols are evaluated during the execution of the class definition, along with computed property keys and static fields (see code below). The results must be functions. They are stored in temporary locations (think local variables), to be invoked later. \n \n \n Invocation: The decorator functions are called later during the execution of a class definition, after methods have been evaluated but before constructor and prototype have been assembled. Once again the results are stored in temporary locations. \n \n \n Application: After all decorator functions were invoked, their results are used, which can affect constructor and prototype. Class decorators are applied after all method and field decorators. \n \n The following code illustrates in which order decorator expressions, computed property keys and field initializers are evaluated: Function   is invoked whenever the expression   after the   symbol is evaluated. In line A, it returns the actual decorator function, which is applied later. When do decorator initializers run?   # When a decorator initializer runs, depends on the kind of decorator: \n \n Class decorator initializers run after the class is fully defined and all static fields were initialized. \n \n \n The initializers of non-static class element decorators run during instantiation, before instance fields are initialized. \n \n \n The initializers of static class element decorators run during class definition, before static fields are defined but after other all other class elements were defined. \n \n Why is that? For non-static initializers, we have five options – they can run: Before  After  , before field initialization Interleaved between fields in definition order After field initialization, before child class instantiation After child class instantiation Why was #2 chosen? \n \n #1 was rejected because decorator initializers must be able to access  , which isn’t possible before   runs. \n \n \n #3 was rejected because running all decorator initializers at the same time is simpler than ensuring that they are properly interleaved. \n \n \n \n #4 was rejected because running decorator initializers before fields ensures that fields don’t see partially initialized methods. For example, if there are   decorators, then field initializers can rely on the decorated methods being bound. \n \n \n #5 was rejected because it would allow superclasses to interfere with subclasses, which would break the rule that superclasses should not be aware of their subclasses. \n \n The following code demonstrates in which order Babel currently invokes decorator initializers. Note that Babel does not yet support initializers for class field decorators (which was a recent change to the decorators API). Techniques for exposing data from decorators   # Sometimes decorators collect data. Let’s explore how they can make this data available to other parties. Storing exposed data in a surrounding scope   # The simplest solution is to store data in a location in a surrounding scope. For example, the decorator   collects classes and stores them in the Set   (line A): The downside of this approach is that it doesn’t work if a decorator comes from another module. Managing exposed data via a factory function   # A more sophisticated approach is to use a factory function   that returns: \n A class decorator  \n A Set  , to which the decorator will add the classes it collects \n Managing exposed data via a class   # Instead of a factory function, we can also use a class. It has two members: \n , a Set with the collected classes \n , a class decorator \n We implemented   by assigning an arrow function to a public instance field (line A). Instance field initializers run in scopes where   refers to the current instance. That is also the outer scope of the arrow function and explains what value   has in line B. We could also implement   via a getter, but then we’d have to return a new function whenever   is read. Class decorators   # Class decorators have the following type signature: Abilities of a class decorator: \n It can change the decorated class by changing  . \n It can replace the decorated class by returning a callable value. \n It can register initializers, which are called after the decorated class is fully set up. \n It does not get   because classes are not members of other language constructs (whereas, e.g., methods are members of classes). \n Example: collecting instances   # In the next example, we use a decorator to collect all instances of a decorated class: The only way in which we can collect all instances of a given class via a decorator is by wrapping that class. The decorator in the field   does that by returning a function (line A) that new-calls the decorated   (line B) and collects and returns the result. Note that we can’t return an arrow function in line A, because arrow functions can’t be new-called. One downside of this approach is that it breaks  : The next subsection explains how we can fix that. Making sure that   works   # In this section, we use the simple decorator   to show how we can support   for wrapped classes. # One way of enabling   is to set the   of the wrapper function to the   of the wrapped   (line A): Why does that work? Because the following expressions are equivalent: For more information on  , see  “JavaScript for impatient programmers” . # Another option for enabling   is to give the wrapper function a method whose key is   (line A): “JavaScript for impatient programmers” has  more information on  . # We can also enable   by returning a subclass of   (line A): Example: freezing instances   # The decorator class   freezes all instances produced by the classes it decorates: This decorator has downsides: \n It breaks  . We have already seen how to fix this. \n Subclassing a decorated class doesn’t work well:\n \n The way in which constructors are connected isn’t ideal – with a wrapped constructor in the mix. This can be partially fixed by returning a subclass of the decorated  . \n Subclasses can’t set up properties, because their   is immutable. There is no way to avoid this downside. \n \n \n The last downside could be avoided by giving class decorators access to the instances of the decorated classes after all constructors were executed. This would change how inheritance works because a superclass could now change properties that were added by subclasses. Therefore, it’s not sure if such a mechanism is in the cards. Example: making classes function-callable   # Classes decorated by   can be invoked by function calls instead of the   operator: Class method decorators   # Class method decorators have the following type signature: Abilities of a method decorator: \n It can change the decorated method by changing  . \n It can replace the decorated method by returning a function. \n It can register initializers. \n  only supports getting the value of its property, not setting it. \n Constructors can’t be decorated: They look like methods, but they aren’t really methods. Example: tracing method invocations   # The decorator   wraps methods so that their invocations and results are logged to the console: Example: binding methods to instances   # Normally, extracting methods (line A) means that we can’t function-call them because that sets   to  : We can fix that via the decorator  : Per decorated method, the initializer registered in line B is invoked whenever an instance is created and adds an own property whose value is a function with a fixed   (line C). Example: applying functions to methods   # The library   has  a decorator  that lets us apply functions to methods. That enables us to use helper functions such as Lodash’s  . The following code shows an implementation   of such a decorator: Class getter decorators, class setter decorators   # These are the type signatures of getter decorators and setter decorators: Getter decorators and setter decorators have similar abilities to method decorators. Example: computing values lazily   # To implement a property whose value is computed   (on demand), we use two techniques: \n \n We implement the property via a getter. That way, the code that computes its value, is only executed if the property is read. \n \n \n The decorator   wraps the original getter: When the wrapper is invoked for the first time, it invokes the getter and creates an own data property whose value is the result. From now on, the own property overrides the inherited getter whenever someone reads the property. \n \n Note that property   is immutable (because there is only a getter), which is why we have to define the property (line A) and can’t use assignment. Class field decorators   # Class field decorators have the following type signature: Abilities of a field decorator: \n \n It cannot change or replace its field. If we need that functionality, we have to use an   (what that is, is described  later ). \n \n \n It can change the value with which “its” field is initialized, by returning a function that receives the original initialization value and returns a new initialization value. \n \n Inside that function,   refers to the current instance. \n \n \n \n It can register initializers. That is a recent change (post-2022-03) of the decorators API and wasn’t possible before. \n \n \n It can expose access to its field (even if it’s private) via  . \n Example: changing initialization values of fields   # The decorator   doubles the original initialization value of a field by returning a function that performs this change: Example: read-only fields (instance public fields)   # The decorator   makes a field immutable. It waits until the field was completely set up (either via an assignment or via the constructor) before it does so. We need two steps to implement the functionality of   (which is why the class is also decorated): \n We first collect all keys of read-only fields (line A). \n Then we wait until the instance was completely set up and make the fields, whose keys we collected, non-writable (line B). We need to wrap the class because decorator initializers are executed too early. \n Similarly to making instances immutable, this decorator breaks  . The same workaround can be used here, too. We’ll later see  a version   that works with auto-accessors  instead of fields. That implementation does not require the class to be decorated. Example: dependency injection (instance public fields)   #  is motivated by the following observation: If we provide the constructor of a class with its dependencies (vs. the constructor setting them up itself), then it’s easier to adapt the dependencies to different environments, including testing. This is an  : The constructor does not do its own setup, we do it for it. Approaches for doing dependency injection: Manually, by creating dependencies and passing them to the constructor. Via “contexts” in frontend frameworks such as React Via decorators and a   (a minor variation of  ) The following code is a simple implementation of approach #3: This is how   is implemented: Example: “friend” visibility (instance private fields)   # We can change the visibility of some class members by making them private. That prevents them from being accessed publicly. There are more useful kinds of visibility, though. For example,   lets a group of   (functions, other classes, etc.) access the member. There are many ways in which friends can be specified. In the following example, everyone who has access to  , is a friend of  . The idea is that a module contains classes and functions that collaborate and that there is some instance data that only the collaborators should be able see. This is how class   is implemented: Example: enums (static public fields)   # There are many ways to implement enums. An OOP-style approach is to use a class and static properties ( more information on this approach ): We can use a decorator to automatically: \n Create a Map from “enum keys” (the names of their fields) to enum values. \n Add enum keys to enum values – without having to pass them to the constructor. \n That looks as follows: Auto-accessors: a new member of class definitions   # The decorators proposal introduces a new language feature:  . An auto-accessor is created by putting the keyword   before a class field. It is used like a field but implemented differently at runtime. That helps decorators as we’ll see soon. This is what auto-accessors look like: How do fields and auto-accessors differ? \n A field creates either:\n \n Properties (static or instance) \n Private slots (static or instance) \n \n \n An auto-accessor creates a private slot (static or instance) for the data and:\n \n A public getter-setter pair (static or prototype) \n A private getter-setter pair (static or instance)\n \n Private slots are not inherited and therefore never located in prototypes. \n \n \n \n \n Consider the following class: Internally, it looks like this: The following code shows where the getters and setters of auto-accessors are located: For more information on why the slots of private getters, private setters and private methods are stored in instances, see  section “Private methods and accessors”  in “JavaScript for impatient programmers”. Why are auto-accessors needed?   # Auto-accessors are needed by decorators: \n They can only influence the values fields are initialized with. \n But they can completely replace auto-accessors. \n Therefore, we have to use auto-accessors instead of fields whenever a decorator needs more control than it has with fields. Class auto-accessor decorators   # Class auto-accessor decorators have the following type signature: Abilities of an auto-accessor decorator: \n It receives the getter and the setter of the auto-accessor via its parameter  .\n \n  provides the same functionality. \n \n \n It can replace the decorated auto-accessor by returning an object with the methods   and/or  . \n It can influence the initial value of the auto-accessor by returning an object with the method  . \n It can register initializers. \n Example: read-only auto-accessors   # We have already implemented  a decorator   for fields . Let’s do the same for auto-accessors: Compared to the field version, this decorator has one considerable advantage: It does not need to wrap the class to ensure that the decorated constructs become read-only. Frequently asked questions   # Why can’t functions be decorated?   # The current proposal focuses on classes as a starting point.  Decorators for function expressions were proposed.  However, there hasn’t been much progress since then and there is no proposal for function  . On the other hand, functions are relatively easy to decorate “manually”: This looks even better with  the proposed pipeline operator : More decorator-related proposals   # The following ECMAScript proposals provide more decorator-related features: \n Stage 2:  “Decorator Metadata”  by Chris Garrett (last update: 2022-04-11)\n \n Quote: “This proposal seeks to extend the Decorators proposal by adding the ability for decorators to associate metadata with the value being decorated.” \n \n \n Stage 0:  “Function Expression Decorators”  by Igor Minar (last update: 2016-01-25) \n Stage 0:  “Method Parameter Decorators”  by Igor Minar (last update: 2016-01-25) \n Resources   # Implementations   # \n Babel currently has the best support for stage 3 decorators, via  .\n \n Be sure to pick  the latest decorator version . \n All the code in this blog post was developed via Babel. \n \n \n TypeScript currently supports stage 1 decorators behind a flag.\n \n There is  a pull request by Ron Buckton  that supports stage 3 decorators and will likely ship in the release after TypeScript 4.9. \n \n \n Libraries with decorators   # These are libraries with decorators. They currently only support stage 1 decorators but can serve as inspirations for what’s possible: \n core-decorators.js  by Jay Phelps (targets Babel) \n “Helpful Decorators For TypeScript Projects”  by Netanel Basal \n Acknowledgements   # \n Thanks to Chris Garrett for answering my questions about decorators. \n Further reading   # \n \n Chapter “Callable values”  [ordinary functions, arrow functions, classes, methods] in “JavaScript for impatient programmers” \n \n \n Chapter “Classes”  in “JavaScript for impatient programmers” \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/07/nodejs-esm-shell-scripts.html", "title": "Creating ESM-based shell scripts for Unix and Windows with Node.js", "content": "Creating ESM-based shell scripts for Unix and Windows with Node.js dev javascript nodejs chapter “Creating cross-platform shell scripts” In this blog post, we learn how to implement shell scripts via Node.js ESM modules. There are two common ways of doing so: \n We can write a stand-alone script and install it ourselves. \n We can put our script in an npm package and use a package manager to install it. That also gives us the option to publish the package to the npm registry so that others can install it, too. \n \n   \n     Required knowledge \n     \n       \n         What’s next in this blog post \n       \n     \n   \n   \n     Node.js ESM modules as standalone shell scripts on Unix \n     \n       \n         Node.js shell scripts on Unix \n       \n       \n         Hashbangs on Unix \n       \n       \n         Making files executable on Unix \n       \n       \n         Running   directly \n       \n     \n   \n   \n     Creating an npm package with shell scripts \n     \n       \n         Setting up the package’s directory \n       \n       \n         Adding dependencies \n       \n       \n         Adding content to the package \n       \n       \n         Running the shell scripts without installing them \n       \n     \n   \n   \n     How npm installs shell scripts \n     \n       \n         Installation on Unix \n       \n       \n         Installation on Windows \n       \n     \n   \n   \n     Publishing the example package to the npm registry \n     \n       \n         Which files are published? Which files are ignored? \n       \n       \n         Checking if a package is properly configured \n       \n       \n         : uploading packages to the npm registry \n       \n       \n         Automatically performing tasks every time before publishing \n       \n     \n   \n   \n     Standalone Node.js shell scripts with arbitrary extensions on Unix \n     \n       \n         Unix: arbitrary filename extension via a custom executable \n       \n       \n         Unix: arbitrary filename extension via a shell prolog \n       \n     \n   \n   \n     Standalone Node.js shell scripts on Windows \n     \n       \n         Windows: configuring the filename extension  \n       \n       \n         Windows Command shell: Node.js scripts via a shell prolog \n       \n       \n         Windows PowerShell: Node.js scripts via a shell prolog \n       \n     \n   \n   \n     Creating native binaries for Linux, macOS, and Windows \n   \n   \n     Shell paths: making sure shells find scripts \n     \n       \n         Unix:  \n       \n       \n         Changing the PATH variable on Windows (Command shell, PowerShell) \n       \n     \n   \n Required knowledge   # You should be loosely familiar with the following two topics: \n ECMAScript Modules, as explained in  chapter “modules”  in “JavaScript for impatient programmers”. \n npm packages, as explained in  the blog post “Publishing and consuming ECMAScript modules via packages – the big picture” . \n What’s next in this blog post   # Windows doesn’t really support standalone shell scripts written in JavaScript. Therefore, we’ll first look into how to write standalone scripts   filename extensions for Unix. That knowledge will help us with creating packages that contain shell scripts. Later, we’ll learn: \n A trick for writing standalone shell scripts on Windows. \n A trick for writing standalone shell scripts   filename extensions on Unix. \n Installing shell scripts via packages is the topic of  another blog post . Node.js ESM modules as standalone shell scripts on Unix   # Let’s turn an ESM module into a Unix shell script that we can run without it being inside a package. In principle, we can choose between two filename extensions for ESM modules: \n  files are always interpreted as ESM modules. \n  files are only interpreted as ESM modules if the closest   has the following entry: \n \n However, since we want to create a standalone script, we can’t rely on   being there. Therefore, we have to use the filename extension   (we’ll get to workarounds later). The following file has the name  : We can already run this file: Node.js shell scripts on Unix   # We need to do two things so that we can run   like this: These things are: \n Adding a   line at the beginning of  \n Making   executable \n Hashbangs on Unix   # In a Unix shell script, the first line is a   – metadata that tells the shell how to execute the file. For example, this is the most common hashbang for Node.js scripts: This line has the name “hashbang” because it starts with a hash symbol and an exclamation mark. It is also often called “shebang”. If a line starts with a hash, it is a comment in most Unix shells (sh, bash, zsh, etc.). Therefore, the hashbang is ignored by those shells. Node.js also ignores it, but only if it is the first line. Why don’t we use this hashbang? Not all Unixes install the Node.js binary at that path. How about this path then? Alas, not all Unixes allow relative paths. That’s why we refer to   via an absolute path and use it to run   for us. For more information on Unix hashbangs, see  “Node.js shebang”  by Alex Ewerlöf. # What if we want to pass arguments such as command line options to the Node.js binary? One solution that works on many Unixes is to use option   for   which prevents it from interpreting all of its arguments as a single name of a binary: On macOS, the previous command works even without  ; on Linux it usually doesn’t. # If we use a text editor on Windows to create an ESM module that should run as a script on either Unix or Windows, we have to add a hashbang. If we do that, the first line will end with the Windows line terminator  : Running a file with such a hashbang on Unix produces the following error: That is,   thinks the name of the executable is  . There are two ways to fix this. First, some editors automatically check which line terminators are already used in a file and keep using them. For example, Visual Studio Code, shows the current line terminator (it calls it “end of line sequence”) in the status bar at the bottom right: \n  (line feed) for the Unix line terminator  \n  (carriage return, line feed) for the Windows line terminator  \n We can switch pick a line terminator by clicking on that status information. Second, we can create a minimal file   with only Unix line terminators that we never edit on Windows: Making files executable on Unix   # In order to become a shell script,   must also be executable (a permission of files), in addition to having a hashbang: Note that we made the file executable ( ) for the user who created it ( ), not for everyone. Running   directly   #  is now executable and looks like this: We can therefore run it like this: Alas, there is no way to tell   to interpret a file with an arbitrary extension as an ESM module. That’s why we have to use the extension  . Workarounds are possible but complicated, as we’ll see later. Creating an npm package with shell scripts   # In this section we create an npm package with shell scripts. We then examine how we can install such a package so that its scripts become available at the command line of your system (Unix or Windows). The finished package is available here: \n On GitHub as  \n On npm as  \n Setting up the package’s directory   # These commands work on both Unix and Windows: Now there are the following files: # One option is to create a package and not publish it to the npm registry. We can still install such a package on our system (as explained later). In that case, our   looks as follows: Explanations: \n Making the package private means that no name or version is needed and that it can’t be accidentally published. \n  denies others the right to use the package under any terms. \n # If we want to publish our package to the npm registry, our   looks like this: For your own packages, you need to replace the value of   with a package name that works for you: \n \n Either a globally unique name. Such a name should only be used for important packages because we don’t want to prevent others from using the name otherwise. \n \n \n Or a  : To publish a package, you need an npm account (how to get one is explained later). The name of your account can be used as a   for package names. For example, if your account name is  , you can use the following package name: \n \n \n Adding dependencies   # Next, we install a dependency that we want to use in one of our scripts – package   (the ESM version of  Lodash ): This command: \n Creates the directory  . \n Installs package   into it. \n Adds the following property to  : \n \n Creates the file  . \n If we only use a package during development, we can add it to   instead of to   and npm will only install it if we run   inside our package’s directory, but not if we install it as a dependency. A unit testing library is a typical dev dependency. These are two ways in which we can install a dev dependency: \n Via  . \n We can use   and then manually move the entry for   from   to  . \n The second way means that we can easily postpone the decision whether a package is a dependency or a dev dependency. Adding content to the package   # Let’s add a readme file and two modules   and   that are shell scripts: We have to tell npm about the two shell scripts so that it can install them for us. That’s what property   in   is for: If we install this package, two shell scripts with the names   and   will become available. You may prefer the filename extension   for the shell scripts. Then, instead of the previous property, you have to add the following two properties to  : The first property tells Node.js that it should interpret   files as ESM modules (and not as CommonJS modules – which is the default). This is what   looks like: This module starts with the aforementioned hashbang which is required if we want to use it on Unix. It imports function   from the built-in module  , calls it and logs the result to the console (i.e., standard output). Note that   does not have to be executable; npm ensure executability of   scripts when it installs them (we’ll see how soon).  has the following content: We import function   from Lodash and use it to display three properties of the object  . Running the shell scripts without installing them   # We can run, e.g.,   like this: How npm installs shell scripts   # Installation on Unix   # A script such as   does not need to be executable on Unix because npm installs it via an executable symbolic link: \n If we install the package globally, the link is added to a directory that’s listed in  . \n If we install the package locally (as a dependency), the link is added to  \n Installation on Windows   # To install   on Windows, npm creates three files: \n  is a Command shell script that uses   to execute  . \n  does the same for PowerShell. \n  does the same for Cygwin, MinGW, and MSYS. \n npm adds these files to a directory: \n If we install the package globally, the files are added to a directory that’s listed in  . \n If we install the package locally (as a dependency), the files are added to  \n Publishing the example package to the npm registry   # Let’s publish package   (which we have created previously) to npm. Before we use   to upload the package, we should check that everything is configured properly. Which files are published? Which files are ignored?   # The following mechanisms are used to exclude and include files when publishing: \n \n The files listed in the top-level file   are excluded. \n \n We can override   with the file  , which has the same format. \n \n \n \n The   property   contains an Array with the names of files that are included. That means we have a choice of listing either the files we want to exclude (in  ) or the files we want to include. \n \n \n Some files and directories are excluded by default – e.g.: \n \n \n \n \n \n \n \n \n \n \n \n Except for these defaults, dot files (files whose names start with dots) are included. \n \n \n The following files are never excluded: \n \n \n  and its variants \n  and its variants \n ,  \n \n \n The npm documentation has  more details  on what’s included and whats excluded when publishing. Checking if a package is properly configured   # There are several things we can check before we upload a package. # A   of   runs the command without uploading anything: This displays which files would be uploaded and several statistics about the package. We can also create an archive of the package as it would exist on the npm registry: This command creates the file   in the current directory. # We can use either of the following two commands to install our package globally without publishing it to the npm registry: To see if that worked, we can open a new shell and check if the two commands are available. We can also list all globally installed packages: # To install our package as a dependency, we have to execute the following commands (while we are in directory  ): We can now run, e.g.,   with either one of the following two commands: : uploading packages to the npm registry   # Before we can upload our package, we need to create an npm user account. The npm documentation  describes how to do that . Then we can finally publish our package: We have to specify public access because the defaults are: \n \n  for unscoped packages \n \n \n  for scoped packages. This setting makes a package   – which is a paid npm feature used mostly by companies and different from   in  . Quoting npm: “With npm private packages, you can use the npm registry to host code that is only visible to you and chosen collaborators, allowing you to manage and use private code alongside public code in your projects.” \n \n Option   only has an effect the first time we publish. Afterward, we can omit it and need to use   to change the access level. We can change the default for the initial   via   in  : # Once we have uploaded a package with a specific version, we can’t use that version again, we have to increase either of the three components of the version: \n We increase   if we made breaking changes. \n We increase   if we made backward-compatible changes. \n We increase   if we made small fixes that don’t really change the API. \n Automatically performing tasks every time before publishing   # There may be steps that we want to perform every time before we upload a package – e.g.: \n Running unit tests \n Compiling TypeScript code to JavaScript code \n That can be done automatically via the   property `\"scripts\". That property can look like this:  is a unit testing library.   is the TypeScript compiler. The following package scripts are run before  : \n  is run:\n \n Before  \n Before  \n After a local   without arguments \n \n \n  is run only before  . \n Standalone Node.js shell scripts with arbitrary extensions on Unix   # Unix: arbitrary filename extension via a custom executable   # The Node.js binary   uses the filename extension to detect which kind of module a file is. There currently is no command line option to override that. And the default is CommonJS, which is not what we want. However, we can create our own executable for running Node.js and, e.g., call it  . Then we can rename our previous standalone script   to   (without any extension) if we change the first line to: Previously, the argument of   was  . This is  an implementation of   proposed by Andrea Giammarchi: This executable sends the content of a script to   via standard input. The command line option   tells Node.js that the text it receives is an ESM module. We also use the following Unix shell features: \n  contains the the first argument passed to   – the path of the script. \n We delete argument   (the path of  ) via   and pass on the remaining arguments to   via  . \n  replaces the current process with the one in which   runs. That ensures that the script exits with the same code as  . \n The hyphen ( ) separates Node’s arguments from the script’s arguments. \n Before we can use  , we have to make sure that it is executable and can be found via the  . How to do that is explained later. Unix: arbitrary filename extension via a shell prolog   # We have seen that we can’t specify the module type for a file, only for standard input. Therefore, we can write a Unix shell script   that uses Node.js to run itself as an ESM module (based on  work by sambal.org ): Most of the shell features that we are using here are described at the beginning of this blog post.   contains the exit code of the last shell command that was executed. That enables   to exit with the same code as  . The key trick used by this script is that the second line is both Unix shell script code and JavaScript code: \n \n As shell script code, it runs  the quoted command   which does nothing beyond expanding its arguments and performing redirections. Its only argument is the path  . Then it pipes the contents of the current file to the   binary. \n \n \n As JavaScript code, it is the string   (which is interpreted as an expression statement and does nothing), followed by a comment. \n \n An additional benefit of hiding the shell code from JavaScript is that JavaScript editors won’t be confused when it comes to processing and displaying the syntax. Standalone Node.js shell scripts on Windows   # Windows: configuring the filename extension     # One option for creating standalone Node.js shell scripts on Windows is to the filename extension   and configure it so that files that have it are run via  . Alas that only works for the Command shell, not for PowerShell. Another downside is that we can’t pass arguments to a script that way: How do we configure Windows so that the Command shell directly runs files such as  ?  specify which app a file is opened with when we enter its name in a shell. If we associate the filename extension   with the Node.js binary, we can run ESM modules in shells. One way to do that is via the Settings app, as explained in  “How to Change File Associations in Windows”  by Tim Fisher. If we additionally add   to the variable  , we can even omit the filename extension when referring to an ESM module. This environment variable can be changed permanently via the Settings app – search for “variables”. Windows Command shell: Node.js scripts via a shell prolog   # On Windows, we are facing the challenge that there is no mechanism like hashbangs. Therefore, we have to use a workaround that is similar to the one we used for extensionless files on Unix: We create a script that runs the JavaScript code inside itself via Node.js. Command shell scripts have the filename extension  . We can run a script named   via either   or  . This is what   looks like if we turn it into a Command shell script  : Running this code as a file via   would require two features that don’t exist: \n Using a command line option to override extension-less files being interpreted as ESM modules by default. \n Skipping lines at the beginning of a file. \n Therefore, we have no choice but to pipe the file’s content into  . We also use the following command shell features: \n  contains the full path of the current script, including its filename extension. In contrast,   contains the command that was used to invoke the script. Therefore, the former shell variable enables us to invoke the script via either   or  . \n  contains the command’s arguments – which we pass on to  . \n  contains the exit code of the last command that was executed. We use that value to exit with the same code that was specified by  . \n Windows PowerShell: Node.js scripts via a shell prolog   # We can use a trick similar to the one used in the previous section and turn   into a PowerShell script   as follows: We can run this script via either: However, before we can do that, we need to set an execution policy that allows us to run PowerShell scripts ( more information on execution policies ): \n The default policies on Windows clients is   and doesn’t let us run any scripts. \n The policy   lets us run unsigned local scripts. Downloaded scripts must be signed. This is the default on Windows servers. \n The following command lets us run local scripts: Creating native binaries for Linux, macOS, and Windows   # The npm package   turns a Node.js package into a native binary that even runs on systems where Node.js isn’t installed. It supports the following platforms: Linux, macOS, and Windows. Shell paths: making sure shells find scripts   # In most shells, we can type in a filename without directly referring to a file and they search several directories for a file with that name and run it. Those directories are usually listed in a special shell variable: \n In most Unix shells, we access it via  . \n In the Windows Command shell, we access it via  . \n In PowerShell, we access it via  . \n We need the PATH variable for two purposes: \n If we want to install our custom Node.js executable  . \n If we want to run a standalone shell script without directly referring to its file. \n Unix:     # Most Unix shells have the variable   that lists all paths where a shell looks for executables when we type in a command. Its value may look like this: The following command works on most shells ( source ) and changes the   until we leave the current shell: The quotes are needed in case one of the two shell variables contains spaces. # On Unix, how the   is configured depends on the shell. You can find out which shell you are running via: MacOS uses Zsh where the best place to permanently configure   is the startup script   –  like this : Changing the PATH variable on Windows (Command shell, PowerShell)   # On Windows, the default environment variables of the Command shell and PowerShell can be configured (permanently) via the Settings app – search for “variables”. comments powered by Disqus."},
{"url": "https://2ality.com/2022/08/node-util-parseargs.html", "title": "Parsing command line arguments with  util.parseArgs()  in Node.js", "content": "Parsing command line arguments with   in Node.js dev javascript nodejs chapter “Parsing command line arguments with  ” In this blog post, we explore how to use the Node.js function   from module   to parse command line arguments. \n   \n     Imports that are implied in this blog post \n   \n   \n     The steps involved in processing command line arguments \n   \n   \n     Parsing command line arguments \n     \n       \n         The basics \n       \n       \n         Using options multiple times \n       \n       \n         More ways of using long and short options \n       \n       \n         Quoting values \n       \n       \n         Option terminators \n       \n       \n         Strict  \n       \n     \n   \n   \n      tokens \n     \n       \n         Examples of tokens \n       \n       \n         Using tokens to implement subcommands \n       \n     \n   \n Imports that are implied in this blog post   # The following two imports are implied in every example in this post: The first import is for test assertions we use to check values. The second import is for function   that is the topic of this post. The steps involved in processing command line arguments   # The following steps are involved in processing command line arguments: The user inputs a text string. The shell parses the string into a sequence of words and operators. If a command is called, it gets zero or more words as arguments. Our Node.js code receives the words via an Array stored in  .   is a global variable on Node.js. We use   to turn that Array into something that is more convenient to work with. Let’s use the following shell script   with Node.js code to see what   looks like: We start with a simple command: If we install the command via npm on Windows, the same command produces the following result on the Windows Command shell: No matter how we invoke a shell script,   always starts with the path of the Node.js binary that is used to run our code. Next is the path of our script. The Array ends with the actual arguments the were passed to the script. In other words: The arguments of a script always start at index 2. Therefore, we change our script so that it looks like this: Let’s try more complicated arguments: These arguments consist of: \n Option   whose value is the text  . Such an option is called a  . \n Option   which has no associated value – it’s a flag that’s either there or not. Such an option is called a  . \n Two so-called   which have no names:   and  . \n Two styles of using arguments are common: \n The main arguments are positional, options provide additional – often optional – information. \n Only options are used. \n Written as a JavaScript function call, the previous example would look like this (in JavaScript, options usually come last): Parsing command line arguments   # The basics   # If we want   to parse an Array with arguments, we first need to tell it how our options work. Let’s assume our script has: \n A boolean option  \n An option   that receives non-negative integers.   has no special support for numbers, so we have to make it a string option. \n A string option  \n We describe these options to   as follows: As long as a property key of   is a valid JavaScript identifier, it is up to you if you want to quote it or not. Both have pros and cons. In this blog post, they are always quoted. That way, options with non-identifier names such as   look the same as those with identifier names. Each entry in   can have the following properties (as defined via a TypeScript type): \n  specifies if an option is boolean or string. \n  defines the short version of an option. It must be a single character. We’ll see soon how to use short versions. \n  indicates if an option can be used at most once or zero or more times. We’ll see later what that means. \n The following code uses   and   to parse an Array with arguments: The prototype of the object stored in   is  . That means that we can use the   operator to check if a property exists, without having to worry about inherited properties such as  . As mentioned before, the number 5 that is the value of  , is processed as a string. The object we pass to   has the following TypeScript type: \n : The arguments to parse. If we omit this property,   uses  , starting with the element at index 2. \n : If  , an exception is thrown if   isn’t correct. More on that later. \n : Can   contain positional arguments? \n This is the type of the result of  : \n  contains the optional arguments. We have already seen strings and booleans as property values. We’ll see Array-valued properties when we explore option definitions where   is  . \n  contains the positional arguments. \n Two hyphens are used to refer to the long version of an option. One hyphen is used to refer to the short version: Note that   contains the long names of the options. We conclude this subsection by parsing positional arguments that are mixed with optional arguments: Using options multiple times   # If we use an option multiple times, the default is that only the last time counts. It overrides all previous occurrences: If, however, we set   to   in the definition of an option,   gives us all option values in an Array: More ways of using long and short options   # Consider the following options: The following is a compact way of using multiple boolean options: We can directly attach the value of a long string option via an equals sign. That is called an  . Short options can’t have inline values. Quoting values   # So far, all option values and positional values were single words. If we want to use values that contain spaces, we need to quote them – with double quotes or single quotes. The latter is not supported by all shells, however. # To examine how shells parse quoted values, we again use the script  : On Unix, these are the differences between double quotes and single quotes: \n \n Double quotes: we can escape quotes with backslashes (which are otherwise passed on verbatim) and variables are interpolated: \n \n \n \n Single quotes: all content is passed on verbatim and we can’t escape quotes: \n \n \n The following interaction demonstrates option values that are doube-quoted and single-quoted: In the Windows Command shell single quotes are not special in any way: Quoted option values in the Windows Command shell: In Windows PowerShell, we can quote with single quotes, variable names are not interpolated inside quotes and single quotes can’t be escaped: # This is how   handles quoted values: Option terminators   #  supports so-called  : If one of the elements of   is a double hyphen ( ), then the remaining arguments are all treated as positional. Where are option terminators needed? Some executables invoke other executables, e.g.  the   executable . Then an option terminator can be used to separate the caller’s arguments from the callee’s arguments. This is how   handles option terminators: Strict     # If the option   is   (which is the default), then   throws an exception if one of the following things happens: \n The name of an option used in   is not in  . \n An option in   has the wrong type. Currently that only haappens if a string option is missing an argument. \n There are positional arguments in   even though   is   (which is the default). \n The following code demonstrates each of these cases:  tokens   #  processes the   Array in two phases: \n Phase 1: It parses   into an Array of tokens: These tokens are mostly the elements of   annotated with type information: Is it an option? Is it a positional? Etc. However, if an option has a value then the token stores both option name and option value and therefore contains the data of two   elements. \n Phase 2: It assembles the tokens into the object that is returned via the result property  . \n We can get access to the tokens if we set   to  . Then the object returned by   contains a property   with the tokens. These are the properties of tokens: Examples of tokens   # As an example, consider the following options: The tokens for boolean options look like this: Note that there are three tokens for option   because it is mentioned three times in  . However, due to phase 2 of parsing, there is only one property for   in  . In the next example, we parse string options into tokens.   has boolean values now (it is always   for boolean options): Lastly, this is an example of parsing positional arguments and an option terminator: Using tokens to implement subcommands   # By default,   does not support subcommands such as   or  . However, it is relatively easy to implement this functionality via tokens. This is the implementation: This is   in action: comments powered by Disqus."},
{"url": "https://2ality.com/2022/10/commonjs-named-exports.html", "title": "How to write CommonJS exports that can be name-imported from ESM", "content": "How to write CommonJS exports that can be name-imported from ESM dev javascript nodejs This blog post explores how to write CommonJS modules so that their exports can be name-imported from ESM modules on Node.js. How to import CommonJS modules from ESM modules   # This is what  the Node.js documentation  says about this topic: When importing CommonJS modules, the module.exports object is provided as the default export. Named exports may be available, provided by static analysis as a convenience for better ecosystem compatibility. In other words: \n Default-importing from CommonJS modules always works. \n Name-importing only works sometimes. \n How to write exports that can be name-imported   # Consider the following ESM module: The import in line A works if the CommonJS module looks like this: We can also assign to  . Exporting objects from CommonJS prevents named imports   # Assigning objects to   prevents named imports: If we now run  , we get an error: Caveat: Named imports from CommonJS modules are not live connections   # In contrast to normal named imports , named CommonJS imports are not live connections: Further reading   # \n \n Section “ECMAScript modules”  in “JavaScript for impatient programmers” \n \n \n Section “Server side: CommonJS modules”  in “JavaScript for impatient programmers” \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/08/npm-package-scripts.html", "title": "Running cross-platform tasks via npm package scripts", "content": "Running cross-platform tasks via npm package scripts dev javascript nodejs chapter “Running cross-platform tasks via npm package scripts” The npm package manager lets us define small shell scripts for tasks and execute them via  . In this blog post, we explore how that works and how we can write them in a way that works across platforms (Unixes and Windows). \n   \n     npm package scripts \n     \n       \n         Shorter npm commands for running package scripts \n       \n       \n         Which shell is used to run package scripts? \n       \n       \n         Preventing package scripts from being run automatically \n       \n       \n         Getting tab completion for package scripts on Unix \n       \n       \n         Listing and organizing package scripts \n       \n     \n   \n   \n     Kinds of package scripts \n     \n       \n         Pre and post scripts \n       \n       \n         Life cycle scripts \n       \n     \n   \n   \n     The shell environment in which package scripts are run \n     \n       \n         The current directory \n       \n       \n         The shell PATH \n       \n     \n   \n   \n     Using environment variables in package scripts \n     \n       \n         Getting and setting environment variables \n       \n       \n         Setting up environment variables via   files \n       \n     \n   \n   \n     Arguments for package scripts \n   \n   \n     The npm log level (how much output is produced) \n     \n       \n         Log levels and information printed to the terminal \n       \n       \n         Log levels and information written to the npm log \n       \n       \n         Configuring logging \n       \n       \n         Output of life cycle scripts that run during  \n       \n       \n         Observations of how npm logging works \n       \n     \n   \n   \n     Cross-platform shell scripting \n     \n       \n         Paths and quoting \n       \n       \n         Chaining commands \n       \n       \n         The exit codes of package scripts \n       \n       \n         Piping and redirecting input and output \n       \n       \n         Commands that work on both platforms \n       \n       \n         Running bin scripts and package-internal modules \n       \n       \n          and  \n       \n     \n   \n   \n     Helper packages for common operations \n     \n       \n         Running package scripts from a command line \n       \n       \n         Running multiple scripts concurrently or sequentially \n       \n       \n         File system operations \n       \n       \n         Putting files or directories into the trash \n       \n       \n         Copying trees of files \n       \n       \n         Watching files \n       \n       \n         Miscellaneous functionality \n       \n       \n         HTTP servers \n       \n     \n   \n   \n     Expanding the capabilities of package scripts \n     \n       \n         : switching between scripts, depending on  \n       \n       \n         Defining operating-system-specific scripts \n       \n     \n   \n   \n     Sources of this blog post \n   \n npm package scripts   #  are defined via property   of  : The value of   is an object where each property defines a package script: \n The property key defines the name of the script. \n The property value defines what to do when the script is run. \n If we type: then npm executes the script whose name is   in a shell. For example, we can use: to run the following command in a shell: In this post, we will occasionally use the   option  , which is an abbreviation for   and tells   to produce less output: This option is covered in more detail in  the section on logging . Shorter npm commands for running package scripts   # Some package scripts can be run via shorter npm commands: \n : If there is no package script  , npm runs  . \n : If there is no package script  , npm runs  ,  ,  ,  .\n \n More information on  . \n \n \n Which shell is used to run package scripts?   # By default, npm runs package scripts via   on Windows and via   on Unix. We can change that via  the npm configuration setting  . However, doing so is rarely a good idea: Many existing cross-platform scripts are written for   and   and will stop working. Preventing package scripts from being run automatically   # Some script names are reserved for   which npm runs whenever we execute certain npm commands. For example, npm runs the script   whenever we execute   (without arguments).  Life cycle scripts are covered in more detail later. If the configuration setting   is  , npm will never run scripts automatically, only if we invoke them directly. Getting tab completion for package scripts on Unix   # On Unix, npm supports tab completion for commands and package script names via  . We can install it by adding this line to our   /   /   / etc.: If you need tab completion for non-Unix platforms, do a web search such as “npm tab completion PowerShell”. Listing and organizing package scripts   #  without a name lists the available scripts. If the following scripts exist: Then they are listed like this: # If there are many package scripts, we can misuse script names as separators (script   will be explained in the next subsection): Now the scripts are listed as follows: Note that the trick of prepending newlines ( ) works on Unix and on Windows. # The package script   prints help information via the bin script   from  package  . We provide descriptions via the   property   (the value of   is abbreviated so that it fits into a single line): This is what the help information looks like: Kinds of package scripts   # If certain names are used for scripts, they are run automatically in some situations: \n  and   are run before and after scripts. \n  are run when a user performs an action such as  . \n All other scripts are called  . Pre and post scripts   # Whenever npm runs a package script  , it automatically runs the following scripts – if they exist: \n  beforehand (a  ) \n  afterward (a  ) \n The following scripts contain the pre script   and the post script  : This is what happens if we run  : Life cycle scripts   # npm runs   during npm commands such as: \n  (which uploads packages to the npm registry) \n  (which creates archives for registry packages, package directories, etc.) \n  (which is used without arguments to install dependencies for packages that were downloaded from sources other than the npm registry) \n If any of the life cycle scripts fail, the whole command stops immediately with an error. What are use cases for life cycle scripts? \n \n Compiling TypeScript: If a package contains TypeScript code, we normally compile it to JavaScript code before we use it. While the latter code is often not checked into version control, it has to be uploaded to the npm registry, so that the package can be used from JavaScript. A life cycle script lets us compile the TypeScript code before   uploads the package. That ensures that in the npm registry, the JavaScript code is always in sync with our TypeScript code. It also ensures that our TypeScript code has no static type errors because compilation (and therefore publishing) stops when those are encountered. \n \n \n Running tests: We can also use a life cycle script to run tests before publishing a package. If the tests fail, the package won’t be published. \n \n These are the most important life cycle scripts (for detailed information on all life cycle scripts, see  the npm documentation ): \n :\n \n Runs before a package archive (a   file) is created:\n \n During  \n During  \n \n \n Runs when a package is installed from git or a local path. \n Runs when   is used without arguments or when a package is installed globally. \n \n \n  runs before a package archive (a   file) is created:\n \n During  \n During  \n \n \n  only runs during  . \n  runs when   is used without arguments or when a package is installed globally.\n \n Note that we can also create a pre script   and/or a post script  . Their names make it clearer when npm runs them. \n \n \n The following table summarizes when these life cycle scripts are run:  Doing things automatically is always a bit tricky. I usually follow these rules: \n I automate for myself (e.g. via  ). \n I don’t automate for others (e.g. via  ). \n The shell environment in which package scripts are run   # In this section, we’ll occasionally use which runs the JavaScript code in   and prints the result to the terminal - for example: The current directory   # When a package script runs, the current directory is always the package directory, independently of where we are in the directory tree whose root it is. We can confirm that by adding the following script to  : Let’s try out   on Unix: Changing the current directory in this manner, helps with writing package scripts because we can use paths that are relative to the package directory. The shell PATH   # When a module   imports from a module whose specifier starts with the name of a package  , Node.js goes through   directories until it finds the directory of  : \n First   in the parent directory of   (if it exists) \n Second   in the parent of the parent directory of   (if it exists) \n And so on, until it reaches the root of the file system. \n That is,   inherits the   directories of its ancestor directories. A similar kind of inheritance happens with bin scripts, which are stored in   when we install a package.   temporarily adds entries to the shell PATH variable (  on Unix,   on Windows): \n  in the package directory \n  in the package directory’s parent \n Etc. \n To see these additions, we can use the following package script:  stands for a single line with this JavaScript code: On Unix, we get the following output if we run  : On Windows, we get: Using environment variables in package scripts   # In task runners such as Make, Grunt, and Gulp, variables are important because they help reduce redundancy. Alas, while package scripts don’t have their own variables, we can work around that deficiency by using   (which are also called  ). We can use the following commands to list platform-specific environment variables: \n Unix:  \n Windows Command shell:  \n Both platforms:  \n On macOS, the result looks like this: In the Windows Command shell, the result looks like this: Additionally, npm temporarily adds more environment variables before it runs a package script. To see what the end result looks like, we can use the following command: This command invokes a built-in package script. Let’s try it out for this  : The names of all of npm’s temporary variables start with  . Let’s only print those, in alphabetical order: The   variables have a hierarchical structure. Under  , we find the name and the definition of the currently running package script: On Windows,   would   in this case. Under prefix  , we can see some of npm’s configuration settings ( which are described in the npm documentation ). These are a few examples: The prefix   gives us access to the contents of  . Its top level looks like this: Under  , we can find the properties of the   property  : The   entries give us access to the properties of  : That means that   lets us set up variables that we can use in package scripts. The next subsection explores that further. Note the object was converted to “nested” entries (line 2 and line 3), while the Array (line 1) and the numbers (line 2 and line 3) were converted to strings. These are the remaining   environment variables: Getting and setting environment variables   # The following   demonstrates how we can access variables defined via   in package scripts: Alas, there is no built-in cross-platform way of accessing environment variables from package scripts. There are, however, packages with bin scripts that can help us. Package   lets us get environment variables: Package   lets us set environment variables: Setting up environment variables via   files   # There are also packages that let us set up environment variables via   files. These files have the following format: Using a file that is separate from   enables us to keep that data out of version control. These are packages that support   files: \n \n Package   supports them for JavaScript modules. We can preload it: \n \n And we can import it: \n \n \n \n Package   lets us use   files via a shell command: \n \n \n \n Package   is an alternative to the previous package: \n \n The package has more features: switching between sets of variables, more file formats, etc. \n \n Arguments for package scripts   # Let’s explore how arguments are passed on to shell commands that we invoke via package scripts. We’ll use the following  : The bin script   looks like this: Positional arguments work as expected:  consumes options and creates environment variables for them. They are not added to  : If we want options to show up in  , we have to use the    . That terminator is usually inserted after the name of the package script: But we can also insert it before that name: The npm log level (how much output is produced)   # npm supports the following log levels: Logging refers to two kinds of activities: \n Printing information to the terminal \n Writing information to npm logs \n The following subsections describe: \n \n How log levels affect these activities. In principle,   logs least, while   logs most. \n \n \n How to configure logging. The previous table shows how to temporarily change the log level via command line options, but there are more settings. And we can change them either temporarily or permanently. \n \n Log levels and information printed to the terminal   # By default, package scripts are relatively verbose when it comes to terminal output. Take, for example, the following   file: This is what happens if the log level is higher than   and the package script exits without errors: This is what happens if the log level is higher than   and the package script fails: With log level  , the output becomes less cluttered: Some errors are swallowed by  : We need at least log level   to see them: Unfortunately, log level   also suppresses the output of   (without arguments): Log levels and information written to the npm log   # By default, the logs are written to the npm cache directory, whose path we can get via  : The contents of the log directory look like this: Each line in a log starts with a line index and a log level. This is an example of a log that was written with log level  . Interestingly, even log levels that are “more verbose” than   (such as  ) show up in it: If   returns with an error, the corresponding log ends like this: If there is no error, the corresponding log ends like this: Configuring logging   #  prints default values for various settings. These are the default values for logging-related settings: If the value of   is  , npm uses directory   inside the npm cache directory (as mentioned previously). \n  lets us override the default so that npm writes its logs to a directory of our choosing. \n  lets us configure how many files are written to the log directory before npm deletes old files. If we set   to 0, no logs are ever written. \n  lets us configure npm’s log level. \n To permanently change these settings, we also use   – for example: \n Getting the current log level: \n \n Permanently setting the current log level: \n \n Permanently resetting the log level to the built-in default: \n \n We can also temporarily change settings via command line options – for example: Other ways of changing settings (such as using environment variables) are explained by  the npm documentation . Output of life cycle scripts that run during     # The output of life cycle scripts than run during   (without arguments) is hidden. We can change that by (temporarily or permanently) setting   to  . Observations of how npm logging works   # \n Only log level   turns off extra output when using  . \n The log levels have no effect on whether log files are created and on what is written to them. \n Error messages are not written to the logs. \n Cross-platform shell scripting   # The two shells that are most commonly used for package scripts are: \n  on Unix \n  on Windows \n In this section, we examine constructs that work in both shells. Paths and quoting   # Tips: \n \n Use relative paths whose segments are separated by slashes: Windows accepts slashes as separators even though you’d normally use backslashes on that platform. \n \n \n Double-quote arguments: While   supports single quotes, the Windows Command shell doesn’t. Unfortunately, we have to escape double quotes when we use them in package script definitions: \n \n \n Chaining commands   # There are two ways in which we can chain commands that work on both platforms: \n A command after   is only executed if the previous command succeeded (exit code is 0). \n A command after   is only executed if the previous command failed (exit code is not 0). \n Chaining while ignoring the exit code differs between platforms: \n Unix:  \n Windows Command shell:  \n The following interaction demonstrates how   and   work on Unix (on Windows, we’d use   instead of  ): The exit codes of package scripts   # The exit code can be accessed via a shell variable: \n Unix:  \n Windows Command shell:  \n  returns with the same exit code as the last shell script that was executed: The following interaction happens on Unix: Piping and redirecting input and output   # \n Piping between commands:  \n Writing output to a file:  \n Reading input from a file:  \n Commands that work on both platforms   # The following commands exist on both platforms (but differ when it comes to options): \n \n . Caveat on Windows: double quotes are printed, not ignored \n \n \n \n \n \n Running bin scripts and package-internal modules   # The following   demonstrates three ways of invoking bin scripts in dependencies: Explanations: \n \n : Bin scripts in dependencies are installed in the directory  . \n \n \n : As we have seen, npm adds   to the shell PATH while it executes package scripts. That means that we can use local bin scripts as if they were installed globally. \n \n \n : When   runs a script, it also adds   to the shell PATH. \n \n On Unix, we can invoke package-local scripts directly – if they have hashbangs and are executable. However that doesn’t work on Windows, which is why it is better to invoke them via  :  and     # When the functionality of a package script becomes too complex, it’s often a good idea to implement it via a Node.js module – which makes it easy to write cross-platform code. However, we can also use the   command to run small JavaScript snippets, which is useful for performing small tasks in a cross-platform manner. The relevant options are: \n  evaluates the JavaScript expression  .\n \n Abbreviation:  \n \n \n  evaluates the JavaScript expression   and prints the result to the terminal.\n \n Abbreviation:  \n \n \n The following commands work on both Unix and Windows (only the comments are Unix-specific): If we need platform-specific line terminators, we can use   – for example, we could replace   in the previous command with: Observations: \n It’s important to put the JavaScript code in double quotes if it contains parentheses – otherwise Unix will complain. \n All built-in modules can be accessed via variables. That’s why we don’t need to import   or  . \n  supports more file system operations. These are documented in  the blog post “Working with the file system on Node.js” . \n Helper packages for common operations   # Running package scripts from a command line   # npm-quick-run  provides a bin script   that lets us use abbreviations to run package scripts – for example: \n  executes   (if   is the first package scripts whose name starts with an “m”). \n  runs the package script  . \n Etc. \n Running multiple scripts concurrently or sequentially   # Running shell scripts concurrently: \n Unix:  \n Windows Command shell:  \n The following two packages give us cross-platform options for that and for related functionality: \n \n concurrently  runs multiple shell commands concurrently – for example: \n \n \n \n npm-run-all  provides several kinds of functionality – for example: \n \n A more convenient way of invoking package scripts sequentially. The following two commands are equivalent: \n \n Running package scripts concurrently: \n \n Using a wildcard to run multiple scripts – for example,   stands for all package scripts whose names start with   ( ,  , etc.): \n \n \n \n File system operations   # Package   lets us use “Unix syntax” to run various file system operations. Everything it does, works on Unix and Windows. Creating a directory: Removing a directory: Clearing a directory (double quotes to be safe w.r.t. the wildcard symbol  ): Copying a file: Removing a file:  is based on the JavaScript library ShellJS, whose repository lists  all supported commands . In addition to the Unix commands we have already seen, it also emulates:  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , and others. Putting files or directories into the trash   # Package   works on macOS (10.12+), Linux, and Windows (8+). It puts files and directories into the trash and supports paths and glob patterns. These are examples of using it: Copying trees of files   # Package   lets us copy trees of files. The following is a use case for  : In TypeScript, we can import non-code assets such as CSS and images. The TypeScript compiler compiles the code to a “dist” (output) directory but ignores non-code assets. This cross-platform shell command copies them to the dist directory: TypeScript compiles:  copies: Watching files   # Package   watches files and runs a shell command every time they change – for example: One common alternative (among many others): \n \n Miscellaneous functionality   # \n cli-error-notifier  shows a native desktop notification if a script fails (has a non-zero exit code). It supports many operating systems. \n HTTP servers   # During development, it’s often useful to have an HTTP server. The following packages (among many others) can help: \n \n \n \n Expanding the capabilities of package scripts   # : switching between scripts, depending on     # The bin script   lets us run a package script   and automatically switches between (e.g.)  ,  , and  , depending on the value of the environment variable  : Defining operating-system-specific scripts   # The bin script   switches between scripts depending on the current operating system. Supported property values are:  ,  ,  ,  ,  . Sources of this blog post   # \n \n npm documentation \n \n \n Node.js documentation \n \n \n “Awesome npm scripts”  by  Ryan Zimmerman  and  Michael Kühnel \n \n \n “Three Things You Didn’t Know You Could Do with npm Scripts”  by  Dominik Kundel \n \n \n “Helpers and tips for npm run scripts”  by  Michael Kühnel \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/08/installing-nodejs-bin-scripts.html", "title": "Installing and running Node.js bin scripts", "content": "Installing and running Node.js bin scripts dev javascript nodejs chapter “Installing npm packages and running bin scripts” The   property   lets an npm package specify which shell scripts it provides (for more information, see  “Creating ESM-based shell scripts for Unix and Windows with Node.js” ). If we install such a package, Node.js ensures that we can access these shell scripts (so-called  ) from a command line. In this blog post, we explore two ways of installing packages with bin scripts: \n \n Locally installing a package with bin scripts means installing it as a dependency inside a package. The scripts are only accessible within that package. \n \n \n Globally installing a package with bin scripts means installing it in a “global location” so that the scripts are accessible everywhere – for either the current user or all users of a system (depending on how npm is set up). \n \n We explore what all of that means and how we can run bin scripts after installing them. \n   \n     Installing npm registry packages globally \n     \n       \n         Which packages are installed globally?  \n       \n       \n         Where are packages installed globally?  \n       \n       \n         Where are shell scripts installed globally?  \n       \n       \n         Where are packages installed globally? The npm installation prefix \n       \n       \n         Changing where packages are installed globally \n       \n     \n   \n   \n     Installing npm registry packages locally \n     \n       \n         Running locally installed bin scripts \n       \n     \n   \n   \n     Installing unpublished packages \n     \n       \n         : installing an unpublished package globally \n       \n       \n         : installing a globally linked package locally \n       \n       \n         : undoing linking \n       \n       \n         Installing unpublished packages via local paths \n       \n       \n         Other ways of installing unpublished packages \n       \n     \n   \n   \n     : running bin scripts in npm packages without installing them \n     \n       \n         The npx cache \n       \n     \n   \n Installing npm registry packages globally   # Package   has the following   property: To install this package globally, we use  : Caveat: On Unix, we may have to use   (we’ll learn soon how to avoid that): After that, we can use the commands   and   in our command lines. Note that only the bin scripts are available globally. The packages are ignored when Node.js looks up bare module specifiers in   directories. Which packages are installed globally?     # We can check which packages are installed globally and where: On Windows, the installation path is  , e.g.: Where are packages installed globally?     # Result on macOS: Result on Windows: Where are shell scripts installed globally?     #  tells us where npm installs shell scripts globally. It also ensures that that directory is available in the shell PATH. Result on macOS: Result on the Windows Command shell: The executable   without a filename extension is for Unix-based Windows environments such as Cygwin, MinGW, and MSYS. Windows PowerShell returns this path for  : Where are packages installed globally? The npm installation prefix   # npm’s   determines where packages and bin scripts are installed globally. This is the installation prefix on macOS: Accordingly: \n Packages are installed in  \n Bin scripts are installed in  \n This is the installation prefix on Windows: Accordingly: \n Packages are installed in  \n Bin scripts are installed in  \n Changing where packages are installed globally   # In this section, we examine two ways of changing where packages are installed globally: \n Changing the npm installation prefix \n Using a Node.js version manager \n # One way of changing where packages are installed globally is to change the npm installation prefix. Unix: Windows Command shell: Windows PowerShell: The configuration data is saved to a file   in the home directory. From now on, global installs will be added to the directory we have just specified. Afterward, we still have to add the   directory to our shell PATH so that our shell finds bin scripts we install globally.  npm will now also be installed at the new location if we tell it to upgrade itself. # Node.js version managers let us install multiple versions of Node.js at the same time and switch between them. Popular ones include: \n Unix:  nvm \n Cross-platform:  Volta \n Installing npm registry packages locally   # To install an npm registry package such as     (into a package), we do the following: This adds the following data to  : Additionally, the package is downloaded into the following directory: On Unix, npm adds these symbolic links for the bin scripts: On Windows, npm adds these files to  : The files without extensions are scripts for Unix-based Windows environments such as Cygwin, MinGW, and MSYS.  tells us where locally installed bin scripts are located – for example: Note: Locally, packages are always installed in a directory   next to a   file. If the latter doesn’t exist in the current directory, npm searches for it in an ancestor directory and installs the package there. To check where npm would install packages locally, we can use the command   – for example (Unix): There is no   in John’s home directory, but npm can’t install anything in an ancestor directory, which is why   shows this directory. Installing a package locally at the current location will lead to   being created and installation progressing as usual. Running locally installed bin scripts   # (All commands in this subsection are executed inside directory  .) # We can run   as follows from a shell: On Unix, we can set up a helper: Then the following command works: # We can also add a package script to  : Now we can execute this command in a shell: That works because npm temporarily adds the following entries to   on Unix: On Windows, similar entries are added to   or  : The following command lists the environment variables and their values that exist while a package script runs: # Inside a package, npx can be used to access bin scripts: More on npx later. Installing unpublished packages   # Sometimes, we have a package that we either haven’t published yet or won’t ever publish and would like to install it. : installing an unpublished package globally   # Let’s assume we have an unpublished package whose name is   that is stored in a directory  . We can make it available globally as follows: If we do that: \n npm adds a symbolic link to the global   (as returned by  ) – for example: \n \n On Unix, npm also adds one symbol link from the global bin directory (as returned by  ) to each bin script. That link is not direct, it goes through the global   directory: \n \n On Windows, it adds the usual 3 scripts (which refer to the linked package via relative paths into the global  ): \n \n Due to how the linked package is referred to, any changes in it will take effect immediately. There is no need to re-link it when it changes. To check if the global installation worked, we can use   to list all globally installed packages. : installing a globally linked package locally   # After we have installed our upublished package globally (see previous subsection), we have the option to install it locally in one of our packages (which can be published or unpublished): That creates the following link: By default, the unpublished package is not added as a dependency to  . The rationale behind that is that   is often used to temporarily work with an unpublished version of a registry package – which shouldn’t show up in the dependencies. : undoing linking   # Undoing the local link: Undoing the global link: Installing unpublished packages via local paths   # Another way of installing an unpublished package locally, is to use   and refer to it via a local path (and not via its package name): That has two effects. First, the following symbolic link is created: Second, a dependency is added to  : This way of installing unpublished packages also works globally: Other ways of installing unpublished packages   # \n Yalc  lets us publish packages to a local “Yalc repository” (think local registry). From that repository, we can install packages as dependencies for, e.g., a package  . They are copied into the directory   and   or   dependencies are added to  . \n \n \n  supports   in   which (if they exist) override normal dependencies. In contrast to   and local path installations: \n \n Normal dependencies don’t have to be changed. \n Relative dependencies are installed as if they came from the npm registry (not via symbolic links). \n \n  also helps with keeping locally installed relative dependencies and their originals in sync. \n \n \n  is a safer version of   which doesn’t require a global install, among other benefits. \n : running bin scripts in npm packages without installing them   # npx  is a shell command for running bin scripts that is bundled with npm. Its most common usage is: This command installs the package whose name is   in the npx cache and runs the bin script that has the same name as the package – for example: That means we can run bin scripts without installing them first. npx is most useful for one-off invocations of bin scripts – for example, many frameworks provide bin scripts for setting up new projects and these are often run via npx. After npx has used a package for the first time, it is available in its cache and subsequent invocations are much faster. However, we can’t be sure how long a package stays in the cache. Therefore, npx isn’t a substitute for installing bin scripts globally or locally. If a package comes with bin scripts whose names are different from its package name, we can access them like this: For example: The npx cache   # Where is npx’s cache located? On Unix, we can find that out via the following command: That returns a path similar to this one: On Windows, we can use (one line broken up into two): That returns a path similar to this one (single path broken up into two lines): Note that npx’s cache is different from the cache that npm uses for the modules it installs: \n \n Unix: \n \n npm cache:  \n npx cache:  \n \n \n \n Windows (PowerShell): \n \n npm cache:  \n npx cache:  \n \n \n The parent directory of both caches can be determined via: For more information on the npm cache, see  the npm documentation . In contrast to the npx cache, data is never removed from the npm cache, only added. We can check its size as follows on Unix: And on Windows PowerShell: comments powered by Disqus."},
{"url": "https://2ality.com/2022/11/linking-from-github-to-mastodon.html", "title": "Linking from GitHub to Mastodon", "content": "Linking from GitHub to Mastodon computers decentralized mastodon github Finding people on Mastodon is still difficult. If you have a GitHub account, you can help others find you by linking from it to your Mastodon account. \n   \n     Options for linking from GitHub to Mastodon \n   \n   \n     Wish: generic fields for GitHub profiles \n   \n   \n     Further reading \n   \n Options for linking from GitHub to Mastodon   # \n \n Option 1: Mention your Mastodon profile URL in your GitHub profile bio. \n \n To avoid GitHub turning part of the URL (starting with the  ) into a clickable link, you can enclose the URL in backticks – e.g., this is what  my bio’s text  looks like: \n \n Downside: The link is not clickable. \n Downside: Can’t be used for  Mastodon’s URL verification  because there is no way to add   to the link. \n Upside: Easy to discover via  a GitHub search  (idea by  ). \n \n \n \n Option 2: Make your Mastodon profile URL your homepage (as described by  Jan Wildeboer ). \n \n Upside: GitHub automatically adds   to the link which means that URL verification works. \n Downside: You can’t use that field for your actual homepage anymore. As far as I know, Mastodon re-checks verification every time you save the Mastodon profile. \n Downside: It‘s not always obvious that the URL refers to a Mastodon profile. \n \n \n \n Option 3: Mention your Mastodon ID in  the profile readme  (which is displayed in the profile). \n \n Downside: GitHub doesn’t let you add   to links, so verification doesn’t work. \n Downside: Doesn’t show up in GitHub searches. \n \n \n Wish: generic fields for GitHub profiles   # My preferred solution would be GitHub letting us add arbitrary fields to the profile: \n Textual key (I’m not sure icons could be done well generically). \n Textual values, with auto-detection for links and automatic  . \n Such generic fields could also be used for homepages, Twitter, other social media platforms, etc. \n Further reading   # \n Discussion on GitHub \n “Getting started with Mastodon”  (my brief tutorial) \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/11/regexp-v-flag.html", "title": "ECMAScript proposal: RegExp flag  /v  makes character classes and character class escapes more powerful", "content": "ECMAScript proposal: RegExp flag   makes character classes and character class escapes more powerful dev javascript es proposal In this blog post, we look at  the ECMAScript proposal “RegExp   flag with set notation + properties of strings”  by Markus Scherer and Mathias Bynens. \n   \n     The new flag  \n   \n   \n     Recap: code units vs. code points vs. graphemes \n     \n       \n         Splitting strings \n       \n     \n   \n   \n     Terminology: character class escapes and character classes \n   \n   \n     How character sets are influenced by RegExp flags \n     \n       \n         Neither   nor  : character sets contain code units \n       \n       \n         : character classes as sets of code points \n       \n       \n         : extended character classes as sets of code point sequences (“strings”) \n       \n     \n   \n   \n     Set operations for character classes \n     \n       \n         Subtraction of character sets via  \n       \n       \n         Intersection of character sets via  \n       \n       \n         Union of characters sets \n       \n     \n   \n   \n     Improved case-insensitive matching \n   \n   \n     Which characters must be escaped inside   character classes? \n   \n   \n     Implementations \n   \n   \n     Resources \n   \n The new flag     # The proposed new regular expression flag   ( ) enables three features: \n \n Support for multi-code-point graphemes (such as some emojis) for character classes and Unicode property escapes ( ). \n \n \n Character classes can be nested and combined via the set operations subtraction and intersection. \n \n \n The flag also improves case-insensitive matching for negated character classes. \n \n Given that the syntax had to be changed to enable nested character classes and set operations, a new flag was the best solution.   can be viewed as an upgrade for  flag  : The two flags are mutually exclusive. The presence of   can be detected via the boolean getter  : Recap: code units vs. code points vs. graphemes   # \n  are the atomic parts of Unicode text. They have a range of 21 bits. \n When Unicode is stored in a location such as a file or a programming language string, the atomic parts of that location are often smaller than 21 bits. Then one or more storage parts must be used to encode a code point. Unicode calls such storage parts  .\n \n JavaScript string code units (which JavaScript calls  ) are 16 bits in size. One or two code units are used to encode a code point (UTF-16 format). \n \n \n A   is any symbol that can be used in Unicode text. A grapheme is composed of one or more code points. Graphemes are the real characters of Unicode. \n The following code shows examples of these concepts: Splitting strings   # Code units, code points and graphemes also matter when it comes to spliting a string into parts. The string method   splits a string into code units: Iterating over a string (via  , spreading, destructuring,  , etc.) splits it into code points:  (which is not part of ECMAScript proper but of  the ECMAScript Internationalization API ) can split strings into graphemes: Terminology: character class escapes and character classes   # A   is a set of Unicode entities to be matched. Depending on regular expression flags, these entities are either code units, code points or code point sequences.  and   are syntax for defining character sets: \n \n A   defines a character set via a predefined name or a key-value pair. It is loosely similar to a variable name in JavaScript. \n \n Examples:  \n \n \n \n A   defines a character set by combining constructs that define character sets. It is delimited by square brackets and loosely similar to an expression in JavaScript. \n \n Examples:  \n \n \n How character sets are influenced by RegExp flags   # Depending on which flags a regular expression has, character class escapes and character classes define either: \n Sets of code units \n Sets of code points \n Sets of graphemes \n Neither   nor  : character sets contain code units   # # With neither   nor  , character classes match code units: # Without   and  , the following character class escapes are supported: \n  is equivalent to  \n \n  is equivalent to  \n \n \n  matches all whitespace code points (which are all encoded as single code units)\n \n  matches the complement of  \n \n \n  is equivalent to  \n \n  is equivalent to  \n \n \n # We can’t use code unit character classes to match a code point that is encoded as two code units because it produces two separate character set elements: This test is equivalent to: Code unit character class escapes have the same downside: : character classes as sets of code points   # The regular expression flag   ( )  was added in ECMAScript 6. With this flag, character sets contain code points and the previously mentioned limitations go away: # Flag   also enables   (which were added to JavaScript in ECMAScript 2018): # Since character set elements are code points, we can’t match sequences of code points – for example: : extended character classes as sets of code point sequences (“strings”)   # With the proposed flag  , character sets contain code point sequences (“strings”). # Flag   enables a new feature inside character classes – we can use   to add code points sequences to their character sets: We can use a single   to add multiple code point sequences – if we separate them with pipes: # With  , we can use Unicode property escapes (  and  ) to specify sets of code points via Unicode properties. With  , we can also use them to specify sets of code point sequences via Unicode properties of strings: For now, the following Unicode properties of strings are supported: \n : single code points \n : e.g. 1️⃣ \n : e.g. ☝🏿 \n : e.g. 🇰🇪 \n : e.g. 🏴󠁧󠁢󠁳󠁣󠁴󠁿 \n : e.g. 🧑‍🌾 \n : union of all of the above sets \n These properties are defined in text files: \n \n \n It’s interesting that the definitions are simply enumerations of code point sequences – for example: There are  plans  to support Unicode properties of strings with the   flag, so this feature may not remain exclusive to  . # Negated character classes still only match code points: Negating Unicode properties of strings is a syntax error. This issue could be fixed if regular expressions treated input strings as sequences of graphemes. However, that would be a significant undertaking and is beyond the scope of the proposal. Set operations for character classes   # To enable set operations for character classes, we must be able to nest them. With character class escapes, there already is nesting. Flag   also lets us nest character classes. The following two regular expressions are equivalent: Subtraction of character sets via     # We can use the   operator to set-theoretically subtract the character sets defined by character classes or character class escapes: Single code points can also be used on either side of the   operator: Intersection of character sets via     # We can use the   operator to set-theoretically intersect the character sets defined by character classes or character class escapes: Union of characters sets   # Two compute the set-theoretical union of character sets, we only need to write their definining constructs next to each other inside a character class: Improved case-insensitive matching   # Flag   has a quirk when it comes to case-insensitive matching. If a character class escape is negated, the complement of its character set is computed first and then   is handled (via  Unicode   (SCF) ) – for example: The character set of   includes (among other code points) lowercase letters such as “a”. During SCF, their uppercase versions are added, which explains the results in the previous example. If a character class is negated, SCF is applied to the character class before its complement is computed – for example: The character set of   contains all lowercase letters. After SCF, it also contains all uppercase letters. The complement of that set matches neither lowercase nor uppercase letters, which explains the results in the previous example. For comparison, this is what happens without  : Two observations: \n Both ways of negating should produce the same results. \n Intuitively, if we add   to a regular expression, it should match at least as many strings as before (not fewer). \n That’s why with flag  , case folding (“deep case closure”) is performed after all character sets were computed (loosely similarly to the first example in this section): Source of this section:  GitHub issue “IgnoreCase vs. complement vs. nested class” Which characters must be escaped inside   character classes?   # Inside   character classes, we must escape: Some characters only have to be escaped in some locations: \n  only has to be escaped if it doesn’t come first or last. \n  only has to be escaped if it comes first. \n Inside   character classes, we additionally must always escape: \n \n Special characters: \n \n \n \n Double punctuators: \n \n \n Consequences: \n \n When escaping plain text for regular expressions,  more characters must be escaped : \n \n \n \n Alas, escaping these characters is currently illegal with flag  .  There are plans to change that, though. \n \n Implementations   # \n The Babel plugin   transpiles regular expressions with flag  :\n \n It was used to test the code in this blog post. \n It does not support the getter  . \n \n \n Resources   # Sources of this blog post (in addition to the proposal itself): \n Specification for the proposal \n Article “RegExp   flag with set notation and properties of strings”  by Mark Davis, Markus Scherer, and Mathias Bynens \n More information on some of the topics covered in this blog post: \n \n Chapter “Unicode – a brief introduction”  in “JavaScript for impatient programmers” \n \n \n Section “Flag: Unicode mode via  ”  in “JavaScript for impatient programmers” \n \n \n Section “Unicode property escapes”  in “JavaScript for impatient programmers” \n \n Useful resources: \n The Wikipedia page “Unicode character property”  contains a list of Unicode character properties \n The Emojipedia page “Every emoji by codepoint”  lists the codepoints that make up emojis. \n The Compart page “Unicode Block ‘Miscellaneous Symbols’”  lists, among others, emojis that are in the Basic Multilingual Plane (16 bits). \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/10/mastodon-getting-started.html", "title": "Getting started with Mastodon", "content": "Getting started with Mastodon computers decentralized mastodon  More information on searching, finding accounts, being found, direct messages, etc. I use both Twitter and Mastodon and like both. Both have pros and cons. In this blog post, I’d like to explain how to get started with Mastodon. \n   \n     How is Mastodon different from Twitter? \n     \n       \n         Mastodon works more like email \n       \n       \n         Mastodon feels calmer \n       \n       \n         Other differences between Mastodon and Twitter \n       \n     \n   \n   \n     Preparing for Mastodon \n     \n       \n         What app should I use? \n       \n       \n         How do do I find a server that works for me? \n       \n       \n         Does it matter which server I pick? \n       \n       \n         How do I move to a new server? \n       \n       \n         Mastodon terminology \n       \n     \n   \n   \n     First steps on Mastodon \n     \n       \n         How do Mastodon IDs work? \n       \n       \n         How does content moderation work? \n       \n       \n         How can I search for content on Mastodon? \n       \n       \n         What is in the various “timelines”? \n       \n     \n   \n   \n     Following accounts \n     \n       \n         How do I follow someone if I have their Mastodon ID? \n       \n       \n         How do I find accounts to follow? \n       \n       \n         Muting accounts, boosts and replies \n       \n     \n   \n   \n     Things to do once you have settled in \n     \n       \n         How can people find me? \n       \n       \n         How do I add a verified URL to my profile? \n       \n       \n         Can I verify my GitHub URL? \n       \n     \n   \n   \n     Posting on Mastodon \n     \n       \n         Etiquette: things to consider when posting on Mastodon \n       \n       \n         How do I configure where my post shows up? \n       \n       \n         How do Mastodon’s direct messages work and how private are they? \n       \n       \n         Why is it important to add hashtags to posts? \n       \n       \n         Why doesn’t Mastodon support quoting of posts? \n       \n       \n         How long will a server store my posts? \n       \n       \n         How does editing posts work? \n       \n     \n   \n   \n     The open foundation of Mastodon \n     \n       \n         What is the Fediverse? \n       \n     \n   \n   \n     Tips \n     \n       \n         Configuring the user interface \n       \n       \n         Editing posts \n       \n       \n         Managing followed accounts \n       \n       \n         Miscellaneous tips \n       \n     \n   \n   \n     Further reading \n   \n How is Mastodon different from Twitter?   # Mastodon works more like email   # Mastodon is similar to email: \n \n To join Mastodon, you need to find a server and get an account on it. \n \n \n You can communicate with anyone, on any server, as long as you know: \n \n The name of their server. \n Their user name on that server. \n \n Similar to email addresses, both of these pieces of information are combined into a single ID.  More on that later. \n \n If you know  RSS : Mastodon is also similar to RSS in many ways. Mastodon feels calmer   # Mastodon was designed to be a calmer experience than Twitter, Facebook, etc.: \n There is no algorithm that recommends content and encourages engagement.\n \n A downside is that it can be more difficult to find interesting accounts.  See below for tips. \n \n \n By default, you only see the posts of the accounts you follow. \n You don’t see ads, posts liked by others, etc. \n Unless you expand a post, you don’t see how often it was liked and shared. \n Other differences between Mastodon and Twitter   # \n \n Virtually all servers are funded via donations. That means: \n \n Accounts are free. \n You should consider donating to help keep your server running. \n \n \n \n The etiquette is different  – e.g.: It’s possible to hide the content of a post so that people have to click if they want to read it. This mechanism is used for topics such as politics and spoilers and called a   because you initially only see the warning label (“politics”, “spoiler”, etc.). \n \n \n Each server has different rules  – e.g.: Some servers only allow posts in English to help them with moderation. \n \n \n Mastodon is based on open protocols (ActivityPub and others), which means that it’s easier to implement apps and services that are compatible with it. \n \n In contrast, Twitter restricts how much third-party apps can do, compared to its own app. And its abilities to communicate with external services are very limited. \n \n \n In the past, the biggest downside of Mastodon for me was that none of the people I know used it. That is changing and it now feels more similar to Twitter to me. Preparing for Mastodon   # What app should I use?   # I’m happy with the web app and have installed it natively via Chrome (it’s a Progressive Web App). Native apps are listed  on the Mastodon website How do do I find a server that works for me?   # \n \n The Mastodon website has  a list of servers  that you can browse. \n \n \n To find out what a server is like, visit it with a web browser. What exactly you see depends on the Mastodon version, but the following two paths should work: \n \n  lets you create an account or sign in.\n \n It either contains the server’s rules or has a link to them. I recommend reading those: For example, some servers forbid posts in languages other than English so that they can moderate properly. \n It should show you how many people administer the server. More administrators make servers more robust w.r.t. administrators quitting, etc. \n \n \n  shows what people post on that server. \n \n \n \n Don’t automatically go with the big servers ( ,  , etc.) – take some time to find a server that works for you: \n \n Popular servers can get overloaded at times (whenever there’s a new influx of users and until they had time to upgrade). \n Having more points of failure helps with the robustness of the whole network. \n \n \n \n Some servers say “get on waitlist”. However: \n \n Quoting Fedi.Tips : “A lot of these servers don’t have a waitlist at all and will accept you pretty quickly, within a few hours in some cases. It’s just the server admin is screening out spammers by switching on the ‘why do you want to join?’ form because spambots find this form harder to cope with.” \n \n \n Further reading:  “Knowing your server”  on the Mastodon website. Does it matter which server I pick?   # \n The content you see in your home timeline is exclusively determined by the accounts you follow. And following works transparently across servers. Therefore, it doesn’t really matter which server you are on. \n If you need to, it’s easy to move (see next question). \n The server determines how content is moderated – which does make a difference. \n The server also affects what you see in  the timelines  – but I rarely if ever look at those. \n How do I move to a new server?   # Moving servers is relatively easy: \n The accounts that follow you, can automatically be pointed to the new location. \n People you follow can be exported and imported. \n Your posts can be exported but not imported. \n More information:  “Moving or leaving accounts”  on the Mastodon website. Mastodon terminology   # \n Instance: a Mastodon server. \n Toot: a post, a tweet. \n Tooting: posting, tweeting. \n Boosting: sharing a post in your timeline, retweeting. \n Fediverse: roughly – all services that are compatible with Mastodon.  Longer explanation. \n Recent development (not yet deployed everywhere):  “Change the nouns ‘toot’ and ‘status’ to ‘post’”. First steps on Mastodon   # How do Mastodon IDs work?   # Each Mastodon ID has two parts (similarly to email addresses): \n The server \n The user \n There are two common ways to refer to accounts: \n Mastodon addresses look like   and are mostly used in Mastodon posts.\n \n Example:  \n When you see a mention in a post, the server part is often omitted, but you need both parts to fully identify an account. \n \n \n Profile URLs look like   and are useful for exchanging IDs (see next entry).\n \n Example:  \n \n \n How does content moderation work?   # \n Each server is responsible for moderating:\n \n There is no central banning. \n Servers can ban any of their users. \n Servers also often ban problematic other servers. \n \n \n Users can:\n \n Block or mute other users (anywhere). \n Block servers. \n Report posts to admins (via the “three dot” menu of a post). \n \n \n More information:  “Dealing with unwanted content”  on the Mastodon website. How can I search for content on Mastodon?   # Because no Mastodon server sees all Mastodon traffic, search is more limited than, e.g., on Twitter.  Quoting Mastodon’s API documentation : Mastodon supports full-text search when ElasticSearch is available. Mastodon’s full-text search allows logged in users to find results from: \n their own posts, \n their favourites, and \n their mentions. \n It deliberately does not allow searching for arbitrary strings in the entire database. A post from Eugen explains why search is less powerful than it could be : Lack of full-text search on general content is intentional, due to negative social dynamics of it in other networks # While searching for text is limited, searching for hashtags isn’t and covers the whole database of a server: \n \n Searching for hashtags show preliminary counts which can be zero. Don’t be deterred by zeros: Click and you’ll often get matching posts. \n \n \n In Mastodon 4+, you can  follow hashtags . \n \n What is in the various “timelines”?   # \n \n 🏠 The   consists of posts people you follow and posts that they share. \n \n \n 🌎 The   consists of all posts that the current server knows about: \n \n Posts created by   (accounts on the current server). \n Posts and boosts by accounts that local accounts follow. \n \n \n \n 👥 The   is a filtered version of the federated timeline: It only shows posts that were created by local accounts. \n \n \n #️⃣ “Explore” provides various ways of browsing the federated timeline. \n \n More information on timelines. Following accounts   # How do I follow someone if I have their Mastodon ID?   # \n If you have the ID of an account on any server (either a URL or an   address), you can use Mastodon’s search to show its profile on the current server and follow it. \n How do I find accounts to follow?   # \n You can find accounts via posts:\n \n Posts   (shared) by accounts you follow \n Posts listed in  the local timeline and the federated timeline \n Posts you find when  searching  for hashtags. \n \n \n You can check out who others follow or who follows them. \n I also recommend finding an admin account for your server and following it. \n # These are directories of Mastodon accounts, organized by topics that they post about: \n fediverse.info \n Trunk \n Fedi.Directory \n # There are services that search the profiles of accounts of people you follow on Twitter for Mastodon IDs and show them to you – for example: \n Fedifinder \n Twitodon \n Debirdify \n Be aware that you are giving these apps access to a lot of data. Don’t forget to deauthorize them once you are done using them. Muting accounts, boosts and replies   # Via the settings in your home timeline (the icon in the top right corner with the sliders), you can: \n Toggle if any boosts should be shown. \n Toogle if any replies should be shown. \n Each profile has a context menu (an icon with three vertical dots) where you can: \n Mute the account\n \n You have the option to mute an account forev for a limited time – e.g., for one day. \n \n \n Hide the boosts of the account \n Block the account:\n \n Effect for you:\n \n You won’t see the account in your home feed. \n You won’t see other people boosting the account. \n You won’t see other people mentioning the account. \n You won’t see the account in public timelines. \n You won’t see notifications from that account. \n \n \n Effect for the blocked account:\n \n The account is forced to unfollow you. \n The account cannot follow you. \n The account won’t see other people’s boosts of you. \n The account won’t see you in public timelines. \n \n \n \n \n More information on  dealing with unwanted content . Things to do once you have settled in   # How can people find me?   # \n \n Mention your the URL of your Mastodon profile on your other social media profiles (Twitter, GitHub, etc.). \n \n \n Use hashtags in posts: Mastodon’s search is more limited than, e.g., Twitter’s. That’s why hashtags matter more than elsewhere.  There is more information on searching above . \n \n \n People are more likely to follow if your Mastodon profile explains who you are: \n \n Some kind of avatar image, a URL of a homepage, etc.\nSeeing a few posts or boosts helps, too. \n You can verify links in your profile (see  next subsection ). \n More information on profiles. \n \n \n \n Mention your Mastodon ID in your Twitter profile so that people can find you via services such as  the ones listed above . \n \n \n Add your name to one of  the Mastodon directories . \n \n How do I add a verified URL to my profile?   # To add a verified URL to your profile: \n Edit your profile. \n “Profile metadata” consists of fields with labels and values. Set one value to the URL of an HTML page that you can edit. \n Editing that page: \n \n Either add to  : \n \n \n \n Or add to  : \n \n \n More information on verifying URLs. Can I verify my GitHub URL?   # Yes!  How is described here. Posting on Mastodon   # Etiquette: things to consider when posting on Mastodon   # Much of the etiquette on Mastodon depends on the server. These are a few things that I have noticed: \n \n You can add a content warning to a post: Initially only that warning will be shown. To view the actual content, users have to click. \n \n Content warnings are encouraged for a variety of topics. For example:\n \n “Politics” is a common content warning and helps people avoid doom-scrolling. \n “Spoiler” is useful for spoiler-y information such as answers to quiz questions, plot spoilers (for books, movies, TV shows), etc. \n “Food”, “Drinks” and “Eye-contact” are common for visual content. \n \n \n More information on content warnings. \n \n \n \n If you post visual content, you should add a description for visually impaired users. If you upload such content, there is an “Edit” link that lets you do that. \n \n \n You can mark attached visual content as “sensitive” and it will be initially blurred. People will have to click to see it. \n \n Media is often marked as sensitive (e.g. photos of food and drinks), so that people only have to see it if they want to. \n More information on marking media as sensitive. \n \n \n \n It’s best not to link to too many tweets: It doesn’t really fit into the platform and many people are on Mastodon to get away from Twitter. \n \n How do I configure where my post shows up?   # Quoting Mastodon creator Eugen Rochko : Twitter forces you to choose between two extremes, a protected account and a fully public account. If you have a public account, all your tweets are visible to everyone and infinitely shareable. Mastodon realizes that it’s not something you might always want, though. That’s why, when you create a post, you can pick one of four levels of  : \n \n 🌎 Public: visible to everyone (your followers, public timelines, anyone looking at your profile) \n \n \n 🔓 Unlisted: visible to your followers and at your profile, but not in public timelines. \n \n \n 🔒 Followers only: only visible to followers and accounts mentioned in the post. \n \n \n  Mentioned people only: only visible to whoever is mentioned in the post \n \n How do Mastodon’s   work and how private are they?   # Direct messages are simply posts whose visibility is “Mentioned people only” (see previous subsection): \n If you mention someone’s Mastodon address, they get a notification and can read the post. \n Direct messages are not end-to-end encrypted and can therefore by read by the administrators of the sending and the receiving Mastodon servers\n \n That is similar to how Twitter’s direct messages can be read by Twitter employees. \n End-to-end encryption for direct messages is being worked on. \n \n \n Thus, whenever privacy is important, use a service that provides end-to-end encryption. Why is it important to add hashtags to posts?   # Mastodon’s search  does not support full text search for other people’s posts. Searching for hashtags works quite well, though. Therefore, if you want your posts to be found, add hashtags. Tips for writing hashtags: \n \n Tags in camel case are more accessible because screen readers can detect where words start: \n \n For example,   is better than  . \n Separating via underscores is also on option (hyphens are not supported in tags), especially if a tag contains an acronym:  \n \n \n \n I avoid inlining tags (mentioning them inside text) and put them at the end of a post. I prefer how that looks. However, inlining tags is OK, accessibility-wise – quoting  Kris Nelson : \n As someone who regularly uses screen readers and works with blind colleagues who rely on screen readers to access the internet, please let me assure you that using #hashtags within the body of a post is not a problem. You don’t need to move them to the end! It is helpful to use #CamelCase to avoid gibberish for many word combos, but the extra # is so minimal as to disappear given how much else screen readers say & how fast they speak to experienced users. \n \n \n Be mindful of polluting search results – e.g. you may write a post “I love seeing all the nice photos of trees at  ”. \n \n Upside: People can click on the hashtag to see the photos. \n Downside: You have just added an entry to the search results that does not contain a photo. \n Alas, there doesn’t seem to be a way to link to   (i.e., a root path on the current server). Therefore, I put a space after   when I refer to (vs. use) a hashtag. Then Mastodon doesn’t consider it a hashtag. \n \n \n Why doesn’t Mastodon support quoting of posts?   # Quoting Mastodon creator Eugen Rochko : Another feature that has been requested almost since the start, and which I keep rejecting is quoting messages. Coming back to my disclaimer, of course it’s impossible to prevent people from sharing screenshots or linking to public resources, but quoting messages is  . It makes it a lot easier for people to immediately engage with the quoted content… and it usually doesn’t lead to anything good. When people use quotes to reply to other people, conversations become performative power plays. “Heed, my followers, how I dunk on this fool!” When you use the reply function, your message is broadcast only to people who happen to follow you both. It means one person’s follower count doesn’t play a massive role in the conversation. A quote, on the other hand, very often invites the followers to join in on the conversation, and whoever has got more of them ends up having the upper hand and massively stressing out the other person. How long will a server store my posts?   # Quoting  Dave Troy : Another design consideration re: Mastodon is that it works well for ephemeral asynchronous communications, but for many reasons should not be counted on as an archival resource. Media attachments are periodically purged and may not be available after a week, or a month, etc. While some servers may try to preserve content forever, this may be costly and unsustainable. Creators, researchers should treat this as an ephemeral resource and make provisions for self-archiving anything important. Therefore: Make sure that you back up posts (yours and others’) that you want to keep around. How does editing posts work?   # In Mastodon 4+, you can edit posts: \n \n In a timeline, the post’s date has an asterisk: \n \n The date is the date of creation. Hovering over it shows the full time and date. \n Hovering over the asterisk shows when the post was last edited. \n \n \n \n In detail view, there is a list of edits at the bottom, so you can check out what the post looked like in the past. \n \n \n If a post you are sharing/boosting is edited, you get a notification. \n \n The open foundation of Mastodon   # What is the  ?   # The Fediverse consists of services that are based on   (interconntected and decentralized) servers that communicate via open protocols. These services are used for   in a broad sense: social networking, blogging, etc. The most common Fediverse protocol is the W3C standard  . That’s what Mastodon uses, which is why it is compatible with all services that also use this protocol (which may or may not be federated). When Mastodon users mention the Fediverse, they usually mean “Fediverse services that are based on ActivityPub” (and therefore compatible with Mastodon). Examples of Fediverse services that are compatible with Mastodon: \n BookWyrm  (book cataloging, think Fediverse Goodreads) \n Drupal  (content management system) \n Friendica  (social networking) \n Funkwhale  (hosting audio, think Fediverse SoundCloud) \n Lemmy  (link aggregator, think Fediverse Reddit) \n Misskey  (microblogging) \n PeerTube  (video hosting, think Fediverse YouTube) \n Pixelfed  (image hosting, think Fediverse Flickr) \n Pleroma  (social networking) \n More information on the Fediverse: \n “Fediverse” on Wikipedia \n “fediverse.info – the bespoke fediverse guide” \n Tips   # Configuring the user interface   # Among others, the following panes have configuration settings (the icon on the top right with sliders): \n For “Home”, you can configure whether to show busts and replies. \n For “Notifications”, you can configure notification sounds and much more. \n Editing posts   # \n The menu of a post has the command “Delete & re-draft” that deletes that post and copies its contents into the text field for creating a new post. \n New in Mastodon 3.5 : editing posts. \n Managing followed accounts   # \n You can mute accounts (hide their posts) forever or for a limited time (7 days, 1 day, etc.). \n If you follow someone, you can switch on the bell icon in their profile and will get notified whenever they post something. That way, you never miss one of their posts. That‘s useful if someone posts infrequently. \n Miscellaneous tips   # \n To show an account or a post from another server in your app, search for their URL. \n Every Mastodon account has an RSS feed that you can follow via a feed reader. \n Further reading   # \n \n Check out the official  “Mastodon quick start guide” . \n \n \n Fedi.Tips has  a website  and  a Mastodon account  with useful information on Mastodon and on the Fediverse. \n \n \n Follow me on Mastodon: \n \n Either search for the URL   and follow me. \n Or go to that URL and click the “Follow” button. \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2008/04/latex-on-mac-os-x.html", "title": "LaTeX on Mac OS X", "content": "LaTeX on Mac OS X apple latex mac \nLaTeX on Mac OS X is a very pleasant experience, because both LaTeX and the operating system have excellent support for PDF. That means that you’ll be able to use a “PDF-only” workflow (with the occasional bitmap graphics thrown in). In this post, I describe my favorite setup for LaTeXing on the Mac.\n \n\n Getting started \n     Installation: The best way is to use the  MacTeX distribution  ( TeX Live  on Mac OS). \n     SyncTeX : Enables jumping between corresponding locations in PDF and LaTeX source. Aquamacs and Skim support it out of the box. SyncTeX has been created as a replacement for the older PDFSync. \n Aquamacs Aquamacs AucTeX RefTeX \n     Overview with screen shots: “ Editing LaTeX with Aquamacs ”. \n     Options → Option Key: Change if you need the option key for special characters (e.g.: backslash on German keyboards or French accents). \n     Command → Jump to PDF (or command-shift-click or C-c C-c \"J)ump To PDF\"): Uses SyncTeX to go to that part of the PDF that corresponds to the cursor position in the LaTeX source. \n     M-x longlines-mode: Avoids inserting hard line breaks (e.g. via auto-fill). This used to be a big problem when you wanted to edit LaTeX source in both Emacs and other GUI editors. Tip: You can remove intra-paragraph line breaks via unfill-region (but this does not work if each line of the paragraph is indented with spaces). \n Skim Skim \n     Enable SyncTeX with Aquamacs: “Preferences → Sync → PDF-TeX Sync support”. \n     More information on PDF syncing: “ TeX and PDF Synchronization – skim-app ”. \n     Jump to LaTex: command-shift-click. \n Tips and tools \n     Mac OS Spaces: I don't usually need them, because an application often suffices as a substitute for a space when it comes to grouping windows. But if you combine two different applications, such as Aquamacs and Skim, spaces are very handy. \n     Check out my  other LaTeX posts . \n external extensive list \n Integrated GUI LaTeX editors: If you are not into Emacs, you'll probably want to take a look at  TeXShop  and  iMacTeX . \n GraphViz: Check out the Mac OS X  GUI application . It exports PDF which is easy to integrate in LaTeX. \n dot2tex : a LaTeX-friendly converter from Graphviz to PGF/TikZ commands, with support for LaTeX (math!) labels and arrows. \n BibTeX:  BibDesk  (Mac OS X only) or  JabRef  (Java). \n jPicEdt  (Java): Graphical eepic editor. \n Conclusion comments powered by Disqus."},
{"url": "https://2ality.com/2005/08/generics-and-parameters-of-type-class.html", "title": "Generics and Parameters of Type Class", "content": "Generics and Parameters of Type Class dev java  This page got mangled years ago and I just tried to restore it. I forgot most of what I knew about Java, so this code may contain syntax errors. Generics allow parameters to determine the type of the return value. This can be used to avoid a cast when returning objects from an internal map, by using the class of the object as a key. Note that   also enforces the type of the value, at compile time. If you need several keys whose value has the same class, you can extend the above idea as follows. If you want different keys with the same content to point to the same value, you'll have to implement   and  , though. comments powered by Disqus."},
{"url": "https://2ality.com/2005/03/semantic-web-reference-card.html", "title": "A Semantic Web Reference Card", "content": "A Semantic Web Reference Card semantic web dev this reference card Planet RDF comments powered by Disqus."},
{"url": "https://2ality.com/2008/02/how-will-mobile-communication-evolve.html", "title": "How will mobile communication evolve?", "content": "How will mobile communication evolve? scitech My guess is that most people will soon find out that constantly being interrupted by one's cell phone makes it hard to relax or concentrate. On the other hand, it   convenient if someone is easy to reach. Is there a way to reconcile the opposing goals of not being interrupted and being connected? Well, asynchronous communication such as email and SMS goes a long way (if one doesn't check for updates too often). But what if you need synchronous communication? Then you can use a message to set up a time interval during which to get in touch directly. This limits the time when you have to be easily reachable. Complementary to this approach is the idea to let people know your current status: Do you want to be contacted, are you busy etc. This idea of a publicly broadcasted status originated in instant messaging and has been further developed by the Twitter service to also work with SMS, web sites etc. I expect this kind of service to be more popular in the future (e.g. I can imagine it being better integrated with cell phones), as we grow more sensitive about being always available. comments powered by Disqus."},
{"url": "https://2ality.com/2008/04/couch-graphical-user-interfaces.html", "title": "Couch graphical user interfaces", "content": "Couch graphical user interfaces computers some new ideas zoomable user interfaces \n\nBut then, there is a third kind of GUI: couch interfaces. With their media center software, both Microsoft and Apple have been quite innovative in this space. The more I use couch interfaces, the more I want a couch interface for almost every desktop application: For example, if I am on the couch, I don't want to leave it to quickly check my email. Any kind of widget such as weather, dictionary or stocks also makes couch-sense.\n\n \n\nNote that couch interfaces are a lot like smartphone interfaces: The screen space is greatly reduced and input facilities are limited. Smartphones partially solved the input problem via multi-touch, couch interfaces could do something similar by building small trackpads into remote controls. Wireless keyboards or  wireless air mice  might also help. But then the Desktop GUI cursor has to be adjusted to couch constraints (by making it larger?).\n comments powered by Disqus."},
{"url": "https://2ality.com/2008/04/how-to-guide-audience-from-novice-to.html", "title": "How to guide an audience from novice to expert", "content": "How to guide an audience from novice to expert education life The Hero's Journey: Are You Experienced? \n     Be careful with comprehensive overviews (of the subject, its history, etc.). \n\n     Prefer concrete examples over abstractions (and/or combine the two). \n\n     Keep things initially simple, add ambivalence later (to complete the knowledge). \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/06/windows-on-macs-via-utm.html", "title": "Running Windows/ARM on Apple Silicon Macs via UTM", "content": "Running Windows/ARM on Apple Silicon Macs via UTM dev javascript nodejs UTM  is a free virtualization software that runs Windows/ARM on Apple Silicon Macs. This blog post explains how to use it. \n   \n     UTM’s instructions \n   \n   \n     Installing Windows/ARM \n   \n   \n     A few tips for using the virtual Windows machine \n   \n   \n     Useful software \n   \n UTM’s instructions   # UTM’s “Gallery”  lists recipes for running various operating systems.  The Windows 11 (ARM) recipe  mostly worked for me. In this blog post I give a few tips that complement those instructions. I’m impressed by how well UTM runs Windows/ARM on my MacBook Pro 14-inch with an M1 Pro. Installing Windows/ARM   # As the recipe mentions, there are three downloads (for the links, see the recipe): \n UTM for Mac \n Windows for ARM (Windows Insider Preview): This is a free download for now. You only need to be a member of the Windows Insider program. It’s free and easy to join – you only need a Microsoft Account (which is also free and easy to create). \n SPICE Guest Tools: Need to be installed on Windows for UTM to fully work (dynamic resizing of the window with the Windows screen, support for networking, sharing files, shared clipboard, etc.). \n The “Create a New Virtual Machine” wizard works really well – I didn’t need to change any of the defaults. Steps: \n Start: We need “Virtualize” (not ”Emulate”), as we are running Windows/ARM natively. \n Operating System: Windows \n Windows: Check “Import VHDX Image” and use the “Browse...” button to point UTM to the downloaded Windows disk image. \n Hardware: I didn’t change the defaults. \n Shared Directory: I created a directory “SharedWithWindows” in my macOS home directory and told UTM about it via the “Browse...” button. \n Summary: I changed the name of the newly created virtual machine from “Windows” to “Windows/ARM”. \n We can now start the virtual machine: \n Follow the Windows installation process until the keyboard is fully configured. \n Afterwards, my installation got stuck because the Windows installer couldn’t access the internet. \n Even if that doesn’t happen, now is the best time to install the SPICE Guest Tools (because afterwards, we can resize the window etc.):\n \n Press Shift-F10 – the Windows command prompt opens (you might have to configure your keyboard so that F10 isn’t a media key, but fn+F10 worked in my case). \n Click the “Drive image options” icon in the top right corner of the UTM window and change it to the SPICE Guest Tools   disk image. This disk image is now “in” Windows drive  . \n Run the SPICE Guest Tools installer by entering “ ” and hitting return.\n \n After “ ”, you can hit the Tab key and Windows completes the filename for you. \n If you are having trouble entering the backslash, you can first enter “ ” and then the filename (without a preceding backslash). \n \n \n \n \n When the SPICE Guest Tools Installer is done, we let it reboot the virtual Windows machine for us. \n We have to configure region and keyboard again, but the virtual machine works much better now. The installation should go through smoothly from now on. \n Windows terminology I wasn’t familiar with: A “Windows Hello PIN” is a password. \n A few tips for using the virtual Windows machine   # \n The Windows Menu is loosely similar to Spotlight and activated by clicking on it (in the Taskbar at the bottom) or by pressing the Command Key. \n Inverted scrolling: Windows only supports Mac-style inverted scrolling for mice, not for trackpads. Solution: Click the “Edit selected VM” icon in the top right corner of the UTM window and check “Input > Invert Mouse Scroll”. \n The shared folder is available in Windows via “Network Drive (Z:)”. \n You can display the keyboard layout by running “On-Screen Keyboard” via the Windows menu. \n By default, the “Microsoft Store” application (Microsoft’s app store) is not installed. I haven’t found a simple way to fix this but I didn’t need the Microsoft Store yet, either. \n I disabled the macOS shortcuts that use the control key plus an arrow key: “System preferences > Keyboard > Shortcuts > Mission Control”. That way I can use these shortcuts when editing text in Windows. \n Useful software   # \n \n : a package manager for Windows (similar to Homebrew on macOS). \n \n \n : Windows/ARM binaries will eventually be normal Node.js downloads ( as documented in a GitHub issue ). Until then there are three options: \n \n We can use Chocolatey to install Node.js – there is  a package   and  a package  . \n We can  download an installer . Alas, this page hasn’t been updated in a while. The latest available version is 16.13.0. \n We can compile Node.js ourselves, as described in  this comment . \n \n \n \n \n \n To display the currently installed version, enter   in PowerShell. \n The install a newer version, check  Microsoft’s website . \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/05/processing-arrays-non-destructively.html", "title": "Processing Arrays non-destructively:  for-of  vs.  .reduce()  vs.  .flatMap()", "content": "Processing Arrays non-destructively:   vs.   vs.  dev javascript In this blog post, we look at three ways of processing Arrays: \n The   loop \n The Array method  \n The Array method  \n The goal is to help you choose between these features whenever you need to process Arrays. In case you don’t know   and   yet, they will both be explained to you. In order to get a better feeling for how these three features work, we use each of them to implement the following functionality: \n Filtering an input Array to produce an output Array \n Mapping each input Array element to one output Array element \n Expanding each input Array element to zero or more output Array elements \n Filter-mapping (filtering and mapping in one step) \n Computing a summary for an Array  \n Finding an Array element \n Checking a condition for all Array elements  \n Everything we do is  : The input Array is never changed. If the output is an Array, it is always freshly created. \n   \n     Processing Arrays via the   loop \n     \n       \n         Filtering with  \n       \n       \n         Mapping with  \n       \n       \n         Expanding with  \n       \n       \n         Filter-mapping with  \n       \n       \n         Computing summaries with  \n       \n       \n         Finding with  \n       \n       \n         Checking a condition with  \n       \n       \n         When to use  \n       \n       \n         Generators and  \n       \n     \n   \n   \n     The Array method  \n     \n       \n         Filtering with  \n       \n       \n         Mapping with  \n       \n       \n         Expanding with  \n       \n       \n         Filter-mapping with  \n       \n       \n         Computing summaries with  \n       \n       \n         Finding with  \n       \n       \n         Checking a condition with  \n       \n       \n         When to use  \n       \n     \n   \n   \n     The Array method  \n     \n       \n         Filtering with  \n       \n       \n         Mapping with  \n       \n       \n         Filter-mapping with  \n       \n       \n         Expanding with  \n       \n       \n          can only produce Arrays \n       \n       \n         When to use  \n       \n     \n   \n   \n     Recommendations \n   \n   \n     Further reading \n   \n Processing Arrays via the   loop   # This is how Arrays can be transformed non-destructively via  : \n Start by declaring the variable   and initializing it with an empty Array. \n For each element   of the input Array:\n \n If a value should be added to  :\n \n Transform   as necessary and push it into  . \n \n \n \n \n Filtering with     # Let’s get a feeling for processing Arrays via   and implement (a simplified version of) the Array method  : Mapping with     # We can also use   to implement the Array method  . Expanding with     #  returns all fruits that the persons in an Array have: Filter-mapping with     # The following code filters and maps in one step: \n Filtering is done via the   statement in line A and the   method in line B. \n Mapping is done by pushing   (not the input element  ). \n Computing summaries with     #  computes the average grade of an Array of students: Caveat: Computing with decimal fractions can result in rounding errors ( more information ). Finding with     #  is also good at finding things in unsorted Arrays: Here, we profit from being able to leave the loop early via   once we have found something (line A). Checking a condition with     # When implementing the Array method  , we once again profit from early loop termination (line A): When to use     #  is a remarkably versatile tool when it comes to processing Arrays: \n Creating output Arrays via pushing is easy to understand. \n When the result isn’t an Array, it’s often useful that we can finish early via   or  . \n Other benefits of   include: \n It works with  synchronous iterables . And we can support  asynchronous iterables  by switching to  a   loop . \n We can use   and   – in functions where these operators are allowed. \n A downside of   is that it can be more verbose than alternatives – depending on what problem we are trying to solve. Generators and     #  was already mentioned in the previous section but I additionally wanted to point out how convenient generators are for processing and producing  synchronous  and  asynchronous  iterables – think streams with on-demand processing of stream items. As examples, let’s implement   and   via synchronous generators: The Array method     # The Array method   lets us compute summaries of Arrays. It is based on the following algorithm: \n [Initializing the summary] We initialize the summary with a value that works for empty Arrays. \n We loop over the Array. Per Array element:\n \n [Updating the summary] We compute a new summary by combining the old summary with the current element. \n \n \n Before we get to   itself, let’s implement its algorithm via  . We’ll use concatenating an Array of strings as an example: The Array method   loops and keeps track of the summary for us, so that we can focus on initializing and updating. It uses the name “accumulator” as a rough synonym for “summary”.   has two parameters: A callback:\n \n Input: old accumulator and current element \n Output: new accumulator \n \n The initial value of the accumulator. In the following code, we use   to implement  : Filtering with     #  is quite versatile. Let’s use it to implement filtering: Alas, JavaScript Arrays are not very efficient when it comes to non-destructively adding elements to Arrays (in contrast to linked lists in many functional programming languages). Thus, mutating the accumulator is more efficient: Mapping with     # We can map via   as follows: A mutatating version is again more efficient: Expanding with     # Expanding with  : Mutating version: Filter-mapping with     # Using   to filter and map in one step: More efficient mutating version: Computing summaries with     #  excels if we can compute a summary efficiently without mutating the accumulator: Caveat: Computing with decimal fractions can result in rounding errors ( more information ). Finding with     # This is (a simplified version of) the Array method  , implemented with  : One limitation of   is relevant here: Once we have found a value, we still have to visit the remaining elements because we can’t exit early.   does not have this limitation. Checking a condition with     # This is (a simplified version of) the Array method  , implemented with  : Again, this implementation could be more efficient if we could exit early from  . When to use     # An upside of   is its conciseness. A downside is that it can be difficult to understand – especially if you are not used to functional programming. I use   if: \n I don’t need to mutate the accumulator. \n I don’t need to exit early. \n I don’t need support for synchronous or asynchronous iterables.\n \n However, it is relatively easy to implement   for iterables . \n \n \n  is a good tool whenever a summary (such as the sum of all elements) can be computed without mutation. Alas, JavaScript is not good at non-destructively and incrementally creating Arrays. That’s why I use   less in JavaScript than the corresponding operations in languages that have built-in immutable lists. The Array method     # The normal   method translates each input element to exactly one output element. In contrast,   can translate each input element to zero or more output elements. To achieve that, the callback doesn’t return values, it returns Arrays of values: Filtering with     # This is how we can filter with  : Mapping with     # This is how we can map with  : Filter-mapping with     # Filtering and mapping in one step is one of the strengths of  : Expanding with     # Expanding input elements into zero or more output elements is another strength of  :  can only produce Arrays   # With  , we can only produce Arrays. That prevents us from: \n Computing summaries with  \n Finding with  \n Checking a condition with  \n We could conceivably produce a value wrapped in an Array. However, we can’t pass data between the invocations of the callback. That prevents us from, e.g., tracking if we have already found something. And we can’t exit early. When to use     #  is good at: \n Filtering and mapping at the same time \n Expanding input elements into zero or more output elements \n I also find it relatively easy to understand. However, it’s not as versatile as   and – to a lesser degree –  : \n It can only produce Arrays as results. \n We can’t pass data between the invocations of the callback. \n We can’t exit early. \n Recommendations   # So how do we best use these tools for processing Arrays? My rough general recommendations are: \n Use the most specific tool you have for the task:\n \n Do you need to filter? Use  . \n Do you need to map? Use  . \n Do you need to check a condition for elements? Use   or  . \n Etc. \n \n \n  is the most versatile tool. In my experience:\n \n People who are familiar with functional programming, tend to prefer   and  . \n People who aren’t, often find   easier to understand. However,   usually leads to more verbose code. \n \n \n  is good at computing summaries (such as the sum of all elements) if mutating the accumulator isn’t needed. \n  excels at filter-mapping and expanding input elements into zero or more output elements. \n Further reading   # The following content is free to read online in  my book “JavaScript for impatient programmers” : \n Section “  loops” \n Section “ : deriving a value from an Array” \n Section “ : mapping to zero or more values” \n Chapter “Synchronous iteration” \n Chapter “Asynchronous iteration” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/06/nodejs-file-system.html", "title": "Working with the file system on Node.js", "content": "Working with the file system on Node.js dev javascript nodejs chapter “Working with the file system on Node.js” This blog post contains: \n An overview of the different parts of Node’s file system APIs. \n  (code snippets) for performing various tasks via those APIs. \n The focus of this post is on shell scripting, which is why we only work with textual data. \n   \n     Concepts, patterns and conventions of Node’s file system APIs \n     \n       \n         Ways of accessing files \n       \n       \n         Function name prefixes \n       \n       \n         Important classes \n       \n     \n   \n   \n     Reading and writing files \n     \n       \n         Reading a file synchronously into a single string (optional: splitting into lines) \n       \n       \n         Reading a file via a stream, line by line \n       \n       \n         Writing a single string to a file synchronously \n       \n       \n         Appending a single string to a file (synchronously) \n       \n       \n         Writing multiple strings to a file via stream \n       \n       \n         Appending multiple strings to a file via a stream (asynchronously) \n       \n     \n   \n   \n     Handling line terminators across platforms \n     \n       \n         Reading line terminators \n       \n       \n         Writing line terminators \n       \n     \n   \n   \n     Traversing and creating directories \n     \n       \n         Traversing a directory \n       \n       \n         Creating a directory ( ,  ) \n       \n       \n         Ensuring that a parent directory exists \n       \n       \n         Creating a temporary directory \n       \n     \n   \n   \n     Copying, renaming, moving files or directories \n     \n       \n         Copying files or directories \n       \n       \n         Renaming or moving files or directories \n       \n     \n   \n   \n     Removing files or directories \n     \n       \n         Removing files and arbitrary directories (shell:  ,  ) \n       \n       \n         Removing an empty directory (shell:  ) \n       \n       \n         Clearing directories \n       \n       \n         Trashing files or directories \n       \n     \n   \n   \n     Reading and changing file system entries \n     \n       \n         Checking if a file or directory exists \n       \n       \n         Checking the stats of a file: Is it a directory? When was it created? Etc. \n       \n       \n         Changing file attributes: permissions, owner, group, timestamps \n       \n     \n   \n   \n     Working with links \n   \n   \n     Further reading \n   \n Concepts, patterns and conventions of Node’s file system APIs   # Ways of accessing files   # We can read or write the whole content of a file via a string. We can open a stream for reading or a stream for writing and process a file in smaller pieces, one at a time. Streams only allow sequential access. We can use file descriptors or FileHandles and get both sequential and random access, via an API that is loosely similar to streams.\n \n  are integer numbers that represent files. They are managed via these functions (only the synchronous names are shown, there are also callback-based versions –   etc.):\n \n  opens a new file descriptor for a file at a given path and returns it. \n  closes a file descriptor. \n \n \n \n \n \n \n \n \n \n Only the synchronous API and the callback-based API use file descriptors. The Promise-based API has a better abstraction,  class  , which is based on file descriptors. Instances are created via  . Various operations are provided via methods (not via functions):\n \n \n \n \n Etc. \n \n \n \n Note that we don’t use (3) in this blog post – (1) and (2) are enough for our purposes. Function name prefixes   # # Functions whose names start with an “l” usually operate on symbolic links: \n ,  ,  \n ,  ,  \n ,  ,  \n Etc. \n # Functions whose names start with an “f” usually manage file descriptors: \n ,  \n ,  \n ,  \n Etc. \n Important classes   # Several classes play important roles in Node’s file system APIs. # Whenever a Node.js function accepts a file system path in a string (line A), it usually also accepts an instance of   (line B): Manually converting between paths and   URLs seems easy but has surprisingly many pitfalls: percent encoding or decoding, Windows drive letters, etc. Instead, it’s better to use the following two functions: \n \n \n We don’t use file URLs in this blog post. In a future blog post, we’ll see use cases for them. # Class   represents fixed-length byte sequences on Node.js. It is a subclass of   (a  TypedArray ). Buffers are mostly used when working with binary files and therefore of less interest in this blog post. Whenever Node.js accepts a Buffer, it also accepts a Uint8Array. Thus, given that Uint8Arrays are cross-platform and Buffers aren’t, the former is preferable. Buffers can do one thing that Uint8Arrays can’t: encoding and decoding text in various encodings. If we need to encode or decode UTF-8 in Uint8Arrays, we can use class   or class  . These classes are available on most JavaScript platforms: # Some functions accept or return native Node.js streams: \n  is Node’s class for readable streams. Module   uses   which is a subclass. \n  is Node’s class for writable streams. Module   uses   which is a subclass. \n Instead of native streams, we can now use cross-platform   on Node.js.  The blog post “Using web streams on Node.js”  explains how. Reading and writing files   # Reading a file synchronously into a single string (optional: splitting into lines)   #  reads the file at   into a single string: Pros and cons of this approach (vs. using a stream): \n Pro: Easy to use and synchronous. Good enough for many use cases. \n Con: Not a good choice for large files.\n \n Before we can process the data, we have to read it in its entirety. \n \n \n Next, we’ll look into spliting the string we have read into lines. # The following code splits a string into lines while removing line terminators. It works with Unix and Windows line terminators: “EOL” stands for “end of line”. We accept both Unix line terminators ( ) and Windows line terminators ( , like the first one in the previous example). For more information, see  section “Handling line terminators across platforms” . # The following code splits a string into lines while including line terminators. It works with Unix and Windows line terminators (“EOL” stands for “end of line”): Line A contains a regular expression with  a lookbehind assertion . It matches at locations that are preceded by a match for the pattern   but it doesn’t capture anything. Therefore, it doesn’t remove anything between the string fragments that the input string is split into. On engines that don’t support lookbehind assertions ( see this table ), we can use the following solution: This solution is simple, but more verbose. In both versions of  , we again accept both Unix line terminators ( ) and Windows line terminators ( ). For more information, see  section “Handling line terminators across platforms” . Reading a file via a stream, line by line   # We can also read text files via streams: We used the following external functionality: \n  creates a Node.js stream (an instance of  ). \n  converts a readable Node.js stream to a web stream (an instance of  ). \n The TransformStream class   is explained in  the blog post “Using web streams on Node.js” .   are the pieces of data produced by streams. If we have a stream whose chunks are strings with arbitrary lengths and  pipe it through a ChunksToLinesStream, then we get a stream whose chunks are lines. \n Web streams are  asynchronously iterable , which is why we can use a   loop to iterate over lines. If we are not interested in text lines, then we don’t need  , can iterate over   and get chunks with arbitrary lengths. More information: \n Web streams are covered in  the blog post “Using web streams on Node.js” . \n Line terminators are covered in  section “Handling line terminators across platforms” . \n Pros and cons of this approach (vs. reading a single string): \n Pro: Works well with large files.\n \n We can process the data incrementally, in smaller pieces and don’t have to wait for everything to be read. \n \n \n Con: More complicated to use and not synchronous. \n Writing a single string to a file synchronously   #  writes   to a file at  . If a file already exists at that path, it is overwritten. The following code shows how to use this function: For information on line terminators, see  section “Handling line terminators across platforms” . Pros and cons (vs. using a stream): \n Pro: Easy to use and synchronous. Works for many use cases. \n Con: Not suited for large files. \n Appending a single string to a file (synchronously)   # The following code appends a line of text to an existing file: We can also use   to perform this task: This code is almost the same as the one we used to overwrite existing content (see the previous section for more information). The only difference is that we added the option  : The value   means that we append data. Other possible values (e.g. to throw an error if a file doesn’t exist yet) are explained in  the Node.js documentation . Watch out: In some functions, this option is named  , in others  . Writing multiple strings to a file via stream   # The following code uses a stream to write multiple strings to a file: We used the following functions: \n  creates a Node.js stream (an instance of  ). \n  converts a writable Node.js stream to a web stream (an instance of  ). \n More information: \n WritableStreams and Writers are covered in  the blog post “Using web streams on Node.js” . \n Line terminators are covered in  section “Handling line terminators across platforms” . \n Pros and cons (vs. writing a single string): \n Pro: Works well with large files because we can write the data incrementally, in smaller pieces. \n Con: More complicated to use and not synchronous. \n Appending multiple strings to a file via a stream (asynchronously)   # The following code uses a stream to append text to an existing file: This code is almost the same as the one we used to overwrite existing content (see the previous section for more information). The only difference is that we added the option  : The value   means that we append data. Other possible values (e.g. to throw an error if a file doesn’t exist yet) are explained in  the Node.js documentation . Watch out: In some functions, this option is named  , in others  . Handling line terminators across platforms   # Alas, not all platform have the same   characters that mark the   (EOL): \n On Windows, EOL is  . \n On Unix (incl. macOS), EOL is  . \n To handle EOL in a manner that works on all platforms, we can use several strategies. Reading line terminators   # When reading text, it’s best to recognize both EOLs. What might that look like when splitting a text into lines? We can include the EOLs (in either format) at the ends. That enables us to change as little as possible if we modify those lines and write them to a file. When processing lines with EOLs, it’s sometimes useful to remove them – e.g. via the following function: Writing line terminators   # When it comes to writing line terminators, we have two options: \n Constant   in module   contains the EOL of the current platform. \n We can detect the EOL format of an input file and use that when we change that file. \n Traversing and creating directories   # Traversing a directory   # The following function traverses a directory and lists all of its descendants (its children, the children of its children, etc.): We used this functionality: \n  returns the children of the directory at  .\n \n If option   is  , the function returns  , instances of  . These have properties such as:\n \n \n \n \n \n \n \n If option   is   or missing, the function returns strings with file names. \n \n \n The following code shows   in action: Creating a directory ( ,  )   # We can use  the following function  to create directories:  determines how the function creates the directory at  : \n \n If   is missing or  ,   returns   and an exception is thrown if: \n \n A directory (or file) already exists at  . \n The parent directory of   does not exist. \n \n \n \n If   is  : \n \n It’s OK if there is already a directory at  . \n The ancestor directories of   are created as needed. \n  returns the path of the first newly created directory. \n \n \n This is   in action: Function   lists all descendants of the directory at  . Ensuring that a parent directory exists   # If we want to set up a nested file structure on demand, we can’t always be sure that the ancestor directories exist when we create a new file. Then the following function helps: Here we can see   in action (line A): Creating a temporary directory   #  creates a temporary directory: It appends 6 random characters to  , creates a directory at the new path and returns that path.  shouldn’t end with a capital “X” because some platforms replace trailing Xs with random characters. If we want to create our temporary directory inside an operating-system-specific global temporary directory, we can use  function  : It’s important to note that temporary directories are not automatically removed when a Node.js script terminates. We either have to delete it ourselves or rely on the operating system to periodically clean up its global temporary directory (which it may or may not do). Copying, renaming, moving files or directories   # Copying files or directories   # : copies a file or directory from   to  . Interesting options: \n  (default:  ): Directories (including empty ones) are only copied if this option is  . \n  (default:  ): If  , existing files are overwritten. If  , existing files are preserved.\n \n In the latter case, setting   to   leads to errors being thrown if file paths clash. \n \n \n  is a function that lets us control which files are copied. \n  (default:  ): If  , the copies in   get the same timestamps as the originals in  . \n This is the function in action: Function   lists all descendants of the directory at  . Renaming or moving files or directories   #  renames or moves a file or a directory from   to  . Let’s use this function to rename a directory: Here we use the function to move a file: Function   lists all descendants of the directory at  . Removing files or directories   # Removing files and arbitrary directories (shell:  ,  )   #  removes a file or directory at  . Interesting options: \n  (default:  ): Directories (including empty ones) are only removed if this option is  . \n  (default:  ): If  , an exception will be thrown if there is no file or directory at  . \n Let’s use   to remove a file: Here we use   to recursively remove a non-empty directory. Function   lists all descendants of the directory at  . Removing an empty directory (shell:  )   #  removes an empty directory (an exception is thrown if a directory isn’t empty). The following code shows how this function works: Function   lists all descendants of the directory at  . Clearing directories   # A script that saves its output to a directory  , often needs to     before it starts: Remove every file in   so that it is empty. The following function does that. We used two file system functions: \n  returns the names of all children of the directory at  . It is explained in  section “Traversing a directory” . \n  removes files and directories (including non-empty ones). It is explained in  section “Removing files and arbitrary directories” . \n This is an example of using  : Trashing files or directories   # The library   moves files and folders to the trash. It works on macOS, Windows, and Linux (where support is limited and help is wanted). This is an example from its readme file:  accepts either an Array of strings or a string as its first parameter. Any string can be a glob pattern (with asterisks and other meta-characters). Reading and changing file system entries   # Checking if a file or directory exists   #  returns   if a file or directory exists at  : Function   lists all descendants of the directory at  . Checking the stats of a file: Is it a directory? When was it created? Etc.   #  returns an instance of   with information on the file or directory at  . Interesting  : \n  (default:  ): What happens if there is no entity at  ?\n \n If this option is  , an exception is thrown. \n If it is  ,   is returned. \n \n \n  (default:  ): If  , this function uses bigints for numeric values (such as timestamps, see below). \n Properties of instances of  : \n What kind of file system entry is it?\n \n \n \n \n \n \n  is the size in bytes \n Timestamps:\n \n There are three kinds of timestamps:\n \n : time of last access \n : time of last modification \n : time of creation \n \n \n Each of these timestamps can be specified with three different units – for example,  :\n \n : instance of  \n : milliseconds since the POSIX Epoch \n : nanoseconds since the POSIX Epoch (requires option  ) \n \n \n \n \n In the following example, we use   to implement a function  : Function   lists all descendants of the directory at  . Changing file attributes: permissions, owner, group, timestamps   # Let’s briefly look at functions for changing file attributes: \n  changes the permission of a file. \n  changes the owner and group of a file. \n  changes the timestamps of a file:\n \n : time of last access \n : time of last modification \n \n \n Working with links   # Functions for working with hard links: \n  create a hard link. \n  removes a hard link and possibly the file it points to (if it is the last hard link to that file). \n Functions for working with symbolic links: \n  creates a symbolic link from   to  . \n  returns the target of the symbolic link at  . \n The following functions operate on symbolic links without dereferencing them (note the name prefix “l”): \n  changes the permissions of the symbolic link at  . \n  changes user and group of the symbolic link at  . \n  changes the timestamps of the symbolic link at  . \n  returns the stats (timestamps etc.) of the symbolic link at  . \n Other useful functions: \n  computes the canonical pathname by resolving dots ( ), double dots ( ), and symbolic links. \n Options of functions that affect how symbolic links are handled: \n :\n \n  (default:  ): If  , copy the files that symbolic links points to, not the symbolic links themselves. \n  (default:  ): If  , the target of a copied symbolic link will be updated so that it still points to the same location. If  , the target won’t be changed. \n \n \n Further reading   # \n Blog post “Using web streams on Node.js” \n “JavaScript for impatient programmers” has several chapters on writing asynchronous code:\n \n “Foundations of asynchronous programming in JavaScript” \n “Promises for asynchronous programming” \n “Async functions” \n “Asynchronous iteration” \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/07/nodejs-child-process.html", "title": "Executing shell commands from Node.js", "content": "Executing shell commands from Node.js dev javascript nodejs chapter “Running shell commands in child processes” In this blog post, we’ll explore how we can execute shell commands from Node.js, via module  . \n   \n     Overview of this blog post \n     \n       \n         Windows vs. Unix \n       \n       \n         Functionality we often use in the examples \n       \n     \n   \n   \n     Spawning processes asynchronously:  \n     \n       \n         How   works \n       \n       \n         When is the shell command executed? \n       \n       \n         Command-only mode vs. args mode \n       \n       \n         Sending data to the stdin of the child process \n       \n       \n         Piping manually \n       \n       \n         Handling unsuccessful exits (including errors) \n       \n       \n         Waiting for the exit of a child process \n       \n       \n         Terminating child processes \n       \n     \n   \n   \n     Spawning processes synchronously:  \n     \n       \n         When is the shell command executed? \n       \n       \n         Reading from stdout \n       \n       \n         Sending data to the stdin of the child process \n       \n       \n         Handling unsuccessful exits (including errors) \n       \n     \n   \n   \n     Asynchronous helper functions based on  \n     \n       \n         \n       \n       \n         \n       \n     \n   \n   \n     Synchronous helper functions based on  \n     \n       \n         \n       \n       \n         \n       \n     \n   \n   \n     Useful libraries \n     \n       \n         tinysh: a helper for spawning shell commands \n       \n       \n         node-powershell: executing Windows PowerShell commands via Node.js \n       \n     \n   \n   \n     How to choose between the functions of module  \n   \n Overview of this blog post   # Module   has a function for executing shell commands (in   child processes) that comes in two versions: \n An asynchronous version  . \n A synchronous version  . \n We’ll first explore   and then  . We’ll conclude by looking at the following functions that are based on them and relatively similar: \n Based on  :\n \n \n \n \n \n Based on  :\n \n \n \n \n \n Windows vs. Unix   # The code shown in this blog post runs on Unix, but I have also tested it on Windows – where most of it works with minor changes (such as ending lines with   instead of  ). Functionality we often use in the examples   # The following functionality shows up often in the examples. That’s why it’s explained here, once: \n \n Assertions:   for primitive values and   for objects. The necessary import is never shown in the examples: \n \n \n \n Function   converts Node’s native   to a web stream (an instance of  ). It is explained in  the blog post on web streams .   is always imported in the examples. \n \n \n The asynchronous function   consumes a readable web stream and returns a string (wrapped in a Promise). It is explained in  the blog post on web streams . This function is assumed to be available in the examples. \n \n Spawning processes asynchronously:     # How   works   #  asynchronously executes a command in a new process: The process runs concurrently to Node’s main JavaScript process and we can communicate with it in various ways (often via streams). Next, there is documentation for the parameters and the result of  . If you prefer to learn by example, you can skip that content and continue with the subsections that follow. #  is a string with the shell command. There are two modes of using this parameter: \n Command-only mode:   is omitted and   contains the whole shell command. We can even use shell features such as piping between multiple executables, redirecting I/O into files, variables, and wildcards.\n \n  must be   because we need an shell to handle the shell features. \n \n \n Args mode:   contains only the name of the command and   contains its arguments.\n \n If   is  , many meta-characters inside arguments are interpreted and features such as wildcards and variable names work. \n If   is  , strings are used verbatim and we never have to escape meta-characters. \n \n \n Both modes are demonstrated  later in this post . # The following   are most interesting: \n  (default:  ) \nShould a shell be used to execute the command?\n \n On Windows, this option should almost always be  . For example,   and   files cannot be executed otherwise. \n On Unix, only core shell features (e.g. piping, I/O redirection, filename wildcards, and variables) are not available if   is  . \n If   is  , we have to be careful with user input and sanitize it because it’s easy to execute arbitrary code. We also have to escape meta-characters if we want to use them as non-meta-characters. \n We can also set   to the path of a shell executable. Then Node.js uses that executable to execute the command. If we set   to  , Node.js uses:\n \n Unix:  \n Windows:  \n \n \n \n \n \nSpecifies the   (CWD) to use while executing the command. \n \nConfigures how standard I/O is set up. This is explained below. \n  (default:  ) \nLets us specify shell variables for the child process. Tips:\n \n Look at   (e.g. in the Node.js REPL) to see what variables exist. \n We can use spreading to non-destructively override an existing variable – or create it if it doesn’t exist yet: \n \n \n \n \nIf we create an AbortController  , we can pass   to   and abort the child process via  . That is demonstrated  later in this post . \n \nIf the child process takes longer than   milliseconds, it is killed. \n # Each of the standard I/O streams of the child process has a numeric ID, a so-called  : \n Standard input (stdin) has the file descriptor 0. \n Standard output (stdout) has the file descriptor 1. \n Standard error (stderr) has the file descriptor 2. \n There can be more file descriptors, but that’s rare.  configures if and how the streams of the child process are piped to streams in the parent process. It can be an Array where each element configures the file descriptor that is equal to its index. The following values can be used as Array elements: \n \n : \n \n Index 0: Pipe   to the child’s stdin. Note that, despite its name, the former is a stream that belongs to the parent process. \n Index 1: Pipe the child’s stdout to  . \n Index 2: Pipe the child’s stderr to  . \n \n \n \n : Ignore the child’s stream. \n \n \n : Pipe the child’s stream to the corresponding stream of the parent process. \n \n For example, if we want the child’s stderr to be logged to the console, we can use   at index 2. \n \n \n \n Native Node.js stream: Pipe to or from that stream. \n \n \n Other values are supported, too, but that’s beyond the scope of this post. \n \n Instead of specifying   via an Array, we can also abbreviate: \n  is equivalent to   (the default for  ). \n  is equivalent to  . \n  is equivalent to  . \n #  returns instances of  . Interesting data properties: \n \nContains the code with which the child process exited:\n \n 0 (zero) means normal exit. \n A number greater than zero means an error happened. \n  means the process hasn’t exited yet. \n \n \n \nThe POSIX signal with which a child process was killed or   if it wasn’t. See the description of method   below for more information. \n Streams: Depending on how standard I/O is configured (see previous subsection), the following streams become available:\n \n \n \n \n \n \n \nThe   (PID) of the child process. If spawning fails,   is  . This value is available immediately after calling  . \n Interesting methods: \n \n \nSends a POSIX signal to the child process (which usually results in the termination of the process): \n \n The man page for   contains a list of values. \n Windows does not support signals, but Node.js emulates some of them – e.g.:  ,  , and  . For more information, see  the Node.js documentation . \n \n This method is demonstrated  later in this post . \n \n Interesting events: \n   \nThis event is emitted after the child process ends:\n \n The callback parameters provide us with either the exit code or the signal code: One of them will always be non-null. \n Some of its standard I/O streams might still be open because multiple processes might share the same streams. Event   notifies us when all stdio streams are closed after the exit of a child process. \n \n \n   \nThis event is most commonly emitted if a process could not be spawned (see  example  later) or the child process could not be killed. An   event may or may not be emitted after this event. \n We’ll see later  how events can be turned into Promises that can be awaited . When is the shell command executed?   # When using the asynchronous  , the child process for the command is started asynchronously. The following code demonstrates that: This is the output: Command-only mode vs. args mode   # In this section, we specify the same command invocation in two ways: \n Command-only mode: We provide the whole invocation via the first parameter  . \n Args mode: We provide the command via the first parameter   and its arguments via the second parameter  . \n # Each command-only spawning with arguments requires   to be   (line A) – even if it’s as simple as this one. In line B, we tell   how to handle standard I/O: \n Ignore standard input. \n Pipe the child process stdout to   (a stream that belongs to the parent process). \n Pipe child process stderr to parent process stderr. \n In this case, we are only interested in the output of the child process. Therefore, we are done once we have processed the output. In other cases, we might have to wait until the child exits. How to do that, is demonstrated later. In command-only mode, we see more pecularities of shells – for example, the Windows Command shell output includes double quotes (last line). # # Let’s explore what happens if there are meta-characters in  : \n If we don’t use a shell, meta-characters such as the dollar sign ( ) have no effect (line A). \n With a shell,   is interpreted as a variable (line B). \n If we don’t want that, we have to escape the dollar sign via a backslash (line C). \n Similar effects occur with other meta-characters such as asterisks ( ). These were two examples of Unix shell meta-characters. Windows shells have their own meta-characters and their own ways of escaping. # Let’s use more shell features (which requires command-only mode): Sending data to the stdin of the child process   # So far, we have only read the standard output of a child process. But we can also send data to standard input: We use the shell command   (line A) to sort lines of text for us. In line B, we use   to convert a native Node.js stream to a web stream (see  the blog post on web streams for more information ). How to write to a WritableStream via a writer (line C) is also explained in  the blog post on web streams . Piping manually   # We previously let a shell execute the following command: In the following example, we do the piping manually, from the echoes (line A) to the sorting (line B): ReadableStreams such as   are asynchronously iterable. That’s why we can use a   loop to read their   (the fragments of the streamed data). For more information, see  the blog post on web streams . Handling unsuccessful exits (including errors)   # There are three main kinds of unsuccessful exits: \n The child process can’t be spawned. \n An error happens in the shell. \n A process is killed. \n # The following code demonstrates what happens if a child process can’t be spawned. In this case, the cause is that the shell’s path doesn’t point to an executable (line A). This is the first time that we use events to work with child processes. In line B, we register an event listener for the   event. The child process starts after the current code fragment is finished. That helps prevent race conditions: When we start listening we can be sure that the event hasn’t been emitted yet. # If the shell code contains an error, we don’t get an   event (line B), we get an   event with a non-zero exit code (line A): # If a process is killed on Unix, the exit code is   (line C) and the signal code is a string (line D): Note that there is no error output (line E). Instead of the child process killing itself (line A), we could have also paused it for a longer time and killed it manually via the process ID that we logged in line B. What happens if we kill a child process on Windows? \n  is  . \n  is  . \n Waiting for the exit of a child process   # Sometimes we only want to wait until a command is finished. That can be achieved via events and via Promises. # We are using the standard Node.js event pattern and register a listener for the   event (line A). # The helper function   that we use in line A, returns a Promise that is fulfilled if an   event is emitted: If   fails, the returned Promise is rejected and   throws an exception in line A.   handles two kinds of failures: \n \n  isn’t zero (line B). That happens: \n \n If there is a shell error. Then   is greater than zero. \n If the child process is killed on Unix. Then   is   and   is non-null.\n \n Killing child process on Windows produces a shell error. \n \n \n \n \n \n An   event is emitted (line C). That happens if the child process can’t be spawned. \n \n Terminating child processes   # # In this example, we use an AbortController to terminate a shell command: We create an AbortController (line A), pass its signal to   (line B), and terminate the shell command via the AbortController (line C). The child process starts asynchronously (after the current code fragment is executed). That’s why we can abort before the process has even started and why we don’t see any output in this case. # In the next example, we terminate a child process via the method   (last line): Once again, we kill the child process before it has started (asynchronously!) and there is no output. Spawning processes synchronously:     #  is the synchronous version of   – it waits until the child process exits before it synchronously(!) returns an object. The parameters are mostly the same as  those of  .   has a few additional properties – e.g.: \n \nIf this property exists, its value is sent to the standard input of the child process. \n  (default:  ) \nSpecifies the encoding that is used for all standard I/O streams. \n The function returns an object. Its most interesting properties are: \n \nContains whatever was written to the standard output stream of the child process. \n \nContains whatever was written to the standard error stream of the child process. \n \nContains the exit code of the child process or  . Either the exit code or the signal code are non-null. \n \nContains the signal code of the child process or  . Either the exit code or the signal code are non-null. \n \nThis property is only created if spawning didn’t work and then contains an Error object. \n With the asynchronous  , the child process ran concurrently and we could read standard I/O via streams. In contrast, the synchronous   collects the contents of the streams and returns them to us synchronously (see next subsection). When is the shell command executed?   # When using the synchronous  , the child process for the command is started synchronously. The following code demonstrates that: This is the output: Reading from stdout   # The following code demonstrates how to read standard output: In line A, we use   to tell   that we are only interested in standard output. We ignore standard input and pipe standard error to the parent process. As a consequence, we only get a result property for standard output (line C) and the property for standard error is   (line D). Since we can’t access the streams that   uses internally to handle the standard I/O of the child process, we tell it which encoding to use, via   (line B). Sending data to the stdin of the child process   # We can send data to the standard input stream of a child process via the options property   (line A): Handling unsuccessful exits (including errors)   # There are three main kinds of unsuccessful exits (when the exit code isn’t zero): \n The child process can’t be spawned. \n An error happens in the shell. \n A process is killed. \n # If spawning fails,   emits an   event. In contrast,   sets   to an error object: # If an error happens in the shell, the exit code   is greater than zero and   is  : # If the child process is killed on Unix,   contains the name of the signal and   is  : Note that no output was sent to the standard error stream (line A). If we kill a child process on Windows: \n  is 1 \n  is  \n  is  \n Asynchronous helper functions based on     # In this section, we look at two asynchronous functions in module   that are based on  : \n \n \n We ignore   in this blog post. Quoting  the Node.js documentation :  spawns a new Node.js process and invokes a specified module with an IPC communication channel established that allows sending messages between parent and child.    #  runs a command in a newly spawned shell. The main differences with   are: \n In addition to returning a ChildProcess,   also delivers a result via a callback: Either an error object or the contents of stdout and stderr. \n Causes of errors: child process can’t be spawned, shell error, child process killed.\n \n In contrast,   only emits   events if the child process can’t be spawned. The other two failures are handled via exit codes and (on Unix) signal codes. \n \n \n There is no parameter  . \n The default for   is  . \n  can be converted to a Promise-based function via  : \n The ChildProcess becomes a property of the returned Promise. \n The Promise is settled as follows:\n \n Fulfillment value:    \n Rejection value: same value as parameter   of the callback but with two additional properties:   and  . \n \n \n    # Works similarly to  , with the following differences: \n The parameter   is supported. \n The default for   is  . \n Like  ,   can be converted to a Promise-based function via  . Synchronous helper functions based on     #    #  runs a command in a new child process and waits synchronously until that process exits. The main differences with   are: \n Only returns the contents of stdout. \n Three kinds of failures are reported via exceptions: child process can’t be spawned, shell error, child process killed.\n \n In contrast, the result of   only has an   property if the child process can’t be spawned. The other two failures are handled via exit codes and (on Unix) signal codes. \n \n \n There is no parameter  . \n The default for   is  . \n    # Works similarly to  , with the following differences: \n The parameter   is supported. \n The default for   is  . \n Useful libraries   # tinysh: a helper for spawning shell commands   # tinysh  by Anton Medvedev is a small library that helps with spawning shell commands – e.g.: We can override the default options by using   to pass an object as  : We can use any property name and tinysh executes the shell command with that name. It achieves that feat via  a Proxy . This is a slightly modified version of the actual library: In line A, we can see that if we get a property whose name is   from  , a function is returned that invokes   and uses   as the first argument. Spreading   in line B enables us to specify options via  . The defaults come first, so that they can be overridden via  . node-powershell: executing Windows PowerShell commands via Node.js   # Using  the library node-powershell  on Windows, looks as follows: How to choose between the functions of module     # General constraints: \n Should other asynchronous tasks run while the command is executed?\n \n Use any asynchronous function. \n \n \n Do you only execute one command at a time (without async tasks in the background)?\n \n Use any synchronous function. \n \n \n Do you want to access stdin or stdout of the child process via a stream?\n \n Only asynchronous functions give you access to streams:   is simpler in this case because it doesn’t have a callback that delivers errors and standard I/O content. \n \n \n Do you want to capture stdout or stderr in a string?\n \n Asynchronous options:   and  \n Synchronous options:  ,  ,  \n \n \n Asynchronous functions – choosing between   and   or  : \n  and   have two benefits:\n \n Failures are easier to handle because they are all reported in the same manner – via the first callback parameter. \n Getting stdout and stderr as strings is easier - due to the callback. \n \n \n You can pick   if those benefits don’t matter to you. Its signature is simpler without the (optional) callback. \n Synchronous functions – choosing between   and   or  : \n  and   have two specialties:\n \n They return a string with the content of stdout. \n Failures are easier to handle because they are all reported in the same manner – via exceptions. \n \n \n Pick   if you need more information than   and   provide via their return values and exceptions. \n Choosing between   and   (the same arguments apply to choosing between   and  ): \n The default for   is   in   but   in  . \n  supports  ,   doesn’t. \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/06/web-streams-nodejs.html", "title": "Using web streams on Node.js", "content": "Using web streams on Node.js dev javascript nodejs chapter “Using web streams on Node.js”  are a standard for   that is now supported on all major web platforms: web browsers, Node.js, and Deno. (Streams are an abstraction for reading and writing data sequentially in small pieces from all kinds of sources – files, data hosted on servers, etc.) For example,  the global function   (which downloads online resources) asynchronously returns a Response which has a property   with a web stream. This blog post covers web streams on Node.js, but most of what we learn applies to all web platforms that support them. \n   \n     What are web streams? \n     \n       \n         Kinds of streams \n       \n       \n         Pipe chains \n       \n       \n         Backpressure \n       \n       \n         Support for web streams in Node.js \n       \n     \n   \n   \n     Reading from ReadableStreams \n     \n       \n         Consuming ReadableStreams via Readers \n       \n       \n         Consuming ReadableStreams via asynchronous iteration \n       \n       \n         Creating pipe chains \n       \n     \n   \n   \n     Turning data sources into ReadableStreams via wrapping \n     \n       \n         A first example of implementing an underlying source \n       \n       \n         Using a ReadableStream to wrap a push source or a pull source \n       \n     \n   \n   \n     Writing to WritableStreams \n     \n       \n         Writing to WritableStreams via Writers \n       \n       \n         Piping to WritableStreams \n       \n     \n   \n   \n     Turning data sinks into WritableStreams via wrapping \n     \n       \n         Example: tracing a ReadableStream \n       \n       \n         Example: collecting written chunks in a string \n       \n     \n   \n   \n     Using TransformStreams \n     \n       \n         Standard TransformStreams \n       \n     \n   \n   \n     Implementing custom TransformStreams \n     \n       \n         Example: transforming a stream of arbitrary chunks to a stream of lines \n       \n       \n         Tip: async generators are also great for transforming streams \n       \n     \n   \n   \n     A closer look at backpressure \n     \n       \n         Signalling backpressure \n       \n       \n         Reacting to backpressure \n       \n     \n   \n   \n     Byte streams \n     \n       \n         Readable byte streams \n       \n       \n         Example: an infinite readable byte stream filled with random data \n       \n       \n         Example: compressing a readable byte stream \n       \n       \n         Example: reading a web page via  \n       \n     \n   \n   \n     Node.js-specific helpers \n   \n   \n     Further reading \n   \n What are web streams?   # Let’s start with an overview of a few fundamentals of web streams. Afterwards, we’ll quickly move on to examples. Streams are a data structure for accessing data such as: \n Files \n Data hosted on web servers \n Etc. \n Two of their benefits are: \n \n We can work with large amounts of data because streams allow us to split them up into smaller pieces (so-called  ) which we can process one at a time. \n \n \n We can work with the same data structure, streams, while processing different data. That makes it easier to reuse code. \n \n  (“web” is often omitted) are a relatively new standard that originated in web browsers but is now also supported by Node.js and Deno (as shown in this  MDN compatibility table ). In web streams, chunks are usually either: \n Text streams: Strings \n Binary streams: Uint8Arrays ( a kind of TypedArray ) \n Kinds of streams   # There are three main kinds of web streams: \n \n A ReadableStream is used to read data from a  . Code that does that is called a  . \n \n \n A WritableStream is used to write data to a  . Code that does that is called a  . \n \n \n A TransformStream consists of two streams: \n \n It receives input from its  , a WritableStream. \n It sends output to its  , a ReadableStream. \n \n The idea is to transform data by “piping it through” a TransformStream. That is, we write data to the writable side and read transformed data from the readable side. The following TransformStreams are built into most JavaScript platforms (more on them later): \n \n Because JavaScript strings are UTF-16 encoded, UTF-8 encoded data is treated as binary in JavaScript. A   converts such data to strings. \n A   converts JavaScript strings to UTF-8 data. \n A ``CompressionStream` compresses binary data to GZIP and other compression formats. \n A   decompresses binary data from GZIP and other compression formats. \n \n \n ReadableStreams, WritableStreams and TransformStreams can be used to transport text or binary data. We’ll mostly do the former in this post.   for binary data are briefly mentioned at the end. Pipe chains   #  is an operation that lets us   a ReadableStream to a WritableStream: As long as the ReadableStream produces data, this operation reads that data and writes it to the WritableStream. If we connect just two streams, we get a convenient way of transferring data from one location to another (e.g. to copy a file). However, we can also connect more than two streams and get   that can process data in a variety of ways. This is an example of a pipe chain: \n It starts with a ReadableStream. \n Next are one or more TransformStreams. \n The chain ends with a WritableStream. \n A ReadableStream is connected to a TransformStream by piping the former to the writable side of the latter. Similarly, a TransformStream is connected to another TransformStream by piping the readable side of the former to the writable side of the latter. And a TransformStream is connected to a WritableStream by piping the readable side of the former to the latter. Backpressure   # One problem in pipe chains is that a member may receive more data than it can handle at the moment.   is a technique for solving this problem: It enables a receiver of data to tell its sender that it should temporarily stop sending data so that the receiver doesn’t get overwhelmed. Another way to look at backpressure is as a signal that travels backwards through a pipe chain, from a member that is getting overwhelmed to the beginning of the chain. As an example, consider the following pipe chain: This is how backpressure travels through this chain: \n Initially, the WriteableStream signals that it can’t process more data at the moment. \n The pipe stops reading from the TransformStream. \n Input accumulates inside the TransformStream (which is buffered). \n The TransformStream signals that it’s full. \n The pipe stops reading from the ReadableStream. \n We have reached the beginning of the pipe chain. Therefore, no data accumulates inside the ReadableStream (which is also buffered) and the WriteableStream has time to recover. Once it does, it signals that it is ready to receive data again. That signal also travels back through the chain until it reaches the ReadableStream and data processing resumes. In this first look at backpressure, several details were omitted to make things easier to understand. These will be covered later. Support for web streams in Node.js   # In Node.js, web streams are available from two sources: \n From  module  \n Via global variables (like in web browsers) \n At the moment, only one API has direct support for web streams in Node.js –  the Fetch API : For other things, we need to use one of the following static methods in module   to either convert a Node.js stream to a web stream or vice versa: \n Node.js Readables can be converted to and from WritableStreams:\n \n \n \n \n \n Node.js Writables can be converted to and from ReadableStreams:\n \n \n \n \n \n Node.js Duplexes can be converted to and from TransformStreams:\n \n \n \n \n \n One other API partially supports web streams: FileHandles have the method  . Reading from ReadableStreams   # ReadableStreams let us read chunks of data from various sources. They have the following type (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): Explanations of these properties: \n  returns a Reader – an object through which we can read from a ReadableStream. ReadableStreams returning Readers is similar to  iterables  returning iterators. \n : There can only be one active Reader per ReadableStream at a time. While one Reader is in use, the ReadableStream is locked and   cannot be invoked. \n : This method makes ReadableStreams  asynchronously iterable . It is currently only implemented on some platforms. \n  cancels the stream because the consumer isn’t interested in it anymore.   is passed on to the   method of the ReadableStream’s   (more on that later). The returned Promise fulfills when this operation is done. \n  feeds the contents of its ReadableStream to a WritableStream. The returned Promise fulfills when this operation is done.   ensures that backpressure, closing, errors, etc. are all correctly propagated through a pipe chain. We can specify options via its second parameter:\n \n  lets us pass an AbortSignal to this method, which enables us to abort piping via an AbortController. \n : If  , it prevents the WritableStream from being closed when the ReadableStream is closed. That is useful when we want to pipe more than one ReadableStream to the same WritableStream. \n The remaining options are beyond the scope of this blog post. They are documented  in the web streams specification . \n \n \n  connects its ReadableStream to a ReadableWritablePair (roughly: a TransformStream, more on that later). It returns the resulting ReadableStream (i.e., the readable side of the ReadableWritablePair). \n The following subsections cover two ways of consuming ReadableStreams: \n Reading via Readers \n Reading via asynchronous iteration \n Consuming ReadableStreams via Readers   # We can use   to read data from ReadableStreams. They have the following type (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): Explanations of these properties: \n : This Promise is fulfilled after the stream is closed. It is rejected if the stream errors or if a Reader’s lock is released before the stream is closed. \n : In an active Reader, this method cancels the associated ReadableStream. \n  deactivates the Reader and unlocks its stream. \n  returns a Promise for a ReadableStreamReadResult (a wrapped chunk) which has two properties:\n \n  is a boolean that is   as long as chunks can be read and   after the last chunk. \n  is the chunk (or   after the last chunk). \n \n \n ReadableStreamReadResult may look familiar if you know how iteration works: ReadableStreams are similar to iterables, Readers are similar to iterators, and ReadableStreamReadResults are similar to the objects returned by the iterator method  . The following code demonstrates the protocol for using Readers:  We can’t read directly from  , we first need to acquire a   (line A). Each ReadableStream can have at most one Reader. After a Reader was acquired,   is locked (line B). Before we can call   again, we must call   (line D).    returns a Promise for an object with the properties   and   (line C). After the last chunk was read,   is  . This approach is similar to how  asynchronous iteration  works in JavaScript. # In the following example, we read chunks (strings) from a text file  : We are converting a Node.js Readable to a web ReadableStream (line A). Then we use the previously explained protocol to read the chunks. # In the next example, we concatenate all chunks of a ReadableStream into a string and return it: Conveniently, the   clause is always executed – now matter how we leave the   clause. That is, the lock is correctly released (line B) if we return a result (line A). Consuming ReadableStreams via asynchronous iteration   # ReadableStreams can also be consumed via  asynchronous iteration : Thankfully, the   loop handles all the details of asynchronous iteration for us: # Let’s redo our previous attempt to read text from a file. This time, we use asynchronous iteration instead of a Reader: # At the moment, Node.js and Deno support asynchronous iteration over ReadableStreams but web browsers don’t: There is  a GitHub issue  that links to bug reports. Given that it’s not yet completely clear how async iteration will be supported on browsers, wrapping is a safer choice than polyfilling. The following code is based on  a suggestion in the Chromium bug report : Creating pipe chains   # ReadableStreams have two methods for creating pipe chains: \n \n  synchronously returns a Promise  . It asynchronously reads all chunks of   and writes them to  . When it is done, it fulfills  . \n We’ll see examples of   when we explore WritableStreams, as it provides a convenient way to transfer data into them. \n \n \n  pipes   into   and returns   (every TransformStream has these properties that refer to its writable side and its readable side). Another way to view this operation is that we create a new ReadableStream by connecting a   to a  . \n We’ll see examples of   when we explore TransformStreams, as this method is the main way in which they are used. \n \n Turning data sources into ReadableStreams via wrapping   # If we want to read an external source via a ReadableStream, we can wrap it in an adapter object and pass that object to the   constructor. The adapter object is called the   of the ReadableStream (queuing strategies are explained later, when we take a closer look at backpressure): This is the type of underlying sources (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): This is when the ReadableStream calls these methods: \n \n  is called immediately after we invoke the constructor of  . \n \n \n  is called whenever there is room in the internal queue of the ReadableStream. It is called repeatedly until the queue is full again. This method will only be called after   is finished. If   doesn’t enqueue anything, it won’t be called again. \n \n \n  is called if the consumer of a ReadableStream cancels it via   or  .   is the value that was passed to these methods. \n \n Each of these methods can return a Promise and no further steps will be taken until the Promise is settled. That is useful if we want to do something asynchronous. The parameter   of   and   lets them access the stream. It has the following type: For now, chunks are strings. We’ll later get to byte streams, where Uint8Arrays are common. This is what the methods do: \n  adds   to the ReadableStream’s internal queue. \n  indicates how much room there is in the queue into which   writes. It is zero if the queue is full and negative if it has exceeded its maximum size. Therefore, if the desired size is zero or negative, we have to stop enqueuing.\n \n If a stream is closed, its desired size is zero. \n If a stream is in error mode, its desired size is  . \n \n \n  closes the ReadableStream. Consumers will still be able to empty the queue, but after that, the stream ends. It’s important that an underlying source calls this method – otherwise, reading its stream will never finish. \n  puts the stream in an error mode: All future interactions with it will fail with the error value  . \n A first example of implementing an underlying source   # In our first example of implementing an underlying source, we only provide method  . We’ll see use cases for   in the next subsection. We use the controller to create a stream with two chunks (line A and line B). It’s important that we close the stream (line C). Otherwise, the   loop would never finish! Note that this way of enqueuing isn’t completely safe: There is a risk of exceding the capacity of the internal queue. We’ll see soon how we can avoid that risk. Using a ReadableStream to wrap a push source or a pull source   # A common scenario is turning a push source or a pull source into a ReadableStream. The source being push or pull determines how we will hook into the ReadableStream with our UnderlyingSource: \n \n Push source: Such a source notifies us when there is new data. We use   to set up listeners and supporting data structures. If we receive too much data and the desired size isn’t positive anymore, we must tell our source to pause. If   is called later, we can unpause it. Pausing an external source in reaction to the desired size becoming non-positive is called  . \n \n \n Pull source: We ask such a source for new data – often asynchronously. Therefore, we usually don’t do much in   and retrieve data whenever   is called. \n \n We’ll see examples for both kinds of sources next. # In the following example, we wrap a ReadableStream around a socket – which pushes its data to us (it calls us).  This example  is taken from the web stream specification: # The tool function   takes an iterable over chunks and turns it into a ReadableStream: Let’s use an async generator function to create an asynchronous iterable and turn that iterable into a ReadableStream:  also works with synchronous iterables: There may eventually by a static helper method   that provides this functionality ( see its pull request for more information ). Writing to WritableStreams   # WritableStreams let us write chunks of data to various sinks. They have the following type (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): Explanations of these properties: \n  returns a Writer – an object through which we can write to a WritableStream. \n : There can only be one active Writer per WritableStream at a time. While one Writer is in use, the WritableStream is locked and   cannot be invoked. \n  closes the stream:\n \n The   (more on that later) will still receive all queued chunks before it’s closed. \n From now on, all attempts to write will fail silently (without errors). \n The method returns a Promise that will be fulfilled if the sink succeeds in writing all queued chunks and closing. It will be rejected if any errors occur during these steps. \n \n \n  aborts the stream:\n \n It puts the stream in error mode. \n The returned Promise fulfills if the sink shuts down successfully and rejects if errors occur. \n \n \n The following subsections cover two approaches to sending data to WritableStreams: \n Writing to WritableStreams via Writers \n Piping to WritableStreams \n Writing to WritableStreams via Writers   # We can use   to write to WritableStreams. They have the following type (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): Explanations of these properties: \n \n  indicates how much room there is in this WriteStream’s queue. It is zero if the queue is full and negative if it has exceeded its maximum size. Therefore, if the desired size is zero or negative, we have to stop writing. \n \n If a stream is closed, its desired size is zero. \n If a stream is in error mode, its desired size is  . \n \n \n \n  returns a Promise that is fulfilled when the desired size changes from non-positive to positive. That means that no backpressure is active and it’s OK to write data. If the desired size later changes back to non-positive, a new pending Promise is created and returned. \n \n \n  writes a chunk to the stream. It returns a Promise that is fulfilled after writing succeeds and rejected if there is an error. \n \n \n  releases the Writer’s lock on its stream. \n \n \n  has the same effect as closing the Writer’s stream. \n \n \n  returns a Promise that is fulfilled when the stream is closed. \n \n \n  has the same effect as aborting the Writer’s stream. \n \n The following code shows the protocol for using Writers: We can’t write directly to a  , we first need to acquire a   (line A). Each WritableStream can have at most one Writer. After a Writer was acquired,   is locked (line B). Before we can call   again, we must call   (line C). There are three approaches to writing chunks. # The first writing approach is to await each result of  : The Promise returned by   fulfills when the chunk that we passed to it, was successfully written. What exactly “successfully written” means, depends on how a WritableStream is implemented – e.g., with a file stream, the chunk may have been sent to the operating system but still reside in a cache and therefore not have actually been written to disk. The Promise returned by   is fulfilled when the stream becomes closed. A downside of this writing approach is that waiting until writing succeeds means that the queue isn’t used. As a consequence, data throughput may be lower. # In the second writing approach, we ignore the Promises returned by   and only await the Promise returned by  : The synchronous invocations of   add chunks to the internal queue of the WritableStream. By not awaiting the returned Promises, we don’t wait until each chunk is written. However, awaiting   ensures that the queue is empty and all writing succeeded before we continue. Invoking   in line A and line B is necessary to avoid warnings about unhandled Promise rejections when something goes wrong during writing. Such warnings are often logged to the console. We can afford to ignore the errors reported by   because   will also report them to us. The previous code can be improved by using a helper function that ignores Promise rejections: One downside of this approach is that backpressure is ignored: We simply assume that the queue is big enough to hold everything we write. # In this writing approach, we handle backpressure efficiently by awaiting the Writer getter  : The Promise in   fulfills whenever the stream transitions from having backpressure to not having backpressure. # In this example, we create a text file   via a WritableStream: In line A, we create a Node.js stream for the file  . In line B, we convert this stream to a web stream. Then we use a Writer to write strings to it. Piping to WritableStreams   # Instead of using Writers, we can also write to WritableStreams by piping ReadableStreams to them: The Promise returned by   fulfills when piping finishes successfully. # Piping is performed after the current task completes or pauses. The following code demonstrates that: In line A we create a ReadableStream. In line B we create a WritableStream. We can see that   (line C) returns immediately. In a new task, chunks are read and written. Then   is closed and, finally,   is fulfilled. # In the following example, we create a WritableStream for a file and pipe a ReadableStream to it: In line A, we create a ReadableStream. In line B, we create a Node.js stream for the file  . In line C, we convert this stream to a web stream. In line D, we pipe our   to the WritableStream for the file. # In the following example, we write two ReadableStreams to a single WritableStream. We tell   to not close the WritableStream after the ReadableStream is closed (line A and line B). Therefore, the WritableStream remains open after line A and we can pipe another ReadableStream to it. Turning data sinks into WritableStreams via wrapping   # If we want to write to an external sink via a WritableStream, we can wrap it in an adapter object and pass that object to the   constructor. The adapter object is called the   of the WritableStream (queuing strategies are explained later, when we take a closer look at backpressure): This is the type of underlying sinks (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): Explanations of these properties: \n \n  is called immediately after we invoke the constructor of  . If we do something asynchronous, we can return a Promise. In this method, we can prepare for writing. \n \n \n  is called when a new chunk is ready to be written to the external sink. We can exert backpressure by returning a Promise that fulfills once the backpressure is gone. \n \n \n  is called after   was called and all queued writes succeeded. In this method, we can clean up after writing. \n \n \n  is called if   or   were invoked.   is the value passed to these methods. \n \n The parameter   of   and   lets them error the WritableStream. It has the following type: \n  is an AbortSignal that we can listen to if we want to abort a write or close operation when the stream is aborted. \n  errors the WritableStream: It is closed and all future interactions with it fail with the error value  . \n Example: tracing a ReadableStream   # In the next example, we pipe a ReadableStream to a WritableStream in order to check how the ReadableStream produces chunks: Example: collecting written chunks in a string   # In the next example, we create a subclass of   that collects all written chunks in a string. We can access that string via method  : A downside of this approach is that we are mixing two APIs: The API of   and our new string stream API. An alternative is to delegate to the WritableStream instead of extending it: This functionality could also be implemented via a class (instead of as a factory function for objects). Using TransformStreams   # A TransformStream: \n Receives input via its  , a WritableStream. \n It then may or may not transform this input. \n The result can be read via a ReadableStream, its  . \n The most common way to use TransformStreams is to “pipe through” them:  pipes   to the writable side of   and returns its readable side. In other words: We have created a new ReadableStream that is a transformed version of  .  accepts not only TransformStreams, but any object that has the following shape: Standard TransformStreams   # Node.js supports the following standard TransformStreams: \n \n Encoding (WHATWG standard)  –   and  : \n \n These streams support UTF-8, but also  many “legacy encodings” . \n A single Unicode code point is encoded as up to four UTF-8 code units (bytes). In byte streams, encoded code points be be split across chunks.   handles these cases correctly. \n Available on most JavaScript platforms ( ,  ). \n \n \n \n Compression Streams (W3C Draft Community Group Report)  –  ,  : \n \n Currently supported compression formats :   (ZLIB Compressed Data Format),   (DEFLATE algorithm),   (GZIP file format). \n Available on many JavaScript platforms ( ,  ). \n \n \n # In the following example, we decode a stream of UTF-8-encoded bytes:  is a ReadableByteStream whose chunks are instances of   ( TypedArrays ). We pipe that stream through a   to get a stream that has string chunks. Note that translating each byte chunk separately (e.g. via  a  ) doesn’t work because  a single Unicode code point is encoded as up to four bytes in UTF-8  and those bytes might not all be in the same chunk. # The following Node.js module logs everything that is sent to it via standard input: We can access standard input via a stream stored in   (  is a global Node.js variable). If we don’t set an encoding for this stream and convert it via  , we get a byte stream. We pipe it through a TextDecoderStream in order to get a text stream. Note that we process standard input incrementally: As soon as another chunk is available, we log it. In other words, we don’t wait until standard input is finished. That is useful when the data is either large or only sent intermittently. Implementing custom TransformStreams   # We can implement a custom TransformStream by passing a Transformer object to the constructor of  . Such has object has the following type (feel free to skim this type and the explanations of its properties; they will be explained again when we encounter them in examples): Explanations of these properties: \n  is called immediately after we invoke the constructor of  . Here we can prepare things before the transformations start. \n  performs the actual transformations. It receives an input chunk and can use its parameter   to enqueue one or more transformed output chunks. It can also choose not to enqueue anything at all. \n  is called after all input chunks were transformed successfully. Here we can perform clean-ups after the transformations are done. \n Each of these methods can return a Promise and no further steps will be taken until the Promise is settled. That is useful if we want to do something asynchronous. The parameter   has the following type: \n  adds   to the readable side (output) of the TransformStream. \n  returns the desired size of the internal queue of the readable side (output) of the TransformStream. \n  closes the readable side (output) and errors the writable side (input) of the TransformStream. It can be used if a transformer is not interested in the remaining chunks of the writable side (input) and wants to skip them. \n  errors the TransformStream: All future interactions with it will fail with the error value  . \n What about backpressure in a TransformStream? The class propagates the backpressure from its readable side (output) to its writable side (input). The assumption is that transforming doesn’t change the amount of data much. Therefore, Transforms can get away with ignoring backpressure. However, it could be detected via   and propagated by returning a Promise from  . Example: transforming a stream of arbitrary chunks to a stream of lines   # The following subclass of   converts a stream with arbitrary chunks into a stream where each chunk comprises exactly one line of text. That is, with the possible exception of the last chunk, each chunk ends with an end-of-line (EOL) string:   on Unix (incl. macOS) and   on Windows. Note that  Deno’s built-in   provides similar functionality. Tip: async generators are also great for transforming streams   # Due to ReadableStreams being asynchronously iterable, we can use  asynchronous generators  to transform them. That leads to very elegant code: A closer look at backpressure   # Let’s take a closer look at backpressure. Consider the following pipe chain:  is a ReadableStream,   is a TransformStream,   is a WritableStream. These are the connections that are created by the previous expression (  uses   to connect   to the writable side of  ): Observations: \n The underlying source of   can be viewed as a pipe chain member that comes before  . \n The underlying sink of   can be viewed as a pipe chain member that comes after  . \n Each stream has an internal buffer: ReadableStreams buffers after their underlying sources. WritableStreams have buffers before their underlying sinks. \n Let’s assume that the underlying sink of   is slow and the buffer of   is eventually full. Then the following steps happen: \n  signals it’s full. \n  stops reading from  . \n  signals it’s full. \n  stops moving chunks from   to  . \n  signals it’s full. \n  stops reading from  . \n  signals it’s full to its underlying source. \n The underlying source pauses. \n This example illustrates that we need two kinds of functionality: \n Entities receiving data need to be able to signal backpressure. \n Entities sending data need to react to signals by exerting backpressure. \n Let’s explore how these functionalities are implemented in the web streams API. Signalling backpressure   # Backpressure is signalled by entities that are receiving data. Web streams have two such entities: \n A WritableStream receives data via the Writer method  . \n A ReadableStream receives data when its underlying source calls the ReadableStreamDefaultController method  . \n In both cases, the input is buffered via queues. The signal to apply backpressure is when a queue is full. Let’s see how that can be detected. These are the locations of the queues: \n The queue of a WritableStream is stored internally in the WritableStreamDefaultController ( see web streams standard ). \n The queue of a ReadableStream is stored internally in the ReadableStreamDefaultController ( see web streams standard ). \n The   of a queue is a number that indicates how much room is left in the queue: \n It is positive if there is still room in the queue. \n It is zero if the queue has reached its maximum size. \n It is negative if the queue has exceeded its maximum size. \n Therefore, we have to apply backpressure if the desired size is zero or less. It is available via the getter   of the object which contains the queue. How is the desired size computed? Via an object that specifies a so-called  .   and   have default queuing strategies which can be overridden via optional parameters of their constructors.  The interface   has two properties: \n Method   returns a size for  .\n \n The current size of a queue is the sum of the sizes of the chunks it contains. \n \n \n Property   specifies the maximum size of a queue. \n The desired size of a queue is the high water mark minus the current size of the queue. Reacting to backpressure   # Entities sending data need to react to signalled backpressure by exerting backpressure. # \n \n We can await the Promise in  . While we do, we are blocked and the desired backpressure is achieved. The Promise is fulfilled once there is room in the queue. Fulfillment is triggered when   has a value greater than zero. \n \n \n Alternatively, we can await the Promise returned by  . If we do that, the queue won’t even be filled. \n \n If we want to, we can additionally base the size of our chunks on  . # The underlying source object that can be passed to a ReadableStream wraps an external source. In a way, it is also a member of the pipe chain; one that comes before its ReadableStream. \n \n Underlying pull sources are only asked for new data whenever there is room in the queue. While there isn’t, backpressure is exerted automatically because no data is pulled. \n \n \n Underlying push sources should check   after enqueuing something: If it’s zero or less, they should exert backpressure by pausing their external sources. \n \n # The underlying sink object that can be passed to a WritableStream wraps an external sink. In a way, it is also a member of the pipe chain; one that comes after its WritableStream. Each external sink signals backpressure differently (in some cases not at all). The underlying sink can exert backpressure by returning a Promise from method   that is fulfilled once writing is finished. There is  an example in the web streams standard  that demonstrates how that works. # The TransformStream connects its writable side with its readable side by implementing an underlying sink for the former and an underlying source for the latter. It has an internal slot   that indicates if internal backpressure is currently active or not. \n \n Method   of the underlying sink of the writable side waits asynchronously until there is no internal backpressure before it feeds another chunk to the TransformStream’s transformer (web streams standard:  ). The transformer may then enqueue something via its TransformStreamDefaultController. Note that   returns a Promise that fulfills when the method is finished. Until that happens, the WriteStream buffers incoming write requests via its queue. Therefore, backpressure for the writable side is signalled via that queue and its desired size. \n \n \n The TransformStream’s backpressure is activated if a chunk is enqueued via the TransformStreamDefaultController and the queue of the readable side becomes full (web streams standard:  ). \n \n \n The TransformStream’s backpressure may be deactivated if something is read from the Reader (web streams standard:  ): \n \n If there is room in the queue now, it may be time to call   of the underlying source (web streams standard:  ). \n  of the underlying source of the readable side deactivates the backpressure (web streams standard:  ). \n \n \n #  reads chunks from the ReadableStream via a reader and write them to the WritableStream via a Writer. It pauses whenever   is zero or less (web streams standard: Step 15 of  ). Byte streams   # So far, we have only worked with  , streams whose chunks were strings. But the web streams API also supports   for binary data, where chunks are Uint8Arrays ( TypedArrays ): \n  has a special   mode. \n  itself doesn’t care if chunks are strings or  Uint8Arrays. Therefore, whether an instance is a text stream or a byte stream depends on what kind of chunks the underlying sink can handle. \n What kind of chunks a   can handle also depends on its Transformer. \n Next, we’ll learn how to create readable byte streams. Readable byte streams   # What kind of stream is created by the   constructor depends on the optional property   of its optional first parameter  : \n If   is omitted or no underlying source is provided, the new instance is a text stream. \n If   is the string  , the new instance is a byte stream: \n \n What changes if a ReadableStream is in   mode? In default mode, the underlying source can return any kind of chunk. In bytes mode, the chunks must be ArrayBufferViews, i.e. TypedArrays (such as Uint8Arrays) or DataViews. Additionally, a readable byte stream can create two kinds of readers: \n  returns an instance of  . \n  returns an instance of  . \n “BYOB“ stands for “Bring Your Own Buffer” and means that we can pass a buffer (an ArrayBufferView) to  . Afterwards, that ArrayBufferView will be detached and no longer usable. But   returns its data in a new ArrayBufferView that has the same type and accesses the same region of the same ArrayBuffer. Additionally, readable byte streams have different controllers: They are instances of   (vs.  ). Apart from forcing underlying sources to enqueue ArrayBufferViews (TypedArrays or DataViews), it also supports ReadableStreamBYOBReaders via  its property  . An underlying source writes its data into the BYOBRequest stored in this property. The web streams standard has two examples of using   in  its section “Examples of creating streams” . Example: an infinite readable byte stream filled with random data   # In the next example, create an infinite readable byte stream that fills its chunks with random data (inspiration:   in “Implementing the Web Streams API in Node.js” ). Due to   being infinite, we can’t loop over it. That’s why we only read its first chunk (line B). The buffer we create in line A is transferred and therefore unreadable after line B. Example: compressing a readable byte stream   # In the following example, we create a readable byte stream and pipe it through a stream that compresses it to the GZIP format: Example: reading a web page via     # The result of   resolves to a response object whose property   is a readable byte stream. We convert that byte stream to a text stream via  : Node.js-specific helpers   # Node.js is the only web platform that supports the following helper functions that it calls  : These functions convert web ReadableStreams, Node.js Readables and AsyncIterators to Promises that are fulfilled with: \n ArrayBuffers ( ) \n Blobs ( ) \n Node.js Buffers ( ) \n JSON objects ( ) \n Strings ( ) \n Binary data is assumed to be UTF-8-encoded: String streams work as expected: Further reading   # All of the material mentioned in this section was a source for this blog post. This post doesn’t cover every aspect of the web streams API. You can find more information here: \n “WHATWG Streams Standard”  by Adam Rice, Domenic Denicola, Mattias Buelens, and 吉野剛史 (Takeshi Yoshino) \n “Web Streams API”  in the Node.js documentation \n More material: \n Web streams API:\n \n “Implementing the Web Streams API in Node.js”  by James M. Snell \n “Streams API”  on MDN \n “Streams—The definitive guide”  by Thomas Steiner \n \n \n Backpressure:\n \n “Node.js Backpressuring in Streams”  by Vladimir Topolev \n “Backpressuring in Streams”  in the Node.js documentation \n \n \n Unicode (code points, UTF-8, UTF-16, etc.):  Chapter “Unicode – a brief introduction”  in “JavaScript for impatient programmers” \n Chapter “Asynchronous iteration”  in “JavaScript for impatient programmers” \n Chapter “Typed Arrays: handling binary data”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/06/global-npm-install-alternatives.html", "title": "Alternatives to installing npm packages globally", "content": "Alternatives to installing npm packages globally dev javascript nodejs There are two ways in which npm packages can be installed: \n \n Locally, into a   directory that npm searches for (or creates) in the current directory and its ancestors: \n \n \n \n Globally, into a global   directory: \n \n (Instead of the long version   of this flag, we can also use the shorter  .) \n \n The latter requires root access on macOS and some other Unix platforms – which is a considerable downside. That’s why this blog post explores alternatives to global installs. \n   \n     Preparation: changing the command line PATH \n   \n   \n     Approach 1: changing the “npm prefix” \n     \n       \n         Setup \n       \n       \n         Installing a package \n       \n       \n         Pros and cons \n       \n     \n   \n   \n     Approach 2: installing into the home directory \n     \n       \n         Setup \n       \n       \n         Installing a package \n       \n       \n         Pros and cons \n       \n     \n   \n   \n     Approach 3: installing into a subdirectory of the home directory \n     \n       \n         Setup \n       \n       \n         Installing a package \n       \n       \n         Pros and cons \n       \n     \n   \n   \n     Approach 4: using npx \n     \n       \n         Pros and cons \n       \n     \n   \n   \n     Approach 5: using a Node.js version manager \n   \n Preparation: changing the command line PATH   # In the remainder of this blog post, we need to change the command line PATH for some approaches. This PATH is a command line variable that lists all paths where the command line looks for executables when we enter a command. If we want to install executables via npm, it’s important that the PATH is set up correctly. There are many good tutorials online, just do a web search for: \n Windows: set path powershell \n MacOS: set path zsh \n Linux (e.g.): set path bash \n On Windows, we can display the current PATH like this: On Unix, we can display it like this: Approach 1: changing the “npm prefix”   # The npm documentation  recommends to change the npm prefix. We can display the current prefix as follows (I’m showing the results for my Mac): Under that prefix, there are two important subdirectories. First, a   directory: Second, a   directory which contains executable files: This directory is part of the macOS PATH by default. npm adds links from it into the global   – e.g.: How do we change npm’s prefix? Setup   # We create a directory and set npm’s prefix to that directory: A tilde ( ) on its own refers to the home directory on Unix and Windows. Instead of that symbol, we can also use the shell variable   (on Unix and Windows), but must take care that shell variables are expanded. Afterwards, we must add   to the PATH. Installing a package   # We can now continue to install packages with the flag  , but they won’t be installed globally, they will be installed into our home directory: Pros and cons   # \n Pro:   works everywhere. \n Con: No   of what’s installed makes reinstalls more work. \n Con: npm itself is now also installed into   (e.g. if you tell it to update itself). \n Approach 2: installing into the home directory   # Another alternative to global installs is to install locally into a   in our home directory and only set up the PATH correctly. Setup   # We first turn our home directory into a package: Then we add   to our PATH. Once we install our first package, the following new files will exist: Installing a package   # Instead, of installing a package globally, we do this: This adds at least the following directory to   (possibly more, depending on how many dependencies   has): Per executable   that   provides, we also get: That is, the executable is a link into the package. Pros and cons   # \n Pro:   records all installed packages. That helps with reinstallations. \n Con: We must go to the home directory before we can install a package. \n Con: Three new files in the home directory –  ,  ,  . \n  This approach  was suggested by Boopathi Rajaa . Approach 3: installing into a subdirectory of the home directory   # This approach is a variation of approach 2. However, instead of turning our home directory into a package, we use a subdirectory of our home directory. Setup   # Then we add   to our PATH. Once we install our first package, the following new files will exist: Installing a package   # Pros and cons   # \n Pro:   records all installed packages. That helps with reinstallations. \n Con: We must go to   before we can install a package. \n Approach 4: using npx   # npx is an option if an executable that we are interested in has the same name as its package. (This is not a strict requirement but we have to type much more otherwise.) It works as follows. If we install the executable   globally and run it this way: Then we can also run it this way – without installing anything: The first time we use this command, npx downloads   into a user-local cache and runs it from there. The download may take some time, but is only needed once. Thus, starting with the second time, running   via npx is virtually as quick as running an installed version. The npm documentation has  more information on npx . Pros and cons   # \n Pro: No installation necessary – which is great for executables we don’t need often. \n Con: Running an executable means more typing. \n Con: Isn’t really an option if an executable doesn’t have the same name as its package. \n Con: Makes it more difficult to prepare for being offline. \n Approach 5: using a Node.js version manager   # There are tools that let us install multiple Node.js versions and switch between them – for example: \n Node Version Manager (nvm) \n Volta \n These tools usually set the npm prefix to a directory somewhere inside the current home directory.   A discussion on Twitter  helped me with writing this blog post. Thanks to everyone who participated! comments powered by Disqus."},
{"url": "https://2ality.com/2022/06/ecmascript-2022.html", "title": "Ecma International approves ECMAScript 2022: What’s new?", "content": "Ecma International approves ECMAScript 2022: What’s new? dev javascript es2022 On 22 June 2022,  the 123nd Ecma General Assembly approved the ECMAScript 2022 language specification , which means that it’s officially a standard now. This blog post explains what’s new. \n   \n     The editors of ECMAScript 2022 \n   \n   \n     What’s new in ECMAScript 2022? \n     \n       \n         New members of classes \n       \n       \n         Private slot checks via the   operator \n       \n       \n         Top-level   in modules \n       \n       \n         \n       \n       \n         Method   of indexable values \n       \n       \n         RegExp match indices \n       \n       \n         \n       \n     \n   \n   \n     FAQ \n     \n       \n         What is the difference between JavaScript and ECMAScript? \n       \n       \n         Who designs ECMAScript? TC39 – Ecma Technical Committee 39 \n       \n       \n         How are features added to ECMAScript? They go through the stages of the TC39 process \n       \n       \n         How important are ECMAScript versions? \n       \n       \n         How is [my favorite feature proposal] doing? \n       \n       \n         Where can I look up which features were added in a given ECMAScript version? \n       \n     \n   \n   \n     Free books on JavaScript \n   \n The editors of ECMAScript 2022   # The editors of this release are: \n Shu-yu Guo \n Michael Ficarra \n Kevin Gibbons \n What’s new in ECMAScript 2022?   # New members of classes   # \n Properties (public slots) can now be created via:\n \n Instance public fields \n Static public fields \n \n \n Private slots  are new and can be created via:\n \n Private fields ( instance private fields  and  static private fields ) \n Private methods and accessors ( non-static  and  static ) \n \n \n Static initialization blocks \n Private slot checks via the   operator   # Private slot checks are also called “ergonomic brand checks for private fields”. The following expression is such a check – it determines if   has a private slot  : This is an example: Note that we can only refer to a private slot inside the scope in which it was declared. More information on private slot checks. Top-level   in modules   # We can now use   at the top levels of modules and don’t have to enter async functions or methods anymore: More information on top-level  .    #  and its subclasses now let us specify which error caused the current one: The cause of an error   shows up in the stack trace and can be accessed via  . More information on  . Method   of indexable values   # Method   of indexable values lets us read an element at a given index (like the bracket operator  ) and supports negative indices (unlike the bracket operator): The following “indexable” types have method  : \n \n \n All Typed Array classes:   etc. \n More information on method   of indexable values. RegExp match indices   # If we add the flag   to a regular expression, using it produces match objects that record the start and end index of each group capture (lines A and B): More information on RegExp match indices.    #  provides a safe way to check if an object   has an   (non-inherited) property with the key  : Note that   detects inherited properties (line A), while   only detects own properties (lines B and C). More information on  . FAQ   # What is the difference between JavaScript and ECMAScript?   # \n \n Short version – colloquially: \n \n JavaScript is the programming language that is implemented by various platforms (browsers, Node.js, Deno, etc.). \n ECMAScript is its standard, as described in  . \n \n \n \n For the long version, see  section “Standardizing JavaScript” in “JavaScript for impatient programmers” . \n \n Who designs ECMAScript? TC39 – Ecma Technical Committee 39   # ECMAScript is designed by the   (TC39) of the standards organization  . Its members are, strictly speaking, companies: Adobe, Apple, Facebook, Google, Microsoft, Mozilla, Opera, Twitter, and others. That is, companies that are usually competitors are working together on JavaScript. Every two months, TC39 has meetings that member-appointed delegates and invited experts attend. The minutes of those meetings are public in  a GitHub repository . Outside of meetings, TC39 also collaborates with various members and groups of the JavaScript community. How are features added to ECMAScript? They go through the stages of the TC39 process   # New ECMAScript features must be proposed to TC39. They go through stages: \n from stage 0 (enables TC39 to comment on a proposal) \n to stage 4 (the proposed feature is ready to added to ECMAScript) \n Once a feature reaches stage 4, it is scheduled to be added to ECMAScript. The feature set of an ECMAScript version is usually frozen in March of each year. Features that reach stage 4 after that deadline are added to next year’s ECMAScript version. For more information, see  section “The TC39 process” in “JavaScript for impatient programmers” . How important are ECMAScript versions?   # Since the TC39 process was instituted, the importance of ECMAScript versions has much decreased. What really matters now is what stage a proposed feature is in: Once it has reached stage 4, it can be used safely. But even then, you still have to check if the engines you are targeting support it. How is [my favorite feature proposal] doing?   # If you are wondering what stages various proposed features are in, see  the TC39 proposals repository . Where can I look up which features were added in a given ECMAScript version?   # There are several places where we can look up what’s new in each ECMAScript version: \n \n In “JavaScript for impatient programmers”, there is  a section that lists what’s new in each ECMAScript version . It also links to explanations. \n \n \n The TC39 repository has a table with  finished proposals  that states in which ECMAScript versions they were (or will be) introduced. \n \n \n Section “Introduction” of the ECMAScript language specification  lists the new features of each ECMAScript version. \n \n \n The ECMA-262 repository has  a page with releases . \n \n Free books on JavaScript   # My books on JavaScript are free to read online: \n \n “JavaScript for impatient programmers (ES2022 edition)”  covers JavaScript up to and including ECMAScript 2022. \n \n \n “Deep JavaScript: Theory and techniques”  covers language foundations in more depth. \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/07/typescript-check-property-key-array.html", "title": "TypeScript: checking at compile time if an Array lists all property keys", "content": "TypeScript: checking at compile time if an Array lists all property keys dev typescript In this blog post, we use TypeScript to ensure that an object stays in sync with an Array that lists its properties. The problem   # Consider the following TypeScript code:  lists the property keys of  . Can we check at compile time if this list is correct? The solution   # Library   enables us to check if two types are equal. The arguments of   are computed as follows: To compute type  , we are using  the indexed access operator  : For a given type  , it computes the types of all properties whose keys are assignable to type  . The following two types are roughly equivalent. That explains the result of computing  . Further reading   # \n Section “The indexed access operator  ”  in “Tackling TypeScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/07/nodejs-esm-main.html", "title": "Node.js: checking if an ESM module is “main”", "content": "Node.js: checking if an ESM module is “main” dev javascript nodejs section “Use case for URLs: detecting if the current module is “main” (the app entry point)” An ESM module can be used in two ways: It can be used as a library from which other modules can import values. It can be used as script that we run via Node.js – e.g., from a command line. In that case, it is called the  . If we want a module to be used in both ways, we need a way to check if the current module is the main module because only then do we execute the script functionality. In this blog post, we learn how to perform that check. Determining if a CommonJS module is main   # With CommonJS, we can use the following pattern to detect if the current module was the entry point (source:  Node.js documentation ): Determining if an ESM module is main   # As of now, ESM modules have no simple built-in way to check if a module is main. Instead, we have to use the following workaround (based on  a tweet by Rich Harris ): Explanations: \n \n  contains the URL of the currently executed ESM module. \n \n \n If we are sure our code always runs locally (which may become less common in the future), we can omit the check in line A. If we do and the code does not run locally, at least we get an exception (and not a silent failure) – thanks to   (see next item). \n \n \n We use   to convert the URL to a local path. This function throws an exception if the protocol isn’t  . \n \n \n  contains the path of the initial module. The comparison in line B works because this value is always an absolute path – Node.js sets it up as follows ( source code ): \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2008/11/graphviz.html", "title": "Graphviz: easy graph visualization", "content": "Graphviz: easy graph visualization dev hack software This tool has been around for a while, but I still like how useful it is, so I thought I'd write a blog entry about it: Graphviz translates simple textual representation of graphs into diagrams. Visually, this covers everything where shapes are connected by lines (be it with or without arrows), which is quite a lot. For example, the definition is displayed by Graphviz as: Notes: \n The definition (and input of Graphviz) is just a text file which can be easily created by a program. \n The GUI version of Graphviz watches files so the diagram will be updated automatically every time the text file changes. \n Graphviz can export its visualizations in many formats (jpg, PDF, SVG, ...). \n More examples:  Graphviz Gallery ,  UML Diagrams Using Graphviz Dot . \n Download  (be sure to use one of the \"Executable Packages from AT&T\"). \n Now, my only wish would be a pure JavaScript implementation of Graphviz. All the Graphviz solutions that I’m aware of depend on a server-side native dot binary to do the graph layout. comments powered by Disqus."},
{"url": "https://2ality.com/2008/12/future-of-ajax.html", "title": "The future of Ajax", "content": "The future of Ajax gwt dev webdev JGoodies Forms MiG Layout The OpenAjax Alliance has voted on a  browser wishlist  that includes a lot of interesting details. This wishlist is supposed to guide browser vendors towards features that make sense for the Ajax community. Not suprisingly, layout issues rank high on that list. The Future of CSS and the end of 3.0 : This article is almost one and a half years old, but it still rings very true to me.\n XUL  is a Firefox-based widget toolkit that can be programmed in JavaScript. It avoids many of the Ajax CSS problems, because it has specifically been designed for applications (and not for hypertext). Firefox-only, but it should not feel alien to Ajax developers because it does not stray to far from browser technologies. While some test code for using XUL via  GWT  is out there, I wish there was something more usable. Better UI Layout comments powered by Disqus."},
{"url": "https://2ality.com/2009/03/remove-white-space-around-pdf-graphics.html", "title": "Remove white space around PDF graphics with pdfcrop", "content": "Remove white space around PDF graphics with pdfcrop latex hack pdf pdfcrop TeX Live comments powered by Disqus."},
{"url": "https://2ality.com/2008/05/fixing-jet-lag.html", "title": "Fixing jet lag", "content": "Fixing jet lag scitech Fasting may fix jet lag Start with the day you will arrive in your final time zone. Count back 16 hours from your normal breakfast time on that day, and stop eating from that point. At your normal breakfast time on the final day, eat a substantial, nutritious, meal comments powered by Disqus."},
{"url": "https://2ality.com/2009/02/javascript-is-becoming-nice-language.html", "title": "JavaScript is becoming a nice language", "content": "JavaScript is becoming a nice language dev javascript V8 TraceMonkey ECMAScript Pythonic Javascript, it's Python with braces! cached comments powered by Disqus."},
{"url": "https://2ality.com/2009/02/incremental-backups-with-rsync-on-unix.html", "title": "incsync – incremental backups with rsync on Unix", "content": "incsync – incremental backups with rsync on Unix hack computers unix \n Rsync  is really cool for backups (if you need bi-directional file synchronization, take a look at  Unison ): If you specify a source and a target directory, rsync makes sure that files are copied from target to source or removed from target until both directories have the same content. Thus, whatever the state of source and target, after invoking rsync, the target is an exact copy of the source. Rsync has command line options that allow one to only back up changes relative to a “previous” directory:\n \n       \n         \n             No arguments: Perform a new backup with the current time as a timestamp. \n             One argument – a timestamp: Continue a previous backup. \n         \n     \n      Each time, it is invoked, only what has changed (since the last invocation) is backed up, in a new directory with a time stamp. \n      incsync uses the open source tool  rsync  for incremental backups. rsync uses Unix hard links (references to files) to do so: Before creating a new backup, one makes a complete copy of the last backup, but the copy does not contain files, only hard links to files. Then one brings the copy up to date with the source directory. Afterwards, the copy looks like a complete backup, but consumes relatively little space on disk. The kicker is that you could now delete the previous backup and the newly created directory would still contain a complete backup. The reason lies in Unix’s handling of hard links: it only deletes a file after there are no more references to it. \n      This script has been inspired by the article “ Time Machine for every Unix out there ”. \n      on GitHub at  incsync . \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/07/nodejs-path.html", "title": "Working with file system paths and file URLs on Node.js", "content": "Working with file system paths and file URLs on Node.js dev javascript nodejs chapter “Working with file system paths and file URLs on Node.js” In this blog post, we learn how to work with file system paths and file URLs on Node.js. \n   \n     Path-related functionality on Node.js \n     \n       \n         The three ways of accessing the   API \n       \n     \n   \n   \n     Foundational path concepts and their API support \n     \n       \n         Path segments, path separators, path delimiters \n       \n       \n         The current working directory \n       \n       \n         Fully vs. partially qualified paths, resolving paths \n       \n     \n   \n   \n     Getting the paths of important directories via module  \n   \n   \n     Concatenating paths \n     \n       \n         : concatenating paths to create fully qualified paths \n       \n       \n         : concatenating paths while preserving relative paths \n       \n     \n   \n   \n     Ensuring paths are normalized, fully qualified, or relative \n     \n       \n         : ensuring paths are normalized \n       \n       \n          (one argument): ensuring paths are normalized and fully qualified \n       \n       \n         : creating relative paths \n       \n     \n   \n   \n     Parsing paths: extracting various parts of a path (filename extension etc.) \n     \n       \n         : creating an object with path parts \n       \n       \n         : extracting the base of a path \n       \n       \n         : extracting the parent directory of a path \n       \n       \n         : extracting the extension of a path \n       \n     \n   \n   \n     Categorizing paths \n     \n       \n         : Is a given path absolute? \n       \n     \n   \n   \n     : creating paths out of parts \n     \n       \n         Example: changing the filename extension \n       \n     \n   \n   \n     Using the same paths on different platforms \n     \n       \n         Relative platform-independent paths \n       \n     \n   \n   \n     Using a library to match paths via globs \n     \n       \n         The minimatch API \n       \n       \n         Syntax of glob expressions \n       \n     \n   \n   \n     Using   URLs to refer to files \n     \n       \n         Class  \n       \n       \n         Converting between URLs and file paths \n       \n       \n         Use case for URLs: accessing files relative to the current module \n       \n       \n         Use case for URLs: detecting if the current module is running as a script \n       \n       \n         Paths vs.   URLs \n       \n     \n   \n Path-related functionality on Node.js   # In this blog post, we explore path-related functionality on Node.js: \n Most path-related functionality is in module  . \n The global variable   has methods for changing the   (what that is, is explained soon). \n Module   has functions that return the paths of important directories. \n The three ways of accessing the   API   # Module   is often imported as follows: In this blog post, this import statement is occasionally omitted. We also omit the following import: We can access Node’s path API in three ways: \n We can access platform-specific versions of the API:\n \n  supports Unixes including macOS. \n  supports Windows. \n \n \n  itself always supports the current platform. For example, this is a REPL interaction on macOS: \n \n Let’s see how function  , which parses file system paths, differs for the two platforms: We parse a Windows path – first correctly via the   API, then via the   API. We can see that in the latter case, the path isn’t correctly split into its parts – for example, the basename of the file should be   (more on what the other properties mean later). Foundational path concepts and their API support   # Path segments, path separators, path delimiters   # Terminology: \n A non-empty path consists of one or more   – most often names of directories or files. \n A   is used to separate two adjacent path segments in a path: \n \n A   separates elements in a list of paths: \n \n We can see path separators and path delimitors if we examine the PATH shell variable – which contains the paths where the operating system looks for executables when a command is entered in a shell. This is an example of a macOS PATH (shell variable  ): The split separator has a length of zero because  the lookbehind assertion    matches if a given location is preceded by a colon but it does not capture anything. Therefore, the path delimiter   is included in the preceding path. This is an example of a Windows PATH (shell variable  ): The current working directory   # Many shells have the concept of the   (CWD) – “the directory I’m currently in”: \n If we use a command with a partially qualified path, that path is resolved against the CWD. \n If we omit a path when a command expects a path, the CWD is used. \n On both Unixes and Windows, the command to change the CWD is  . \n  is a global Node.js variable. It provides us with methods for getting and setting the CWD: \n  returns the CWD. \n  changes the CWD to  .\n \n There must be a directory at  . \n That change does not affect the shell, only the currently running Node.js process. \n \n \n Node.js uses the CWD to fill in missing pieces whenever a path isn’t   (complete). That enables us to use partially qualified paths with various functions – e.g.  . # The following code demonstrates   and   on Unix: # So far, we have used the current working directory on Unix. Windows works differently: \n Each drive has a  . \n There is a  . \n We can use   to set both at the same time: When we revisit a drive, Node.js remembers the previous current directory of that drive: Fully vs. partially qualified paths, resolving paths   # \n A   does not rely on any other information and can be used as is. \n A   is missing information: We need to turn it into a fully qualified path before we can use it. That is done by   it against a fully qualified path. \n # Unix only knows two kinds of paths: \n \n  are fully qualified and start with a slash: \n \n \n \n  are partially qualified and start with a filename or a dot: \n \n \n Let’s use   (which is explained in more detail  later ) to resolve relative paths against absolute paths. The results are absolute paths: # Windows distinguishes four kinds of paths (for more information, see  Microsoft’s documentation ): \n There are absolute paths and relative paths. \n Each of those two kinds of paths can have a drive letter (“volume designator”) or not. \n Absolute paths with drive letters are fully qualified. All other paths are partially qualified.  against a fully qualified path  , picks up the drive letter of  :  against a fully qualified path, can be viewed as updating the latter:  against a fully qualified path   depends on the drive letter of  : \n Same drive letter as  ? Resolve   against  . \n Different drive letter than  ? Resolve   against the current directory of  ’s drive. \n That looks as follows: Getting the paths of important directories via module     # The module   provides us with the paths of two important directories: \n \n  returns the path to the home directory of the current user – for example: \n \n \n \n  returns the path of the operating system’s directory for temporary files – for example: \n \n \n Concatenating paths   # There are two functions for concatenating paths: \n  always returns fully qualified paths \n  preserves relative paths \n : concatenating paths to create fully qualified paths   # Concatenates the   and return a fully qualified path. It uses the following algorithm: \n Start with the current working directory. \n Resolve   against the previous result. \n Resolve   against the previous result. \n Do the same for all remaining paths. \n Return the final result. \n Without arguments,   returns the path of the current working directory: One or more relative paths are used for resolution, starting with the current working directory: Any fully qualified path replaces the previous result: That enables us to resolve partially qualified paths against fully qualified paths: : concatenating paths while preserving relative paths   # Starts with   and interprets the remaining paths as instructions for ascending or descending. In contrast to  , this function preserves partially qualified paths: If   is partially qualified, the result is partially qualified. If it is fully qualified, the result is fully qualified. Examples of descending: Double dots ascend: Single dots do nothing: If arguments after the first one are fully qualified paths, they are interpreted as relative paths: Using more than two arguments: Ensuring paths are normalized, fully qualified, or relative   # : ensuring paths are normalized   # On Unix,  : \n Removes path segments that are single dots ( ). \n Resolves path segments that are double dots ( ). \n Turns multiple path separators into a single path separator. \n For example: On Windows,  : \n Removes path segments that are single dots ( ). \n Resolves path segments that are double dots ( ). \n Converts each path separator slash ( ) – which is legal – into a the preferred path separator ( ). \n Converts sequences of more than one path separator to single backslashes. \n For example: Note that   with a single argument also normalizes and works the same as  :  (one argument): ensuring paths are normalized and fully qualified   # We have already encountered  . Called with a single argument, it both normalizes paths and ensures that they are fully qualified. Using   on Unix: Using   on Windows: : creating relative paths   # Returns a relative path that gets us from   to  : On Windows, we get a fully qualified path if   and   are on different drives: This function also works with relative paths: Parsing paths: extracting various parts of a path (filename extension etc.)   # : creating an object with path parts   # Extracts various parts of   and returns them in an object with the following properties: \n : last segment of a path\n \n : the filename extension of the base \n : the base without the extension. This part is also called the   of a path. \n \n \n : the beginning of a path (before the first segment) \n : the directory in which the base is located – the path without the base \n Later, we’ll see  function   which is the inverse of  : It converts an object with path parts into a path. # This is what using   on Unix looks like: The following diagram visualizes the extent of the parts: For example, we can see that   is the path without the base. And that   is   plus  . # This is how   works on Windows: This is a diagram for the result: : extracting the base of a path   # Returns the base of  : Optionally, this function can also remove a suffix: Removing the extension is case sensitive – even on Windows! : extracting the parent directory of a path   # Returns the parent directory of the file or directory at  : : extracting the extension of a path   # Returns the extension of  : Categorizing paths   # : Is a given path absolute?   # Returns   if   is absolute and   otherwise. The results on Unix are straightforward: On Windows, “absolute” does not necessarily mean “fully qualified” (only the first path is fully qualified): : creating paths out of parts   # Creates a path out of a path object: Example: changing the filename extension   # We can use   to change the extension of a path: If we know the original filename extension, we can also use a regular expression to change the filename extension: Using the same paths on different platforms   # Sometimes we’d like to use the same paths on different platforms. Then there are two issues that we are facing: \n The path separator may be different. \n The file structure may be different: home directories and directories for temporary files may be in different locations, etc. \n As an example, consider a Node.js app that operates on a directory with data. Let’s assume that the app can be configured with two kinds of paths: \n Fully qualified paths anywhere on the system \n Paths inside the data directory \n Due to the aforementioned issues: \n \n We can’t reuse fully qualified paths between platforms. \n \n Sometimes we need absolute paths. These have to be configured per “instance” of the data directory and stored externally (or inside it and ignored by version control). These paths stay put and are not moved with the data directory. \n \n \n \n We can reuse paths that point into the data directory. Such paths may be stored in configuration files (inside the data directory or not) and in constants in the app’s code. To do that: \n \n We have to store them as relative paths. \n We have to ensure that the path separator is correct on each platform. \n \n The next subsection explains how both can be achieved. \n \n Relative platform-independent paths   # Relative platform-independent paths can be stored as Arrays of path segments and turned into fully qualified platform-specific paths as follows: To create relative platform-specific paths, we can use: The following function converts relative platform-specific paths into platform-independent paths: Using   on Unix: Using   on Windows: Using a library to match paths via     # The  npm module   lets us match paths against patterns that are called  ,  , or  : Use cases for globs: \n Specifying which files in a directory should be processed by a script. \n Specifying which files to ignore. \n More glob libraries: \n multimatch  extends minimatch with support for multiple patterns. \n micromatch  is an alternative to minimatch and multimatch that has a similar API. \n globby  is a library based on  fast-glob  that adds convenience features. \n The minimatch API   # The whole API of minimatch is documented in  the project’s readme file . In this subsection, we look at the most important functionality. Minimatch compiles globs to JavaScript   objects and uses those to match. # Returns   if   matches   and   otherwise. Two interesting options: \n \n  (default:  ) \nIf  , wildcard symbols such as   and   match “invisible” path segments (whose names begin with dots): \n \n \n \n  (default:  ) \nIf  , a pattern without slashes is matched against the basename of a path: \n \n \n # Class   enables us to only compile the glob to a regular expression once and match multiple times: This is how this class is used: Syntax of glob expressions   # This subsection covers the essentials of the syntax. But there are more features. These are documented here: \n Minimatch’s unit tests  have many examples of globs. \n The Bash Reference manual has  a section on filename expansion . \n # Even on Windows, glob segments are separated by slashes – but they match both backslashes and slashes (which are legal path separators on Windows): # Minimatch does not normalize paths for us: Therefore, we have to normalize paths if we don’t create them ourselves: # Patterns without   (that match more flexibly) must match exactly. Especially the path separators must line up: That is, we must decide on either absolute or relative paths. With option  , we can match patterns without slashes against the basenames of paths: # The   asterisk ( ) matches any path segment or any part of a segment: The asterisk does not match “invisible files“ whose names start with dots. If we want to match those, we have to prefix the asterisk with a dot: Option   lets us switch off this behavior: # ´  matches zero or more segments: If we want to match relative paths, the pattern still must not start with a path separator: The double asterisk does not match “invisible” path segments whose names start with dots: We can switch off that behavior via option  : # If we start a glob with an exclamation mark, it matches if the pattern after the exclamation mark does not match: # Comma-separate patterns inside braces match if one of the patterns matches: # A pair of integers separated by double dots defines a range of integers and matches if any of its elements matches: Padding with zeros is supported, too: Using   URLs to refer to files   # There are two common ways to refer to files in Node.js: \n Paths in strings \n Instances of   with the protocol  \n For example: Class     # In this section, we take a closer look at class  . More information on this class: \n Node.js documentation: section  “The WHATWG URL API” \n Section “API“  of the WHATWG URL standard \n In this blog post, we access class   via a global variable because that’s how it’s used on other web platforms. But it can also be imported: # URLs are a subset of URIs. RFC 3986, the standard for URIs, distinguishes  two kinds of  : \n A   starts with  a scheme  followed by a colon separator. \n All other URI references are  . \n # Class   can be instantiated in two ways: \n \n \n  must be a URI. It specifies the URI of the new instance. \n \n \n \n  must be a URI. If   is a relative reference, it is resolved against   and the result becomes the URI of the new instance. \n If   is a URI, it completely replaces   as the data on which the instance is based. \n \n Here we can see the class in action: # Let’s revisit this variant of the   constructor: The argument   is coerced to string. Therefore, any object can be used – as long as it becomes a valid URL when coereced to string: That enables us to resolve relative references against   instances: Used this way, the constructor is loosely similar to  . # Instances of   have the following properties: # There are three common ways in which we can convert URLs to strings: Method   enables us to use URLs in JSON data: # The properties of   instances are not own data properties, they are implemented via getters and setters. In the next example, we use the utility function   (whose code is shown at the end), to copy the values returned by those getters into a plain object: Alas, the pathname is a single atomic unit. That is, we can’t use class   to access its parts (base, extension, etc.). # We can also change parts of a URL by setting properties such as  : We can use the setters to create URLs from parts ( idea by Haroen Viaene ): # We can use property   to manage the search parameters of URLs. Its value is an instance of  . We can use it to read search parameters: We can also change search parameters via it: Converting between URLs and file paths   # It’s tempting to convert between file paths and URLs manually. For example, we can try to convert an   instance   to a file path via  . However that doesn’t always work – it’s better to use  this function : The following code compares the results of that function with the values of  : This function  is the inverse of  : It converts   to a file URL: Use case for URLs: accessing files relative to the current module   # One important use case for URLs is accessing a file that is a sibling of the current module: This function uses   which contains the URL of the current module (which is usually a   URL on Node.js). Using   would have made the previous code even more cross-platform. However, as of Node.js 18.5,   doesn’t work for   URLs yet: Use case for URLs: detecting if the current module is running as a script   # See  the blog post “Node.js: checking if an ESM module is ‘main’” . Paths vs.   URLs   # When shell scripts receive references to files or export references to files (e.g. by logging them on screen), they are virtually always paths. However, there are two cases where we need URLs (as discussed in previous subsections): \n To access files relative to the current module \n To detect if the current module is running as a script \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/02/generate-emails-with-mailto-urls-and.html", "title": "Generate emails with mailto URLs and Python ", "content": "Generate emails with mailto URLs and Python  dev python \n recipients: comma-separated email addresses (no spaces; Outlook needs semicolons instead of commas) \n value: should be URL-encoded (e.g. space becomes %20) \n key: subject, cc, bcc, body \n Example:  mailto:joe@example.com,jane@example.com?subject=hello&body=How%20are%20you%3F \n \n     A simple way of sending emails in Java: mailto links \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/05/multiple-dispatch-fix-for-some-problems.html", "title": "Multiple dispatch: a fix for some problems of single dispatch (Java etc.)", "content": "Multiple dispatch: a fix for some problems of single dispatch (Java etc.) programming languages pl fundamentals dev java software engineering \n\nIn this article, we'll first look at Java's single dispatch and Java's overloading and then use what we have learned to understand multiple dispatch and how it solves some design dilemmas that can't be solved with single dispatch.\n\n \n\n Dynamic dispatch Overloading Multiple dispatch \n\nNote that the if statements were for illustration only, languages with multiple dispatch have efficient algorithms for performing the checks and selecting a method.\n\n What advantages does this have? \n\nOne more example of collaborating objects is the visitor pattern: It is a clumsy simulation of multiple dispatch with single dispatch. What you have at its core is the object for the algorithm collaborating with the object for the data. With multiple dispatch, things are much simpler, there is less code to write and the data objects do not have to be prepared for visitors. Interestingly, even the explicit object for the algorithm disappears, because the generic function replaces it.\n\n \n\nAnother area where the asymmetry of single dispatch shows is with the null value. For example, \"abc\".equals(null) is OK while null.equals(\"abc\") causes an exception (and is not even directly syntactically correct). If you introduce null checks as selection criterion for methods, then handling null values is simple with multiple dispatch.\n\n \n\nExtending a class is trivial with multiple dispatch, just create a new generic function that accepts instances of that class as its argument. With Java, people often overlook external static methods that actually extend a given class, because they don't know where to look. For example, if you don't know Java well, you might be puzzled as to why List has no sort() method. If you do, you know that the class Collections has a static method sort(List) that you have to use. In languages with multiple dispatch, one already assumes that in general, a generic function is relevant for several classes. The development tools help one with finding all functions that apply to a given class, making sure that code is re-used instead of re-invented.\n\n \n\nHaving code tightly integrated with the data is less desirable in settings where you serialize objects. With generic functions, code and data are separate and it is easier to use the same data structures on the server and the client. The server can host a lot of code that generates or modifies data. The client only has to display the data and lets the server handle the more complicated stuff. This is a frequent scenario when doing client-server communication with the Google Web Toolkit. As Java does not have generic functions, the server-only functionality has to be moved to external static helper methods. Consequently, things are even less encapsulated, slightly messy and one loses polymorphism.\n\n Predicate dispatch Conclusion Further reading The basics in depth \n     “ Multiple dispatch in practice ” by Radu Muschevici, Alex Potanin, Ewan Tempero, James Noble. \n\n     “ Expressive and Modular Predicate Dispatch for Java ” by Todd Millstein, Christopher Frost, Jason Ryder, Alessandro Warth. A paper about extending Java with predicate dispatch. \n\n     “ Visitor Pattern Versus Multimethods ”. Explains how the two relate, via the Nice programming language. \n Advanced topics \n     “ Python 3000 - Adaptation or Generic Functions? ” by Guido van van Rossum. Illustrates how generic functions subsume adaptation. \n\n     “ The DCI Architecture: A New Vision of Object-Oriented Programming ” by Trygve Reenskaug, James O. Coplien. Explains that objects-as-data are fairly stable whereas the algorithms that span several objects are not. I suspect that their solution could benefit from multiple dispatch. \n Languages close to Java with multiple dispatch \n     “ The MultiJava Project ”. Extends Java with multiple dispatch. The papers on that site provide more information on multiple dispatch. \n\n     “ JPred: Practical Predicate Dispatch for Java ”. Extends Java with predicate dispatch. \n\n     “ The Nice programming language ”. A JVM-based language with multiple dispatch whose syntax stays relatively close to Java. \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/06/gwts-future-20-and-my-wishes.html", "title": "GWT's future: 2.0 and my wishes", "content": "GWT's future: 2.0 and my wishes gwt dev GWT New features in GWT 2.0 In-browser hosted mode: see your hosted mode webapp in a real web browser. This obviates many needs for compilation. Plus both compilation and starting hosted mode will become faster. Developer-guided code splitting: you tell the compiler roughly were to split to lazily load code and the compiler figures out how to package your code.\n Better layout: the GWT team seems to have worked on better CSS-based layouts. I'll believe it when I see it, but if this works, it will fix one of the biggest Ajax problems. GWT Can Do What?! A Preview of Google Web Toolkit 2.0 Open wishes Hyena Trephine  Server-side image generation: generate a JPG, PNG or SVG image on the server, send it to the client, display it in an image. Right now, the work-around is to use a  data: URL  with base-64 encoded binary data and assign it to an image. But that wastes space and does not work with SVG in a cross-browser fashion.\n @Ignore annotation for methods: This would mark server-only methods and prevent client-side code from being generated. The current work-around is to move server-only code to static methods in a different class. Swapping a server-only implementation of an interface with a client-side place holder: With custom field serializers you can control how a class is serialized but not what class is instantiated. This is a problem whenever you have a nested data structure that contains server-only implementations. I currently do my own reflection-based traversal and swap implementations to solve this problem (directed by annotations). Hardly a simple solution.\n  True dynamic loading of client-side GWT code: would be the perfect client-side complement to server-side OSGi modules. Then OSGi modules (or even just plug-in JARs) could bring their own client-side code. Currently this does not work, because GWT always compiles the reachable code of all used modules into a single monolithic \"binary\". The kind of code splitting that is planned for GWT 2.0 seems to be almost there, but serves a different purpose.  GWT API for  Bespin 's widget library: This widget library is completely drawn by JavaScript in the canvas tag. Sounds crazy, works really well, because JavaScript has gotten so fast.\n  Full client-side regular expressions (preferably with an API that works server-side, too).  Non-static GWT.create(): It would be nice if class objects could be sent to the client for instantiation. Currently, the only work-around is to register serializable factories (that actually do the instantiation, statically) and send those to the client. Related reading: “ Timefire: Relaxing constraints on GWT.create() ” String.format(): is useful, easy to implement, and should work on the client. Class.getSimpleName(): same as above.\n  Better layout: Hopefully GWT 2.0 delivers on this front. What I miss is to be able to specify “take up as little space as possible” (as opposed to * or fixed spaces). Vertical spacing is often tricky, too.\n  Better widgets: The scarcity of widgets is still one of GWT's weak spots. Mappings to JavaScript widget libraries are possible, but then one does not profit from GWT's small code size. A few widgets I'd like to see are:  A more flexible suggest box (that can make suggestions anywhere and has a configurable trigger character; both things are relatively easy to add to the current suggest box). A tab bar where one can add widgets to the right of the tabs (right-justified). A span-based HTML widget. Tables: a table that can be translated back to a model (with the incubator's ScrollTable, row numbers change when sorting), a table with grouping (see  SmartGwt ), and a tree table. More events: an OnEnterKey event for TextBox and onChange events that are fired whenever a change happens; not just when un-focusing a TextBox or TextArea. comments powered by Disqus."},
{"url": "https://2ality.com/2009/07/what-is-appeal-of-gwt-and-ajax.html", "title": "What is the appeal of Ajax and GWT?", "content": "What is the appeal of Ajax and GWT? gwt dev webdev I love web applications (because I use 3 different computers having data travel with me is great). I’ve always disliked Applets and Flash. With advanced browser use (tabs, drag&drop of links, etc.), anything that is not well integrated feels constricting. Mobile applications: Web applications are currently the best solution if you need something that runs on the smartphone platforms Android, iPhone, Palm Pre, and Blackberry. The browsers of all of these platforms are WebKit-based, making testing less of a chore. Windows Mobile 6 is out there, too, but feels dated now, and I'm not sure how capable its browser is.\n There is tremendous momentum behind the browser as a platform. New user interface ideas are constantly being tried out, JavaScript is getting really fast, gains lots of APIs ( geolocation  comes to mind), etc. Compared to desktop Java: GWT makes programming web applications almost as simple (in some cases simpler) as programming Swing. So why   use it? Compared to other Ajax solutions: GWT has Java's superior tooling, one has a single code base for client and server, and GWT’s compiler produces highly optimized code (due to Java’s static nature).\n What should be the platform of your next application? comments powered by Disqus."},
{"url": "https://2ality.com/2022/01/pipe-operator.html", "title": "A pipe operator for JavaScript: introduction and use cases", "content": "A pipe operator for JavaScript: introduction and use cases dev javascript es proposal The proposal  “Pipe operator ( ) for JavaScript”  (by J. S. Choi, James DiGioia, Ron Buckton and Tab Atkins) introduces a new operator. This operator is an idea borrowed from functional programming that makes applying functions more convenient in many cases. This blog post describes how the pipe operator works and what its use cases are (there are more than you might expect!). \n   \n     The two competing proposals \n   \n   \n     The Hack pipe operator \n     \n       \n         A first use case \n       \n     \n   \n   \n     The F# pipe operator \n     \n       \n         F# pipe is better at chaining unary (one-parameter) functions \n       \n       \n         Currying: important for the F# pipe operator but not a good fit for JavaScript \n       \n       \n         Hack pipe is better at: method calls, operators, literals,  ,  \n       \n       \n         F# pipe is better at destructuring \n       \n     \n   \n   \n     Use cases for the pipe operator \n     \n       \n         Flat syntax for nested function calls \n       \n       \n         Post-processing values \n       \n       \n         Chaining for non-method language constructs \n       \n     \n   \n   \n     Summary: Hack pipe vs. F# pipe \n     \n       \n         How likely is it that JavaScript gets a pipe operator? \n       \n     \n   \n   \n     Potential improvements for Hack pipe and F# pipe \n     \n       \n         F# pipe: better support for functions with arities greater than 1 \n       \n       \n         Smart pipelines: Hack pipes with optional  \n       \n       \n         An extra operator for unary functions that complements the Hack pipe \n       \n     \n   \n   \n     Do we really need a pipe operator? What are the alternatives? \n     \n       \n         \n       \n       \n         Using intermediate variables \n       \n       \n         Reusing a variable multiple times \n       \n     \n   \n   \n     Share your use cases! \n   \n   \n     Further reading \n   \n The two competing proposals   # There originally were two competing proposals for a pipe operator, inspired by other programming languages: \n \n  by Microsoft is a functional programming language whose core is based on OCaml. This pipe operator works together well with   (I’ll explain what that is soon). \n \n \n  by Facebook is – roughly – a statically typed version of PHP. This pipe operator focuses on language features other than curried functions. It includes syntactic support for partial application. \n \n The latter proposal won. However, if you prefer the F# pipe, there is good news: Its benefits may be added to the Hack pipe at a later time (details are explained later). We’ll start by exploring the Hack pipe. Then we’ll move on to the F# pipe and compare its pros and cons with the pros and cons of the Hack pipe. The Hack pipe operator   # This is an example of using the Hack pipe operator  : The left-hand side of the pipe operator   is an expression that is evaluated and becomes the value of the special variable  . We can use that variable on the right hand side. The returns the result of evaluating its right-hand side. In other words, the previous example is equivalent to: The following examples demonstrate that   really works like any other variable: A first use case   # We’ll see more use cases later, but let’s quickly look at a core use case now. Consider these nested function calls: This notation usually does not reflect how we think about the computational steps. Intuitively, we’d describe them as: \n Start with the value  . \n Then apply   to it. \n Then apply   to the result. \n Then apply   to the result. \n Then assign the result to  . \n The Hack pipe operator lets us express this intuition better: The F# pipe operator   # The F# pipe operator is roughly similar to the Hack pipe operator. However, it doesn’t have the special variable  . Instead, expects a function at its right-hand side and applies that function to its left-hand side. Therefore, the following two expressions are equivalent: F# pipe is better at chaining   (one-parameter) functions   # The following three statements are equivalent: We can see that Hack pipe is more verbose than F# pipe in this case. Currying: important for the F# pipe operator but not a good fit for JavaScript   # F# pipe works well in functional programming languages with built-in support for  . What is currying? Normal (uncurried) functions can have zero or more parameters – for example:  functions have at most one parameter – they are  . Functions with more parameters are emulated via unary functions that return functions: Currying makes it easy to create functions where the initial arguments are   (filled in). For example, these are three ways of defining the same function: With currying, piping into a function with more than one parameter is concise: Alas, currying has downsides when used in JavaScript: \n \n Currying can only fill in initial parameters. That works well in functional programming languages where the parameter with the data to operate on comes last (e.g.  ). However, JavaScript’s functions are not structured that way and methods are often used, too. \n \n \n I dislike using the same operator – function invocation – for both function calls and partial application: I prefer seeing immediately if a function is called or partially applied. With currying, I often can’t tell the difference – especially if I don’t know the signature of a function. \n \n \n Currying doesn’t work with the named parameter pattern: We can’t curry a function that uses this pattern. \n \n \n Currying doesn’t work with parameter default values: If omitting parameters triggers partial application, we can’t use it to trigger default values. \n \n For more information, see  “Currying is not idiomatic in JavaScript” . # The   in Hack pipe expressions could be considered an operator for partial application. For example, the following two expressions are equivalent: Hack pipe is better at: method calls, operators, literals,  ,     # To use the following constructs, we need arrow functions: For   and  , we’d need special syntax – e.g.: F# pipe is better at destructuring   # With the F# pipe, we can use a unary function to destructure an input value: With the Hack pipe we have to either avoid destructuring: Or we have to use an immediately-invoked arrow function: Should do-expressions ever be added to JavaScript, we could destructure via a variable declaration: Use cases for the pipe operator   # There are three common kinds of use cases for the pipe operator: \n Flat syntax for nested function calls \n Post-processing values: Given a value, we can apply a function by only adding code   it – where normal function calls require code before and after the value. \n Chaining for non-method language constructs \n We’ll explore these use cases via Hack pipe, but they are also use cases for F# pipe. Flat syntax for nested function calls   # # All iterators created by the JavaScript standard library have a common prototype. That prototype is not directly accessible, but we can retrieve it like this: With the pipe operator, the code becomes easier to understand: # Mixin classes  are a pattern where we use functions as factories for subclasses to emulate multiple inheritance. For example, these are two mixin classes: Both return a subclass of a given class  . Without the pipe operator, these mixins are used as follows: With the pipe operator, we get: Post-processing values   # With the pipe operator, we can write functions such as   that post-process values in some manner: We can see that the Hack pipe is more verbose here than the F# pipe would be. More on that later. # Consider the following function: How would we change this code to log the result of   before it is returned? Without the pipe operator, we’d have to introduce a temporary variable or wrap a function call around the operand of  . With the pipe operator, we can do this: In line A, we used  the comma operator . To evaluate the following expression: JavaScript first evaluates   and then   and then returns the latter result. # In the following code, the value that we post-process is a function – we add a property to it: The previous code is equivalent to: We could also have used the pipe operator like this: # Tagged templates  are one way of post-processing template literals. The pipe operator can also do that: Note that template literals have access to more data than functions we apply via pipe. They are therefore considerably more powerful – for example,   can only be done via a template literal. If a pipe-triggered function call is enough, we get the benefit of being able to apply multiple post-processing operations at the same time and can even combine those with a template literal (as is done in the example). Chaining for non-method language constructs   # # Thanks to the pipe operator, we can chain operations similarly to how we can chain method invocations: This code is easy to read and less verbose than introducing intermediate variables. # We can chain methods such as the Array methods   and  . However: \n They are a fixed set of operations that is built into a class. There is no way to add more Array methods via a library. (A library could create a subclass but that doesn’t help us if we get an Array from somewhere else.) \n Tree-shaking (dead code elimination) is difficult if not impossible with methods. \n With the pipe operator, we can chain functions as if they were methods – without the two aforementioned downsides: Summary: Hack pipe vs. F# pipe   # Strengths of F# pipe: \n Is better if we have code that uses currying. \n Is less verbose when working with unary functions – e.g. when post-processing values. \n Destructuring is slightly easier. \n Strengths of Hack pipe: \n Works better with typical (uncurried) JavaScript code and functions with an arity higher than 1. \n Supports   and   (without special syntax). \n TC39 is currently only persuing the Hack pipe.  Concerns against F# pipe  include: \n Memory performance (due to the creation and invocation of functions) \n Difficult to make   and   work \n Might encourage a split in the ecosystem between code that uses currying and code that doesn’t. \n How likely is it that JavaScript gets a pipe operator?   # Progress is being made on the Hack pipe, but F# is not being persued anymore (for details, see  the Hack operator proposal ). Potential improvements for Hack pipe and F# pipe   # In this section, we examine ways in which the two operators could be improved. However, it’s not always clear if the added complexity would be worth it. F# pipe: better support for functions with arities greater than 1   # If JavaScript had a partial application operator ( as proposed here ), then using F# pipes would look almost the same as using Hack pipes: A few downsides remain, though: \n Memory performance doesn’t improve (we still need function calls). \n Doesn’t work with operators such as  . \n Doesn’t work with   and  . \n Smart pipelines: Hack pipes with optional     # We could make Hack pipe less verbose in the unary case: \n Is there a   in the right-hand side of the   operator? \n If yes, then   works like the Hack pipe. \n If not, then   works like the F# pipe. \n Example: Note that line A is different than the normal Hack pipe. A proposal for this approach  has been discarded, but it could be revived as an add-on for Hack pipes. An extra operator for unary functions that complements the Hack pipe   # We could complement the Hack pipe with a special operator   for unary functions that works like the F# pipe (line A): Do we really need a pipe operator? What are the alternatives?   # In this section, we look at alternatives to the pipe operator. They are quite elegant but all have the following downsides: \n They are only good at chaining, not at post-processing. \n Even if verbosity is only a little increased per processing step, it adds up and makes a built-in pipe operator more convenient. \n    # One alternative to a pipe operator is to use a function – for example, the proposed  : Thanks to arrow functions, this approach is less verbose than we might expect. Its downsides are: \n We can’t use   and  . \n Functions are created and invoked. \n Using intermediate variables   # We could use intermediate variables: On one hand, that’s more verbose than piping. On the other hand, the variable names describe what is going on – which can be useful if a step is complicated. Reusing a variable multiple times   # The following technique  is a variation of the previous technique – it reuses a short variable name such as  : (I’m not sure who deserves credit for this technique; I’ve first seen it used  here .) We save characters due to the shorter variable name and because we don’t need one variable declaration per step. A downside of this technique is that it can’t be used multiple times within the same scope. And there is no simple way of wrapping a code block around such a code fragment, either. However, we can fix that via an immediately-invoked Arrow function: Props to  @emnudge  for suggesting using a parameter default value. Share your use cases!   # Is there an interesting use case for the pipe operator that I missed? Let us know in the comments. Further reading   # \n Blog post  “Currying versus partial application (with JavaScript code)” \n Blog post  “Currying is not idiomatic in JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/02/wrapper-objects.html", "title": "What are wrapper objects for primitive values?", "content": "What are wrapper objects for primitive values? dev javascript jslang This blog post is first in a series of two: What are wrapper objects for primitive values? How do primitive values get their properties? Each of the primitive types  ,  ,  ,   and   has an associated   ( ,  ,  ,  ,  ). In this blog post, we examine what these classes are good for. \n   \n     Wrapper classes for primitive types \n   \n   \n     Instantiating wrapper classes \n     \n       \n         Generically wrapping primitive values \n       \n       \n         Unwrapping primitive values \n       \n       \n         Primitive values vs. wrapper objects \n       \n     \n   \n   \n     Function-calling wrapper classes \n   \n   \n     Further reading \n   \n Wrapper classes for primitive types   # This is an exhaustive list of JavaScript’s primitive values: \n \n \n booleans \n numbers \n bigints \n strings \n symbols \n Each primitive type (except for the types of   and  ) has a corresponding  : \n \n \n \n \n \n The key purpose of these classes is to provide properties (mostly methods) for primitive values. We’ll see how exactly that works in the second of this series of blog posts. This is an example: There are two ways of invoking wrapper classes: \n \n All wrapper classes can be function-called, which converts an arbitrary value to the primitive type that the class represents. This is a descriptive way of converting to primitive types and I recommend it. \n \n \n Only the wrapper classes  ,  , and   can be instantiated via  . Doing this (explicitly) is almost never useful for programmers. \n \n Instantiating wrapper classes   # The wrapper classes  ,  , and   can be instantiated via  : That is,   wraps a primitive string and produces a wrapper object. The wrapper classes   (ES2020) and   (ES6) are relatively new and can’t be instantiated: Generically wrapping primitive values   # In addition to wrapping a primitive value by  -invoking a wrapper class, we can also do so generically by function-calling   (the class of most objects): With  , we can even create instances of   and   (even though those classes can’t be  -invoked): As an aside, if the argument of   is an object, it is simply returned without any changes: Unwrapping primitive values   # The generic way of unwrapping a wrapper object is method  : Primitive values vs. wrapper objects   # Interestingly, the primitive value   is not an instance of the wrapper class  :  also shows us that   is primitive, but   is an object: That is, the values of a primitive type are different from the instances of the associated wrapper class. In day-to-day programming, I pretend that wrapper objects don’t exist. They are used under the hood but rarely useful elsewhere. For more information on the differences between primitive values and objects, see  “JavaScript for impatient programmers” . Function-calling wrapper classes   # Function-calling wrapper classes provides us with a descriptive way of converting arbitrary values to primitives:  has a special status in that it is more of a factory function for symbols (whose parameter is a string that describes the created symbol) than a conversion function: Function-applying a wrapper class to one of its instances, unwraps that instance: Further reading   # The following chapters in  “JavaScript for impatient programmers”  explain primitive values: \n Chapter “Values”  [primitive values vs. objects] \n Chapter “Booleans” \n Chapter “Numbers” \n Chapter “Bigints – arbitrary-precision integers” \n Chapter “Strings” \n Chapter “Symbols” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/03/properties-of-primitives.html", "title": "How do primitive values get their properties?", "content": "How do primitive values get their properties? dev javascript jslang This blog post is second in a series of two: What are wrapper objects for primitive values? How do primitive values get their properties? JavaScript has two kinds of values: \n primitive values ( ,  , booleans, numbers, bigints, strings, symbols) \n objects (all other values) \n The ECMAScript specification states : A primitive value is a datum that is represented directly at the lowest level of the language implementation. However, despite this fact, we can still use primitive values (other than   and  ) as if they were immutable objects: This blog post answers the following question: How do primitive values get their properties? We’ll look at: \n Getting property values \n Invoking property values (a.k.a. method calls) \n Setting property values \n Each time, we’ll first examine what’s going on via JavaScript code and then investigate how the language specification explains the phenomena. Note that JavaScript engines only mimick the   behavior of the language specification. Some of what the spec does   is not very efficient (e.g. wrapping primitive values) and often done differently in engines. \n   \n     Required knowledge \n   \n   \n     References: referring to storage locations in the specification \n   \n   \n     Referring to the property of a primitive produces a property reference \n   \n   \n     Getting references \n     \n       \n         JavaScript: getting \n       \n       \n         Language specification: getting \n       \n     \n   \n   \n     Invoking references \n     \n       \n         JavaScript: invoking \n       \n       \n         Language specification: invoking \n       \n     \n   \n   \n     Assigning to references \n     \n       \n         JavaScript: changing existing properties \n       \n       \n         JavaScript: creating new properties \n       \n       \n         Language Specification: assigning to references \n       \n       \n         Language specification: Why are primitive values not extensible? \n       \n     \n   \n   \n     Further reading \n   \n Required knowledge   # In order to understand this blog post, you should be loosely familiar with the following two topics. \n \n The primitive types  ,  ,  ,  , and   have the associated    ,  ,  , and  .  The previous blog post  has more information on them. \n \n \n JavaScript has two different modes for executing code: \n \n The cleaner  :\n \n Is switched on implicitly in modules and classes. \n Must be switched on explicitly elsewhere. \n \n \n The older   (a.k.a.  ). \n \n For more information on these modes, see  JavaScript for impatient programmers . \n \n References: referring to storage locations in the specification   # When performing operations such as getting, setting or invoking, the affected storage locations could be: \n Property references ( ,  ) \n Super references ( ,  ) \n Private references ( ) \n Variable references ( ) \n The specification uses a single data structure,   (short: references) to represent all of these storage locations. That makes it easier to describe the operations. A reference record is an intermediate spec-internal value that represents storage locations. It has the following slots: \n \n  (language value, environment record,  ): the container in which a value is stored \n \n \n  (string, symbol, private name): the key of a binding. If the base is an environment record, it’s always a string. \n \n \n  (boolean):   if the reference was created in strict mode,   otherwise. \n \n \n  (language value,  ): only needed for super references (which need to preserve the value of  ). In other references, it is the spec-internal value  . \n \n Referring to a property in JavaScript code initially produces a reference that stores both the base and the property key. The following two spec operations illustrate how references work: \n \n  converts an intermediate value   (a spec-internal value or a language value) to a language value. This is done before storing a (possibly intermediate) value somewhere, before using a value as an argument in a function call, etc. If   is a reference, it is “dereferenced” and becomes a language value. In the process, the reference and its information is lost. We don’t know where the language value came from anymore. \n \n \n  stores a value   in a storage location   which must be a reference. For this operation, a reference provides crucial information: In which base (i.e., container) should we store  ? Where in the container should we store it? \n \n In the next section, we’ll explore how referring to the property of a primitive value produces a reference. In subsequent sections, we’ll see what happens when we are getting, invoking or assigning to references. Referring to the property of a primitive produces a property reference   # Consider the following syntax that refers to a property via the dot ( ) operator ( relevant section in the spec ):     If   evaluates to a primitive value, evaluation produces the following property reference record: \n : the primitive value that   evaluates to \n : the name of the property (a string) \n : a boolean indicating whether the property was mentioned in strict mode or not \n : is  \n Getting references   # Getting a reference is something that happens before an argument can be used by an invoked function and before a value can be stored somewhere. JavaScript: getting   # When we access an   (non-inherited) property of a primitive value, JavaScript converts the primitive value to an object by wrapping it. It then returns the value of the corresponding own property of the wrapper object: The previous interaction is relatively weak evidence that primitives get properties via wrapping. Inherited primitive properties also come from wrapper objects. And here the evidence is stronger: We’ll get definitive proof for the role of wrapping next, by looking at the language specification. Language specification: getting   # The spec operation   is the final step when evaluating an expression (syntax) to an actual JavaScript value. In converts a spec-internal value or a language value to a language value. If   is applied to a reference   that was created by accessing a property of a primitive value (see previous section), the following steps happen: \n Let   be  . This is an important step – see below why. \n The property value is read from   via a spec-internal method: \nThe second parameter is only needed for getters (which have access to the dynamic receiver of a property access). \n The most commonly used implementation of the internal method   is  the one of ordinary objects .\n \n It calls  the spec operation   which does the following:\n \n Traverse the prototype chain of   until you find a property  . If you can’t find a property, return  . \n If   is a data property, return its value. If   is an accessor with a getter, invoke it. Otherwise, return  . \n \n \n \n \n The crucial step is this one: Let   be to   ensures that   is an object, so that JavaScript can access the property whose name is  . In our case,   is primitive and   wraps it. This proves that getting the value of a property of a primitive is achieved by wrapping the primitive. Invoking references   # JavaScript: invoking   # We have already seen that all properties of primitive values come from wrapper objects – especially inherited properties (which most methods are): Let’s investigate what the value of   is when we invoke a method on a primitive value. To get access to  , we add two methods to   which are inherited by all wrapper classes: We create the methods via   because it always executes its “body” in non-strict mode. Let’s invoke the methods on a string: In strict mode,   refers to the (unwrapped) string. In sloppy mode,   refers to a wrapped version of the string. Language specification: invoking   # In the previous subsection, we have seen that when we invoke a method on a primitive value  , there are two important phenomena: The method is looked up in a wrapped version of  . In strict mode,   refers to  . In sloppy mode,   refers to a wrapped version of  . In the spec, a method call is made by invoking (second   rule) a property reference (first   rule). These are  the relevant syntax rules : \n  :\n \n     \n   \n (Remaining rules are omitted) \n \n \n  :\n \n   \n     \n     \n \n \n The evaluation of the second   rule is handled  as follows .   \n Let   be the result of evaluating  , a property reference. \n Let   be the result of  .\n \n  We have seen in the previous section that   wraps the base of a property reference so that it can read a property value. \n \n \n Next, a spec operation is called:   (we are ignoring  , as it’s not relevant to this blog post). \n  works as follows (I’m omitting a few steps that are not relevant here): \n Determine  :\n \n Is   a property reference? Then   is  .\n \n  returns   (if   is not a   reference).\n \n    is still primitive at this point. \n \n \n \n \n Otherwise,   is  . \n \n \n The   are evaluated and the result is assigned to  . \n If   is not an object or not callable, a   is thrown. \n A spec operation is invoked:  \n \n This operation returns  . \n \n \n If   is an ordinary function,  its implementation   is invoked: \n  is a new  execution context  (with storage for parameters and more) that is created for the current call. \n \n A spec operation is called –  :\n \n The operation checks  :\n \n : don’t create a   binding (  is an arrow function) \n :   is bound to  . Therefore:\n \n  is   if   didn’t come from a property reference. \n  is primitive if   came from a primitive property reference.\n \n    is not wrapped in strict mode. \n \n \n \n \n Otherwise we are in sloppy mode:\n \n If   is   or  :\n \n Let   be  .  A realm  is one “instance” of the JavaScript platform (global data etc.). In web browsers, each iframe has its own realm. \n Let   be  \n \n \n Otherwise,   is bound to  .\n \n    is wrapped in sloppy mode. \n \n \n \n \n \n \n \n \n Assigning to references   # JavaScript: changing existing properties   # In strict mode, we get an exception if we try to change an existing property of a primitive value (in sloppy mode, there is a silent failure): Why doesn’t that work? The primitive value is wrapped before the assignment happens and all own properties of a wrapped string are non-writable (immutable): For information on property descriptors, see  “Deep JavaScript” . JavaScript: creating new properties   # We also can’t create new properties for primitive values. That fails with an exception in strict mode (silently in sloppy mode): Why that doesn’t work is more complicated this time. As it turns out, we can add properties to wrapped primitive values: So, wrapper objects are clearly   (new properties can be added): However, primitive values are not extensible: Language Specification: assigning to references   # In this subsection, we explore two phenomena: Primitive values are wrapped before assignment happens. That’s why existing (own and inherited) properties can’t be changed. We can’t add new properties to primitive values. This is the syntax for assigning:     Its evaluation  consists of the following steps: \n Let   be the result of evaluating  . \n Let   be the result of evaluating  . \n Let   be  . \n Perform  . \n Return  . \n The spec operation   performs the actual assignment: \n Let   be  .\n \n  The primitive value in   is wrapped before setting. \n \n \n Let   be  .\n \n Note that the last argument is a primitive value. It is used when invoking a setter, which has access to   (as with methods, unwrapped in strict mode, wrapped in sloppy mode). \n \n \n If   is   and   is  , throw a   exception. That is, in strict mode, there is an exception, in sloppy mode a silent failure. \n The most commonly used implementation of the internal method   is  the one of ordinary objects : \n Return  .\n \n Let   be  .\n \n  describes property   prior to assigning. It determines if an assignment can be made – e.g.: If   isn’t writable, we can’t assign to it. \n \n \n Return  .\n \n If the own property descriptor   is   (which means there is no own property whose name is  ): Try to find a setter by traversing the prototype chain of  . Note that   always points to where setting started.\n \n If that isn’t successful, assign a default data property descriptor to  : \n \n \n \n Is   a data descriptor?\n \n If   isn’t writable, return  .\n \n  If an inherited or own property is read-only, we can’t assign to it. \n \n \n If   is not  , return  .\n \n  We can’t add new properties to primitive values. \n \n \n \n \n (The remaining steps are omitted.) \n \n \n \n \n Language specification: Why are primitive values not extensible?   # In this subsection we explore why primitive values are not extensible.  is specified as follows: \n If   is not  , return  .\n \n This explains the result for primitive values. \n \n \n Return  .\n \n Return  .\n \n  of ordinary objects : \n :\n \n Return   (a boolean) \n \n \n \n \n \n \n Further reading   # \n \n Blog post on references in JavaScript:  “Why is   not a method call?” \n \n \n Section “Strict mode vs. sloppy mode”  in “JavaScript for impatient programmers” \n \n \n Chapter “Property attributes: an introduction”  in “Deep JavaScript” [  of properties, encoding them via  ] \n \n \n Chapter “Protecting objects from being changed”  in “Deep JavaScript” [levels of protecting an object:  ,  ,  ] \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/03/array-find-last.html", "title": "ECMAScript proposal: searching Arrays from end to start via  .findLast()  and  .findLastIndex()", "content": "ECMAScript proposal: searching Arrays from end to start via   and  dev javascript es proposal This blog post describes the ECMAScript proposal  “Array find from last”  by Wenlu Wang and Daniel Rosenwasser. \n   \n     Topic of this blog post: methods of Arrays and of Typed Arrays \n   \n   \n     Searching Arrays \n   \n   \n     Simple implementations \n   \n   \n     Availability \n   \n   \n     Further reading \n   \n Topic of this blog post: methods of Arrays and of Typed Arrays   # In this blog post, we explore methods of Arrays. But everything we learn also applies to  Typed Arrays . Searching Arrays   # The following three methods search Arrays from start to end: So far, only   has a version that searches from end to start: The proposal introduces such versions for   and  : Simple implementations   # The following code shows simple implementations (fewer checks than the actual implementations) of   and  : Availability   # The proposal mentions  2 polyfills  that are currently available. Additionally libraries such as  Lodash and Ramda  also provide the operations   and   for Arrays. Further reading   # \n Section “Searching elements:  ,  ”  in “JavaScript for impatient programmers” \n Chapter “Arrays”  in “JavaScript for impatient programmers” \n Chapter “Typed Arrays: handling binary data”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/03/naming-conflicts.html", "title": "JavaScript naming conflicts: How existing code can force proposed features to be renamed", "content": "JavaScript naming conflicts: How existing code can force proposed features to be renamed dev javascript jslang Sometimes the name of a proposed feature (a method, a global variable, etc.) clashes with existing code and has to be changed. This blog post explains how that can happen and lists features that were renamed. \n   \n     Evolving JavaScript: Don’t break the web! \n   \n   \n     Source of conflict: adding methods to built-in prototypes \n     \n       \n         Term: monkey patch \n       \n       \n         Reasons against changing built-in prototypes \n       \n       \n         Examples of proposed prototype methods whose names had to be changed \n       \n       \n         Modifying built-in prototypes wasn’t always considered bad style \n       \n     \n   \n   \n     Source of conflict: checking for the existence of a property \n   \n   \n     Source of conflict: checking for the existence of a global variable \n   \n   \n     Source of conflict: creating local variables via  \n     \n       \n         JavaScript’s   statement \n       \n       \n         Conflicts due to  \n       \n       \n         Unscopables: preventing conflicts caused by  \n       \n     \n   \n   \n     Conclusion \n   \n   \n     Further reading \n   \n Evolving JavaScript: Don’t break the web!   # One core principle for evolving JavaScript is to not “break the web”: All existing code must continue to work after a new feature is added to the language. The downside is that existing quirks can’t be removed from the language. But the upsides are considerable: Old code continues to work, upgrading to new ECMAScript versions is simple, etc. For more information on this topic, see  section “Evolving JavaScript: Don’t break the web”  in “JavaScript for impatient programmers”. When a name is chosen for a new feature such as a method name, one important test is to add that feature in a   (an early pre-release) of a browser and check if any websites exhibit bugs. The next sections cover four sources of conflict where that was the case in the past and features had to be renamed. Source of conflict: adding methods to built-in prototypes   # In JavaScript, we can add methods to built-in values by changing their prototypes: It’s fascinating that the language can be changed in this manner. This kind of runtime modification is called a  . The next subsection explains that term. Then we’ll look at the downsides of such modifications. Term: monkey patch   # If we add methods to built-in prototypes, we are modifying a software system at runtime. Such modifications are called  . I try to avoid jargon, including this term, but it’s good to be aware of it. There are two possible explanations for its meaning (quoting  Wikipedia ): \n \n It came “from an earlier term,  , which referred to changing code sneakily – and possibly incompatibly with other such patches – at runtime. The word  , homophonous with   (or nearly so), became  , possibly to make the patch sound less intimidating.” \n \n \n It “refers to ‘monkeying about’ with the code (messing with it).” \n \n Reasons against changing built-in prototypes   # With any kind of global namespace, there is always a risk of name clashes. That risk goes away when there are mechanisms to resolve conflicts – for example: \n \n Global modules  are identified  via bare module specifiers or URLs. Name clashes among the former are prevented via the npm registry. Name clashes among the latter are prevented via domain name registries. \n \n \n Symbols  were added to JavaScript to avoid name clashes between methods. For example, any object can become iterable by adding a method whose key is  . Since each symbol is unique, this key never clashes with any other property key. \n \n However, methods with string keys can cause name clashes: \n Different libraries might use the same name for methods they add to  . \n If a name is already used by a library anywhere, it can’t be used for a new feature of JavaScript’s standard library anymore. There are several cases where that was an issue. They are described in the next section. \n Ironically, being careful with adding a method can make matters even worse – for example: Here, we check if a method already exists. If not, we add it. This technique works if we are implementing a   that adds a new JavaScript method to engines that don’t support it. (That’s a legitimate use case for modifying built-in prototypes, by the way. Maybe the only one.) However, if we use this technique for a normal library method and JavaScript later gets a method with the same name, then the two implementations work differently and all code that uses the library method breaks when it uses the built-in method. Examples of proposed prototype methods whose names had to be changed   # \n \n The ES6 method   was originally  , which clashed with a method that was added globally by  the JavaScript framework MooTools  ( bug report ). \n \n \n The ES2016 method   was originally   which clashed with a method added by MooTools ( bug report ). \n \n \n The ES2019 method   was originally   which clashed with MooTools ( bug report ,  blog post ). \n \n Modifying built-in prototypes wasn’t always considered bad style   # You may be wondering: How could the creators of MooTools have been so careless? However, adding methods to built-in prototypes wasn’t always considered bad style. Between ES3 (December 1999) and ES5 (December 2009), JavaScript was a stagnant language. Frameworks such as MooTools and Prototype improved it. The downsides of their approaches only became obvious after JavaScript’s standard library grew again. Source of conflict: checking for the existence of a property   # The ES2022 method   was originally  . It had to be renamed because the following libraries checked for property   to determine if an object is an HTML collection (and not an Array):  Magic360 ,  YUI 2 ,  YUI 3  ( related section in the proposal ). Source of conflict: checking for the existence of a global variable   # Since ES2020, we can access the global object via  . Node.js has always used the name   for this purpose. The original plan was to standardize that name for all platforms. However, the following pattern is used frequently to determine the current platform: This pattern (and  similar ones ) would break if browsers also had a global variable named  . Therefore, the standardized name was changed to  . Source of conflict: creating local variables via     # JavaScript’s   statement   # Using  JavaScript’s   statement  has been discouraged for a long time and was even made illegal in  , which was introduced in ECMAScript 5. Among other locations, strict mode is active in ECMAScript modules. The   statement turns the properties of an object into local variables: Conflicts due to     # The framework Ext.js uses code that is loosely similar to the following fragment: When the ES6 method   was added to JavaScript, it broke   if it was called with an Array (line B): The   statement turned all properties of the Array   into local variables. One of them was the inherited property  . Therefore, the statement in line A logged  , not the parameter   anymore ( bug report 1 ,  bug report 2 ). Unscopables: preventing conflicts caused by     # The public symbol   lets an object hide some properties from the   statement. It is used only once in the standard library, for  : The list of unscopables consists of   and methods introduced alongside or after it. Conclusion   # We have seen four ways in which proposed JavaScript constructs can name-clash with existing code: \n Adding methods to built-in prototypes \n Checking for the existence of a property \n Checking for the existence of a global variable \n Creating local variables via  \n Some sources of conflict are difficult to predict, but a few general rules exist: \n Don’t change global data. \n Avoid checking for existence or non-existence of global data. \n Be aware that built-in values might get additional properties in the future (own or inherited ones). \n The safest way for a library to provide functionality for JavaScript values is via functions. Should JavaScript get  a pipe operator , we could even use them like methods. Question for readers: Did I forget any interesting cases where proposed names had to be changed? Further reading   # \n \n Section “Evolving JavaScript: Don’t break the web”  in “JavaScript for impatient programmers” \n \n \n Section “Polyfills: emulating native web platform features”  in “JavaScript for impatient programmers” \n \n \n Section “Strict mode vs. sloppy mode”  in “JavaScript for impatient programmers” \n \n \n Section “The   statement”  in “Speaking JavaScript” \n \n \n Chapter “Symbols”  in “JavaScript for impatient programmers” \n \n \n Section “Property key  ”  in “Exploring ES6” \n \n \n Blog post “A pipe operator for JavaScript: introduction and use cases” \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/04/shadow-realms.html", "title": "ShadowRealms – an ECMAScript proposal for a better  eval()", "content": "ShadowRealms – an ECMAScript proposal for a better  dev javascript es proposal \n Update 2022-04-05:\n \n Rewrote section “The global data in ShadowRealms is a subset of the platform’s global data”. \n New section “Uncaught errors thrown in evaluated code”. \n A longer explanation in section “A simple library for transferring objects across realms” \n Added Rick Waldron to the list of authors/champions. \n \n \n This blog post describes the ECMAScript proposal  “ShadowRealm API”  by Dave Herman, Caridy Patiño, Mark S. Miller, Leo Balter, and Rick Waldron. Class   provides a new way of evaluating code at runtime – think   but better: \n Each instance has its own global JavaScript scope. \n Code is evaluated in that scope. If it changes global data, that only affects the ShadowRealm, but not the real global data. \n \n   \n     Realms \n   \n   \n     The ShadowRealm API \n     \n       \n         \n       \n       \n         \n       \n       \n         Uncaught errors thrown in evaluated code \n       \n       \n         The global data in ShadowRealms is a subset of the platform’s global data \n       \n       \n         How Content Security Policy (CSP) affects ShadowRealms \n       \n     \n   \n   \n     Passing values between realms \n     \n       \n         Non-callable objects can’t cross realms \n       \n       \n         Functions are wrapped when they cross realms \n       \n     \n   \n   \n     How does   evaluate its code? \n     \n       \n         Pitfall: no static imports \n       \n       \n         The code is parsed as a sequence of statements \n       \n       \n         Scoping: sloppy mode vs. strict mode \n       \n     \n   \n   \n     How does   evaluate its code? \n   \n   \n     Getting objects into and out of ShadowRealms \n     \n       \n         A simple library for transferring objects across realms \n       \n     \n   \n   \n     Use cases for ShadowRealms \n     \n       \n         Running tests in ShadowRealms \n       \n       \n         Running web apps in ShadowRealms \n       \n     \n   \n   \n     Comparing ShadowRealms with other ways of evaluating code \n     \n       \n          and  \n       \n       \n         Web Workers \n       \n       \n         iframes \n       \n       \n         Module   on Node.js \n       \n     \n   \n   \n     Upcoming complementary proposals \n     \n       \n         Compartments \n       \n       \n         Module blocks proposal \n       \n     \n   \n   \n     Implementations \n   \n   \n     Acknowledgements \n   \n   \n     Further reading \n   \n Realms   # A   is an instance of the JavaScript platform: its global environment with all built-in data set up correctly. For example, each iframe has an associated realm: The global object of the document is different from the global object of the iframe (line A). Global variables such as   are different, too (line B). The ShadowRealm API   # Quoting  the proposal : The primary goal of this proposal is to provide a proper mechanism to control the execution of a program, providing a new global object, a new set of intrinsics, no access to objects cross-realms, a separate module graph and synchronous communication between both realms. ShadowRealms execute code with the same JavaScript heap as the surrounding context where the ShadowRealm is created. Code runs synchronously in the same thread.  is a class with the following type signature: Each instance of   has its own realm. Two methods allow us to evaluate code inside that realm: \n  synchronously evaluates a string   inside a ShadowRealm. This method is loosely similar to  . \n : asynchronously imports inside a ShadowRealm and returns the result via a Promise. That means we get non-blocking evaluation (for third-party scripts etc.). \n The realm in which we instantiate   is called the  . The instance is called the  .    # Method   has the following type signature:  works much like  : In contrast to  , the code is evaluated inside the realm of  : If   returns a function, that function is wrapped so that invoking it from the outside, runs it inside the ShadowRealm: Whenever a value is passed to or from a ShadowRealm, it must be primitive or callable. If not, an exception is thrown: More on passing values between realms later.    # Method   has the following type signature: Inside its ShadowRealm, it imports the named import whose name is   from a module whose specifier is   and returns its value asynchronously, via a Promise. As with   functions are wrapped so that invoking them from outside the ShadowRealm runs them inside the ShadowRealm: For now, the API requires the parameter  . In the future, omitting it may return (a Promise for) a module namespace object. Therefore, if we only want to load a module without importing anything (e.g. a polyfill that changes global data), we have to use a workaround – for example: As with  , values passed to or from ShadowRealms (incl. arguments and results of cross-realm function calls) must be primitive or callable. More on that soon. Uncaught errors thrown in evaluated code   # Syntax errors in the code lead to a   being thrown: An uncaught error inside a ShadowRealm is delivered via a  : Alas, at the moment we don’t get either name, message or stack trace of the original error. Maybe that will change in the future. The global data in ShadowRealms is a subset of the platform’s global data   # ShadowRealms contain the following global data: \n \n The global data of ECMAScript \n \n \n A subset of the platform-specific global data (such as   in browsers or   on Node.js). One key requirement is that all platform-specific properties of the global object must be configurable (which is one of  the attributes of properties ) so that they can be deleted. That gives us the option to hide those features from the code that we evaluate. \n \n How Content Security Policy (CSP) affects ShadowRealms   # \n Not allowing   for a page prevents synchronous evaluation via   in ShadowRealms. \n Directives such as   affect what modules can be loaded via  . \n Passing values between realms   # There are several ways in which values can be passed between an incubator realm and a child realm: \n Sending values to a ShadowRealm:\n \n Passing arguments to a function that comes from the ShadowRealm. \n \n \n Receiving values from a ShadowRealm:\n \n The results of   and  \n The result of invoking a function that comes from the ShadowRealm. \n \n \n Whenever a value crosses realms, the internal specification operation   is used to   it: \n \n A primitive value is returned without any changes. \n \n \n A callable object is wrapped in a  . More on wrapped functions later. \n \n \n Any other kind of object causes an exception: \n \n \n Non-callable objects can’t cross realms   # Why aren’t non-callable object allowed to cross realms? The goal is complete separation between realms: Code executed in a ShadowRealm should never be able to access its incubator realm. Objects have prototype chains. When transferring a prototype chain to another realm, we have two options: \n \n We could only copy the first object in the prototype chain and let the chain continue in another realm. Alas, almost all prototype chains give us access to   which lets us execute arbitrary code in the source realm (see code below). \n \n \n We could copy the complete prototype chain. However, there is no simple way to transfer objects such as   and  . \n \n Almost all objects have  the standard property   that refers to the class of the object: Via this property, we can get access to  : The ShadowRealms repository has  an issue  where this topic is discussed in more detail. The code above is inspired by  a blog post by Joseph Griego . We’ll see later how we can still transfer objects between realms (spoiler: it might be added as a feature in the future but can also be implemented via a library.) Functions are wrapped when they cross realms   # Whenever a function crosses realms, it is wrapped: \n The   is a function from a foreign realm. \n A so-called   wraps the wrappee. The wrapper protects the wrappee from the local realm and the local realm from the wrappee. \n This is how a wrapped function keeps realms separate: \n \n Function call arguments enter the wrappee’s realm and are wrapped for that realm (via  ). The implicit argument   is treated the same way. \n \n \n Values returned by the wrappee enter the wrapper’s realm and are wrapped for that realm. \n \n \n The wrappee is executed in a new scope whose parent scope is the birth scope of the wrappee. As a consequence, the global scope is the global scope of the wrappee’s realm. \n \n \n Only one feature of the wrappee is exposed: The wrapper forwards function calls. However:\n \n The wrapper can’t be  -invoked. \n Neither the wrappee’s properties nor its prototype can be accessed from the wrapper’s realm. \n \n \n Note that wrapped functions are never unwrapped: If a wrapper is passed back into the wrappee’s realm, it is simply wrapped again. For details, see  this issue . The following code demonstrates what happens if a sloppy-mode function from a ShadowRealm is wrapped and called: Its   is the   of the ShadowRealm, not the   of the incubator realm: This is what happens if the wrappee is a strict-mode function: How does   evaluate its code?   # Pitfall: no static imports   # In code parsed by  , we can’t use static imports. Why? Due to  top-level  , static imports can be asynchronous – and   is supposed to work synchronously. A workaround is to import dynamically via  : The code is parsed as a sequence of statements   # The grammar rule used by   is   – the same as it is for non-module   elements. That means, it consists of a sequence of statements. The following subsections explore what that means for the code. #  returns a value. How does it do that given that its input is a statement? In normal JavaScript code, statements don’t evaluate to values. However, the language specification defines so-called   for statements. Those are used by  ,  , browser consoles, REPLs, etc. We can use   to explore how completions work. The completion of an expression statement is the value of the expression: The completion of a code block is the completion of the last statement in that block: The completion of an   statement  is the completion of either the then-branch or the else-branch – depending on the condition: # There is a syntactic ambiguity between function declarations and function expressions. Ordinary function definitions are parsed as function declarations. That is,   does not consider the following code to be an anonymous function expression: The completion of a function declaration is  : If we want   to return a function, we must ensure that the function definition is parsed as an expression, which we can do by wrapping it in parentheses: Note that arrow functions don’t have this issue – they are always parsed as expressions: # Another syntactic ambiguity is between code blocks and object literals. Normally,   interprets curly braces as code blocks: If we want to create an object, we neeed to put parentheses around the curly braces: Scoping: sloppy mode vs. strict mode   # By default,   uses   and the so-called   is the global scope. That means that   declarations and function declarations create properties of  the global object : In contrast, a new   is created for each invocation of  . That environment is used by   and   declarations: In strict mode, the lexical environment (that is created freshly for each invocation) is also used as the   environment. Therefore,   declarations and function declarations don’t create properties of the global object: How does   evaluate its code?   # The code used by   is an ECMAScript module and we only import from the code. Therefore, none of the pitfalls of   exist: \n The module has its own scope whose parent scope is the global scope of the ShadowRealm. \n Modules are in strict mode by default. \n Getting objects into and out of ShadowRealms   # There currently is no built-in support for transferring objects across realms. It might be added in the future. One possibility (but this is just my guess) is for it to work like  transferrable objects  (which is used for moving objects between from and to web workers). However, transferring objects can also be implemented via a library. Caridy Patiño’s  IRealm  is a complete experimental solution. It is based on  . A simple library for transferring objects across realms   # Let’s explore what a very simply solution could look like. (Warning: don’t use this code in production. Among other things, it does not protect against code execution via  .) The approach is as follows: \n Each value in a foreign realm is   before it is transferred:\n \n A primitive value isn’t changed. \n An object (which may not be callable and therefore transferrable) is wrapped in a function (which is always transferrable). That function applies any  ECMAScript Proxy  trap with the name   and the arguments   to the wrapped object. \n The arguments passed to the wrapped object come from another realm and must be foreign-wrapped. \n The result of applying the trap will be transferred to another realm and must be local-wrapped. \n \n \n After crossing over, the value is  :\n \n A primitive value isn’t changed. \n A callable object (non-callable objects can’t be transferred) is wrapped in a Proxy whose handler feeds all trapped operations to the callable object. \n The arguments of the trapped operations will be sent to another realm and must be local-wrapped. \n The result of invoking the callable object comes from another realm and must be foreign-wrapped. \n \n \n One issue remains: When we evaluate code, we must post-process the result. It must first be local-wrapped in the ShadowRealm and then be foreign-wrapped in the incubator realm. Foreign-wrapping could be done by wrapping the ShadowRealm method  . But how do we local-wrap the evaluation result inside the ShadowRealm? As it turns out, an elegant solution is to transfer function   of the ShadowRealm: \n We first local-wrap it inside the ShadowRealm. \n After we receive it in the incubator realm, we foreign-wrap it. \n If we call the double-wrapped  , the argument is evaluated inside the ShadowRealm. The result will be properly wrapped (twice), as will be any data that we extract from it (by accessing properties etc.). For more information on JavaScript Proxies, see  the chapter on them in “Deep JavaScript” . Missing features of this library: \n \n It doesn’t preserve identity: If two values are equal in one realm, they should also be equal after they are transferred to another realm. That could be implemented by caching the results of wrapping in a WeakMap. \n \n \n It doesn’t prevent code executed in a ShadowRealm from accessing the   and   of the incubator realm. That can be achieved by pre-populating the cache WeakMap with entries that map the incubator   and   to functions that throw exceptions. \n \n Use cases for ShadowRealms   # What can ShadowRealms be used for? \n \n Web apps such as IDEs or paint apps can run third-party code such as plugins or filters. \n \n \n Programming environments can run user code in ShadowRealms. \n \n \n Servers can run third-party code in ShadowRealms. \n \n \n Test runners can run tests in ShadowRealms so that the incubator realm isn’t affected and each suite can start in a fresh realm (which helps with reproducibility). \n \n \n For web scraping (extracting data from web pages) and web app testing, web apps can be run in ShadowRealms. \n \n The next two sections explain the last two items in more detail. Running tests in ShadowRealms   # In this section we examine a very simple proof of concept of how we could run tests in ShadowRealms. The test library collects tests that are specified via   and lets us run them via  . Test code uses the library to specify tests: In the next example, we dynamically load module   to collect the tests and then run them. Alas, there is currently no way to load a module without importing anything. That’s why there is a default export in the last line of the previous example. We use the ShadowRealm method   to import that default export. Running web apps in ShadowRealms   # The library jsdom  creates an encapsulated browser environment which can be used to test web apps, extract data out of HTML, etc.  It currently uses the Node.js module   and could probably be updated to instead use ShadowRealms (with the benefit of the latter being cross-platform). Comparing ShadowRealms with other ways of evaluating code   #  and     # ShadowRealms are similar to   and   but improve on them: We can create new realms and evaluate code in them. That protects the realm that triggers the evaluation from the actions performed by the code. Web Workers   # Web Workers are an even stronger isolation mechanism than ShadowRealms. Code in them runs in separate processes and communication is asynchronous. Therefore, ShadowRealms are a good choice whenever we want something more lightweight. We get the convenience of synchronous evaluation and have more freedom w.r.t. setting up global data. iframes   # As we have seen, each iframe has its own realm. We can synchronously execute code inside it: Compared to ShadowRealms, there are the following downsides: \n We can only use iframes in browsers. \n We need to add an iframe to the DOM in order to initialize it.\n \n Afterwards, we can detach the iframe, but then   won’t work anymore. \n \n \n Each iframe realm contains the complete DOM, which makes some customizations impossible. \n By default, objects can cross realms which means extra work is required to ensure safe code evaluation. \n Module   on Node.js   # Node’s   module  is similar to the ShadowRealm API but has more features: caching JavaScript engine data for faster startup, intercepting  , setting up the global object externally (via  ), etc. Upcoming complementary proposals   # Compartments   # The proposal for   is currently at stage 1. It could build on ShadowRealms and allows the us to further control evaluation: \n We can intercept static and dynamic imports. \n We can configure the locale of the child realm. \n Etc. \n Module blocks proposal   # The proposal for   is currently at stage 2 enables us to nest modules: We can create module blocks inside modules and each one of them defines a module. Module blocks can be used in many locations where we currently use module specifiers. That makes them convenient for  : Implementations   # \n Leo Balter and Rick Waldron have written  a ShadowRealms polyfill . \n Starting with  Safari Technology Preview 142 , Safari supports ShadowRealms (without flags). \n Acknowledgements   # The following people provided important feedback to this blog post: \n Caridy Patiño \n Leo Balter \n Allen Wirfs-Brock \n Further reading   # Sources of this blog post: \n \n ECMAScript proposal “ShadowRealm API”  by Dave Herman, Caridy Patiño, Mark S. Miller, Leo Balter, and Rick Waldron. \n \n \n The proposal has  a section that lists presentations  whose slides I found helpful. \n \n Related topics: \n \n Section “Strict mode vs. sloppy mode”  in “JavaScript for impatient programmers” \n \n \n Section “Global variables and the global object”  in “JavaScript for impatient programmers” \n \n \n Chapter “Evaluating code dynamically:  ,  ”  in “JavaScript for impatient programmers” \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/07/css-layout-soon-good-enough-for-guis.html", "title": "CSS layout: soon good enough for GUIs", "content": "CSS layout: soon good enough for GUIs dev webdev layout The ultimate CSS layout spec for webapps PDF high \n CSS Template Layout Module : lets one specify grid-based layouts in a really neat ASCII-art-like way. Go to “ CSS Template Layout demos ” to see examples. \n \n \n css-template-layout : implements template layout in current browsers via JavaScript. \n \n Flexible Box Layout Module : is “based on the box model in the XUL user-interface language used for the user interface of many Mozilla-based applications (such as Firefox)”. To get a grid, you need to nest several boxes. I prefer template layout's more direct approach. \n \n CSS Grid Positioning Module Level 3 : mainly for document layout (multi-column layout etc.). \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/05/rfc-9239.html", "title": "RFC 9239: Updates to ECMAScript media types", "content": "RFC 9239: Updates to ECMAScript media types dev javascript (This blog post is based on  a tweet thread  and additional input by Mathias Bynens.) After work started on it in August 2017, May 2022 finally saw the publication of  RFC 9239 “Updates to ECMAScript media types”  by  Matthew A. Miller ,  Myles Borins ,  Mathias Bynens , and  Bradley Farias . It updates JavaScript MIME type registrations to align with reality: \n The JavaScript MIME type is now unambiguously  . \n  is now a registered filename extension, specifically for JavaScript modules. \n This unblocks tooling and server software like Apache to support JavaScript modules out of the box in a unified manner, like e.g. Node.js already does. Better industry alignment on MIME type and file extensions increases interoperability across tooling and other software. What are the consequences of   now being the only standard MIME type for JavaScript?   #  is now the only standard MIME type for JavaScript.  All others  are considered  historical and obsolete aliases. That doesn’t change anything in practice because web browsers still have to accept all JavaScript MIME types. But it resolves a long-standing disagreement between standards: \n The HTML Standard acknowledged that   is the most commonly used type:\n \n “the MIME type used to refer to JavaScript in this specification is  ” \n “Servers should use   for JavaScript resources. Servers should not use other JavaScript MIME types for JavaScript resources, and must not use non-JavaScript MIME types.” \n \n \n IANA/IETF:\n \n previously recommended  \n previously called   “obsolete” \n \n \n Do we have to use the filename extension   for modules now?   # The RFC does not mean that we have to use the filename extension   for modules – we can continue to use whatever extension we like. In other words, this RFC is good news for everyone – regardless of personal preferences w.r.t. filename extensions. Let’s examine how filename extensions work on various JavaScript platforms. Module filename extensions on Node.js   # On Node.js we have two options: \n Use   without configuration. \n Use   and add   to  . \n We can also pass “string input” to Node.js via  ,  , or standard input. To interpret such input as an ECMAScript module, use  . Module filename extensions on Deno   # Deno supports the filename extensions  ,  , and  . Files with these extensions are always interpreted as ECMAScript modules (in TypeScript syntax if the extension is  ). Module filename extensions on web browsers   # Web browsers don’t care about filename extensions at all, only about MIME types. Therefore, we can use any filename extension as long as our web server serves the files as  . Further reading   # \n “Publishing and consuming ECMAScript modules via packages – the big picture” \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/07/emacs-org-mode-notes-planning.html", "title": "Emacs org-mode: notes, planning, authoring – in plain text", "content": "Emacs org-mode: notes, planning, authoring – in plain text hci software computers organizing \n Everything is text. This does have disadvantages, but the advantages are obvious: easily exchanged by email, put into version control, a format many applications understand, etc. \n Outlining \n Hyperlinks to emails, web pages, files, etc. inside content \n \n Meta-data such as tags and dates attached to content \n \n Tables: continuously aligns all the cells of a column and can move columns around. \n \n Spreadsheets: you can perform calculations in tables \n \n Publishing: content can be published as HTML and LaTeX \n \n \n The org-mode web site \n Google tech talk on org-mode \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/05/rest-vs-spread.html", "title": "The triple dot syntax ( ... ) in JavaScript: rest vs. spread", "content": "The triple dot syntax ( ) in JavaScript: rest vs. spread dev javascript In JavaScript, the same syntax – triple dots ( ) – is used for two different mechanisms: \n Rest syntax is for receiving data. \n Spreading is for sending data. \n This blog post examines how these mechanisms work and why they are not operators. \n   \n     Receiving data: rest syntax \n   \n   \n     Sending data: spreading \n   \n   \n     Rest and spread are not operators \n   \n   \n     Further reading (use cases etc.) \n   \n Receiving data: rest syntax   # A rest parameter is a special kind of parameter that receives all remaining arguments of a function call via an Array: We can also use rest syntax in Array-destructuring: And we can use it in object-destructuring: Sending data: spreading   # Spreading into a function call turns Array elements into function call arguments. We can also spread Arrays into Array literals: And we can spread objects into object literals: Rest and spread are not operators   # Operators such as   or   are used to write independent expressions that evaluate to values. Those expressions can be used in many contexts. In contrast, rest and spread are part of their surroundings. That’s why they shouldn’t be called operators: \n Rest syntax: rest parameters (function definitions), rest elements (Array-destructuring), rest properties (object-destructuring) \n With spreading, I usually say: “spreading into ...” (function calls, Array literals, object literals). \n Further reading (use cases etc.)   # Rest syntax: \n Rest parameters \n Destructuring via rest elements \n Destructuring via rest properties \n Spreading: \n Spreading into function calls \n Spreading into Array literals \n Spreading into object literals \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/04/change-array-by-copy.html", "title": "ECMAScript proposal “Change Array by copy”: four new non-destructive Array methods", "content": "ECMAScript proposal “Change Array by copy”: four new non-destructive Array methods dev javascript es proposal This blog post describes the ECMAScript proposal  “Change Array by copy”  by Robin Ricard and Ashley Claymore. It proposes four new methods for Arrays and Typed Arrays: \n \n \n \n \n \n   \n     The new methods are for Arrays and TypedArrays \n   \n   \n     Destructive vs. non-destructive Array methods \n     \n       \n         Destructive Array methods \n       \n       \n         The new non-destructive methods \n       \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     The new methods will also be available for Tuples \n   \n   \n     Implementations \n   \n   \n     Further reading \n   \n The new methods are for Arrays and TypedArrays   # This blog post only demonstrates the new methods with Arrays, but they are also available for Typed Arrays – that is, instances of the following classes: \n \n \n \n \n \n \n \n \n \n \n \n Destructive vs. non-destructive Array methods   # Most Array methods are   – they don’t change the Arrays that they are invoked on: However, there are also   methods such as   that change their receivers:  first sorts the Array in place and then returns it. In line A we can see that  , the receiver of the method call, and  , the value returned by the method, are the same object. Destructive Array methods   # These Array methods are destructive: \n \n \n \n If we want to apply one of these methods to an Array without changing it, we can use one of the following patterns: That is, we first make a copy of   and then change that copy. The new non-destructive methods   # The proposal introduces non-destructive versions of the three destructive Array methods so that we don’t need the aforementioned patterns anymore: \n \n \n Non-destructive version of  \n \n \n \n Non-destructive version of  \n \n \n \n Non-destructive version of  \n \n It also introduces a non-destructive method that has no corresponding destructive method: \n \n \n This method non-destructively replaces an Array element at a given   (think non-destructive version of  ). \n \n The next sections describe these four methods in more detail.    #  is the non-destructive version of  : This is a simple polyfill for  :    #  is the non-destructive version of  : This is a simple polyfill for  :    # Method   is more complicated than other destructive methods: \n It deletes   elements, starting at index  . \n It then inserts   at index  . \n It returns the deleted elements. \n In other words –   Array elements are replaced with  :  is the non-destructive version of  . It needs to return the changed version of its receiver and therefore doesn’t give us access to the deleted elements: This is a simple polyfill for  :    # This method call: is the non-destructive version of: The following code demonstrates how   works: This is a simple polyfill for  : The new methods will also be available for Tuples   # The proposed ECMAScript feature   is basically an immutable Array. Tuples have all methods that Arrays have – except for the destructive ones. Adding non-destructive versions of the latter to Arrays therefore helps Tuples and means that we can use the same methods to non-destructively change Arrays and Tuples. Implementations   # The proposal lists  implementations and polyfills  that are currently available. Further reading   # \n Chapter “Arrays”  in “JavaScript for impatient programmers” \n Chapter “Typed Arrays”  in “JavaScript for impatient programmers” \n Blog post  “A first look at records and tuples in JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/07/detexify-draw-to-find-latex-symbol.html", "title": "Detexify: draw to find a LaTeX symbol", "content": "Detexify: draw to find a LaTeX symbol latex hack computers Detexify comments powered by Disqus."},
{"url": "https://2ality.com/2009/07/do-you-need-software-license.html", "title": "Do you need a software license?", "content": "Do you need a software license? dev law web software engineering As a content producer: You have created a web page or a program and want to make sure that people use it the way you want them to. As a content user: You need a picture for your web site and are not sure where to find one that you are allowed to put online. names separate page choose copyleft Flickr Picasa Web Albums pictures search page comments powered by Disqus."},
{"url": "https://2ality.com/2009/08/incentives-are-bad-for-performance.html", "title": "Incentives are bad for performance", "content": "Incentives are bad for performance psychology life ted video The surprising science of motivation Praise Children for Effort, Not Intelligence, Study Says comments powered by Disqus."},
{"url": "https://2ality.com/2009/07/requirements-rdf-and-social.html", "title": "Requirements: RDF and social applications", "content": "Requirements: RDF and social applications semantic web social dev Named graphs: are supported by almost all RDF engines. They partition the RDF repository. Social applications should authorize access at graph granularity. That way, some graphs can be private and others public. RDF allows one to hide the “seams” between graphs at will. An RDF repository should support this by enabling one to show and hide graphs on the fly, during access. SPARQL and  Sesame  can both do this. The former by constraining the graph URI, the latter by specifying a set of contexts when invoking RepositoryConnection.getStatements().\n Distributed version control : provides two abilities. First, versioning is useful for personal use (history, undo) and collaborative use (conflict management, tracking who made what changes). Second, peer-to-peer synchronization is useful for offline use, backup, and collaboration.  Pastwatch  is an example of very clever (file-based) distributed version control.\n Text handling: to make long texts that are stored in RDF literals more accessible, one should be able to configure what property values are to be indexed. Ideally, version control would only store changes between versions (as opposed to the complete text). As an alternative to storing the text in the RDF repository, one can let the property point to an external document management system. Still, the necessity for version control remains.\n Record the author of a statement: so that a social application can track who contributed what.\n Support for XML literals in SPARQL Ease of use: should be easy to install and use; should focus on core RDF repository features.\n Open Anzo : an RDF engine that supports versioning, user-based authentication, and text indexing. Replication is possible, but not in a distributed manner. Open Anzo’s philosophy is very much in line with this post.\n IBM Semantic Layered Research Platform : does not seem to be updated any more. Poorly documented. I'm not sure if it can do distributed synchronization.   This is Open Anzo's precursor (see comments below).\n OpenLink data spaces : powerful, offers all kinds of import and export services. But the free version does not have replication. I'm not sure how far beyond two-way replication its features go. KiWi  (Knowledge in a wiki): an intriguing social content platform that rolls its own RDF engine. Its content model deviates from pure RDF. It also cannot do distributed synchronization. Not publically available, yet. Sesame  has a new project called  AliBaba  that provides repository federation and change logging.\n Changesets : an RDF vocabulary for keeping a history of changes. Useful for exporting data from a repository that supports versioning.\n comments powered by Disqus."},
{"url": "https://2ality.com/2009/09/clip-shows.html", "title": "Clip shows", "content": "Clip shows tv life wikipedia article comments powered by Disqus."},
{"url": "https://2ality.com/2009/08/mobile-html-dial-number-via-hyperlink.html", "title": "Mobile HTML: dial a phone number via a hyperlink", "content": "Mobile HTML: dial a phone number via a hyperlink mobile dev hack webdev really cool way SMS URLs and Skype URLs comments powered by Disqus."},
{"url": "https://2ality.com/2009/09/canvas-based-game-ajax-has-come-far.html", "title": "Canvas-based game: Ajax has come far", "content": "Canvas-based game: Ajax has come far dev gaming webdev computers webapp Berts Breakdown Ajaxian EffectGames comments powered by Disqus."},
{"url": "https://2ality.com/2009/11/java-7-will-have-closures.html", "title": "Java 7 will have closures!", "content": "Java 7 will have closures! dev java “ Closures after all? ” is continually updated with new links and information. Gafter’s “ Closures for Java ” has been updated with the new syntax which closely resembles  FCM . Thus, the new closures use FCM syntax and (a simplified version of) Gafter’s type system. Correction: Gafter’s spec  was written  2 weeks before Devoxx, as an attempt at a compromise between the competing proposals.\n Reinier Zwitserloot  has more background on how everything came about.  Stephen Colebourne gives an  overview  of the current situation.  Mark Reinhold posts “ Closures for Java: The Q&A ”.\n comments powered by Disqus."},
{"url": "https://2ality.com/2021/08/iteration-helpers.html", "title": "JavaScript needs more helper functions for iteration (map, filter, etc.) – where should we put them?", "content": "JavaScript needs more helper functions for iteration (map, filter, etc.) – where should we put them? dev javascript iteration Iteration is a standard that connects operations with data containers: Each operation that follows this standard, can be applied to each data container that implements this standard. In this blog post: \n We first explore three questions:\n \n How does JavaScript’s iteration work? \n What are its quirks? \n What do helper functions for iteration look like? Examples include iteration versions of the Array methods  ,  , and  . \n \n \n Next, we examine the pros and cons of several approaches for implementing helper functions:  As methods of data containers? As functions? Etc. Two of these approaches are supported by concrete proposals. \n The post concludes by explaining additional benefits of iteration and iteration-based helpers. \n \n   \n     JavaScript iteration and its quirks \n     \n       \n         What is iteration? \n       \n       \n         Core iteration entities: iterables and iterators \n       \n       \n         Iterators that are also iterable \n       \n       \n         : the prototype of all iterators in the standard library \n       \n     \n   \n   \n     Where to put helper functions for iterables? \n     \n       \n         Approach: methods of iterables \n       \n       \n         Approach: wrapping iterables \n       \n       \n         Approach: introducing a superclass for iterators \n       \n       \n         Approach: functions \n       \n     \n   \n   \n     More benefits of iteration and iteration helpers \n   \n   \n     Conclusion \n     \n       \n         If methods are preferred over functions \n       \n       \n         A module-based standard library? \n       \n     \n   \n   \n     Further reading on iteration \n   \n JavaScript iteration and its quirks   # What is iteration?   # Iteration was added to JavaScript in ECMAScript 6. There are two sides to this   (interfaces and rules for using them): \n A data producer (such as a data structure) can implement the iteration protocol and expose its output (or content) through it. \n A data consumer (such as an algorithm) can retrieve its input via the iteration protocol. \n A data producer that implements the iteration protocol is called an  . That term is also used as an adjective: “an iterable data structure”. A key benefit of iteration is that each data consumer that uses iteration, can be used with each iterable data producer. The JavaScript standard library already has several iteration-based data producers and data consumers – for example: \n Data producers:\n \n Arrays, Maps, Sets, strings \n Results of   (iterable objects that are not Arrays) \n Results of   (iterable objects that are not Arrays) \n \n \n Data consumers\n \n \n \n Spreading into Arrays ( ) \n Spreading into function calls ( ) \n \n \n Alas, JavaScript does not yet support many iteration-based algorithms. These are three examples of helper functions that would be useful: \n : lists the results of invoking a callback on each value of an iterable. \n : lists all values of an iterable for which a callback returns  . \n : invokes a callback with each value of an iterable. \n Both input and output of   and   are iterable, which means that we can chain these operations. Core iteration entities: iterables and iterators   # The two most important entities in the iteration protocol are: \n : This entity is the container that holds data. It exposes that data by being a factory for  . \n : This entity returns each value contained in an iterable, one at a time (think cursor in a database). \n An object   becomes iterable by implementing one method: \n : This method return  . \n An     is an object that delivers values via one method: \n : This method returns objects with two properties:\n \n : contains the current value \n : is   as long as there still are values and   afterwards. \n \n \n This is what using iteration looks like in practice: Iterators that are also iterable   # When implementing an iterable, a common technique is to make that iterable also an iterator: In line A, we don’t return a new object, we return  . This technique has three upsides: Our code becomes simpler. We can iterate over iterators. Generator functions and methods can be used to implement both iterables and iterators. We’ll first examine upside #2 and then upside #3. # In line B in the following code, we can continue the iteration that we started in line A. # All iterators created by the JavaScript standard library are iterable. The objects returned by generators are also both iterators and iterables. Therefore, we can use generators to implement iterables: But we can also use them to implement iterators (line A): # With iterable iterators, we now have two kinds of iterators. On one hand, there are iterables over which we can iterate as often as we want: On the other hand, there are iterables over which we can only iterate once: Conceptually, things have become more confusing: \n On one hand,  , spreading, etc. only accept iterables. \n On the other hand, constructs such as generators,  , and   return iterators that just happen to also be iterable. \n : the prototype of all iterators in the standard library   # In the ECMAScript specification, internal objects are enclosed in percent signs. One such object is  : This method is inherited by all objects that have   as a prototype and makes them iterable – if   is also an iterator. Even though   is not directly accessible from JavaScript, we can access it indirectly:  is in the prototype chain of all iterators that are created by the standard library: One of the proposals for iteration helpers depends on the fact that   is a prototype of many iterators. We’ll get into the details when we look at that proposal. Where to put helper functions for iterables?   # Approach: methods of iterables   # If we want to be able to method-chain iteration helpers like we can with Arrays, the conceptually cleanest way is to make those helpers methods of iterable objects. That could look as follows. Now we can do: # If we want our helpers to be methods, then iterables are the right location for them. Apart from chaining, another benefit of methods is that specific classes can override a default implementation of an operation if they can implement it more efficiently (via the specific features of the class). Alas, we are facing a fatal obstacle: We can’t change the inheritance hierarchies of existing classes (especially not of  ). That makes it impossible to use this approach. Approach: wrapping iterables   # Another way of enabling method chains is via a technique that became popular in the JavaScript world via the libraries jQuery and Underscore: We wrap the objects that we want to operate on and add methods to them that way: \n Upside of this approach: It’s conceptually clean. No work-arounds are required, we don’t need to change iteration in any way. \n We can method-chain helper invocations. \n Downside of this approach: wrapping introduces extra overhead. \n Approach: introducing a superclass for iterators   # Yet another way of getting method chaining is by adding helper methods to iterators. There is  an ECMAScript language proposal  for this approach. How does that work? As we have seen, all iterators created by the standard library already have the object   in their prototype chains. We can complete this prototype into a full class: Interestingly, due to how   works and due to   being a prototype of each iterator in the standard library, many objects are already instances of  : This is what using the new approach looks like: # With this approach, we have to distinguish three kinds of iterables: \n Iterables that are not iterators (Arrays, Sets, Maps, results of  , etc.) \n Iterable iterators that extend   ( ,  , etc.) \n Iterable iterators that don’t extend   (in existing code). \n The proposal provides the tool function   to handle all these cases in the same manner: \n If an iterable is not an iterator, it returns its iterator. \n If an iterable is an iterator and extends  , it returns it as is. \n If an iterable is an iterator and does not extend  , it wraps that iterable so that it has the methods of  . \n # \n As with the previous two approaches, we can chain methods. \n Classes can override default helper implementations with more efficient ones. \n # \n Requiring all iterators to extend   is a significant change of the original iteration protocol.\n \n Not all existing code will be updated to meet this requirement. \n Some iterators may not be able to meet this requirement (e.g. subclasses). \n \n \n The location of the new methods is not ideal. When we want to apply an operation to an iterable, we have to distinguish: non-iterator iterables, iterable iterators that extend  , and iterable iterators that don’t extend  .\n \n This can be handled via  , but then we get an API that is like the wrapping approach. \n \n \n If helper methods are intended for iterables then putting them in iterators is a conceptual mismatch.\n \n This becomes especially obvious when using  : It converts an iterable to an iterator, then we invoke iterator methods, then we use a construct such as   to process the result. That construct only accepts iterables, but instances of   also happen to be iterable. \n If an operation accepts more than one operand (such as  ), these operands would be iterables, while   would be an instance of  . \n A practical consequence of the mismatch is that we have to create an iterator before we can apply a helper to a non-iterator iterable. \n I agree that the status quo w.r.t. iterables vs. iterators is already slightly confusing. I’d prefer not to make things worse. \n \n \n The set of built-in operations can’t be extended. If a library wants to provide more iterator helpers, they cannot be added to   and would probably be functions. \n Different from prior art: Established libraries such as JavaScript’s Underscore/Lodash library and Python’s itertools are based on functions. \n Approach: functions   # The established way of providing helpers for iterables is actually not via methods but via functions. Examples include Python’s itertools and JavaScript’s Underscore/Lodash. The library   prototypes what that would look like. It is implemented roughly like this: Note that   isn’t really an object but a namespace/pseudo-module for the functions, similar to   and  . Should JavaScript get  a pipeline operator , we could even use these functions as if they were methods: # \n Helpers as functions follow the tradition established by Underscore/Lodash and others. \n Conceptually, functions work well as iterable helpers: operands and results are always iterables. \n The set of helpers can be extended by anyone, because any function will be in the same category as the built-in helpers.\n \n Especially functions that create iterables (such as  ) will be important additions to this category. \n \n \n The current iteration protocol does not have to change. \n # Functions won’t allow method chaining. However: \n In my experience, chains are rarely long. And even with long chains, I don’t mind introducing intermediate variables (as was done in the example before the previous one). \n We may get  a pipeline operator  in JavaScript and then can chain helper functions (as in the previous example). Note that the pipeline operator is nice to have for functions, but not a requirement. Their other benefits stand on their own. \n If we are not chaining, functions are convenient: In contrast, this is what using iterator methods looks like: More benefits of iteration and iteration helpers   # In this blog post, we have only seen  : We immediately get a new item when we request it from an iterator. But there is also   where code pauses until the next item is available. One important use case for asynchronous iteration is processing streams of data (e.g.  web streams  and  Node.js streams ). Even if we apply multiple operations to an asynchronous iterable, the input data is processed one item at a time. That enables us to work with very large datasets because we don’t have to keep all of them in memory. And we see output much more quickly (compared to first applying the first operation to the complete dataset, then the second operation to the result, etc.). Conclusion   # We have explored iteration and four approaches for implementing iteration helpers: Methods of iterables Wrapping iterables Introducing a superclass for iterators ( proposal ) Functions ( proposal ) I expect (at most) one of these approaches to be added to JavaScript. How should we choose? Given all the constraints we are facing, my favorite is (4): \n We don’t have to change the current iteration protocol. \n Operations on iterables are conceptually cleaner and easier to use. \n The built-in set of operations can be extended. \n JavaScript may eventually get  a pipeline operator . That would even enable us to chain functions. But the pipeline operator is not required to make functions an appealing solution ( details ). If methods are preferred over functions   # If methods are preferred over functions, I’d argue in favor of wrapping (as done by jQuery and supported by Underscore/Lodash). Compare: A module-based standard library?   # Using global variables as namespaces for functions is a common pattern in JavaScript. Examples include: \n \n \n \n \n There is  a proposal for built-in modules in JavaScript  (i.e., a module-based standard library). Built-in modules would provide functionality such as what is listed above and could also contain function-based iteration helpers: Further reading on iteration   # Chapters in my book “JavaScript for impatient programmers” (which is free to read online): \n “Synchronous iteration” \n “Synchronous generators” \n “Asynchronous iteration” \n comments powered by Disqus."},
{"url": "https://2ality.com/2021/06/typescript-esm-nodejs.html", "title": "TypeScript and native ESM on Node.js", "content": "TypeScript and native ESM on Node.js dev typescript esm nodejs In this blog post, I’ll explain everything you need to know in order to use and produce native ECMAScript modules on Node.js. The GitHub repository   is an example of a TypeScript ESM package that works on Node.js. It still uses the   workaround (which isn’t needed in TypeScript 4.7 and later). (Thanks to Guy Beford and Oleg Drapeza for their feedback on this post.) \n   \n     TypeScript 4.7: better support package exports and Node’s ESM \n   \n   \n     The basics \n     \n       \n         \n       \n       \n         \n       \n       \n         TypeScript \n       \n       \n         Visual Studio Code \n       \n     \n   \n   \n     Package exports: hiding package internals and providing nicer module specifiers \n     \n       \n         An entry point for the package itself \n       \n       \n         Nicer module specifiers for a subtree \n       \n       \n         Exporting files anywhere inside a directory without filename extensions \n       \n       \n         Mapping a directory to a file \n       \n       \n         Advanced package exports features \n       \n       \n         Recommendations for using package exports \n       \n     \n   \n   \n     What about browsers? \n   \n   \n     Further reading \n   \n TypeScript 4.7: better support package exports and Node’s ESM   # Starting with  TypeScript 4.7 , there is no need for adding   to   anymore because TypeScript now understands package exports. If you are writing Node.js code, the following settings in   can help: The basics   # Let’s assume we are implementing an npm package   via TypeScript. The package has the following file structure:    # \n Line A ( ): We are telling TypeScript to generate ECMAScript modules.\n \n ,  : support for basic ESM features \n : additionally, support for dynamic imports and  . \n \n \n Line B ( ): This value is needed for Node.js. \n Line C ( ): I needed this setting in order to import a legacy CommonJS module. The   were the default export in that case. \n    # The following entry is needed in  : Specifying a   is recommended anyway, but a must here because TypeScript doesn’t support   yet, only  . TypeScript   # If the package is npm-installed in another package, this is how that package imports the function  : The key point is that, by default, we need to provide filename extensions, especially for modules within the same package. Visual Studio Code   # By default, VS Code does not add filename extensions when it adds imports for us. That can be changed via the following two settings: This is how we can add filename extensions to existing local imports (within a package): \n Search:  \n Replace:  \n Package exports: hiding package internals and providing nicer module specifiers   # In this section, we explore how   work. They are specified via property   in   and support two important features: \n Hiding internals:\n \n Without property  , every module in   can be accessed via   such as  . \n Once it exists, only specifiers listed in it can be used. Everything else is hidden from the outside. \n \n \n Nicer module specifiers:\n \n Module specifiers without filename extensions. That is now the recommended format for exported (non-local) modules. \n Shorter paths for deeply nested modules. \n \n \n Recall that this is the file structure of the package: An entry point for the package itself   # : We only provide   for backward-compatibility.  performs the same mapping as  , but for TypeScript’s type definitions. This is the import statement in TypeScript: Nicer module specifiers for a subtree   # : Here, we shorten the module specifiers of the whole subtree under  : Without the exports, the import statement would be: Note the asterisks in this   entry: These are not filesystem globs but instructions for how to map external module specifiers to internal ones. # With the following trick, we expose everything in directory   with the exception of  Exporting files anywhere inside a directory without filename extensions   # : Any file that is a descendant of   can be imported without a filename extension: Mapping a directory to a file   # : Here, we want to export   as if it were the directory in which it resides: Advanced package exports features   # Node.js supports more exports features, for example  . We can change our mapping depending on how our package is imported – e.g. via   or via  : Additionally, it’s possible to distinguish between browsers and Node.js, and more. Recommendations for using package exports   # Package exports have two important benefits: \n We can hide internals. \n We get nicer module specifiers. \n Both benefits help with providing a nicely abstract interface to code using our package. In fact, the recommended style for module specifiers is now: \n Importing from within the current package: Use filename extensions in module specifiers.\n \n Example:  \n \n \n Importing from another package: Avoid filename extensions in module specifiers.\n \n Example:  \n \n \n What about browsers?   # So far, I have only tested this setup on Node.js, but I’d assume that bundlers will support these features, too. If not already, then eventually. I’m happy to see that ESM is supported increasingly well everywhere. For example, I moved the test-driven exercises for  my book “JavaScript for impatient programmers”  (in plain JavaScript) to native ESM on Node.js a while ago, and that worked really well. Further reading   # \n Introduction to ECMAScript modules  (chapter in “JavaScript for impatient programmers”) \n Moving npm packages to ESM:  “Hello, Modules!”  by Sindre Sorhus \n Tooling that’s enabled by ESM:  “Life with ESM”  by Chris Coyier \n comments powered by Disqus."},
{"url": "https://2ality.com/2021/09/class-static-block.html", "title": "ES2022 feature: class static initialization blocks", "content": "ES2022 feature: class static initialization blocks dev javascript es2022 The ECMAScript proposal  “Class static initialization blocks”  by Ron Buckton is at  stage 4  and scheduled to be included in ECMAScript 2022. For setting up an instance of a class, we have two constructs in JavaScript: \n Field: Create (and optionally initialize) instance properties. \n Constructor: A block of code that is executed before setup is finished. \n For setting up the static part of a class, we only have static fields. The ECMAScript proposal introduces static initialization blocks for classes, which, roughly, are to static classes what constructors are to instances. \n   \n     Why do we need static blocks in classes? \n   \n   \n     A more complicated example \n   \n   \n     Details \n   \n   \n     Support in engines for class static blocks \n   \n   \n     Is JavaScript becoming to much like Java and/or a mess? \n   \n   \n     Conclusion \n   \n Why do we need static blocks in classes?   # When setting up static fields, using external functions often works well: Using the external functions   and   works well ins this case because we can see that they are invoked from inside the class and because they are completely independent of the class. Things become less elegant if we want to set up two static fields at the same time: This time, there are several issues: \n Invoking   is an extra step that either has to be performed outside the class, after creating it. Or it is performed via a workaround (line A). \n  does not have access to the private data of  . \n With a proposed static block (line A), we have a more elegant solution. A more complicated example   # One way of implementing enums in JavaScript is via a superclass   with helper functionality (see  the library   for a more powerful implementation of this idea): We need to collect static fields so that we can iterate over the keys of enum entries (line B). This is a final step after creating all static fields. We again use a workaround (line A). A static block would be more elegant. Details   # The specifics of static blocks are relatively logical (compared to the more complicated rules for instance members): \n There can be more than one static block per class. \n The execution of static blocks is interleaved with the execution of static field initializers. \n The static members of a superclass are executed before the static members of a subclass. \n The following code demonstrates those rules: Support in engines for class static blocks   # \n V8: unflagged in v9.4.146 ( source ) \n SpiderMonkey: behind a flag in v92, intent to ship unflagged in v93 ( source ) \n TypeScript: v4.4 ( source ) \n Is JavaScript becoming to much like Java and/or a mess?   # This is a tiny feature that doesn’t compete with other features. We can already run static code via fields with the   workaround. Static blocks mean that this workaround isn’t necessary anymore. Other than that, classes are simply one of many tools in the belt of a JavaScript programmer. Some of us use it, others don’t, and there are many alternatives. Even JavaScript code that uses classes often also uses functions and tends to be lightweight. Conclusion   # Class static blocks are a relatively simple feature that rounds out the static features of classes. Roughly, it is the static version of an instance constructor. Its mainly useful whenever we have to set up more than one static field. comments powered by Disqus."},
{"url": "https://2ality.com/2021/06/temporal-api.html", "title": "Temporal: getting started with JavaScript’s new date time API", "content": "Temporal: getting started with JavaScript’s new date time API dev javascript es proposal \n 2022-01-10:   was renamed to  . \n 2021-06-30: Rearranged the content and created a section on the concepts and patterns used by the Temporal API. \n 2021-06-29: Clarified how   uses the ISO-8601 calendar. Listed the properties of some classes. \n , JavaScript’s current date time API is  infamously difficult to use .  The ECMAScript proposal “Temporal”  is a new and better date time API and currently at stage 3. It was created by  Philipp Dunkel ,  Maggie Johnson-Pint ,  Matt Johnson-Pint ,  Brian Terlson ,  Shane Carr ,  Ujjwal Sharma ,  Philip Chimento ,  Jason Williams , and  Justin Grant . This blog post has two goals: \n Giving you a feeling for how Temporal works \n Helping you get started with it \n However, it is not an exhaustive documentation: For many details, you will have to consult  the (excellent) documentation for Temporal . \n   \n     The Temporal API \n   \n   \n     Background: representing time \n     \n       \n         From solar time to standard time \n       \n       \n         Time standards: UTC vs. Z vs. GMT \n       \n       \n         Time zones vs. time offsets \n       \n       \n         Calendars \n       \n       \n         ECMAScript Extended ISO-8601/RFC 3339 Strings \n       \n     \n   \n   \n     Concepts and patterns of the Temporal API \n     \n       \n         Wall-clock time vs. exact time \n       \n       \n         The core classes of the Temporal API \n       \n       \n         Creating instances of Temporal classes \n       \n       \n         Updating time values \n       \n       \n         Values that are “like” instances of classes ( ,  ,  , etc.) \n       \n     \n   \n   \n     A closer look at Temporal’s classes \n     \n       \n         : the current time \n       \n       \n         Exact time: class  , class  , nanoseconds since epoch \n       \n       \n         Plain (wall-clock time) classes \n       \n       \n         Helper classes \n       \n     \n   \n   \n     Examples \n     \n       \n         Input and output \n       \n       \n         Sorting dates \n       \n       \n         Converting between Temporal values \n       \n       \n         Converting between time zones \n       \n       \n         Date time arithmetic \n       \n     \n   \n   \n     Implementations of the Temporal API \n   \n   \n     More information on the APIs   and  \n   \n The Temporal API   # The Temporal date time API is accessible via the global variable  . It is a pleasure to use: \n All objects are immutable. Changing them produces new values, similarly to how strings work in JavaScript. \n There is support for time zones and non-Gregorian calendars. \n There are several specialized classes for Temporal values (date time values with time zones, date time values without time zones, date values without time zones, etc.). That has several benefits:\n \n The context of a value (time zone or not, etc.) is easier to understand. \n It is often more obvious how to achieve a given task. \n  can be used with much less consideration. \n \n \n January is month 1. \n Parts of this blog post: \n The post starts with background knowledge. That will help you with the remainder of the post, but you should be fine without it. \n Next, there is an overview of all the classes of the Temporal API and how they fit together. \n At the end, there is a comprehensive section with examples. \n Background: representing time   # From solar time to standard time   # Historically, how we measure time has progressed over the years: \n Apparent solar time (local apparent time) : One of the earliest ways of measuring time was to base the current time on the position of the sun. For example, noon is when the sun is directly overhead. \n Mean solar time (local mean time) : This time representation corrects the variations of apparent solar time so that each day of the year has the same length. \n Standard time  and time zones: Standard time specifies how the clocks within a geographical region are to be synchronized. It was established in the 19th century to support weather forecasting and train travel. In the 20th century, standard time was defined globally and geographical regions became  . \n  is the current time within a time zone (as shown by a clock on the wall). Wall-clock time is also called  . Time standards: UTC vs. Z vs. GMT   # UTC, Z, and GMT are ways of specifying time that are similar, but subtly different: \n \n UTC (Coordinated Universal Time) is the time standard that all times zones are based on. They are specified relative to it. That is, no country or territory has UTC as its local time zone. \n \n \n Z (Zulu Time Zone) is a military time zone that is often used in aviation and the military as another name for UTC+0. \n \n \n GMT (Greenwich Mean Time) is a time zone used in some European and African countries. It is UTC plus zero hours and therefore has the same time as UTC. \n \n Sources: \n “The Difference Between GMT and UTC”  at TimeAndDate.com \n “Z – Zulu Time Zone (Military Time)”  at TimeAndDate.com \n Time zones vs. time offsets   # Temporal’s time zones are based on  the IANA Time Zone Database (short: tz database) . IANA stands for Internet Assigned Numbers Authority. In that database, each time zone has an identifier and rules defining offsets for UTC times. If a time zone has standard time and daylight saving time, the offsets change during a year: In standard time, the time offset for the   time zone is +1:00 (line A). In daylight saving time, the time offset is +2:00 (line B). # \n “Time Zone Database”  on the IANA website is a list of time zone names. \n “List of tz database time zones”  on Wikipedia is another list of time zone names. \n “Time Difference” (“Zeitverschiebung”)  lists time zones for cities etc. – for example, the time zone for San Francisco is  . \n Calendars   # The calendars supported by Temporal are based on the standard  Unicode Unicode Common Locale Data Repository (CLDR)  – among  others : \n : Thai Buddhist calendar \n : Traditional Chinese calendar \n : Coptic calendar \n : Traditional Korean calendar \n : Ethiopic calendar, Amete Mihret (epoch approx, 8 C.E.) \n : Gregorian calendar \n : Traditional Hebrew calendar \n : Indian calendar \n : Islamic calendar \n : ISO calendar (Gregorian calendar using the ISO-8601 calendar week rules) \n : Japanese Imperial calendar \n : Persian calendar \n : Republic of China calendar \n  is used by most western countries and gets extra support in Temporal, via methods such as   (which returns the current date and wall-clock time in the system time zone and ISO-8601 calendar). ECMAScript Extended ISO-8601/RFC 3339 Strings   # The standards ISO-8601 and RFC 3339 specify how to represent dates in strings. Currently, they are missing functionality that is needed and  added by Temporal : \n Representing month-day data as strings \n Representing IANA Time Zone Names in date time strings \n Representing calendar systems in date time strings \n The goal is to eventually get these additions standardized (beyond ECMAScript). # Month-day syntax looks like this: # The following code shows what a full date time string looks like. In practice, many of these parts will often be missing: Parts of the date time string in the previous example: \n Date:  \n \n year   month   day \n \n \n Separator between date and time:  \n Time:  \n \n hour   minute   seconds \n  (separator between seconds and fractions of a second) \n milliseconds (3 digits) \n microseconds (3 digits) \n nanoseconds (3 digits) \n \n \n Time offset relative to UTC:  \n \n Alternative:   which means  \n \n \n Time zone:  \n Calendar:  \n The last two items are not currently standardized. Concepts and patterns of the Temporal API   # Wall-clock time vs. exact time   # Temporal distinguishes two kinds of time. Given a global instant of time: \n  (also called   or  ) varies globally, depending on the time zone of a clock. \n  (also called  ) is the same everywhere. \n  is one way of representing exact time: It’s a number counting time units (such as nanoseconds) before or since   (midnight UTC on January 1, 1970). The core classes of the Temporal API   # Let’s first take a quick look at Temporal’s core classes and what data goes into them. They are covered in more detail later. \n Exact time:\n \n Wall-clock time plus time zone:\n \n :  \n \n \n UTC:\n \n :  \n \n \n \n \n Abstract time (no associated time standard):\n \n :  \n :  \n :  \n :  \n :  \n \n \n Durations:\n \n :  \n \n \n Creating instances of Temporal classes   # There are two main ways of creating instances of Temporal classes. # On one hand, we can create instances via constructors. Each constructor accepts the minimal amount of data needed to fully specify an instance. For example, in the case of the two classes for exact time,   and  , the point in time itself is specified via epoch nanoseconds. # On the other hand, we can create instances via the static factory method  . It is overloaded: Most classes support three kinds of values for its parameter. First, if the parameter is an instance of the same class, then that instance is cloned: Second, all other objects are interpreted as specifying various fields with time-related information: Third, all primitive values are coerced to string and parsed: Note that we didn’t need to specify the offset in line A, but it is shown in line B. Updating time values   # The fields we use when creating an instance via   become properties of that instance: These properties are immutable: If we want to change them, we have to create a new instance where they have different values. Method   lets us do that: Values that are “like” instances of classes ( ,  ,  , etc.)   # Whenever Temporal needs an instance of a class  , it accepts any value that is “like” an instance of class  : An instance of class  An object that can be parsed via  \n \n Note that the properties of such an object are a subset of the properties of an instance of  . \n \n A string that can be parsed via   – these are three ways of specifying time zones (last arguments of the following constructor invocations):  – these are three ways of specifying calendars (last arguments of the following constructor invocations):  – these are three ways of specifying durations (argument of  ): A closer look at Temporal’s classes   # : the current time   # The object   has several factory methods for creating Temporal values representing the current time: Properties of  : \n \n \n \n \n \n \n \n \n \n These properties are documented  here . # We can use   to access the current time zone of the system. This time zone can change – for example, when the system travels: The concept of a “current calendar” is more complicated. Ideas for how to best handle it are still evolving. This is the current way of getting the ID (a string) of the “preferred calendar”: Exact time: class  , class  , nanoseconds since epoch   # Temporal represents exact time in three ways: \n Via class   (UTC time). \n Via class   (wall-clock time plus a time zone and a calendar). \n Via a bigint number expressing nanoseconds since epoch. \n # Class   represents global exact time. Its time standard is UTC. It is mostly a container for nanoseconds since epoch. That is also reflected by it not having properties such as   and   (which   and   have). For some operations (such as  ),   internally uses an ISO-8601 calendar, but that calendar is not stored in instances. Use case: \n Internal dates that are not shown to end users (time stamps in logs, etc.). \n Properties of  : \n \n \n \n \n \n \n Properties of  : \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n These properties are documented  here . # Class   represents time via wall-clock time plus a time zone and a calendar. Use cases for this class: \n Representing actual events \n Converting time between zones \n Time computations where daylight saving time may play a role (“one hour later”) \n Properties of  : \n \n \n Properties of  : \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n These properties are documented  here . Plain (wall-clock time) classes   # # If a class doesn’t have a time zone, Temporal calls it “plain”. There are three timezone-less classes:  ,  , and  . They are abstract representations of time. Use cases for these classes: \n Displaying the wall-clock time in a given time zone (see below). \n Time computations when the time zone doesn’t matter (“The first Wednesday of May 1998”).  \n Properties of  : \n \n \n Properties of  : \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n These properties are documented  here .  and   have subsets of  ’s properties. # An instance of   abstractly refers to a particular month in a particular year. Use case: \n Identifying a monthly recurring event (“the October 2022 meeting”) \n # An instance of   abstractly refers to a particular day in a particular month. Use case: \n Identifying a yearly recurring event (“Bastille Day is July 14”) \n Helper classes   # # All Temporal classes that contain full dates use calendars to help them with various computations. Most code will use the ISO-8601 calendar, but other calendar systems are supported, too. # Instances of   represent time zones. They support IANA time zones, UTC, and UTC offsets. For most use cases, IANA time zones are the best choice because they enable proper handling of daylight saving time. # A duration represents a length of time – for example, 3 hours and 45 minutes. Durations are used for temporal arithmetic: \n Measuring differences between two Temporal values \n Adding time to a temporal value \n Etc. \n Note that there is no simple normalization for durations: \n Sometimes, we mean “90 minutes”. \n Sometimes, we mean “1 hour 30 minutes”. \n The former should not be automatically converted to the latter. # Method   of duration objects returns strings that conform to the ISO-8601 notation for durations: Observations: \n All duration strings start with  . \n Time information starts with  . \n Examples   # Input and output   # # The static factory method   always accepts strings: The   method works predictably and can be configured: However,   doesn’t let you hide minutes in this case – you have to convert the   to a   if that is what you want: # All Temporal date time values have a   method and can therefore be stringified to JSON: If you want to parse JSON with date time values, you need to set up  a JSON reviver . # Temporal’s support for converting date time values to human readable strings is similar to  ’s : Temporal does not support parsing human-readable strings. # On one hand, we can convert legacy dates to Temporal instants: This is an alternative to the previous approach: On the other hand, one of the fields exposed by   provides us with the epoch time in milliseconds – which we can use to create a date: Sorting dates   # Every date time class   provides a function   for sorting instances of  :  also accepts strings – if they can be parsed via  : Converting between Temporal values   # # # # Converting between time zones   # Date time arithmetic   # # # # To compute Labor Day (first Monday in September) for a given year, we need to figure out how many days to add to September 1 in order to get to weekday 1 (Monday). Implementations of the Temporal API   # The “Can I use” page for Temporal  shows on which platforms the API is supported. For now, the proposal warns: Although this proposal's API is not expected to change, implementers of this proposal MUST NOT ship unflagged Temporal implementations until IETF standardizes timezone/calendar string serialization formats. See  #1450  for updates. The proposal has  a list of polyfills for the Temporal API . More information on the APIs   and     # \n The official Temporal documentation is currently  hosted on GitHub , but will eventually be moved to  MDN Web Docs . \n The legacy   API is documented in  a chapter  in the book “JavaScript for impatient programmers”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2021/07/simple-monorepos.html", "title": "Simple monorepos via npm workspaces and TypeScript project references", "content": "Simple monorepos via npm workspaces and TypeScript project references dev typescript esm nodejs A monorepo is a single repository that is used to manage multiple projects. In this blog post, we’ll explore how to set up a simple monorepo for two npm packages. All we need is already built into npm and TypeScript. \n   \n     What is a monorepo and why is it useful? \n   \n   \n     My use case for a monorepo: static site generation \n   \n   \n     My first failed attempt: local path installations \n   \n   \n     A better solution: npm workspaces and TypeScript project references \n     \n       \n         Producing ESM modules via TypeScript \n       \n       \n         npm workspaces \n       \n       \n         TypeScript project references \n       \n       \n         Tip: What to do when Visual Studio Code doesn’t see changes in another package \n       \n     \n   \n   \n     One step remains: publishing \n   \n   \n     Conclusion \n     \n       \n         Three wishes \n       \n     \n   \n   \n     Further reading \n   \n What is a monorepo and why is it useful?   # Whenever we have to develop multiple interdependent npm packages in parallel, we have two options: We can keep the packages in separate repositories and publish them to npm separately. We can keep all packages in a single repository and publish them to npm from there. The benefit of (2) is that it’s easier to keep the packages in sync: We can install and build all packages at the same time. And, in Visual Studio Code, we can jump between packages while editing. My use case for a monorepo: static site generation   # “Monorepo” sounds fancy, but my use case for it is actually relatively simple. I am currently working on a minimal static site generator that is called  . It comes in two parts: \n The npm package   contains the tool and is published to the npm registry. \n The npm package   is just an (unpublished) directory and contains:\n \n The blog itself is a directory with Markdown files. \n The look of the site is defined via TypeScript (JSX and Preact). \n A   module invokes the command line interface of Stoa and passes it configuration data (incl. the JSX views for rendering pages). \n \n \n My first failed attempt: local path installations   # I started developing via so-called  : Afterward,   has the following dependency: This approach has several upsides: \n It’s simple: There is nothing extra to configure or install. \n It’s easier than using  , which involves two steps and leads to global changes. \n In   there is a symbolic link (symlink) to  , which means that, as Stoa is developed, we’ll see the changes from  . (Caveat:   does not use symlinks, it copies the dependency’s files over.) \n But it also has significant downsides: \n The way   is set up now, it can’t use the version of Stoa in the npm registry. \n Installing and building must be done separately for each directory (vs. once for a monorepo). \n Due to the symlink, packages that are dependencies of both   and   are not de-duplicated. That is fatal for some packages – for example, we can’t use hooks in React and Preact if the render function and the JSX components come from different packages. \n A better solution: npm workspaces and TypeScript project references   # After my failed attempt with local path installations, I set up a monorepo for   and  . Producing ESM modules via TypeScript   # In  a previous blog post , I explained how to produce ESM modules via TypeScript. That’s also what I have configured for both packages in the monorepo. It has the following file system layout:  looks like this:  tells Node.js to interpret   files as ESM modules (not CommonJS modules).  configures the JavaScript level. It means that, e.g.: \n File  \n can be imported via  . \n In other words, this setting achieves two things: \n We don’t have to mention directory   in module specifiers. \n We don’t have to mention the filename extension   in module specifiers. \n  makes sure that TypeScript finds the type definitions (  files) that it needs. This is what’s in  : The command   is defined via   and starts generation via the JavaScript version of  . The latter file contains: So far, we are still not in monorepo territory: Each of the two packages   and   exists in its own (mostly separate) directory. npm workspaces   # A   is what npm calls a monorepo: A directory with subdirectories that are npm packages. We turn   into a workspace by adding a   to it:  looks like this: Unfortunately, npm overloads the term “workspaces”: The packages in an npm workspace are also called workspaces. Now we can do: Then this happens: \n All dependencies of   and   are installed into  . \n  also contains symbolic links to   and  . \n  and   do not have their own   directory. However, when they import modules, Node.js looks for them in the next   higher up in the file tree. The symlink in   enables   to import from  . What have we achieved? \n Duplicate packages are not an issue anymore because all package dependencies are installed into the same  . \n  can import   as if the former were a standalone directory and the latter were a published package. \n We can use a single command to install all dependencies. \n We can run npm commands in multiple workspaces ( details ). \n  automatically sees all changes we make in  . \n TypeScript project references   # We still need to compile each of the two packages separately via TypeScript. We can fix that via  , which are the TypeScript name for a monorepo. We need to create three files: \n \n \n \n The file system layout now looks like this: This is  : The normal   (which we need in standalone mode) contains: This   has a sibling   that is required due to the project reference in  : Let’s examine the properties: \n  lets us add the properties to the standalone   that we need to make project references work. Alas, we can’t add them to   itself because then it wouldn’t work in standalone mode anymore. \n  is required for project references. \n  must be   for project references. \n What have we achieved? We can now use single commands to clean, build, watch (etc.) all packages. For example, we can add these scripts to  : Another benefit is that we can click (Mac: cmd-click, Windows: ctrl-click) on something that   imported from   and Visual Studio Code will jump to the original source code – and not to the   file ( details ). Tip: What to do when Visual Studio Code doesn’t see changes in another package   # Sometimes, we make a change in one package and Visual Studio Code doesn’t see that change in another package that depends on it. There are two things we can do when that happens: \n We can execute the command “TypeScript: Restart TS Server” ( details ). \n Opening the relevant   file also usually helps. \n One step remains: publishing   # I have not shown you how to publish   to npm and how to turn   into a downloadable archive, but that’s relatively easy to achieve. Conclusion   # We have seen how we can set up a very simple monorepo by only using what’s already built into npm and TypeScript. That makes it much easier to develop multiple packages in parallel. I managed to preserve the ability to compile package   on its own. I haven’t seen that in the other TypeScript project references setups that I’ve come across. Three wishes   # I am very happy with this setup, but still have three wishes related to TypeScript: \n If I refactor in Visual Studio Code, the changes only affect a single package. It would be nice if all packages were changed. \n With an npm workspace, I don’t have to change a package when I add it to a workspace. Alas, that’s not true for TypeScript project references where I must add a  . \n I wish I didn’t have to add   to a   to make   work with TypeScript. I’m hoping that TypeScript will be able to derive this information from   in the future. \n Further reading   # npm workspaces: \n Official documentation of npm workspaces \n TypeScript project references: \n Official documentation of TypeScript project references \n “Boost your productivity with TypeScript project references”  by Paul Cowan \n  (by Ryan Cavanaugh) is a repository that demonstrates how to use project references. \n Other material: \n “TypeScript and native ESM on Node.js”  on this blog \n comments powered by Disqus."},
{"url": "https://2ality.com/2021/12/node-protocol-imports.html", "title": "New in Node.js:  node:  protocol imports", "content": "New in Node.js:   protocol imports dev javascript nodejs Node.js now supports a   protocol for built-in modules. The new   protocol   # Previously: Now: Benefits of   imports   # What are the benefits of using   module specifiers? \n It’s immediately clear that a built-in Node.js module is imported. Given how many of them there now are, that’s useful information. \n There is no risk of a module in   overriding the built-in module.\n \n This is especially important whenever Node.js adds a new built-in module. \n \n \n Support for   imports   # \n Supported in Node.js starting:\n \n v16.0.0, v14.18.0 (ESM   and CommonJS  ) \n v14.13.1, v12.20.0 (only ESM  ) \n \n \n Supported in TypeScript by the latest versions of  . \n More material   # \n “  Imports” in the Node.js documentation \n Twitter thread from 2021-12-12 \n Twitter thread from 2021-07-26 \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/03/type-annotations-first-look.html", "title": "First look: adding type annotations to JavaScript", "content": "First look: adding type annotations to JavaScript dev javascript es proposal \n  I’m quoting a few insightful tweets at the end of this blog post. \n The ECMAScript proposal “Types as comments”  (by Gil Tayar, Daniel Rosenwasser, Romulo Cintra, Rob Palmer, and others) is about adding type annotations to JavaScript (there is also  an accompanying blog post ). Such type annotations would look similar to TypeScript’s and Flow’s annotations and are completely ignored at runtime. In this blog post, I briefly explain how the proposed type annotations would work and then describe what I think about them. \n   \n     How do the proposed type annotations work? \n   \n   \n     Thoughts on adding type annotations to JavaScript \n     \n       \n         My thoughts \n       \n       \n         Thoughts by TypeScript team member  \n       \n       \n         Thoughts by former TypeScript team member  \n       \n       \n         Tweets by various people \n       \n     \n   \n   \n     Further reading \n   \n How do the proposed type annotations work?   # This is an example: The parameters   and   have type annotations: The type  , separated by a colon. This is how these annotations are handled: \n \n At runtime, JavaScript engines completely ignore them – as if they were comments. \n \n \n At development time, type checkers can statically analyze the annotations and warn developers about potential issues. \n \n So far, we have only seen relatively simple type annotations. More complicated ones are also proposed – e.g.: \n Interfaces ( ) \n Type aliases ( ) \n Type assertions ( ) \n Generic invocations (e.g.  ) \n And more ( see proposal ) \n Thoughts on adding type annotations to JavaScript   # My thoughts   # Upsides: \n \n Having a standard for type notations would be good and would make it easier for tooling and experiments in this field. \n \n \n It would become possible to program (e.g.) TypeScript without compiling the source code. There would only be type checking at development time. This would considerably improve the development experience for statically typed JavaScript: \n \n No intermediate files would be needed for execution.\n \n This would be especially useful on Node.js where you could run TypeScript files directly. \n \n \n No source maps would be needed to see the original source code while debugging. \n  files often won‘t be needed either. \n \n This development experience is similar to  providing type information via JSDoc comments  – which is already a popular way of using TypeScript. \n \n Downsides: \n I like that right now, static typing systems such as TypeScript are completely optional layers on top of JavaScript and don’t add any complexity to JavaScript. \n The proposal adds much new syntax to the language. Even if engines ignore it, they must still be able to parse it. Upgrading JavaScript tools will take time and effort. \n If TypeScript (etc.) aren’t compiled to JavaScript before deploying libraries to npm, browsing source code written by TypeScript developers will become less pleasant for people who don’t like TypeScript.\n \n To help with this, removing all type annotations from a file might become an operation supported by text editors. \n \n \n Various thoughts: \n Python’s   are similar to the proposal. \n How would the proposal affect Deno? Does it provide any benefits for its TypeScript-centric approach? \n The value of minification would grow for type-annotated code: more saved storage space and a bigger increase in parsing speed. \n Using TypeScript as a strict superset of JavaScript would probably become even more popular than it already is. That means: no enums, no TypeScript-style decorators (but there is  a proposal to add slightly different ones to JavaScript ), etc. \n I can understand if JavaScript developers are afraid of TypeScript taking over their language. However, this proposal will be as far as things will go w.r.t. adding TypeScript features to JavaScript. From the viewpoint of JavaScript engines, type annotations will be more like comments. What are your thoughts? Let us know in the comments! Thoughts by TypeScript team member     # [Source:  tweet thread ] Here’s one way to think about this. Would you ever intentionally   unminified JS to your production website? Probably not Do you   minified code today? Definitely not. But is it useful to be able to   unminified code? Extremely! Removing type annotations is the same thing. And just like your lint rules might enforce a style guide, your choice of type checker can validate type annotations you write. Runtimes ignore both style and type “errors”, both of which vanish completely in minfication. You could imagine a world where JS didn’t allow indentation. We’d probably write a compile-to-JS language (or many) that allowed indentation, maybe with style rules. “Indentation in the browser” would be the idea of just allowing indentation, not re-implementing those style rules. Thoughts by former TypeScript team member     # [Source:  tweet thread ] One angle I don’t think people have explored when thinking about ‘Types As Comments’ is how much modern JS development has moved to a ‘soft fork’ of the JS language for types/tools. ‘Types as Comments’ would allow a lot of TS codebases to move back towards alignment with JS. The TS design goals are set up to ensure that TypeScript stays as an non-hostile ‘soft fork’ of the language, thus ‘JS + types’ as the one-liner. Now with ‘Types as Comments’ allowing for ‘types in JS’ to not be a fork but a legit subset instead of superset. Tweets by various people   # \n \n : “Reading through [the proposal], it is clear that this is not going to be easy. It’s mainly hard to decide  . \n For example:   seems simple, but what about  ? \n [...] \n Did you know that    is  ? It makes sense when you think about it, just never did.” \n \n \n : “If I worked on a compiler and I was tasked with making things faster, I would be reaching for those annotations to help pre-optimise code as much as I could!” \n \n Given that  asm.js  and AssemblyScript use type declarations to produce faster code, this idea seems plausible. \n \n \n \n : “The only benefit from my PoV is that I would be able to copy my TS code and evaluate it quickly in a console etc, without stripping the types first.” \n \n Further reading   # \n \n A quick introduction to TypeScript’s type notation:  chapter “The essentials of TypeScript”  in “Tackling TypeScript” \n \n \n Using TypeScript via JSDoc comments and pure JavaScript:  “JSDoc reference”  in the TypeScript handbook \n \n \n Blog post:  “A proposal for type syntax in JavaScript”  by Daniel Rosenwasser \n \n \n ECMAScript poposal:  “Types as comments”  by Gil Tayar, Daniel Rosenwasser, Romulo Cintra, Rob Palmer, and others \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/01/structured-clone.html", "title": "structuredClone() : deeply copying objects in JavaScript", "content": ": deeply copying objects in JavaScript dev javascript jslang Spreading is a common technique for copying objects in JavaScript: \n Spreading into an Array literal  to copy an Array \n Spreading into an Object literal  to copy a plain object \n Spreading has one significant downside – it creates  : The top levels are copied, but property values are shared.  is a new function that will soon be supported by most browsers, Node.js and Deno. It creates deep copies of objects. This blog post explains how it works. \n   \n     On which JavaScript platforms is   available? \n   \n   \n     Copying objects via spreading is shallow \n   \n   \n     Copying objects deeply via  \n   \n   \n     Which values can   copy? \n     \n       \n         Most built-in values can be copied \n       \n       \n         Some built-in values can’t be copied \n       \n       \n         Instances of user-defined classes become plain objects \n       \n       \n         The property attributes of copied objects \n       \n     \n   \n   \n     Sources of this blog post \n   \n   \n     Further reading \n   \n On which JavaScript platforms is   available?   # Even though   is not part of ECMAScript, it was added to the platform-specific parts of many platforms and is still widely available (either now or soon): \n Chrome 98 \n Safari 137 (Technology Preview Release) \n Firefox 94 \n Node.js 17.0 \n Deno 1.14 \n Tips: \n  isn’t always available in WebWorkers – check  the MDN browser compatibility table  for more information. \n On platforms that don’t support  , we can use  a polyfill . \n Copying objects via spreading is     # One common way of copying Arrays and plain objects in JavaScript is via spreading. This code demonstrates the latter: Alas, this way of copying is  . On one hand, the key-value entry   is a copy, so changing it does not change  : On the other hand, the Array in   is shared with  . If we change it, we also change  : Copying objects deeply via     # Structured clone has the following typeSignature: (This function has a second parameter which is rarely useful and beyond the scope of this blog post. I couldn’t even replicate the use case that MDN showed for it. For more information, see  the MDN page for  .)  copies objects deeply: Which values can   copy?   # Most built-in values can be copied   # Primitive values can be copied: Most built-in objects can be copied – even though they have internal slots: However, when copying a regular expression, property   is always reset to zero. Some built-in values can’t be copied   # Some built-in objects cannot be copied –   throws a   if we try to do so: \n Functions (ordinary functions, arrow functions, classes, methods) \n DOM nodes \n Demonstration of the former: What does the exception look like that is thrown by  ? Instances of user-defined classes become plain objects   # In the following example, we copy an instance of the class  . The result,  , is not an instance of  . To summarize –   never copies the prototype chain of an object: \n Copies of built-in objects have the same prototypes as the originals. \n Copies of instances of user-defined classes always have the prototype   (like plain objects). \n The property attributes of copied objects   #  doesn’t always faithfully copy the   of objects: \n Accessors are turned into data properties. \n In copies, the property attributes always have default values. \n Read on for more information. # Accessors become data properties: # Data properties of copies always have the following attributes: Sources of this blog post   # \n Section “Safe passing of structured data”  in the WHATWG HTML standard \n “The structured clone algorithm”  on MDN \n “ ”  on MDN \n Further reading   # \n Chapter “Copying objects and Arrays”  of “Deep JavaScript” \n Chapter “Copying instances of classes:   vs. copy constructors”  of “Deep JavaScript” \n Chapter “Property attributes: an introduction”  of “Deep JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/01/symbol-factory.html", "title": "Setting up symbol-valued constants via proxies", "content": "Setting up symbol-valued constants via proxies dev javascript proxy Dean Tribble (via Rob Palmer) has come up with  a neat trick  to create constants whose values are strings with their names. With a minor change, we can use it to set up symbol-valued constants. Setting up constants   # How does it work?   # Each property of the pattern that object-destructures  , triggers a property   operation. Therefore, line B is equivalent to: The method in line A intercepts each of these   operations. Among other information, it is provided with the key of the relevant property. It then creates and returns a symbol whose description is the property key. Wouldn’t it be better to cache the results?   # You might think that we should cache the results so that every time we use a name, we get the same symbol. We can do that via a   (we can’t use a   because its keys must be objects): Or we can use  : However, each invocation producing a fresh symbol is a feature, not a bug – for example: We want each   to be unique! We could cache and always access factory results via properties of  , but then we aren’t protected against typos and basically get one big enum. Further reading   # \n Chapter “Metaprogramming with Proxies”  in “Deep JavaScript” \n Chapter “Symbols”  in “JavaScript for impatient programmers” \n Chapter “Destructuring”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2009/11/javascript-will-probably-be-moving.html", "title": "JavaScript will (probably) be moving forward", "content": "JavaScript will (probably) be moving forward dev javascript webdev ECMA Harmony and the Future of JavaScript ECMAScript wiki comments powered by Disqus."},
{"url": "https://2ality.com/2022/01/esm-specifiers.html", "title": "Publishing and consuming ECMAScript modules via packages – the big picture", "content": "Publishing and consuming ECMAScript modules via packages – the big picture dev javascript esm Updates: \n 2022-07-23: Documented  how to specify a license for a package in  \n 2022-07-22: Complete rewrite of section “Packages: JavaScript’s units for software distribution”. \n 2022-01-17: Added material on bare specifiers with subpaths that have filename extensions. \n The ecosystem around delivering ECMAScript modules via packages is slowly maturing. This blog post explains how the various pieces fit together: \n Packages – JavaScript’s units for software distribution \n The three kinds of ECMAScript module specifiers \n Providing and using packages via module specifiers in Node.js, Deno and web browsers \n  I’m assuming that you are loosely familiar with the syntax of ECMAScript modules. If you are not, you can read  chapter “modules”  in “JavaScript for impatient programmers”. \n   \n     Packages: JavaScript’s units for software distribution \n     \n       \n         Publishing packages: package registries, package managers, package names \n       \n     \n   \n   \n     The file system layout of a package \n     \n       \n         \n       \n       \n         Property   of  \n       \n       \n         Property   of  \n       \n       \n         Property   of  \n       \n     \n   \n   \n     Archiving and installing packages \n     \n       \n         Installing an existing package from git \n       \n       \n         Creating a new package and installing dependencies \n       \n     \n   \n   \n     Referring to ECMAScript modules via specifiers \n     \n       \n         Filename extensions in module specifiers \n       \n       \n         Using class   to explore how module specifiers work \n       \n     \n   \n   \n     Module specifiers in Node.js \n     \n       \n         Resolving module specifiers in Node.js \n       \n       \n         Package exports: controlling what other packages see \n       \n       \n         Package imports \n       \n       \n          protocol imports \n       \n     \n   \n   \n     Module specifiers in browsers \n     \n       \n         Filename extensions in browsers \n       \n       \n         Using npm packages in browsers \n       \n       \n         Import maps \n       \n     \n   \n   \n     Module specifiers in Deno \n   \n   \n     Further reading and sources of this post \n   \n Packages: JavaScript’s units for software distribution   # In the JavaScripte ecosystem, a   is a way of organizing software projects: It is a directory with a standardized layout. A package can contain all kinds of files - for example: \n A web application written in JavaScript, to be deployed on a server \n JavaScript libraries (for Node.js, for browsers, for all JavaScript platforms, etc.) \n Libraries for programming languages other than JavaScript: TypeScript, Rust, etc. \n Unit tests (e.g. for the libraries in the package) \n Node.js-based shell scripts – e.g., development tools such as compilers, test runners, and documentation generators \n Many other kinds of artifacts \n A package can   other packages (which are called its  ): \n Libraries needed by the package’s JavaScript code \n Shell scripts used during development \n Etc. \n The dependencies of a package are installed inside that package (we’ll see how soon). One common distinction between packages is: \n  can be installed by us:\n \n Global installation: We can install them globally so that their shell scripts become available at the command line. \n Local installation: We can install them as dependencies into our own packages. \n \n \n  never become dependencies of other packages, but do have dependencies themselves. Examples include web applications that are deployed to servers. \n The next subsection explains how packages can be published. Publishing packages: package registries, package managers, package names   # The main way of publishing a package is to upload it to a package registry – an online software repository. The de facto standard is  the   but it is not the only option. For example, companies can host their own internal registries. A   is a command line tool that downloads packages from a registry (or other sources) and installs them as shell scripts and/or as dependencies. The most popular package manager is called   and comes bundled with Node.js. Its name originally stood for “Node Package Manager”. Later, when npm and the npm registry were used not only for Node.js packages, that meaning was changed to “npm is not a package manager” ( source ). There are other popular package managers such as yarn and pnpm. All of these package managers use the npm registry by default. Each package in the npm registry has a name. There are two kinds of names: \n \n  are unique across the whole registry. These are two examples: \n \n \n \n  consist of two parts: A scope and a name. Scopes are globally unique, names are unique per scope. These are two examples: \n \n The scope starts with an   symbol and is separated from the name with a slash. \n \n The file system layout of a package   # Once a package   is fully installed, it almost always looks like this: What are the purposes of these file system entries? \n \n  is a file every package must have: \n \n It contains metadata describing the package (its name, its version, its author, etc.). \n It lists the dependencies of the package: other packages that it needs, such as libraries and tools. Per dependency, we record:\n \n A range of version numbers. Not specifying a specific version allows for upgrades and for code sharing between dependencies. \n By default, dependencies come from the npm registry. But we can also specify other sources: a local directory, a GZIP file, a URL pointing to a GZIP file, a registry other than npm’s, a git repository, etc. \n \n \n \n \n \n  is a directory into which the dependencies of the package are installed. Each dependency also has a   folder with its dependencies, etc. The result is a tree of dependencies. \n \n Some packages also have the file   that sits next to  : It records the exact versions of the dependencies that were installed and is kept up to date if we add more dependencies via npm.    # This is a starter   that can be created via npm: What are the purposes of these properties? \n \n Some properties are required for public packages (published on the npm registry): \n \n  specifies the name of this package. \n  is used for version management and follows  semantic versioning  with three dot-separated numbers:\n \n The   is incremented when incompatible API changes are made. \n The   is incremented when functionality is added in a backward compatible manner. \n The   is incremented when small changes are made that don’t really change the functionality. \n \n \n \n \n \n Other properties for public packages are optional: \n \n ,  ,   are optional and make it easier to find packages. \n  clarifies how this package can be used. It makes sense to provide this value if the package is public in any way.  “Choose an open source license”  can help with making this choice. \n \n \n \n  is a property for packages with library code. It specifies the module that “is” the package (explained later in this chapter). \n \n \n  is a property for setting up abbreviations for development-time shell commands. These can be executed via  . For example, the script   can be executed via  . \n \n Other useful properties: \n \n  lists the dependencies of a package. Its format is explained soon. \n \n \n  are dependencies that are only needed during development. \n \n \n The following setting means that all files with the name extension   are interpreted as ECMAScript modules. Unless we are dealing with legacy code, it makes sense to add it: \n \n \n \n  lists modules within the package that are installed as shell scripts. Its format is explained soon. \n \n \n  specifies a license for the package. Its format is explained soon. \n \n \n Normally, the properties   and   are required and npm warns us if they are missing. However, we can change that via the following setting: \n \n That prevents the package from accidentally being published and allows us to omit name and version. \n \n , see  the npm documentation . Property   of     # This is what the dependencies in a   file look like: The properties record both the names of packages and constraints for their versions. Versions themselves follow the  semantic versioning  standard. They are up to three numbers (the second and third number are optional and zero by default) separated by dots: : This number changes when a packages changes in incompatible ways. : This number changes when functionality is added in a backward compatible manner. : This number changes when backward compatible bug fixes are made. Node’s version ranges are explained in  the   repository . Examples include: \n A specific version without any extra characters means that the installed version must match the version exactly: \n \n  or   means that the components that are numbers must match, the components that are   or omitted can have any values: \n \n  matches any version: \n \n  means that the installed version must be   or higher: \n \n  means that the installed version must be   or lower: \n \n  is the same as  : \n \n  (as used in the previous example) is a   and means that the installed version can be   or higher but must not introduce breaking changes. That is, the major version must be the same: \n \n Property   of     # This is how we can tell npm to install modules as shell scripts: If we install a package with this   value globally, Node.js ensures that the commands   and   become available at the command line. If we install the package locally, we can use the two commands in package scripts or via  the   command . A string is also allowed as the value of  : This is an abbreviation for: Property   of     # The value of property   is always a string with a SPDX license ID. For example, the following value denies others the right to use a package under any terms (which is useful if a package is unpublished): The SPDX website lists all available license IDs . If you find it difficult to pick one,  the website “Choose an open source license”  can help – for example, this is the advice if you “want it simple and permissive”: The MIT License is short and to the point. It lets people do almost anything they want with your project, like making and distributing closed source versions. Babel, .NET, and Rails use the MIT License. You can use that license like this: Archiving and installing packages   # Packages in the npm registry are often archived in two different ways: \n For development, they are stored in a git repository. \n To make them installable via npm, they are uploaded to the npm registry. \n Either way, the package is archived without its dependencies – which we have to install before we can use it. If a package is stored in a git repository: \n We normally want the same dependency tree to be used every time we install the package.\n \n That’s why   is usually included. \n \n \n We can regenerate artifacts from other artifacts – for example, compile TypeScript files to JavaScript files. \n If a package is published to the npm registry: \n It should be flexible with its dependencies so that upgrading dependencies and sharing packages in a dependency tree becomes possible.\n \n That’s why   is never uploaded to the npm registry. \n \n \n It often contains generated artifacts - for example, JavaScript files compiled from TypeScript files are included so that people who only use JavaScript don’t have to install a TypeScript compiler. \n Dev dependencies (property   in  ) are only installed during development but not when we install the package from the npm registry. Note that unpublished packages in git repositories are handled similarly to published packages during development. Installing an existing package from git   # To install an existing package   from git, we clone its repository and: Then the following steps are performed: \n  is created and the dependencies are installed. Installing a dependency also means downloading that dependency and installing its dependencies (etc.). \n Sometimes additional setup steps are performed. Which ones those are can be configured via  . \n If the root package doesn’t have a   file, it is created during installation (as mentioned, dependencies don’t have this file). In a dependency tree, the same dependency may exist multiple times, possibly in different versions. There a ways to minimize duplication, but that is beyond the scope of this blog post. # This is a (slightly crude) way of fixing issues in a dependency tree: Note that that may result in different, newer, packages being installed. We can avoid that by not deleting  . Creating a new package and installing dependencies   # There are many tools and technique for setting up new packages. This is one simple way: Afterward, the directory looks like this: This   has the starter content that we have already seen. # Right now,   doesn’t have any dependencies. Let’s say we want to use the library  . This is how we install it into our package: This command performs the following steps: \n \n The package is downloaded into  . \n \n \n Its dependencies are also installed. Then the dependencies of its dependencies. Etc. \n \n \n A new property is added to  : \n \n \n \n  is updated with the exact version that was installed. \n \n Referring to ECMAScript modules via     # Code in other ECMAScript modules is accessed via   statements (line A and line B): Both static imports and dynamic imports use   to refer to modules: \n The string after   in line A. \n The string argument in line B. \n There are three kinds of module specifiers: \n \n  are full URLs – for example: \n \n Absolute specifiers are mostly used to access libraries that are directly hosted on the web. \n \n \n  are relative URLs (starting with  ,   or  ) – for example: \n \n Every module has a URL whose protocol depends on its location ( ,  , etc.). If it uses a relative specifier, JavaScript turns that specifier into a full URL by resolving it against the module’s URL. \n Relative specifiers are mostly used to access other modules within the same code base. \n \n \n  are paths (without protocol and domain) that start with neither slashes nor dots. They begin with the names of packages. Those names can optionally be followed by  : \n \n Bare specifiers can also refer to packages with scoped names: \n \n Each bare specifier refers to exactly one module inside a package; if it has no subpath, it refers to the designated “main” module of its package. A bare specifier is never used directly but always   – translated to an absolute specifier. How resolution works depends on the platform. We’ll learn more soon. \n \n Filename extensions in module specifiers   # \n Absolute specifiers and relative specifiers always have filename extensions – usually   or  . \n There are three styles of bare specifiers:\n \n Style 1: no subpath \n Style 2: a subpath without a filename extension. In this case, the subpath works like a modifier for the package name: \n \n Style 3: a subpath with a filename extension. In this case, the package is seen as a collection of modules and the subpath points to one of them: \n \n \n \n Caveat of style 3 bare specifiers: How the filename extension is interpreted depends on the dependency and may differ from the importing package. For example, the importing package may use   for ESM modules and   for CommonJS modules, while the ESM modules exported by the dependency may have bare paths with the filename extension  . Using class   to explore how module specifiers work   # Module specifiers are based on URLs, which are a subset of URIs. RFC 3986, the standard for URIs, distinguishes  two kinds of  : \n A   starts with  a scheme  followed by a colon separator. \n All other URI references are  . \n Class   is available on most JavaScript platforms and can be instantiated in two ways: \n \n \n  must be a URI. It specifies the URI of the new instance. \n \n \n \n  must be a URI. If   is a relative reference, it is resolved against   and the result becomes the URI of the new instance. \n If   is a URI, it completely replaces   as the data on which the instance is based. \n \n Here we can see the class in action: Acknowledgement: The idea of using   in this manner and the functions   and   come from Guy Bedford. #  allows us to test how relative module specifiers are resolved against the   of an importing module: # Due to   throwing an exception if a string isn’t a valid URI, we can use it to determine if a module specifier is absolute: # We use   to determine if a specifier is bare: Module specifiers in Node.js   # Let’s see how module specifiers work in Node.js. Especially bare specifiers are handled differently than in browsers. Resolving module specifiers in Node.js   # The   works as follows: \n Parameters:\n \n URL of importing module \n Module specifier \n \n \n Result: Resolved URL for module specifier \n This is the algorithm: \n \n If a specifier is absolute, resolution is already finished. Three protocols are most common: \n \n  for local files \n  for remote files \n  for built-in modules ( discussed later ) \n \n \n \n If a specifier is relative, it is resolved against the URL of the importing module. \n \n \n If a specifier is bare: \n \n \n If it starts with  , it is resolved by looking it up among the   (which are explained later) and resolving the result. \n \n \n Otherwise, it is a bare specifier that has one of these formats (the subpath is optional): \n \n \n \n \n The resolution algorithm traverses the current directory and its ancestors until it finds a directory   that has a subdirectory matching the beginning of the bare specifier, i.e. either: \n \n \n \n \n That directory is the directory of the package. By default, the (potentially empty) subpath after the package ID is interpreted as relative to the package directory. The default can be overridden via   which are explained next. \n \n \n \n The result of the resolution algorithm must point to a file. That explains why absolute specifiers and relative specifiers always have filename extensions. Bare specifiers mostly don’t because they are abbreviations that are looked up in package exports. Module files usually have these filename extensions: \n If a file has the name extension  , it is always an ES module. \n A file that has the name extension   is an ES module if the closest   has this entry:\n \n \n \n \n If Node.js executes code provided via stdin,   or  , we use  the following command-line option  so that it is interpreted as an ES module: Package exports: controlling what other packages see   # In this subsection, we are working with a package that has the following file layout:  are specified via property   in   and support two important features: \n Hiding the internals of a package:\n \n Without property  , every module in package   can be accessed via a relative path after the package name – e.g.: \n \n Once the property exists, only specifiers listed in it can be used. Everything else is hidden from the outside. \n \n \n Nicer module specifiers: Package export let us define bare specifier subpaths for modules that are shorter and/or have better names. \n Recall the three styles of bare specifiers: \n Style 1: bare specifiers without subpaths \n Style 2: bare specifiers with extension-less subpaths \n Style 3: bare specifiers with subpaths with extensions \n Package exports help us with all three styles # : We only provide   for backward-compatibility (with older bundlers and Node.js 12 and older). Otherwise, the entry for   is enough. With these package exports, we can now import from   as follows. This imports   from this file: # : We are mapping the specifier subpath   to a module file. That enables the following import: # The previous subsection explained how to create a single mapping for an extension-less subpath. There is also a way to create multiple such mappings via a single entry: : Any file that is a descendant of   can now be imported without a filename extension: Note the asterisks in this   entry: These are more instructions for how to map subpaths to actual paths than wildcards that match fragments of file paths. # : We are mapping the specifier subpath   to a module file. That enables the following import: # : Here, we shorten the module specifiers of the whole subtree under  : Without the exports, the import statement would be: Note the asterisks in this   entry: These are not filesystem globs but instructions for how to map external module specifiers to internal ones. # With the following trick, we expose everything in directory   with the exception of  Note that this trick also works when exporting subtrees   filename extensions. # We can also make exports  : Then a given path maps to different values depending on the context in which a package is used.  For example, we could provide different implementations for Node.js and for browsers: The   condition matches when no other key matches and must come last. Having one is recommended whenever we are distinguishing between platforms because it takes care of new and/or unknown platforms.  Another use case for conditional package exports is switching between “development” and “production” environments: In Node.js we can specify an environment like this: Package imports   # Package imports  let a package define abbreviations for module specifiers that it can use itself, internally (where package exports define abbreviations for other packages). This is an example: : The package import   is   (with the same features as  conditional package exports ): \n \n If the current package is used on Node.js, the module specifier   refers to package  . \n \n \n Elsewhere,   refers to the file   inside the current package. \n \n (Only package imports can refer to external packages, package exports can’t do that.) What are the use cases for package imports? \n Referring to different platform-specific implementations modules via the same module specifier (as demonstrated above). \n Aliases to modules inside the current package – to avoid relative specifiers (which can get complicated with deeply nested directories). \n Be careful when using package imports with a bundler: This feature is relatively new and your bundler may not support it.  protocol imports   # Node.js has many built-in modules such as   and  . All of them are available as both ES modules and CommonJS modules. One issue with them is that they can be overridden by modules installed in   which is both a security risk (if it happens accidentally) and a problem if Node.js wants to introduce new built-in modules in the future and their names are already taken by npm packages. We can use  the   protocol  to make it clear that we want to import a built-in module. For example, the following two import statements are mostly equivalent (if no npm module is installed that has the name  ): An additional benefit of using the   protocol is that we immediately see that an imported module is built-in. Given how many built-in modules there are, that helps when reading code. Due to   specifiers having a protocol, they are considered absolute. That’s why they are not looked up in  . Module specifiers in browsers   # Filename extensions in browsers   # Browsers don’t care about filename extensions, only about content types. Hence, we can use any filename extension for ECMAScript modules, as long as they are served with  a JavaScript content type  (  is recommended). Using npm packages in browsers   # On Node.js, npm packages are downloaded into the   directory and accessed via bare module specifiers. Node.js traverses the file system in order to find packages. We can’t do that in web browsers. Two approaches are common for bringing npm packages to browsers. # A bundler is a build tool. It works roughly as follows: \n Given a directory with a web app. We point the bundler to the app’s   – the module where execution starts. \n It collects everything that module imports (its imports, the imports of the imports, etc.). \n It produces a  , a single file with all the code. That file can be used from an HTML page. \n If an app has multiple entry points, the bundler produces multiple bundles. It’s also possible to tell it to create bundles for parts of the application that are loaded on demand. When bundling, we can use bare import specifiers in files because bundlers know how to find the corresponding modules in  . Modern bundlers also honor package exports and package imports. Why bundle? \n Loading a single file tends to be faster than loading multiple files – especially if there are many small ones. \n Bundlers only include code in the file that is really used (which is especially relevant for libraries). That saves storage space and also speeds up loading. \n A downside of bundling is that we need to bundle the whole app every time we want to run it. # There are package managers for browsers that let us download modules referenced via bare specifiers as single bundled files that can be used in browsers. As an example, consider the following directory of a web app: We used a bundler to install the module referenced by   into a single file. Module   can import it like this: To deploy this app, the contents of   and   are copied to the production server (in addition to non-JavaScript artifacts). What are the benefits of this approach compared to using a bundler? \n We install the external dependencies once and then can always run our app immediately – no prior bundling required (which can be time-consuming). \n Unbundled code is easier to debug. \n This approach can be further improved:   are a browser technology that lets us define abbreviations for module specifiers – e.g.   for  . Import maps are explained later. Note that with this approach, package exports are not automatically honored. We have to take care that we either use the correct paths into packages and/or set up our import maps correctly. It’s also possible to use tools such as  JSPM Generator  that generate import maps automatically. Such tools can take package exports into consideration. # We have seen two approaches for using npm packages in browsers: Bundling a web app into a single file. Benefits: faster loading, less storage required. Running a web app with separate modules. Benefits: app runs without bundling, easier debugging. In other words: Approach (2) is better during development. Approach (1) is better for deploying software to production servers. And there are indeed build tools that combine both approaches – for example,  Vite : \n \n During development, a web app is run via its local development server. Whenever a browser requests a JavaScript file, the dev server first examines the file. If any import has a bare specifier, the server does two things: \n \n \n The imported module is looked up in   and bundled into a single JavaScript file. That file is cached, so this step only happens the first time a bare specifier is encountered. \n \n \n The JavaScript file is changed so that the import specifier isn’t bare anymore, but refers to the bundle. \n \n \n The changes to the JavaScript code are minimal and local (only one file is affected). That enables on-demand processing via the dev server. The web app remains a collection of separate modules. \n \n \n For deployment, Vite compiles the JavaScript code of the app and its dependencies into one file (multiple ones if parts of the app are loaded on demand). \n \n Import maps   # An import map is a data structure with key-value entries. This is what an import map looks like if we store it   – inside an HTML file: We can also store import maps in external files (the content type must be  ): Terminology: \n The keys of an import map are called  . \n The values are called  . \n How do import maps work? Roughly, Whenever JavaScript encounters an import statement or a dynamic  , it   its module specifier: It looks for the first map entry whose specifier key matches the import specifier and replaces the key’s occurrence with the resolution result. We’ll see concrete examples soon. Let’s dig into more details first.  There are two general categories of specifier keys: Specifier keys without trailing slashes match import specifiers exactly. Specifier keys with trailing slashes match prefixes of import specifiers. In category 1, there are three kinds of specifier keys: \n Bare specifier keys with or without subpaths: \n \n Relative specifier keys start with   ,   or  : \n \n Absolute specifier keys start with protocols: \n \n Category 2 contains the same kinds of specifier keys – except that they all end with slashes.  Resolution results can also end with slashes or not (they have to mirror what the specifier key looks like). There are only two kinds of non-prefix resolution results (bare specifiers are not allowed): \n URLs: \n \n Relative references (must start with  ,  ,  ): \n \n Prefix resolution results also consist of URLs and relative references but always end with slashes.  For import maps,   is important: \n Specifier keys are immediately normalized:\n \n Bare specifier keys and absolute specifier keys remain unchanged. \n Relative specifier keys are resolved against the URL of their import map (  file or   file). \n \n \n Resolution results are also immediately normalized, in the same manner. \n Import specifiers are resolved against the URLs of the importing modules before they are matched against normalized specifier keys. \n Normalization makes it possible to match relative specifier keys against relative import specifiers.    is the process of converting a module specifier to a fetchable URL. To resolve an import specifier, JavaScript looks for the first map entry whose specifier key matches the import specifier: \n \n A specifier key without a slash matches an import specifier if both are exactly equal. In that case, resolution returns the corresponding resolution result. \n \n \n A specifier key with a slash matches any import specifier that starts with it – in other words if the specifier key is a prefix of the import specifier. In that case, resolution replaces the occurrence of the specifier key in the import specifier with the resolution result and returns the outcome. \n \n \n If there is no matching map entry, the import specifier is returned unchanged. \n \n Note that import maps do not affect   elements, only JavaScript imports. # With package exports, we can define: \n Subpaths (empty, with filename extensions, without filename extensions) for single modules: \n \n Subpaths with filename extensions for directories with modules: \n \n Subpaths without filename extensions for directories with modules: \n \n Import maps have analogs to the first two features, but nothing that is similar to the last feature. # # This import map enables these imports: # We can now import like this: # We can now import like this: # We are remapping the import from an external resource to a local file: # The online package contents are remapped to the version we downloaded into  : # To ensure that trees of connected files (think HTML using CSS, image and JavaScript files) are updated together,  a common technique  is to mention  the hash of the file  (which is also called its  ) in the filename. The hash serves as a version number for the file. An import map enables us to use import specifiers without hashes: # Scopes lets us override map entries depending on where an import is made from. That looks as follows (example taken from  the import maps explainer document ): Module specifiers in Deno   # Bare specifiers are rarely used in Deno (but  import maps are available ). Instead, libraries are accessed via URLs with version numbers – for example: These URLs are abbreviated via  the following technique : Per project, there is a file   that re-exports library exports that are used more than once: Other files get their imports from  : Deno caches absolute imports. Its cache can be persisted, e.g. to ensure that it’s available when a computer is offline.  Example in Deno’s manual : Further reading and sources of this post   # Further reading: \n Chapter “Modules”  in “JavaScript for impatient programmers” \n “TypeScript and native ESM on Node.js”  on 2ality \n Sources of this blog post: \n RFC 3986: URI Generic Syntax \n “Modules: ECMAScript modules”  in the Node.js documentation \n “Modules: packages”  in the Node.js documentation \n Readme of “Import Maps” (W3C draft community group report) \n The following people provided important input for this blog post: \n Myles Borins \n Bradley Farias \n Titus \n Martín Ciparelli \n I’m very grateful for his review of this blog post: \n Guy Bedford \n comments powered by Disqus."},
{"url": "https://2ality.com/2022/01/array-grouping.html", "title": "ECMAScript proposal: grouping Arrays via  .group()  and  .groupToMap()", "content": "ECMAScript proposal: grouping Arrays via   and  dev javascript es proposal This blog post describes the ECMAScript proposal  “Array grouping”  by Justin Ridgewell. \n   \n     Grouping Arrays \n     \n       \n         How to choose between   and  ? \n       \n     \n   \n   \n     Use cases for grouping \n     \n       \n         Handling cases \n       \n       \n         Grouping by property value \n       \n       \n         Counting elements \n       \n     \n   \n   \n     What if each input Array element can belong to multiple groups? \n   \n   \n     Implementations \n     \n       \n         Implementing grouping ourselves \n       \n       \n         Libraries \n       \n     \n   \n   \n     Acknowledgements \n   \n Grouping Arrays   # The proposal introduces two new Array methods: \n \n \n These are their type signatures: Both methods   Arrays: \n Input: an Array \n Output: groups. Each group has a   and an Array with  . \n The algorithm iterates over the Array. For each Array element, it asks its callback for a group key and adds the element to the corresponding group. Therefore: Concatenating all group members is equal to the input Array – if we ignore the order of elements. The two methods differ in how they represent the groups: \n  stores the groups in an object: Group keys are stored as property keys. Group members are stored as property values. \n  stores the groups in a Map: Group keys are stored as Map keys. Group members are stored as Map values. \n In the next section, we’ll look into use cases for grouping and which method to use for which use case. This is a first example of grouping: The prototype of the object returned by   is  . That makes it a better dictionary because no properties are inherited and property   does not have any special behavior (for details see  “JavaScript for impatient programmers” ). How to choose between   and  ?   # How do we choose between the two grouping methods? If we want to destructure (and we know the group keys ahead of time), we use  : Otherwise, using a Map has the benefit that keys are not limited to strings and symbols. We’ll see   in action soon. Use cases for grouping   # These are three common use cases for group Arrays: \n Handling cases:\n \n There is a fixed set of group keys that we know ahead of time. \n We want one Array with values per case. \n \n \n Grouping by property value:\n \n We get an arbitrary set of group keys. \n We are interested in [group key, group members] pairs. \n \n \n Counting members of groups:\n \n This use case is similar to grouping by property value, but we are only interested in how many input Array elements have a given property value, not in which elements they are. \n \n \n Next, we’ll see an example for each use case and which of the two grouping methods is a better fit. Handling cases   # The     returns Arrays such as the following one: We can group the Array elements as follows: For this use case,   works better because we can use destructuring (line A). Grouping by property value   # In the next example, we’d like to group persons by country: For this use case,   is a better choice because we can use arbitrary keys in Maps whereas in objects, keys are limited to strings and symbols. Counting elements   # In the following example, we count how often each word occurs in a given text: We are only interested in the sizes of the groups. In line A, we take a detour via an Array because Maps don’t have a method  . Once again, we use   because Maps can have arbitrary keys. What if each input Array element can belong to multiple groups?   # We cannot use the grouping methods if each element of the input Array can belong to multiple groups. Then we have to write our own grouping function – for example: Implementations   # Implementing grouping ourselves   # These are simple implementations of the two grouping methods: Libraries   # \n core-js has poyfills for   and  . \n The Lodash method   is equivalent to  . \n Acknowledgements   # \n The discussion in  this Twitter thread helped me with this blog post  – e.g. responses by:\n \n \n \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/02/latex-pdf-slides-and-dual-displays.html", "title": "LaTeX, PDF slides, and dual displays", "content": "LaTeX, PDF slides, and dual displays latex hack presenting computers pdf TeX Live Beamer Class themes PDF Presenter  (Windows) \n SplitShow  (Mac OS) \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/09/seven-donts-for-websites.html", "title": "Seven don’ts for websites", "content": "Seven don’ts for websites dev webdev computers web The following is a list of seven things that frequently bug me about websites. \n  If I go to foo.com then the .com indicates that I want to see the American version of the Foo Inc. website. I do not want to see a map of the world where I need to click several times to finally get to my destination. A better solution is to put a link somewhere that allows you to jump to other versions. Flag icons work well here, because you don't need to understand the language of the current version to jump to a different one (e.g. finding “Germany” on a Chinese website is difficult if you don't read Chinese). \n \n  If you use a web browser, the websites you are visiting know your   (five digits such as 127.0.0.1). In principle, this address is completely abstract (as opposed to, say, ZIP codes which can be mapped to a location), but there are databases that allow you to map it back to a location. This works pretty well, but is sometimes abused to automatically switch to the language of your location. But what if you are an American who is abroad and wants to access an American website. Or if you are German and want to check out an American website (not its German version). Solution: A small note in the language the site thinks it has detected. Something like “Click here to see the English version of this page”. \n \n  Often such a page shows a movie that tells you what the website is about. By all means, link to introductory information on the home page, but don't force me to watch/read it, every time. \n \n  I don't particularly like Flash. It still has its uses for video, but most other things can now be done in HTML5. With Flash, you cannot bookmark pages or copy text. The website's content cannot be found via Google and it won't work on (most) mobile devices. Furthermore, most Flash websites make up strange new ways of navigation. Why change something that people know and that works well? \n \n  URLs should be compact and easily understandable by humans. That is, one should be able to figure out what a page is about by looking at the URL. Thus, if the page ever goes away, one has a greater chance of finding out where it went. Amazon is both a sinner and a saint here. Some Amazon URLs have a lot of ugly pieces in them (“ref” and such). On the other hand, book URLs sometimes include the ISBN and an abbreviation of the title. This is a great practice, because the ISBN is a unique ID that is useful to both machines and humans and because the title allows humans to figure out what is there. Lazy programmers sometimes let the fact that there is a single script that displays all web pages show up in the URL: www.example.com/display.php?page=start. Even worse are meaningless page IDs (?page=17). Both can be avoided by putting in a little more effort. \n \n  Often, a website shows all kinds of details, so that the things that people are most frequently looking for are hard to find. Especially expert-designed web pages suffer from this, because it is often difficult to focus for experts (in their area of expertise). Examples are bank and government websites. But food websites are also often problematic: I don't want to play a game, I want to find out about the products and/or their ingredients. Example: See picture below. \n \n  This is fortunately rare, but every now and then, I discover an error page in my browser that says “page does not exist”. The problem is that the original URL is nowhere to be found: The error page URL has replaced it in the browser address bar (=history cannot be used) and it isn't displayed on the error page. If there are many tabs open then it's really hard to figure out what went wrong. \n  Forbidding or enforcing characters in passwords. As if passwords weren't annoying enough on their own, some sites decide to make handling them even more complicated. Hassles I've experienced so far were: At most 10 characters allowed, no punctuation allowed, must use a digit. Source:  xkcd comments powered by Disqus."},
{"url": "https://2ality.com/2010/03/collecting-only-those-bibtex-entries.html", "title": "Collecting only those BibTeX entries that are used in a document", "content": "Collecting only those BibTeX entries that are used in a document latex hack computers RefTeX  (comes with Emacs): Invoke “Ref -> Global Actions -> Create BibTeX File”. RefTeX continues to amaze me, it has many useful features for managing references, tables of contents, etc. \n \n Bibtool  (available e.g. via MacPorts) \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/09/foreign-languages-four-ways-to-avoid.html", "title": "Foreign languages: four ways to avoid learning vocabulary", "content": "Foreign languages: four ways to avoid learning vocabulary foreign languages life  Instead, there is  evidence  that beginners fare much better if they can remain passive. Otherwise, they would be asked to build on something that they don’t understand and that decreases confidence. I admit that this one is a bit counter-intuitive, but if you think about how long children stay relatively mute and mainly observe, it makes more sense.  Instead, it’s best to learn words in context. Learning individual words is hard, learning words in context is easier. The best example is how much text one remembers from songs in a foreign language. One “learns” the song as a whole and not the words, but one remembers their meaning, too, as a byproduct. Context and (less painful) repetition seem to help with recall.  Instead, it’s best to learn building blocks. If you know a language well, you don’t apply grammar rules, you use pieces you know. If something is grammatically incorrect, it “sounds wrong”, finding out why is much more complicated. That is, you have an intuitive feeling instead of explicit knowledge of the grammar. Backpedaling a little, I do think you should learn grammar (e.g., I find  conjugation tables  helpful), but its role is to support the building blocks and not the other way around.  Take a short text in the foreign language and read it aloud many times. Most traditional textbooks contain this kind of text. Before you start reading, make sure that you understand the text. You should also listen to it being read by a native speaker. If a word is difficult, you write the translation above it (this is where the text becomes bilingual). The translation should be word by word, even if there is a better (non-literal) translation. This makes sure that you stay in the foreign language as much as possible. The repetition leads to the sentences being memorized and saying it aloud is speaking practice (without any uncertainties). [I’ve used this method for years, but have also later encountered it in the great German book “ Sprachen lernen leicht gemacht ” by Vera F. Birkenbihl.]  Download an MP3 in the foreign language and listen to it without actively trying to understand it. This is a complementary measure to other ways of learning a language and makes the sound of the language more familiar to you. It is best to start when you already understand a little. Repeating the same material several times is also beneficial. Thankfully, the internet now provides us with all kinds of MP3 material: news, podcasts, etc.  It was just the other day that I’ve heard about a new auditory method for learning a language that is called “ No-Work Spanish ”. You listen to an audio book where each sentence in Spanish is followed by the translation in English. This method is the auditory analog of (1) and could obviously be adapted to other foreign and native languages. \n Pimsleur  also provides auditory language courses. \n  This is my abbreviated name for the  Rosetta Stone  language course series. It is obviously a simplification and you should read their web pages for an accurate description. Rosetta Stone (RS) simulates a child’s experience of adults pointing at things. It does so via a computer program that shows and names pictures with things, activities etc. You have a choice between ordering a CD with the program or of running the program online. In both cases it is the same program (a web application, including Flash technology). RS also employs voice recognition to check your pronunciation. All of RS is technically really well done: You can click on almost anything to hear it spoken; there is an alphabet with example words that is always accessible (I tested it with Russian); etc. Alas, it wasn’t for me. The words that I learned with RS did not stick, whereas I have no such problems when using method (1). But I’ve always found that I needed to see a word in writing if I wanted to remember it (RS is not all about pictures, but enough so that I prefer method (1)). So if you have a different learning style, this might well be the perfect solution for you. To find out if it is, you can check out the free test drive at their web site. You also have to see if you can afford it (=it is not cheap). As an aside, it would be nice to see their technology (such as clicking on a word to hear its pronunciation) applied to method (1). \n \nAnother visual way of learning new words are picture dictionaries. Googling for “picture dictionary” turns up great resources, many of them free. Flattr comments powered by Disqus."},
{"url": "https://2ality.com/2010/02/next-generation-of-web-application-ui.html", "title": "The next generation of web application UI layout", "content": "The next generation of web application UI layout dev webdev layout \n Sproutcore : Looks great, JavaScript-centric, borrows patterns from Ruby on Rails (project layout, models) and Cocoa (binding, properties). Sproutcore has a Ruby-based generator for code that makes it easy to get started and is itself easy to install, thanks to Ruby’s Gem packaging mechanism. Sproutcore is used by Apple for MobileMe. Current disadvantages: sparsely documented, relatively slow development turn-around (it takes a while to reload after changes).  Demos . \n \n Google Web Toolkit (GWT) : Java-centric, having a single code base on client and server is priceless, great tooling (Eclipse), fast development turn-around, well documented. The new kind of layout is a feature called “ Layout Panels ”. GWT is used by Google for Google Wave.  Demos . \n Cappuccino : I have not tried this one out. I’m not sure that having a custom language (Objective-J) on top of JavaScript is the way to go, especially as Sproutcore does most (all?) of what Objective-J is capable of in pure JavaScript. Cappuccino has a cool browser-based IDE and GUI builder called  Atlas . \n blog post The ultimate CSS layout spec for webapps comments powered by Disqus."},
{"url": "https://2ality.com/2009/11/javas-missing-features.html", "title": "Things I miss most in Java", "content": "Things I miss most in Java dev java \n  are useful for implementing abstractions that involve behavior. Smalltalk provides ample proof that functions and object-orientation go together well. Instead of giving Java functions as objects, its creators decided to support the encapsulation of behavior via inner classes. At long last, it looks like  Java 7 will have closures . They are essentially functions with built-in compatibility with single-method interfaces. Not perfect, but certainly very useful.\n \n  are also coming to Java 7. Reinier Zwitserloot has a nice  write-up  of the rationale and current state of Jigsaw, Java’s module system. It is interesting that one requirement was that module have to cross-cut packages so that the core of Java can be properly modularized. \n  let one repeatedly invoke a method. The method does not return a value, it   it. A yielded value is passed to the caller in the same manner as with a return statement. But, the next time the method is invoked, execution continues after the last yield. Thus, a yield suspends method execution, and an invocation resumes it. This helps whenever data has to be computed  , on demand and in a piecemeal fashion: (The beginning of) an infinite list can be iterated over by writing a generator with an infinite loop. Tree iterators become trivial to write; one uses a generator and recursion. And so on... Astonishingly, generators are already in an  experimental version  of the JVM.\n \n  are class fragments that can be added to (mixed in) any given class, while defining it. The effect is similar to multiple inheritance, but results in a chain of classes (and not a tree, as with true multiple inheritance). Mix-ins are also sometimes called abstract subclasses, because they are classes whose superclass is left to be filled in. While it doesn’t look like mix-ins will be added to Java anytime soon, they could be simulated by tools as interfaces with implementations: If one attaches method implementations to special  s, those implementations could be automatically added to classes implementing such interfaces. While the compiled code will contain redundancies, the source code won’t and subtyping will work as expected. The attaching could be done by letting an annotation refer to a class. \n  Wouldn’t it be nice if one could let a class implement an interface after it has already been defined? After all, one can add new leaves to the inheritance tree, why not new inner nodes? This would give one many of the benefits of duck typing, while keeping compile-time checking. \n multiple dispatch better code browsing comments powered by Disqus."},
{"url": "https://2ality.com/2010/04/gwt-important-java-technology-features.html", "title": "GWT, an important Java technology: features, future and wishes", "content": "GWT, an important Java technology: features, future and wishes gwt dev java DWR Dojo A single code base for client and server. Great development tools, via Eclipse: refactoring, code navigation, etc. This was one of the reasons the creators of GWT chose Java as the source language. Server-side JavaScript certainly would have been a possibility, and compiling JavaScript to JavaScript is not  unheard  of, either.\n Quick turn-around: after making changes, the server and client can be reloaded quickly to reflect those changes (only the first start of the client is a bit slow, subsequent reloads are fast). Easy install of development tools: All you need are two Eclipse plugins and you are done. IDE support: One of the Eclipse plugins helps with various coding tasks and errors (such as keeping Service and AsyncService consistent). Easy deployment of applications: GWT produces a WAR file. Drop it into a servlet container such as Jetty or Tomcat. Done. Fast and reliable GUI layout : Still limited compared to what Swing and SWT offer, but for the first time acceptable. True client-side technology: GWT is tightly integrated into the browser environment and stays close to JavaScript. This makes it easy to keep pace with the rapid progress that browsers are making. GWT is also one of the few Java frameworks that can be used to write offline web applications, because it relies so little on the server.\n gwt-dnd : Implements Drag and Drop in pure GWT. Smart GWT : GWT does currently not have too many widgets. Smart GWT is a GWT wrapper around the SmartClient JavaScript library which has lots of widgets. While GWT is really good at this kind of wrapping, there is some baggage involved: load times of web applications increase, and there is a new API to learn.\n GWT Mosaic : Also extends GWT, but as pure GWT and with less widgets/features. Other wrappers for JavaScript libraries exist. But beware, some of them have very restrictive licenses.\n Currently, the  GWT incubator  hosts experimental features. Long-term, its parts will be migrated to either separate projects or the GWT core. A  post  reveals interesting things about GWT’s future. For example, it will get  data-backed widgets .\n More widgets: The current widgets are limited (menus don’t ensure that they are visible, no support for shortcuts, no resizable dialogs, no context menus, etc.) and there are not enough of them. I expect this area to improve quickly, though, now that all the important foundations have been laid (event handlers, modular CSS, layout panels). Switching back-ends: Many computers are only intermittently online.  Programming an offline mode for a GWT application is difficult, because  the server usually hosts important functionality. A hypothetical way of  solving this is by installing a back-end locally. The client could  switch between this back-end and the server. Managing installed back-ends should  work similar to Java Web Start. A local back-end could also  provide a GWT application with desktop features, because it has access  to desktop resources such as the file system. Better client-side modularity: I love Eclipse’s modularity, especially  when working in a team. You can have a core plugin that is extended via  other plugins residing in separate projects. It would be nice if one  could extend a GWT application in a similar fashion. On the server side  that is possible via OSGi. On the client side, that is currently not  possible. Sending binary data from server to browser: For example, one cannot  create images on the server and send them to the client via RPC.  Data URIs  are a  work-around, but a poor one. Annotations for hiding code from the client: If an object is  transferred back and forth between client and server, there are often some server-only methods. An annotation would allow one to hide those methods. There is an  issue  for this feature. You can star it, if you would like to see it fixed.\n Instantiating classes via class literals: There is no Class.newInstance() in client-side GWT. One has to resort to sending a factory to the client. Two two useful methods: Class#getSimpleName(), String.format() are simple to implement, so I don’t see the reason for not doing so in client-side GWT. Simpler unscrambling of GWT method names: If you want to invoke GWT code from JavaScript you need to prevent GWT from scrambling your method names.  Doing this  is a bit more complicated than it should be. A simpler solution would be to add an annotation to methods whose names one wants to preserve.\n comments powered by Disqus."},
{"url": "https://2ality.com/2010/10/use-bash-as-stop-watch.html", "title": "Use Bash as a stop watch", "content": "Use Bash as a stop watch dev hack shell If you need to time something and don’t want to use any fancy GUI apps, you can use the following command in the Bash shell (Mac OS X or Linux terminal): Explanation: Print out time and date, wait for a single key to be pressed (  prevents that key from being shown), and print out time and date again.  Great suggestion from the comments. The following is an even simpler solution (hit return at the end of the line to start the stop watch, hit return again to stop it). comments powered by Disqus."},
{"url": "https://2ality.com/2010/08/3-ted-talks-on-education.html", "title": "3 TED talks on education", "content": "3 TED talks on education education life ted video Dan Meyer: Math class needs a makeover \n Charles Leadbeater: Education innovation in the slums \n Sugata Mitra: How kids teach themselves \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/10/ish-node-ios.html", "title": "Running Node.js on iOS and iPadOS via iSH", "content": "Running Node.js on iOS and iPadOS via iSH dev javascript nodejs ios ipados The iOS/iPadOS app iSH is available on  the app store  and runs Linux via x86 emulation. And you can install Node.js on it! Installing Node.js on iSH   # \n \n  How is explained  in the project’s wiki . \n \n \n    ( source ) \n \n \n   \n \n \n The Wiki has  a list of packages  that can be installed in the same manner. \n \n Acknowledgement   # If found out that running Node.js on iSH is now possible via  a tweet  by @asciidisco. comments powered by Disqus."},
{"url": "https://2ality.com/2021/01/undefined-null-revisited.html", "title": "undefined  vs.  null  revisited", "content": " vs.   revisited dev javascript jshistory Many programming languages have one “non-value” called  . It indicates that a variable does not currently point to an object – for example, when it hasn’t been initialized yet. In contrast, JavaScript has two such non-values:   and  . In this blog post, we examine how they differ and how to best use or avoid them. \n   \n      vs.  \n     \n       \n         The ECMAScript language specification on   vs.  \n       \n       \n         Two non-values – a mistake that can’t be removed \n       \n       \n         The history of   and  \n       \n     \n   \n   \n     Occurrences of   in the language \n   \n   \n     Occurrences of   in the language \n   \n   \n     Operators that treat   and/or   specially \n     \n       \n          and parameter default values \n       \n       \n          and destructuring default values \n       \n       \n          and   and optional chaining \n       \n       \n          and   and nullish coalescing \n       \n     \n   \n   \n     Handling   and  \n     \n       \n         Neither   nor   are used as actual values \n       \n       \n         Either   or   is a “switched off” value \n       \n       \n         Other ways of handling “switched off” \n       \n     \n   \n   \n     My approach \n   \n  vs.     # Both values are very similar and often used interchangeably. How they differ is therefore subtle. The ECMAScript language specification on   vs.     # The ECMAScript language specification describes them as follows: \n  is “used when a variable has not been assigned a value”  (source) . \n  “represents the intentional absence of any object value”  (source) . \n We’ll see later how to best handle these two values as a programmer. Two non-values – a mistake that can’t be removed   # Having two non-values in JavaScript is now considered a design mistake (even by JavaScript’s creator, Brendan Eich). Why isn’t one of those values removed from JavaScript, then? One core principle of JavaScript is to never break backward compatibility. That principle has  many upsides . Its biggest downside is that design mistakes can’t be removed. The history of   and     # In Java (which inspired many aspects of JavaScript), initialization values depend on the static type of a variable: \n Variables with object types are initialized with  . \n Each primitive type has its own initialization value. For example,   variables are initialized with  . \n In JavaScript, each variable can hold both object values and primitive values. Therefore, if   means “not an object”, JavaScript also needs an initialization value that means “neither an object nor a primitive value”. That initialization value is  . Occurrences of   in the language   # If a variable   has not been initialized yet, its value is  : If a property   is missing, accessing the property produces the values  : If a function does not explicitly return anything, the function implicitly returns  : If a function has a   statement without an argument, the function implicitly returns  : If a parameter   is omitted, the language initializes that parameter with  : Optional chaining  via   returns   if   is   or  : Occurrences of   in the language   # The prototype of an object is either an object or, at the end of a chain of prototypes,  .   does not have a prototype: If we match a regular expression (such as  ) against a string (such as  ), we either get an object with matching data (if matching was successful) or   (if matching failed): The  JSON data format  does not support  , only  : Operators that treat   and/or   specially   #  and parameter default values   # A parameter default value is used if: \n A parameter is missing. \n A parameter has the value  . \n For example: That   also triggers the parameter default value points towards it being a metavalue. The following example demonstrates where that is useful: In line A, we don’t specify a parameter default value for  . When this parameter is missing, we forward that status to   and let it pick a default value.  and destructuring default values   # Default values in destructuring work similarly to parameter default values – they are used if a variable either has no match in the data or if it matches  :  and   and optional chaining   # When there is  optional chaining  via  : \n If   is   or  , return  . That is, this happens whenever   would throw an exception. \n Otherwise, return  . \n The following two operations work similarly:  and   and nullish coalescing   # The  nullish coalescing operator   lets us use a default value if a value is   or  : The  nullish coalescing assignment operator   combines nullish coalescing with assignment: Handling   and     # The following subsections explain the most common ways of handling   and   in our own code. Neither   nor   are used as actual values   # As an example, we may want a property   to always exist and to always be a string. There are two common ways to achieve this. Note that, in this blog post, we only check for   and   and not whether a value is a string or not. You have to decide for yourself if you want to implement that as an additional security measure or not. # This looks as follows: Why choose this approach? \n \n We want to treat   and   the same because JavaScript code often does – for example: \n \n \n \n If there is an issue in our code and either   or   appears, we want it to fail as quickly as possible. \n \n # This looks as follows: We can’t use a parameter default value here because it is only triggered by  . Instead, we rely on the  nullish coalescing assignment operator  . Why choose this approach? \n We want to treat   and   the same (see previous section). \n We want our code to deal robustly and silently with   and  . \n Either   or   is a “switched off” value   # As an example, we may want a property   to be either a string or “switched off” (  doesn’t have a title). There are several ways to achieve this. # This looks as follows: Alternatively,   can trigger a default value: Why choose this approach? \n We need a non-value that means “switched off”. \n We don’t want our non-value to trigger parameter default values and destructuring default values. \n We want to stringify the non-value as JSON (something that we can’t do with  ). \n # This looks as follows: Why choose this approach? \n We need a non-value that means “switched off”. \n We do want our non-value to trigger parameter default values and destructuring default values. \n One downside of   is that it is often created accidentally in JavaScript: by an uninitialized variable, a typo in a property name, forgetting to return something from a function, etc. # When receiving a value, it can make sense to treat both   and   as “not a value”. However, when we are creating values, we want to be unambiguous so that handling those values remains simple. This points toward a different approach: What if we need a “switched off” value, but don’t want to use either   or   as such a value? Read on for details. Other ways of handling “switched off”   # # We can create a special value that we use whenever the property   is switched off: # The   comes from object oriented programming: \n All subclasses of a common superclass have the same interface. \n Each subclass implements a different mode in which an instance operates. \n One of those modes is “null”. \n In the following example,   implements the “null” mode. We also could have used the null object pattern for just the title (instead of for the whole file object). # The Maybe type is a function programming technique: We could have encoded “just” and “nothing” via Arrays. The benefit of our approach is that it is well supported by TypeScript (via  discriminating unions ). My approach   # There are three reasons why I don’t like to use   as a “switched off” value: \n  often appears accidentally in JavaScript. \n  triggers default values for parameters and destructuring (some people prefer   for the same reason). \n Therefore I use either of the following two approaches if I need a special value: \n I use   as a “switched off” value. (As an aside, this approach is relatively well supported by TypeScript.) \n I avoid both   and   via one of the techniques described above. This has the upside of being cleaner and the downside of involving more work. \n \nMy book  “JavaScript for impatient programmers”  is free to read online! This is its sales pitch: This book makes JavaScript less challenging to learn for newcomers, by offering a modern view that is as consistent as possible. comments powered by Disqus."},
{"url": "https://2ality.com/2021/01/looping-over-arrays.html", "title": "Looping over Arrays:  for  vs.  for-in  vs.  .forEach()  vs.  for-of", "content": "Looping over Arrays:   vs.   vs.   vs.  dev javascript This blog post compares four ways of looping over Arrays: \n \n The   loop: \n \n \n \n The   loop: \n \n \n \n The Array method  : \n \n \n \n The   loop: \n \n \n  is often the best choice. We’ll see why. \n   \n     The   loop [ES1] \n   \n   \n     The   loop [ES1] \n   \n   \n     The Array method   [ES5] \n     \n       \n         Breaking from   – a workaround \n       \n     \n   \n   \n     The   loop [ES6] \n     \n       \n          and iterable objects \n       \n       \n          and Array indices \n       \n       \n          and the entries ([index, value] pairs) of an Array \n       \n     \n   \n   \n     Conclusion \n   \n The   loop [ES1]   # The plain   loop in JavaScript is old. It already existed in ECMAScript 1. This   loop logs the index and value of each element of  : What are the pros and cons of this loop? \n It is quite versatile, but alas also verbose when all we want to do is loop over an Array. \n It is still useful if we don’t want to start looping with the first Array element. None of the other looping mechanisms let us do that. \n The   loop [ES1]   # The   loop is as old as the   loop – it also already existed in ECMAScript 1. This   loop logs the keys of  :  is not a good choice for looping over Arrays: \n It visits property keys, not values. \n As property keys, the indices of Array elements are strings, not numbers ( more information on how Array elements work ). \n It visits all enumerable property keys (both own and inherited ones), not just those of Array elements. \n  visiting inherited properties does have a use case: Looping over all enumerable properties of an object. But even here, I’d prefer iterating over the prototype chain manually because you have more control. The Array method   [ES5]   # Given that neither   nor   are particularly well suited for looping over Arrays, a helper method was introduced in ECMAScript 5:  : This method is really convenient: It gives us access to both Array elements and Array element indices without us having to do much. Arrow functions (which were introduced in ES6) made this method even more syntactically elegant. The main downsides of   are: \n You can’t use   in the “body” of this kind of loop. \n You can’t leave a   loop early. In   loops, we can use  . \n Breaking from   – a workaround   # There is a workaround if you want to use a loop like   and leave early:   also loops over all Array elements and stops if its callback returns a truthy value. Arguably, this is an abuse of   and I’m not sure how easy it is to understand this code (compared to   and  ). The   loop [ES6]   # The   loop was added to JavaScript in ECMAScript 6:  works really well for looping over Arrays: \n It iterates over Array elements. \n We can use  .\n \n And it’s easy to migrate to  , should you need to. \n \n \n We can use   and   – even for outer scopes. \n  and iterable objects   # An additional benefit of   is that we can loop not just over Arrays, but over any iterable object – for example, over Maps: Iterating over   produces [key, value] pairs which we  destructure  to directly access the components of each pair.  and Array indices   # The Array method   returns an iterable over the indices of an Array:  and the entries ([index, value] pairs) of an Array   # The Array method   returns an iterable over [index, value] pairs. If we use   and destructuring with this method, we get convenient access to both indices and values: Conclusion   # As we have seen, the   loop beats  ,  , and   w.r.t. usability. Any difference in performance between the four looping mechanisms should normally not matter. If it does, you are probably doing something very computationally intensive and switching to WebAssembly may make sense. \nMy book  “JavaScript for impatient programmers”  is free to read online! This is its sales pitch: This book makes JavaScript less challenging to learn for newcomers, by offering a modern view that is as consistent as possible. comments powered by Disqus."},
{"url": "https://2ality.com/2021/06/error-cause.html", "title": "ECMAScript proposal: Error cause (chaining errors)", "content": "ECMAScript proposal: Error cause (chaining errors) dev javascript es proposal In this blog post, we examine  the ECMAScript proposal “Error cause”  (by Chengzhong Wu and Hemanth HM). It describes a feature where instances of   can optionally specify that they were caused by another error. \n   \n     Why would we want to chain errors? \n   \n   \n     How to chain errors \n     \n       \n         Consequence for your own code \n       \n     \n   \n   \n     Alternatives to the built-in support for  \n     \n       \n          (created by  ) \n       \n       \n         A custom error class \n       \n       \n         A library \n       \n     \n   \n   \n     More information on exception handling in JavaScript \n   \n Why would we want to chain errors?   # Sometimes, we catch errors that are thrown during a more deeply nested function call and would like to attach more information to it: The statements inside the   clause may throw all kinds of errors. In most cases, an error won’t be aware of the path of the file that caused it. That‘s why we would like to attach that information in line A. How to chain errors   # The proposal enables us to do the following:  and its subclasses now have an object with options as a second parameter. The first supported option is   – the error that caused the current error. Consequence for your own code   # If you subclass  , it makes sense to support the second parameter with options: Alternatives to the built-in support for     #  (created by  )   # If   rejects its returned Promise, the rejection value is an instance of   that records which (zero or more) errors caused the rejection:  is a reasonable workaround if   is not supported on an engine that you are targeting, however: \n  works best if we are handling multiple concurrent invocations. \n  with   works best for single non-concurrent calls. \n A custom error class   # The following custom error class supports chaining. A library   # There are several libraries that support chaining errors. Three examples: \n Node.js and browsers:  node-common-errors \n Node.js only:  node-verror \n Node.js only:  composite-error \n More information on exception handling in JavaScript   # \n Chapter “Exception handling”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/09/ecmascript-2021.html", "title": "ECMAScript 2021", "content": "ECMAScript 2021 dev javascript es2021   The 121st Ecma General Assembly approved the  ECMAScript 2021 language specification , which means that it’s officially a standard now. This blog post describes what’s new. The editors of ECMAScript 2021   # The editors of this release are: \n Jordan Harband \n Shu-yu Guo \n Michael Ficarra \n Kevin Gibbons \n A word on ECMAScript versions   # Note that since  the TC39 process  was instituted, the importance of ECMAScript versions has much decreased. What really matters now is what stage a proposed feature is in: Once it has reached stage 4, it can be used safely. But even then, you still have to check if your engines of choice support it. The features of ES2021 (stage 4 proposals)   # \n \n  (Peter Marshall, Jakob Gruber, Mathias Bynens) \n \n \n  (Mathias Bynens, Kevin Gibbons, Sergey Rubanov) \n \n \n WeakRefs (Dean Tribble, Mark Miller, Till Schneidereit, Sathya Gunasekaran, Daniel Ehrenberg) [ proposal ] \n \n \n Logical assignment operators  (Justin Ridgewell, Hemanth HM) \n \n \n Underscores ( ) as separators in  number literals  and  bigint literals  (Sam Goto, Rick Waldron) \n \n FAQ   # What do the stages mean?   # They refer to maturity stages of the so-called “TC39 process”. Check  section “The TC39 process”  in “JavaScript for impatient programmers” for more information. How is [my favorite proposed feature] doing?   # If you are wondering what stages various proposed features are in, consult  the readme of the ECMA-262 GitHub repository . Is there an official list of ECMAScript features?   # Yes, the TC39 repo lists  finished proposals  and mentions in which ECMAScript versions they are introduced. Free books on ES2021   # The following books cover JavaScript up to and including ECMAScript 2021 and are free to read online: \n “JavaScript for impatient programmers” \n “Deep JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2021/06/json-modules.html", "title": "ECMAScript proposal: JSON modules", "content": "ECMAScript proposal: JSON modules dev javascript es proposal In this blog post, we examine  the ECMAScript proposal “JSON modules”  (by Sven Sauleau, Daniel Ehrenberg, Myles Borins, and Dan Clark). It lets us import JSON data as if it were an ECMAScript module. \n   \n     Why would we want to import JSON like a module? \n   \n   \n     Getting JSON data via  \n   \n   \n     Dynamically importing JSON modules via  \n   \n   \n     Why the extra syntax? \n   \n   \n     Availability \n   \n   \n     More information on modules in JavaScript \n   \n Why would we want to import JSON like a module?   # Various bundlers (such as webpack) have allowed us to import JSON data as if it were an ECMAScript module for a long time. JSON modules turn this into a standard feature. Why is that interesting? It provides a convenient way of using, e.g., configuration data in our apps. Take, for example, the following file structure:  looks as follows: This is  : The syntax from   until the end is called an  . JSON modules were one of the use cases for which import assertions were created. The default export  of a JSON module contains the JSON data. There are no named exports. Getting JSON data via     # Without JSON modules, we would have to use  : We are using two relatively new features: \n The Fetch API , an API based on Promises for downloading files in JavaScript code (line B and line C). \n The module metadata property   (line A). \n  has two downsides compared to JSON modules: \n The code is slightly more complicated. \n Node.js currently has no built-in support for  . (And I suspect JSON modules will be supported sooner than  .) \n Dynamically importing JSON modules via     # The previous   statement was   (fixed at runtime). We can also import JSON modules dynamically (changeably at runtime): Note that  the   operator  (line A) returns a module namespace object. That is why we return the value of property   (which contains the default export) in line B. Why the extra syntax?   # You may wonder why we have to use extra syntax at the end of the important statement: Why can’t JavaScript detect that this is JSON by looking at the filename extension? This is not possible because it can cause security issues: Browsers never look at filename extensions, they look at content types. And servers are responsible for providing content types for files. Therefore, two things can happen when importing a   file: \n Our own server might send a content type other than   and the importing would go wrong in some manner. \n With an external server, things are even more risky: If it sends the file with the content type  , it could execute code inside our app. \n Therefore, JavaScript won’t rely on content types when importing JSON. Availability   # \n Chrome 91 supports JSON modules (source:  Chrome Platform Status ). \n More information on modules in JavaScript   # \n Chapter “Modules”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/10/js-plus-other-languages.html", "title": "Writing JavaScript tools in other languages – a new trend?", "content": "Writing JavaScript tools in other languages – a new trend? dev javascript jstools Recently, we have seen an uptick of JavaScript tools being written in languages other than JavaScript. This blog post lists a few examples and explains the appeal of not using JavaScript. Examples   # I asked on Twitter  and these are a few of the examples that people mentioned: \n esbuild – Go : JavaScript bundler and minifier. It packages up JavaScript and TypeScript code for distribution on the web.\n \n Used by:  Snowpack ,  Vite ,  Hugo \n \n \n swc – Rust : JavaScript/TypeScript compiler \n Google Closure Compiler – Java : JavaScript checker and optimizer \n \n RSLint – Rust : JavaScript linter \n Flow – OCaml : static typechecker for JavaScript \n dprint – Rust : code formatting platform \n \n Fast Node Manager (fnm) – Rust : Node.js version manager \n Volta – Rust : manage JavaScript command-line tools such as  ,  ,  . \n Why other languages?   # What are the benefits of using languages other than JavaScript (or languages that compile to JavaScript)? \n They can be compiled to native binaries which have faster startup times. \n Native binaries also usually run considerably faster than JavaScript code. \n Many languages make it much easier to parallelize code. \n Additionally, many non-JavaScript languages can now be compiled to WebAssembly, resulting in binaries that are almost as portable as JavaScript – and integrate well with it. Given that each language has its own specialties, a non-JS language may also be better suited for a given task. For example, OCaml/ReasonML, Haskell, and other functional languages support algebraic data types, which help with processing data structures such as abstract syntax trees that are used when parsing and/or compiling formal languages. Upsides of using JavaScript   # Using JavaScript also has benefits: \n \n It’s easier to find contributors for tools: On one hand, programmers familiar with the non-JS language tend to be less interested in working on JavaScript-related tools. On the other hand, a non-JS language is a considerable hurdle for JavaScript programmers. \n \n \n You can “dog-food” – apply a language tool to the code of the tool itself. As a consequence, working on the tool’s code base gives you a better idea of what you want from the tool. \n \n \n JavaScript has a rich ecosystem with a language specification, much documentation, good tools and many libraries (via npm). \n \n \n For functional programming, TypeScript is not as elegant as specialized languages, but you can get relatively close without losing the JavaScript ecosystem. For example, discriminated union types are slightly more verbose than algebraic data types, but have many of the same benefits (such as compile-time exhaustiveness checks). \n \n If high performance is important,  AssemblyScript  may be an option: It is a strict variant of TypeScript that is compiled to WebAssembly. comments powered by Disqus."},
{"url": "https://2ality.com/2021/01/import-assertions.html", "title": "ECMAScript proposal: Import assertions", "content": "ECMAScript proposal: Import assertions dev javascript es proposal The ECMAScript proposal “Import assertions”  (by Myles Borins, Sven Sauleau, Dan Clark, and Daniel Ehrenberg) introduces syntax for associating metadata with import statements. In this blog post, we examine what that looks like and why it’s useful. \n   \n     Import assertions \n   \n   \n     History: importing non-JavaScript artifacts as modules \n   \n   \n     Use cases for importing non-JavaScript artifacts \n   \n   \n     The syntax of import assertions \n     \n       \n         Static import statements \n       \n       \n         Dynamic imports \n       \n       \n         Re-export statements \n       \n     \n   \n   \n     Upcoming features based on import assertions \n     \n       \n         JSON modules \n       \n       \n         Importing WebAssembly \n       \n     \n   \n   \n     Further reading on modules \n   \n Import assertions   # The motivating use case for import assertions was importing JSON data as a module. That looks as follows (and is further specified in  a separate proposal ): You may wonder why a JavaScript engine can’t use the filename extension   to determine that this is JSON data. However, a core architectural principle of the web is to never use the filename extension to determine what’s inside a file. Instead, content types are used. Therefore, there is a risk of doing importing wrong if a server has incorrectly configured content types. Specifying the necessary metadata at the import location solves this issue. Before we take a more detailed look at how import assertions work, let’s examine the history of importing non-JavaScript artifacts in the world of JavaScript. History: importing non-JavaScript artifacts as modules   # Importing artifacts that are not JavaScript code as modules, has a long tradition in the JavaScript ecosystem. For example, the JavaScript module loader RequireJS has support for so-called  . To give you a feeling for how old RequireJS is: Version 1.0.0 was released in 2009. Specifiers of modules that are imported via a plugin look like this: For example, the following module specifier imports a file as JSON: Inspired by RequireJS, webpack supports the same module specifier syntax for its  . Use cases for importing non-JavaScript artifacts   # These are a few use cases for importing non-JavaScript artifacts: \n Importing JSON configuration data \n Importing WebAssembly code as if it were a JavaScript module \n Importing CSS to build user interfaces \n For more use cases, you can take a look at  the list of webpack’s loaders . The syntax of import assertions   # Let’s examine in more detail what import assertions look like. Static import statements   # We have already seen a normal (static) import statement: The import assertions start with the keyword  . That keyword is followed by an object literal. For now, the following object literal features are supported: \n Unquoted keys and quoted keys \n The values must be strings \n There are no other syntactic restrictions placed on the keys and the values, but engines are encouraged to throw an exception if they don’t support a key and/or a value. That makes it easier to add more features in the future because no one will use keys and values in unexpected ways. Dynamic imports   # To support import assertions,  dynamic imports  get a second parameter – an object with configuration data: The import assertions don’t exist at the top level; they are specified via the property  . That makes it possible to add more configuration options in the future. Re-export statements   # A re-export imports and exports in a single step. For the former, we need assertions: Upcoming features based on import assertions   # Import assertions are really just syntax. They lay the foundation for actual features that make use of that syntax. JSON modules   # The first feature based on import assertions is probably going to be  JSON modules . Importing WebAssembly   # Whether or not import assertions will be used to support directly importing WebAssembly from JavaScript is currently under  discussion . If they are used, we’ll probably be able to create web workers like this: And we’d also need import assertions in HTML script elements: Further reading on modules   # The chapter on “Modules”  in “JavaScript for impatient programmers” is an in-depth introduction to ECMAScript modules. comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/what-google-maps-can-teach-you-about.html", "title": "What Google Maps can teach you about user interface design", "content": "What Google Maps can teach you about user interface design dev hci Google Maps and Label Readability  Conclusion: Avoid transparency for content, though it sometimes works for UI controls that should not obscure the content. For example, a button to leave the full-screen mode of a web browser.  Conclusion: Clearly structure your content. Use different font sizes, ample spacing, etc.  Conclusion: Apply lighter tones (gray instead of black etc.) to less important UI elements. iTunes has done this for its most recent version and it reduces the subjective clutter, because UI elements don’t distract from the content as much. historic version 1933 1932 Daring Fireball comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/displaying-math-in-html.html", "title": "Displaying math in HTML", "content": "Displaying math in HTML dev webdev math MathML : is a markup language for math that can be embedded in HTML. Firefox already supports it, WebKit will soon (and thus Safari and Chrome). You can check out MathML in a  demo document . \n MathJax : a JavaScript-based solution that works in all major browsers. It can be integrated into many blogging engines and wikis. The image below is an example of a formula displayed in Google Chrome. In Chrome, it is not a bitmap image, it scales smoothly! \n Kindle software comments powered by Disqus."},
{"url": "https://2ality.com/2021/06/object-hasown.html", "title": "ECMAScript proposal: Accessible  Object.prototype.hasOwnProperty()", "content": "ECMAScript proposal: Accessible  dev javascript es proposal In this blog post, we examine  the ECMAScript proposal “Accessible  ”  (by Jamie Kyle and Tierney Cyren). It proposes a new, simpler way of checking if an object has an   (non-inherited) property. \n   \n     Checking if an object has an own property \n     \n       \n         The   operator isn’t always what we want \n       \n       \n          isn’t safe \n       \n       \n         Accessing   directly \n       \n     \n   \n   \n     The proposal:  \n   \n   \n     A warning about using objects as dictionaries \n   \n   \n     Frequently asked questions about  \n     \n       \n         Wouldn’t   be a better name? \n       \n       \n         What is the difference between   and  ? \n       \n       \n         Why wasn’t method   added to  ? \n       \n     \n   \n   \n     Availability of  \n   \n   \n     More information on object-oriented programming in JavaScript \n   \n Checking if an object has an own property   # In this section, we look at existing ways of checking if an object has an own property. Each of them has downsides, which is why   is needed. The   operator isn’t always what we want   # The   operator checks if an object has a property with a given name: However, if we treat objects as dictionaries, then we want to ignore inherited properties (and   considers them). For example, interpreted as a dictionary, the following object should be empty, but   says that it has the property  : That’s because   inherits method   from  :  isn’t safe   # All objects created via object literals inherit the method   from  . That method seems to do what we want: However,   fails in two cases. First, we can create objects that don’t inherit from   and don’t have that method: Second, if an object has an own property with the name  , then that property overrides   and we can’t access it: Accessing   directly   # To fix the issues we encountered in the previous section, we need to access   directly:  works exactly like  . The proposal:     # The new proposal works exactly the way we want: A warning about using objects as dictionaries   # In general, objects are not good dictionaries: There are  several pitfalls  we have to contend with. Instead,  Maps  are great dictionaries and have no pitfalls. Frequently asked questions about     # Wouldn’t   be a better name?   # Alas, that name isn’t available anymore: Why?   is a function, which is an object: What is the difference between   and  ?   #  works like the   operator and considers inherited properties:  ignores inherited properties: Why wasn’t method   added to  ?   #  only contains  ECMAScript Proxy traps . Therefore, it is not a suitable location for a utility method such as  . Availability of     # \n The proposal  lists  the JavaScript engines that already support  . \n The npm package   by Jordan Harband  is a polyfill. \n When migrating from library functions such as   to  , you can use  Jamie Kyle’s codemod . \n More information on object-oriented programming in JavaScript   # Material in the book “JavaScript for impatient programmers”: \n Two chapters on object-oriented programming:  “Objects” ,  “Classes” \n Section  “Dictionary objects” \n \n Subsection  “The pitfalls of using an object as a dictionary” \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/web-as-application-platform-latest.html", "title": "The web as an application platform: latest developments", "content": "The web as an application platform: latest developments dev cloud webdev \n    (Note: JavaScript can be seen as an  implementation of the ECMAScript specification.) I was very disappointed after the feature-rich ECMAScript 4  was abandoned , but there is some  neat stuff   coming in ECMAScript 5: Inheritance has been simplified, some  meta-programming will be possible, methods for iteration have been added  to arrays, etc. What is great is that many modern browsers already support these features, making them quasi-standard. \n becoming faster  It is still kind of weird to have programs delivered as source code. But with parsers being fast, one more intermediate step is not that much of a deal. Long-term, I would love to have some kind of compact storage format similar to Java class files [3]. \n   Node.js   has been around for a while now. It is Chrome’s V8 JavaScript engine  running server-side JavaScript. With web apps becoming increasingly  powerful, I expect servers to become much smaller, more like glorified  databases with which the apps sync. Still, having a elegant server  technology available that scales well and uses the same language as the browser is invaluable. I expect one killer feature of Node.js (compared to Java) to be cheap and simple hosting.  \n  Browsers are getting features that were once reserved for operating systems such as  key-value databases  (look at the editors of the linked document to see how widespread this standard will become),  3D graphics , and more. \n   Chrome  has them, as does  Firefox .  That means we get the option to either quickly test drive a web  application or to permanently install it. There will also be a way to  pay for web apps (necessary for them to compete with native apps). \n  You might already be running web applications outside a browser without knowing it. For example,  this article  lists how many iPad applications use HTML5 to display their content.  This allowed the developers to quickly port them to the  Chrome app store. It also lends further credence to the prediction that one  day, most applications will be based on web technologies. For mobile  apps, they already are the easiest cross-platform strategy. \n \n What’s new in ECMAScript 5 New device APIs for web browsers What is the JavaScript equivalent of Java class files? CSS3 Grid Layout is perfect for webapp GUIs The cloud and how it changes mobile computing \n\n\n\n\n comments powered by Disqus."},
{"url": "https://2ality.com/2021/06/private-field-checks.html", "title": "ECMAScript proposal: Ergonomic brand checks for private fields", "content": "ECMAScript proposal: Ergonomic brand checks for private fields dev javascript es proposal In this blog post, we examine  the ECMAScript proposal “Ergonomic brand checks for private fields”  (by Jordan Harband). It proposes a compact way for checking if an object has a given private field. \n   \n     Background on private fields \n   \n   \n     Quick recap: Each class has its own private fields \n     \n       \n         Two different classes with private fields that have the same name \n       \n       \n         Private fields in classes created via factories \n       \n     \n   \n   \n     Checking if a private field exists \n     \n       \n         Checking via   doesn’t always work \n       \n       \n         A safe way to check \n       \n       \n         The proposal: checking via the   operator \n       \n     \n   \n   \n     More information on object-oriented programming in JavaScript \n   \n Background on private fields   # For this blog post, it helps if you are familiar with private fields (but you’ll probably be fine if not). If you want to read up on this topic: I have written  four blog posts about public fields and private members in classes . Quick recap: Each class has its own private fields   # Let’s first review one important characteristic of private fields: They are unique per class. They are not even shared with subclasses. Two different classes with private fields that have the same name   # The following example demonstrates what happens if two different classes both have a private field called  :  can access   in instances of   (line A), but it can’t access that field in instances of   (line B). Private fields in classes created via factories   # Private fields being unique per class is even more interesting when dealing with class factories such as the following function  : If we use   to create two classes   and  , we see the same behavior as in the previous example: Checking if a private field exists   # So how do we check if an object has a given private field? Checking via   doesn’t always work   # We may think we can use  , but, alas, we can’t, as the next example demonstrates. The thinking is: All objects created via   have the private field  . Therefore, if, for an arbitrary object  , the expression   is  , we should always be able to access  . This is indeed correct for all objects created via  : However, we can also create objects that are instances of  , but not created via  : Only the constructor of   adds the private fields. Therefore,   does not have the private field   and the result   in line A is wrong. A safe way to check   # The following code contains a safe way to check if a private field exists: Given an arbitrary object  , we try to read the private field   (line A). If that works, we return   (line B). If it doesn’t, we return   (line C). Note that we can’t do a generic check (via a parameter) for private fields because we only have fixed access. Let’s see the results for a real instance and a fake instance: Alas, this solution is verbose. That’s where the proposal comes in. The proposal: checking via the   operator   # With the proposal, checking if an object has a given private field is much more convenient (line A): More information on object-oriented programming in JavaScript   # In the book “JavaScript for impatient programmers” there are two chapters on object-oriented programming: \n “Objects” \n “Classes” \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/whats-new-in-ecmascript-5.html", "title": "What’s new in ECMAScript 5", "content": "What’s new in ECMAScript 5 dev javascript webdev jslang \n     JavaScript’s strict mode: a summary \n     es5-shim: use ECMAScript 5 in older browsers   \n \n     “ ECMAScript 5: The Definitive Slides ” by longtime O’Reilly author David Flanagan. There are several useful additional links at the end. \n     “ ECMAScript 5 compatibility table ” shows what is already available in browsers and it is quite a lot. Nice to see that the IE9 column is very green. \n \n       ECMA-262, 5th Edition   \n     ECMAScript 5: What’s New in JavaScript Programming \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/simple-way-of-sending-emails-in-java.html", "title": "A simple way of sending emails in Java: mailto links", "content": "A simple way of sending emails in Java: mailto links dev hack java java.awt.Desktop mailto: URL syntax \n recipients: comma-separated email addresses (no spaces; Outlook needs semicolons instead of commas) \n value: should be URL-encoded (e.g. space becomes %20) \n key: subject, cc, bcc, body \n Example:  mailto:joe@example.com,jane@example.com?subject=hello&body=How%20are%20you%3F \n Java source code Generate emails with mailto URLs and Python comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/tip-get-all-unix-console-programs-to.html", "title": "Tip: get all Unix console programs to support arrow keys", "content": "Tip: get all Unix console programs to support arrow keys emacs dev hack unix shell \n Start Emacs. Use the -nw (no window) option if you want to start it inside the console. \n Type Esc-X “shell” Return \n \n Now text input is much more comfortable.  \n \n History: Esc-P goes to previous text input, Esc-N moves forward in time. You can also just move around the screen with the arrow keys, edit and hit Return. \n Leave Emacs via Ctrl-X Ctrl-C. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/type-assertions-typescript.html", "title": "Type assertions in TypeScript", "content": "Type assertions in TypeScript dev javascript typescript This blog post is about   in TypeScript, which are related to type casts in other languages and performed via the   operator. \n   \n     Type assertions \n     \n       \n         Alternative syntax for type assertions \n       \n       \n         Example: asserting an interface \n       \n       \n         Example: asserting an index signature \n       \n     \n   \n   \n     Constructs related to type assertions \n     \n       \n         Non-nullish assertion operator (postfix  ) \n       \n       \n         Definite assignment assertions \n       \n     \n   \n Type assertions   # A type assertion lets us override a static type that TypeScript has computed for a storage location. That is useful for working around limitations of the type system. Type assertions are related to type casts in other languages, but they don’t throw exceptions and don’t do anything at runtime (they do perform a few minimal checks statically). \n \n In line A, we widen the type of the Array to  . \n \n \n In line B, we see that this type doesn’t let us access any properties ( details ). \n \n \n In line C, we use a type assertion (the operator  ) to tell TypeScript that   is an Array. Now we can access property  . \n \n Type assertions are a last resort and should be avoided as much as possible. They (temporarily) remove the safety net that the static type system normally gives us. Note that, in line A, we also overrode TypeScript’s static type. But we did it via a type annotation. This way of overriding is much safer than type assertions because there is much less you can do. TypeScript’s type must be assignable to the type of the annotation. Alternative syntax for type assertions   # TypeScript has an alternative “angle-bracket” syntax for type assertions: That syntax has grown out of style and is not compatible with React JSX code (in   files). Example: asserting an interface   # In order to access property   of an arbitrary object  , we temporarily change the static type of   to   (line A and line B). Example: asserting an index signature   # In the following code (line A), we use the type assertion  , so that we can access the properties of a value whose inferred type is  . That is, we are overriding the inferred static type   with the static type  . Constructs related to type assertions   # Non-nullish assertion operator (postfix  )   # If a value’s type is a union that includes the types   or  , the   (or  ) removes these types from the union. We are telling TypeScript: “This value can’t be   or  .” As a consequence, we can perform operations that are prevented by the types of these two values – for example: # After we use the Map method  , we know that a Map has a given key. Alas, the result of   does not reflect that knowledge, which is why we have to use the nullish assertion operator: Since the values of   are never  , we can detect missing Map entries by checking if the result of   is   (line A): Definite assignment assertions   # If   is switched on, we occasionally need to tell TypeScript that we do initialize certain properties – even though it thinks we don’t. This is an example where TypeScript complains even though it shouldn’t: The errors go away if we use   (exclamation marks) in line A and line B: comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/javascripts-prototypal-inheritance.html", "title": "An easy way to understand JavaScript’s prototypal inheritance", "content": "An easy way to understand JavaScript’s prototypal inheritance programming languages pl fundamentals dev javascript jslang Prototypes as classes \nThis blog post explains JavaScript’s prototypal inheritance in a simple way. As it turns out, if we initially leave out constructors, then it is easy to understand. Thus, we first look at the fictional programming language ProtoScript which is JavaScript minus constructors, explain it, and then move on to constructors. As a result, you should have a solid understanding of prototypal inheritance and won’t be confused, any more, by all the JavaScript tricks out there.\n \n Inheritance in the fictional ProtoScript \nIn class-based languages, whenever we have a set of similar objects, say persons with a name that can be converted to a text string, we create a class for that set. In ProtoScript, which does not have classes, we create an initial person, e.g.\n \nTo summarize: Like JavaScript, ProtoScript does not have classes, only objects. But the special property   and a clever way of sharing some objects, while copying others allow us to do everything that class-based languages can. Like in other prototype-based languages, we have the pleasure of always directly manipulating objects and there are fewer abstractions involved such as classes or instantiation. This makes prototype-based languages more intuitive for beginners. The next section explores JavaScript’s constructors.\n\n Back to JavaScript ECMAScript 5 Further reading  “ Organizing Programs Without Classes ”. A great introduction to the prototype-based programming language Self and how it compares to class-based languages. This greatly helped me understand how prototypal inheritance works. “ Lightweight JavaScript inheritance APIs ” presents APIs that help with inheritance. The post focuses on APIs that change JavaScript as little as possible. “ Going completely prototypal in JavaScript ” shows what an API for prototypal inheritance looks like. comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/eight-important-books-for-software.html", "title": "Eight important books for software developers", "content": "Eight important books for software developers dev book software engineering Engineering \n Design Patterns. Elements of Reusable Object-Oriented Software  [ uk ,  de ], Erich Gamma, Richard Helm, Ralph E. Johnson. Addison-Wesley. \nIt pays to know all of the design pattern passively, because they have become common vocabulary between developers. I’ve found that the best way of using them is to let the ideas increase one’s knowledge and then start the design  . I’ve also seen some ugly code where people started their design from the patterns. \n Refactoring. Improving the Design of Existing Code  [ uk ,  de ], Martin Fowler. Addison-Wesley. \nNo need to read throroughly here, but still contains many nice ideas one should be aware of. \n The Pragmatic Programmer. From Journeyman to Master  [ uk ,  de ], Andrew Hunt, David Thomas, Ward Cunningham. Addison-Wesley. \nTips for the craftsmanship of software engineering: what to automate, how to code, etc. \n Effective Java (2nd Edition)  [ uk ,  de ], Joshua Bloch. Addison-Wesley. \nMany important rules for everyday Java programming tasks: clarifications of the standard mechanisms, new techniques (some of them inspired by functional programming) etc. \n Process and Psychology \n Extreme Programming Installed  [ uk ,  de ], Ron Jeffries, Ann Anderson, Chet Hendrickson. Addison-Wesley. \nThe most technical book in this section, as it also contains comments on coding and more engineering related things. It is really fun to read about a process that is not described in a theoretical way, but as a pragmatic list of all the things one can do to improve teamwork. \n Peopleware: Productive Projects and Teams  [ uk ,  de ], Tom DeMarco, Timothy Lister. Dorset House Publishing. \nAs lame as \"putting people first\" sounds, this book makes profound (and exciting) sense. \n Difficult Conversations. How to discuss what matters most  [ uk ,  de ], Douglas Stone, Bruce Patton, Sheila Heen. Penguin Putnam. \nA nice manual on human interaction that builds on the common sense most people alread have. If my head is filled with all these criticisms, misgivings and admirations concerning other people, then what do they mean? What should I do about them? When should I tell others about them, when not? \n The Now Habit: A Strategic Program for Overcoming Procrastination and Enjoying Guilt-Free Play  [ uk ,  de ], Neil A. Fiore. Jeremy P. Tarcher. \nI do not like the title, but I like the content. This book is especially useful if you work mostly for yourself. It shows that being more efficient is not necessarily about discipline. \n comments powered by Disqus."},
{"url": "https://2ality.com/2010/12/crazy-javascript-hack-unzipping-file.html", "title": "Crazy JavaScript hack: unzipping a file", "content": "Crazy JavaScript hack: unzipping a file dev javascript webdev clientjs getting better involved Read the binary data of the ZIP file from the server via XMLHttpRequest. You need to specify a charset x-user-defined to ensure that each byte stays a single character. \n Translate the binary data to base 64 and turn it into a PNG  data URI . PNG is zipped internally, so if you get the header right, the web browser will unzip the data as soon as the image is drawn somewhere. \n Draw the image into a  Canvas  object, with a height of 1 pixel. Read the uncompressed data from the Canvas, pixel by pixel. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/97-things-every-programmer-should-know.html", "title": "97 Things Every Programmer Should Know", "content": "97 Things Every Programmer Should Know dev textbook software engineering 97 Things Every Programmer Should Know uk de online The Golden Rule of API Design Raja Kannappan comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/any-unknown-typescript.html", "title": "The top types  any  and  unknown  in TypeScript", "content": "The top types   and   in TypeScript dev javascript typescript In TypeScript,   and   are types that contain all values. In this blog post, we examine how they work. \n   \n     TypeScript’s two top types \n   \n   \n     The top type  \n     \n       \n         Example:  \n       \n       \n         Example:  \n       \n     \n   \n   \n     The top type  \n   \n TypeScript’s two top types   #  and   are so-called   in TypeScript. Quoting  Wikipedia : The   [...] is the   type, sometimes called the   as all other types in any given type system are subtypes [...]. In most cases it is the type which contains every possible [value] in the type system of interest. That is, when viewing types as sets of values (for more information on what types are, see  “What is a type in TypeScript? Two perspectives” ),   and   are sets that contain all values. As an aside, TypeScript also has the    , which is the empty set. The top type     # If a value has type  , we can do everything with it: Every type is assignable to type  : Type   is assignable to every type: With   we lose any protection that is normally given to us by TypeScript’s static type system. Therefore, it should only be used as a last resort, if we can’t use more specific types or  . Example:     # The result of   depends on dynamic input, which is why the return type is   (I have omitted the parameter   from the signature):  was added to TypeScript before the type   existed. Otherwise, its return type would probably be  . Example:     # The function  , which converts arbitrary values to strings, has the following type signature: The top type     # The type   is a type-safe version of the type  . Whenever you are thinking of using  , try using   first. Where   allows us to do anything,   is much more restrictive. Before we can perform any operation on values of type  , we must first narrow their types via: \n \n Type assertions : \n \n \n \n Equality: \n \n \n \n Type guards : \n \n \n \n Assertion functions : \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/type-guards-assertion-functions-typescript.html", "title": "TypeScript: narrowing types via type guards and assertion functions", "content": "TypeScript: narrowing types via type guards and assertion functions dev javascript typescript In TypeScript, a value can have a type that is too general for some operations – for example, a union type. This blog post answers the following questions: \n What is   of types?\n \n (Spoiler: focusing on a subset of an overly general type, in a specific region of a program) \n \n \n What are   and   and how can we use them to narrow types? \n \n   \n     When are static types too general? \n     \n       \n         Narrowing via  \n       \n       \n         Narrowing via  \n       \n       \n         More cases of types being too general \n       \n       \n         The type  \n       \n     \n   \n   \n     Narrowing via built-in type guards \n     \n       \n         Strict equality ( ) \n       \n       \n         ,  ,  \n       \n       \n         Checking for distinct properties via the operator  \n       \n       \n         Checking the value of a shared property (discriminated unions) \n       \n       \n         Narrowing dotted names \n       \n       \n         Narrowing Array element types \n       \n     \n   \n   \n     User-defined type guards \n     \n       \n         Example of a user-defined type guard:  \n       \n       \n         Example of a user-defined type guard:  \n       \n     \n   \n   \n     Assertion functions \n     \n       \n         TypeScript’s support for assertion functions \n       \n       \n         Asserting a boolean argument:  \n       \n       \n         Asserting the type of an argument:  \n       \n     \n   \n   \n     Quick reference: user-defined type guards and assertion functions \n     \n       \n         User-defined type guards \n       \n       \n         Assertion functions \n       \n     \n   \n   \n     Alternatives to assertion functions \n     \n       \n         Technique: forced conversion \n       \n       \n         Technique: throwing an exception \n       \n     \n   \n   \n     : library with type guards \n   \n When are static types too general?   # To see how a static type can be too general, consider the following function  : The skeleton of   looks as follows: Inside the body of  , we don’t know if the type of     or  . Before we do, we can’t really work with  . Narrowing via     # The solution is to check the type of   at runtime, via   (line A and line B): In this blog post, we interpret types as sets of values. (For more information on this interpretation and another one, see  “What is a type in TypeScript? Two perspectives” .) Inside the then-blocks starting in line A and line B, the static type of   changes, due to the checks we performed. We are now working with subsets of the original type  . This way of reducing the size of a type is called  . Checking the result of   and similar runtime operations are called  . Note that narrowing does not change the original type of  , it only makes it more specific as we pass more checks. Narrowing via     # Narrowing also works if we use   instead of  : More cases of types being too general   # These are more examples of types being too general: \n \n Nullable types: \n \n \n \n Discriminated unions: \n \n \n \n Types of optional parameters: \n \n \n Note that these types are all union types! The type     # If a value has  the type  , we can do almost nothing with it and have to narrow its type first (line A): In other words: The type   is too general and we must narrow it. In a way,   is also a union type (the union of all types). Narrowing via built-in type guards   # As we have seen, a   is an operation that returns either   or   – depending on whether its operand meets certain criteria at runtime. TypeScript’s type inference supports type guards by narrowing the static type of an operand when the result is  . Strict equality ( )   # Strict equality works as a type guard: We can also use   to differentiate between the components of a union type: ,  ,     # These are three common built-in type guards: Note how the static type of   is narrowed inside the then-blocks. Checking for distinct properties via the operator     # If used to check for distinct properties, the operator   is a type guard: Note that the following check would not have worked: The problem in this case is that, without narrowing, we can’t access property   of a value whose type is  . # Alas,   only helps us with union types: Checking the value of a shared property (discriminated unions)   # In a discriminated union, the components of a union type have one or more properties in common whose values are different for each component. As a consequence, checking the value of one of those properties is a type guard: In the previous example,   is a so-called  : All components of the union type   have it and it has a different value in each one. An   statement and equality checks work similarly to a   statement: Narrowing dotted names   # We can also narrow the types of properties (even of nested ones that we access via chains of property names): Let’s take a look at several locations in the previous code: \n Line A: We narrowed the type of   via a type guard. \n Line B: Callbacks may be executed much later (think of asynchronous code), which is why TypeScript undoes narrowing inside callbacks. \n Line C: The preceding assignment also undid narrowing. \n Narrowing Array element types   # # If we use   to check that all Array elements are non-nullish, TypeScript does not narrow the type of   (line A): Note that   has to be read-only. If it weren’t, another reference to it would statically allow us to push   into   inside the   statement. But that renders the narrowed type of   incorrect. The previous code uses the following   (more on what that is soon):  (line A) is  a utility type  that removes the types   and   from union type  . #  produces Arrays that have narrower types (i.e., it doesn’t really narrow existing types): (  is defined in the previous subsection.) Alas, even here, we must use a type guard function directly – an arrow function with a type guard is not enough: User-defined type guards   # TypeScript lets us define our own type guards – for example: The return type   is a  . It is part of the type signature of  : A user-defined type guard must always return booleans. If   returns  , TypeScript can narrow the type of the actual argument   to  : Note that TypeScript doesn’t care how we compute the result of a user-defined type guard. That gives us a lot of freedom w.r.t. the checks we use. For example, we could have implemented   as follows: Alas, the type   does not let us make the function call in line A. Therefore, we have to use the type   for the parameter  . Example of a user-defined type guard:     # This is how this function is used: Example of a user-defined type guard:     # # This is a first attempt to implement   in TypeScript: Because it is difficult to turn an expected result of   (such as   or  ) into a type  , we opted to specify   via an example value. This is not ideal, but it works: # A better solution is to use overloading (several cases are omitted): (This approach is an idea by  Nick Fisher .) # An alternative is to use an interface as a map from strings to types (several cases are omitted): (This approach is an idea by  Ran Lottem .) Assertion functions   # An assertion function checks if its parameter fulfills certain criteria and throws an exception if it doesn’t. For example, one assertion function supported by many languages, is  .   throws an exception if the boolean condition   is  . On Node.js,   is supported via  the built-in module  . The following code uses it in line A: TypeScript’s support for assertion functions   # TypeScript’s type inference provides special support for assertion functions, if we mark such functions with   as return types. W.r.t. how and what we can return from a function, an assertion signature is equivalent to  . However, it additionally triggers narrowing. There are two kinds of assertion signatures: \n Asserting a boolean argument:  \n Asserting the type of an argument:  \n Asserting a boolean argument:     # In the following example, the assertion signature   states that the parameter   must be  . Otherwise, an exception is thrown. This is how   causes narrowing: The invocation of the assertion function   in line A influenced the static type of   in line B (in a manner similar to type guards). Asserting the type of an argument:     # In the following example, the assertion signature   states that the parameter   must have the type  . Otherwise, an exception is thrown. This time, calling the assertion function, narrows the type of its argument: # The function   adds properties to existing objects and updates their types accordingly: An intersection type   produces a type that has the properties of both   and  . Quick reference: user-defined type guards and assertion functions   # User-defined type guards   # \n Type predicate:  \n Result:  \n Assertion functions   # # \n Assertion signature:  \n Result:  , exception \n # \n Assertion signature:  \n Result:  , exception \n Alternatives to assertion functions   # Technique: forced conversion   # An assertion function narrows the type of an existing value. A forced conversion function returns an existing value with a new type – for example: The corresponding assertion function looks as follows: Forced conversion is a versatile technique with uses beyond being an alternative to assertion functions. For example, you can convert an input format (think JSON schema) that is easy to write into an output format that is easy to work with in code. Technique: throwing an exception   # Consider the following code: Instead of the   statement that starts in line A, we also could have used an assertion function: Throwing an exception is a quick alternative if we don’t want to write such a function. Similarly to calling an assertion function, this technique also updates the static type. : library with type guards   # The library   provides a collection of type guards for TypeScript – for example: \n Primitives:  ,  , etc. \n Specific types:  ,  ,  , etc. \n Various checks:  ,  , etc. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/validating-data-typescript.html", "title": "TypeScript: validating external data", "content": "TypeScript: validating external data dev javascript typescript  means ensuring that data has the desired structure and content. With TypeScript, validation becomes relevant when we receive external data such as: \n Data parsed from JSON files \n Data received from web services \n In these cases, we expect the data to fit static types we have, but we can’t be sure. Contrast that with data we create ourselves, where TypeScript continuously checks that everything is correct. This blog post explains how to validate external data in TypeScript. \n   \n     JSON schema \n     \n       \n         An example JSON schema \n       \n     \n   \n   \n     Approaches for data validation in TypeScript \n     \n       \n         Approaches not using JSON schema \n       \n       \n         Approaches using JSON schema \n       \n       \n         Picking a library \n       \n     \n   \n   \n     Example: validating data via the library Zod \n     \n       \n         Defining a “schema” via Zod’s builder API \n       \n       \n         Validating data \n       \n       \n         Type guards \n       \n       \n         Deriving a static type from a Zod schema \n       \n       \n         External vs. internal representation of data \n       \n     \n   \n   \n     Conclusion \n   \n JSON schema   # Before we can explore approaches for data validation in TypeScript, we need to take a look at   because several of the approaches are based on it. The idea behind  JSON schema  is to express the   (structure and content, think static type) of JSON data in JSON. That is, metadata is expressed in the same format as data. The use cases for JSON schema are: \n \n Validating JSON data: If we have a schema definition for data, we can use tools to check that the data is correct. One issue with data can also be fixed automatically: We can specify default values that can be used to add properties that are missing. \n \n \n Documenting JSON data formats: On one hand, the core schema definitions can be considered documentation. But JSON schema additionally supports descriptions, deprecation notes, comments, examples, and more. These mechanisms are called  . They are not used for validation, but for documentation. \n \n \n IDE support for editing data: For example, Visual Studio Code supports JSON schema. If there is a schema for a JSON file, we gain several editing features: auto-completion, highlighting of errors, etc. Notably, VS Code’s support for   files is completely based on a JSON schema. \n An example JSON schema   # This example is taken from  the   website : The following JSON data is valid w.r.t. this schema: Approaches for data validation in TypeScript   # This section provides a brief overview of various approaches for validating data in TypeScript. For each approach, I list one or more libraries that support the approach. W.r.t. libraries, I don’t intend to be comprehensive because things change quickly in this space. Approaches not using JSON schema   # \n \n Approach: Invoking builder methods and functions to produce both validation functions (at runtime) and static types (at compile time). Libraries include: \n \n  (demonstrated later in this blog post) \n \n \n \n \n \n Approach: Invoking builder methods and only producing validation functions. Libraries taking this approach often focus on making validation as versatile as possible: \n \n \n \n \n \n \n \n Approach: Compiling TypeScript types to validation code at compile time. Libraries: \n \n TypeScript transformer:  \n Babel macro:  \n \n \n Approaches using JSON schema   # \n \n Approach: Converting TypeScript types to JSON schema. Libraries: \n \n \n \n \n \n \n Approach: Converting a JSON schema to TypeScript types. Libraries: \n \n \n \n \n \n \n \n Approach: Validating JSON data via JSON schemas. Both of the previous approaches tend to also do this. npm packages: \n \n \n \n \n \n Picking a library   # Which approach and therefore library to use, depends on what we need: \n \n If we are starting with TypeScript types and want to ensure that data (coming from configuration files, etc.) fits those types, then builder APIs that support static types are a good choice. \n \n \n If our starting point is a JSON schema, then we should consider one of the libraries that support JSON schema. \n \n \n If we are handling data that is more messy (e.g. submitted via forms), we may need a more flexible approach where static types play less of a role. \n \n Example: validating data via the library     # Defining a “schema” via Zod’s builder API   # Zod has a builder API that produces both types and validation functions. That API is used as follows: For larger schemas, it can make sense to break things up into multiple   declarations. Zod can produce a static type from  , but I decided to (redundantly!) manually maintain the static type  : Why the redundancy? \n It’s easier to read. \n It helps with migrating to a different validation library or approach, should I ever have to. \n Zod’s generated type is still helpful because we can check if it’s assignable to  . That will warn us about most problems related to the two getting out of sync. Validating data   # The following function checks if the parameter   conforms to  : The static type of the result of   is what Zod derived from  . By making   the return type of  , we ensure that the former type is assignable to the latter. Type guards   #  is a type guard: It can make sense to define a custom type guard that supports   instead of what Zod infers. Deriving a static type from a Zod schema   # The parameterized type   can be used to derive a type from a schema: External vs. internal representation of data   # When working with external data, it’s often useful to distinguish two types. On one hand, there is the type that describes the input data. Its structure is optimized for being easy to author: On the other hand, there is the type that is used in the program. Its structure is optimized for being easy to use in code: After we have used Zod to ensure that the input data conforms to  , we use a conversion function that converts the data to a value of type  . Conclusion   # My use case for a data validation library was making sure that data matched a given TypeScript type. Therefore, I would have preferred to directly compile the type to a validation function. So far, only the Babel macro   does that and it requiring Babel ruled it out for me. I think I would also be OK with a tool that compiles a TypeScript type to a separate module with a validation function. But that also has downsides, usability-wise. Therefore, Zod currently is a good solution for me and I haven’t had any regrets. For libraries that have a builder API, I’d like to have tools that compile TypeScript types to builder API invocations (online and via a command line). This would help in two ways: \n The tools can be used to explore how the APIs work. \n We have the option of producing API code via the tools. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/logical-assignment-operators.html", "title": "ES2021: Logical assignment operators", "content": "ES2021: Logical assignment operators dev javascript es2021 The ECMAScript proposal “Logical assignment operators”  (by Justin Ridgewell and Hemanth HM) introduces the following compound assignment operators: \n \n \n \n Existing compound assignment operators   # JavaScript already has the following compound assignment operators: \n Arithmetic assignment operators:  \n Bitwise assignment operators:  \n Bitwise shift assignment operators:  \n Each of these assignment operators works as follows: \n The expression:  \n is equivalent to:  \n Recap: short circuiting   # Before we can examine the proposed operators, we have to take a brief detour and learn about  . The logical operator  ,  ,   all   – their second operands are only evaluated if their first operands don’t already determine the result: The proposed logical assignment operators   # Logical assignment operators work differently from other compound assignment operators: Why is   equivalent to the following expression? Why not to this expression? The former expression has the benefit of short-circuiting: The assignment is only evaluated if   evaluates to  . Therefore, the assignment is only performed if it’s necessary. In contrast, the latter expression always performs an assignment. Example: using   to add missing properties   # Example: breaking up an expression   # Consider the following function which returns an expression spread out across multiple lines: This expression can be broken up as follows: Note: There are other, probably better, ways to improve the initial code. E.g., a   statement. comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/computing-with-types.html", "title": "Computing with types in TypeScript", "content": "Computing with types in TypeScript dev javascript typescript \n  Much new content in  Sect. “Union types and intersection types” \n In this blog post, we explore how we can compute with types at compile time in TypeScript. Note that the focus of this post is on learning how to compute with types. Therefore, we’ll use literal types a lot and the examples are less practically relevant. Future blog posts will cover real-world use cases. \n   \n     Types as metavalues \n   \n   \n     Generic types: factories for types \n   \n   \n     Union types and intersection types \n     \n       \n         Union types ( ) \n       \n       \n         Intersection types ( ) \n       \n     \n   \n   \n     Control flow \n     \n       \n         Conditional types \n       \n       \n         Mapped types \n       \n     \n   \n   \n     Various other operators \n     \n       \n         The index type query operator  \n       \n       \n         The indexed access operator  \n       \n       \n         The type query operator  \n       \n     \n   \n Types as metavalues   # Consider the following two levels of TypeScript code: \n Program level: At runtime, we can use values and functions. \n Type level: At compile time, we can use specific types and generic types. \n The type level is a metalevel of the program level. What does it mean that we can compute with types? The following code is an example: In line A, we are taking the following steps: \n The input of our computation is the type  , an object literal type. \n We apply the operation   to the input. It lists the property keys of an object type. \n We give the output of   the name  . \n At the type level we can compute with the following “values”: Generic types: factories for types   # Generic types are functions at the metalevel – for example: The generic type   has the parameter  . Its result is  , wrapped in a tuple type. This is how we use this metafunction: We pass the parameter   to   and give the result the alias  . The result is a tuple type with a single component – the type  . Union types and intersection types   # Union types ( )   # The type operator   is used to create union types: If we view type   and type   as sets, then   is the set-theoretic union of these sets. Put differently: The members of the result are members of at least one of the operands. Syntactically, we can also put a   in front of the first component of a union type. That is convenient when a type definition spans multiple lines: # TypeScript represents collections of metavalues as unions of literal types. We have already seen an example of that: We’ll soon see type-level operations for looping over such collections. # Due to each member of a union type being a member of   one of the component types, we can only safely access properties that are shared by all component types (line A). To access any other property, we need a type guard (line B): Intersection types ( )   # The type operator   is used to create intersection types: If we view type   and type   as sets, then   is the set-theoretic intersection of these sets. Put differently: The members of the result are members of both operands. # The intersection of two object types has the properties of both types: (The generic type   is explained later.) # If we are mixin in an object type   into another type  , then we need an intersection type (line A): Control flow   # Conditional types   # A   has the following syntax: If   is assignable to  , then the result of this type expression is  . Otherwise, it is  . # In the following example,   only wraps types in one-element tuples if they have the property   whose values are numbers: # We can use a conditional type to implement an assignability check: For more information on the type relationship  , see the blog post  “What is a type in TypeScript? Two perspectives” . # Conditional types are  : Applying a conditional type   to a union type   is the same as the union of applying   to each component of  . This is an example: In other words, distributivity enables us to “loop” over the components of a union type. This is another example of distributivity: # Interpreted as a set, type   is empty. Therefore, if it appears in a union type, it is ignored: That means we can use   to ignore components of a union type: This is what happens if we swap the type expressions of the then-branch and the else-branch: # Excluding types from a union is such a common operation that TypeScript provides the built-in utility type  : # The inverse of   is  : # Similarly to JavaScript’s ternary operator, we can also chain TypeScript’s conditional type operator: Mapped types   # A   produces an object by looping over a collection of keys – for example: The operator   is a crucial part of a mapped type: It specifies where the keys for the new object literal type come from. # The following built-in utility type lets us create a new object by specifying which properties of an existing object type we want to keep: It is used as follows: # The following built-in utility type lets us create a new object type by specifying which properties of an existing object type we want to omit: Explanations: \n \n  means that   must be a subtype of the type of all property keys: \n \n \n \n  means: take the keys of   and remove all “values” mentioned in  . \n \n  is used as follows: Various other operators   # The index type query operator     # We have already encountered the type operator  . It lists the property keys of an object type: Applying   to a tuple type has a result that may be somewhat unexpected: The result includes: \n The indices of the tuple elements, as strings:  \n The type   of index property keys \n The name of the special instance property  \n The names of all   methods:  \n The property keys of an empty object literal type are the empty set  : This is how   handles intersection types and union types: This makes sense if we remember that   has the properties of   type   and type  .   and   only have property   in common, which explains  . The indexed access operator     # The indexed access operator   returns the types of all properties of   whose keys are assignable to type  .   is also called a  . These are examples of the operator being used: The type in brackets must be assignable to the type of all property keys (as computed by  ). That’s why   and   are not allowed. However, we can use   and   as index types if the indexed type has an index signature (line A):  includes the type   because number keys are a subset of string keys in JavaScript (and therefore in TypeScript). Tuple types also support indexed access: The bracket operator is also distributive: The type query operator     # The type operator   converts a (JavaScript) value to its (TypeScript) type. Its operand must be an identifier or a sequence of dot-separated identifiers: The first   is a value, while the second   is its type, a string literal type. This is another example of using  : Sect. “Adding a symbol to a type” in another blog post  describes an interesting use case for  . comments powered by Disqus."},
{"url": "https://2ality.com/2020/06/private-static-methods-accessors-in-classes.html", "title": "ECMAScript proposal: private static methods and accessors in classes", "content": "ECMAScript proposal: private static methods and accessors in classes dev javascript es proposal js classes This blog post is part of a series on new members in bodies of class definitions: Public class fields Private class fields Private prototype methods and getter/setters in classes Private static methods and getter/setters in classes This post explains private static methods and accessors in classes, as described in the ECMAScript proposal  “Static class features”  by Shu-yu Guo and Daniel Ehrenberg. \n   \n     Overview: private static methods and accessors \n   \n   \n     An example with private static methods \n     \n       \n         Pitfall: Don’t access private static constructs via  \n       \n     \n   \n   \n     The specification for private static fields, methods, and accessors \n     \n       \n         The foundations laid by private prototype methods \n       \n       \n         The specification for private static constructs \n       \n       \n         The internal representation of private static methods and private instance fields illustrated in JavaScript \n       \n     \n   \n Overview: private static methods and accessors   # The following kinds of private static methods and accessors exist: An example with private static methods   # The following class has a private static method  : This code shows the key benefit of private static methods, compared to external (module-private) helper functions: They can access private instance fields (line A and line B). Pitfall: Don’t access private static constructs via     # Accessing public static constructs via   lets us avoid redundant use of class names. It works because those constructs are inherited by subclasses. Alas, we can’t do the same for private static constructs: The problem in line A is that   points to   which does not have the private field  . For more information, see  the blog post “Private class fields” . The specification for private static fields, methods, and accessors   # The foundations laid by private prototype methods   # Support for static methods and accessors is based on mechanisms that were introduced for prototype methods and accessors ( more information ). We will only examine private methods, but everything we discover also applies to private getters and setters. # Consider a method   that is created “inside” an object  . This method is stored externally, in a specification data structure called  . Private names are also used to represent other private class elements. They are looked up via  , which map identifiers to private names and exist next to environments for variables. Private environments are explained later. In this case, the private name has the following slots: \n \n \n \n  points to the method object (a function) \n The   of a private method is the object it was created in. # Each object   has an internal slot   which contains the brands of all methods that can be invoked on  . There are two ways in which elements are added to the private brands of an object: \n \n When a class   is  -invoked, it adds   to the private brands of  . That means that  ’s private prototype methods (whose brand is  ) can be invoked on  . \n \n \n If a class   has private static methods,   is added to the private brands of  . That means that  ’s private static methods (whose brand is  ) can be invoked on  . \n \n # Therefore, the private brands of an object are related to the prototype chain of an object. Why has this mechanism been introduced if it is so similar? \n \n Private methods are designed to be actually private and to have integrity. That means that they shouldn’t be affected by outside changes. If the private brands of an object were determined by its prototype chain, we could enable or disable private methods by changing the chain. We could also observe part of the executions of private methods by observing the traversal of the prototype chain via a Proxy. \n \n \n This approach guarantees that, when we invoke a private method on an object, its private fields also exist (as created by constructors and evaluations of class definitions). Otherwise, we could use   to create an instance without private instance fields to which we could apply private methods. \n \n # Execution contexts now have three environments: \n  points to the environment for   and   (block scoping). \n  points to the environment for   (function scoping). \n  points to an environment that maps identifiers prefixed with   to   records. \n Functions now have two lexical environments: \n  refers to the environment of the scope in which the function was created. \n  refers to the environment with the private names that was active when the function was created. \n The operation   temporarily changes the current execution context for the body of a class: \n The   is set to  , a new declarative environment. \n The   is set to  , a new declarative environment. \n For each identifier   of the   of the class body, one entry is added to the   of  . The key of that entry is  , the value is a new private name. The specification for private static constructs   # The following parts of the runtime semantics rule   are relevant for static private constructs (  refers to the constructor): \n \n Step 28.b.i: Perform   for each static  \n \n Step 28.d.ii: If the result is not empty, it is added to a list   (so that it can be attached to   later). \n \n \n \n Step 33.a: If there is a static method or accessor   in   of   and  ’s   is  : Execute  . Intuitively, that means: object   can be receiver of methods stored in object  \n \n \n Step 34.a: For each   in  :  \n \n The internal representation of private static methods and private instance fields illustrated in JavaScript   # Let’s look at an example. Consider the following code from earlier in this post: Internally, it is roughly represented as follows: \n Thanks for feedback:  Daniel Ehrenberg \n Thanks for feedback:  Ricky Munroe \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/08/minimal-react.html", "title": "Minimal React: getting started with the frontend library", "content": "Minimal React: getting started with the frontend library dev javascript frontend react This blog post explains how to get started with React while using as few libraries as possible. \n   \n     Required knowledge \n   \n   \n     About this blog post \n   \n   \n     The repository \n   \n   \n     What is React? \n     \n       \n         The traditional model-view-controller (MVC) approach \n       \n       \n         React \n       \n     \n   \n   \n     First example: counting clicks \n     \n       \n         Adding the user interface to the HTML page \n       \n       \n         Creating user interface elements \n       \n       \n         The component  \n       \n     \n   \n   \n     Second example: expandable sections \n     \n       \n         User interface component  \n       \n       \n         User interface component  \n       \n       \n         Exercises \n       \n     \n   \n   \n     Third example: quiz \n     \n       \n         The model \n       \n       \n         Immer \n       \n       \n         The root controller pattern \n       \n       \n         The user interface components \n       \n       \n         Exercises \n       \n     \n   \n   \n     How does Snowpack work? \n     \n       \n         Building \n       \n     \n   \n   \n     Conclusion \n     \n       \n         State management via the root controller pattern \n       \n       \n         Next steps \n       \n       \n         Learning more about the React ecosystem \n       \n     \n   \n Required knowledge   # Things you should know before reading this blog post: \n JavaScript: You should have already written code in that language. \n Browser DOM (document object model): It helps if you are loosely familiar with how the DOM represents HTML and how it handles events. \n npm: It also helps if you have a basic understanding of the npm package manager for Node.js. \n About this blog post   # Many tutorials provide comprehensive introductions to the React ecosystem. I wanted to try something different: What is the smallest set of libraries that allows you to be productive in React? This is an exhaustive list of the npm packages that the code in this blog post depends on: \n Build tool  :\n \n \n \n \n \n User interface library  :\n \n \n \n \n \n React helper library   (to specify user interfaces via an HTML-like syntax):\n \n \n \n \n Library   for non-destructively updating data:\n \n \n \n \n The repository   # The repository   contains the examples that we are exploring in this blog post: \n You can try out the examples  online . \n You can install it locally to play with the complete setup. Everything is installed inside a single directory, so it’s easy to remove later on. \n However, installing the repository is not required for following this blog post. All relevant data is quoted inside the post. \n The repository has the following structure: \n \n \n : HTML files \n : JavaScript code \n : Instructions for installing and running the project \n : Configuring the npm package manager \n : Configuring the Snowpack build tool \n \n \n  specifies the npm packages that the JavaScript code depends on:  also defines two scripts: These are executed via: \n Starting the development web server:  \n \n Abbreviated:  \n \n \n Creating a standalone application (that runs without the development server):  \n What is React?   # React is a library for creating user interfaces in web browsers. Before we take a look at how it works, let us remind ourselves how user interfaces are created if they are based on a traditional model-view-controller approach. The traditional model-view-controller (MVC) approach   # This object-oriented approach gets its name from three roles that objects play in it: \n The   is the data to be accessed via the graphical user interface. \n The   displays the model. \n The   reacts to   (actions by the user) and updates model and view accordingly. \n Traditional MVC-based user interfaces work as follows: \n A tree of user interface components is created once. \n Each user interface component manages its own state and updates it incrementally, in response to user interactions. \n “Glue code” that is external to the user interface components, propagates state changes between them. \n This approach has downsides: \n The user interface logic is often scattered across the code. \n Cross-component changes are difficult to implement. \n It’s easy to introduce inconsistencies because there can be many different combinations of states. \n React   # React works differently: \n The user interface is encoded as a tree-shaped data structure. It is called  , due to its similarity with the   used by browsers to represent HTML. \n There is a single (nested) model for the complete user interface. \n A user interface component is simply a function that maps a model to a user interface.\n \n The root component has as input the whole model and passes on parts of that model to subcomponents (which are also functions). \n \n \n When the user interacts with the user interface, the model is changed accordingly and the complete user interface is recreated (by invoking the root component again).\n \n To make this viable, performance-wise, React compares the virtual DOM returned by the root component with the current browser DOM. It only changes the latter where the former differs. \n \n \n Benefits of this approach: \n It’s easier to understand the user interface logic. \n Cross-component dependencies are easier to implement. \n The data flow is simpler: always from the top of the user interface component tree to its bottom. \n First example: counting clicks   # The first example is in the file  . Adding the user interface to the HTML page   # This is the body of the HTML page: This is how   adds its user interface to the web page: \n Line A is how we create user interface elements (via the virtual DOM). Read on for more information. \n Line B is the HTML element in which React creates the user interface. \n Creating user interface elements   # Consider the following syntax from the previous example: There are two layers to this syntax. #  is a  . Tagged templates are a JavaScript language feature that lets us embed foreign syntax in JavaScript code. Each tagged template is actually a function call – for example: The the last line is equivalent to: Tag functions such as   can return arbitrary values and are usually guided by their input. In this case, the input is: \n The     are static (the same each time this particular function call is made) \n The     and   are dynamic (possibly different each time this particular function call is made) \n Substitutions are inserted “into” the template via the syntax  . The     supports React’s syntax for creating virtual DOM elements. It parses its input to produce its output. #  is a non-standard JavaScript language feature introduced by React. It lets us use HTML-ish expressions to create virtual DOM data. JSX must be compiled to standard JavaScript and is supported by several compilers – for example: \n Babel :\n \n Input: modern and/or future JavaScript \n Output: current or older JavaScript \n \n \n TypeScript :\n \n Input: JavaScript plus static type information (roughly, a superset of JavaScript) \n Output: current or older JavaScript \n \n \n In this tutorial, we use a tagged template instead of JSX, which has the benefit that we can use plain JavaScript (no compilation is necessary). There are only minor differences between   syntax and JSX, which is why I’ll occasionally use the name JSX for the former. There are two kinds of elements. # First, the name of an element can be a function whose name starts with an uppercase letter: This expression is equivalent to: In this case,   makes the following function call: # Second, the name of an element can also be a string that starts with a lowercase letter: This expression is equivalent to: In this case,   directly creates virtual DOM data. # Let’s go back to the initial code: What is happening here? We are invoking the component   (a function) and pass it a single parameter, whose label is  . This is what the root model looks like: The component     # The component is implemented as follows: The component returns a single virtual DOM element, a  . We use the   syntax to insert values into the returned data: \n The click event handler  \n The number  \n The click event handler  \n # The function call   in line A adds   to our code: \n  is the current model data (the M in MVC). \n  is the initial value of  . \n  can be used to change  . Whenever we do that, React automatically reruns the   component so that the user interface always reflects what’s in the model. \n Never mind   React does this! There is a ton of magic going on behind the scenes. Therefore, it is better to think of   as a language mechanism rather than as a function call.   and other similar functions are called   because they let us hook into React’s API. # Clicks on the   element are handled by the following function: If a user clicks on an   element that has the attribute  , then, by default, the browser goes to the location specified by the attribute. The method call in line A prevents that from happening. In line B, we create a new root model. We don’t change the existing model, we create a modified copy of it. Non-destructively updating data is a best practice in React. It avoids  several problems . In line C, we use the setter created by the   hook to make   the new root model. As mentioned before,   will also recreate the complete user interface by invoking   again. Clicks on the   are handled by the following function: This time, we don’t need to prevent a default action. We again create a new root model and activate it via  . Second example: expandable sections   # The second example is in the file  . # This time, the entry point of the JavaScript code looks like this: The initial root model is: Function   adds a single user-interface-related property to the root model: We use  spreading ( )  to copy each element of the Array   while adding the new property  . Once again, we are not modifying the original data, we are updating it non-destructively. User interface component     # This is the root user interface component of the current example: We again use the   hook to manage the model. This time, the component returns an Array of virtual DOM elements (that are created by the subcomponent  ). Note the   attribute in line A. Whenever we use an Array as virtual DOM data, each of the elements must have a unique key. The idea is that React can more efficiently update the browser’s DOM if each Array element has a unique identity. For example, if we only rearrange the elements but don’t otherwise change them, then React only needs to rearrange browser DOM nodes. User interface component     # This is the component for a single section: # In line A, we are specifying CSS via an object literal: \n CSS property names such as   are translated to JavaScript identifiers such as  . \n CSS property values are specified via strings. \n # In line C, we are using   to insert a string into the user interface. JSX handles whitespace differently from HTML: Whitespace between lines is completely ignored. That’s why there is a space after each triangle. Why does JSX do that? We can see the benefit in line B: The opening   tag can be on its own line and no space is inserted between that tag and the text in the next line. # In line D, we are evaluating a condition: \n If the condition is true, we don’t insert anything into the user interface (as indicated by the special value  ). \n If the condition is false, we insert virtual DOM data into the user interface. \n # In line E, we are dealing with clicks on the triangle: \n First, we prevent the browser’s default action. \n Next, we change the model of the root component via   (which was passed to   via a parameter). That leads to the user interface being re-rendered. \n Function   non-destructively updates   so that only the section is expanded whose index is  . Exercises   # \n Add numbers to the sections. \n Change the code so that more than one section can be open at the same time.\n \n You’ll need to change and rename  . \n \n \n Third example: quiz   # The third example is in the file  . The model   # This is the data that encodes quiz entries. Each entry has a question and zero or more answers: Immer   # This time, we use  the library   to help us with non-destructively updating data. It works as follows: We provide the Immer function   with the data to be updated,   and a callback. The callback destructively changes its parameter   so that it has the desired shape. It treats   as if it were  , but the former is actually a special object: Immer observes the operations that are performed on it. They tell Immer how to create a modified copy of  . The following function uses Immer to add two user interface properties to  : \n Property   is added to each entry (line A). \n Property   is added to each answer (line B). \n If we handled the non-destructive updating ourselves,   would look as follows: In line A, we copy   via spreading ( ) while adding the new property   and overriding the existing property   (whose value we need to copy). We can see that the Immer-based code is simpler, but not much. As we’ll see soon, Immer especially shines with deeply nested data. The root controller pattern   # This is how the root component   is rendered into the HTML page: The root component   knows the complete model (the result of  ). Each of its subcomponents receives part of the root model and a reference to a so-called  , which is an instance of the following class: Whenever a user interaction happens in one of the subcomponents of  , that subcomponent asks the root controller to change the root model accordingly. After the change, the root controller calls   (which originally was created via the   hook) and the whole user interface is recreated. The root controller having access to the whole model has one considerable benefit: It’s easy to manage cross-component changes. In line A and line B, we used Immer to non-destructively update  . This time, the code is much simpler than without Immer. I call the pattern of passing a root controller object to all user interface components the  . The user interface components   # # This is the implementation of the root component: A React component must return valid virtual DOM data. Valid data is: \n A single virtual DOM element \n A boolean, a number, or a string \n  (which produces zero output) \n An Array where each element is valid virtual DOM data \n In line A, we use the special component   to return multiple elements. This works better than an Array because conceptually, Array elements tend to be similar in nature and produced via iteration. And with an Array, we would have to specify   attributes.  has two subcomponents:   and  . # Each quiz entry is initially   – the user can check and uncheck answers as desired. Once they submit the answers they think are correct, the entry is  . Now they can’t change the selected answers anymore and the quiz app lets them know if they got their answers right or not. # The component   displays entries that are open: With an open entry, we can submit our answers via a button (line A). Note how the click handler   uses the root controller instance in   to change the model and to refresh the user interface. We also refresh the complete user interface whenever the user changes a checkbox (line B). # The component   displays entries that are closed: This time, all answers are disabled – we can’t check or uncheck them anymore (line B). We give the user feedback if they got their answers right (line A). # Component   is shown at the end of the quiz: In line A, we once again have to account for the JSX whitespace rules: In order for the number after “of” to be separated from the word “entry” or “entries”, we have to insert a space before the latter. This component summarizes: \n : How many entries have we answered already? \n : How many entries did we answer correctly? \n Exercises   # \n Use the browser function   to load a JSON file with the quiz data.\n \n You can put that JSON file in the   directory. \n You will invoke   first and render   after you have received the JSON data. \n \n \n Change   so that it doesn’t use the Immer library. That should make it obvious how useful that library is. \n How does Snowpack work?   # Snowpack is configured via the file  . Its contents are (with one minor setting omitted): Apart from the dependencies that we have stated in  , that is all the configuration data that Snowpack needs:   states which directories contain data that Snowpack should serve or build. Snowpack serves and builds three kinds of data: \n The mounted directories \n Directory   with Snowpack-related metadata (which is can be used in advanced building scenarios) \n Directory  :\n \n After an  , directory   contains all dependencies mentioned in  . There are usually multiple files per package and some of them may be in the CommonJS module format which browsers don’t support natively. \n Snowpack examines the JavaScript code in the mounted directories. Whenever one of the dependencies is mentioned, it compiles the package in   into browser-compatible code in  . Often the latter is a single file. \n \n \n Additionally Snowpack slightly changes the imports in mounted JavaScript files. Other than the imports, Snowpack doesn’t change anything in JavaScript files (during development time, when using the server). Building   #  is performed via the following command: Snowpack writes the complete web app into the directory   (including   etc.). This version of the app works without the Snowpack development server and can be deployed online. Conclusion   # State management via the root controller pattern   # I’ve used the root controller pattern in several of my React applications and I got surprisingly far without needing a more advanced state management solution. If you don’t want to pass the root controller explicitly, you can take a look at  the   hook . Next steps   # The React ecosystem consists of a small core (the library itself) that is complemented by many external add-ons. That has an upside and a downside: \n Upside: It’s relatively easy to learn the core. The add-ons are all optional. \n Downside: There is a lot of choice w.r.t. the add-ons, which can result in serious analysis paralysis. \n There are two good options for getting started: \n \n Start small, e.g. with the setup shown in this blog post. Only add more libraries if you really need them – each one increases the weight of the project. \n \n \n The React team has created a “batteries included” application setup called  . That’s a good starting point if you want more functionality from the get-go. \n \n Learning more about the React ecosystem   # \n \n If you want to read more about the React ecosystems, there are many guides available online. For example,  “React Libraries in 2020”  by Robin Wieruch. \n \n \n You can also use React to develop native applications:   is also based on a virtual DOM. But in this case, it is used to render native user interfaces. This is a compelling proposition, especially for cross-platform applications. \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/07/eliminating-duplicate-objects.html", "title": "Eliminating duplicate objects: three approaches", "content": "Eliminating duplicate objects: three approaches dev javascript In this blog post, we look at three approaches for eliminating duplicate objects from Arrays. Eliminating duplicates from Arrays   # Eliminating duplicate values from Arrays is simple – as long as the values are primitive (and therefore compared by value): However, that approach doesn’t work with the following data because a Set would consider each object to be unique: Approach 1: building a new Array without duplicates   # We only add an object from   to   if it doesn’t already exist in that Array. That’s why the earlier Jane with ID   “wins”. Approach 2: using     #  returns the first index where a member appears. We tell   to only keep the members at those indices. That’s why the first Jane “wins”. Approach 3: a Map from unique keys to members   # If an object that is added to the Map has the same unique key as a previous object, it replaces that object. That’s why the later Jane with ID   “wins”. Variants of approach 1 and approach 2   # \n We use a Set to record unique keys of members that we have visited. \n If the key of the current member is already in that Set, then we don’t push it (approach 1) or filter it out (approach 2). \n This may help with large Arrays because we don’t have to search them. On the other hand, creating keys and maintaining a Set affects performance negatively. Further reading   # \n Chapter on Sets  in “JavaScript for impatient programmers” \n Chapter on Maps  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/reflection-and-meta-programming-in.html", "title": "Reflection and meta-programming in JavaScript", "content": "Reflection and meta-programming in JavaScript pl fundamentals dev javascript jslang ECMAScript 5 Reflection \n \nWhen examining the properties of an object, JavaScript’s default is to include inherited properties. Thus, you have to make sure that a method does what you want and that will usually be to ignore inherited properties. One clue is to look for the presence or absence of “own” in the method name. For example, ES5’s   returns all direct (non-inherited) property descriptors of an object.\n function.js Meta-programming \n  One use case is to have an object with no methods and to turn every method invocation into a request made to a server. Another use case is to use an object B to intercept every method call to an object A and to log it. This can be done by making A the prototype of B and by letting it react to unknown (i.e., all) methods. The pseudo-method   allows one to do that. It is supported by Firefox and Rhino, but not by V8 (Chrome, node.js). It is on the list of features that might make it into V8, though. Given the following definition.\n \n  ECMAScript 5 allows one to define functions that implement the getting or the setting of a property. That means that a property can be completely virtual. For example, one could forbid setting it via its property descriptor and always compute its value. Given the following definition.\n \n “ The Art of the Metaobject Protocol ” [ uk ,  de ] by Gregor Kiczales, Jim des Rivieres, Daniel G. Bobrow. This can be seen as a precursor to Kiczales’ work an aspect-orientation. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/bookmarklets-what-they-are-and-how-to.html", "title": "Bookmarklets: simple plugins for your browser", "content": "Bookmarklets: simple plugins for your browser browser bookmarklet hack computers \n      Usually, a bookmarklet is provided on the web as a link that you drag to your bookmarks bar. \n      of useful bookmarklets:\n         \n         This blog lists  several bookmarklets . \n         Twitter : share the current web page on Twitter.  \n         Tumblr : publish a link to the current web page. \n         Instapaper : archive a copy of the current web page. (There is  major magic  going on behind the scenes.) \n         \n     \n      bookmarklets can be quickly invoked via  browser keywords . \n javascript:alert(\"hello\") \n  \n Implementing bookmarklets in JavaScript \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/browser-keywords-using-address-bar-as.html", "title": "Browser keywords: using the address bar as a command line", "content": "Browser keywords: using the address bar as a command line browser firefox hack computers chrome Examples \n “gg foo” googles for “foo”  \n “we foo” searches Wikipedia for “foo” \n “dict panache” looks up “panache” in an online dictionary \n “imdb inception” looks up “inception” in IMDB. \n How it works Tips \n     Keywords in Google Chrome: “Preferences → Basics → Search → Manage Search Engines...” \n     Keywords in Firefox: Go to the properties of a bookmark and set a value for “Keyword”. \n     Keyboard shortcuts that work in most browsers:\n         \n             Ctrl-T (Mac: Cmd-T) opens a new tab. \n             Ctrl-L (Mac: Cmd-L) gets you to the address bar. \n         \n     \n Details \n     Lifehacker  explains  the basics of keywords. \n     Mozilla  describes  the “add a keyword for this search” feature. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/09/item-method.html", "title": "ECMAScript proposal: Method  .item()  for Arrays, Typed Arrays, and strings", "content": "ECMAScript proposal: Method   for Arrays, Typed Arrays, and strings dev javascript es proposal The ECMAScript proposal “ ”  (by Shu-yu Guo and Tab Atkins) introduces the mentioned method for   values (Arrays, Typed Arrays, strings). Given an index, the method returns the corresponding element. Its key benefit is that indices can be negative (  gets the last element,   the second last, etc.). This blog post examines   in detail.  The method name   ended up not being web-compatible. The tentative new name is  . \n   \n     Method   for indexable classes \n     \n       \n         Out-of-bounds indices \n       \n       \n         Classes that have method  \n       \n     \n   \n   \n     Accessing the elements at the end of an Array – alternatives to  \n   \n   \n     A polyfill for  \n     \n       \n         npm packages with polyfills \n       \n     \n   \n   \n      and upgrading indexable DOM collections \n   \n   \n     Example:   with callback \n   \n   \n     FAQ \n     \n       \n         Why not allow negative indices in brackets? \n       \n       \n         Why not   and  ? \n       \n       \n         What about the ECMAScript proposal for  ? \n       \n     \n   \n   \n     Sources and acknowledgements \n   \n Method   for indexable classes   # Method   works as follows for Arrays: That is, the following two expressions are roughly equivalent: The previous two lines demonstrates the key benefit of  : We can use negative indices that access the elements at the end of an Array. Other Array methods such as   already support negative indices (while the square bracket operator   doesn’t): Out-of-bounds indices   # If an index is out of bounds, the square bracket operator accesses the value of a non-index property: The range of Array indices  is [0, 2^32^−1) (the maximum Array length 2^32^−1 is excluded). In contrast,   returns   in such a case: That makes working with indices a little bit safer. Classes that have method     # The proposal is to add method   to all   classes and primitive types of ECMAScript: \n \n All Typed Array classes:   etc. \n \n Additionally, several DOM classes already have that method: \n  (dynamic, returned by  ,  , etc.) \n  (static, returned by  ) \n  (static, value of  ) \n And others \n Accessing the elements at the end of an Array – alternatives to     # When it comes to negative indices, there are alternatives to  , but they are clumsy and/or inefficient: If we need to get the last element of an Array and don’t mind that element being removed in the process, then we can also use  : A polyfill for     # This is how we could polyfill   (a slightly edited version of  code shown in the proposal ): npm packages with polyfills   # The following two npm packages provide polyfills: \n \n \n  and upgrading indexable DOM collections   # A current plan for the DOM is to base existing and upcoming indexable DOM data structures such as   and   on  . Instances of that class are proxies for Arrays and therefore have methods such as   that are currently not available in indexable DOM data structures. Then it will no longer be necessary to convert these data structures to Arrays before using these methods: All indexable DOM data structures have the method  .  For various reasons , the easiest way to make   compatible with them, was to add this method to  . Example:   with callback   # The following code shows where   is useful:  is always the last parameter of the   callback. This is a workaround if   isn’t available in line A: FAQ   # Why not allow negative indices in brackets?   # Unfortunately, JavaScript can’t be changed to allow negative indices in square brackets. The problem is that such a change would break existing code. Let’s look at a few examples. I don’t recommend the techniques they are using, but similar code does exist on the web. Each one would break if negative indices were allowed in brackets. First example: Second example: Third example: Why not   and  ?   # As explained in Sect. “  and upgrading indexable DOM collections”, the method name   helps with upgrading the DOM. That’s why this name was preferred over alternatives. What about the ECMAScript proposal for  ?   # There is also  a stage 1 proposal for a getter/setter  . However, quoting that proposal: Other proposals ( Array.prototype.item  and  Array Slice Notation ) also sufficiently solve this problem, and are advancing quicker through the standards track. Should one of these proposals advance to Stage 3, this proposal will be dropped. Sources and acknowledgements   # Sources of this blog post: \n The ECMAScript proposal for  \n “HTMLCollection vs NodeList”  by  Celeste Layne \n The following people contributed to this blog post via discussions on Twitter: \n Sylvain Pollet-Villard \n Marek Szkudelski \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/going-completely-prototypal-in.html", "title": "Going completely prototypal in JavaScript", "content": "Going completely prototypal in JavaScript pl fundamentals dev javascript jslang Prototypes as classes \nIn this post we present the Proto API which implements inheritance in JavaScript in a purely prototypal fashion. This contrasts it with all other JavaScript inheritance APIs that the author is aware of.\n \n \nTo clarify what “purely prototypal” means, let us look at class inheritance and prototypal inheritance and how it compares to JavaScript:\n \n\t Class inheritance works as follows: Classes are factories for objects. For methods and properties (attributes, fields), one specifies which ones are shared between instances (class methods and properties) and which ones appear in each instance (instance methods and properties). If we look closely, we see that instance methods are actually also shared between instances, but they act at the instance level. \n\t Prototypal inheritance works as follows: You construct an initial instance and copy it for every new instance you need. For shared data and for instance methods, all copies have a common   (which JavaScript would call the prototype). The initial instances replace classes as creators of new instances. Thus, there are only ever objects and they are all manipulated directly. \n\t JavaScript inheritance is an uneven mix of the previous two. The prototype is built directly, instance properties are put into a constructor which acts as an instance factory. \n \nTo improve JavaScript’s inheritance, most frameworks go the route of class inheritance and introduce class objects. For example, the following is Qooxdoo code:\n proto.js \nRelated reading:\n Reflection and meta-programming in JavaScript  (explains how to list the arguments of a function, a trick that is used in the Proto implementation) An easy way to understand JavaScript’s prototypal inheritance \n Lightweight JavaScript inheritance APIs comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/three-javascript-shells.html", "title": "Three JavaScript shells", "content": "Three JavaScript shells dev javascript jslang \n     \n         Rhino : Download, unzip, go into its directory and type “java -jar js.jar”. Editing is limited, but you can  fix that .\n     \n     \n         \n             Better line editing: see  section  in “New in Rhino”.\n             \n         \n         \n             \n                 Shell documentation \n             \n         \n         \n             Help:  \n             \n             Printing an object: use the   method to see an object’s properties.\n             \n             Rhino 1.7R2 does not support ECMAScript 5, yet. You need to check out and build the latest version.\n             \n             \n                 \n                     Check out:  \n                     \n                     Go into directory:  \n                     \n                     Display build options:  \n                     \n                     Build jar:  \n                     \n                 \n             \n         \n     \n     \n         node.js : Download, build and install (as explained on the website). Type “node” to start. Its editing is quite capable, it even shows properties if you hit Tab after the dot in input such as “obj.”.\n     \n     \n         \n             \n                 Shell documentation \n             \n             Help:  \n             \n             Load a file: cannot be done from inside the shell, but there is a  work-around .\n             \n         \n     \n Web Console comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/bookmarklets-quickly-link-to-website.html", "title": "Bookmarklets: quickly link to a website", "content": "Bookmarklets: quickly link to a website browser bookmarklet hack blogging computers bookmarklets For HTML WYSIWYG editors:  wysiwyg link \n Usage: Run bookmarklet, select all, paste into your HTML editor. Works great with Blogger. \n JavaScript:  \n For HTML source code editors:  source link \n Usage: Run bookmarklet, copy the current selection, hit Return, paste somewhere. \n JavaScript:  \n For other editors:  title + url \n Usage: Run bookmarklet, copy the current selection, hit Return, paste somewhere. \n JavaScript:  \n new bookmarklet comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/new-device-apis-for-web-browsers.html", "title": "New device APIs for web browsers", "content": "New device APIs for web browsers dev webdev Device APIs and Policy Working Group \n Accessing a devices’s  contacts  and calendar \n Accessing camera and microphone via  forms  and an  API \n Messaging  (SMS, MMS, emails) \n Systems info and events  (CPU, network, etc.) \n Permissions for device API access  \n And more...  \n Chrome mentions comments powered by Disqus."},
{"url": "https://2ality.com/2020/02/understanding-types-typescript.html", "title": "What is a type in TypeScript? Two perspectives", "content": "What is a type in TypeScript? Two perspectives dev javascript typescript What are types in TypeScript? This blog post describes two perspectives that help with understanding them. \n   \n     Three questions for each perspective \n   \n   \n     Perspective 1: types are sets of values \n   \n   \n     Perspective 2: type compatibility relationships \n   \n   \n     Nominal type systems vs. structural type systems \n   \n   \n     Further reading \n   \n Three questions for each perspective   # The following three questions are important for understanding how types work and need to be answered from each of the two perspectives. \n What does it mean for   to have the type  ? \n \n \n Is   assignable to  ? \n \n \n How is   derived from  ,  , and  ? \n \n Perspective 1: types are sets of values   # From this perspective, a type is a set of values: \n If   has the type  , that means that all values that can be assigned to   must be elements of the set  . \n \n  is assignable to   is   is a subset of  . As a consequence, all values allowed by   are also allowed by  . \n \n The type union of the types  ,  , and   is the set-theoretic union of the sets that define them. \n Perspective 2: type compatibility relationships   # From this perspective, we are not concerned with values and how they flow when code is executed. Instead, we take a more static view: \n \n Source code has locations and each location has a static type. In a TypeScript-aware editor, we can see the static type of a location if we hover above it with the cursor. \n \n \n When a source location is connected to a target location via an assignment, a function call, etc., then the type of the source location must be compatible with the type of the target location. The TypeScript specification defines type compatibility via so-called  . \n \n \n The type relationship   defines when a source type   is assignable to a target type  : \n \n  and   are identical types. \n  or   is the type  . \n Etc. \n \n \n Let’s consider the questions:  has type   if the static type of   is assignable to  .  is assignable to   if they are assignment-compatible. How type unions work is defined via  the type relationship  . An interesting trait of TypeScript’s type system is that the same variable can have different static types at different locations: Nominal type systems vs. structural type systems   # One of the responsibilities of a static type system is to determine if two static types are compatible: \n The static type   of an actual parameter (provided, e.g., via a function call) \n The static type   of the corresponding formal parameter (specified as part of a function definition) \n This often means checking if   is a subtype of  . Two approaches for this check are (roughly): \n \n In a   or   type system, two static types are equal if they have the same identity (“name”). One type is a subtype of another if their subtype relationship was declared explicitly. \n \n Languages with nominal typing are C++, Java, C#, Swift, and Rust. \n \n \n \n In a   type system, two static types are equal if they have the same structure (if their parts have the same names and the same types). One type   is a subtype of another type   if   has all parts of   (and possibly others) and each part of   has a subtype of the corresponding part of  . \n \n Languages with structural typing are OCaml/ReasonML, Haskell, and TypeScript. \n \n \n The following code produces a type error (line A) in nominal type systems, but is legal in TypeScript’s structural type system because class   and class   have the same structure: TypeScript’s interfaces also work structurally – they don’t have to be implemented in order to match: Further reading   # \n Chapter “Type Compatibility” in the TypeScript Handbook \n Section “TypeRelationships” in the TypeScript Specification \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/04/typing-functions-typescript.html", "title": "Typing functions in TypeScript", "content": "Typing functions in TypeScript dev javascript typescript This blog post explores static typing for functions in TypeScript. For the remainder of this post, most things that are said about functions (especially w.r.t. parameter handling), also apply to methods. \n   \n     Defining statically typed functions \n     \n       \n         Function declarations \n       \n       \n         Arrow functions \n       \n     \n   \n   \n     Types of functions \n     \n       \n         Function type signatures \n       \n       \n         Interfaces with call signatures \n       \n       \n         Checking if a value matches a type \n       \n     \n   \n   \n     Parameters \n     \n       \n         When do parameters have to be type-annotated? \n       \n       \n         Optional parameters \n       \n       \n         Rest parameters \n       \n       \n         Named parameters \n       \n       \n          as a parameter \n       \n     \n   \n   \n     Overloading \n     \n       \n         Overloading function declarations \n       \n       \n         Overloading via interfaces \n       \n       \n         Overloading on string parameters (event handling etc.) \n       \n       \n         Overloading methods \n       \n     \n   \n   \n     Assignability \n     \n       \n         The rules for assignability \n       \n       \n         Consequences of the rules for functions \n       \n     \n   \n   \n     Further reading and sources of this blog post \n   \n Defining statically typed functions   # Function declarations   # This is an example of a function declaration in TypeScript: \n \n Parameters: If the compiler option   is on (which it is if   is on), then the type of each parameter must be either inferrable or explicitly specified. (We’ll take a closer look at inference later.) In this case, no inference is possible, which is why   and   have type annotations. \n \n \n Return value: By default, the return type of functions is inferred. That is usually good enough. In this case, we opted to explicitly specify that   has the return type   (last type annotation in line A). \n \n Arrow functions   # The arrow function version of   looks as follows: In this case, we can also use an expression body: Types of functions   # Function type signatures   # We can define types for functions via function type signatures: The name of this type of function is  . It matches all functions that: \n Have two parameters whose types are   and  . We need to name parameters in function type signatures, but the names are ignored when checking if two function types are compatible. \n Have the return type  . Note that this time, the type is separated by an arrow and can’t be omitted. \n (We’ll cover the precise compatibility rules later.) Interfaces with call signatures   # We can also use interfaces to define function types: Note: \n The member in line A is a  . It looks similar to a method signature, but doesn’t have a name. \n The type of the result is separated by a colon, not by an arrow. \n On one hand, interfaces are more verbose. On the other hand, they let us specify properties of functions (which is rare, but does happen): We can also specify properties via a type intersection ( ) of a function signature type and an object literal type: Checking if a value matches a type   # As an example, consider this scenario: A library exports the following function type. We want to define a function whose type is compatible with  . And we want to check immediately if that’s indeed the case (vs. finding out later when we use it for the first time). # If we declare a variable via  , we can perform the check via a type annotation: Note that we don’t need to specify the type of parameter   because TypeScript can use   to infer it. # Checking function declarations is more complicated: # The following solution is slightly over the top (i.e., don’t worry if you don’t fully understand it), but it demonstrates several advanced features: \n \n Parameters: We use   to extract a tuple with the parameter types. The three dots declare a rest parameter, which collects all parameters in a tuple/Array.   destructures that tuple. (More on rest parameters later in this post.) \n \n \n Return value: We use   to extract the return type. \n \n Parameters   # When do parameters have to be type-annotated?   # Recap: If   is switched on (  switches it on), the type of each parameter must either be inferrable or explicitly specified. In the following example, TypeScript can’t infer the type of   and we must specify it: In line A, TypeScript can use the type   to infer the type of   and we don’t need to add a type annotation: Here, TypeScript can use the type of   to infer the type of  : This is the type of  : Optional parameters   # In this section, we look at several ways in which we can allow parameters to be omitted. # If we put a question mark after the name of a parameter, that parameter becomes optional and can be omitted when calling the function: This is how   can be invoked: # Externally, parameter   of   has the type  . Therefore,   is mostly equivalent to the following function. The only way in which   is different from   is that the parameter can’t be omitted in function calls (line A). In other words: We must be explicit when omitting a parameter whose type is  . # If we specify a parameter default value for  , we don’t need to provide a type annotation because TypeScript can infer the type: Note that the internal type of   is   because the default value ensures that it is never  . Let’s invoke  : # We can also specify both a type and a default value: Rest parameters   # # A rest parameter collects all remaining parameters in an Array. Therefore, its static type is usually an Array. In the following example,   is a rest parameter: # The next example demonstrates two features: \n We can use tuple types such as   for rest parameters. \n We can destructure rest parameters (not just normal parameters). \n  is equivalent to the following function: Named parameters   #  are a popular pattern in JavaScript where an object literal is used to give each parameter a name. That looks as follows: In plain JavaScript, functions can use destructuring to access named parameter values. Alas, in TypeScript, we additionally have to specify a type for the object literal and that leads to redundancies: Note that the destructuring (incl. the default value for  ) all happens in line A, while line B is exclusively about TypeScript. It is possible to define a separate type instead of the inlined object literal type that we have used in line B. However, in most cases, I prefer not to do that because it slightly goes against the nature of parameters which are local and unique per function. If you prefer having less stuff in function heads, then that’s OK, too.  as a parameter   # Each ordinary function always has the implicit parameter   – which enables it to be used as a method in objects. Sometimes we need to specify a type for  . There is TypeScript-only syntax for this use case: One of the parameters of an ordinary function can have the name  . Such a parameter only exists at compile time and disappears at runtime. As an example, consider the following interface for DOM event sources (in a slightly simplified version): The   of the callback   is always an instance of  . The next example demonstrates that TypeScript uses the type information provided by the   parameter to check the first argument of   (line A and line B): Additionally, we can’t invoke   as a method of an object   because then its receiver isn’t an instance of  : Overloading   # Sometimes a single type signature does not adequately describe how a function works. Overloading function declarations   # Consider function   which we are calling in the following example: How would we implement  ? The following implementation works for the two function calls in the previous example: However, with this type signature, function calls are legal at compile time that produce runtime errors: The following code fixes these issues: What is going on here? \n The actual implementation starts in line C. It is the same as in the previous example. \n In line A and line B there are the two type signatures (function heads without bodies) that can be used for   (the type signature of the actual implementation cannot be used). The type signature of   is overloaded. \n My advice is to only use overloading when it can’t be avoided. For example, I’d have preferred to split   into two functions: \n \n \n Overloading via interfaces   # In interfaces, we can have multiple, different call signatures. That enables us to use the interface   for overloading in the following example: Overloading on string parameters (event handling etc.)   # In the next example, we overload and use string literal types (such as  ). That allows us to change the type of parameter   depending on the value of parameter  : In this case, it is relatively difficult to get the types of the implementation (starting in line A) right, so that the statement in the body (line B) works. As a last resort, we can always use the type  . Overloading methods   # # The next example demonstrates overloading of methods: Method   is overloaded. # The type definition for   is an example of an overloaded interface method: \n In the first signature, the return type is the same as the type of  . \n In the second signature, the elements of the returned Array have the same type as the result of  . This version of   is similar to  . \n Assignability   # In this section we look at the type compatibility rules for  : Can functions of type   be transferred to storage locations (variables, object properties, parameters, etc.) of type  ? Understanding assignability helps us answer questions such as: \n Given the function type signature of a formal parameter, which functions can be passed as actual parameters in function calls? \n Given the function type signature of a property, which functions can be assigned to it? \n The rules for assignability   # In this subsection, we examine general rules for assignability (including the rules for functions). In the next subsection, we explore what those rules mean for functions. A type   is  assignable  to a type   if one of the following conditions is true: \n  and   are identical types. \n  or   is the   type. \n  is a string literal type and   is the primitive type String. \n  is a union type and each constituent type of   is assignable to  . \n  and   are function types and:\n \n  has a rest parameter or the number of required parameters of   is less than or equal to the total number of parameters of  . \n For parameters that are present in both signatures, each parameter type in   is assignable to the corresponding parameter type in  . \n The result type of   is   or the result type of   is assignable to the result type of  . \n \n \n (Remaining conditions omitted.) \n Consequences of the rules for functions   # # \n Target parameter types must be assignable to corresponding source parameter types.\n \n Why? Anything that the target accepts must also be accepted by the source. \n \n \n The source result type must be assignable to target result type.\n \n Why? Anything that the source returns must be compatible with the expectations set by the target. \n \n \n Example: The following example demonstrates that if the target result type is  , then the source result type doesn’t matter. Why is that?   results are always ignored in TypeScript. # The source must not have more parameters than target: The source can have fewer parameters than the target: Why is that? The target specifies the expectations for the source: It must accept the parameter  . Which it does (but it ignores it). This permissiveness enables: The callback for   only has one of the three parameters that are mentioned in the type signature of  : Further reading and sources of this blog post   # \n TypeScript Handbook \n TypeScript Language Specification \n Chapter “Callable values”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/two-useful-gimp-features.html", "title": "Two useful Gimp features", "content": "Two useful Gimp features hack web design app computers gimp Gimp \n Remove empty space around an image: There are two ways to do this. \n \n With the possibility of manual adjustment: Go to the “Rectangle select tool”, select something, click on “Auto Shrink” in the toolbar. Next invoke “Crop to Selection” in the “Image” menu. \n Automatic: Invoke “Autocrop Image” in the “Image” menu. \n \n Finding out the best compression ratio: If you save a lossless image format such as PNG to a more compact format such as JPG, you can get a live preview of how the compression affects image quality. Very useful for trying out different settings. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/faking-bookmark-separators-in-chrome.html", "title": "Faking bookmark separators in Chrome", "content": "Faking bookmark separators in Chrome hack computers chrome \n\nThe  favicon  in this file is provided via a  data URI . You can get more Chrome favicons (including vertical ones for the bookmarks bar) at  favicon.cc .\n comments powered by Disqus."},
{"url": "https://2ality.com/2020/02/typing-arrays-typescript.html", "title": "Typing Arrays in TypeScript", "content": "Typing Arrays in TypeScript dev javascript typescript In this blog post, we examine how Arrays can be typed in TypeScript. \n   \n     Roles of Arrays \n   \n   \n     Ways of typing Arrays \n     \n       \n         Array role “list”: array type literals vs. interface type  \n       \n       \n         Array role “tuple”: tuple type literals \n       \n       \n         Objects that are also Array-ish: interfaces with index signatures \n       \n     \n   \n   \n     Pitfall: type inference doesn’t always get Array types right \n     \n       \n         Inferring types of Arrays is difficult \n       \n       \n         Type inference for non-empty Array literals \n       \n       \n         Type inference for empty Array literals \n       \n       \n          assertions for Arrays and type inference \n       \n     \n   \n Roles of Arrays   # Arrays are used in the following two roles in JavaScript (and sometimes a mix of the two): \n Lists: All elements have the same type. The length of the Array varies. \n Tuple: The length of the Array is fixed. The elements do not necessarily have the same type. \n TypeScript accommodates these two roles by offering various ways of typing arrays. We will look at those next. Ways of typing Arrays   # Array role “list”: array type literals vs. interface type     # An Array type literal consists of the element type followed by  . In the following code, the Array type literal is  : An Array type literal is a shorthand for using the global generic interface type  : If the element type is more complicated, then you need to put them in parentheses: In this case, I prefer  : Both array type literals and   require all elements to have the same type. That’s how we know that they are for Arrays-as-lists. Array role “tuple”: tuple type literals   # If the Array has a fixed length and each element has a different, fixed type that depends on its position, then we can use tuple type literals such as  : Objects that are also Array-ish: interfaces with index signatures   # If an interface has only an index signature, we can use it for Arrays: An interface that has both an index signature and property signatures, only works for objects (because indexed elements and properties need to be defined at the same time): Pitfall: type inference doesn’t always get Array types right   # Inferring types of Arrays is difficult   # Due to the two roles of Arrays, it is impossible for TypeScript to always guess the right type. As an example, consider the following Array literal that is assigned to the variable  : What is the best type for  ? The following are all reasonable options: Type inference for non-empty Array literals   # When we use non-empty Array literals, TypeScript’s default is to infer list types (not tuple types): Alas, that’s not always what we want: The inferred type for   should be a tuple type. It isn’t and that’s why its results don’t match the type parameter   of   in the last line. We can fix this by specifying the return type of   explicitly (instead of relying on type inference): We also could have used   instead of   for the result of  . Type inference for empty Array literals   # If we initialize a variable via an empty Array literal, then TypeScript initially infers the type   and incrementally updates that type as we make changes: Note that the initial inferred type isn’t influenced by what happens later. If we use assignment instead of  , things work the same: In contrast, if the Array literal has at least one element, then the element type is fixed and doesn’t change later:  assertions for Arrays and type inference   # We can suffix an Array literal with  a   assertion : We are declaring that   won’t change – which has the following effects: \n \n The Array becomes  : We can’t use operations that change it: \n \n \n \n TypeScript infers a tuple. Compare: \n \n \n \n TypeScript infers literal types (  etc.) instead of more general types. That is, the inferred tuple type is not  . \n \n Here are two more examples of   assertions: comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/coffeescript-versus-javascript-without.html", "title": "CoffeeScript versus paren-free JavaScript", "content": "CoffeeScript versus paren-free JavaScript esnext dev javascript coffeescript CoffeeScript A word about conciseness CoffeeScript CoffeeScript \nThe above example shows that there is no   in CoffeeScript and variables are automatically declared. But having to declare variables is one of JavaScript’s best features, because it catches typos. As an aside,   will soon be improved as the block-scoped  .\n details \n\t Array slicing and splicing \n\t Everything is an expression (especially if statements) – man do I miss this from functional languages \n\t Classes, inheritance, super calls. \n\t Destructuring assignment. Yes, as seen in Python, functional languages, etc. \n\t Extended regular expressions (with whitespace and comments) – absolutely needed \n\t And more (some of it adds unnecessary clutter and differences with JavaScript) \n Paren-free JavaScript proposed \n     \n        Mandatory blocks: paren-free syntax makes blocks (as opposed to single statements) mandatory. Quote:\n         dangling else \n        This is a good call. It will lead to cleaner and more uniform JavaScript code.\n     \n     Migration: Eich suggests to make for-in syntax with parens an error. Then migrating to the new syntax incurs initial costs. But it also lets one detect incompatible code early on and makes the overall semantics simpler (than if compatibility was preserved). \n Brendan Eich’s dream for the next version of JavaScript ECMAScript.next features are taking shape Google’s Traceur: compile ECMAScript.next to JavaScript on the fly comments powered by Disqus."},
{"url": "https://2ality.com/2020/03/class-definitions-typescript.html", "title": "Class definitions in TypeScript", "content": "Class definitions in TypeScript dev javascript typescript In this blog post, we examine how class definitions work in TypeScript: \n First, we take a quick look at the features of class definitions in plain JavaScript. \n Then we explore what additions TypeScript brings to the table. \n \n   \n     Cheat sheet: classes in plain JavaScript \n     \n       \n         Basic members of classes \n       \n       \n         Modifier:  \n       \n       \n         Modifier:   (private) \n       \n       \n         Modifiers for accessors:   (getter) and   (setter) \n       \n       \n         Modifier for methods:   (generator) \n       \n       \n         Modifier for methods:  \n       \n       \n         Computed class member names \n       \n       \n         Combinations of modifiers \n       \n       \n         Under the hood \n       \n       \n         More information \n       \n     \n   \n   \n     Non-public data slots in TypeScript \n     \n       \n         Private properties \n       \n       \n         Private fields \n       \n       \n         Private properties vs. private fields \n       \n       \n         Protected properties \n       \n     \n   \n   \n     Private constructors \n   \n   \n     Initializing instance properties \n     \n       \n         Strict property initialization \n       \n       \n         Making constructor parameters  ,  , or  \n       \n     \n   \n   \n     Abstract classes \n   \n Cheat sheet: classes in plain JavaScript   # This section is a cheat sheet for class definitions in plain JavaScript. Basic members of classes   # Modifier:     # Modifier:   (private)   # Warning: \n Support for private methods is currently quite limited. \n Private fields have broader, but also limited, support. \n Modifiers for accessors:   (getter) and   (setter)   # There are two kinds of accessors: getters and setters. Modifier for methods:   (generator)   # Modifier for methods:     # Computed class member names   # Comments: \n The main use case for this feature is symbols such as  . But any expression can be used inside the square brackets. \n We can compute the names of fields, methods, and accessors. \n We cannot compute the names of private members (which are always fixed). \n Combinations of modifiers   # Fields: Methods: Limitations of methods: \n Accessors can’t be async or generators. \n Under the hood   # It’s important to keep in mind that with classes, there are two chains of prototype objects: \n The instance chain which starts with an instance. \n The static chain which starts with the class of that instance. \n Consider the following JavaScript (not TypeScript!) example: The two prototype chains look as follows: More information   # \n Chapter “Classes”  in “JavaScript for impatient programmers” \n Non-public data slots in TypeScript   # By default, all data slots in TypeScript are public properties. There are two ways of keeping data private: \n Private properties \n Private fields \n We’ll look at both next. Note that TypeScript does not currently support private methods. Private properties   # Any property can be made private by prefixing it with the keyword   (line A): We now get compile-time errors if we access that property in the wrong scope (line A): However,   doesn’t change anything at runtime. There, the property   is indistinguishable from a public property: We can also see that private properties aren’t protected at runtime when we look at the JavaScript code that the class is compiled to: Private fields   # Since version 3.8, TypeScript also supports private fields: That code is mostly used the same way as the other version: However, this time, the data is completely safe. Using the private field syntax outside classes is even a JavaScript syntax error (which is why we have to use   in line A, so that the code runs): The compilation result is much more complicated now: This code uses a common technique for keeping instance data private: \n Each WeakMap implements one private field. \n It associates instances with private data. \n For more information on this technique, see  “JavaScript for impatient programmers” . Private properties vs. private fields   # \n Downsides of private properties:\n \n We can’t reuse the names of private properties in subclasses (because the properties aren’t private at runtime). \n No protection at runtime. \n \n \n Upside of private properties:\n \n Clients can circumvent the protection and access private properties. This can be useful if someone needs to work around a bug. In other words: Being completely protected has pros and cons. \n \n \n Protected properties   # Private properties can’t be accessed in subclasses (line A): We can fix the previous example by switching from   to   in line A (we also switch in line B, for consistency’s sake): Private constructors   # We can also make constructors private. That is useful when we have static factory methods and want clients to always use those methods, never the constructor directly. Static methods can access private instance members, which is why the factory methods can still use the constructor. In the following code, there is one static factory method  . It sets up instances via asynchronously loaded data. Keeping the asynchronous code in the factory method enables the actual class to be completely synchronous: In real-world code, we would use   or a similar Promise-based API to load data asynchronously in line A. Right now, the private constructor prevents   from being subclassed. If we want to allow subclasses, we can use  . Initializing instance properties   # Strict property initialization   # If the compiler setting   is switched on (which is the case if we use  ), then TypeScript checks if all declared instance properties are correctly initialized: \n \n Either via assignments in the constructor: \n \n \n \n Or via initializers for the property declarations: \n \n \n However, sometimes we initialize properties in a manner that TypeScript doesn’t recognize. Then we can use exclamation marks ( ) to switch off TypeScript’s warnings (line A and line B): # In the following example, we also need definite assignment assertions. Here, we set up instance properties via the constructor parameter  : Notes: \n In line B, we initialize all properties: We use   to copy the properties of parameter   into  . \n In line A, the   ensures that the class declares all properties that are part of interface  . \n Making constructor parameters  ,  , or     # If we use the keyword   for a constructor parameter, then TypeScript does two things for us: \n It declares a public instance property with the same name. \n It assigns the parameter to that instance property. \n Therefore, the following two classes are equivalent: If we use   or   instead of  , then the corresponding instance properties are private or protected (not public). Abstract classes   # Two constructs can be abstract in TypeScript: \n An abstract class can’t be instantiated. Only its subclasses can – if they are not abstract, themselves. \n An abstract method has no implementation, only a type signature. Each concrete subclass must have a concrete method with the same name and type signature as that abstract method.\n \n If a class has any abstract methods, it must be abstract, too. \n \n \n The following code demonstrates abstract classes and methods. On one hand, there is the abstract superclass   and its helper class  : On the other hand, there are the concrete subclasses   and  : And finally, this is us using   and  : Notes about abstract classes: \n They can be seen as interfaces with bundled implementations. \n However, a class can only extend one abstract superclass but implement multiple interfaces. \n “Abstractness” only exists at compile time. At runtime, abstract classes are normal classes and abstract methods don’t exist (due to them only providing compile-time information). \n Abstract classes can be seen as templates where each abstract method is a blank that has to be filled in (implemented) by subclasses. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/04/typescript-workflows.html", "title": "How does TypeScript work? The bird’s eye view", "content": "How does TypeScript work? The bird’s eye view dev javascript typescript This blog post gives the bird’s eye view of how TypeScript works: What is the structure of a typical TypeScript project? What is compiled and how? How can we use IDEs to write TypeScript? This post is meant to be read before learning how to write TypeScript code (material for doing that is listed  at the end ). \n   \n     The structure of TypeScript projects \n     \n       \n         \n       \n     \n   \n   \n     Programming TypeScript via an integrated development environment (IDE) \n   \n   \n     Other files produced by the TypeScript compiler \n     \n       \n         In order to use npm packages from TypeScript, we need type information \n       \n     \n   \n   \n     Using the TypeScript compiler for plain JavaScript files \n   \n   \n     What to read next \n   \n The structure of TypeScript projects   # This is one possible file structure for TypeScript projects: Explanations: \n Directory   contains the TypeScript files:\n \n Subdirectory   contains the actual code. \n Subdirectory   contains tests for the code. \n \n \n Directory   is where the output of the compiler is stored. \n The TypeScript compiler compiles a TypeScript file such as   to a JavaScript file   (and possibly other files). \n  is used to configure the TypeScript compiler. \n    # The contents of   look as follows: We have specified that: \n The root directory of the TypeScript code is  . \n The directory where the TypeScript compiler saves its output is  . \n The module format of the output files is CommonJS. \n Programming TypeScript via an integrated development environment (IDE)   #  is one of the most popular IDEs for writing TypeScript code. In order to use it well, we need to understand that TypeScript source code is processed in two independent ways: \n \n Checking open editors for errors: This is done via a so-called  . They are an editor-independent way of providing editors with language-related services (detecting errors, refactorings, auto-completions, etc.). Editors (such as IDEs) communicate with language servers via a special protocol (JSON-RPC, i.e. JSON-based remote procedure calls). That enables one to write such servers in almost any programming language. \n \n Important fact to remember: The language server only lists errors for currently open editors and it doesn’t compile TypeScript, it only analyzes it statically. \n \n \n \n  (compiling TypeScript files to JavaScript files): Here, we have two choices. \n \n We can run a build tool via a command line. For example, the TypeScript compiler   has a   mode that watches input files and compiles them to output files whenever they change. As a consequence, whenever we save a TypeScript file in the IDE, we immediately get the corresponding output file(s). \n We can run   from within Visual Studio Code. In order to do so, it must be installed either inside project that we are currently working on or globally (via the Node.js package manager npm). \n \n With building, we get a complete list of errors. For more information on compiling TypeScript in Visual Studio Code, see  the official documentation for that IDE . \n \n Other files produced by the TypeScript compiler   # Given a TypeScript file  , the TypeScript compiler can produce several kinds of artifacts. The most common ones are: \n JavaScript file:  \n Declaration file:   (contains type information; think   file minus the JavaScript code) \n Source map file:  \n TypeScript is often not delivered via   files, but via   files and   files: \n The JavaScript code contains the actual functionality and can be consumed via plain JavaScript. \n The declaration files help programming editors with auto-completion and similar services. This information enables plain JavaScript to be used via TypeScript. However, we even profit from it if we work with plain JavaScript because it gives us better auto-completion and more. \n A source map specifies for each part of the output code in  , which part of the input code in   produced it. Among other things, this information enables runtime environments to execute JavaScript code, while showing the line numbers of the TypeScript code in error messages. In order to use npm packages from TypeScript, we need type information   # The npm registry is a huge repository of JavaScript code. If we want to use a JavaScript package from TypeScript, we need type information for it: \n The package itself may include   files or even the complete TypeScript code. \n If it doesn’t, we may still be able to use it:  DefinitelyTyped  is a repository of declaration files that people have written for plain JavaScript packages. \n The declaration files of DefinitelyTyped reside in the   namespace. Therefore, if we need a declaration file for a package such as  , we have to install the package  . Using the TypeScript compiler for plain JavaScript files   # The TypeScript compiler can also process plain JavaScript files: \n \n With the option  , the TypeScript compiler copies JavaScript files in the input directory over to the output directory. Benefit: When  migrating from JavaScript to TypeScript  we can start with a mix of JavaScript and TypeScript files and slowly convert more JavaScript files to TypeScript. \n \n \n With the option  , the compiler additionally type-checks JavaScript files (  must be on for this option to work). It does so as well as it can, given the limited information that is available. \n \n If a JavaScript file contains the comment  , it will not be type-checked. \n Without  , the comment   can be used to type-check individual JavaScript files. \n \n \n \n The TypeScript compiler uses static type information that is specified via JSDoc comments (see below for an example). If we are thorough, we can fully statically type plain JavaScript files and even derive declaration files from them. \n \n \n With the option  , the compiler does not produce any output, it only type-checks files. \n \n This is an example of a JSDoc comment that provides static type information for a function  : More information:  Type-Checking JavaScript Files  in the TypeScript Handbook. What to read next   # \n “Understanding TypeScript’s type notation” \n “Creating CommonJS-based npm packages via TypeScript” \n “Strategies for migrating to TypeScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/04/migrating-to-typescript.html", "title": "Strategies for migrating to TypeScript", "content": "Strategies for migrating to TypeScript dev javascript typescript This blog post gives an overview of strategies for migrating code bases from JavaScript to TypeScript. It also mentions material for further reading. \n   \n     Three strategies for migrating \n   \n   \n     Strategy: mixed JavaScript/TypeScript code bases \n   \n   \n     Strategy: adding type information to plain JavaScript files \n   \n   \n     Strategy: migrating large projects by snapshot testing the TypeScript errors \n   \n   \n     Conclusion \n   \n Three strategies for migrating   # These are three strategies for migrating to TypeScript: \n \n We can support a mix of JavaScript and TypeScript files for our code base. We start with only JavaScript files and then switch more and more files to TypeScript. \n \n \n We can continue to use plain JavaScript and add type information via JSDoc comments until everything if fully typed. At that point, we switch to TypeScript. \n \n \n For large projects, there may be too many TypeScript errors during migration. Then snapshot tests for the errors can help. \n \n \n “Migrating from JavaScript”  in the TypeScript Handbook \n Strategy: mixed JavaScript/TypeScript code bases   # The TypeScript compiler supports a mix of JavaScript and TypeScript files if we use the compiler option  : \n TypeScript files are compiled. \n JavaScript files are simply copied over to the output directory (after a few simple type checks). \n At first, there are only JavaScript files. Then, one by one, we switch files to TypeScript. While we do so, our code base keeps being compiled. This is what   looks like: \n “Incrementally Migrating JavaScript to TypeScript”  by  Clay Allsopp . \n Strategy: adding type information to plain JavaScript files   # This approach works as follows: \n We continue to use our current build infrastructure. \n We run the TypeScript compiler, but only as a type checker (compiler option  ). \n We add type information via JSDoc comments (see example below) and type definition files. \n Once TypeScript’s type checker doesn’t complain anymore, we use the compiler to build the code base (similar to the previous strategy). Switching from   files to   files is not urgent now because the whole code base is already fully statically typed. We can even produce type files (filename extension  ) now. \n This is how we specify static types for plain JavaScript via JSDoc comments: \n \n “Type-Checking JavaScript Files”  in the TypeScript Handbook \n \n \n “How we gradually migrated to TypeScript at Unsplash”  by  Oliver Joseph Ash \n \n Strategy: migrating large projects by snapshot testing the TypeScript errors   # In large JavaScript projects, switching to TypeScript may produce too many errors – no matter which approach we choose. Then snapshot-testing the TypeScript errors may be an option: \n We run the compiler on the whole code base for the first time. \n The errors produced by the TypeScript compiler become our initial snapshot. \n As we work on the code base, we compare new error output with the previous snapshot: Sometimes errors disappear. Then we can create a new snapshot. Sometimes new errors appear. Then we either have to fix these errors (if we can) or create a new snapshot. \n \n “How to Incrementally Migrate 100k Lines of Code to Typescript”  by  Dylan Vann \n Conclusion   # We have taken a quick look at various strategies for migrating to TypeScript. Two more tips: \n Start your migration with experiments: Play with your code base and try out various approaches before committing to one of them. \n Then lay out a clear plan for going forward. Talk to your team w.r.t. prioritization:\n \n Sometimes finishing the migration quickly may take priority. \n Sometimes the code remaining fully functional during the migration may take priority. \n And so on... \n \n \n What have your experiences been when you migrated code bases from JavaScript to TypeScript? Let us know in the comments! comments powered by Disqus."},
{"url": "https://2ality.com/2020/04/npm-cjs-typescript.html", "title": "Creating CommonJS-based npm packages via TypeScript", "content": "Creating CommonJS-based npm packages via TypeScript dev javascript typescript This blog post describes how to use TypeScript to create npm packages with CommonJS modules. All the artifacts that are shown can be downloaded via  the GitHub repository   (I deliberately have not published it to npm).  You should be familiar with how npm packages work. \n   \n     Limitations \n   \n   \n     The repository  \n   \n   \n     \n   \n   \n     \n   \n   \n     \n     \n       \n         Scripts \n       \n       \n         More information \n       \n       \n          vs.  \n       \n     \n   \n   \n     \n   \n   \n     TypeScript code \n     \n       \n         \n       \n       \n         \n       \n     \n   \n Limitations   # We are using what TypeScript currently supports best: \n All TypeScript code is compiled to CommonJS modules with the filename extension  . \n We only import CommonJS modules. \n Especially on Node.js, TypeScript currently doesn’t really support ECMAScript modules and filename extensions other than  . The repository     # This is how the repository   is structured: Apart from the  for the package, the repository contains: \n : the actual code of the package \n : a test for  \n : configuration data for the TypeScript compiler \n  contains scripts for compiling: \n Source: directory   (TypeScript code) \n Target: directory   (CommonJS modules; the directory doesn’t yet exist in the repository) \n This is where the compilation results for the two TypeScript files are put:    # This file lists the directories that we don’t want to check into git: Explanations: \n  is set up via  . \n The files in   are created by the TypeScript compiler (more on that later). \n    # When it comes to which files should and should not be uploaded to the npm registry, we have different needs than we did for git. Therefore, in addition to  , we also need the file  : The two differences are: \n We want to upload the results of compiling TypeScript to JavaScript (directory  ). \n We don’t want to upload the TypeScript source files (directory  ). \n Note that npm ignores the directory   by default.    #  looks like this: Let’s take a look at the properties: \n : The value   means that   files are interpreted as CommonJS modules. \n : When using a bare import with just the name of the package, this is the module that will be imported. \n  points to the bundled type declaration file. \n The next two subsections cover the remaining properties. Scripts   # Property   defines various commands for building that can be invoked via   (etc.): \n : Use  the cross-platform package   to delete the compilation results.   provides a variety of shell commands with the benefit of not needing a separate package for each command we may want to use. \n ,  : Use the TypeScript compiler   to compile the TypeScript files according to  .   must be installed globally or locally (then package   would be a dev dependency). \n ,  : Use  the unit test framework Mocha  to run one test or all tests. \n : This script is run run before a tarball is packed (due to  ,  , and when installing dependencies from git). \n Note that when we are using an IDE, we don’t need the scripts   and   because we can let the IDE build the artifacts. But they are needed for the script  . More information   # \n “Awesome npm scripts”  has tips for writing cross-platform scripts. \n The npm docs for   explain various properties of that file. \n The npm docs for   explain the   property  . \n  vs.     #  should only contain the packages that are needed when importing a package. That excludes packages that are needed for running tests etc. Packages whose names start with   provide TypeScript type definitions (which enable auto-completion even for JavaScript) for packages that don’t include them. Are these normal dependencies or dev dependencies? It depends: \n \n If the type definitions of our package refer to type definitions in another package, that package is a normal dependency. \n \n \n Otherwise, the package is only needed during development time and a dev dependency. \n \n    # \n : Where are our TypeScript files located? \n : Where should the compilation results be put? \n : What is the targeted ECMAScript version? Features that the targeted version does not support will be compiled to features that it does support. Therefore, if we target ES3, many features with be compiled. \n : What platform features should TypeScript be aware of? Possibilities includes the ECMAScript standard library and the DOM of browsers. The Node.js API is supported differently, via the package  . \n : Specifies the format of the compilation output. \n The remaining options are explained by  the official documentation for  . TypeScript code   #    # This file provides the actual functionality of the package: It uses  function   of the library Lodash . That’s why Lodash is a normal dependency – it is needed at runtime.    # This file contains a unit test for  : We can run the test like this: \n The npm command   is an abbreviation for the npm command  . \n  is an abbreviation for   (which runs that script from  ). \n As you can see, we are running the compiled version of the test (in directory  ), not the TypeScript code. For more information on the unit test framework Mocha, see  its homepage . comments powered by Disqus."},
{"url": "https://2ality.com/2020/04/classes-as-values-typescript.html", "title": "Types for classes as values in TypeScript", "content": "Types for classes as values in TypeScript dev javascript typescript chapter “Types for classes as values” In this blog post, we explore classes as values: \n What types should we use for such values? \n What are the use cases for these types? \n \n   \n     Types for specific classes \n     \n       \n         The type operator  \n       \n       \n         Constructor type literals \n       \n       \n         Object type literals with construct signatures \n       \n     \n   \n   \n     A generic type for classes:  \n     \n       \n         Example: creating instances \n       \n       \n         Example: casting with runtime checks \n       \n       \n         Example: Maps that are type-safe at runtime \n       \n       \n         Pitfall:   does not match abstract classes \n       \n     \n   \n Types for specific classes   # Consider the following class: This function accepts a class and creates an instance of it: What type should we use for the parameter   if we want it to be   or a subclass? The type operator       # TypeScript clearly separates two kinds of syntax: \n Runtime (dynamic): plain JavaScript\n \n Statements become code and may produce values as side effects (e.g. function declarations). \n Expressions become values. \n \n \n Compile time (static): TypeScript\n \n Type expression become types. \n \n \n The class   creates two things: \n The constructor function  \n The interface   for instances of  \n Depending on where we mention  , it therefore means different things. That’s why we can’t use the type   for   – it matches   of class  , not class   itself. We can fix this via the type operator   (another bit of static syntax that also exists dynamically).   stands for the type of the dynamic(!) value  . Constructor type literals   # A   is a function type literal with a prefixed  . The prefix indicates that   is a function that must be invoked via  . Object type literals with construct signatures   # Recall that  members of interfaces and object literal types (OLTs)  include method signatures and call signatures. Call signatures enable interfaces and OLTs to describe functions. Similarly,   enable interfaces and OLTs to describe constructor functions. They look like call signatures with the added prefix  . In the next example,   has an object literal type with a construct signature: A generic type for classes:     # With the knowledge we have acquired, we can now create a generic type for classes as values – by introducing a type parameter  : Instead of a type alias, we can also use an interface: Example: creating instances   #  enables us to implement the   operator:  is used as follows: Example: casting with runtime checks   # With  , we can change the type of a value to something more specific. This is also safe at runtime, because we both statically change the type and perform a dynamic check. The following code provides an example: Example: Maps that are type-safe at runtime   # One use case for   and   are type-safe Maps: The key of each entry in a   is a class. That class determines the static type of the entry’s value and is also used for checks at runtime. This is   in action: Pitfall:   does not match abstract classes   # We cannot use abstract classes when   is expected: Why is that? The rationale is that constructor type literals and construct signatures should only be used for values that can actually be  -invoked ( GitHub issue with more information ). We can fix this as follows: Downsides of this approach: \n Slightly confusing. \n Does not work for   checks. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/04/webpack-typescript.html", "title": "Creating web apps via TypeScript and webpack", "content": "Creating web apps via TypeScript and webpack dev javascript typescript This blog post describes how to create web apps via TypeScript and webpack. We will only be using the DOM API, not a particular frontend framework. The repository   with the files can be downloaded from GitHub.  It helps if you have a rough understanding of how TypeScript, webpack, and npm work. \n   \n     Limitations \n   \n   \n     The repository  \n     \n       \n         Installing, building and running the web app \n       \n       \n         Building in Visual Studio Code \n       \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     \n   \n   \n     Using webpack without a loader:  \n   \n Limitations   # Using ES modules via TypeScript and npm is still fragile. Therefore, we will stick with CommonJS modules, bundled as script files. The repository     # This is how the repository   is structured: In order to build the web app, we need to compile two sets of files into the directory  : \n TypeScript files are stored in  . \n HTML files are stored in  . \n Both tasks are handled by webpack: \n \n For TypeScript, webpack starts at  , locates all TypeScript and JavaScript files that are used, and compiles them into the single script file  . This process is called  . For compiling TypeScript to JavaScript, webpack uses the   (plugin)  . \n \n \n Copying the files in   is done via the webpack    . \n \n Installing, building and running the web app   # First we need to install all npm packages that our web app depends on: Then we need to run webpack (which was also installed by the previous step) via a script in  : From now on, webpack watches the files in the repository for changes and rebuilds the web app whenever it detects any. In a different command line, we can now start a web server that serves the contents of   on localhost: If we go to the URL printed out by the web server, we can see the web app in action. Note that simple reloading may not be enough to see the results after changes – due to caching. You may have to force-reload by pressing shift when reloading. Building in Visual Studio Code   # Instead of building from a command line, we can also do that from within Visual Studio Code, via a so-called  : \n Execute “Configure Default Build Task...” from the “Terminal” menu. \n Choose “npm: wpw”. \n Optional – set up the proper problem matcher in  : \n \n We can now execute “Run Build Task...” from the “Terminal” menu.    #  specifies our scripts and the npm packages that the project depends on: \n  means that npm doesn’t complain if we don’t provide a package name and a package version. \n Scripts:\n \n : We probably won’t invoke the TypeScript compiler   directly if we use webpack with  . \n : run webpack once, compile everything. \n : webpack watches the files and only compiles what changes, incrementally. \n : run the server   and serve the contents of directory  . \n \n \n Dependencies:\n \n Webpack incl. support for using it via a CLI (command line interface) and plugins:  ,  ,  ,  \n Needed by  :  \n Webserver for the web app:  \n Library plus type definitions that the TypeScript code uses:  ,  \n \n \n    # This is how we configure webpack: For more information on configuring webpack, see  the webpack website .    # This file configures the TypeScript compiler: The option   is not needed if we use webpack with  . However, we’ll need it if we use webpack without a loader (as explained later in this post).    # This is the HTML page of the web app: The   with the id   is where the web app displays its output.   contains the bundled code.    # This is the TypeScript code of the web app: For more information on  , see  Lodash’s documentation . Using webpack without a loader:     # Instead of depending on  , we can also first compile all TypeScript files to JavaScript files (via the TypeScript compiler) and then bundle those files via webpack. More information on how that works is provided in  the blog post “Creating CommonJS-based npm packages via TypeScript” . We now don’t have to configure   and our webpack configuration file is simpler: Why would we want to produce intermediate files before bundling them? One benefit is that we can use Node.js to run unit tests for some of the TypeScript code. comments powered by Disqus."},
{"url": "https://2ality.com/2020/05/records-tuples-first-look.html", "title": "A first look at records and tuples in JavaScript", "content": "A first look at records and tuples in JavaScript dev javascript es proposal In this blog post, we take a first look at the ECMAScript proposal  “Record & Tuple”  (by Robin Ricard and Rick Button). This proposal adds two kinds of compound primitive values to JavaScript: \n Records, immutable compared-by-value versions of plain objects \n Tuples, immutable compared-by-value versions of Arrays \n \n   \n     Comparing by value \n     \n       \n         Records and tuples are primitives \n       \n       \n         Restrictions of what can be inside records and tuples \n       \n       \n         Converting objects to records and tuples \n       \n       \n         Converting records and tuples to objects \n       \n       \n         Working with records \n       \n       \n         Working with tuples \n       \n       \n         Why are values that are compared by value immutable in JavaScript? \n       \n       \n         Benefits of compound primitives \n       \n     \n   \n   \n     Examples: Sets and Maps become more useful \n     \n       \n         Eliminating duplicates via Sets \n       \n       \n         Compound keys in Maps \n       \n     \n   \n   \n     Examples: efficient deep equals \n     \n       \n         Processing objects with compound property values \n       \n       \n         Has an object changed? \n       \n       \n         Testing \n       \n     \n   \n   \n     The pros and cons of the new syntax \n   \n   \n     JSON and records and tuples \n   \n   \n     Future: classes whose instances are compared by value? \n   \n   \n     Acknowledgements \n   \n   \n     Further reading \n   \n Comparing by value   # At the moment, JavaScript only compares primitive values such as strings   (by looking at their contents): In contrast, objects are compared   (each object has a unique identity and is only strictly equal to itself): The proposal  Record & Tuple  (by Robin Ricard and Rick Button) lets us create compound values that are compared by value. For, example, by prefixing an object literal with a number sign ( ), we create a   – a compound value that is compared by value and immutable: If we prefix an Array literal with  , we create a   – an Array that is compared by value and immutable: Compound values that are compared by value are called   or  . Records and tuples are primitives   # We can see that records and tuples are primitives when we use  : Restrictions of what can be inside records and tuples   # \n Records:\n \n Keys must be strings. \n Values must be primitives (including records and tuples). \n \n \n Tuples.\n \n Elements must be primitives (including records and tuples). \n \n \n Converting objects to records and tuples   # Caveat: These conversions are shallow. If any of the nodes in a tree of values is not primitive, then   and   will throw an exception. Converting records and tuples to objects   # Caveat: These conversions are shallow. Working with records   # Working with tuples   # Why are values that are compared by value immutable in JavaScript?   # Some data structures such as hash maps and search trees have slots in which keys are placed according to their values. If the value of key changes, it generally has to be put in a different slot. That’s why, in JavaScript, values that can be used as keys, are either: \n Compared by value and immutable (primitives) \n Compared by identity and potentially mutable (objects) \n Benefits of compound primitives   # Compound primitives help with: \n \n Deeply comparing objects – which is a built-in operation and can be invoked, e.g., via  . \n \n \n Sharing values: If an object is mutable, we need to deeply copy it if we want to share it safely. With immutable values, sharing is not a problem. \n \n \n Non-destructive updates of data: We can safely reuse parts of a compound value when we create a modified copy of it (due to everything being immutable). \n \n \n Using data structures such as Maps and Sets: They become more powerful because two compound primitives with the same content are considered strictly equal everywhere in the language (including keys of Maps and elements of Sets). \n \n The next sections demonstrate these benefits. Examples: Sets and Maps become more useful   # Eliminating duplicates via Sets   # With compound primitives, we can eliminate duplicates even though they are compound (and not atomic, like primitive values): This does not work with Arrays: Compound keys in Maps   # As objects are compared by identity, it rarely makes sense to use them as keys in (non-weak) Maps: This is different if we use compound primitives: The Map in line A maps addresses (Records) to names. Examples: efficient deep equals   # Processing objects with compound property values   # In the following example, we use the Array method   (line B) to extract all entries whose address is equal to   (line A). Has an object changed?   # Whenever we work with cached data (such   in the following example), the built-in deep equality lets us check efficiently if anything has changed. Testing   # Most testing frameworks support deep equality to check if a computation produces the expected result. For example, the built-in Node.js module   has the function  . With compound primitives, we have an alternative to such functionality: Note: Given that built-in equality checks do more than just compare values, it is more likely that they will support compound primitives and be more efficient for them (vs. the checks becoming obsolete). The pros and cons of the new syntax   # One downside of the new syntax is that the character   is already used elsewhere (for private fields) and that non-alphanumeric characters are always slightly cryptic. We can see that here: The upside is that this syntax is concise. That’s important if a construct is used often and we want to avoid verbosity. Additionally, crypticness is much less of an issue because we get used to the syntax. Instead of special literal syntax, we could have used factory functions: This syntax could be improved if JavaScript supported  Tagged Collection Literals  (a proposal by Kat Marchán that she has withdrawn): Alas, even if we use shorter names, the result is still visually cluttered: JSON and records and tuples   # \n  treats records like objects and tuples like Arrays (recursively). \n  works like   but returns records instead of objects and tuples instead of Arrays (recursively). \n Future: classes whose instances are compared by value?   # Instead of plain objects or Arrays, I like to use classes that are often just data containers because they attach names to objects. For that reason, I’m hoping that we’ll eventually get classes whose instances are immutable and compared by value. It’d be great if we also had support for deeply and non-destructively updating data that contains objects produced by value type classes. Acknowledgements   # \n Thanks to Daniel Ehrenberg and Rob Palmer for reviewing this blog post. \n Among others, the following people replied to  a tweet of mine  and contributed to this blog post:  @asp_net ,  @bomret ,  @imchriskitchens ,  @jamiedixon ,  @mattxcurtis ,  @orangecms . \n Further reading   # \n Chapter “The problems of shared mutable state and how to avoid them”  in “Deep JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/brendan-eichs-dream-for-next-version-of.html", "title": "Brendan Eich’s dream for the next version of JavaScript", "content": "Brendan Eich’s dream for the next version of JavaScript esnext dev javascript Harmony outlines \n \n  \n \n  as block-scoped  . A variable declaration with   is always handled as if it had been made at the beginning of a function, even if it is inside a for loop or an if statement. That will change with   and remove a frequent source of errors. \n  for constant variable declarations \n Compact function syntax:   becomes   (including an implicit return) \n  is replaced by rest parameters and default arguments (see below). \n Records: read-only objects (no Object.freeze()).  \n Tuples: read-only arrays with slicing and negative indices that access elements at the end.  \n Paren-free syntax for  . \n Modules: The  simple modules  proposal will probably make it into Harmony. \n Iteration: Lots of cool stuff, inspired by Python.\n \n Rest parameters:  \n Default parameter values:  \n Spread: the opposite of rest parameters.  \n Destructuring assignments for arrays and objects. The latter takes some getting used to, the variables one assigns to must have the same names as the object keys.\n \n \n Self -style  full prototypal inheritance  (  much different from how JS is now). \n\t Handle   like Lua:   should be syntactic sugar for   (where   is the function stored in  ). \n Python-style keyword arguments (but I do agree with a comment made by Eich that destructuring makes them less urgent). \n Turn “class methods” such as   into instance methods: Instead of  , I’d like to use  . \n  statement: I would make braces mandatory and introduce an   keyword (could also be named  ) \n Implicit returns: It would be nice if the same could be done for if-then-else (i.e., it becomes an expression). No more ternary if operator! \n I’ve  critiqued  CoffeeScript’s syntax and compared it to JS without parens. \n \n      Dion Almaer has posted a response to Eich’s post: “ JavaScript Harmony: The JS Train Is Moving ” \n      The  Harmony wiki  contains lots of interesting stuff, mainly under the “strawman” namespace \n      Eich has a follow-up as  short podcast  where he describes how the ECMA meeting after his post went. He mentions that two aspects of Harmony are still top secret. Curious... \n      More details on Harmony: “ David Herman on ECMAScript.next ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/html5-parsing.html", "title": "HTML5 parsing", "content": "HTML5 parsing dev html5 webdev post specification \n\nFun anecdote told by John Resig (check the  post  for more details and links): \n HTML 5 validator more \n Better interoperability between browsers. \n Better compatibility with web pages. Apparently, lots of effort and web crawling went into designing the HTML5 parsing algorithm. \n SVG and MathML can be embedded in HTML. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/three-contexts-of-device-interaction.html", "title": "The three contexts of device interaction", "content": "The three contexts of device interaction dev hci computers The Incident CNET \n\nThe contexts are:\n  You carry the device with you, it is less than an arm’s length away from you. The archetypal mobile device is the cell phone.  The device sits somewhere stationary and is about an arm’s length away from you (sometimes more, sometimes less). The archetypal stationary device is the desktop computer.  The device is out of reach, you would have to get up and/or walk a little to touch it. The archetypal remote device is the television. \n\n\n \n  Direct interaction. Touch has become very popular and is usually complemented by buttons. \n  Indirect interaction. Keyboards are used for text entry, a pointing device such as a mouse to interact with graphical user interface elements. A recent innovation is to use trackpads with gestures (mouse gestures have been around for a while, but gestures make more sense with a touch surface). \n  Indirect interaction. Remote controls (which can be considered simplified keyboards) are the norm. A recent innovation is to use body gestures, as popularized by Microsoft’s Kinect. \n \n  Mobile and remote devices usually show few details and have simplified user interfaces. \n Stationary devices provide a high level of detail and sophisticated user interfaces. \n \n Tablets such as the iPad are a device that shares characteristics with typical mobile devices (touch user interface) and typical stationary devices (high level of detail). \n Playing games  by connecting the iPad to a TV and using the iPhone as a controller. \n A  projector  from Sanyo stands 2ft (about 60cm) away from a wall and functions as a whiteboard via infrared pens (whose “writing” is registered by built-in front-facing cameras, leading to virtual ink being projected). A remote device (a projector) that is partially used in a stationary manner. \n \n  Using a Bluetooth keyboard with an iPad switches contexts. Accordingly, touch becomes impractical, because moving your hand from the keyboard to the iPad is tiresome. A trackpad on the keyboard would help, but then the whole user interface metaphor has to change, too. One is effectively turning the iPad into a notebook. That this is so easy, hardware-wise is testament to the versatility of tablets. Further evidence is the next iPad probably having a  proximity sensor  which would allow it to wake up when the case’s cover is opened and to go to sleep when it is closed. \n  Using a desktop computer with a remote control switches contexts. Well, any time you are away from your desktop computer, you switch contexts. Then controlling it remotely should be possible. Currently, remote controls are used for this purpose. Soon, Kinect-style body gestures might fulfill that duty. \n  If a devices hosts a set of applications and the user switches context, then the applications should adapt accordingly. It is not yet clear what the best way for doing so is. Switching a tablet from mobile to stationary might mean that a cursor should be shown for a pointing device. Switching a desktop computer from stationary to remote has been prototyped several times (Microsoft’s Media Center, Apple’s Frontrow, Google TV). As a remote device, I think a computer (be it a desktop computer, a media PC, a smart TV, a console) will mainly be used for shared experiences: Playing a game together, sharing photos, sharing a movie, playing music or music videos, etc. Google seems to think that a remote device has to offer (almost) the complete desktop experience. Gruber  argues against it  and I agree. \n  With more devices specialized for different contexts floating around in households, linking them becomes interesting. The scenario above where a TV-connected iPad uses the iPhone as a controller is a good example. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/javascripts-strict-mode-summary.html", "title": "JavaScript’s strict mode: a summary", "content": "JavaScript’s strict mode: a summary dev javascript jslang JavaScript: Why the hatred for strict mode? \nDouglas Crockford has written a  nice post  on the strict mode (source: Matthias Hölzl). The following is a summary of it.\n \n\n What it is \n     You can selectively switch on strict mode for your JavaScript code and enable a more modern version of it. This kind of opt-in allows JavaScript implementors to evolve the language without sacrificing compatibility. \n     Strict mode is part of the  ECMAScript 5  standard. \n     You can enable strict mode for a complete file or a single function:\n         \n             Complete file: put the line   at the beginning of the file. As a statement, this does nothing and will be ignored by legacy JavaScript interpreters. \n             Single function: using the mode for a complete file might break some functions in it, so by putting the line mentioned above at the beginning of a function, you can enable strict mode for it. \n         \n     \n     Safety is one of the main motivations for strict mode (see end of Crockford’s  post ) \n Most important changes \n     Improved safety: very limited use of  ,   statement not permitted. \n     Global variables must be explicitly declared (no more auto-creation). This helps to prevent typos. \n     Calling constructor functions without  : Prior to strict mode,   was bound to the global object which resulted in properties being added to that object. In strict mode,   will be bound to   and an exception will usually be thrown if constructors are called without  . \n     Noisy failure: Attempting to change a read-only property throws an exception. So does attempting to delete a non-configurable property. \n     No more octal numbers: As a remnant from JavaScript’s C inheritance, numbers with leading zeros were interpreted as octal. Now 0100 really is 100 and not 64. And 08 is not an error, any more. \n     Arguments object: The properties arguments.callee and arguments.caller have been eliminated (for safety reasons: it keeps them secret from foreign code). \n     Function parameters: No more duplicate parameter names or variables that have the same name as a parameter. \n Related reading \n     Find out what browsers support strict mode:  ECMAScript 5 compatibility table \n     What’s new in ECMAScript 5 \n      Mozilla has written a good post on strict mode: “ ECMAScript 5 strict mode in Firefox 4 ” \n       ECMA-262-5 in detail. Chapter 2. Strict Mode  [very detailed] \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/branding-web-technologies-and-new-html5.html", "title": "Branding web technologies and the new HTML5 logo", "content": "Branding web technologies and the new HTML5 logo dev webdev a logo and t-shirts \n I like the look of the logo and the website. \n It is a great idea to provide icons for various web technologies: offline & storage, device access, css3 & styling, etc.  \n \n Bruce Lawson suggests the term  NEWT  (New Exciting Web Technologies) which already has a nice-looking logo. This term is supposed to include   webapp-related new technologies and is more accurate than HTML5. But it is still technology-related and end-user-unfriendly. \n \n\n\n \n The best approach might be to focus on webapps. With iPhone apps becoming increasingly popular, this could get the word out about open alternatives. Already there are many good  web games  out there. The word “app” now means something to end users, it makes sense to use it in the context of the web and to brand things accordingly. \n Technology Blog on the public-webapps mailing list drop \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/javascript-hack-send-current-web-page.html", "title": "JavaScript hack: send the current web page to another server", "content": "JavaScript hack: send the current web page to another server dev javascript clientjs bookmarklet following hack Daring Fireball comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/ultimate-css-layout-spec-for-webapps.html", "title": "CSS3 Grid Layout is perfect for webapp GUIs", "content": "CSS3 Grid Layout is perfect for webapp GUIs dev webdev layout Prior solutions \n  There were  a number of interesting proposals  to adapt CSS layouting to the needs of GUI application developers. None of them really took off. \n Some JavaScript framework authors took matters into their own hands and implemented  surprisingly capable layout  on top of traditional CSS. Others (such as Qooxdoo) perform layout calculations in JavaScript and recompute the layout every time they receive a resize event. That is not as smooth as relying on CSS, but leads to more capable solutions. \n Palm presented  Enyo , a framework that allows one to dynamically change layout depending on the size of the screen (think cell phone versus tablet). \n Grid Layout Grid Layout \nThe only thing missing is the option to declare several columns (or rows) to have the same size. This is useful for the final button row in dialogs (“OK”, “Cancel”, ...) where all buttons should have the same size.\n\n Related reading “ JGoodies :: Forms ”: Check out their  whitepaper, very clear analysis of the issues that arise in GUI layouting.   Internet Explorer 10 is good for webapp developers  [IE10 supports Grid Layout]   CSS Grid Layout is coming to Firefox in 2012 comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/let-big-company-host-your-javascript.html", "title": "Let a big company host your JavaScript libraries", "content": "Let a big company host your JavaScript libraries dev javascript clientjs Content Delivery Networks three reasons \n Decreased latency: Chances are high that a CDN server is closer to a user than your own server. Thus: faster delivery. \n Increased parallelism: Some browsers impose per-host limits on the number of connections. If your JavaScript libraries come from a different server, more of your own content can be loaded in parallel. \n Better caching: If several sites use the same CDN, a copy of your library might already be cached in a user’s browser. \n \n Naturally, a reason against it is that it does not always work when you work offline, with file URLs. If that matters, you can dynamically load your libraries and switch to locally stored versions if the URL protocol is file. \n The post suggests to use  protocol-relative URLs  if you want your site to work both with HTTP and HTTPS. This breaks down if you are using file URLs to test your site (as the CDNs cannot be reached via that protocol). \n The CDN approach is also useful if you just want to quickly try out a small example, without downloading a library. \n Privacy is an issue. If you use Google’s libraries, they will be able to track who comes to your website and from where. [Source: comment from Wesley P] \n \n Google  (most major JavaScript libraries) \n Microsoft  hosts several jQuery files, including jQuery Templates. \n \n Note:   was renamed to  . Isn’t the latter more ugly? Or was the intention to subtly market ASP.NET? \n \n cdnjs  hosts less popular libraries. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/javascript-html-templating-overview-and.html", "title": "JavaScript HTML templating: overview and solutions", "content": "JavaScript HTML templating: overview and solutions dev javascript webdev clientjs What is HTML templating? Templating engines for JavaScript \n     Meta-elements such as   should not use angle brackets, because this clashes with the surrounding HTML. \n     As much logic as possible should be defined in JavaScript and not in the template. This is achieved by letting the template invoke externally defined JavaScript functions. If possible, these functions should also be kept separate from the data, because the data might come from an external source such as a web service. \n \n     John Resig’s  Micro-Templating : has become a kind of a classic in the community and is notable for its briefness and simplicity. Disadvantages: Uses angle brackets, not very powerful, uses the   statement which is currently being phased out of JavaScript. I suspect that the   trick shown above originated in Micro-Templating. \n\n     jQuote2 : an improved version of Micro-Templating. Disadvantages: Angle brackets. \n\n     Mustache : Is available for a variety of programming languages. Good syntax, but I don’t like having to mix data and functions. Furthermore, one can only invoke nullary functions in the template and not directly apply a function to a value. \n\n     Normal Template : Looks nice, I like its syntax. I only decided against it because of jQuery Templates’ larger community (maybe not now, but definitely in the future). \n\n     jQuery Templates : Due to the support of Microsoft, jQuery Templates has  become  an official jQuery plugin and thus   solution for templating in jQuery. Plus its syntax is nice and when it translates from data to HTML, one can hand in two objects: one with data and another one with helper functions. This keeps the logic away from the data. \n    \n     Google’s Closure Templates : You put template definition in separate files and Closure Templates compiles it to programming code. Positives: fast, language-neutral (works with Java and JavaScript). Negatives: compilation makes development slightly less convenient. \n jQuery Templates: quick start and tips comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/wrapping-long-lines-in-tags.html", "title": "Wrapping long lines in <pre> tags", "content": "Wrapping long lines in <pre> tags dev hack html5 comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/intl-pluralrules.html", "title": "Simple pluralization via  Intl.PluralRules", "content": "Simple pluralization via  dev javascript intl In this blog post, we’ll explore a very simple way to handle reporting of numbers of items that respects   (in English: singular and plural). Avoiding pluralization   # By prefixing the items to be counted, we can avoid pluralization: On the upside, this looks reasonable and may even be quicker to read, depending on how one’s brain works. But it can’t always be used and not everyone likes this style. Pluralization via     # The JavaScript internationalization API  can be accessed via the global variable  . One of its services is  , which determines the grammatical number associated with a numeric number: In English, this API uses   for singular and   for plural. This functionality is easy to implement for English. The main value of the API is that it also works for other languages. A simple tool function for pluralization   # For sophisticated apps, you’ll want to use translation files. For small and less important apps, the following tool function will do:  is used like this: Further reading and source of this blog post   # \n “ ”  by  Mathias Bynens  for the V8 Blog \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/01/regexp-lastindex.html", "title": "JavaScript regular expressions:  /g ,  /y , and  .lastIndex", "content": "JavaScript regular expressions:  ,  , and  dev javascript regexp \n  Restructured the content to make the introduction easier to understand. \n In this blog post, we examine how the RegExp flags   and   work and how they depend on the RegExp property  . We’ll also discover an interesting use case for   that you may not have considered yet. \n   \n     The flags   and  \n     \n       \n         Flag   ( ) \n       \n       \n         Flag   ( ) \n       \n     \n   \n   \n     The regular expression property  \n     \n       \n          and  \n       \n       \n          and  \n       \n     \n   \n   \n     Pitfalls of   and  \n     \n       \n         Pitfall: We can’t inline a regular expression with   or  \n       \n       \n         Pitfall: Removing   or   can break code \n       \n       \n         Pitfall: Adding   or   can break code \n       \n       \n         Pitfall: Code can produce unexpected results if   isn’t zero \n       \n       \n         Measures for avoiding the pitfalls of  ,  , and  \n       \n     \n   \n   \n     Use case for  : starting matching at a given index \n     \n       \n         Example: Checking if a regular expression matches at a given index \n       \n       \n         Example: Finding the location of a match, starting at a given index \n       \n       \n         Example: Replacing an occurrence at a given index \n       \n     \n   \n   \n     Summary:   ( ) and   ( ) \n     \n       \n         Automatically generated result table \n       \n     \n   \n   \n     Conclusion \n   \n   \n     Further reading \n   \n The flags   and     # These flags can be summarized as follows: \n  ( ) activates multi-match modes for several regular expression operations. \n  ( ) is similar to  , but there can’t be gaps between matches. \n The following two regular expression operations completely ignore   and  : \n \n \n All other operations are affected by them, in some ways. Flag   ( )   # Let’s see what the multi-match modes look like. # Without  ,   always returns a match object for the first match: With  , it returns one new match per invocation and   when there are no more matches: # Without  ,   only replaces the first match: With  ,   replaces all matches: #  only works if   is set and returns all match objects: Flag   ( )   # We will use   together with   for now (think “  without gaps”). To understand   on its own, we’ll need to learn about the RegExp property  , which we’ll get to soon. # With  , each match returned by   must immediately follow the previous match. That’s why it only returns two matches in the following example: # With  ,   replaces all matches, as long as there are no gaps between them: # With  ,   returns match objects for adjacent matches only: The regular expression property     # The regular expression property   only has an effect if at least one of the flags   and   is used. For regular expression operations that are affected by it, it controls where matching starts.  and     # For example,   uses   to remember where it currently is in the input string:  honors   but does not change it:  ignores   and sets it to zero: To summarize, for several operations,   means: Match at   or later.  and     # For  ,   means: Match at exactly  . It works as if the beginning of the regular expression were anchored to  . Note that   and   continue to work as usually: They anchor matches to the beginning or end of the input string, unless   is set. Then they anchor to the beginnings or ends of lines.  matches multiple times if   is set (even if   is not set): If   is used without  , then   replaces the first occurrence that is found (directly) at  . It updates  . Pitfalls of   and     # Pitfall: We can’t inline a regular expression with   or     # A regular expression with   can’t be inlined. For example, in the following   loop, the regular expression is created fresh, every time the condition is checked. Therefore, its   is always zero and the loop never terminates. With  , the problem is the same. Pitfall: Removing   or   can break code   # If code expects a regular expression with   and has a loop over the results of   or  , then a regular expression without   can cause an infinite loop: Why is there an infinity loop? Because   always returns the first result, a match object, and never  . With  , the problem is the same. Pitfall: Adding   or   can break code   # With  , there is another caveat: It is affected by  . Therefore, if we want to check exactly once if a regular expression matches a string, then the regular expression must not have  . Otherwise, we generally get a different result every time we call  : The first invocation produces a match and updates  . The second invocation does not find a match and resets   to zero. If we create a regular expression specifically for  , then we probably won’t add  . However, the likeliness of encountering   increases if we use the same regular expression for replacing and for testing. Once again, this problem also exists with  : Pitfall: Code can produce unexpected results if   isn’t zero   # Given all the regular expression operations that are affected by  , we must be careful with many algorithms that   is zero at the beginning. Otherwise, we may get unexpected results: Normally,   is zero in newly created regular expressions and we won’t change it explicitly like we did in the example. But   can still end up not being zero if we use the regular expression multiple times. Measures for avoiding the pitfalls of  ,  , and     # As an example of dealing with   and  , we revisit   from the previous example. How do we prevent a wrong regular expression from breaking our code? Let’s look at three approaches. # First, we can throw an exception if   isn’t set or   isn’t zero: # Second, we can clone the parameter. That has the added benefit that   won’t be changed. # Several regular expression operations are not affected by   or by flags. For example,   ignores   if   is present: Here,   works even though we didn’t check or fix  . Use case for  : starting matching at a given index   # Apart from storing state,   can also be used to start matching at a given index. This section describes how. Example: Checking if a regular expression matches at a given index   # Given that   is affected by   and  , we can use it to check if a regular expression   matches a string   at a given  :  is anchored to   due to  . Note that we must not use the assertion   which would anchor   to the beginning of the input string. Example: Finding the location of a match, starting at a given index   #  lets us find the location where a regular expression matches: Alas, we can’t change where   starts looking for matches. As a work-around, we can use   for searching: Example: Replacing an occurrence at a given index   # When used without   and with  ,   makes one replacement – if there is a match at  : Summary:   ( ) and   ( )   # The following two methods are completely unaffected by   and  : \n \n \n Legend: \n Column “#” specifies how many results a method delivers. \n  means  \n  means  \n Is the operation affected by  ?\n \n ✓ Yes:   is either updated or unchanged. \n ✗ No: By default,   isn’t touched, but several operations reset it to zero. \n \n \n Automatically generated result table   # I have written  a small Node.js script  that prints the following result table: (Older versions of   don’t throw a   if   is missing.) Conclusion   # The regular expression property   has two significant downsides: \n It makes regular expressions stateful:\n \n We now have to be mindful of the states of regular expressions and how we share them. \n For many use cases, we can’t make them immutable via freezing, either. \n \n \n Support for   is inconsistent among regular expression operations. \n On the upside,   also gives us additional useful functionality: We can dictate where matching should begin (for some operations). Further reading   # \n Chapter “Regular expressions ( )”  in “JavaScript for impatient programmers” \n Blog post “ECMAScript feature:  ” \n Blog post “ECMAScript proposal:  ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/01/enum-pattern.html", "title": "A class-based enum pattern for JavaScript", "content": "A class-based enum pattern for JavaScript dev javascript pattern In this blog post, we examine a pattern for implementing enums in JavaScript that is based on classes. We’ll also take a look at  Enumify, a library that helps with the enum pattern . \n   \n     Implementing enums: first attempts \n   \n   \n     The enum pattern \n   \n   \n     Enumify: a helper library for the enum pattern \n     \n       \n         Instance properties \n       \n       \n         Prototype methods \n       \n       \n         Static features \n       \n     \n   \n   \n     Examples of using Enumify \n     \n       \n         Enum values with instance properties \n       \n       \n         Switching over enum values \n       \n       \n         Enum values with instance getters \n       \n       \n         State machines via instance methods \n       \n       \n         Arbitrary enum values \n       \n     \n   \n   \n     Support for public static fields \n   \n   \n     Further reading \n   \n Implementing enums: first attempts   # An enum is a type that consists of a set of values. For example, TypeScript has built-in enums and with them, we can define our own boolean type: Or we can define our own type for colors: This TypeScript code is compiled to the following JavaScript code (a few details are omitted, to make things easier to understand): This implementation has several problems: Logging: If you log an enum value such as  , you don’t see its name. Type safety: Enum values are not unique, they can be mixed up with other numbers. For example, the number   can be mistaken for   and vice versa. Membership check: You can’t easily check whether a given value is an element of  . Continuing with plain JavaScript, we can fix problem #1 by using strings instead of numbers as enum values: We additionally get type safety if we use symbols as enum values: One problem with symbols is that we need to convert them to strings explicitly, we can’t coerce them (e.g. via   or inside template literals): And while we can test for membership, it’s not simple: The enum pattern   # Using a custom class for the enum gives us a membership test and more flexibility with regard to enum values: I call this way of using classes as enums the  . It is inspired by how Java implements enums. Logging: Membership test: Enumify: a helper library for the enum pattern   # Enumify  is a library that helps with the enum pattern. It is used as follows: Instance properties   # Enumify adds several instance properties to enum values: Prototype methods   # Enumify implements  : Static features   # Enumify sets up two static properties –   and  : It provides the inheritable static method  : And it implements inheritable iterability: Examples of using Enumify   # Enum values with instance properties   # Switching over enum values   # Downside of the enum pattern: Generally, we can’t refer to other enum values when creating an enum values (because those other enum values may not exist yet). As a work-around, we can implement helpers externally, via functions: Enum values with instance getters   # Another work-around for not being able to use other enum values when declaring enum values is to delay accessing sibling values via getters: The getters are passed to the constructor inside objects. The constructor copies them to the current instance via   and  . Alas, we can’t use   here because it can’t copy getters and methods. State machines via instance methods   # In the following example, we implement a state machine. We pass properties (including methods) to the constructor, which copies them into the current instance. The state machine detects sequences of three   inside strings: Arbitrary enum values   # One occasionally requested feature for enums is that enum values be numbers (e.g. for flags) or strings (e.g. to compare with values in HTTP headers). That can be achieved by making those values properties of enum values. For example: Support for public static fields   # The enum pattern and Enumify are based on public static fields. Support for them currently looks as follows: \n MDN lists support for public static fields in various JavaScript engines. \n Babel has the plugin   for public static fields. \n TypeScript has supported static fields in classes for a very long time. \n Further reading   # \n Blog post  “ECMAScript proposal: public class fields” \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/01/typescript-enums.html", "title": "TypeScript enums: How do they work? What can they be used for?", "content": "TypeScript enums: How do they work? What can they be used for? dev javascript typescript This blog post answers the following two questions: \n How do TypeScript’s enums work? \n What can they be used for? \n \n   \n     The basics \n     \n       \n         Numeric enums \n       \n       \n         Casing of enum member names \n       \n       \n         Quoting enum member names \n       \n       \n         String-based enums \n       \n       \n         Heterogeneous enums \n       \n     \n   \n   \n     Specifying enum member values \n     \n       \n         Literal enum members \n       \n       \n         Constant enum members \n       \n       \n         Computed enum members \n       \n     \n   \n   \n     Downsides of numeric enums \n     \n       \n         Downside: logging \n       \n       \n         Downside: loose type-checking \n       \n       \n         Recommendation: prefer string-based enums \n       \n     \n   \n   \n     Use cases for enums \n     \n       \n         Use case: bit patterns \n       \n       \n         Use case: multiple constants \n       \n       \n         Use case: more self-descriptive than booleans \n       \n       \n         Use case: safer string constants \n       \n     \n   \n   \n     Enums at runtime \n     \n       \n         Reverse mappings \n       \n       \n         String-based enums at runtime \n       \n     \n   \n   \n      enums \n     \n       \n         Compiling non-const enums \n       \n       \n         Compiling const enums \n       \n     \n   \n   \n     Enums at compile time \n     \n       \n         Enums are objects \n       \n       \n         Exhaustiveness checks for literal enums \n       \n       \n          and enums \n       \n     \n   \n   \n     Acknowledgment \n   \n The basics   # JavaScript has one type with a finite amount of values: boolean, which has the values   and   and no other values. With enums, TypeScript lets you define similar types statically yourself. Numeric enums   # This is a simple example of an enum: The entries   and   are called the   of the enum  . As in object literals, trailing commas are allowed and ignored. We can use members as if they were literals such as  ,  , or   – for example: # Each enum member has a   and a  . The default for enums is to be  . That is, each member value is a number: Instead of TypeScript specifying enum member values for us, we can also specify them ourselves: This kind of explicit specification via an equals sign is called an  . We can omit the value of a member if the preceding member value is a number. Then TypeScript increments that value by one and uses it for the current member: Casing of enum member names   # There are several precedents for naming constants (in enums or elsewhere): \n Traditionally, JavaScript has used all-caps names, which is a convention it inherited from Java and C:  \n Well-known symbols are camel-cased and start with lowercase letters because they are related to property names:  \n The TypeScript manual uses camel-cased names that start with uppercase letters. This is the standard TypeScript style and we used it for the   enum. \n Quoting enum member names   # Similar to JavaScript objects, we can quote the names of enum members: There is no way to compute the names of enum members. Object literals support computed names via square brackets. String-based enums   # Instead of numbers, we can also use strings as enum member values: If an enum is completely string-based, we cannot omit any initializers. Heterogeneous enums   # The last kind of enums is called  . The member values of a heterogeneous enum are a mix of numbers and strings: Note that the previously mentioned rule applies here, too: We can only omit an initializer if the previous member value is a number. Heterogeneous enums are not used often because they have few applications. Alas, TypeScript only supports numbers and strings as enum member values. Other values, such as symbols, are not allowed. Specifying enum member values   # TypeScript distinguishes three ways of specifying enum member values: \n \n  are initialized: \n \n implicitly or \n via number literals or string literals (explicitly).\nSo far, we have only used literal members. \n \n \n \n  are initialized via expressions whose results can be computed at compile time. \n \n \n  are initialized via arbitrary expressions. \n \n In this list, earlier entries are less flexible, but support more features. The next subsections cover each entry in more detail. Literal enum members   # An enum member is   if its value is specified: \n implicitly or \n via a number literal (incl. negated number literals) or \n via a string literal. \n If an enum has only literal members, we can use those members as types (similar to how, e.g., number literals can be used as types): Additionally, literal enums support exhaustiveness checks (which we’ll look at later). Constant enum members   # An enum member is constant if its value can be computed at compile time. Therefore, we can either specify its value implicitly (that is, we let TypeScript specify it for us). Or we can specify it explicitly and are only allowed to use the following syntax: \n Number literals or string literals \n A reference to a previously defined constant enum member (in the current enum or in a previous enum) \n Parentheses \n The unary operators  ,  ,  \n The binary operators  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  \n This is an example of an enum whose members are all constant (we’ll see soon how that enum is used): If an enum has only constant members, we can’t use members as types anymore. But we can still do exhaustiveness checks. Computed enum members   # The values of   can be specified via arbitrary expressions. For example: This was a numeric enum. String-based enums and heterogeneous enums are more limited. For example, we cannot use method invocations to specify member values: Downsides of numeric enums   # Downside: logging   # When logging members of numeric enums, we only see numbers: Downside: loose type-checking   # When using the enum as a type, the values that are allowed statically are not just those of the enum members – any number is accepted: Why aren’t there stricter static checks?  Daniel Rosenwasser explains : The behavior is motivated by bitwise operations. There are times when   is intended to produce another  . Instead you end up with  , and you don’t want to have to cast back to  . I think if we did TypeScript over again and still had enums, we’d have made a separate construct for bit flags. How enums are used for bit patterns is demonstrated soon in more detail. Recommendation: prefer string-based enums   # My recommendation is to prefer string-based enums (for brevity’s sake, this blog post doesn’t always follow this recommendation): On one hand, logging output is more useful for humans: On the other hand, we get stricter type checking: Use cases for enums   # Use case: bit patterns   # In  the Node.js file system module , several functions have the parameter mode. Its value is used to specify file permissions, via an encoding that is a holdover from Unix: \n Permissions are specified for three categories of users:\n \n User: the owner of the file \n Group: the members of the group associated with the file \n All: everyone \n \n \n Per category, the following permissions can be granted:\n \n r (read): the users in the category are allowed to read the file \n w (write): the users in the category are allowed to change the file \n x (execute): the users in the category are allowed to run the file \n \n \n That means that permissions can be represented by 9 bits (3 categories with 3 permissions each): Node.js doesn’t do this, but we could use an enum to work with these flags: Bit patterns are combined via  bitwise Or : # The main idea behind bit patterns is that there is a set of flags and that any subset of those flags can be chosen. Therefore, using real sets to choose subsets is a more self-descriptive way of performing the same task: Use case: multiple constants   # Sometimes, we have sets of constants that belong together: This is a good use case for an enum: The benefits of this enum are: \n Constant names are grouped and nested inside the namespace  . \n We can use the type   whenever we need one of those constants and TypeScript checks statically that no other values are used. \n Use case: more self-descriptive than booleans   # When booleans are used to represent alternatives, then enums are usually a more self-descriptive choice. # For example, to represent whether a list is ordered or not, we can use a boolean: However, an enum is more self-descriptive and has the additional benefit that we can add more alternatives later if we need to. # Similarly, we can encode whether an operation succeeded or failed via a boolean or via an enum: Use case: safer string constants   # Consider the following function that creates regular expressions. Using a string-based enum is more convenient: Enums at runtime   # TypeScript compiles enums to JavaScript objects. As an example, take the following enum: TypeScript compiles this enum to: In this code, the following assignments are made: There are two groups of assignments: \n The first two assignments map enum member names to values. \n The second two assignments map values to names. That enables  , which we will look at next. \n Reverse mappings   # Given a numeric enum: The normal mapping is from member names to member values: Numeric enums also support a   from member values to member names: String-based enums at runtime   # String-based enums have a simpler representation at runtime. Consider the following enum. It is compiled to this JavaScript code: TypeScript does not support reverse mappings for string-based enums.  enums   # If an enum is prefixed with the keyword  , it doesn’t have a representation at runtime. Instead, the values of its member are used directly. Compiling non-const enums   # To observe this effect, let us first examine the following non-const enum: TypeScript compiles this code to: Compiling const enums   # This is the same code as previously, but now the enum is const: Now the representation of the enum as a construct disappears and only the values of its members remain: Enums at compile time   # Enums are objects   # TypeScript treats (non-const) enums as if they were objects: Exhaustiveness checks for literal enums   # When we accept an enum member value, we often want to make sure that: \n We don’t receive illegal values. \n We didn’t forget to consider any enum member values. (This becomes especially relevant if we add new enum member values later on.) \n # In the following code, we take two measures against illegal values: The measures are: \n At compile time, the type   prevents illegal values being passed to the parameter  . \n At runtime, the   case is used to throw an exception if there is an unexpected value. \n # We can take one more measure. The following code performs an  : TypeScript will warn us if we forget to consider all enum members. How does the exhaustiveness check work? For every case, TypeScript infers the type of  : In the default case, TypeScript infers the type   for   because we never get there. If however, we add a member   to  , then the inferred type of   is  . And that type is statically incompatible with the type   of the parameter of  . We therefore get the following error message at compile time: Argument of type 'NoYes.Maybe' is not assignable to parameter of type 'never'. Conveniently, this kind of exhaustiveness check also works with   statements: # Alternatively, we also get an exhaustiveness check if we specify a return type for  : If we add a member to  , then TypeScript complains that   may return  .  Alas, this approach does not work with   statements ( more information ).  and enums   # We can use the   type operator to create the type whose elements are the keys of the enum members. When we do so, we need to combine   with  : Why do this? It can be more convenient than defining the type   directly. # If we use   without  , we get a different, less useful, type:  is the same as  . Acknowledgment   # \n Thanks to Disqus user   for their feedback to this blog post. \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/01/typing-objects-typescript.html", "title": "Typing objects in TypeScript", "content": "Typing objects in TypeScript dev javascript typescript chapter “Typing objects” In this blog post, we will explore how objects and properties are typed statically in TypeScript. \n   \n     Roles played by objects \n   \n   \n     Types for objects \n   \n   \n      vs.   in TypeScript \n     \n       \n         Plain JavaScript: objects vs. instances of  \n       \n       \n          (uppercase “O”) in TypeScript: instances of class  \n       \n       \n          (lowercase “o”) in TypeScript: non-primitive values \n       \n       \n          vs.  : primitive values \n       \n       \n          vs.  : incompatible property types \n       \n     \n   \n   \n     Object type literals and interfaces \n     \n       \n         Differences between object type literals and interfaces \n       \n       \n         Nominal type systems vs. structural type systems \n       \n       \n         Members of interfaces and object type literals \n       \n       \n         Index signatures: objects as dicts \n       \n       \n         Interfaces describe instances of  \n       \n       \n         Excess property checks \n       \n     \n   \n   \n     Type inference \n   \n   \n     Other features of interfaces \n     \n       \n         Optional properties \n       \n       \n         Read-only properties \n       \n     \n   \n   \n     JavaScript’s prototype chains and TypeScript’s types \n   \n   \n     Sources of this blog post \n   \n Roles played by objects   # In JavaScript, objects can play two roles (always at least one of them, sometimes mixtures): \n \n Records: A fixed amount of properties that are known at development time. Each property can have a different type. \n \n \n Dictionaries: An arbitrary amount of properties whose names are not known at development time. All property keys (strings and/or symbols) have the same type, as do the property values. \n \n First and foremost, we will explore objects as records. We will briefly encounter objects as dictionaries later in this post. Types for objects   # There are two different general types for objects: \n  with an uppercase “O” is the type of all instances of class  : \n \n  with a lowercase “o” is the type of all non-primitive values: \n \n Objects can also be described via their properties: In the next sections, we’ll examine all these ways of typing objects in more detail.  vs.   in TypeScript   # Plain JavaScript: objects vs. instances of     # In plain JavaScript, there is an important distinction. On one hand, most objects are instances of  . That means: \n \n  is in their prototype chains: \n \n \n \n They inherit its properties. \n \n \n On the other hand, we can also create objects that don’t have   in their prototype chains. For example, the following object does not have any prototype at all:  is an object that is not an instance of class  :  (uppercase “O”) in TypeScript: instances of class     # In TypeScript,   is the type of all instances of class  . It is defined by two interfaces: \n Interface   defines the properties of  . \n Interface   defines the properties of class   (i.e., the object pointed to by that global variable). \n All instances of   inherit the properties of interface  . We can see that if we create a function that returns its parameter: If an instance of   comes in, it always satisfies the return type – which requires it to have a method  .  (lowercase “o”) in TypeScript: non-primitive values   # In TypeScript,   is the type of all non-primitive values (primitive values are  ,  , booleans, numbers, bigints, strings). With this type, we can’t access any properties of a value.  vs.  : primitive values   # Interestingly, type   includes primitive values: Why? The properties of   can also be accessed via primitive values: Conversely,   does not include primitive values:  vs.  : incompatible property types   # With type  , TypeScript complains if an object has a property whose type conflicts with the corresponding property in interface  : With type  , TypeScript does not complain (because   has no properties and there can’t be any conflicts): Object type literals and interfaces   # TypeScript has two ways of defining object types that are very similar: We can use either semicolons or commas as separators. Trailing separators are allowed and optional. Differences between object type literals and interfaces   # In this section, we take a look at the most important differences between object type literals and interfaces. Source of this section:  GitHub issue “TypeScript: types vs. interfaces”  by  Johannes Ewald # Object type literals can be inlined, while interfaces can’t be: # Type aliases with duplicate names are illegal: Conversely, interfaces with duplicate names are merged: # For Mapped types (line A), we need to use object type literals: # Only possible in interfaces: From now on, “interface” means “interface or object type literal” (unless stated otherwise). Nominal type systems vs. structural type systems   # One of the responsibilities of a static type system is to determine if two static types are compatible: \n The static type   of an actual parameter (provided, e.g., via a function call) \n The static type   of the corresponding formal parameter (specified as part of a function definition) \n This often means checking if   is a subtype of  . Two approaches for this check are (roughly): \n \n In a   or   type system, two static types are equal if they have the same identity (“name”). One type is a subtype of another if their subtype relationship was declared explicitly. \n \n Languages with nominal typing are C++, Java, C#, Swift, and Rust. \n \n \n \n In a   type system, two static types are equal if they have the same structure (if their parts have the same names and the same types). One type   is a subtype of another type   if   has all parts of   (and possibly others) and each part of   has a subtype of the corresponding part of  . \n \n Languages with structural typing are OCaml/ReasonML, Haskell, and TypeScript. \n \n \n The following code produces a type error (line A) in nominal type systems, but is legal in TypeScript’s structural type system because class   and class   have the same structure: TypeScript’s interfaces also work structurally – they don’t have to be implemented in order to “match”: Members of interfaces and object type literals   # Members of interfaces and object type literals can be: \n \n Property signatures define properties: \n \n \n \n Method signatures define methods: \n \n Note that the names of parameters (in this case:  ) help with documenting how things work, but have no other purpose. \n \n \n Index signatures help when interfaces describe Arrays or objects that are used as dictionaries. \n \n Note: The property key name   is only there for documentation purposes. I often use   or  . \n \n \n Call signatures enable interfaces to describe functions: \n \n \n \n Constructor signatures enable interfaces to describe classes and constructor functions: \n \n \n Property signatures and method signatures should be self-explanatory. Call and constructor signatures are beyond the scope of this blog post. We’ll take a closer look at index signatures next. Index signatures: objects as dicts   # So far, we have only used interfaces for objects-as-records with fixed keys. How do we express the fact that an object is to be used as a dictionary? For example: What should   be in the following code fragment? We use an index signature (line A) to express that   is for objects that map string keys to string values: # Index signature keys must be either   or  : \n Symbols are not allowed. \n  is not allowed. \n Type unions (e.g.  ) are not allowed. However, multiple index signatures can be used per interface. \n # Just like in plain JavaScript, TypeScript’s number property keys are a subset of the string property keys ( see “JavaScript for impatient programmers” ). Accordingly, if we have both a string index signature and a number index signature, the property type of the former must be a supertype of the latter. The following example works because   is a supertype of  : # If there are both an index signature and property and/or method signatures in an interface, then the type of the index property value must also be a supertype of the type of the property value and/or method. In contrast, the following two interfaces produce no errors: Interfaces describe instances of     # All interfaces describe objects that are instances of   and inherit the properties of  . In the following example, the parameter   of type   is compatible with the result type  : Similarly,   is understood to have a method  : Excess property checks   # As an example, consider the following interface: There are two ways (among others) in which this interface could be interpreted: \n Closed interpretation: It could describe all objects that have   the properties   and   with the specified types. On other words: Those objects must not have   (more than the required properties). \n Open interpretation: It could describe all objects that have   the properties   and  . In other words: Excess properties are allowed. \n TypeScript uses both interpretations. To explore how that works, we will use the following function: The default is that the excess property   is allowed: However, if we use object literals directly, then excess properties are forbidden: # Why the restriction? The open interpretation that allows excess properties is reasonably safe when the data comes from somewhere else. However, if we create the data ourselves, then we profit from the extra protection against typos that the closed interpretation gives us – for example: Property   is optional and can be omitted (we’ll examine optional properties in more detail later). If we mistype its name in an object literal, TypeScript will assume that we created an excess property and left out  . Thankfully, we get a warning because excess properties are not allowed in object literals: If an object with the same typo came from somewhere else, it would be accepted. # If an interface is empty (or the object type literal   is used), excess properties are always allowed: If we want to enforce that objects have no properties, we can use the following trick (credit:  Geoff Goodman ): # What if we want to allow excess properties in object literals? As an example, consider interface   and function  : One option is to assign the object literal to an intermediate variable: A second option is to use a type assertion: A third option is to rewrite   so that it uses a type parameter: A fourth option is to extend interface   so that it allows excess properties: We’ll continue with two examples where TypeScript not allowing excess properties, is an issue. # In this example, we’d like to implement an  , but TypeScript doesn’t allow the extra property  : Alas, even with a type assertion, there is still one type error: We can either add an index signature to interface  . Or – especially if that is not possible – we can introduce an intermediate variable: # The following comparison function can be used to sort objects that have the property  : For example in unit tests, we may want to invoke this function directly with object literals. TypeScript doesn’t let us do this and we need to use one of the work-arounds. Type inference   # These are the types that TypeScript infers for objects that are created via various means: In principle, the return type of   could be  . I assume that it is   to be backward compatible with old code. Other features of interfaces   # Optional properties   # If we put a question mark ( ) after the name of a property, that property is declared to be optional. For example, in the following example, property   is optional: That means that it’s OK to omit it (line A): # What is the difference between   and  ? An optional property can do everything that   can. We can even use the value   for the former: However, only   can be omitted: Types such as   are useful if we want to make omissions explicit. When people see such an explicitly omitted property, they know that it exists but was switched off. Read-only properties   # In the following example, property   is read-only: As a consequence, we can read it, but we can’t change it: JavaScript’s prototype chains and TypeScript’s types   # TypeScript doesn’t distinguish own and inherited properties. They are all simply considered to be properties. The downside of this approach is that there are some JavaScript phenomena that can’t be typed statically. Its upside is that the type system is simpler. Sources of this blog post   # \n TypeScript Handbook \n TypeScript Language Specification \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/01/special-values-typescript.html", "title": "Adding special values to types in TypeScript", "content": "Adding special values to types in TypeScript dev javascript typescript One way of understanding types is as sets of values. Sometimes there are two levels of values: \n Base level: normal values \n Meta level: special values \n In this blog post, we examine how we can add special values to base-level types. \n   \n     Adding special values in band \n     \n       \n         Adding   or   to a type \n       \n       \n         Adding a symbol to a type \n       \n     \n   \n   \n     Adding special values out of band \n     \n       \n         Discriminated unions \n       \n       \n         Other kinds of type unions \n       \n     \n   \n Adding special values in band   # One way of adding special values is to create a new type which is a superset of the base type where some values are special. These special values are called  . They exist   (think inside the same channel), as siblings of normal values. As an example, consider the following interface for readable streams: At the moment,   only handles text lines, but not ends of files (EOFs). How could we add support for EOF? Possibilities include: \n An additional method   that needs to be called before calling  . \n  throws an exception when it reaches an EOF. \n A sentinel value for EOF. \n The next two subsections describe two ways in which we can introduce sentinel values. Adding   or   to a type   # When using strict TypeScript, no simple object type (defined via interfaces, object patterns, classes, etc.) includes  . That makes it a good sentinel value that we can add to the base type   via a type union: Now, whenever we are using the value returned by  , TypeScript forces us to consider both possibilities: strings and   – for example: In line A, we can’t use the string method   because   might be  . We can fix this as follows: Now, when execution reaches line A, we can be sure that   is not  . Adding a symbol to a type   # We can also use values other than   as sentinels. Symbols and objects are best suited for this task because each one of them has a unique identity and no other value can be mistaken for it. This is how to use a symbol to represent EOF: Note that we need the   operator here. TypeScript distinguishes values and types: \n  is a value. \n The first operand of the union type operator   must be a type. \n # As an aside,   only look like values, but they are actually types – for example:  looks like a value, but is a type (the type whose only member is the number  ). We can see that if we refer to   via a constant: Adding special values out of band   # What do we do if potentially   value can be returned by a method? How do we ensure that base values and meta values don’t get mixed up? This is an example where that might happen: Whatever special value for   we come up with, it is always possible to use   for the type parameter  . The solution is to encode normal values and special values differently, so that they exist separately and can’t be mixed up. This kind of separate existence is called   (think in a different channel). Discriminated unions   # A   is a type union over several object types that all have at least one property in common. That property must have a different value for each object type – we can think of it as the ID of the object type. In the following example,   is a discriminated. Due to the check in line A, we can access the property   in line B, even though that property is specific to type  . # When deciding how to implement iterators, TC39 also couldn’t use a fixed sentinel value. Otherwise, that value could appear in iterables and break code. One solution would have been to pick a sentinel value when starting an iteration. TC39 instead opted for a discriminated union with the common property  : Other kinds of type unions   # Other kinds of type unions can be as convenient as discriminated unions, as long as we have the means to distinguish the members of the union. One possibility is distinguish via unique properties: Another possibility is distinguish via   and/or instance checks: comments powered by Disqus."},
{"url": "https://2ality.com/2020/02/typescript-exhaustiveness-checks-via-exceptions.html", "title": "TypeScript: exhaustiveness checks via exceptions", "content": "TypeScript: exhaustiveness checks via exceptions dev javascript typescript TypeScript supports  exhaustiveness checking  for enums and similar types. This blog post shows how to use idiomatic JavaScript for this kind of check. Pattern: exhaustiveness checks via exceptions   # Consider the following enum: The   statement in the following code is idiomatic JavaScript: Can we also get static errors in TypeScript? In line A, the inferred type of   is   because we have already taken care of all values that it can have. Therefore, we can instantiate the following exception in line A: If, however, we forget one of the   cases, then the type of   isn’t   anymore and we get a static error: Benefit: also works with   statements   # TypeScript also warns us if we use   statements: Another way of checking exhaustiveness   # Instead of using a default case, we can also specify a return type. Then TypeScript warns us if we forget a case (because we implicitly return  ): Downside: doesn’t work with   statements   # Alas, with this approach, we get a warning even if we exhaustively handle all cases (see second function,  ): Comparing the two approaches   # How does this approach compare to using an exception? \n Upside: less verbose \n Downsides:\n \n No protection at runtime \n Doesn’t work with   statements \n \n \n Can this pattern be used elsewhere, too?   # This pattern works for: \n Enums \n Type unions \n Discriminated unions \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/02/source-code-sections.html", "title": "Sections in source code", "content": "Sections in source code dev javascript ide In this blog post, I’ll briefly explain the idea of having   in source code. The IDE   has a related concept:  . Source code sections   # In my code, I like to group related constructs – for example: Visual Studio Code: folding regions   # Visual Studio Code supports  . These are marked as follows: Alas, they only affect folding. There is  an issue asking to display regions in the code outline , though. comments powered by Disqus."},
{"url": "https://2ality.com/2020/02/enum-alternatives-typescript.html", "title": "Alternatives to enums in TypeScript", "content": "Alternatives to enums in TypeScript dev javascript typescript A recent blog post explored how TypeScript enums work.  In this blog post, we take a look at alternatives to enums. \n   \n     Unions of singleton values \n     \n       \n         Unions of string literal types \n       \n       \n         Unions of symbol singleton types \n       \n       \n         Type unions vs. enums \n       \n     \n   \n   \n     Discriminated unions \n     \n       \n         Step 1: the syntax tree as a class hierarchy \n       \n       \n         Step 2: the syntax tree as a type union of classes \n       \n       \n         Step 3: the syntax tree as a discriminated union \n       \n       \n         Discriminated type unions vs. normal type unions \n       \n     \n   \n   \n     Object literals as enums \n     \n       \n         Object literals with string-valued properties \n       \n       \n         Upsides and downsides of using object literals as enums \n       \n     \n   \n   \n     Enum pattern \n   \n   \n     Summary of enums and enum alternatives \n   \n   \n     Acknowledgement \n   \n   \n     Further reading \n   \n Unions of singleton values   # An alternative to creating an enum that maps keys to values, is to create a union of singleton types (one per value). Read on to see how that works. Unions of string literal types   # Let’s start with an enum and convert it to a union of string literal types. An alternative is to use a type union: Quick recap : \n We can consider types to be sets of values. \n A   is a type with one element. \n The union type operator   is related to the set-theoretic union operator  . \n In this case, the operands of the type union are  string literal types : \n  is the type whose only element is the string  \n  is the type whose only element is the string  \n These types are specified with the same syntax as string literals, but they exist at a different level: \n String literal type – type level: represents a set with a single string in it \n String literal – value level: represents a string \n Let’s use   in an example: # The following code demonstrates that TypeScript checks exhaustiveness for unions of string literal types: We forgot the case   and TypeScript warns us that the function is not guaranteed to only return strings, anymore. # One downside of string literal unions is that non-member values can mistakenly be considered to be members: This is logical because the Spanish   and the English   are the same value. The real problem is that there is no way to give them different identities. Unions of symbol singleton types   # Instead of unions of string literal types, we can also use unions of symbol singleton types. Let’s start with a different enum this time: Translated to a union of symbol singleton types, it looks as follows: The following function translates members of   to strings: Let’s compare this approach to unions of string literal types: \n Exhaustiveness checks work for both approaches. \n Using symbols is more verbose \n In contrast to string literal types, symbols are type-safe. \n The last point is demonstrated in the following example: Type unions vs. enums   # Type unions and enums have some things in common: \n You can auto-complete member values. However, you do it differently:\n \n With enums, you get auto-completion after the enum name and a dot. \n With type unions, you get auto-completion in place or – if it’s a union of string literal types – inside string literal quotes. \n \n \n Exhaustiveness checks work for both. \n But they also differ. Downsides of unions of symbol singleton types are: \n They are slightly verbose. \n There is no namespace for their members. \n It’s slightly harder to migrate from them to different constructs (should it be necessary): It’s easier to find where enum member values are mentioned. \n Upsides of unions of symbol singleton types are: \n They are not a custom TypeScript language construct and therefore closer to plain JavaScript. \n String enums are only type-safe at compile time. Unions of symbol singleton types are additionally type-safe at runtime.\n \n This matters especially if our compiled TypeScript code interacts with plain JavaScript code. \n \n \n Discriminated unions   # Discriminated unions  are related to  algebraic data types  in functional programming languages. To understand how they work, consider the data structure   that represents expressions such as: A syntax tree is either: \n A number \n The addition of two syntax trees \n We’ll start by creating an object-oriented class hierarchy. Then we’ll transform it into something slightly more functional. And finally, we’ll end up with a discriminated union. Step 1: the syntax tree as a class hierarchy   # This is a typical OOP implementation of a syntax tree:  is the superclass of   and  . The keyword   is syntactic sugar for: \n Declaring the instance property  \n Initializing this property via the parameter  \n This is an example of using  : Note:  Trailing commas in argument lists  are allowed in JavaScript since ECMAScript 2016. Step 2: the syntax tree as a type union of classes   # If we define the syntax tree via a type union (line A), we don’t need object-oriented inheritance: Since   and   don’t have a superclass, they don’t need to invoke   in their constructors. Interestingly, we create trees in the same manner as before: Step 3: the syntax tree as a discriminated union   # Finally, we get to discriminated unions. These are the type definitions for  : We have switched from classes to interfaces and therefore from instances of classes to plain objects. The interfaces of a discriminated union must have at least one property in common and that property must have a different value for each one of them. That property is called the   or  . Compare: \n The class of an instance is usually determined by its prototype chain. \n The type of a member of a discriminated union is determined by its discriminant. \n This is a member of  : We don’t need the type annotation in line A, but it helps ensure that all objects have the correct structure. If we don’t do it here, we’ll find out about problems later. TypeScript tracks the value of the discriminant and updates the type of the member of the union accordingly: In line A, we haven’t checked the discriminant  , yet. Therefore, the current type of   is still   and we can’t access property   in line B. In line C, TypeScript knows that   is   and can therefore infer the type   for  . That’s why accessing   in the next line is OK, this time. # We conclude this step with an example of how to implement functions for discriminated unions. If there is an operation that can be applied to members of all subtypes, the approaches for classes and discriminated unions differ: \n With classes, it is common to use a polymorphic method where each class has a different implementation. \n With discriminated unions, it is common to use a single function that handles all possibles cases and decides what to do by examining the discriminant of its parameter. \n The following example demonstrates the latter approach. The discriminant is examined in line A and determines which of the two   cases is executed. Note that TypeScript performs exhaustiveness checking for discriminated unions: If we forget a case, TypeScript will warn us. Note that with the OOP approach, we had to modify the classes in order to add functionality. In contrast, with the functional approach, external parties can add functionality. Discriminated type unions vs. normal type unions   # Discriminated unions and normal type unions have two things in common: \n There is no namespace for member values. \n TypeScript performs exhaustiveness checking. \n The next two subsections explore two advantages of discriminated unions over normal unions: # With discriminated unions, values get descriptive property names. Let’s compare: Normal union: Discriminated union: Now people who read the source code immediately know what the string is: a native pathname. # The following discriminated union cannot be implemented as a normal union because we can’t distinguish the types of the union in TypeScript. Object literals as enums   # The following pattern for implementing enums is common in JavaScript: We can attempt to use it in TypeScript as follows: Alas, in line A, TypeScript infers the type  . Accordingly, we can pass any symbol to   and TypeScript won’t complain at compile time: We can try and define   differently, but that doesn’t change anything: In contrast, if we use constants instead of properties, we get a union between three different values: Object literals with string-valued properties   # We need   in line A so that   isn’t  . Alas, it doesn’t change anything if the property values are symbols. Using string-valued properties is: \n Better at development time because we get exhaustiveness checks and a static type for the enum values. \n Worse at runtime because strings can be mistaken for enum values. \n Upsides and downsides of using object literals as enums   # Upsides: \n We have a namespace for the values. \n We don’t use a custom construct and are closer to plain JavaScript. \n Exhaustiveness checks are performed (if we use string-valued properties). \n There is a narrow type for enum values (if we use string-valued properties). \n Downsides: \n No dynamic membership check is possible (without extra work). \n Non-enum values can be mistaken for enum values statically or at runtime (if we use string-valued properties). \n Enum pattern   # The following example demonstrates  a Java-inspired enum pattern  that works in plain JavaScript and TypeScript: Alas, TypeScript doesn’t perform exhaustiveness checks, which is why we get an error in line A. Summary of enums and enum alternatives   # The following table summarizes the characteristics of enums and their alternatives in TypeScript: Titles of table columns: \n Unique values: No non-enum value can be mistaken for an enum value. \n Namespace for enum keys \n Is it possible to iterate over enum values? \n Membership check for values at compile time: Is there a narrow type for a set of enum values? \n Membership check for values at runtime.\n \n For the enum pattern, the runtime membership test is  . \n Note that a membership test can be implemented relatively easily if it is possible to iterate over enum values. \n \n \n Exhaustiveness check (statically by TypeScript) \n Footnotes in table cells: Discriminated unions are not really unique, but mistaking values for union members is relatively unlikely (especially if we use a unique name for the discriminant property). If the discriminant property has a unique enough name, it can be used to check membership. Acknowledgement   # \n Thanks to  Kirill Sukhomlin  for his suggestion on how to define   for an object literal. \n Further reading   # \n A class-based enum pattern for JavaScript \n TypeScript enums: How do they work? What can they be used for? \n Adding special values to types in TypeScript \n TypeScript: exhaustiveness checks via exceptions \n comments powered by Disqus."},
{"url": "https://2ality.com/2020/02/types-for-classes-typescript.html", "title": "Class-related types in TypeScript", "content": "Class-related types in TypeScript dev javascript typescript  Major rewrite of this blog post. In this blog post about TypeScript, we examine types related to classes and their instances. \n   \n     The two prototype chains of classes \n   \n   \n     Interfaces for instances of classes \n   \n   \n     Interfaces for classes \n     \n       \n         Example: converting from and to JSON \n       \n       \n         Example: TypeScript’s built-in interfaces for the class   and for its instances \n       \n     \n   \n   \n     Classes as types \n     \n       \n         Pitfall: classes work structurally, not nominally \n       \n     \n   \n   \n     Further reading \n   \n The two prototype chains of classes   # Consider this class: The following diagram shows the runtime structure of class  : There are two prototype chains of objects in this diagram: \n Class (left-hand side): The static prototype chain consists of the objects that make up the class  . The prototype object of class   is its superclass,  . \n Instance (right-hand side): The instance prototype chain consists of the objects that make up the instance  . The chain starts with the instance   and continues with   (which holds the prototype methods of the class) and   (which holds the prototype methods of class  ). \n In this blog post, we’ll first explore instance objects and then classes as objects. Interfaces for instances of classes   # Interfaces specify services that objects provide. For example: TypeScript’s interfaces work structurally : In order for an object to implement an interface, it only needs to have the right properties with the right types. We can see that in the following example: Structural interfaces are convenient because we can create interfaces even for objects that already exist (i.e., we can introduce them after the fact). If we know ahead of time that an object must implement a given interface, it often makes sense to check early if it does, in order to avoid surprises later. We can do that for instances of classes via  : Comments: \n TypeScript does not distinguish between inherited properties (such as  ) and own properties (such as  ). \n \n As an aside, private properties are ignored by interfaces and can’t be specified via them. This is expected given that private data is for internal purposes only. \n Interfaces for classes   # Classes themselves are also objects (functions). Therefore, we can use interfaces to specify their properties. The main use case here is describing factories for objects. The next section gives an example. Example: converting from and to JSON   # The following two interfaces can be used for classes that support their instances being converted from and to JSON: We use these interfaces in the following code: This is how we can check right away if class   (as an object) implements the interface  : The following way of making this check may seem like a good idea: However, this approach doesn’t really work: \n We can’t  -call   because   does not have a construct signature. \n If   has static properties beyond  , TypeScript won’t let us access them. \n Example: TypeScript’s built-in interfaces for the class   and for its instances   # It is instructive to take a look at TypeScript’s built-in types: On one hand, interface   is for class   itself: On the other hand, interface   is for instances of  : Classes as types   # Consider the following class: This class definition creates two things. First, a constructor function named   (that can be invoked via  ): Second, an interface named   that matches instances of  : Here is the proof that   really is an interface: Pitfall: classes work structurally, not nominally   # There is one pitfall, though: Using   as a static type is not a very strict check: Why doesn’t TypeScript complain in line A? That’s due to structural typing: Instances of   and of   have the same structure and are therefore statically compatible. We can make the two groups of objects incompatible by adding private properties: The private properties switch off structural typing in this case. Further reading   # \n Chapter “Classes”  in “JavaScript for impatient programmers” \n Blog post “Typing objects in TypeScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/what-is-javascript-equivalent-of-java.html", "title": "Does JavaScript have a bytecode, like Java?", "content": "Does JavaScript have a bytecode, like Java? dev javascript webdev jslang JavaScript myth: JavaScript needs a standard bytecode \nThe web and thus JavaScript is slowly turning into a  great platform . Part of the allure of the (partially) competing Java platform is that it has a core that goes beyond “Java the language”: The Java Virtual Machine (JVM). There are now  many languages  that target the JVM, for example:  Groovy ,  JRuby ,  Fantom ,  Jython ,  Scala ,  ABCL ,  Clojure , and  Gosu . Java class files store JVM programs as Java bytecode, a compact binary format that source code is compiled to. Does JavaScript have something similar?\n \n \nShort answer: No. The situation is as follows.\n \n      JavaScript engines have become so fast that it is viable to compile  other languages  to JS source. That is, we have virtual machines that are fed source code! Thus, for the purpose of storing and exchanging programs, JavaScript source code corresponds to Java bytecode. Parsing JavaScript is fast, so it does not present too much of a problem as an intermediate step.  There are also examples of compiling JavaScript (or something very similar) to JavaScript: the  Closure Compiler ,  Qooxdoo ,  CoffeeScript . Lastly,  GWT  even compiles a static language (Java) to a dynamic one (JavaScript). Recently,   [3] have allowed one to debug a language that is compiled to JavaScript in its source code. \n\n      I don’t think we could get browser vendors to agree to a common bytecode for all JavaScript virtual machines, because there is no common ground:\n         \n             JavaScript: Firefox, Safari and Internet Explorer each use different bytecode, Google’s V8 compiles directly to machine code. \n             Non-Javascript languages: Good virtual machines are usually designed specifically for a given programming language. This makes it even harder to find a bytecode that pleases all parties if one includes non-JavaScript languages. \n         \n        Thus, it is obvious why there is no common binary format and why JavaScript has no direct analog to Java class files. For faster loading, compactness, and possibly obfuscation, the abstract syntax tree could be used (an extreme way of minification, if you will). \n    \n       Minification can be used to reduce the size of source code. The simplest kind of minification is to remove comments. But further compression can be achieved. Take, for example, the following source code [source:  N. C. Zakas ].\n \n        This is reduced by  YUI Compressor  to\n \n        Zakas gives  more details .\n     \n\n \nRelated reading:\n Proper tail calls in Harmony Programming languages based on JavaScript VMs SourceMap on Firefox: source debugging for languages compiled to JavaScript [update: WebKit, too] comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/tom-demarco-on-collaborative-design.html", "title": "Tom DeMarco on “The Collaborative Design Imperative”", "content": "Tom DeMarco on “The Collaborative Design Imperative” dev software engineering Eight important books for software developers \n Examples of systems: the digestive system, the health care system, the global weather system, political systems, Linux, etc. \n A system is a complex interconnected set of components that act together to achieve some end. [It is arguable how much nature is driven by an end.] \n In software development, two things qualify as systems:\n                 \n the software product that your team is building \n the project that builds it \n \n \n \n Code as a set of messages from the project to the computer. \n Every bit that is in any of these messages has to have been inside a human brain at one time or another. \n \n Early estimation by von Neumann: 10 \n Later approach to estimation: How much data gets into the brain? Answer: Eye bandwidth (other channels are negligible) is about 10 Mbit/s, but we   much less.\n             \n This amounts to a brain capacity of about 1GB. \n \n \n Thus, we need to collaborate on large projects, to combine brain capacities. \n \n Natural systems: big pieces, tightly integrated [“big” as in “complex”]. For example, the human nervous system or hormonal system. We can never really understand natural systems like the two aforementioned ones, because they are too complex and too tightly integrated. \n Successful technical systems: small pieces, loosely integrated. \n \n Conceptual Design:  How a proposed system fits into, interacts with, and alters the reality that surrounds it.\n                 \n Team size: Fred Brooks (DeMarco: “my hero”) has a new book out: “ The Design of Design ”. In it, he writes that the optimal team size for doing conceptual design is one, at most two (if one of the two is dominant). \n \n \n Internal Design: Derivation of an optimal piece structure to achieve the chosen conceptual design\n                 \n Team size: Large teams are needed. \n \n \n Due to their size, many software projects set new records regarding human collaboration. This is ironic, as you need to be a loner to become a programmer. That is, you must like to work on problems on your own. [This is how things get started, the whole presentation is about the need to work in teams to really be productive.] \n \n Traditional maxim: “Trust is given as trustworthiness is demonstrated”. DeMarco: “Tell that to your kids! But it is a lie.” Instead: Trust must go ahead of demonstrated trustworthiness. You give trust to gain trust. It is how you motivate team members. This goes beyond what is generally considered “professional”. Professional bandwidth is not enough to exchange trust, social interaction is needed. He cites the difficulty to establish trust with outsourced colleagues. \n As an example, DeMarco says that he still remembers all six people in his life that ever gave him more trust than he had demonstrated to be worthy of [I’m guessing he is talking about bosses]. He says that he would follow them anywhere. \n \n I like the communication channel metaphor, it shows that it’s really hard to communicate our brains contents, because our interfaces are so limited. \n Knowledge can be increased brain-internally, by deriving new facts from old ones. I wonder how much that matters. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/faceted-navigation-of-data.html", "title": "Faceted navigation of data", "content": "Faceted navigation of data dev hci computers facets \nFaceted navigation combines a summary of those values with a way of selecting only those entities that have a given value. Faceted navigation is currently most prominently used in music programs. As an example, consider the following small database of songs:\n \nThe second role a facet plays is for navigation. It is based on the observation mentioned above that facets partition the set of faceted entities. For navigation, facet values are interpreted as  . Selecting a value shows only those entities where the facet has that value. After restricting the result set, one can continue to refine it by repeating the last two steps: One first computes the facet values as a summary of the restricted, smaller, set and then further restricts it by selecting from these values. For music, this kind of navigation is often hierarchical: One starts with genre, continues with artist, and then selects from the albums of that artist. But it works non-hierarchically, too. Several artists might collaborate for an album. Then it makes sense to look upwards in the “hierarchy”: Given an album, what are the artists?\n \nShopping websites frequently use tree-based navigation (but faceted navigation is becoming increasingly popular). Their trees force you into making your choices in a certain order: first choose shirt or pants, then choose male or female, then color. With faceted navigation, you can create the facets “function”, “gender”, “color” and start your choice at any of them. This can be seen as an on-demand generation of a tree, the remainder of this pseudo-tree is rearranged as you make your choices. Often, restrictions are shown in the order in which they have been made, for example:\n \nFaceted navigation works well as a complement to text search. Searching for text among the entries is a form of restriction. The computed summary now tells the user where the text appeared (in which albums etc.).\n \nRelated reading:\n \n     Try it out:  faceted navigation of the 2ality blog . \n     Faceted search  on Wikipedia \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/01/jquery-templates-quick-start-and-tips.html", "title": "jQuery Templates: quick start and tips", "content": "jQuery Templates: quick start and tips dev javascript webdev clientjs \nBefore you continue, you should probably read my  overview of templating , as it introduces several concepts relevant to this post. The example presented here shows a list of articles on an HTML page. Each article has a title and tags.\n \n \n makes sense \n \n \n     Input:  \n     Output:  } \n \n \n template overview \n \n \n \n \n \n \n     You can download the complete source code of the above example as the HTML file  tmpl_test.html . \n     jQuery Templates is  well documented . \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/paradox-of-choice-there-can-be-too-much.html", "title": "Choice is a paradox: there can be too much of it", "content": "Choice is a paradox: there can be too much of it psychology life The Paradox of Choice – Why More Is Less book \n More freedom ⇒ more welfare \n More choice ⇒ more freedom \n Thus: More choice ⇒ more welfare \n \n Three-fold increase in cereal brands in the 1990s. \n There used to be a telephony monopoly and a single phone model. Now you have many options and models. \n People self-medicate, make their own medical choices. \n People choose how they look via plastic surgery. If they are unattractive, it is  . \n Flexible work situations: your choice when to work and when not. A choice that you have to make frequently, because the tools are always there (smartphones). \n Marital and familial arrangements: nothing is set in stone. Generally positive, but also keeps people constantly worried.  \n \n Survey: “There is currently more choice than I need...” (Europe, consumer products). \n Answers: Clothing 65%, washing machines 80%, savings accounts 75%, utilities 75%, cars 80%, cleaning products 80%, cell phones 78%. \n No matter what product category, there was always a majority stating that there was too much choice. \n Paralysis \n 6 versus 24 flavors of jam on display at a shop. More people came to the table in the latter case, but only one tenth bought something. \n Writing essays for extra credit: 30 versus 6 available topics. Fewer people participated in the latter case. \n Speed dating: More matches are made if there are 6 choices than if there are 12. \n The number of mutual funds that an employer makes available affect the participation of employees: For every 10 funds, participation goes down 2%. \n \n Not participating meant passing up a significant amount of money (matching money). \n This runs counter to conventional wisdom. \n \n Effects of reducing the assortment of groceries: strong brands gain, higher-priced brands gain, store brands lose. Shoppers assess variety by how many units there are. One can reduce brands by 25% without a perceived decrease in variety, while customers buy more and report greater ease of shopping. \n 2 caveats: \n \n  No paralysis if you know beforehand   what you want\n (very rare). \n No paralysis if options are alignable on the \nsame scale (e.g. same product in different quantities). \n \n Decision and performance quality decreases. If there is too much to judge thoroughly, you adopt a simpler strategy. \n Example: If there were too many options for retirement funding, people more often put money into their savings account (wasting money). \n Decreased satisfaction. You do better, but feel worse. \n Study: digital CD players. People prefer a player with 21 features to one \nwith 7 (but admit decreased usability). After they have actually used both of them, they\n chose the simpler one. \n \n Regret. With many options you can easily image that something else would have been better. \n Opportunity costs. No choice is the best in all respects. The more alternatives there are, the easier one will identify attractive features that are missing from one’s choice. \n \n Study: Choice between $2 or a good pen. 75% choose the pen. Choice between $2, 1 good pen, 2 cheaper pens. 45% chose one of the two pen options. Explanation: None of the pen options was clearly better, so money was the easier choice. \n Study: When you ask someone what they would pay for a plane ticket, people are willing to pay more if asked directly (“How much would you pay for a ticket to Los Angeles?”) than if additionally mentioning alternatives (“There are many nice destinations in the US: Los Angeles, New York City, San Francisco. How much would you pay for a ticket to Los Angeles?). \n \n As an aside: When do people feel time pressure? If you ask one group what things they still have to do and another one what things they would still like to do, then the latter group felt more time pressure. \n Higher expectations with more options. \n Self-blame: With more options,   made the wrong choice. \n \n Study: Maximizers get better jobs, but they are more pessimistic, anxious, stressed, etc. \n \n Delegate your choices. The people making your choices for you don’t even have to vastly more knowledgeable or intelligent than you, just not having to make a choice pays off.  \n Libertarian \npaternalism . 28% of licensed drivers in the US are organ donors, 85% of Americans think that organ donation is good. In Europe: 90% are donors. Difference: organ donation is opt-in in the US and opt-out in Europe. \n \n Conclusion: Provide citizens with a choice, but ensure that if they\n do nothing, a choice is made for them that is in their best interest.  \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/six-things-javascript-needs-to-learn.html", "title": "Six things JavaScript needs to learn from Java", "content": "Six things JavaScript needs to learn from Java dev javascript jslang java  Java has acceptable inheritance built into the language (although primitives are a nuisance and traits or mixins would be nice). In JS, if you want to do inheritance, getting by with just the language is painful. Thankfully it is easy to extend it and that lead to some very nice inheritance APIs. But there are simply too many of them. And most of them are much too complex. The most minimalist yet elegant solution I have seen so far is John Resig’s Simple Inheritance [1]. \n  Similarly to inheritance, JS can be extended easily, but there is no common standard.  CommonJS  might find some mid-term traction, though.  I am not using the term “type annotations”, in order to avoid confusion with Java’s annotations. Having type information is natural in Java, because it is statically typed. JS is a more dynamic language and does not strictly need it. However, many APIs do include types as comments or in external specs. For example, Mozilla uses  Web IDL  in specs such as the  IndexedDB API . It would be nice to have the standardized option for adding this kind of information so that tools have something to work with.  Static analysis , e.g. done via  DoctorJS , can infer many types, but I would still like the option to add this information explicitly. As an aside, if an IDE did type inference, then I would love to see the inferred types, e.g., next to the formal parameters of a function.  Java has JavaDoc, JS has several competing standards.  JUnit is the dominant standard for unit testing in Java, while almost every JS framework comes with its own implementation.  While Java’s runtime library  is not perfect , having it is great. JS should have more standardized APIs and save JS frameworks from reinventing the wheel. An even better example of useful built-in functionality is the runtime library of Python. This would allow one to use JavaScript for many scripting tasks.  node.js packages  are an important start. ECMAScript 5 JS Harmony type guards Lightweight JavaScript inheritance APIs comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/es5-shim-use-ecmascript-5-in-older.html", "title": "es5-shim: use ECMAScript 5 in older browsers", "content": "es5-shim: use ECMAScript 5 in older browsers dev javascript jslang ECMAScript 5 es5-shim Narwhal module ECMAScript 5 compatibility table comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/javascript-variable-scoping-and-its.html", "title": "JavaScript variable scoping and its pitfalls", "content": "JavaScript variable scoping and its pitfalls dev javascript jslang \nThe   of a variable defines where the variable is accessible. For example, if a variable is declared at the beginning of a function, it is accessible from within that function, but not from outside and usually dies when the function is finished. In this case, the function is the scope of the variable. When a scope is entered, a new   is created that maps variable names to values. Scopes can be nested. A variable is accessible in its scope and in all scopes nested within that scope.\n \n  Most mainstream languages are block-scoped – new environments are created when entering a block and scopes are nested by nesting blocks. In contrast, JavaScript variables are function-scoped – new environments are only created when entering a function and scopes are nested by nesting functions. That means that even if you declare a variable inside a block such as the “then” block of an if statement, it is accessible everywhere in the surrounding function. The following code illustrates this.\n \n  Scoping in JavaScript is  , it is determined by the nesting of syntactic constructs. To ensure static scoping, the environment is attached to values that access variables in the environment. An example of such a value is the returned function in the following code.\n \n  Closures plus function-scoped variables lead to unexpected behavior. Given the following code.\n \n  In block-scoped programming languages the following would\nwork.\n Immediately Invoked Function Expression comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/efficiently-creating-javascript-objects.html", "title": "Efficiently creating JavaScript objects: closures versus prototypes", "content": "Efficiently creating JavaScript objects: closures versus prototypes dev javascript jslang Closure Versus Prototypal Pattern Deathmatch \n     Advantages of the closure pattern:\n         \n             You can encapsulate private data. \n         \n     \n     Advantages of the prototypal pattern: \n         \n             Going up the prototype chain is highly optimized in most JavaScript engines and happens fast. \n             You save space, because no closure has to be created and   is shared between objects (as opposed to added to each object). \n             I also find it more readable: Instance variables are defined in the constructor, instance methods are defined in the prototype. \n             Easier to analyze for tool builders. I feel for them, as they have to handle all of those JavaScript patterns and APIs out there. \n         \n     \n ECMAScript Harmony comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/what-should-be-on-your-business-card.html", "title": "What should be on your business card?", "content": "What should be on your business card? howto life business near field communication David Risley \n  Reuse logos, fonts, etc. from your blog, whenever it makes sense. \n  Sometimes people forget who a business card is from. A photo is very useful for reminding them. But it doesn’t have to be on your card (where it is difficult to get right). If your card links to your Facebook page or your homepage, then you should be fine. Your homepage should have your photo, anyway, because it’s important for figuring out who someone is. Don’t be shy about this. \n  You   use the back side of your card. But you don’t have to. I like empty back sides, because it allows either the giver or the receiver of a card to add notes. \n  Start with your homepage. All other sites can be linked to from there, so it is up to you what else you consider important: \n \n Twitter has replaced email for some people (not for me). Use a website link for Twitter, to give people that are not familiar with it a chance. \n More possibilities: your blog, Facebook, LinkedIn, Xing, etc. \n \n  Decide what you want to highlight. Your real-world data can instill confidence [ Philipp Rauschmayer ]. Or you might want to show all of your virtual identity, or just a part of it. Depending on how you live, either of the above can change quickly, so you need to factor that in when considering how long your business card should “last”. \n Seth Godin \n    If you do, it shows in two ways. The quality of the paper and the edges of the card. Color also tends to come out better if professionally printed. \n \n \n Don’t put too much content on your card.  \n There is not need to print “http://” before a URL, these days. People recognize what it is without that prefix, and so do web browsers. \n \n \n \n stick to one or two fonts  \n avoid big garish fonts \n don’t use underlines or bold and italics at the same time  \n if you use color, be subtle \n margins matter, don’t print too close to the edge \n use  proper dashes , curly quotes, and curly apostrophes \n \n \n Rethink your business card  [Various suggestions about what can be done with business cards.] \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/type-coercion.html", "title": "Type coercion in JavaScript", "content": "Type coercion in JavaScript dev javascript es spec In this blog post, we examine the role of   in JavaScript. We will go relatively deeply into this subject and, e.g., look into how the ECMAScript specification handles coercion. \n   \n     What is type coercion? \n   \n   \n     How internal type conversion functions are used in the ECMAScript specification \n     \n       \n         Converting to primitive types and objects \n       \n       \n         Converting to numeric types \n       \n       \n         Converting to property keys \n       \n       \n         Converting to Array indices \n       \n       \n         Converting to Typed Array elements \n       \n     \n   \n   \n     Intermission: expressing specification algorithms in JavaScript \n   \n   \n     Example coercion algorithms \n     \n       \n         \n       \n       \n          and related operations \n       \n       \n         \n       \n       \n          and related operations \n       \n     \n   \n   \n     Operations that coerce \n     \n       \n         Addition operator ( ) \n       \n       \n         Abstract Equality Comparison ( ) \n       \n     \n   \n   \n     Glossary: terms related to type conversion \n   \n What is type coercion?   # Each operation (function, operator, etc.) expects its parameters to have certain types. If a value doesn’t have the right type for a parameter, the two most common options for a caller are: \n They can explicitly convert the value so that it has the right type. For example, in the following interaction, we want to multiply two numbers that are written out in strings: \n \n They can let the operation make the conversion for them: \nThis kind of implicit conversion is called  . \n JavaScript initially didn’t have exceptions, which is why it uses coercion and error values for most of its operations: However, there are also cases (especially when it comes to newer features) where it throws exceptions if an argument doesn’t have the right type: \n \n Accessing properties of   or  : \n \n \n \n Using symbols: \n \n \n \n Mixing bigints and numbers: \n \n \n \n New-calling or function-calling values that don’t support that operation: \n \n \n \n Changing read-only properties (only throws in strict mode): \n \n \n How internal type conversion functions are used in the ECMAScript specification   # The following sections describe the most important internal functions used by the ECMAScript specification to convert actual parameters to expected types. For example, in TypeScript, you would write: In the specification, this looks  as follows  (translated to JavaScript, so that it is easier to understand): Converting to primitive types and objects   # Whenever primitive types or objects are expected, the following conversion functions are used: \n \n \n \n \n \n These internal functions have analogs in JavaScript that are very similar: Because we now have bigints in addition to numbers, the specification often uses   where it previously used  . Read on for more information. Converting to numeric types   # \n  is used whenever either a number or a bigint is expected. Execution is then forwarded to   (think method of the type of  ). \n  is used whenever a number without a fraction is expected. The range of the result is often restricted further afterwards.\n \n It uses   and removes the fraction (similar to  ). \n \n \n ,   coerce numbers to 32-bit integers and are used by bitwise operators (see table below).\n \n : signed, range [−2^31^, 2^31^−1] (limits are included) \n : unsigned (hence the  ), range [0, 2^32^−1] (limits are included) \n \n \n Coercion of bitwise operators for numbers (BigInt operators don’t limit the number of bits). Converting to property keys   #  returns a string or a symbol and is used by: \n The bracket operator  \n Computed property keys in object literals \n The left-hand side of the   operator \n \n \n \n \n \n Several methods of  \n Converting to Array indices   # \n  is used (directly) mainly for string indices.\n \n Helper function for  \n Range of result  : 0 ≤   ≤ 2^53^−1 \n \n \n  is used for Typed Array indices.\n \n Main difference with  : throws an exception if argument is out of range. \n Range of result  : 0 ≤   ≤ 2^53^−1 \n \n \n  is used for Array indices.\n \n Range of result  : 0 ≤   < 2^32^−1 (the upper limit is excluded, to leave room for the  ) \n \n \n Converting to Typed Array elements   # When you set the value of a Typed Array element, one of the following conversion functions is used: \n \n \n \n \n \n \n \n \n \n Intermission: expressing specification algorithms in JavaScript   # In the remainder of the post, we’ll encounter several specification algorithms, but “implemented” as JavaScript. \n Spec: If Type(value) is String\n \n JavaScript:   (very loose translation, defined below) \n \n \n Spec: If IsCallable(method) is true\n \n JavaScript:   (defined below) \n \n \n Spec: Let numValue be ToNumber(value)\n \n JavaScript:  \n \n \n Spec: Let isArray be IsArray(O)\n \n JavaScript:  \n \n \n Spec: If O has a [[NumberData]] internal slot\n \n JavaScript:  \n \n \n Spec: Let tag be Get(O, @@toStringTag)\n \n JavaScript:  \n \n \n Spec: Return the string-concatenation of \"[object \", tag, and \"]\".\n \n JavaScript:  \n \n \n Some things are omitted – for example, the  ReturnIfAbrupt shorthands    and  . Example coercion algorithms   #    # The operation   is an intermediate step for many coercion algorithms (some of which we’ll see later in this post). It converts an arbitrary values to primitive values.  is used often in the spec because many operations (eventually) only work with primitive values. For example, we can use the plus operator ( ) to add numbers and to concatenate strings, but we can’t use it to concatenate Arrays. This is what the JavaScript version of   looks like:  can have one of three values: \n  means: if possible,   should be converted to a number. \n  means: if possible,   should be converted to a string. \n  means: there is no preference for either numbers or strings. \n  lets objects override the conversion to primitive via  . If an object doesn’t do that, it is passed on to  : # Three property keys are relevant for the conversion to primitive values: \n  is preferred when   indicates that we’d like the primitive value to be a string. \n  is preferred when   indicates that we’d like the primitive value to be a number. \n  is for customizing the conversion to primitive. That is only done twice in the standard library:\n \n \n \n Returns the wrapped symbol. \n Exists to support two use cases:\n \n Symbols have a method   that returns a string. \n Instances of   should not be accidentally converted to strings. \n \n \n \n \n \n \n Explained in more detail soon. \n \n \n \n \n Let’s examine how   influences which property key is used: \n  calls   with   set to  : \n \n  calls   with   set to  : \n \n # These are a few examples of how various operations use  : \n . The following operations prefer numbers:\n \n \n \n ,  \n Abstract Relational Comparison ( ) \n \n \n . The following operations prefer strings:\n \n \n \n \n \n . The following operations are neutral w.r.t. the type of the returned primitive value:\n \n Abstract Equality Comparison ( ) \n Addition Operator ( ) \n  (  can be either a number or a string) \n \n \n As we have seen, the default behavior is for   being handled as if it were  . Only instances of   and   override this behavior. # This is how Dates handle being converted to primitive values: The only difference with the default algorithm is that   becomes   (and not  ). This can be observed if we use operations that set   to  : \n \n  coerces a Date to a string if the other operand is a primitive value other than  ,  , and  : \n \n \n \n If the first operand of   is a number, we can see that the second operand was coerced to a string because the result was computed via string concatenation (not via numeric addition): \n \n \n  and related operations   # This is the JavaScript version of  : Note how this function uses   as an intermediate step before converting the primitive result to a string (line A).  deviates in an interesting way from how   works: If   is a symbol, the former throws a   while the latter doesn’t. Why is that? The default for symbols is that converting them to strings throws exceptions: That default is overridden in   and   (both are described in the next sections): # In line A, we can see what happens if   is function-called and its argument is a symbol. We can also see that   works differently if it function-called and if it is new-called. The helper function   and   are shown next. # In addition to  , you can also use method   to convert a symbol to a string. Its specification looks as follows. # The default specification for   looks as follows: This operation is used if you convert plain objects to strings: By default, it is also used if you convert instances of classes to strings: You can configure what comes after “ ” inside the square brackets: If you call   directly, you can access the overridden behavior:    #  is used by, among others, the bracket operator. This is how it works: Once again, objects are converted to primitives before working with primitives.  and related operations   #  is used by, among others, by the multiplication operator ( ). This is how it works: #  works as follows: The structure of   is similar to the structure of  . Operations that coerce   # Addition operator ( )   # This is how JavaScript’s addition operator is specified: Steps of this algorithm: \n Both operands are converted to primitive values. \n If one of the results is a string, both are converted to strings and concatenated (line A). \n Otherwise, both operands are converted to numeric values and added (line B). \n Abstract Equality Comparison ( )   # The following operations are not shown here: \n \n \n \n Glossary: terms related to type conversion   # Now that we have taken a closer look at how JavaScript’s type coercion works, let’s conclude with a brief glossary of terms related to type conversion: \n \n In  , we want the output value to have a given type. If the input value already has that type, it is simply returned unchanged. Otherwise, it is converted to a value that has the desired type. \n \n \n  means that the programmer uses an operation (a function, an operator, etc.) to trigger a type conversion. Explicit conversions can be: \n \n : If a value can’t be converted, an exception is thrown. \n : If a value can’t be converted, an error value is returned. \n \n \n \n What   is, depends on the programming language. For example, in Java, it is explicit checked type conversion. \n \n \n  is implicit type conversion: An operation automatically converts its arguments to the types it needs. Can be checked or unchecked or something in-between. \n \n [Source:  Wikipedia ] comments powered by Disqus."},
{"url": "https://2ality.com/2019/11/object-property-attributes.html", "title": "Attributes of object properties in JavaScript", "content": "Attributes of object properties in JavaScript dev javascript oop In this blog post, we take a closer look at how the ECMAScript specification sees JavaScript objects. In particular, properties are not atomic in the spec, but composed of multiple   (think fields in a record). Even the value of a data property is stored in an attribute! \n   \n     The structure of objects \n     \n       \n         Internal slots \n       \n       \n         Property keys \n       \n       \n         Property attributes \n       \n     \n   \n   \n     Property descriptors \n     \n       \n         Retrieving descriptors for properties \n       \n       \n         Creating new properties via descriptors \n       \n       \n         Changing existing properties via descriptors \n       \n     \n   \n   \n     Pitfall: inherited read-only properties can’t be assigned to \n   \n   \n     API: property descriptors \n   \n   \n     Use cases for  \n     \n       \n         : copying properties into an object \n       \n       \n         : cloning objects \n       \n     \n   \n The structure of objects   # In the ECMAScript specification , an object consists of: \n , which are storage locations that are not accessible from JavaScript, only to operations in the specification. \n A collection of  . Each property associates a   with   (think fields in a record). \n Internal slots   # This is how the specification describes internal slots (the emphasis is mine): \n Internal slots correspond to internal state that is associated with objects and used by various ECMAScript specification algorithms. \n Internal slots are not object properties and they are not inherited. \n Depending upon the specific internal slot specification, such state may consist of values:\n \n of any ECMAScript language type or \n of specific ECMAScript specification type values. \n \n \n Unless explicitly specified otherwise, internal slots are allocated as part of the process of creating an object and may not be dynamically added to an object. \n Unless specified otherwise, the initial value of an internal slot is the value  . \n Various algorithms within this specification create objects that have internal slots. However,  . \n Internal methods and internal slots are identified within this specification using names enclosed in double square brackets  . \n There are two kinds of internal slots: \n Method slots for manipulating objects (getting properties, setting properties, etc.) \n Data slots with storage (listed in the table below) \n Descriptions for these data slots: \n  stores the prototype of an object.\n \n Can be changed via   and  \n \n \n  indicates if it is possible to add properties to an object.\n \n Can be set to   via  . \n \n \n  is used to manage  private class fields . \n Property keys   # The key of a property is either: \n A string \n A symbol \n Property attributes   # There are two kinds of properties and they have different attributes: \n A   stores data. Its attributes   holds any JavaScript value. \n An   has a getter function and/or a setter function. The former is stored in the attribute  , the latter in the attribute  . \n The following table lists all property attributes. We have already encountered the attributes  ,  , and  . The other attributes work as follows: \n  determines if the value of a data property can be changed. \n  determines if the attributes of a property can be changed. If it is  , then:\n \n You cannot delete the property. \n You cannot change a property from a data property to an accessor property or vice versa. \n You cannot change any attribute other than  . \n However, one more attribute change is allowed: You can change   from   to  . The rationale behind this anomaly is  historical : Property   of Arrays has always been writable and non-configurable. Allowing its   attribute to be changed enables us to freeze Arrays. \n \n \n  influences some operations (such as  ). If it is  , then those operations ignore the property. \n Property descriptors   # A   encodes the attributes of a property as a JavaScript object. Their TypeScript interfaces look as follows. The question marks indicate that each property is optional. If you omit a property when passing a descriptor to an operation, then its default value is used. Retrieving descriptors for properties   # The following code retrieves the object descriptor for the data property  : In the next example, we retrieve the property descriptor for the getter  : Using   in line A is a work-around so that   works. Creating new properties via descriptors   # You can also create new properties via property descriptors: Changing existing properties via descriptors   # If an own property already exists, then defining it via a descriptor changes that property. On one hand that allows us to use   like assignment: On the other hand, we can also use   to turn a data property into a getter (and vice versa): Pitfall: inherited read-only properties can’t be assigned to   # If an inherited property is read-only, then we can’t use assignment to change it. The rationale is that overriding an inherited property by creating an own property can be seen as non-destructively changing the inherited property. Arguably, if a property is non-writable, we shouldn’t be able to do that. Let’s look at an example: We can’t change the property via assignment. But we can still create an own property by defining it: Accessor properties that don’t have a setter are also considered to be read-only: API: property descriptors   # The following functions allow you to work with property descriptors: \n \n \n Creates or changes a property on   whose key is   and whose attributes are specified via  . Returns the modified object. \n \n \n \n \n The batch version of  . Each property of   holds a property descriptor. The keys of the properties and their values tell   what properties to create or change on  . \n \n \n \n \n First, creates an object whose prototype is  . Then, if the optional parameter   has been provided, adds properties to it – in the same manner as  . Finally, returns the result. For example, the following code snippet produces the same result as the previous snippet: \n \n \n \n \n Returns the descriptor of the own (non-inherited) property of   whose key is  . If there is no such property,   is returned. \n \n \n \n \n Returns an object where each property key   of   is mapped to the property descriptor for  . The result can be used as input for   and  . \n \n Using   in line A is a work-around so that   works. \n \n Use cases for     # : copying properties into an object   # Since ES6, JavaScript already has had a tool method for copying properties:  . However, this method uses simple get and set operations to copy a property whose key is  : That means that it only creates a faithful copy of a property if: \n Its attribute   is   and its attribute   is   (because that’s how assignment creates properties). \n It is a data property. \n The following example illustrates this limitation. Object   has a setter whose key is  . If we use   to copy property  , then the accessor property   is converted to a data property: Fortunately, using   together with   does faithfully copy the property  : # A method that uses   is firmly connected with its   (the object it is stored in). There is currently no way to copy or move such a method to a different object. : cloning objects   # Shallow cloning is similar to copying properties, which is why   is a good choice here, too. To create the clone, we use  : comments powered by Disqus."},
{"url": "https://2ality.com/2019/11/nodejs-streams-async-iteration.html", "title": "Easier Node.js streams via async iteration", "content": "Easier Node.js streams via async iteration dev javascript nodejs async Working with Node.js streams is much more pleasant if we use asynchronous iteration. This blog post explores how to do that. \n   \n     Recap: asynchronous iteration and asynchronous generators \n   \n   \n     Streams \n     \n       \n         Pipelining \n       \n       \n         Text encodings \n       \n       \n         Helper function:  \n       \n       \n         A few preliminary remarks \n       \n     \n   \n   \n     Readable streams \n     \n       \n         Creating readable streams \n       \n       \n         Reading from readable streams via  \n       \n       \n         Transforming readable streams via async generators \n       \n     \n   \n   \n     Writable streams \n     \n       \n         Creating writable streams for files \n       \n       \n         Writing to writable streams \n       \n     \n   \n   \n     Quick reference: stream-related functionality \n   \n   \n     Acknowledgement \n   \n   \n     Further reading and sources of this post \n   \n Recap: asynchronous iteration and asynchronous generators   # Asynchronous iteration  is a protocol for retrieving the contents of a data container asynchronously (meaning the current “task” may be paused before retrieving an item). Asynchronous generators  help with async iteration. For example, this is an asynchronous generator function: \n The   loop iterates over the input  . This loop is also available in normal asynchronous functions. \n The   feeds values into the asynchronous iterable that is returned by this generator. \n In the remainder of the blog post, pay close attention to whether a function is an async function or an async generator function: Streams   # A stream is a pattern whose core idea is to “divide and conquer” a large amount of data: We can handle it if we split it into smaller pieces and handle one portion at a time. Node.js supports several kinds of streams – for example: \n \n  are streams from which we can read data. In other words, they are sources of data. An example is a  , which lets us read the contents of a file. \n \n \n  are streams to which we can write data. In other words, they are sinks for data. An example is a  , which lets us write data to a file. \n \n \n A   is both readable and writable. As a writable stream, it receives pieces of data,   (changes or discards) them and then outputs them as a readable stream. \n \n Pipelining   # To process streamed data in multiple steps, we can   (connect) streams: Input is received via a readable stream. Each processing step is performed via a transform stream. For the last processing step, we have two options:\n \n We can write the data in the most recent readable stream into a writable stream. That is, the writable stream is the last element of our pipeline. \n We can process the data in the most recent readable stream in some other manner. \n \n Part (2) is optional. Text encodings   # When creating text streams, it is best to always specify an encoding: \n \n The Node.js docs have  a list of supported encodings and their default spellings  – for example: \n \n \n \n \n \n \n \n A few different spellings are also allowed. You can use   to check which ones are: \n \n \n The default value for encodings is  , which is equivalent to  . Helper function:     # We will occasionally use the following helper function. You don’t need to understand how it works, only (roughly) what it does. This function is implemented via the event-based API. We’ll later see a simpler way of doing this – via async iteration. A few preliminary remarks   # \n \n We’ll only use text streams in this post. \n \n \n In the examples, we’ll occasionally encounter   being used at the top level. In that case, we imagine that we are  inside a module  or inside the body of an async function. \n \n \n Whenever there are newlines, we support both: \n \n Unix:   (LF) \n Windows:   (CR LF) \n \n The newline characters of the current platform can be accessed via  the constant   in module  . \n \n Readable streams   # Creating readable streams   # # We can use   to create readable streams: # The static method   creates a readable stream which holds the data contained in  .   can be a synchronous iterable or an asynchronous iterable. The parameter   is optional and can, among other things, be used to specify a text encoding. #  accepts any iterable and can therefore also be used to convert strings to streams: At the moment ,   treats a string like any other iterable and therefore iterates over its code points. That isn’t ideal, performance-wise, but should be OK for most use cases. I expect   to be often used with strings, so maybe there will be optimizations in the future. Reading from readable streams via     # Every readable stream is asynchronously iterable, which means that we can use a   loop to read its contents: # The following function is a simpler reimplementation of the function that we have seen at the beginning of this blog post. Note that, in this case, we had to use an async function because we wanted to return a Promise. Transforming readable streams via async generators   # Async iteration provides an elegant alternative to transform streams for processing streamed data in multiple steps: \n The input is a readable stream. \n The first transformation is performed by an async generator that iterates over the readable streams and yields as it sees fit. \n Optionally, we can transform further, by using more async generators. \n At the end, we have several options for handling the async iterable returned by the last generator:\n \n We can convert it to a readable stream via   (which can later be piped into a writable stream). \n We can use an async function to process it. \n Etc. \n \n \n To summarize, these are the pieces of such processing pipelines: readable \n→ first async generator [→ … → last async generator] \n→ readable or async function In the following example, the final step is performed by the async function   which logs the items in an iterable to the console. Writable streams   # Creating writable streams for files   # We can use   to create writable streams: Writing to writable streams   # In this section, we look at three approaches to writing to a writable stream: Writing directly to the writable stream via its method  . Using method   of a readable stream to pipe it into the writable stream. Using function   from module   to pipe a readable stream into the writable stream. To demonstrate these approaches, we implement the same function   in three different ways. # The default version of   is callback-based but can be turned into a Promise-based version via   (line A). We used the following two patterns: \n \n Writing to a writable stream while handling backpressure (line B): \n \n \n \n Closing a writable stream and waiting until writing is done (line C): \n \n \n # We used the following pattern (line A): There is also  , but that method has  a caveat  (if the readable emits an error, then the writable is not closed automatically).   does not have that caveat. Quick reference: stream-related functionality   # Module  : \n \n   (since 0.7.8) \n Contains the end-of-line character sequence used by the current platform. \n \n Module  : \n \n   (since 0.9.1) \n Returns   if   correctly names one of the supported Node.js encodings for text.  Supported encodings  include: \n \n \n \n \n \n \n  (each byte as two hexadecimal characters) \n \n \n Module  : \n \n   (since 10.0.0) \n Readable streams are asynchronously iterable. For example, you can use   loops in asyc functions or async generators to iterate over them. \n \n \n   (since 10.0.0) \n The returned Promise is settled when reading/writing is done or there was an error. \n This promisified version is created as follows: \n \n \n \n   (since 10.0.0) \n Pipes between streams. The returned Promise is settled when the pipeline is complete or when there was an error. \n This promisified version is created as follows: \n \n \n \n   (since 12.3.0) \n Converts an iterable into a readable stream. \n \n These options are the same as the options for the   constructor and  documented  there. \n \n Module  : \n \n   (since 2.3.0) \n Creates a readable stream. More options are available. \n \n \n   (since 2.3.0) \n With option   you can specify if you want to write or append and what happens if a file does or does not exist. More options are available. \n \n The static type information in this section is based on  Definitely Typed . Acknowledgement   # \n Thanks to  @ehmicky  for telling me about several stream-related utility functions. \n Further reading and sources of this post   # \n Section “Streams Compatibility with Async Generators and Async Iterators”  in the Node.js docs \n Chapter “Async functions”  in “JavaScript for impatient programmers” \n Chapter “Asynchronous iteration”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/unison.html", "title": "Synching into cloud directories (Dropbox etc.) to ignore  node_modules", "content": "Synching into cloud directories (Dropbox etc.) to ignore  dev nodejs In this blog post, I describe how you can ignore   by bidirectionally syncing into a cloud directory (as managed via Dropbox etc.).  make sync services difficult to use   # Challenge: \n Especially with multiple devices, cloud syncing is really convenient and complements version control nicely. \n All sync services that I have tried, break down when faced with  , due to the sheer amount of small files. \n Possible solutions: Several Node.js package managers are exploring mostly eliminating  . This will be a good mid-term solution. Configuring sync services so that they ignore directories named  . Alas, the basic versions of Dropbox, iCloud, and Google Drive don’t let you do that at the moment. Bidirectionally synchronizing into a cloud directory and ignoring   while doing so. We’ll look into (3) next. Unison   # Unison  is a tool for bidirectional file synchronization that runs on macOS, Unix, and Windows. Its website describes how to install it. Caveat on macOS: If you want the watch mode to work, a tool called   must be available via the shell. I’m using autozimu’s  unison-fsmonitor  and it works well for me. The following shell script watches and syncs continuously: Options: \n : Unison watches both sync directories for changes and syncs incrementally when it detects any. \n : Resolve conflicts automatically. \n : Ignore the specified files during syncing. \n Bonus   # \n For now, I’m starting the script manually. Eventually, I want to do this automatically on macOS, via  launchd . \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/top-level-await.html", "title": "ECMAScript proposal: top-level  await", "content": "ECMAScript proposal: top-level  dev javascript es proposal The ECMAScript proposal  “Top-level  ”  by Myles Borins lets you use the asynchronous   operator at the top level of modules. Before, you could only use it in  async functions  and  async generators . \n   \n     Why   at the top level of a module? \n     \n       \n         Loading modules dynamically \n       \n       \n         Using a fallback if module loading fails \n       \n       \n         Using whichever resource loads fastest \n       \n     \n   \n   \n     Why work-arounds aren’t good enough \n     \n       \n         First attempt: immediately-invoked top-level async function \n       \n       \n         Second attempt: notifying importers via a Promise when exports are safe to use \n       \n       \n         Third attempt: putting exports in an object that is delivered via a Promise \n       \n       \n         Final attempt: top-level  \n       \n     \n   \n   \n     How does top-level   work under the hood? \n   \n   \n     The pros and cons of top-level  \n   \n   \n     Implementations \n   \n   \n     Further reading \n   \n Why   at the top level of a module?   # Why would we want to use the   operator at the top levels of modules? It lets us initialize a module with asynchronously loaded data. The next three subsections show three examples of where that is useful. Loading modules dynamically   # In line A, we  dynamically import  a module. Thanks to top-level  , that is almost as convenient as using a normal, static import. Using a fallback if module loading fails   # Using whichever resource loads fastest   # Due to  , variable   is initialized via whichever download finishes first. Why work-arounds aren’t good enough   # In this section, we attempt to implement a module that initializes its export via asynchronously loaded data. We first try to avoid top-level   via several work-arounds. However, all of those work-arounds have downsides. Therefore we end up with top-level   being the best solution. First attempt: immediately-invoked top-level async function   # The following module initializes its export   asynchronously: Instead of declaring and invoking an async function, we can also use an  : Note – we must always wrap the async arrow function in parentheses: \n The invocation parentheses cannot directly follow the body of the arrow function. \n Even in expression context, we cannot omit the parentheses around the arrow function. \n To see the downside of this approach, let’s try to use  : Directly after importing,   is   (line A). We must wait until the asynchronous work is finished before we can access it (line B). We need to find a way to do this reliably – our current approach is not safe. For example, it won’t work if   takes longer than 100 milliseconds. Second attempt: notifying importers via a Promise when exports are safe to use   # Importers need to know when it is safe to access the asynchronously initialized export. We can let them know via a Promise named  : The immediately-invoked async arrow function synchronously(!) returns a Promise that is fulfilled with   once the function terminates. The fulfillment happens implicitly, because we don’t return anything. Importers now wait for  ’s fulfillment and can then safely access  : This approach has several downsides: Importers must be aware of the pattern and use it correctly. It’s easy for importers to get the pattern wrong, because   is already accessible before   is fulfilled. The pattern is “viral”:   can only be imported by other modules if it also uses this pattern and exports its own Promise. In our next attempt, we’ll try to fix (2). Third attempt: putting exports in an object that is delivered via a Promise   # We want importers to not be able to access our export before it is initialized. We do that by default-exporting a Promise that is fulfilled with an object that holds our exports:  is used as follows: This new approach is better, but our exports are not static (fixed) anymore, they are created dynamically. As a consequence we lose all the benefits of a static structure (good tool support, better performance, etc.). While this pattern is easier to use correctly, it is still viral. Final attempt: top-level     # Top-level   eliminates all downsides of our most recent approach, while keeping all of the upsides: We still initialize our export asynchronously, but we do so via top-level  . We can import   without knowing that it has asynchronously initialized exports: The next section explains how JavaScript ensures under the hood that everything works properly. How does top-level   work under the hood?   # Consider the following two files. Both are roughly equivalent to the following code: JavaScript statically determines which modules are asynchronous (i.e., either a direct import or an indirect import has a top-level  ). All the Promises exported by those modules (and only those) are passed to  . The remaining imports are handled as usually. Note that rejections and synchronous exceptions are converted as in async functions. The pros and cons of top-level     # People already initialize modules asynchronously, via various patterns (some of which we have seen in this blog post). Top-level   is easier to use and makes async initialization transparent to importers. On the downside, top-level   delays the initialization of importing modules. Therefore, it‘s best to use it sparingly. Asynchronous tasks that take longer are better performed later, on demand. However, even modules without top-level   can block importers (e.g. via an infinite loop at the top level), so blocking per se is not an argument against it. Implementations   # Support for top-level  : \n V8: supports it behind the command line flag  .  This is the relevant issue. \n \n It may take a while until the feature is available in Chromium. \n But the flag   works in Node.js 13.3+. \n \n \n Webpack supports it behind a flag. \n Parser support has been added to Babel ( pull request ). \n Further reading   # \n The top-level   proposal  was an important source of this blog post. Is is very well written and quite readable. \n Section “Loading modules dynamically via  ”  in “JavaScript for impatient programmers” \n Chapter “Async functions”  in “JavaScript for impatient programmers” \n Chapter “Asynchronous iteration”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/promise-any.html", "title": "ES2021:  Promise.any()", "content": "ES2021:  dev javascript es2021 The ECMAScript proposal  “Promise.any()”  (by Mathias Bynens, Kevin Gibbons, and Sergey Rubanov) introduces a new Promise combinator for JavaScript. This blog post explains how it works. Background information   # The following two sources contain background information that may be useful for understanding this blog post: \n Blog post  “JavaScript Promise combinators:  ,  ,  ” \n Chapter  “Promises for asynchronous programming”  of “JavaScript for impatient programmers” \n    # This is the type signature of  :  returns a Promise  . How it is settled, depends on the parameter   (which refers to an iterable over Promises): \n If and when the first Promise is fulfilled,   is resolved with that Promise. \n If all Promises are rejected,   is rejected with an instance of   that contains all rejection values. \n This is the type signature of   (a few members were omitted): The following diagram illustrates how   works: This is what happens if one Promise is fulfilled: This is what happens if all Promises are rejected:  vs.     # There are two ways in which   and   can be compared: \n They are inverses of each other:\n \n : First input rejection rejects the result Promise or its fulfillment value is an Array with input fulfillment values. \n : First input fulfillment fulfills the result Promise or its rejection value is an Array with input rejection values. \n \n \n The have different focuses:\n \n  is interested in   fulfillments. The opposite case (at least one rejection) leads to a rejection. \n  is interested in the first fulfillment. The opposite case (only rejections) leads to a rejection. \n \n \n  vs.     #  and   are also related, but interested in different things: \n  is interested in settlements. The Promise which is settled first, “wins”. In other words: We want to know about the asynchronous computation that terminates first. \n  is interested in fulfillments. The Promise which is fulfilled first, “wins”. In other words: We want to know about the asynchronous computation that succeeds first. \n The main – relatively rare – use case for   is  timing out Promises . The use cases for   are broader. We’ll look at them next. Use cases for     # We use   if we have multiple asynchronous computations and we are only interested in the first successful one. In a way, we let the computations compete with each other and use whichever one is fastest. The following code demonstrates what that looks like when downloading resources: We can use the same pattern to use whichever module downloads more quickly: For comparison, this is the code we’d use if the secondary server is only a fallback – in case the primary server fails: How would we implement  ?   # A simple implementation of   is basically a mirror version of an implementation of  .  Check out the code in the blog post on Promise combinators for more information. Support for     # \n The npm package   provides a polyfill. \n For the status of other implementations, please consult  the feature proposal . \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/string-prototype-replaceall.html", "title": "ES2021:  String.prototype.replaceAll", "content": "ES2021:  dev javascript es feature es2021 The normal string method   only lets you replace one occurrence if you search for string (and not a regular expression with the flag  ).  The proposal “ ”  (by Peter Marshall, Jakob Gruber, Mathias Bynens) fixes that. : the status quo   # Let’s look at three options for replacing that we currently have. First, we can search for a string and replace the first occurrence: Second, we can search for a regular expression with the flag   and replace all occurrences: Third, we can convert a string into a regular expression with flag   and replace all occurrences: “JavaScript for impatient programmers” has  a few more details on  . : replacing strings multiple times   # The proposed string method   provides one service that   can’t: Searching for a string and replacing all occurrences:  throws an exception if we use a regular expression that does not have the flag  . The assumption is that we made a mistake and should switch to   if we really only want to replace the first occurrence. The following code demonstrates that: Other than that,   works like  . This table summarizes the differences between   and  : Implementations   # \n Polyfills:\n \n \n \n \n \n Support in JavaScript engines:  Keep an eye on the proposal for updates . \n Further reading   # \n Section “Flag   and its pitfalls”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/ecmascript-2020.html", "title": "ECMAScript 2020: the final feature set", "content": "ECMAScript 2020: the final feature set dev javascript es2020  Today,  the ES2020 candidate  was released, with the final feature set of that version. This blog post describes what’s new. A word on ECMAScript versions   # Note that since  the TC39 process  was instituted, the importance of ECMAScript versions has much decreased. What really matters now is what stage a proposed feature is in: Once it has reached stage 4, it can be used safely. But even then, you still have to check if your engines of choice support it. The features of ES2020 (stage 4 proposals)   # \n  (Jordan Harband) \n  (Domenic Denicola) \n  (Domenic Denicola) \n BigInt – arbitrary precision integers  (Daniel Ehrenberg) \n  (Jason Williams, Robert Pamely, Mathias Bynens) \n  (Jordan Harband) \n  mechanics (Kevin Gibbons) [ proposal ] \n Optional chaining  (Gabriel Isenberg, Claude Pache, Dustin Savery) \n Nullish coalescing Operator  (Gabriel Isenberg) \n \n FAQ   # What do the stages mean?   # They refer to maturity stages of the so-called “TC39 process”. Check  section “The TC39 process”  in “JavaScript for impatient programmers” for more information. How is [my favorite proposed feature] doing?   # If you are wondering what stages various proposed features are in, consult  the readme of the ECMA-262 GitHub repository . Is there an official list of ECMAScript features?   # Yes, the TC39 repo lists  finished proposals  and mentions in which ECMAScript versions they are introduced. Free books on ES2021   # The following books cover JavaScript up to and including ECMAScript 2021 and are free to read online: \n “JavaScript for impatient programmers” \n “Deep JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/11/creating-class-instances.html", "title": "Techniques for instantiating classes", "content": "Techniques for instantiating classes dev javascript oop In this blog post, we examine several approaches for creating instances of classes: Constructors, factory functions, etc. We do so by solving one concrete problem several times. The focus of this post is on classes, which is why alternatives to classes are ignored. \n   \n     The problem: initializing a property asynchronously \n   \n   \n     Solution: Promise-based constructor \n     \n       \n         Using an immediately-invoked asynchronous arrow function \n       \n     \n   \n   \n     Solution: static factory method \n     \n       \n         Improvement: private constructor via secret token \n       \n       \n         Improvement: constructor throws, factory method borrows the class prototype \n       \n       \n         Improvement: instances are inactive by default, activated by factory method \n       \n       \n         Variant: separate factory function \n       \n     \n   \n   \n     Subclassing a Promise-based constructor (advanced) \n   \n   \n     Conclusion \n   \n   \n     Further reading \n   \n The problem: initializing a property asynchronously   # The following container class is supposed to receive the contents of its property   asynchronously. This is our first attempt: Key issue of this code: Property   is initially  . In line A, we declare the  private field    that we use in line B and line C. The Promise inside the constructor of   is settled asynchronously, which is why we can only see the final value of   if we finish the current task and start a new one, via  . In other words, the instance of   is not completely initialized, yet, when we first see it. Solution: Promise-based constructor   # What if we delay access to the instance of   until it is fully initialized? We can achieve that by returning a Promise from the constructor. By default, a constructor returns a new instance of the class that it is part of. We can override that if we explicitly return an object: Now we have to wait until we can access our instance (line B). It is passed on to us one the data was “downloaded” (line A). There are two possible sources of errors in this code: \n The download may fail and produce a rejection. \n An exception may be thrown in the body of the first   callback. \n In either case, the errors become rejections of the Promise that is returned from the constructor. Pros and cons: \n A benefit of this approach is that we can only access the instance once it is fully initialized. And there is no other way of creating instances of  . \n A disadvantage is that it may be surprising to have a constructor return a Promise instead of an instance. \n Using an immediately-invoked asynchronous arrow function   # Instead of using the Promise API directly to create the Promise that is returned from the constructor, we can also use an asynchronous arrow function that  we invoke immediately : Solution: static factory method   # Our next attempt is to implement a  . That is,   now has the static method   which returns Promises for instances of  : Pros and cons: \n A benefit of this approach is that the constructor becomes simple. \n A disadvantage of this approach is that it’s now possible to create instances that are incorrectly set up, via  . \n Improvement: private constructor via secret token   # If we want to ensure that instances are always correctly set up, we must ensure that only   can invoke the constructor of  . We can achieve that via a secret token: Assuming that   and   reside in the same module, outside parties don’t have access to   and therefore can’t create instances of  . Pros and cons: \n Benefit: safe and straightforward. \n Disadvantage: slightly verbose. \n Improvement: constructor throws, factory method borrows the class prototype   # The following variant of our solution disables the constructor of   and uses a trick to create instances of it another way (line A): Internally, an instance of   is any object whose prototype is  . That’s why we can create instances via   (line A) and that’s why   works in line B. Pros and cons: \n Benefit: elegant;   works. \n Disadvantages:\n \n Creating instances is not completely prevented. To be fair, though, the work-around via   can also be used for our previous solutions. \n We can’t use  private fields  and  private methods  in  , because those are only set up correctly for instances that were created via the constructor. \n \n \n Improvement: instances are inactive by default, activated by factory method   # Another, more verbose variant is that, by default, instances are switched off via the flag  . The initialization method   that switches them on cannot be accessed externally, but   can invoke it: The flag   is enforced via the private method   which must be invoked at the beginning of every method. The major downside of this solution is its verbosity. There is also a risk of forgetting to invoke   in each method. Variant: separate factory function   # For completeness sake, I’ll show another variant: Instead of using a static method as a factory you can also use a separate stand-alone function. Stand-alone functions as factories are occasionally useful, but in this case, I prefer a static method: \n The stand-alone function can’t access private members of  . \n I prefer the way   looks. \n Subclassing a Promise-based constructor (advanced)   # In general, subclassing is something to use sparingly. With a separate factory function, it is relatively easy to extend  . Alas, extending the class with the Promise-based constructor leads to severe limitations. In the following example, we subclass  . The subclass   has its own private field   that it initializes asynchronously by hooking into the Promise returned by the constructor of its superclass. Alas, we can’t instantiate this class: Why the failure? A constructor always adds its private fields to its  . However, here,   in the subconstructor is the Promise returned by the superconstructor (and not the instance of   delivered via the Promise). However, this approach still works if   does not have any private fields. Conclusion   # For the scenario examined in this blog post, I prefer either a Promise-based constructor or a static factory method plus a private constructor via a secret token. However, the other techniques presented here can still be useful in other scenarios. Further reading   # \n Asynchronous programming:\n \n Chapter “Promises for asynchronous programming”  in “JavaScript for impatient programmers” \n Chapter “Async functions”  in “JavaScript for impatient programmers” \n Section “Immediately invoked async arrow functions”  in “JavaScript for impatient programmers” \n \n \n OOP:\n \n Chapter “Classes”  in “JavaScript for impatient programmers” \n Blog post “ES proposal: private class fields” \n Blog post “ES proposal: private methods and accessors in JavaScript classes” \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/12/regexp-match-indices.html", "title": "ECMAScript proposal: RegExp match indices", "content": "ECMAScript proposal: RegExp match indices dev javascript es proposal \n  Important change: RegExp match indices must now explicitly be switched on via the RegExp flag   ( ).\n \n RegExp match indices are supported by V8 v9.0 and later ( source ). \n \n \n The ECMAScript proposal “RegExp match indices”  (by Ron Buckton) adds more information to regular expression match objects (as returned by   and other methods): They now record for each captured group where it starts and where it ends. Read on for more information. Match objects   # The following methods match regular expressions against strings and return match objects if they succeed: \n  returns   or single match objects. \n  returns   or single match objects (if flag   is not set). \n  returns an iterable of match objects (flag   must be set; otherwise, an exception is thrown). \n The key responsibility of a match object is to store the captures that were made by groups. Numbered groups   # This is how we access what the numbered groups of a regular expression captured: The proposal now also gives us the start and end indices of what was matched, via  : Named groups   # The captures of named groups are accessed likes this: Their indices are stored in  : Multiple match objects   #  returns an iterable of match objects. With the proposal, each one includes indices. Note that we are using named groups, but each named group also leads to a numbered capture. A realistic example   # One important use case for match indices are parsers that point to where exactly a syntactic error is located. The following code solves a related problem: It points to where quoted content starts and where it ends (see demonstration at the end). Note that we do not handle Unicode graphemes with more than one code unit correctly. That is, this code only works when each printable glyph is represented by one code unit (JavaScript character). Support for this feature   # \n The npm package   provides a polyfill. \n V8 issue: “Implement RegExp match offsets proposal” \n \n You can activate the experimental implementation in Node.js via the flag  . \n \n \n Further reading   # \n Chapter “Regular expressions ( )”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/david-herman-on-ecmascriptnext.html", "title": "David Herman on ECMAScript.next", "content": "David Herman on ECMAScript.next esnext dev javascript a video of his talk \nRoadmap for ECMAScript.next:\n \n     Spring 2011: proposal freeze (no more proposals allowed) \n     2013 (roughly): spec finished, parts will be in browsers before that. \n     opt-in via MIME type in script tag:   (where “ ” is a placeholder for something that has still to be determined) \n \n Fixes: removing quirks \n Expressiveness: support better, more concise idioms \n Power: doing what couldn’t previously be done \n Fixes \n Eliminate the arguments variable:\n \n \n Extending typeof: \"null\" for null (currently \"object\") \n Don’t auto-create global variables (already in strict mode [2]) \n Block-scoping, not function-scoping [3], via   (“let is the new var”) \n Expressiveness \n     Old:  \n     New:  \n     Non-methods don’t have implicit   argument, any more. Must declare explicitly that you expect   in sharp functions.\n \n Power \n Proper tail calls. Use case: If you tail-call a function, it can determine what to do next, via another tail call. Not needed often, but useful.     \n \n    Binary data via structured types: can be read from a binary stream, complement typed arrays.\n     \n \n Proxies: create an object with a handler that implements all ways of accessing the object (reading a property, writing a property, invoking a method, etc.). Use cases: logging, remoting. \n Module loaders: implement custom semantics for modules (e.g. CoffeeScript modules, Python modules, static checking of JavaScript, etc.). \n Related posts Brendan Eich’s dream for the next version of JavaScript JavaScript’s strict mode: a summary JavaScript variable scoping and its pitfalls comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/commit-messages-indicate-what.html", "title": "Commit messages indicate what programming languages make people swear the most", "content": "Commit messages indicate what programming languages make people swear the most programming languages dev Cussing in Commits: Which Programming Language Inspires the Most Swearing? \n C++ takes top honors, but just barely. \n Ruby and JavaScript are neck and \nneck behind C++. \n After that it drops off considerably with C, Java and \nC# placing in the middle. \n Python and PHP developers are either very \nhappy about using those languages, or perhaps just very mild-mannered \ndevelopers. \n \n The top swearword-inducing programming languages are those that give you many different ways of doing the same thing. Be it DSL-supporting language constructs in Ruby or patterns in JavaScript. My guess is that these programming languages tend to accentuate programming style. Programming style being an emotional topic, this leads to strong reactions. \n \n I find it hard to get past my own taste. One example that is actually minor, but always gets me, is where \npeople put the opening brace (e.g. in Java or JavaScript). I hate \nit when it isn’t in the same line as the brace-opening \nstatement. Yet there is no rational reason for this, just my taste. To me, it just  . \n \n A problem with JavaScript might also be that many people don’t really understand the language yet. If you are aware of the quirks and oddities, it starts to make sense. This will get better, because the stated goal for  future versions  is quirk-elimination. \n I don’t trust programmers who swear a lot. It often has to do with ignorance. Yes, you hate that piece of code, but there is a reason it is there. Even very good programmers frequently write bad code. My own experience is that only iterations and code reviews lead to good code. \n The article’s favorite commit message: “fuck it. let’s release.”. Funny. \n \n   Guess what programming language grew most in popularity in 2010? \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/02/die-zweite-stammstrecke-schlecht-fur.html", "title": "Die zweite Stammstrecke: schlecht für München", "content": "Die zweite Stammstrecke: schlecht für München politics life münchen S-Bahn: Das Aus für die zweite Stammstrecke! Martin Runge \n\nGrundlage der Entscheidung für die zweite Stammstrecke und gegen den Südring war\nein vergleichendes Gutachten, auf das im folgenden mehrmals Bezug\ngenommen wird.\n\n \n\n \n \n  Das vergleichende Gutachten macht viele falsche Annahmen, z.B. was den Autoverkehr in die Innenstadt anbelangt. Außerdem wurden einige Punkte aus Kostengründen wieder aus dem Vorschlag gestrichen, werden aber immer noch als Vorteile gewertet.   \n  Selbst wenn man das Gutachten beim Wort nimmt, würden die Kosten\n bedeuten, dass Geld aus dem gesamten Bayern abgezogen wird und u.a.\nnicht mehr für wichtige Projekte in Münchens Vororten zur Verfügung\nsteht, wie dem Ausbau der S-Bahn. \n  Um die Kosten für die 2. Ststr. niedrig zu halten, wird es auf einigen Linien Taktverschlechterungen geben. Dafür werden Express S-Bahnen hinzugenommen. \n  Im Laufe der Planungen wurde klar, wie teuer alles werden würde. Folglich wurde bei Qualität und Sicherheit gespart. \n \n Weniger Haltestellen als ursprünglich geplant. \n Riskante Einsparungen bei der Sicherheit (lange, enge, komplizierte Fluchtwege, Löschpunkte sind nicht dauernd mit Wasser versorgt, keine automatische Rauchabführung, etc.). Es muss tiefer gegraben werden, als ursprünglich gedacht, was die Sicherheitsbedenken erhöht. \n \n  Gerade beim Bauabschnitt Haidhausen gibt es viele Unwägbarkeiten, sowohl rechtlicher, als auch bautechnischer Natur. Momentane Schätzungen gehen von einem Bauende um 2034 aus, wenn nicht später. Selbst wenn Unterstützer der Stammstrecke sie für Olympia 2018 (so es denn kommt) fertig sehen wollen, dann geben sie zu, dass das ein “ehrgeiziges Ziel” sei. Klartext: nicht realistisch. \n  Der Einsatz von Langzügen würde genügen, dafür ist aber momentan kein Geld da. Hauptproblem ist die große Zug-Anzahl die Münchens Westen benötigt, während die 2. Ststr. auch dem Osten hohe Kosten zumuten würde. Das Nadelöhr Laim-Pasing würde nicht aufgehoben. \n  Ein anfälliger Punkt am Ostbahnhof ist   der Abzweigung der 2. Ststr. Wenn dort also etwas passiert, sind beide Stammstrecken unbenutzbar. \n   \n  Die 2. Ststr. hat in Berlin wenig Befürworter, viele münchner Verbände sind dagegen, in diverse Gremien hat sich die Stimmung geändert. \n  Diese besteht u.a. aus Bauunternehmen und hat wohl Einfluss auf das Gutachten genommen. \n \n , um Druck vom Stadtzentrum zu nehmen und die Attraktivität anderer Gebiete zu erhöhen. \n  Sogar billiger als vom Gutachten geschätzt. Es gibt zudem abgespeckte Versionen, die noch weniger kosten. \n \n  Es gibt mehrere Töpfe, aus denen finanziert werden könnte, da auch Fernverkehr involviert ist.  \n \n  Eine echte Nahverkehrstangente ist wichtig für München. Jede andere größere deutsche Stadt hat eine.  \n  Alle relevanten Bezirksausschüsse haben sich für den Südring ausgesprochen. Im Gegensatz zu Haidhausen (bei der 2. Ststr.) haben die Anwohner zwei klare Vorteile: Bessere Nahverkehrserschliessung und besserer Lärmschutz (der bei einem Ausbau erstmals rechtlich notwendig wird). \n \n  Teilnehmen an der öffentlichen Diskussion. \n Schreiben an die Abgeordneten (Kommune, Land, Bund), damit sie die Stimmung der Wähler mitbekommen. \n Schreiben an Münchens Oberbürgermeister,  Christian Ude . \n S-Bahn München Quelle Quelle “ Nahverkehr – Viele Fahrgäste, wenig Züge ” [Der Ausbau der S4 nach Buchenau wird aufgeschoben, u.a. wegen der Kosten für die zweite Stammstrecke.] “ Zweite Stammstrecke zuerst - S-4-Ausbau muss zurückstehen ”. Die Überschrift sagt bereits alles. Zitat, bezugnehmend auf Vorschläge, die S4 auszubauen: \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/mac-tip-remount-ejected-storage-device.html", "title": "Mac tip: remount an ejected storage device (without unplugging)", "content": "Mac tip: remount an ejected storage device (without unplugging) apple hack computers mac comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/gender-neutral-pronouns-in-english.html", "title": "Gender-neutral pronouns in English", "content": "Gender-neutral pronouns in English english life possessive pronoun \n The user has to click on his/her name. The user has to click on their name. \n\n Five Grammar Myths... And Whether They Matter comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/javascript-values-not-everything-is.html", "title": "JavaScript values: not everything is an object", "content": "JavaScript values: not everything is an object dev javascript jslang \nThis blog post explains that JavaScript has two main kinds of values: primitive values and objects. There are several things one needs to be aware of when working with them.\n \n Kinds of values: primitives versus objects The definition \n     Strings:  \n     \n     Numbers:  ,   (all numbers in JavaScript are floating point)\n     \n     Booleans:  ,  \n     \n     : usually explicitly assigned\n     \n     : usually a default value, automatically assigned\n     \n \n     Wrappers for primitives:  ,  ,  . Rarely used directly.\n     \n     Creatable by literals. The following literals produce objects that can also be created via a constructor. Use literals whenever you can.\n         \n              is the same as  \n              is the same as  \n              is the same as  \n              is the same as  \n         \n     \n     Dates:  \n     \n Different natures \n     \n \n     \n      Every object you create via an expression such as a constructor or a literal is considered different from every other object; a fact that can be observed via the equality operator (===). That operator compares objects  : two objects are only equal if they have the same identity. It does not matter whether they have the same content or not.\n \n     \n    \n      Thus, two variables can refer to the same object – changes you make via one variable can be observed via the other variable.\n \n        \n     \n \n      any property you add will be immediately forgotten.\n \n     \n      To compare two primitives, one looks at their values, their content. If their values are the same then they are considered equal.\n \n        That means that the identity of a primitive is its value, it does not have an individual identity.\n     \n Pitfall: Primitive values and their wrappers \n Primitive to wrapper:  \n Wrapper to primitive:  \n Primitive values don’t have methods of their own strict mode The Secret Life of JavaScript Primitives Categorizing values: typeof and instanceof typeof \n \nComments:\n \n     Returning   for   is a well-known bug that can’t be fixed, because it would break existing code. That does not mean that   is actually an object  [4] . \n      allows you to check whether a variable has been declared, without throwing an exception. No function can possibly do that, because you can’t pass it such a variable.\n \n     \n     Functions are actually objects; giving them their own category is a bit inconsistent, but sometimes useful. \n     Arrays are objects and correctly categorized as such. \n [5] [6] instanceof Related content JavaScript’s strict mode: a summary An easy way to understand JavaScript’s prototypal inheritance JavaScript: converting any value to an object “ null is not an object ” – comment on Stack Overflow. What is JavaScript’s typeof operator used for? Improving the JavaScript typeof operator comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/web-sites-dynamic-page-extension-versus.html", "title": "Web sites: dynamic page extension versus paged navigation", "content": "Web sites: dynamic page extension versus paged navigation dev hci webdev computers \n Dynamic page extension: New content is appended to the current page. Examples: \n \n DZone  and  normal Twitter  recognize when you\n are close to the end of the page and add new entries. \n \n Mobile Twitter  has a\n link at the end of the page to “show more”. \n \n Paged navigation: New content is shown on a new page. Example: Google’s search results. \n \n \n \n  You can return to where you currently are via a bookmark. Naturally, care has to be taken so that URLs are stable. For example, page numbers that count back from the current entry are not stable. Page number two will contain different entries as soon as the current entry changes. \n  Keeping pages small saves resources. This matters especially on mobile browsers. \n  On one hand, there is less content to scroll. On the other hand, you can actually scroll to the end of the page, as a location. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/lightweight-javascript-inheritance-apis.html", "title": "Lightweight JavaScript inheritance APIs", "content": "Lightweight JavaScript inheritance APIs dev javascript jslang \nWhat does an API look like that helps us with inheritance, but otherwise changes JavaScript as little as possible? We use the name “object factory” for a construct that allows us to create objects. Here are the required pieces of an API:\n \n      Having a single construct means less clutter. Conversely, defining a constructor function in traditional JavaScript is always a two-step process: Function first, prototype second. \n      As a result, code that uses the API looks familiar and is thus easier to understand. \n      Methods usually fall into the former category, data properties usually fall into the latter. These definitions are what object creation is all about. \n      Tricky in traditional JavaScript, so we want an API to help us. \n      Adding methods to the   property of a constructor function is common practice in JavaScript and should be supported by an API. \n      Verbose in traditional JavaScript. \n      There needs to be a way for testing whether an object is an instance of a given object factory. \n Traditional JavaScript \n      must be an object whose prototype is  . We solve this problem by using ECMAScript 5’s   (which is explained in the next section). An often-used more traditional solution is to assign  , but then   has the instance variables of   which are redundant. \n     An instance of   must have the instance variables of  , in addition to its own. We solve this be letting the   constructor invoke the   constructor, but without the   operator. Thus, no new instance is created, but   still adds its instance variables as required. \n     Invoking super-methods. We have to directly refer to the super-method (which is part of the super-prototype) to do so. \n     Enabling  :   works by checking whether   is in the prototype chain of  . Thus, instead of  , we could have written  .   is an ECMAScript 5 method. \n ECMAScript 5 \n  A property in ECMAScript can have the following characteristics:\n \n     There are three kinds of properties:\n         \n             A   is a normal property in an object where it associates a name with a value. \n             A   is a property where access is handled via a getter and a setter method. The property value might be computed and thus not stored anywhere. \n             An   is managed by the JavaScript engine and might not be accessible at all via JavaScript, or only indirectly. For example, the prototype of an object is not writable in many JavaScript engines and only accessible via  . \n         \n         Property attributes: There are three boolean flags that determine how a property works.\n             \n                 writable: if true, the value of a property can be changed \n                 enumerable: if false, the property is hidden in some contexts \n                 configurable: if true, the property can be deleted, its attributes can be changed, and it can be changed from a data property to an accessor property (or vice versa) \n             \n         \n    \n     Own versus inherited: Own properties are directly contained in  , inherited properties are accessible via the prototype chain. \n \n     : assign the value of a data property \n     ,  : Assign the getter and setter of an accessor property. \n     ,  ,  : Set the corresponding property attributes. The default is for all attributes to be  . \n \n  We don’t use constructors to create instances, but normal functions (no   or  ). These functions can be called   and use   to create objects that have a common prototype.\n \n  Inheritance needs to take care of two things: the prototype and the instance. A super-prototype is extended by prepending the sub-prototype. That is, the super-prototype becomes the sub-prototype’s parent. Thus, the super-prototype must be accessible from the sub-factory. Ensuring the presence of both super-properties and sub-properties in an instance is more complicated. A naive thought might be to make the super-property-descriptors available to the sub-factory, but then we cannot easily initialize values via parameters. Thus, we simulate the traditional approach by giving a factory function an optional parameter   to which it should add properties.   corresponds to   in traditional JavaScript. If   is undefined, a new instance of the super-prototype is created. The sub-function uses   to hand in an instance of the sub-prototype.\n YUI \n     This API is the absolute minimum needed to introduce inheritance to traditional JavaScript. \n     It handles the wiring of the prototypes and sets the   property of a constructor function so that one can refer to the super-constructor generically, without a hard-coded name. \n     Node.js has the function   which is similar.     \n \n     Inheritance Patterns in YUI 3 \n     Create Class Hierarchies with  \n Prototype.js \n     If a method has a first argument named  , Prototype will hand in the super method. I like the explicitness and simplicity of this approach (similar to Java marking overriding methods with the   annotation). One has to be careful about minification, though, because it often renames function arguments to save space. \n     Initialization happens in the   method. This separates object construction and object initialization. Constructor chaining becomes method chaining, using the standard   mechanism. \n     Not that the above code is not much different from traditional JavaScript (which was one of the requirements). \n \n     Prototype JavaScript framework: Defining classes and inheritance \n John Resig’s Simple Inheritance \n     You cannot have an object both be invokable via new (only functions can do that) and be the prototype (with methods) for instances. This is a shame, because it prevents the classes from inheriting class methods from their super-classes. The main example is the method   which must be added to each new class. \n     Accessing overridden methods: The API temporarily adds the super-method to  , under the name of  . This automatically takes care of giving the super-method the proper value for  . If recursive method invocations are to work,   has to be saved before invoking a method and restored afterwards. The API takes care of this transparently. \n \n John Resig - Simple JavaScript Inheritance . Explains how the API is used and how it has been implemented. Class.js , my own lightweight inheritance API which is very similar to the Simple Inheritance API, but may be easier to understand than Resig’s code.\n         \n             Warning: The code uses the ECMAScript 5 API which means you will need a  shim  on older browsers. \n         \n     \n     The prototype property of a constructor function must contain an object whose prototype is the prototype property of the super-constructor. This is achieved by the code by letting the super-constructor produce as in instance, but in a special mode where it doesn’t add instance variables or otherwise initializes the instance. My implementation uses   for this purpose, obviating the need for a special mode. \n     The global Class is created inside a non-method function by assigning to  . It thus uses a JavaScript quirk where   is the global object in non-methods. This is not permitted in  strict mode . \n     The xyz regular expression tests whether a function’s source code can be searched for the property name  . Potential obstacles are minification and JavaScript engines that don’t return a function’s source code when it is coerced to string. \n     Also incompatible with  strict mode : accessing  . \n Further reading \n     traits.js : Brings the programming construct  trait  to JavaScript, in a style that complements ECMAScript 5’s  . \n     Prototypes as classes – an introduction to JavaScript inheritance \n     A JavaScript class pattern that starts with a function \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/make-nodejs-code-pretty-via-generator.html", "title": "Make node.js code pretty via a generator-based library", "content": "Make node.js code pretty via a generator-based library esnext dev nodejs javascript node.js \nThe only problem with node.js code: You get one nested function expression for each outside request you make.\n \n fork-join \nRelated reading:\n task.js on GitHub Who says JavaScript I/O has to be ugly? Iterators and generators  [Firefox documentation] ECMAScript.next: the “TXJS” update by Eich comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/mac-tips-not-only-for-switchers.html", "title": "Mac tips (not only) for switchers", "content": "Mac tips (not only) for switchers apple hack computers mac \n\n \n\n \n Option key ⌥: Mac speak for “Alt”.  \n Command key ⌘: Used for menu commands. \n Aqua: The name of the Mac OS X GUI. Meaning: You can usually\nsubstitute “GUI” for “Aqua”, sometimes also used to differentiate\nX11-based programs from true Mac OS X programs. \n Cocoa: An object-oriented API for writing Mac OS X programs, inherited from the NeXT operating system. A variant of Cocoa, Cocoa Touch is used on iOS devices (which run a port of Mac OS X). \n \n Applications: Mac applications are just directories whose name\nends with “.app”, in the Finder, you can use the context menu to look\ninside such a folder. \n \n Thus, one can easily bundle files with an application. This was used when Apple switched from PowerPC processors to Intel processors to include binaries for both architectures in a single application. \n Applications are easy to install and uninstall: You just copy\nthem wherever you want to use them and trash them for deinstallation. Alternative ways of installing are via Installer packages and the Mac App Store. \n \n File system layout: Inspired by the Unix /usr/bin etc., but a bit easier to understand. \n \n Mac OS X: Where The Files Belong Now \n \n Hidden files: Under the Finder (but not under the shell) much of Mac OS X's Unix personality is hidden. Similarly to Unix, files whose names start with a dot are not shown in the Finder. \n \n Mac OS X Hidden Files & Directories \n \n \n Use an Option click to position the cursor in the terminal, e.g. when you are using emacs over ssh. \n Open files with Mac applications:  \n \n \n \n \n \n Drop files on a Terminal window to paste their path.  \n ssh-agent: Already runs for the complete session (including all GUI apps). Thus, you only need to ssh-add your keys (via Terminal).  \n \n Drag and drop \n \n D&D and Option-Tab: You can use Option-Tab during D&D, in order to easily transfer data between programs. \n \n \n D&D a file on Mail.app: Creates a new email message whose attachment is the file. \n \n Finder: Command-clicking on a window title gives you a list of folders enclosing the current one. \n Sleep display: \n \n  Put the cursor in a hot corner. Use “System Preferences → \nDesktop + Screen Saver → Hot Corners” (or search for “corner”) to \nconfigure a corner so that the display is put to sleep if the cursor \nstays in it. \n Type Ctrl-Shift-Eject \n \n \n Mac OS X has many keyboard shortcuts [4].\n \n Many Emacs key bindings work in Mac applications (Ctrl-A, Ctrl-E, Ctrl-K, etc.) \n Keyboard and character viewer menu: can be enabled via the “Keyboard” preference pane. Allows you to access characters such as arrows from any application. \n Use F1, F2, etc. as function keys: Helpful if you develop with an IDE, enabled via the “Keyboard” preference pane. \n Command key combinations and dialog windows: In some cases, you can use a Command key combination to click a button. For example: When you are in danger of overwriting a file, a dialog appears and you can use Command-R to replace or Command-D for “Don’t Save”. \n Shut down dialog: activate via Ctrl-Eject, type the initial character of any of the buttons to click them. \n \n Including a mouse pointer in the shot: This is where the “Grab” application helps. \n Entire screen, window, selection: See Preview.app, menu “File” which has a submenu for screenshots. \n Entire screen: Command-Shift-3 \n Selection: Command-Shift-4 \n \n Benefit: Can also be used to count pixels on screen \n Variation: Hit space and get a cursor that selects a window to be shot.  \n \n \n Activate via Command-Space \n Calculations: addition, multiplication, etc. Even sin and cos work. [6] \n Filter by file type: For example, “kind: pdf”. \n Phrases: Put words that should appear in a given order, next to each other, in quotes. \n Exclude folders: Use the Spotlight preference pane to hide some folder from indexing and appearing in search results. \n \n iTunes: By default, the Ping button transports you to the iTunes store. Option-click instead gets you to your own library. The following preference makes the latter the default. \n In Terminal type:  \n \n \n Safari: Enable the debug menu (which has some nifty stuff in it, you can e.g. change the user agent)\n   \n Type:  \n \n \n Terminal: Enable focus-follows-mouse\n   \n Type:  \n \n \n Mac OS X 10.6 Snow Leopard: the Ars Technica review Essential Mac applications   Gimp on Mac OS X Mac OS X keyboard shortcuts   11 Tips To Use Spotlight More Efficiently Spotlight - Calculator Functions Mac keyboard and trackpad: save battery power comments powered by Disqus."},
{"url": "https://2ality.com/2019/08/promise-combinators.html", "title": "JavaScript Promise combinators:  .all() ,  .race() ,  .allSettled()", "content": "JavaScript Promise combinators:  ,  ,  dev javascript es feature es2020 promises \n  Complete rewrite of section “Overview”. \n In this blog post, we take a look at three static methods of  : \n  and   which JavaScript has had since ECMAScript 6 when Promises were added to the language. \n  which recently advanced to stage 4 and will therefore be part of ECMAScript 2020. \n \n   \n     Overview \n   \n   \n     Recap: Promise states \n   \n   \n     What is a combinator? \n   \n   \n     \n     \n       \n         Asynchronous   via  \n       \n       \n         A more realistic   example \n       \n       \n         A simple implementation of  \n       \n     \n   \n   \n     \n     \n       \n         Using   to time out a Promise \n       \n       \n         A simple implementation of  \n       \n     \n   \n   \n     \n     \n       \n         A first demo of  \n       \n       \n         A longer example for  \n       \n       \n         A simple implementation of  \n       \n       \n         Availability \n       \n     \n   \n   \n     (Advanced) \n   \n   \n     Short-circuiting \n   \n   \n     Concurrency and  \n     \n       \n         Sequential execution vs. concurrent execution \n       \n       \n         Concurrency tip: focus on when operations start \n       \n       \n          is fork-join \n       \n     \n   \n   \n     Further reading \n   \n Overview   # Each of the following methods receives an iterable over input Promises and returns a single output Promise  . \n  of  : if all input Promises are fulfilled.\n \n Value: Array with the fulfillment values of the input Promises \n \n \n  of   [SC]: if one input Promise is rejected.\n \n Value: rejection value of the input Promise \n \n \n  processing Arrays with Promises (rejections terminate processing) \n ECMAScript 6 \n \n  of   [SC]: if the first input Promise is settled.\n \n Value: settlement value of the input Promise \n \n \n  reacting to the first settlement among multiple Promises \n ECMAScript 6 \n \n  of  : if all input Promise are settled.\n \n Value: Array with one   for each input Promise. A settlement object contains the kind of settlement and the settlement value \n \n \n  of  : never (*) \n  processing Arrays with Promises (rejections don’t terminate processing) \n ECMAScript 2020 \n Legend: \n [SC] means that   happens: the output Promise is settled before every input Promise is settled. \n (*) If there are errors when iterating over the input iterables, then those produce rejections. \n Recap: Promise states   # Given an asynchronous operation that returns a Promise. These are possible states of the Promise: \n Pending: the initial state of a Promise. The operation isn’t finished, yet. \n Fulfilled: The operation succeeded and provided a   for the Promise. \n Rejected: The operation failed and provided a   for the Promise. \n Settled: The Promise is either fulfilled or rejected. Once a Promise is settled, its state doesn’t change anymore. \n What is a combinator?   # The   is a pattern in functional programming for building structures. It is based on two kinds of functions: \n  (short:  ) create atomic pieces. \n  (short:  ) combine atomic and/or compound pieces to create compound pieces. \n When it comes to JavaScript Promises: \n Primitive functions include:  ,  \n Combinators include:  ,  ,  \n Next, we’ll take a closer look at  ,  , and  .    # This is the type signature of  :  returns a Promise which is: \n Fulfilled if all   are fulfilled.\n \n Then its fulfillment value is an Array with the fulfillment values of  . \n \n \n Rejected if at least one Promise is rejected.\n \n Then its rejection value is the rejection value of that Promise. \n \n \n This is a quick demo of the output Promise being fulfilled: The following example demonstrates what happens if at least one of the input Promises is rejected: The following diagram illustrates how   works: Asynchronous   via     # Array transformation methods such as  ,  , etc., are made for synchronous computations. For example: What happens if the callback of   is a Promise-based function (a function that maps normal values to Promises)? Then the result of   is an Array of Promises. Alas, that is not data that normal code can work with. Thankfully, we can fix that via  : It converts an Array of Promises into a Promise that is fulfilled with an Array of normal values. A more realistic   example   # Next, we’ll use   and   to downlooad text files from the web. For that, we need the following tool function:  uses the Promise-based  fetch API  to download a text file as a string: \n First, it asynchronously retrieves a   (line A). \n  (line B) checks if there were errors such as “file not found”. \n If there weren’t any, we use   (line C) to retrieve the content of the file as a string. \n In the following example, we download two text files: A simple implementation of     # This is a simplified implementation of   (e.g., it performs no safety checks):    # This is the type signature of  :  returns a Promise   which is settled as soon as the first Promise   among   is settled.   has the same settlement value as  . In the following demo, the settlement of the fulfilled Promise (line A) happens before the settlement of the rejected Promise (line B). Therefore, the result is also fulfilled (line C). In the next demo, the rejection happens first: Note that the Promise returned by   is settled as soon as the first among its input Promises is settled. That means that the result of   is never settled. The following diagram illustrates how   works: Using   to time out a Promise   # In this section, we are going to use   to time out Promises. The following helper function will be useful several times:  returns a Promise that is resolved with   after   milliseconds. This function times out a Promise:  returns a Promise whose settlement is the same as the one of whichever Promise settles first among the following two: The parameter  A Promise that is rejected after   milliseconds To produce the second Promise,   uses the fact that resolving a pending Promise with a rejected Promise leads to the former being rejected. Let’s see   in action. Here, the input Promise is fulfilled before the timeout. Therefore, the output Promise is fulfilled. Here, the timeout happens before the input Promise is fulfilled. Therefore, the output Promise is rejected. It is important to understand what “timing out a Promise” really means: \n If the input Promise is settled quickly enough, its settlement is passed on to the output Promise. \n If it isn’t settled quickly enough, the output Promise is rejected. \n That is, timing out only prevents the input Promise from affecting the output (since a Promise can only be settled once). But it does not stop the asynchronous operation that produced the input Promise. That is a different subject matter. A simple implementation of     # This is a simplified implementation of   (e.g., it performs no safety checks):    # The feature  “ ”  was proposed by Jason Williams, Robert Pamely, and Mathias Bynens. This time, the type signatures are a little more complicated. Feel free to skip ahead to the first demo which should be easier to understand. This is the type signature of  : It returns a Promise for an Array whose elements have the following type signature:  returns a Promise  . Once all   are settled,   is fulfilled with an Array. Each element   of that Array corresponds to one Promise   of  : \n If   is fulfilled with the fulfillment value  , then   is \n \n If   is rejected with the rejection value  , then   is \n \n Unless there is an error when iterating over  , the output Promise   is never rejected. The following diagram illustrates how   works: A first demo of     # This is a quick first demo of how   works: A longer example for     # The next example is similar to  the   plus   example  (from which we are borrowing the function  ): We are downloading multiple text files whose URLs are stored in an Array. However, this time, we don’t want to stop when there is an error, we want to keep going.   allows us to do that: A simple implementation of     # This is a simplified implementation of   (e.g., it performs no safety checks): Availability   # The npm package   contains the official polyfill. (Advanced)   # All remaining sections are advanced. Short-circuiting   # For a Promise combinator,   means that the output Promise is settled early – before all input Promises are settled. Two combinators short-circuit: \n : The output Promise is rejected as soon as one input Promise is rejected. \n : The output Promise is settled as soon as one input Promise is settled. \n Once again, settling early does not mean that the operations behind the ignored Promises are stopped. It just means that their settlements are ignored. Concurrency and     # Sequential execution vs. concurrent execution   # Consider the following code: Using   in this manner executes Promise-based functions  : only after the result of   is settled will   be executed.  helps execute Promise-based functions more concurrently: Concurrency tip: focus on when operations start   # Tip for determining how “concurrent” asynchronous code is: Focus on when asynchronous operations start, not on how their Promises are handled. For example, each of the following functions executes   and   concurrently because they are started at nearly the same time. On the other hand, both of the following functions execute   and   sequentially:   is only invoked after the Promise of   is fulfilled.  is fork-join   #  is loosely related to the concurrency pattern “fork join”. Let’s revisit an example that we have encountered  previously : \n Fork: In line A, we are forking two asynchronous computations and executing them concurrently. \n Join: In line B, we are joining these computations into a single “thread” which is started once all of them are done. \n Further reading   # \n Chapter  “Promises for asynchronous programming”  of “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/08/remainder-vs-modulo.html", "title": "Remainder operator vs. modulo operator (with JavaScript code)", "content": "Remainder operator vs. modulo operator (with JavaScript code) dev javascript \n  New section  “An intuitive explanation of modulo” \n You may have read that JavaScript’s   operator is a remainder operator, not a modulo operator. This blog post explains what that means. Overview: two operators   # Let’s assume there are two operators that are very similar: \n The    \n The    \n If both operands have the same signs, then the operators produce the same results: If, however, they have different signs, then the result of   has the same sign as the first operand, while the result of   has the same sign as the second operand: Why is that? Read on. The remainder operator     # We’ll first take a closer look at the   operator: In order to compute the remainder, we use the following two equations: ,  ,  , and   are all integers (for the sake of this blog post). In order to compute the remainder we must find the  : And we do so by dividing the   by the  .   ensures that the resulting   is an integer.     The modulo operator     # The modulo operator is based on the same equations, but it uses   to compute quotients: \n If both dividend and divisor are positive, the modulo operator produces the same results as the remainder operator (example 3). \n If, however, dividend and divisor have different signs, then the results are different (example 4). \n The reason for that is that   and   produce the same results for positive numbers, but different results for negative numbers.    (dividend is 5, divisor is 3)    (dividend is −5, divisor is 3) An intuitive explanation of modulo   # Modulo can also be viewed as an operation that maps an arbitrary number into a given range – for example: maps   into the range That is, zero is included, 3 is excluded. If   is already inside the range, performing the mapping is simple: If   is greater than or equal to the upper boundary of the range, then the upper boundary is subtracted from   until it fits into the range: That means we are getting the following mapping for non-negative integers: This is how the mapping is extended so that it also covers negative integers:  maps   as follows: Negative right-hand side   #  maps   to the range   has the following mapping (the same as  ): Uses of the modulo operation in JavaScript   # The ECMAScript specification uses modulo several times – for example: \n \n To convert the operands of  the   operator  to unsigned 32-bit integers (via  ): \n \n \n \n To convert arbitrary numbers so that they fit into Typed Arrays. For example,   is used to convert numbers to unsigned 8-bit integers (after first converting them to integers): \n \n \n Conclusions and further reading   # Which of   and   is supported and how depends on the programming language: \n JavaScript‘s   operator is a remainder operator. \n Python’s   operator is a modulo operator. \n If you want to read more about remainder and modulo: \n The Wikipedia page on “modulo operation”  has much information. \n The ECMAScript specification  mentions  that   is computed via “truncating division”. \n Sect. “Rounding”  in “JavaScript for impatient programmers” describes several ways of rounding in JavaScript. \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/08/global-this.html", "title": "ES feature:  globalThis", "content": "ES feature:  dev javascript es feature es2020 section “ ” The ECMAScript proposal “ ” by Jordan Harband provides a new standard way of accessing the global object. JavaScript’s global scope   # JavaScript’s variable scopes are nested and form a tree whose root is the global scope. That scope is only the direct scope when a script runs in a web browser. There are two kinds of global variables: \n  are normal variables.\n \n They are created in the top level of a script, via  , `let, and class declarations. \n \n \n  are stored in properties of the  .\n \n They are created in the top level of a script, via   and function declarations. \n They can also be created, deleted, and read via the global object. \n Other than that, they work like normal variables. \n \n \n The global object can be accessed via  . The following HTML fragment demonstrates   and the different kinds of global variables. Note that each module has its own scope. Therefore, variables that exist at the top level of a module are not global. The following diagram illustrates how the various scopes are related. Values of     # Whenever there is no   (the object of a method call), the value of   depends on the current scope: \n Top level of scripts: global object (in browsers, there is an indirection that we’ll explore later) \n Top level of ECMAScript modules:  \n During a function call:\n \n Strict mode (including modules):  \n Sloppy mode: same as global  \n \n \n If you call   indirectly, it is executed in global scope, sloppily. Therefore, you can use the following code to get the global  :  is also always evaluated in sloppy mode: There is one important caveat, though:  ,  , etc. are not available if you use CSP (Content Security Policy). That makes this approach unsuitable in many cases. In browsers, the global   does not point directly to the global object   # As an example, consider an iframe on a web page: \n Whenever the   of the iframe changes, it gets a new global object. \n However, the global   always has the same value, which can be checked from outside the iframe,  as demonstrated in the feature proposal . \n Browsers achieve that by distinguishing two objects: \n  is the global object. It changes whenever the location changes. \n  is an object that forwards all accesses to the current  . This object never changes. \n In browsers, global   refers to the  ; everywhere else, it directly refers to the global object.  and alternatives ( , etc.)   #  is the new standard way of accessing global  . Existing simple ways depend on the platform: \n Global variable  : is the classic way of referring to the global object. But it doesn’t work in Node.js and in Web Workers. \n Global variable  : is available in Web Workers and browsers in general. But it isn’t supported by Node.js. Some people take   appearing in code, as a sign that that code works in both Web Workers and normal browser settings. \n Global variable  : is only available in Node.js. \n The proposal also standardizes that the global object must have   in its prototype chain. The following is already true in web browsers today: Use cases for     # The global object is now considered a mistake that JavaScript can’t get rid of, due to backward compatibility. It affects performance negatively and is generally confusing. ECMAScript introduced several features that make it easier to avoid the global object – for example: \n ,  , and class declarations don’t create global object properties when used in global scope. \n Each ECMAScript module has its own local scope. \n It is normally preferable to refer to global variables as variables and not as properties of  . That has always worked on all JavaScript platforms. Therefore, there are relatively few use cases for   – for example: \n Polyfills and shims that provide new features on JavaScript engines. \n Feature detection, to find out what features a JavaScript engine supports. \n A polyfill   # The proposal’s author, Jordan Harband, has written  a polyfill  for  . Using it with CommonJS syntax: Using it with ES6 module syntax: The package always uses the “most native” approach available (  on Node.js etc.,   in normal browser contexts, etc.). Computing a reference to the global object   # Internally, the polyfill uses the function   to compute a reference to the global object. This is how that is achieved: : : FAQ:     # Why not use  ,  , or   everywhere?   # Alas, that is not possible, because many JavaScript libraries use these variables to detect which platform they are running on. What other names for   were considered?   # An issue  in the proposal’s repository lists names that were considered and why they were rejected. Sources and background   # General background: \n A general overview of global variables:  section “Global variables”  in “JavaScript for impatient programmers” \n In-depth information on how JavaScript manages its global variables:  “How do JavaScript’s global variables really work?”  on 2ality \n Useful background for what happens in browsers:  “Defining the WindowProxy, Window, and Location objects”  by Anne van Kesteren \n Various ways of accessing the global   value:  “A horrifying   polyfill in universal JavaScript”  by Mathias Bynens \n Specifications: \n Very technical:  “Realms, settings objects, and global objects”  in the WHATWG HTML standard \n In the ECMAScript specification, you can see how web browsers customize global  :  “InitializeHostDefinedRealm()” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/08/nullish-coalescing.html", "title": "ES2020: Nullish coalescing for JavaScript", "content": "ES2020: Nullish coalescing for JavaScript dev javascript es feature es2020 This blog post describes the ECMAScript feature proposal  “Nullish coalescing for JavaScript”  by Gabriel Isenberg. It proposes the   operator that replaces   when it comes to providing default values. Overview   # The result of   is: \n  if   is   or  \n  otherwise \n Examples: Legacy: default values via     # Quick recap of how  the logical Or operator   works – the following two expressions are equivalent: That is: \n If   is  truthy  then the result of   is  . \n Otherwise it is  . \n That makes it possible to use   to specify a default value that is to be used if the actual value is falsy: Note that almost always, the default value should only be used if the actual value is   or  . That works, because both   and   are falsy: Alas, the default value is also used if the actual value is any of the other falsy values – for example: Therefore, this invocation of   does not work properly: Nullish coalescing operator     # The nullish coalescing operator   is intended to replace the logical Or operator   when it comes to providing default values. The following two expressions are equivalent: Default values are provided like this: For   and  , the   operator works the same as the   operator: However, for other left-hand-side operands, it never returns the default values – even if the operands are falsy: Let’s rewrite   and use  : Now calling it with a   whose   is the empty string, works as desired: Default values via destructuring   #  was used as a simple way of motivating the   operator. Note that you can also use destructuring to implement it: A realistic example of using the   operator   # As a realistic example, we will use the   to simplify the following function. The string method   is explained in  “JavaScript for impatient programmers” . If we use the   operator, we get the following code: Nullish coalescing and optional chaining   # The nullish coalescing operator   was explicitly designed to complement  optional chaining of property accesses . For example, in the following code, the two are used together in line A. Implementations   # \n You can check  the ECMAScript Next compatibility table  to find out where the   operator is supported. \n Babel has the plugin  \n Further reading   # \n Blog post  “ES proposal: optional chaining” \n Section “Logical Or ( )”  in “JavaScript for impatient programmers” \n Chapter “Destructuring”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/eval-via-import.html", "title": "Evaluating JavaScript code via  import()", "content": "Evaluating JavaScript code via  dev javascript The   operator  lets us dynamically load ECMAScript modules. But they can also be used to evaluate JavaScript code ( as Andrea Giammarchi recently pointed out to me ), as an alternative to  . This blog post explains how that works.  does not support   and     # A significant limitation of   is that it doesn’t support module syntax such as   and  . If we use   instead of  , we can actually evaluate module code, as we will see later in this blog post. In the future, we may get   which are, roughly, a more powerful   with support for modules. Evaluating simple code via     # Let’s start by evaluating a   via  : What is going on here? \n First we create a so-called  . The protocol of this kind of URI is  . The remainder of the URI encodes the full resource instead pointing to it. In this case, the data URI contains a complete ECMAScript module – whose content type is  . \n Then we dynamically import this module and therefore execute it. \n Warning: This code only works in web browsers. On Node.js,   does not support data URIs. Accessing an export of an evaluated module   # The fulfillment value of the Promise returned by   is a module namespace object. That gives us access to the default export and the named exports of the module. In the following example, we access the default export: Creating data URIs via tagged templates   # With an appropriate function   (whose implementation we’ll see later), we can rewrite the previous example and create the data URI via a  tagged template : The implementation of   looks as follows: For the encoding, we have switched from   to  . Compare: \n Source code:  \n Data URI 1:  \n Data URI 2:  \n Each of the two ways of encoding has different pros and cons: \n Benefits of   (percent-encoding):\n \n Much of the source code is still readable. \n \n \n Benefits of  :\n \n The URIs are usually shorter. \n Easier to nest because it doesn’t contain special characters such as apostrophes. We’ll see an example of nesting in the next section. \n \n \n  is a global utility function that encodes a string via base 64. Caveats: \n It is not available on Node.js. \n It should only be used for characters whose Unicode code points range from 0 to 255. \n Evaluating a module that imports another module   # With tagged templates, we can nest data URIs and encode a module   that imports another module  : Further reading   # \n Wikipedia on Data URIs \n Section on   in “JavaScript for impatient programmers” \n Section on tagged templates in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/multi-module-eval.html", "title": "Letting web app users run multi-module JavaScript code", "content": "Letting web app users run multi-module JavaScript code dev javascript In a web app of mine, I wanted to let end users run multi-module JavaScript that they enter via text fields. It turns out that this simple idea is relatively difficult to implement. In this blog post, I’ll explain how to do it. It is less polished than usual – I mainly wanted to get the knowledge out there. Overview   # \n Use  Rollup  to combine the user’s multiple modules into a single string:\n \n Input: multiple modules, passed to Rollup as strings. \n Output: the bundle in a string and a source map. \n \n \n  the text string. \n If that produces an exception then the line and column numbers in the exception’s stack trace refer to the bundle, not the input modules.\n \n Therefore: Use the source map and  the library source-map  to go from bundle source code locations to input module names and source code locations. \n Unfortunately, Chrome, Safari, and Firefox all have different stack trace formats, which is why this approach only works in Chrome and other V8-based browsers. \n \n \n The web app itself is bundled via webpack. Bundling via Rollup   # Before we can bundle, we need a way to pass the modules to Rollup as strings (vs. files in a file system). That can be achieved via a plugin: Now we can bundle the code: Where do the strings for the modules come from?   # Even for “global” modules such as  , we need to provide strings. webpack’s  raw-loader  can help here: That allows us to develop modules for the user’s code with the same tools as the web app (even though the web app exists at a meta-level, relative to the user’s code). Bundle formats   # Rollup supports several bundle formats (AMD, CommonJS, ES module, etc.).  The Rollup REPL  helps with exploring the different bundle formats. The best format for our purposes is “iife”. The following code is an example of this format: If we remove   at the beginning and the semicolon at the end, we can   this code. Syntax errors   # If Rollup finds syntax errors, it throws instances of   that include the following properties:  is a string that shows the lines surrounding the syntax error and points to its location. Importing Rollup   # I had to import Rollup as follows in order to not lose the static type information in my IDE: Alas, that imports from the Node.js version of Rollup, not from the browser version. I fixed that by adding the following entry to  : Executing the bundle   # To execute the bundle, a simple   suffices. Why   and not  ? The former is a safer version of the latter ( details ). Handling exceptions   # If the evaluated code throws an exception, we get stack traces that look as follows: The stack trace includes line numbers for the web app and line numbers for the end user’s code. I could not find any stack trace parsing library that parsed such stack traces correctly. Hence, I did some quick and dirty parsing via a regular expression. The   line numbers refer to the bundled code. We can use the library  source-map  to get the original module names and locations: By wrapping the code contained in the callback (line A),   ensures that the resources it creates are disposed of, after they are not needed, anymore. Setting up the source-map library   # Internally, source-map uses Wasm code. I had to use version 0.8.0-beta.0 in order to load that code from the web app bundle. The JavaScript code looks like this: Thanks to webpack and the arraybuffer-loader, we can import the Wasm code into an ArrayBuffer. We need the following entry in  : comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/babel-loader-typescript.html", "title": "Compiling TypeScript via webpack and babel-loader", "content": "Compiling TypeScript via webpack and babel-loader dev typescript webpack babel  has one downside: We can’t pipe the output of another loader into it; it always reads the original file. As a work-around, we can use   to compile TypeScript. This blog post explains how. : Notes: \n The order of the presets seems to matter. My setup didn’t work if   came after  . \n : Make sure you get targeted browsers and the inclusion of builtins right ( see documentation ).\n \n For example, if you transpile async functions to JavaScript that doesn’t even use generators, then you need to include the regenerator runtime. \n \n \n : comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/shared-mutable-state.html", "title": "The problems of shared mutable state and how to avoid them", "content": "The problems of shared mutable state and how to avoid them dev javascript deepjs This blog post answers the following questions: \n What is shared mutable state? \n Why is it problematic? \n How can its problems be avoided? \n Sections marked with “(advanced)” go deeper and can be skipped if you want to read this blog post more quickly. \n   \n     What is shared mutable state and why is it problematic? \n   \n   \n     Avoiding sharing by copying data \n     \n       \n         Shallow copying vs. deep copying \n       \n       \n         Shallow copying in JavaScript \n       \n       \n         Deep copying in JavaScript \n       \n       \n         How does copying help with shared mutable state? \n       \n     \n   \n   \n     Avoiding mutations by updating non-destructively \n     \n       \n         Background: Destructive updates vs. non-destructive updates \n       \n       \n         How does non-destructive updating help with shared mutable state? \n       \n     \n   \n   \n     Preventing mutations by making data immutable \n     \n       \n         Background: immutability in JavaScript \n       \n       \n         Immutable wrappers (advanced) \n       \n       \n         How does immutability help with shared mutable state? \n       \n     \n   \n   \n     Libraries for avoiding shared mutable state \n     \n       \n         Immutable.js \n       \n       \n         Immer \n       \n     \n   \n   \n     Acknowledgements \n   \n   \n     Further reading \n   \n What is shared mutable state and why is it problematic?   # Shared mutable state works as follows: \n If two or more parties can change the same data (variables, objects, etc.) and \n if their lifetimes overlap, \n then there is a risk of one party’s modifications preventing other parties from working correctly. This is an example: Here, there are two independent parties: function   and function  . The latter wants to log an Array before and after sorting it. However, it uses  , which clears its parameter. Therefore,   logs an empty Array in line A. In the remainder of this post, we look at three ways of avoiding the problems of shared mutable state: \n Avoiding sharing by copying data \n Avoiding mutations by updating non-destructively \n Preventing mutations by making data immutable \n In particular, we will come back to the example that we’ve just seen and fix it. Avoiding sharing by copying data   # Before we can get into how copying avoids sharing, we need to take a look at how data can be copied in JavaScript. Shallow copying vs. deep copying   # There are two “depths” with which data can be copied: \n  only copies the top-level entries of objects and Arrays. The entry values are still the same in original and copy. \n  also copies the entries of the values of the entries, etc. That is, it traverses the complete tree whose root is the value to be copied and makes copies of all nodes. \n The next sections cover both kinds of copying. Unfortunately, JavaScript only has built-in support for shallow copying. If we need deep copying, we need to implement it ourselves. Shallow copying in JavaScript   # Let’s look at several ways of shallowly copying data. # We can  spread into object literals  and  spread into Array literals  to make copies: Alas, spreading has several limitations: \n \n The prototype is not copied: \n \n \n \n Special objects such as regular expressions and dates have special “internal slots” that aren’t copied. \n \n \n Only own (non-inherited) properties are copied. Given how  prototype chains  work, this is usually the best approach. But you still need to be aware of it. In the following example, the inherited property   of   is not available in  , because we only copy own properties and don’t keep the prototype. \n \n \n \n Only enumerable properties are copied. For example, the own property   of Array instances is not enumerable and not copied: \n \n \n \n Independently of  the   of a property, its copy will always be a data property that is writable and configurable – for example: \n \n That means that getters and setters are not copied faithfully, either: The attributes   (for data properties),   (for getters), and   (for setters) are mutually exclusive. \n \n \n \n Copying is shallow: The copy has fresh versions of each key-value entry in the original, but the values of the original are not copied themselves. For example: \n \n \n Some of these limitations can be eliminated, others can’t: \n \n We can give the copy the same prototype as the original during copying: \n \n Alternatively, we can set the prototype of the copy after its creation, via  . \n \n \n There is no simple way to generically copy special objects. \n \n \n As mentioned, only own properties being copied is more of a feature than a limitation. \n \n \n We can use   and   to copy objects ( how to do that is explained later ): \n \n They consider all attributes (not just  ) and therefore correctly copy getters, setters, read-only properties, etc. \n  retrieves both enumerable and non-enumerable properties. \n \n \n \n We’ll look at deep copying later in this post. \n \n #  works mostly like spreading into objects. That is, the following two ways of copying are mostly equivalent: Using a method instead of syntax has the benefit that it can be polyfilled on older JavaScript engines via a library.  is not completely like spreading, though. It differs in one, relatively subtle point: it creates properties differently. \n  uses   to create the properties of the copy. \n Spreading   new properties in the copy. \n Among other things, assignment invokes own and inherited setters, while definition doesn’t ( more information on assignment vs. definition ). This difference is rarely noticeable. The following code is an example, but it’s contrived: # JavaScript lets us create properties via  , objects that specify property attributes. For example, via the  , which we have already seen in action. If we combine that method with  , we can copy more faithfully: That eliminates two limitations of copying objects via spreading. First, all attributes of own properties are copied correctly. Therefore, we can now copy own getters and own setters: Second, thanks to  , non-enumerable properties are copied, too: Deep copying in JavaScript   # Now it is time to tackle deep copying. First, we will deep-copy manually, then we’ll examine generic approaches. # If we nest spreading, we get deep copies: # This is a hack, but, in a pinch, it provides a quick solution: In order to deep-copy an object  , we first convert it to a JSON string and the parse that JSON string: The significant downside of this approach is that we can only copy properties with keys and values that are supported by JSON. Some unsupported keys and values are simply ignored: Others cause exceptions: # The following function generically deep-copies a value  : The function handles three cases: \n If   is an Array we create a new Array and deep-copy the elements of   into it. \n If   is an object, we use a similar approach. \n If   is a primitive value, we don’t have to do anything. \n Let’s try out  : Note that   only fixes one issue of spreading: shallow copying. All others remain: prototypes are not copied, special objects are only partially copied, non-enumerable properties are ignored, most property attributes are ignored. Implementing copying completely generically is generally impossible: Not all data is a tree, sometimes you don’t want to all properties, etc. # We can make our previous implementation of   more concise if we use   and  : # Two techniques are often used to implement deep copying for instances of classes: \n  methods \n Copy constructors \n # This technique introduces one method   per class whose instances are to be deep-copied. It returns a deep copy of  . The following example shows three classes that can be cloned. Line A demonstrates an important aspect of this technique: compound instance property values must also be cloned, recursively. # A   is a constructor that uses another instance of the current class to set up the current instance. Copy constructors are popular in static languages such as C++ and Java, where you can provide multiple versions of a constructor via   (  meaning that it happens at compile time). In JavaScript, you could do something like this (but it’s not very elegant): This is how you’d use this class: Instead,   work better in JavaScript (  meaning that they are class methods). In the following example, the three classes  ,   and   each have a static factory method  : In line A, we once again use recursive copying. This is how   works: How does copying help with shared mutable state?   # As long as we only read from shared state, we don’t have any problems. Before we modify it, we need to “un-share” it, by copying it (as deeply as necessary).  is a technique to always copy when issues   arise. Its objective is to keep the current entity (function, class, etc.) safe: \n Input: Copying (potentially) shared data passed to us, lets us use that data without being disturbed by an external entity. \n Output: Copying internal data before exposing it to an outside party, means that that party can’t disrupt our internal activity. \n Note that these measures protect us from other parties, but they also protect other parties from us. The next sections illustrate both kinds of defensive copying. # Remember that in the motivating example at the beginning of this post, we got into trouble because   modified its parameter  : Let’s add defensive copying to this function: Now   doesn’t cause problems anymore, if it is called inside  : # Let’s start with a class   that doesn’t copy internal data it exposes (line A): As long as   isn’t used, everything works well: If, however, the result of   is changed (line A), then the   ceases to work correctly: The solution is to copy the internal   defensively before it is exposed (line A): Now changing the result of   doesn’t interfere with the operation of   anymore: Avoiding mutations by updating non-destructively   # We will first explore the difference between updating data destructively and non-destructively. Then we’ll learn how non-destructive updates avoid mutations. Background: Destructive updates vs. non-destructive updates   # We can distinguish two different ways of updating data: \n A   of data mutates the data so that it has the desired form. \n A   of data creates a copy of the data that has the desired form. \n The latter way is similar to first making a copy and then changing it destructively, but it does both at the same time. # This is how we destructively set the property   of an object: The following function non-destructively changes properties: It is used as follows: Spreading makes   more concise: Note: Both versions of   update shallowly. # This is how we destructively set an element of an Array: Non-destructively updating an Array is more complicated than non-destructively updating an object.  and spreading make   more concise: Note: Both versions of   update shallowly. # So far, we have only updated data shallowly. Let’s tackle deep updating. The following code shows how to do it manually. We are changing name and employer. # The following function implements generic deep updating. If we see   as the root of a tree that we are updating, then   only deeply changes a single branch (line A and C). All other branches are copied shallowly (line B and D). This is what using   looks like: How does non-destructive updating help with shared mutable state?   # With non-destructive updating, sharing data becomes unproblematic, because we never mutate the shared data. (Obviously, this only works if all parties do this.) Intriguingly, copying data becomes trivially simple: The actual copying of   happens only if and when it is necessary and we are making non-destructive changes. Preventing mutations by making data immutable   # We can prevent mutations of shared data by making that data immutable. Next, we’ll examine how JavaScript supports immutability. Afterwards, we’ll discuss how immutable data helps with shared mutable state. Background: immutability in JavaScript   # JavaScript has three levels of protecting objects: \n  makes it impossible to add new properties to an object. You can still delete and change properties, though.\n \n Method:  \n \n \n  prevents extensions and makes all properties   (roughly: you can’t change how a property works anymore).\n \n Method:  \n \n \n  seals an object after making all of its properties non-writable. That is, the object is not extensible, all properties are read-only and there is no way to change that.\n \n Method:  \n \n \n For more information, see  “Speaking JavaScript” . Given that we want our objects to be completely immutable, we only use   in this blog post. #  only freezes   and its properties. It does not freeze the values of those properties – for example: # If we want deep freezing, we need to implement it ourselves: Revisiting the example from the previous section, we can check if   really freezes deeply: Immutable wrappers (advanced)   # An immutable wrapper wraps a mutable collection and provides the same API, but without destructive operations. We now have two interfaces for the same collection: One is mutable, the other one is immutable. This is useful when we have mutable internal data that we want to expose safely. The next two sections showcase wrappers for Maps and Arrays. They both have the following limitations: \n They are sketches. More work is needed to make them suitable for practical use: Better checks, support for more methods, etc. \n They work shallowly. \n # Class   produces wrappers for Maps: This is the class in action: # For an Array  , normal wrapping is not enough because we need to intercept not just method calls, but also property accesses such as  .  JavaScript proxies  enable us to do this: Let’s wrap an Array: How does immutability help with shared mutable state?   # If data is immutable, it can be shared without any risks. In particular, there is no need to copy defensively. Non-destructive updating complements immutable data and makes it mostly as versatile as mutable data, but without the associated risks. Libraries for avoiding shared mutable state   # There are several libraries available for JavaScript that support immutable data with non-destructive updating. Two popular ones are: \n Immutable.js  provides immutable (versions of) data structures such as  ,  ,  , and  . \n Immer  also supports immutability and non-destructive updating but for plain objects and Arrays. \n These libraries are described in more detail in the next two sections. Immutable.js   # In its repository,  the library Immutable.js  is described as: Immutable persistent data collections for JavaScript which increase efficiency and simplicity. Immutable.js provides immutable data structures such as: \n \n  (which is different from JavaScript’s built-in  ) \n  (which is different from JavaScript’s built-in  ) \n \n Etc. \n In the following example, we use an immutable  : Explanations: \n In line A we create a new, different version   of  , where   is mapped to  . \n In line B, we check that the change was non-destructive. \n In line C, we update   and undo the change made in line A. \n In line D, we use Immutable’s built-in   method to check that we really undid the change. \n Immer   # In its repository,  the library Immer  is described as: Create the next immutable state by mutating the current one. Immer helps with non-destructively updating (potentially nested) plain objects and Arrays. That is, there are no special data structures involved. This is what using Immer looks like: The original data is stored in  .   provides us with a variable  . We pretend that this variable is   and use operations with which we would normally make destructive changes. Immer intercepts these operations. Instead of mutating  , it non-destructively changes  . The result is referenced by  . As a bonus, it is deeply immutable. Acknowledgements   # \n Ron Korvig  reminded me to use static factory methods and not overloaded constructors for deep-copying in JavaScript. \n Further reading   # \n Spreading:\n \n Section “Spreading into object literals”  in “JavaScript for impatient programmers” \n Section “Spreading into Array literals”  in “JavaScript for impatient programmers” \n \n \n Property attributes:\n \n Section “Property Attributes and Property Descriptors”  in “Speaking JavaScript” \n Section “Protecting Objects”  in “Speaking JavaScript” \n \n \n Prototype chains:\n \n Section “Prototype chains”  in “JavaScript for impatient programmers” \n Section “Properties: Definition Versus Assignment”  in “Speaking JavaScript” \n \n \n Chapter “Metaprogramming with proxies”  in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/regexp-lookaround-assertions.html", "title": "Regular expressions in JavaScript: lookaround assertions by example", "content": "Regular expressions in JavaScript: lookaround assertions by example dev javascript regexp These are lookaround assertions in regular expressions in JavaScript: \n Positive lookahead:  \n Negative lookahead:  \n Positive lookbehind:  \n Negative lookbehind:  \n This blog post shows examples of using them. Cheat sheet: lookaround assertions   # At the current location in the input string: \n Lookahead assertions (ECMAScript 3):\n \n Positive lookahead:   matches if   matches what comes after the current location. \n Negative lookahead:   matches if   does not match what comes after the current location. \n \n \n Lookbehind assertions (ECMAScript 2018):\n \n Positive lookbehind:   matches if   matches what comes before the current location. \n Negative lookbehind:   matches if   does not match what comes before the current location. \n \n \n For more information, see “JavaScript for impatient programmers”:  lookahead assertions ,  lookbehind assertions . A word of caution about regular expressions   # Regular expressions are a double-edged sword: powerful and short, but also sloppy and cryptic. Sometimes different, longer approaches (especially proper parsers) may be better, especially for production code. Another caveat is that lookbehind assertions are a relatively new feature that may not be supported by all JavaScript engines you are targeting. Example: Specifying what comes before or after a match (positive lookaround)   # In the following interaction, we extract quoted words: Two lookaround assertions help us here: \n  “must be preceded by a quote” \n  “must be followed by a quote” \n Lookaround assertions are especially convenient for   in its   mode, which returns whole matches (capture group 0). Whatever the pattern of a lookaround assertion matches is not captured. Without lookaround assertions, the quotes show up in the result: Example: Specifying what does not come before or after a match (negative lookaround)   # How can we achieve the opposite of what we did in the previous section and extract all unquoted words from a string? \n Input:  \n Output:  \n Our first attempt is to simply convert positive lookaround assertions to negative lookaround assertions. Alas, that fails: The problem is that we extract sequences of characters that are not bracketed by quotes. That means that in the string  , the “r” in the middle is considered unquoted, because it is preceded by an “a” and followed by an “e”. We can fix this by stating that prefix and suffix must be neither quote nor letter: Another solution is to demand via   that the sequence of characters   start and end at word boundaries: One thing that is nice about negative lookbehind and negative lookahead is that they also work at the beginning or end, respectively, of a string – as demonstrated in the example. There are no simple alternatives to negative lookaround assertions   # Negative lookaround assertions are a powerful tool and difficult to emulate via other (regular expression) means. If you don’t want to use them, you normally have to take completely different approach. For example, in this case, you could split the string into (quoted and unquoted) words and then filter those: Benefits of this approach: \n It works on older engines. \n It is easy to understand. \n Interlude: pointing lookaround assertions inward   # All of the examples we have seen so far have in common that the lookaround assertions dictate what must come before or after the match but without including those characters in the match. The regular expressions shown in the remainder of this blog post are different: Their lookaround assertions point inward and restrict what’s inside the match. Example: match strings not starting with     # Let‘s assume we want to match all strings that do not start with  . Our first attempt could be the regular expression  . That works well for  : However,   gives us an empty string: The problem is that assertions such as lookaround assertions don’t expand the matched text. That is, they don’t capture input characters, they only make demands about the current location in the input. Therefore, the solution is to add a pattern that does capture input characters: As desired, this new regular expression rejects strings that are prefixed with  : And it accepts strings that don’t have the full prefix: Example: match substrings that do not contain     # In the following example, we want to find where   does not end with  . Here, the lookbehind assertion   acts as a   and prevents that the regular expression matches strings that contain  ' at this location. Example: skipping lines with comments   # Scenario: We want to parse lines with settings, while skipping comments. For example: How did we arrive at the regular expression  ? We started with the following regular expression for settings: Intuitively, it is a sequence of the following parts: \n Start of the line \n Non-colons (zero or more) \n A single colon \n Any characters (zero or more) \n The end of line \n This regular expression does reject   comments: But it accepts others (that have colons in them): We can fix that by prefixing   as a guard. Intuitively, it means: ”The current location in the input string must not be followed by the character  .” The new regular expression works as desired: Example: smart quotes   # Let’s assume we want to convert pairs of straight double quotes to curly quotes: \n Input:  \n Output:  \n This is our first attempt: Only the first quote and the last quote is curly. The problem here is that the   quantifier matches   (as much as possible). If we put a question mark after the  , it matches  : Supporting escaping via backslashes   # What if we want to allow the escaping of quotes via backslashes? We can do that by using the guard   before the quotes: As a post-processing step, we would still need to do: However, this regular expression can fail when there is a backslash-escaped backslash: The second backslash prevented the quotes from becoming curly. We can fix that if we make our guard more sophisticated (  makes the group non-capturing): (Credit:  @jonasraoni ) The new guard allows pairs of backslashes before quotes: One issue remains. This guard prevents the first quote from being matched if it appears at the beginning of a string: We can fix that by changing the first guard to:  Further reading   # \n Chapter “Regular expressions ( )”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/10/hybrid-npm-packages.html", "title": "Hybrid npm packages (ESM and CommonJS)", "content": "Hybrid npm packages (ESM and CommonJS) dev javascript jsmodules nodejs esm commonjs \n ESM support in Node.js is not experimental, anymore. This post was updated to reflect that. \n Conditional exports are now explained. \n In this blog post, we look at npm packages that contain both  ES modules  and  CommonJS modules . Required knowledge: How ES modules are supported natively on Node.js. You can read  this blog post  if necessary. \n   \n     Legacy approach for putting ES modules on npm \n   \n   \n     ES modules on npm for Node.js with built-in ESM and browsers \n     \n       \n         Option 1 (experimental, needs conditional exports): ESM and CommonJS are both bare imports \n       \n       \n         Option 2: bare-import CommonJS, deep-import ESM (maximum backward compatibility) \n       \n       \n         Option 3: bare-import ESM, deep-import CommonJS with backward compatibility \n       \n       \n         Option 4: bare-import ESM, deep-import CommonJS with   and  \n       \n     \n   \n   \n     Acknowledgements \n   \n   \n     Further reading \n   \n Legacy approach for putting ES modules on npm   # npm packages have come with ESM versions for a long time. The most popular legacy approach seems to be to have the following two lines in  : The first line is the CommonJS entry point into the package. The second line points bundlers (which are mainly used for browsers) to an ESM bundle of all of the code in this package. The files in this package are: On Node.js, this package is used as follows: In bundled browser code, this package is used as follows: Most bundlers can also handle CommonJS modules and compile them to browser code. ES modules on npm for Node.js with built-in ESM and browsers   # Native support for ES modules in Node.js: Node.js 12+ supports ESM natively behind the flag  Node.js 13.2.0+ supports native ESM without that flag. Terminology: \n I’m using the term   for both ways of supporting ESM natively. \n I’m using the term   for versions of Node.js that do not support ESM natively. \n With ESM Node.js, we have new options for implementing hybrid packages. Option 1 (experimental, needs conditional exports): ESM and CommonJS are both bare imports   # Scenario: We want to make it easy for clients of our package to upgrade from an existing CommonJS-only version to a hybrid version. Therefore, the existing CommonJS module specifier should not change. We also want ESM importers to use the same module specifier as CommonJS importers. Caveat: This scenario is enabled by  conditional exports  which are still experimental and must be switched on via  . Files in the package: : Notes: \n  means that   files are interpreted as CommonJS. For pre-ESM Node.js, we need   to be CommonJS. \n  defines the entry point for pre-ESM Node.js. \n  defines  package exports . Package exports enable us to override   and to define deep import paths without filename extensions (which are normally required when using  deep import paths  to import ES modules).\n \n The path   overrides the outer  . Its value can either be a string that points to a module or an object with  . In this case, we have the following conditions:\n \n  specifies the entry point for CommonJS modules \n  specifies the entry point that is used in all other cases \n \n \n \n \n  specifies the entry point for legacy tools. \n Node.js supports the following conditions: \n : The importer must be a CommonJS modules \n : The target platform must be Node.js \n : The catch-all case (similar to JavaScript switch statements) \n Other conditions must be defined and supported by other target platforms and tools. Examples include:  ,  ,  ,  , Requiring from CommonJS modules: Importing from ESM modules: # The CommonJS part of the package is used like this (natively on Node.js and if a bundler supports CommonJS): The main (bare import) entry point for this package is  . As a result, the module specifier of the hybrid version of this package is still   (unchanged from the CommonJS-only version). Interpretation of   files: \n ESM Node.js:   ensures that   files are interpreted as CommonJS modules. \n Pre-ESM Node.js: always interprets   as CommonJS. \n # The ESM part of the package is used like this (natively on ESM Node.js and in browsers): Entry points: \n ESM Node.js: Due to the filename extension  , Node.js interprets the file pointed to by   as an ES module. \n Pre-ESM Node.js: uses the CommonJS entry point (see previous subsection). \n Modern bundlers can use the same entry point as ESM Node.js. \n Older bundlers use the entry point specified via  . \n # Browsers don’t care about filename extensions, only about content types, but some tools may still have trouble with the filename extension  . If we want to avoid those, we can switch to the following approach. Files in the package: : Note: \n  means that   files are interpreted as ESM by default. \n : Note: \n This file overrides our default. Inside the directory ``mypkg/commonjs/ .js` files are now interpreted as CommonJS modules. \n Option 2: bare-import CommonJS, deep-import ESM (maximum backward compatibility)   # Scenario: We want to make it easy for clients of our package to upgrade from an existing CommonJS-only version to a hybrid version. We also want to use   for ES modules, to be maximally compatible with existing tools. This hybrid package has the following files: : Notes: \n  means that we normally want   files to be interpreted as ES modules. \n  defines a package export that enables the module specifier   for the ES module. \n : Note: \n  overrides the default module type. Now all files inside   are interpreted as CommonJS. \n Importing from CommonJS: Importing from ESM: Option 3: bare-import ESM, deep-import CommonJS with backward compatibility   # Scenario: We are creating a completely new package and want it to be both hybrid and as backward compatible as possible. Now we can give preference to ESM and use the bare import   for that module format. Our package now looks like this: : : This package is used as follows: The module specifier   is an abbreviation for  . This kind of abbreviation is enabled by the filename   (a feature that is only available for CommonJS, not for ESM). That’s why   was renamed to  . Option 4: bare-import ESM, deep-import CommonJS with   and     # Scenario: Our package is new and should be hybrid, but we now have the luxury of only targeting modern bundlers ESM Node.js Therefore, we can use the filename extensions   (ESM) and   (CommonJS) to indicate module formats. I like being able to distinguish them from   script files (bundles for pre-module browsers, etc.). That looks as follows: : Notes: \n \n  isn’t really needed here because it’s the default (and because there aren’t any   files). But it’s now recommended to always add a  , in order to help bundlers and other tools understand the files in a package. \n \n Benefit of interpreting   files as CommonJS: It’s easier to move old   CommonJS files into this package. \n \n \n \n We can omit the following property because we don’t have to support older bundlers (which need it). \n \n \n ESM and CommonJS are used the same way as in option 3: \n ESM Node.js can use either ESM or CommonJS. \n Modern bundlers can use the same ESM and CommonJS entry points as ESM Node.js. \n # Scenario: We want to support pre-ESM Node.js. A modern bundler is still a requirement (due to the filename extension  ). We support pre-ESM Node.js by switching to   in directory  . This also works in ESM Node.js, due to   in  . Acknowledgements   # Among others, the following people provided important input for this blog post: \n github.com/mgtitimoli \n github.com/jampy \n @evanplaice \n @WebReflection \n @bhathos \n @joelnet \n github.com/GeoffreyBooth \n Further reading   # \n “The new ECMAScript module support in Node.js 12”  on 2ality \n Chapter “Modules”  in “JavaScript for impatient programmers” \n “Compatibility [of native ES modules] with CommonJS-only versions of Node.js”  in the Node.js docs \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/javascript-overview-of-regular.html", "title": "JavaScript: an overview of the regular expression API", "content": "JavaScript: an overview of the regular expression API dev javascript jslang regexp \n     [2013-08-08] New blog post: “ The flag /g of JavaScript’s regular expressions ”\n     \n     [2013-08-07] Explained how   and   work when the flag   is set.\n     \n Regular expression syntax \n     Escaping: the backslash escapes special characters, including the slash in regular expression literals (see below) and the backslash itself.\n     \n         If you specify a regular expression in a string you must escape twice: once for the string literal, once for the regular expression. For example, to just match a backslash, the string literal becomes  . \n         The backslash is also used for some special matching operators (see below). \n     \n     \n     Non-capturing group:   works like a capturing group for delineating the subexpression  , but does not return matches and thus does not have a group number. \n     Positive look-ahead:   means that   matches only if it is followed by  .   itself is not counted as part of the regular expression. \n     Negative look-ahead:   the negated version of the previous construct:   must not be followed by  . \n     Repetitions:   matches exactly n times,   matches at least n times,   matches at least n, at most m times. \n     Control characters:   matches Ctrl-X (for any control character X),   matches a linefeed,   matches a carriage return. \n     Back reference:   refers back to group n and matches its contents again. \n Creating a regular expression \n     Flags: boolean values indicating what flags are set.\n         \n             : is flag   set? \n             : is flag   set? \n             : is flag   set? \n         \n     \n     If flag   is set:\n         \n             : the index where to continue matching next time. \n         \n     \n RegExp.prototype.test(): determining whether there is a match String.prototype.search(): finding the index of a match RegExp.prototype.exec(): capture groups, optionally repeatedly \n     Properties:\n         \n             : The complete input string. \n             : The index where the match was found. \n         \n     \n     Array: whose length is the number of capturing groups plus one.\n         \n             0: The match for the complete regular expression (group 0, if you will). \n             n ≥ 1: The capture of group n. \n         \n     \n String.prototype.match(): capture groups or all matches String.prototype.replace(): search and replace \n     :\n         \n             either a string (to be found literally, has no groups) \n             or a regular expression. \n         \n     \n     :\n         \n             either a string describing how to replace what has been found \n             or a function that computes a replacement, given matching information. \n         \n     \n \n      inserts a dollar sign $. \n      inserts the complete match. \n      inserts the text before the match. \n      inserts the text after the match. \n      inserts group n from the match. n must be at least 1,   has no special meaning. \n \nExample:\n String.prototype.split(): splitting strings \n      can be\n         \n             a string: separators are matched verbatim \n             a regular expression: for more flexible separator matching. Many JavaScript implementations include the first capturing group in the result array, if there is one. \n         \n     \n      optionally specifies a maximum length for the returned array. A value less than 0 allows arbitrary lengths. \n Sources \n     ECMAScript Language Specification, 5th edition. \n     Regular Expressions  at the Mozilla Developer Network Doc Center \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/information-management-classics.html", "title": "Information management classics: Lifestreams (1996)", "content": "Information management classics: Lifestreams (1996) info mgmt computers Naming a file and choosing a storage location is unneeded overhead.\n Directories are inadequate as a classification\n  mechanism. Classification should be dynamic and multi-dimensional\n  (more than one “directory” a file can be in).\n Archiving should be automatic. Often users completely remove\n  files to avoid clutter. Putting them away in an organized (and\n  retrievable) way is difficult.\n Summarizing, compressing, visualizing groups of documents is\n  important and should scale.\n Computers should make “reminding” convenient. The goal should\n  be to make calendars active (send an email etc.) and integrate them\n  into the system.\n Personal data should be accessible anywhere and compatibility should be automatic (that is, many devices should be supported).\n \n  The past is used for archiving. \n The present holds what the user is currently working on. \n A date of creation can also be in the future, with the intention of the document being a reminder: something to be worked on in the future, an email to be sent automatically, an upcoming event, etc. \n \n “new” for creating a new unnamed document, without having to specify a storage location; \n “clone” for duplicating documents; \n “freeze” for making documents read-only; \n “transfer” for distributing documents, sending emails etc.; \n and “print” for printing documents. \n \n \n A substream is created by filtering either the global stream or another substream. It is updated dynamically, whenever documents change. \n \n One example of filtering is using the full-text “find” operation. The substream only comprises those documents of its superstream that contain the search text. \n \n A   of a stream is a dynamic document that summarizes one aspect of that stream. For example, “by document size” shows a table with document sizes. \n \n Email: is sent via the “transfer” operation. Automatic sending in the future is done by place the email creation date in the future. The future is thus a convenient metaphor for automation.\n \n Phone call records: the agent-supplied operation “make a phone call” automatically logs phone call records. A calling list can be created by summarizing them, possibly after a filtering step.\n \n Stock portfolio management: Each stock is a document. Summaries provide lists and graphs.\n \n Bookmark management: A daemon watches web browsers and automatically adds new bookmarks to a stream (as a URL document). These documents can be easily transfered to other users, via the “transfer” operation. \n \n \n Using time as the dominant criterion for ordering is smart, because it is intuitive and easily remembered. It also can be automatically attached as meta-data to documents. Conversely, document names have to be created manually. \n \n A similar kind of meta-data that is available to modern applications is geo-location. \n \n Splitting time into past, present, and future elegantly separates different ways of working with documents. However, this separation should probably be handled differently: \n \n Past, present: should be more like labels that are attached to documents, e.g. “archived” and “current”. \n Future: It is better to store a separate due date instead of using the date of creation, because even if with a reminder for the future, you will sometimes want to know when it was created. \n \n Delivering data to many devices (desktop computers, mobile phones, etc.) has been solved via webapps. It would still be a challenge if current smartphones didn’t have modern web browsers. \n Lifestreams Project Home Page comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/javascript-how-it-all-began.html", "title": "JavaScript: how it all began", "content": "JavaScript: how it all began dev javascript jslang jshistory \nA company called  Netscape  was founded in 1994 and created one of the first web browsers. They recruited Eich in 1995, because they wanted him to create a programming language for that web browser. The lure for him was that he would be able to base the language on Scheme (a Lisp dialect). Scheme’s influence led to JavaScript having closures. Another influence was the prototype-based programming language  Self  which is responsible for JavaScript’s prototypal inheritance (some of the elegance of this approach is hidden by JavaScript’s muddled adoption of it). Next, Java got included in the browser. It quickly gained popularity and influenced Netscape’s decisions regarding JavaScript. For example, its name:\n \n      That’s right. It was all within six months from May till December (1995) that it was Mocha and then LiveScript. And then in early December, Netscape and Sun did a license agreement and it became JavaScript.  [2] \n [3] \nEich blames some of JavaScript’s idiosynchracies on having had to finish a prototype quickly, which\nsubsequently was changed little before being deployed. His favorite JavaScript features  [4]  are:\n \n     First-class functions  \n     Closures  \n     Prototypes  \n     Object literals and array literals  \n Brendan’s Roadmap Updates: Popularity JavaScript creator ponders past, future The A-Z\n    of Programming Languages: JavaScript A Brief History of JavaScript \n     A brief history of ECMAScript versions (including Harmony/ES.next) \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/how-google-chrome-reduces-processor.html", "title": "How Google Chrome reduces the processor load of webapps", "content": "How Google Chrome reduces the processor load of webapps browser computers chrome several measures \n  which tracks a similar API on Firefox. Until now, if you wanted to animate 2D or 3D content, you had to use timers that called you back in regular intervals so that you could update the animated content. The new API works as follows: Instead of telling the browser to call you back each 1/25 second, you tell it to call you back when it is ready to let you draw the next animation frame. You can optionally specify where you are drawing. All this has has two advantages: \n \n You are not called back if the animated content is not currently visible (be it because it has scrolled out of view or because the tab is currently not visible). \n You are only called back as often as the platform can handle. Quoting Google: “Excessive CPU consumption by timers on web pages is not a theoretical \nproblem. We have measured web sites containing mostly static text \ncontent firing timers at a rate of over two hundred per second.” \n \n  If a tab isn’t visible then its timers are run at most once per second. This should still be enough for applications that need to be notified at a given time, but it will prevent invisible animations from slowing down the browser. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/03/first-look-at-upcoming-javascript.html", "title": "A first look at the upcoming JavaScript modules", "content": "A first look at the upcoming JavaScript modules esnext dev javascript \nJudging by a tweet by David Herman, he is excited about something (he is shouting!) and so should we be:\n @littlecalculist \n     Static scoping \n     Orthogonality from existing features \n     Smooth refactoring from global code to modular code \n     Fast compilation \n     Simplicity and usability \n     Standardized protocol for sharing libraries \n     Compatibility with browser and non-browser environments \n     Easy external loading \n \n     Module: the module as source, either defined inline or loaded externally. \n     Module instance: The evaluated module in use, linked to other modules. It has internal state and external (exported) bindings. \n     Module instance object: The module instance reified as an object. Naturally, only exported bindings are accessible. \n \n     All globals in a module are only module-global. This allows for shared state and nicely encapsulates things. \n     Cyclic dependencies are possible. \n     A module can be loaded dynamically, the resulting module instance object is handed to a callback. \n David Herman on ECMAScript.next \n harmony:modules [ES Wiki] \n Modules and namespaces in JavaScript  [patterns etc. for current-day ECMAScript 5] comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/singleton-pattern-and-its-simplest.html", "title": "The Singleton pattern and its simplest implementation in Java", "content": "The Singleton pattern and its simplest implementation in Java dev java \nThe Singleton is a design pattern [1] to ensure that a class has only a single instance. The name is derived from the mathematical term   which means a set with exactly one element. This pattern is mainly used if a class implements a service (which is usually instantiated only once). A typical Singleton looks as follows:\n \n     Enforce the constraint of exactly one instance. \n     Hint at how this class is to be used: To get an instance, one doesn’t invoke the constructor, but accesses the static variable. Thus, one cannot accidentally misuse the class. Classes with factory methods have private constructors for the same reason. \n \nAs an alternative to the above solutions, one could also use static methods and store internal state in static variables. But then one loses some of the amenities of instances, such as the ability to conform to an interface. Or the ability to pass around a reference and invoke methods. It should be noted that the Singleton pattern hampers testability, because Singletons are harder to replace in a test environment. If you want to implement services (or components) via classes, it is better to use dependency injection (e.g. via Guice [3]). In addition to increased configurability, you also get explicit dependencies stated in constructors.\n \nRelated reading:\n The classic book on design patterns, recommended: “ Design Patterns: Elements of Reusable Object-Oriented Software ” by Erich Gamma, Richard Helm, Ralph Johnson, John M. Vlissides. The  Wikipedia article  on the Singleton pattern (which inspired this post and from which the enum implementation is taken). Google Guice , a lightweight dependency injection framework for Java. The website also explains dependency injection well. The Singleton pattern in JavaScript: not needed comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/using-html5-figures-in-todays-browsers.html", "title": "Using HTML5 figures in today’s browsers", "content": "Using HTML5 figures in today’s browsers dev html5 comments powered by Disqus."},
{"url": "https://2ality.com/2019/05/unpacking-hoisting.html", "title": "Unpacking hoisting", "content": "Unpacking hoisting dev javascript Quoting  a recent tweet  by ES6 spec author Allen Wirfs-Brock: Hoisting is old and confused terminology. Even prior to ES6: did it mean “moved to the top of the current scope” or did it mean “move from a nested block to the closest enclosing function/script scope”? Or both? This blog post proposes a different approach to describing declarations (inspired by a suggestion by Allen). Declarations: scope and activation   # I propose to distinguish two aspects of declarations: \n Scope: Where can a declared entity be seen? This is a static trait. \n Activation: When can I access an entity? This is a dynamic trait: Some entities can be accessed as soon as we enter their scopes. For others, we have to wait until execution reaches their declarations. \n The following table summarizes how various declarations handle these aspects. “Duplicates” describes whether or not it is allowed to declare a name twice within the same scope. “Global prop.” describes if a declaration adds a property to the global object when it is executed in a   (a precursor to modules), in global scope.   means   (which is explained later). Function declarations are block-scoped in strict mode (e.g. inside modules), but function-scoped in non-strict mode. The following sections describe the behavior of some of these constructs in more detail.  and  : temporal dead zone   # For JavaScript, TC39 needed to decide what happens if you access a constant in its direct scope, before its declaration: Some possible approaches are: The name is resolved in the scope surrounding the current scope. You get  . There is an error. (1) was rejected, because there is no precedent in the language for this approach. It would therefore not be intuitive to JavaScript programmers. (2) was rejected, because then   wouldn’t be a constant – it would have different values before and after its declaration.  uses the same approach (3) as  , so that both work similarly and it’s easy to switch between them. The time between entering the scope of a variable and executing its declaration is called the   (TDZ) of that variable: \n During this time, the variable is considered to be uninitialized (as if that were a special value it has). \n If you access an uninitialized variable, you get a  . \n Once you reach a variable declaration, the variable is set to either the value of the initializer (specified via the assignment symbol) or   – if there is no initializer. \n The following code illustrates the temporal dead zone: The next example shows that the temporal dead zone is truly   (related to time): Even though   is located before the declaration of   and uses that variable, we can call  . But we have to wait until the temporal dead zone of   is over. Function declarations and early activation   # A function declaration is always executed when entering its scope, regardless of where it is located within the scope. That enables you to call a function   before it is declared: The early activation of   means that the previous code is equivalent to: If you declare a function via   or  , then it is not activated early: In the following example, you can only use   after its declaration. Calling ahead without early activation   # Even if a function   is not activated early, it can be called by a preceding function   (in the same scope) – if we adhere to the following rule:   must be invoked after the declaration of  . The functions of a module are usually invoked after its complete body was executed. Therefore, in modules, you rarely need to worry about the order of functions. Lastly, note how early activation automatically keeps the aforementioned rule: When entering a scope, all function declarations are executed first, before any calls are made. A pitfall of early activation   # If you rely on early activation to call a function before its declaration, then you need to be careful that it doesn’t access data that isn’t activated early. The problem goes away if you make the call to   after the declaration of  . The pros and cons of early activation   # We have seen that early activation has a pitfall and that you can get most of its benefits without using it. Therefore, it is better to avoid early activation. But I don’t feel strongly about this and, as mentioned before, often use function declarations, because I like their syntax. Class declarations are not activated early   # Class declarations are not activated early: Why is that? Consider the following class declaration:  is optional. Its operand is an expression. Therefore, you can do things like this: Evaluating such an expression must be done at the location where it is mentioned. Anything else would be confusing. That explains why class declarations are not activated early. : hoisting (partial early activation)   #  is an older way of declaring variables that predates   and   (which are preferred now). Consider the following   declaration. This declaration has two parts: \n Declaration  : The scope of a  -declared variable is the innermost surrounding function and not the innermost surrounding block, as for most other declarations. Such a variable is already active at the beginning of its scope and initialized with  . \n Assignment  : The assignment is always executed in place. \n The following code demonstrates  : comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/singleton-pattern-in-javascript-not.html", "title": "The Singleton pattern in JavaScript: not needed", "content": "The Singleton pattern in JavaScript: not needed dev javascript jslang \nAn object in an object-oriented language mostly plays one of two roles: It is either a data structure or a component providing a service. In the former case, you tend to make multiple copies (think tree nodes). In the latter case, often only a single copy is needed (think database manager). The singleton pattern (in mathematics, a singleton is a set with exactly one element) has been invented for class-based languages to help them implement components. In such languages, you cannot directly create the component object, you need a class to do so (there are exceptions, but let us ignore them for the sake of this post). With the singleton pattern, you pretend that the class   its single instance and create a one-to-one association between class and instance. The following is an implementation of the singleton pattern in Java [1]:\n \nSo how about JavaScript? It lets you directly create objects (being one of the few programming languages that allow you to do so) and there is no trickery necessary.\n Security considerations \n     Prevent copies from being made: Programmers coming from Java to JavaScript seem more concerned about this than others. You do this by completely hiding the instance’s constructor. Consult [3] for an in-depth treatise. \n     Prevent the singleton from being exchanged: An attacker might try to swap your singleton for their implementation. By making property   in the namespace read-only and non-configurable (i.e., the read-only setting cannot be changed), you can prevent that.\n \n     \n     Prevent changes to the singleton: The methods  ,  , and   give you (increasingly thorough) means to lock down an object [4]. \n     Keep data private: This again seems to be most important to Java people. See below for a solution. \n The Singleton pattern and its simplest implementation in Java JavaScript Getters and Setters The singleton design pattern in JavaScript \n Object.freeze Function (JavaScript) \n JavaScript variable scoping and its pitfalls comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/internet-explorer-10-is-good-for-webapp.html", "title": "Internet Explorer 10 is “native” and good for webapp developers", "content": "Internet Explorer 10 is “native” and good for webapp developers Internet Explorer 10 Preview \n ECMAScript 5 strict mode : enables a more modern dialect of JavaScript [2]. \n CSS3 Grid Layout : is great for laying out graphical user interfaces [3]. \n \n Website  arewenativeyet.com \n Mozilla Bug 649408 - Support Native HTML5  \n Announcement on IE blog: “ Native HTML5: First IE10 Platform Preview Available for Download ” JavaScript’s strict mode: a summary CSS3 Grid Layout is perfect for webapp GUIs   comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/javascript-converting-any-value-to.html", "title": "JavaScript: converting any value to an object", "content": "JavaScript: converting any value to an object dev javascript jslang ECMAScript 5 specification \n  uses an instance of   to access  . \n The   method sets   to   and invokes  , without any (explicit) parameters. \n  (ECMA-262, 15.2.4.4) invokes the internal abstract operation ToObject (ECMA-262, 9.9). This operation converts a primitive to a (wrapper) object and leaves an object untouched. Thus, given a value, you always end up with an object. \n JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2019/01/json-superset.html", "title": "ES2019: JSON superset", "content": "ES2019: JSON superset dev javascript es2019 json The proposal “ JSON superset ” (by Richard Gibson) is at  stage 4  and therefore part of ECMAScript 2019. This blog post explains how it works. At the moment, JSON (as standardized via  ECMA-404 ) is not a subset of ECMAScript: \n Until recently, ECMAScript string literals couldn’t contain the characters U+2028 LINE SEPARATOR and U+2029 PARAGRAPH SEPARATOR (you had to use an escape sequence to put them into a string). That is, the following source code produced a syntax error: \n \n JSON string literals can contain these two characters: \n \n Given that the syntax of JSON is fixed, a decision was made to remove the restriction for ECMAScript string literals. That simplifies the grammar of the specification, because you don’t need separate rules for ECMAScript string literals and JSON string literals. comments powered by Disqus."},
{"url": "https://2ality.com/2019/01/string-prototype-trimstart-trimend.html", "title": "ES2019:  String.prototype.trimStart  /  String.prototype.trimEnd", "content": "ES2019:   /  dev javascript es2019 The proposal “  /  ” (by Sebastian Markbåge) is at  stage 4  and therefore part of ECMAScript 2019. This blog post explains how it works. The string methods   and     # JavaScript already supports removing all whitespace from both ends of a string: The proposal additionally introduces methods for only trimming the start of a string and for only trimming the end of a string: Legacy string methods:   and     # Many web browsers have the string methods   and  . Those were added to Annex B of the ECMAScript specification (as aliases for   and  ): features that are required for web browsers and optional elsewhere. For the core standard, this proposal chose different names, because “start” and “end” make more sense than “left” and “right” for human languages whose scripts aren’t left-to-right. In that regard, they are consistent with the string methods   and  . What characters count as whitespace?   # For trimming, whitespace means: \n WhiteSpace code points ( spec ):\n \n  (CHARACTER TABULATION, U+0009) \n  (LINE TABULATION, U+000B) \n  (FORM FEED, U+000C) \n  (SPACE, U+0020) \n  (NO-BREAK SPACE, U+00A0) \n  (ZERO WIDTH NO-BREAK SPACE, U+FEFF) \n Any other Unicode character with the property   in category   ( ). \n \n \n LineTerminator code points ( spec ):\n \n  (LINE FEED, U+000A) \n  (CARRIAGE RETURN, U+000D) \n  (LINE SEPARATOR, U+2028) \n  (PARAGRAPH SEPARATOR, U+2029) \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/04/nodejs-esm-impl.html", "title": "The new ECMAScript module support in Node.js 12", "content": "The new ECMAScript module support in Node.js 12 dev javascript nodejs jsmodules   “Hybrid npm packages (ESM and CommonJS)” Node.js 12 (which was released on 2019-04-23) brings improved support for ECMAScript modules. It implements phase 2 of  the plan that was released late last year . For now, this support is available behind the usual flag  . Read on to find out how exactly this new support for ECMAScript modules works. Brief spoiler: The filename extension   will be more convenient, but   can also be enabled for ES modules. Terms and abbreviations used in this blog post   # \n CommonJS module (CJS): refers to the original Node.js module standard. \n ECMAScript module (ES module, ESM): refers to modules as standardized via the ECMAScript specification. \n  means property   of  . \n Module specifiers   #  are the strings that identify modules. They work slightly differently in CommonJS modules and ES modules. Before we look at the differences, we need to learn about the different categories of module specifiers. Categories of module specifiers   # In ES modules, we distinguish the following categories of specifiers. These categories originated with CommonJS modules. \n \n Relative path: starts with a dot. Examples: \n \n \n \n Absolute path: starts with a slash. Example: \n \n \n \n URL: includes a protocol (technically, paths are URLs, too). Examples: \n \n \n \n Bare path: does not start with a dot, a slash or a protocol, and consists of a single filename without an extension. Examples: \n \n \n \n Deep import path: starts with a bare path and has at least one slash. Example: \n \n \n CommonJS module specifiers   # This is how CommonJS handles module specifiers: \n CommonJS does not support URLs as specifiers. \n Relative paths and absolute paths are handled as expected. \n You can load a directory   as a module:\n \n If there is a file  \n If there is a file   whose property   points to a module file. \n \n \n Bare paths and deep import paths are resolved against a directory   that is found:\n \n In the same directory as the importing module \n In the parent of that directory \n Etc. \n \n \n If a specifier   does not refer to a file, the system tries the specifiers  ,   and  . \n Additionally, CommonJS modules have access to two special module-global variables: \n : contains the path of the current module. \n : contains the path of the parent directory of the current module. \n Source of this section: page  “Modules”  of the Node.js documentation. ES module specifiers in Node.js   # \n All specifiers, except bare paths, must refer to actual files. In contrast to CommonJS, ESM does not add missing filename extensions. \n Only   is supported as a protocol for URL specifiers. \n Absolute paths are currently not supported. As a work-around, you can use a URL that starts with  . \n Relative paths are resolved as they are in web browsers – relative to the path of the current module. \n Bare paths are resolved relative to a   directory. The module that a bare path refers to, is specified via   (similarly to CJS). \n Deep import paths are also resolved relative to a   directory. \n Importing directories is not supported. In other words, neither   (which can only be used for packages) nor   work. \n All built-in Node.js modules are available via bare paths and have named ESM exports. For example: Filename extensions   # Node.js supports the following default filename extensions: \n  for ES modules \n  for CommonJS modules \n The filename extension   stands for either ESM or CommonJS. Which one it is, depends on  , which has two settings: \n \n  (the default): files with the extension   or without an extension are parsed as CommonJS. \n \n \n \n : files with the extension   or without an extension are parsed as ESM. \n \n \n To find the   for a given file, Node.js searches in the same directory as the file, the parent directory, etc. Interpreting non-file source code as either CommonJS or ESM   # Not all source code that is executed by Node.js, comes from files. You can also send it code via stdin,   and  . The command line option   lets you specify how such code is interpreted: \n As CommonJS (the default):  \n As ESM:  \n Interoperability   # Importing CommonJS from ESM   # At the moment, you have two options for importing a CommonJS module from an ES module. Consider the following CommonJS module. The first option is to default-import it (support for named imports may be added in the future): The second option is to use  : Importing ESM from CommonJS   # If you want to import an ES module from a CommonJS module, you can use  the   operator . As an example, take the following ES module: Here we import it from a CommonJS module: Various other features   #    # Given that   and   are not available in ES modules, we need an alternative.   is that alternative. It contains a   URL with an absolute path. For example: Important: Use   to extract the path –   doesn’t always work properly: The inverse of   is  : it converts a path to a file URL. We’ll see an example of using   and   later in this post.    #  contains a promisified version of the   API and works as expected:    # With the flag  , Node.js loads   files as JSON. Take, for example, the JSON file  : We can import it from an ES module as follows (if we use both the flag for ESM and for JSON modules): ES modules on npm   # At the moment, with a bare path  , you have to decide between: \n \n \n You can’t do both (deep import paths are a reasonable work-around). An effort to change that is ongoing. It will probably be done by making   more powerful. Until that feature is ready, the people working on it, have  the following request : “Please do not publish any ES module packages intended for use by Node.js until this is resolved.” Using ES modules on Node.js   # Starting with Node.js 12, you have the following options for using ES modules on Node.js: \n Via a library:  esm  by  John-David Dalton .   also supports older versions of Node.js. \n Flag   ( documentation ) \n The flag for ESM support will probably be removed in October 2019, when Node.js 12 reaches LTS status. Further reading and sources of this blog post   # \n Three pieces of official documentation were important sources for this blog post:\n \n The pull request  for the new ESM implementation \n The blog post announcing the new implementation \n The API documentation for the new implementation \n \n \n For more information on scripts, CommonJS modules and ES modules, consult chapter “ Modules ” of “JavaScript for impatient programmers” \n  – thanks for reviewing this blog post: \n Rob Palmer \n Guy Bedford \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/07/public-class-fields.html", "title": "ECMAScript proposal: public class fields", "content": "ECMAScript proposal: public class fields dev javascript es proposal js classes This blog post is part of a series on new members in bodies of class definitions: Public class fields Private class fields Private prototype methods and getter/setters in classes Private static methods and getter/setters in classes In this post, we look at  , which create instance properties and static properties. \n   \n     Overview \n     \n       \n         Public instance fields \n       \n       \n         Public static fields \n       \n     \n   \n   \n     Public instance fields and public static fields \n     \n       \n         Public instance fields \n       \n       \n         Public static fields \n       \n     \n   \n   \n     Why the name public fields? \n   \n   \n     Example: replacing a constructor with a field \n   \n   \n     (Advanced) \n   \n   \n     Assignment vs. definition \n     \n       \n         Assigning to properties \n       \n       \n         Defining properties \n       \n       \n         The pros and cons of using definition for public fields \n       \n     \n   \n   \n     When are public instance fields executed? \n   \n   \n     The scope of field initializers \n   \n   \n     The property attributes of public fields \n   \n   \n     Availability \n   \n Overview   # Public instance fields   # Computed field keys are similar to  computed property keys  in object literals. Public static fields   # Public instance fields and public static fields   # Public instance fields   # The motivation for public fields is as follows. Sometimes, you have an assignment in a constructor that creates an instance property, but is not influenced by any other data in the constructor (such as a parameter): In such a case, you can use a field to move the creation of   out of the constructor: You can also omit the initializer ( ). In that case, the property is initialized with  : Public static fields   # At the moment, JavaScript has no way of creating a static property within a class; you have to create it via an external assignment: One work-around is to create a static getter: A static field provides a more elegant solution: Why the name  ?   # Public fields create properties. They have the name “fields” to emphasize how syntactically similar they are to   (which are the subject of an upcoming blog post). Private fields do not create properties. Similarly, “public” describes the nature of public fields, when compared to private fields. Example: replacing a constructor with a field   # This is a brief, more realistic example where we can also replace the constructor with a field: If we move the creation of   out of the constructor, we don’t need the constructor, anymore: (Advanced)   # The remaining sections cover advanced aspects of public fields. Assignment vs. definition   # There is one important way in which creating a property via a constructor and creating a property via a field differ: The former uses  ; the latter uses  . What do these two terms mean? Assigning to properties   # Let’s first take a look at how   to properties works with plain objects. This operation is triggered by the assignment operator ( ). In the following example, we assign to property   (line A): In classes, creating a property via assigning also invokes a setter (if there is one). In the following example, we create property   (line A): Defining properties   # Again, we are starting our examination with plain objects. How does   a property work? There is no operator for defining, we need to use the helper method  : The last argument of   is a  , an object that specifies the   (characteristics) of a property.   is one such characteristic. Others include   – whether the value of a property can be changed. A public field creates a property via definition, not via assignment: That is, public fields always create properties and ignore setters. The pros and cons of using definition for public fields   # There are arguments   using definition for public fields: \n If we move the creation of a property out of the constructor, to a field, then the behavior of our code changes. That is a refactoring hazard. \n Until now, using the assignment operator   for properties always triggered assignment. \n These are the arguments in favor of using definition: \n The mental model for entities declared at the top level of a class is  : The entity will always be created, independently of what is inherited. \n Precedents for creating properties via definition include: property definitions in object literals and prototype declarations in classes. \n As so often, the decision to use definition (and not assignment) is a compromise where the pros and cons were weighed. When are public instance fields executed?   # The execution of public instance fields roughly follows these two rules: \n In base classes, public instance fields are executed immediately before the constructor. \n In derived classes, public instance fields are executed immediately after  . \n This is what that looks like: The scope of field initializers   # In the initializer of a public instance field,   refers to the current instance: In the initializer of a public static field,   refers to the current class: Additionally,   works as expected: The property attributes of public fields   # By default, public fields are writable, enumerable and configurable: For more information on the property attributes  ,  ,   and  , see “ JavaScript for impatient programmers ”. Availability   # Class fields are currently implemented in: \n Babel 7.0+ . Before this feature is at stage 4, it must be switched explicitly, via the plugin  . \n Node.js 12+ \n Chrome:\n \n Public fields:  Chrome 72+ \n Private fields:  Chrome 74+ \n \n \n For more information, see  the proposal . comments powered by Disqus."},
{"url": "https://2ality.com/2019/07/global-scope.html", "title": "How do JavaScript’s global variables really work?", "content": "How do JavaScript’s global variables really work? dev javascript es feature In this blog post, we examine how JavaScript’s global variables work. Several interesting phenomena play a role: the scope of scripts, the so-called  , and more. Scopes   # The   (short:  ) of a variable is the region of a program where it can be accessed. JavaScript’s scopes are   (they don’t change at runtime) and they can be nested – for example: The scope introduced by the   statement (line B) is nested inside the scope of function   (line A). The innermost surrounding scope of a scope S is called the   of S. In the example,   is the outer scope of  . Lexical environments   # In the JavaScript language specification, scopes are “implemented” via  . They consist of two components: \n \n An   (think dictionary) that maps variable names to variable values. This is where JavaScript stores variables. One key-value entry in the environment record is called a  . \n \n \n A reference to the   – the environment representing the outer scope of the scope represented by the current environment. \n \n The tree of nested scopes is therefore represented by a tree of nested environments, linked by   references. The global object   # The global object is an object whose properties are global variables. (We’ll examine soon how exactly it fits into the tree of environments.) It has several different names: \n Everywhere ( proposed feature ):  \n Other names for the global object depend on platform and language construct:\n \n : is the classic way of referring to the global object. But it only works in normal browser code; not in Node.js and not in   (processes running concurrently to normal browser code). \n : is available everywhere in browsers, including in Web Workers. But it isn’t supported by Node.js. \n : is only available in Node.js. \n \n \n The global object contains all built-in global variables. The global environment   # The global scope is the “outermost” scope – it has no outer scope. Its environment is the  . Every environment is connected with the global environment via a chain of environments that are linked by outer references. The outer reference of the global environment is  . The global environment combines two environment records: \n An   that works like a normal environment record, but keeps its bindings in sync with an object. In this case, the object is the global object. \n A normal ( ) environment record. \n The following diagram shows these data structures.   and   are explained soon. The next two subsections explain how the object record and the declarative record are combined. Creating variables   # In order to create a variable that is truly global, you must be in global scope – which is only the case at the top level of scripts: \n Top-level  ,  , and   create bindings in the declarative record. \n Top-level   and function declarations create bindings in the object record. \n Additionally, the global object contains all built-in global variables and contributes them to the global environment via the object record. Getting or setting variables   # When we get or set a variable and both environment records have a binding for that variable, then the declarative record wins: Module environments   # Each module has its own environment. It stores all top-level declarations – including imports. The outer environment of a module environment is the global environment. Conclusion: Why does JavaScript have both normal global variables and the global object?   # The global object is generally considered to be a mistake. For that reason, newer constructs such as  ,  , and classes create normal global variables (when in script scope). Thankfully, most of the code written in modern JavaScript, lives in  ECMAScript modules and CommonJS modules . Each module has its own scope, which is why the rules governing global variables rarely matter for module-based code. Further reading   # \n Blog post  “ES proposal:  ” \n Sect.  “Lexical Environments”  in the ECMAScript specification provides a general overview over environments. \n Sect.  “Global Environment Records”  covers the global environment. \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/07/private-class-fields.html", "title": "ECMAScript proposal: private class fields", "content": "ECMAScript proposal: private class fields dev javascript es proposal js classes This blog post is part of a series on new members in bodies of class definitions: Public class fields Private class fields Private prototype methods and getter/setters in classes Private static methods and getter/setters in classes In this post, we look at  , a new kind of private slot in instances and classes. This feature is specified by two ECMAScript proposals: \n “Class public instance fields & private instance fields”  by Daniel Ehrenberg, Jeff Morrison, Kevin Smith, and Kevin Gibbons. \n “Class public static fields, private static methods, private getters/setters”  by Daniel Ehrenberg, Kevin Gibbons, Jeff Morrison, Kevin Smith, and Shu-Yu Guo \n \n   \n     Overview \n     \n       \n         Private static fields \n       \n       \n         Private instance fields \n       \n     \n   \n   \n     From underscores to private instance fields \n     \n       \n         Starting with underscores \n       \n       \n         Switching to private instance fields \n       \n     \n   \n   \n     All code inside the body of a class can access all private fields \n   \n   \n     (Advanced) \n   \n   \n     How are private fields managed under the hood? \n     \n       \n         Each evaluation of a class definition produces new private names \n       \n     \n   \n   \n     Pitfall: Using   to access private static fields \n     \n       \n          and public static fields \n       \n       \n          and private static fields \n       \n     \n   \n   \n     “Friend” and “protected” privacy \n   \n   \n     FAQ \n     \n       \n         Why the  ? Why not declare private fields via  ? \n       \n     \n   \n   \n     Further reading \n   \n Overview   # Private fields are a new kind of data slot that is different from properties. They can only be accessed directly inside the body of the class in which they are declared. Private static fields   # Tip: Never use   to access a private static field, always use the direct class name (as in line A). Why is explained  later in this post . Private instance fields   # Using private fields with   (equal signs followed by values): Using private instance fields without initializers: From underscores to private instance fields   # A common technique for keeping data private in JavaScript is to prefix property names with underscores. In this section, we’ll start with code that uses this technique and then change it, so that it uses private instance fields. Starting with underscores   # This technique doesn’t give us any protection; it merely suggests to people using this class: Don’t touch these properties, they are considered private. The main benefit of this technique is that it is convenient. With private fields, we don’t lose the convenience and gain true privacy. Switching to private instance fields   # We can switch from underscores to private fields in two steps: We replace each underscore with a hash symbol. We declare all private fields at the beginning of the class. All code inside the body of a class can access all private fields   # For example, instance methods can access private static fields: And static methods can access private instance fields: (Advanced)   # The remaining sections cover advanced aspects of private fields. How are private fields managed under the hood?   # In the ECMAScript specification, private fields are managed via a data structure that is attached to objects. That is, private fields are roughly handled as follows. Comments: \n In this example, everything that has two underscores, is metadata that is managed by the JavaScript engine and only accessible to it. \n  are unique keys. They are only accessible inside the body of the class. \n  is a dictionary that maps private names to values. Each instance with private fields has such a dictionary.\n \n Due to   only being accessible to the engine, we don’t need to take measures to protect it. \n (As an aside, the specification stores private field values in lists. However, using a   made the example easier to understand.) \n After setup, if you use a private name that is not already a key in   then the engine throws a  . \n \n \n Consequences: \n You can only access the private data stored in   and   if you are inside the body of class   – because you only have access to the private names there. \n Private fields are not accessible in subclasses. \n Each evaluation of a class definition produces new private names   # Sometimes you evaluate the same class definition multiple times. That’s what   does in the following example: The private name   is created freshly each time. Therefore,   works for  , but not for  : Pitfall: Using   to access private static fields   # You can use   to access public static fields, but you shouldn’t use it to access private static fields.  and public static fields   # Consider the following code: Public static fields are properties. If we make the method call: then   points to   and everything works as expected. We can also invoke   via the subclass:  inherits  ,   points to   and things continue to work, because   also inherits the property  . (As an aside, setting   in this case would create a new property inside   that non-destructively overrides the property in  .)  and private static fields   # Consider the following code: Invoking   via   works, because   points to  : However, invoking   via   does not work, because   now points to   and   has no private static field  : The work-around is to accesss   directly, via  : “Friend” and “protected” privacy   # Sometimes, we want certain entities to be “friends” of a class. Such friends should have access to the private data of the class. In the following code, the function   is a friend of the class  . We use WeakMaps to make data private, which allows   to let friends access that data. It is easy to control who has access to the private data: If they have access to   and  , they have access to the private data. If we put the previous code fragment inside a module then the data is private within the whole module. For more information on this technique, consult Sect.  “Keeping private data in WeakMaps”  in “JavaScript for impatient programmers”. It also works for sharing private data between a superclass and subclasses (“protected” visibility). FAQ   # Why the  ? Why not declare private fields via  ?   # In principle, private fields could be handled as follows: Whenever an expression such as   appears in the body of  , JavaScript has to decide: \n Is   a public property? \n Is   a private field? \n Statically, JavaScript doesn’t know if the declaration   applies to   (due to it being an instance of  ) or not. That leaves two options for making the decision:  is always interpreted as a private field. JavaScript decides at runtime:\n \n If   is an instance of  , then   is interpreted as a private field. \n Otherwise   is interpreted as a public property. \n \n Both options have downsides: \n With option (1), we can’t use   as a public property, anymore – for any object. \n With option (2), there is a performance penalty. \n That’s why the name prefix   was introduced. The decision is now easy: If we use  , we want to access a private field. If we don’t, we want to access a public property.  works for statically typed languages (such as TypeScript) because they know at compile time if   is an instance of   and can then treat   as private or public. Further reading   # \n Chap.  “WeakMaps ( )”  in “JavaScript for impatient programmers”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/07/optional-chaining.html", "title": "ES2020: optional chaining", "content": "ES2020: optional chaining dev javascript es feature es2020 This blog post describes the ECMAScript proposal  “Optional chaining”  by Gabriel Isenberg, Claude Pache, and Dustin Savery. Overview   # The following kinds of optional operations exist. The rough idea is: \n If the value before the question mark is neither   nor  , then perform the operation after the question mark. \n Otherwise, return  . \n Example: optional static property access   # Consider the following data: We can use optional chaining to safely extract street names: Handling defaults via nullish coalescing   # The proposed  nullish coalescing operator  allows us to use the default value   instead of  : (Advanced)   # The remaining sections cover advanced aspects of optional chaining. The operators in more detail   # Optional static property access   # The following two expressions are equivalent: Examples: Optional dynamic property access   # The following two expressions are equivalent: Examples: Optional function or method call   # The following two expressions are equivalent: Examples: Note that this operator produces an error if its left-hand side is not callable: Why? The idea is that the operator only tolerates deliberate omissions. An uncallable value (other than   and  ) is probably an error and should be reported, rather than worked around. Short-circuiting   # In a chain of property accesses and function/method invocations, evaluation stops once the first optional operator encounters   or   at its left-hand side: This behavior differs from a normal operator/function where JavaScript always evaluates all operands/arguments before evaluating the operator/function. It is called  . Other short-circuiting operators: \n \n \n \n Alternatives to optional chaining   # Until now, the following alternatives to optional chaining were used in JavaScript.  operator   # The following two expressions are roughly equivalent: For each  ,   is only evaluated (and returned) if   is truthy.   therefore acts as a condition or guard for  . # Apart from the verbosity, using   has two downsides. First, if it fails,   returns its left-hand side, while   always returns  : Second,   fails for all falsy left-hand sides, while   only fails for   and  : Note that, here,   returning its left-hand side is worse than in the previous example. Destructuring   # In principle, you can also use destructuring for handling chained property accesses. But it’s not pretty: Lodash     # The function   of the Lodash library is another alternative to optional chaining. For example, the following two expressions are equivalent: Availability of optional chaining   # \n Babel has the plugin  . \n For availability elsewhere, please consult  MDN web docs . \n Frequently asked questions   # Why are there dots in   and  ?   # The syntaxes of the following two optional operator are not ideal: Alas, the less elegant syntax is necessary, because distinguishing the ideal syntax (first expression) from the conditional operator (second expression) is too complicated: Why does   evaluate to   and not  ?   # The operator   is mainly about its right-hand side: Does property   exist? If not, stop early. Therefore, keeping information about its left-hand side is rarely useful. However, only having a single “early termination” value does simplify things. comments powered by Disqus."},
{"url": "https://2ality.com/2019/07/private-methods-accessors-in-classes.html", "title": "ECMAScript proposal: private prototype methods and accessors in classes", "content": "ECMAScript proposal: private prototype methods and accessors in classes dev javascript es proposal js classes This blog post is part of a series on new members in bodies of class definitions: Public class fields Private class fields Private prototype methods and getter/setters in classes Private static methods and getter/setters in classes In this blog post, we look at private methods and private accessors (getters and setters) for JavaScript classes. They are a new kind of class member that can’t be accessed outside the body of their class. To understand this post, you should be familiar with  private class fields . This feature is the subject of the ECMAScript proposal  “Private methods and getter/setters for JavaScript classes”  by Daniel Ehrenberg and Kevin Gibbons. \n   \n     Overview: private prototype methods and accessors \n   \n   \n     From a naming convention to true privacy \n   \n   \n     How are private methods handled in the ECMAScript specification? (advanced) \n     \n       \n         Private names \n       \n       \n         Private brand checks \n       \n     \n   \n   \n     Implementations \n   \n   \n     Further reading \n   \n Overview: private prototype methods and accessors   # The following kinds of private prototype methods and accessors exist: As you can see, their names are prefixed with the same symbol   as private class fields, which indicates that they are private. From a naming convention to true privacy   # In the following code, the name of method   starts with an underscore. That is a hint to clients of that class that this method is private, but it doesn’t make it truly private: It can still be accessed outside the body of class  . In the next code fragment, we turn   into a private method  : How are private methods handled in the ECMAScript specification? (advanced)   # The following code illustrates how the specification handles the private method of class  . Private accessors are handled similarly. Private names   # Similarly to private fields , there is a private name ( ). This name is only accessible in the body of the class. The private method   is stored in the private name, in property   (line A). Property   indicates that the private method is   (but not stored in)  . What does that mean? \n Due to   not being stored in  , it can’t be accessed outside the body of the class. \n  is set up with   as its  . As a consequence, if you use   inside  , the search for   starts inside  . For details, read section  “Referring to superproperties in methods”  in “Exploring ES6”. \n Private brand checks   # In the previous section, we have seen that the   of a private method is the prototype object it is associated with. In the internal field  , each object records the private brands of its private methods and private accessors. This field is set up by the constructors. Before invoking a private method or private accessor, there is always a  . That check ensures that the private method is associated with one of the (original) prototypes of the receiver object ( ). Implementations   # Babel has two relevant plugins: \n Class fields:  \n Private methods and private accessors:  \n You can use those plugins in  the Babel REPL , but you need to add them in order to activate them (bar on the left, section “Plugins”). Further reading   # \n Chapter  “Classes”  in “JavaScript for impatient programmers” \n Section  “Referring to superproperties in methods”  in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/07/testing-static-types.html", "title": "Testing static types in TypeScript", "content": "Testing static types in TypeScript dev typescript  This is experimental work. Read the comments for more information on its limitations. In this blog post, we’ll examine how we can test static types in TypeScript (inferred types, etc.). For example, given the following function: We’d like to check in a unit test that TypeScript infers this return type: In order to do that, we need a few tools that we are going to look at first. Resources you may find useful while reading this blog post   # \n If you want a quick refresher for TypeScript’s type notation, you can check out “ Understanding TypeScript’s type notation ”. It explains terms such as   and  . \n If you want to examine the code that is shown here, I recommend  TypeScript’s Playground , which displays inferred types and more. \n Conditional types   # A conditional type  lets you switch between two types, depending on whether a given type fulfills a type assertion: In this case, “fulfilling” means: Is   a subtype of  ? If you think of types as sets then “subtype of” means “subset of”. At the moment ( due to limitations of TypeScript type inference ), conditional types are mainly useful for computing with types. And not, e.g., to type the results of functions. A simple example   # In the following example, we store the result of computing with types in a type  : Note that   and   are types here (so-called  ). Parameterized types as functions for types   # In the following example, we use the     like a function for types.   is a  . Asserting types via conditional types   # We can use conditional types to test static types. For example, via the following parameterized type: This type has a parameter   whose value is a static type. If that type is a subtype of  , the result of using   is the type  . Otherwise, it is the type  . If a variable has that type then no real value can be assigned to it. This is an example of using   – we want to check that   does have the statically inferred type   (or a subtype): The next example checks if   does have the type   and fails. As an aside, the following simplification of this technique does not work: The condition of   goes to the else branch, but the resulting type   is not in conflict with anything and does not produce an error. Extracting return types   # TypeScript provides several  parameterized utility types . One of them is relevant for us here: Its result is the return type of a function type. In the next example, we use it to assert that the return type of   is  : Generic type tests   # The following parameterized type builds on the ideas we have already seen and checks whether a given type   is equal to an expected type  : We are checking two conditions: \n Is   a subtype of  ? \n Is   a subtype of  ? \n If both are true then   is equal to  .  in action   # The following example uses  : We can also just check the inferred return type: Further resources   # \n Important source of this blog post: “ TypeScript compile-time inference assertions ” by  Sufian Rhazi . \n The Microsoft tool  dtslint  lets you check static types via  . \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/iterating-over-arrays-and-objects-in.html", "title": "Iterating over arrays and objects in JavaScript", "content": "Iterating over arrays and objects in JavaScript dev javascript jslang  loops, array methods (courtesy of ECMAScript 5 [1]), listing property keys.  loops \n     break [label]: exit from a loop. \n     continue [label]: stop the current loop iteration, immediately continue with the next one. \n     label: A label is an identifier followed by a colon. In front of a loop, a label allows you to break or continue that loop even from a loop nested inside of it. In front of a block, you can break out of that block. In both cases the name of the label becomes an argument of   or  . Example for breaking out of a block:\n \n     \n \n     Traditional way of iterating over arrays. \n     Can use  , but scope is always the complete surrounding function. \n \n     Iterate over property keys, including inherited ones. \n     Don’t use for arrays. It iterates over both array indices and property keys. There will thus be problems as soon as someone adds a property to an array. \n     Can use  , but scope is always the complete surrounding function. \n     Properties can be deleted during iteration. \n Array methods for iteration Iterate \n     \n        The callback has the following signature (sometimes it returns no value, sometimes a boolean).\n \n     \n     The   argument allows you to specify an object that is to be accessed via   in  . \n \n      is similar to  , but only iterates over an object’s own properties. \n     : returns   if the callback returns   for every element. \n     : returns   if the callback returns true for at least one element. \n Transform \n     : Each output array element is the result of applying   to an input element. \n     : The output array contains only those input elements for which   returns true. \n Reduce \n     : Compute a value by applying   to pairs ( ,  ) of array elements.\n     \n     : Same as  , but from right to left. \n Listing property keys \n     : Lists all enumerable own property keys of an object. Example:\n \n     \n     : Lists all own property keys of an object, including non-enumerable ones.\n \n        Comment: The main reason that prototype methods are not enumerable is to hide them from iteration mechanisms that include inherited properties.\n     \n Best practices Iterating over arrays \n     Simple   loop. \n     One of the iteration methods. \n     Never use   or  . \n Iterating over objects \n     Combine   with  , in the manner described above. \n     Combine   or   with   array iteration.\n \n     \n \n     Iterate over the property (key,value) pairs of an object: Iterate over the keys, use each key to retrieve the corresponding value. Other languages make this simpler, but not JavaScript. \n Related reading What’s new in ECMAScript 5 comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/ecmascript-5-spec-lexicalenvironment.html", "title": "ECMAScript 5 spec: LexicalEnvironment versus VariableEnvironment", "content": "ECMAScript 5 spec: LexicalEnvironment versus VariableEnvironment dev javascript jslang \n  You will have a much easier time understanding this post if you already know how environments work in ECMAScript 5.\n \nLet us start with a quick summary of environments and execution contexts in ECMAScript 5:\n \n     The declaration is moved to the beginning of the surrounding function as  . \n     The initializer becomes a simple assignment   that replaces the declaration. \n Data structures \n A reference to the outer environment (  in the global environment).\n An   maps identifiers to values. There are two kinds of environment records:\n     \n         declarative environment records: store the effects of variable declarations, and function declarations. \n         object environment records: are used by the   statement and for the global environment. They turn an object into an environment. For  , that is the argument of the statement. For the global environment, that is the global object. \n     \n \n     Environments: two references to environments.\n         \n             LexicalEnvironment (lookup and change existing): resolve identifiers. \n             VariableEnvironment (add new): hold bindings made by variable declarations\n              and function declarations. \n         \n        Both are usually the same. The next sections explain situations where they diverge.\n     \n ThisBinding: the current value of  . \n Handling temporary scopes via LexicalEnvironment and VariableEnvironment \n     LexicalEnvironment temporarily points to a new environment that has been put in front of the old LexicalEnvironment. The new environment holds the temporary bindings of the inner scope. \n     VariableEnvironment does not change its value and is thus still the same as the old LexicalEnvironment, denoting the outer scope. New bindings are added here and will also be found when doing a lookup via LexicalEnvironment, because the latter comes before the former in the environment chain. \n     After leaving the temporary scope, LexicalEnvironment’s old value is restored and it is again the same as VariableEnvironment. \n  statement [ES5, 12.10]: the object that is the argument of the statement becomes a temporary environment.  clause [ES5, 12.14]: the exception that is the argument of this clause is made available via a temporary environment. Functions and their scope: declarations versus expressions \nIf you instead use a function expression, the output is “bar” on all platforms.\n \nReferences:\n Standard ECMA-262: ECMAScript Language Specification comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/ecmascriptnext-features-are-taking.html", "title": "ECMAScript.next features are taking shape", "content": "ECMAScript.next features are taking shape esnext dev javascript \n Harmony proposals : Features that browser vendors (in the  TC39  [2]) agreed should be part of ECMAScript.next. Highlights: \n \n Destructuring assignment \n Iterators \n Generators \n Modules \n \n Strawman : Proposals where TC39 is still debating whether to include them in ECMAScript.next or not. Quoting a  tweet  by Brendan Eich: \nExamples: \n \n Shorter function syntax \n Data structures: maps, sets, ... \n Class abstractions \n Paren-free syntax \n \n More blog posts on ECMAScript.next:  ecmascript.next . ECMA, TC-39, and Bears - Oh My! Eich’s ECMAScript.next status update: arrow function syntax, classes, transpilers    comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/creating-new-programming-languages-is.html", "title": "Creating new programming languages is becoming easier ... and harder", "content": "Creating new programming languages is becoming easier ... and harder programming languages dev talked Rust , thanks to platforms such as  LLVM  and the JVM. , because modern IDEs such as Eclipse have made it clear that you cannot separate a language from its tools. My favorite example, expressed in pseudo-arithmetic: \nIn other words: Eclipse fixes some of Java’s deficiencies. Note that this is an old lesson that has long ago been taught by languages that come with sophisticated development environments (e.g.  Smalltalk  or  Genera ). But this lesson is just now becoming mainstream again. comments powered by Disqus."},
{"url": "https://2ality.com/2011/04/modules-and-namespaces-in-javascript.html", "title": "Patterns for modules and namespaces in JavaScript", "content": "Patterns for modules and namespaces in JavaScript dev javascript jslang Bridging the module gap between Node.js and browsers \nJavaScript does not come with support for modules. This blog post examines patterns and APIs that provide such support. It is split into the following parts:\n Patterns for structuring modules. APIs for loading modules asynchronously. Related reading, background and sources. Patterns for structuring modules \n     Namespacing: A top-level module is put into a global variable. That variable is the namespace of the module content. \n     Holding content: Each property of the module holds a value. \n     Nesting modules: One achieves nesting by putting a module inside another one. \n Filling a module with content  Object literal.\n         \n             Pro: Elegant syntax. \n             Con: As a single, sometimes very long syntactic construct, it imposes constraints on its contents. One must maintain the opening brace before the content and the closing brace after the content. And one must remember to not add a comma after the last property value. This makes it harder to move content around. \n         \n      Assigning to properties.\n         \n             Con: Redundant repetitions of the namespace identifier. \n         \n     The Module pattern: private data and initialization \n     Con: Harder to read and harder to figure out what is going on. \n     Con: Harder to patch. Every now and then, you can reuse existing code by patching it just a little. Yes, this breaks encapsulation, but it can also be very useful for temporary solutions. The module pattern makes such patching impossible (which may be a feature, depending on your taste). \n     Alternative for private data: use a naming convention for private properties, e.g. all properties whose names start with an underscore are private. \n Referring to sibling properties \n     Module pattern with object literal: assign the object to a local variable before returning it. \n     Module pattern with parameter: the parameter is the custom identifier. \n Private data and initialization for properties Types in object literals \n     Use an inheritance API where constructor and prototype can be defined simultaneously [4]. \n     Wrap the two parts of the type in an IIFE:\n \n     \n Managing namespaces APIs for loading modules asynchronously The file is downloaded. The file is interpreted. RequireJS RequireJS website \nRequireJS tries to keep with the spirit of CommonJS, with using string names to refer to dependencies, and to avoid modules defining global objects, but still allow coding a module format that works well natively in the browser. RequireJS implements the Asynchronous Module Definition (formerly Transport/C) proposal.\n \nIf you have modules that are in the traditional CommonJS module format, then you can easily convert them to work with RequireJS.\n \n     Specify and use internationalization data. \n     Load text files (e.g. to be used for HTML templating) \n     Use JSONP service results for initial application setup. \n YUI3 \n     Provide IDs “dd” and “anim” of the modules you want to load. \n     Provide a callback to be invoked once all modules have been loaded. \n     The parameter   of the callback is the YUI namespace. This namespace contains the sub-namespaces   and   for the modules. As you can see, the ID of a module and its namespace are usually different. \n Script loaders \n     LABjs: a relatively simple script loader. Use it instead of RequireJS if you need to load scripts in a precise order and you don't need to manage module dependencies. Background: “ LABjs & RequireJS: Loading JavaScript Resources the Fun Way ” describes the differences between LABjs and RequireJS. \n     yepnope : A fast script loader that allows you to make the loading of some scripts contingent on the capabilities of the web browser. \n Related reading, background and sources \n     A first look at the upcoming JavaScript modules \n JavaScript variable scoping and its pitfalls \n Loading Scripts Without Blocking CommonJS Modules Lightweight JavaScript inheritance APIs \n     Namespacing in JavaScript \n     YUI2:  A JavaScript Module Pattern \n     YUI3:\n YUI Global Object \n     How to get started with RequireJS \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/new-ways-of-playing-old-instruments.html", "title": "New ways of playing old instruments", "content": "New ways of playing old instruments music life video Piano Keith Jarrett This is part 2c. \n\n“Das ist meins” by Annette Focks: The (highly recommended) movie “ Vier Minuten (2006) ” is about a girl in prison who has created her own style of piano music.  This piece  starts simple and then, after 30 seconds, becomes more complex. If you like this one, you can also watch “ Handkanten Akt ” by Jan Tilman Schade, from the same movie.\n\n Guitar “Four Hands Guitar” by Antoine Dufour and Tommy Gauthier. Jan Schmidle \n\n “Tight Trite Night” by Andy McKee.  He plays the guitar in all kinds of cool ways ( flageolet  etc.). [via  Jan Schmidle ]\n\n Zither \n “Kroužení” by Michal Müller. \n \n “Jazz Exercise No. 5” by Harald Oberlechner. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/why-is-revenue-of-technical-books.html", "title": "Why is the revenue of technical books declining?", "content": "Why is the revenue of technical books declining? life media The ‘book’ is dead Daring Fireball prior post \n Convenient beats free (as long as the price is fair). iTunes is a good positive example, O’Reilly’s “Safari” is a negative one. Quote from a comment to the original post: \nThe same holds for buying a DVD, but at least measures are being implemented to add a downloadable file to physical video media so that the video can be played on mobile devices. \n Google filtering out pirated content might not be feasible, for technical, legal, and ethical reasons (this kind of censorship can easily be abused). \n The core issue: Is a book still the best possible format for delivering technical content when Google enables you to get answers to your questions via an internet search? Quote: \n \n Mozilla Developer Network documentation JavaScript: The Good Parts comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/eichs-ecmascriptnext-status-update.html", "title": "Eich’s ECMAScript.next status update at JSConf: arrow function syntax, classes, transpilers", "content": "Eich’s ECMAScript.next status update at JSConf: arrow function syntax, classes, transpilers esnext dev javascript ECMAScript.next: the “TXJS” update by Eich \nAt  JSConf.US 2011 , JavaScript creator Brendan Eich gave an update [1] on what features will make it into ECMAScript.next, the version after ECMAScript 5 [3].\n\n \n\n Probably in ECMAScript.next \n      Array comprehensions\n \n     \n     Support for binary data \n Advocated by Eich Arrow function syntax records tuples \n\n  Eich argues that better syntax for type definitions should be introduced. I am glad to hear this, because it is an essential feature for improving tool support for JavaScript. The term   has been frequently used at JSConf for this kind of improvement and caused a lot of controversy [4], because people were (justifiably) scared that JavaScript’s inheritance would be completely overhauled. But it makes sense to use that term, because people immediately make the right associations (a class has instances, etc.). However, classes in JavaScript won't be much more than syntactic sugar for what is already there.\n \n    \n  were a big topic in the talk and at the conference. They are compilers that translate from a source language to JavaScript, often on the fly, dynamically. Transpilers greatly help with exploring new language features before they become part of ECMAScript.next.\n \n     ES.next modules  support dynamic transpilation. \n     CoffeeScript [5] does static transpilation. \n     Traceur is a new ECMAScript.next transpiler from Google. Eich had some reservations about how Google developed Traceur [2]. \n     Coming to Firefox: debugging the original source code. \n \n\n  Paren-free [5] is still in the cards; more operators.\n \n    \nRelated reading:\n My JSConf.US Presentation | Brendan Eich Google’s Traceur: compile ECMAScript.next to JavaScript on the fly ECMAScript.next features are taking shape \n JavaScript classes \n CoffeeScript versus paren-free JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/googles-traceur-compile-ecmascriptnext.html", "title": "Google’s Traceur: compile ECMAScript.next to JavaScript on the fly ", "content": "Google’s Traceur: compile ECMAScript.next to JavaScript on the fly  esnext dev javascript Google’s Traceur Getting started Supported features language features \n     Inheritance: classes, traits \n     Modules \n     Iterators, for-each loop, generators, deferred functions \n     Block-scoped let bindings \n     Destructuring assignment \n     Parameter handling: default values, rest parameters, spread operator \n Caveats JSConf.US presentation Alex Russell’s response \n The project raises concerns about  openwashing : Is Google’s actual agenda behind this open source project to control where ECMAScript.next is going? Probably not, but the following points set a tone that is slightly off. \n Traceur has been created in secret, without involving TC39, and then presented for maximum “wow” effect at JSConf (Eich calls this “delayed open source” which   be a means of control). In contrast, Mozilla’s  Narcissus  has always been developed in the open, to foster discussion with the community. \n Some features are different from current ES.next proposals. This risks forking the community. \n The  JSConf Traceur slides  are Chrome-only, neither (mobile) Safari nor Firefox works. Alex Russell’s explanation: “As for the slides, that looks to be a bug in Traceur support for FF which we’re still sorting through.” But the problem exists on Safari, too, which does not bode well for cross-browser compatibility. \n Related reading \n     My JSConf.US Presentation | Brendan Eich \n     \n ECMAScript.next features are taking shape \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/programming-language-variables-scope.html", "title": "Programming language variables: scope and extent", "content": "Programming language variables: scope and extent programming languages dev javascript jslang Static versus dynamic \n     \n        Statically, one examines the program as it exists in source code, without running it. Given the following code, we can make the static assertion that function   is nested inside function  .\n \n        The adjective   is used synonymously with  , because both pertain to the   (the words, the source) of the program.\n     \n     \n        Dynamically, one examines what happens while executing the program (“at runtime”). Given the following code,   and   have a dynamic relationship, because   invokes  .\n \n     \n Variable bindings and their scope and extent \n     Scope (a spatial property): Where can the binding be accessed? \n     Extent (a temporal property): How long does the binding exist? \n \n  The   of a variable is the syntactic construct “in which” a binding has been created. What constructs form scopes depends on the programming language: any kind of block in most languages, only functions in JavaScript. One has two options when it comes to determining where else a variable is accessible, in addition to the direct scope:\n \n     \n        Static (lexical) scoping: A variable is accessible from the direct scope and all scopes lexically nested in it. In the following example,   is visible in its direct scope, function  , but also in the nested scope, function  .\n \n     \n     \n        Dynamic scoping: In dynamic scoping, a variable declared in a function is accessible in all invoked functions. The example below illustrates dynamic scoping. If   is invoked, which in turn invokes  , then   at   refers to the binding in  .\n \n     \n \n     \n        Scopes can be nested. The direct scope can be seen as nesting all other scopes where a variable is accessible. In that case, the nested scopes are called  , the direct scope is called  . In static scoping, nesting happens by nesting syntactic constructs. In dynamic scoping, nesting happens by recursively invoking functions.\n     \n     \n        Variables can be shadowed. If an inner scope declares a variable with the same name as a variable in an outer scope, the outer variable is   by the inner one: it cannot be accessed in the inner scope (or scopes nested in it), because mentions of it refer to the inner binding. In the following example, the declaration in   shadows the declaration in  . Thus,   has the value   in   and in  .\n \n     \n \n     \n        Dynamic extent: A variable exists starting with its declaration until its existence is explicitly ended. This usually means that the direct scope of the declaration has finished computing. To handle nested scopes, dynamic extent is often managed via a stack of bindings. Dynamic extent is common in simpler programming languages. JavaScript, however, can do more. Read on.\n     \n     \n        Indefinite extent: In JavaScript, the extent of a variable starts with its declaration. Its binding exists as long as there is code that refers to it. Thus, if a function leaves its static scope, it keeps variables in outer scopes alive if it refers to them. In the following example, function   keeps   alive, because it leaves its static scope (the function  ). Later, once there are no more references to   (such as  ), both   and the binding for   can be garbage-collected.\n \n     \n Related reading Scope and Extent  (chapter 3 in “Common Lisp the Language” by Guy Steele). This chapter is the source of part of this post. comments powered by Disqus."},
{"url": "https://2ality.com/2018/08/nodemon-code-snippets.html", "title": "Running code snippets via Node.js and nodemon", "content": "Running code snippets via Node.js and nodemon dev javascript nodejs nodemon This blog post describes a trick for running a snippet of JavaScript code with Node.js while working on it. nodemon   # As an example, let’s assume we want to experiment with  the standard Node.js function  . We create the file  , with the following content: How can we run   while we are working on it? We first install  the npm package  : Then we can use it to continuously run  : Whenever we save  , nodemon runs it again. That means that we can edit that file in an editor and see the results of our changes whenever we save it. Trying out nodemon without installing it   # You can even try out nodemon without installing it, via  the Node.js tool npx : comments powered by Disqus."},
{"url": "https://2ality.com/2018/08/enums-via-proxies.html", "title": "Setting up constants via proxies", "content": "Setting up constants via proxies dev javascript js proxies In this blog post, a describe a little hack for quickly setting up constants (think enum values, but not wrapped inside a namespace). It is more an educational puzzle than something you should actually use in your code. A simple version   # TypeScript enums   # As an example, consider the following TypeScript enum (JavaScript itself does not have enums): I usually prefer to use strings as enum values, because they are easier to debug: A pure JavaScript solution   # You can achieve something similar in JavaScript as follows. How does it work? We combine two ingredients to achieve this effect. First, the proxy is an object where, whatever key you use to read a property, you always get that key as a value: Second, using property value shorthands during destructuring lets us specify both a property key and a variable name at the same time. That is, the following two declarations are equivalent. Symbols as values for the constants   # If you use symbols as values for the constants, you get more type safety. The only line of the proxy that changes is line A. Further reading   # \n Chapter “ Metaprogramming with proxies ” in “Exploring ES6” \n Chapter “ Destructuring ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/05/child-process-streams.html", "title": "Working with stdout and stdin of a child process in Node.js", "content": "Working with stdout and stdin of a child process in Node.js dev javascript nodejs async In this blog post, we run shell commands as child processes in Node.js. We then use async language features to read the stdouts of those processes and write to their stdins. Running commands in child processes   # Let’s start with running a shell command in a child process: Observations: \n We are using  , because, later on, it lets us access stdin, stdout and stderr of the command while it is running. \n In line A, we are connecting the stdin of the child process to the stdin of the current process (etc.). \n In line B, we are waiting until the process is completely finished. \n Waiting for a child process to exit via a Promise   # Function   looks as follows. Promisified writing to a child process   # The following code uses   to asynchronously write to the   of a child process running a shell command: We spawn a separate process, called  , for the shell command.   writes to  . It does so asynchronously and pauses via  , to avoid requiring too much buffering. Observations: \n In line A, we tell   to let us access stdin via   ( ). stdout and stderr are forwarded to   and  , as previously. \n We don’t   in line B for the writing to finish. Instead, we   until the child process   is done. \n Read on for an explanation of how   works. Promisified writing to streams   # Writing to Node.js streams usually involves callbacks ( see docs ). It can be promisified as follows.  works similarly. Reading from a child process   # The following code uses asynchronous iteration (line C) to read content from the   of a child process: Observations: \n Line A: We ignore stdin, want to access stdout via a stream and forward stderr to  . \n Line B: We   until   is completely done. Without this  ,   would be printed before the first line of  . \n Piping between child processes   # In the following example, the function  : \n Reads content from the   of a   child process. \n Writes content to the   of a   child process. \n In other words, we are implementing something similar to Unix piping: This is the code: Further reading   # \n Blog post “ Reading streams via async iteration in Node.js ” \n Chapter “ Asynchronous iteration ” in “Exploring ES2018 and ES2019” \n Chapter “ Async functions ” in “Exploring ES2016 and ES2017” \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/12/nodejs-esm-phases.html", "title": "ECMAScript modules in Node.js: the new plan", "content": "ECMAScript modules in Node.js: the new plan dev javascript nodejs jsmodules Status of ECMAScript module (ESM) support in Node.js: \n Experimental support for ESM  was added in  Node.js 8.5.0 (2017-09-12) . \n Afterwards, the Node.js Foundation Technical Steering Committee formed the   to help design missing pieces and to guide the implementation towards its (non-experimental) release. The Modules Team is comprised of people from several different web development areas (frontend, backend, JS engines, etc.). \n In October, the Modules Team published the document “ Plan for New Modules Implementation ”. This blog post explains what it contains. The phases   # The work of the Modules Team is split into  : \n Phase 1: Establish a “minimal kernel” – a foundational set of rules and features that is both minimal and as uncontroversial as possible. \n Phase 2 and later: Build on the kernel and tackle the design of more complicated features. \n The minimal kernel is a foundation for further work. The new design will replace the current experimental implementation, once it has similar capabilities. Phase 1: Minimal kernel of ESM support in Node.js   # Simplifying module specifiers   # One of the goals of the Modules Team is “ browser equivalence ”: Node.js should stay as close to browsers as possible. The kernel achieves that by making the resolution of   (the URLs pointing to modules) simpler: \n Each module specifier must end with a file name extension. That is:\n \n No file name extension is added automatically. \n Importing a directory   is not supported (neither via   nor via the field   in  ). \n \n \n ES modules can import built-in Node.js modules (  etc.). All other bare paths must have file name extensions. \n By default, only   files are supported (check Phase 2 if you are interested in other file name extensions). That is, the following kinds of files cannot be imported via  : CommonJS modules, JSON files, native modules. \n Bringing important CommonJS features to ES modules   # \n URL of current module (CommonJS:  ):  \n Dynamically importing ES modules (always possible via   in CommonJS):  \n Interoperability:   # \n ES modules can import CommonJS modules via  . This works  as follows  (with plans to make it more concise, e.g. via a function  ): \n \n CommonJS modules can import ES modules via  . \n Phase 2 and later   # \n Phase 2:\n \n Support for “bare” specifiers such as  . This will probably involve some kind of mapping from such specifiers to real paths. \n Support for file name extensions other than  . That includes support for ES modules in   files. \n \n \n Phase 3 will probably focus on module loaders with extension points that user code can hook into. \n When can I use ES modules on Node.js?   # \n Via a library:  esm  by  John-David Dalton . Also supports older versions of Node.js. \n Behind a flag:  available now .\n \n Caveat: Not yet updated to Phase 1+ (as of Node.js 11.5.0). \n \n \n No flag and based on Phase 1+: The goal of the Modules Team is to make this happen as soon as possible. Hopefully, it will be unflagged in Node.js 14 ( April 2020 ) and backported as far back as possible. \n Frequently asked questions   # \n \n \n Every solution for distinguishing ESM and CJS has pros and cons. Using a different extension is a reasonable compromise ( more information ). \n \n \n \n \n \n \n That makes it possible to reuse code. For example, to write libraries that work both on browsers and on Node.js. \n It also makes it easier to switch between frontend and backend when coding. \n \n \n \n \n \n Structure (static vs. dynamic) and loading process (async vs. sync) of ES modules and CommonJS modules are quite different. The restrictions keep things simple – considering the long-term future where ESM will be dominant. \n \n \n \n \n \n There are many stakeholders and many different platforms involved (Node.js, npm, browsers, JS engines, TypeScript, TC39, etc.). If we end up with ES modules working well everywhere then it’s worth the wait, IMO. \n \n \n Acknowledgement   # \n Thanks to Myles Borins for his feedback on this blog post. \n Further reading and sources of this blog post   # \n “ Plan for New Modules Implementation ” by the Node.js Foundation Modules Team \n Chapter “ Modules ” in “JavaScript for impatient programmers” (covers scripts, CommonJS modules and ES modules) \n The first experimental ESM support in Node.js is described in  a previous blog post . \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/01/well-formed-stringify.html", "title": "ES2019: Well-formed  JSON.stringify", "content": "ES2019: Well-formed  dev javascript es2019 json The proposal “ Well-formed  ” (by Richard Gibson) is at  stage 4  and therefore part of ECMAScript 2019. This blog post explains how it works. According to  the RFC for JSON , if you exchange JSON “in public”, you must encode it as UTF-8. That can be a problem if you use  , because it may return sequences of UTF-16 code units that can’t be encoded as UTF-8. How can that happen? If a JavaScript string contains a   (a JavaScript character in the range 0xD800–0xDFFF) then   produces a string with a lone surrogate: Lone UTF-16 surrogates cannot be encoded as UTF-8, which is why this proposal changes   so that it represents them via code unit escape sequences: Note: JSON supports code unit escape sequences (e.g.  ), but not code point escape sequences (e.g.  ). comments powered by Disqus."},
{"url": "https://2ality.com/2019/01/object-from-entries.html", "title": "ES2019:  Object.fromEntries()", "content": "ES2019:  dev javascript es2019 The proposal “ ” (by Darien Maillet Valentine, Jordan Harband and Kevin Gibbons) is at  stage 4  and therefore part of ECMAScript 2019. This blog post explains how it works.  vs.     # Given an iterable over [key,value] pairs,   creates an object: It does the opposite of  : Combining   with   helps with implementing a variety of operations related to objects. Read on for examples. Examples   # In this section, we’ll use   and   to implement several tool functions from the library  Underscore .    #  removes all properties from   whose keys are not among  . The removal is  :   creates a modified copy and does not change the original. For example: We can implement   as follows:    #  non-destructively swaps the keys and the values of an object: We can implement it like this:    #  is like the Array method  , but for objects: This is an implementation:    #  returns the key of the first property for which   returns  : We can implement it as follows: An implementation   #  could be implemented as follows (I’ve omitted a few checks): The official polyfill is available via  the npm package  . A few more details about     # \n Duplicate keys: If you mention the same key multiple times, the last mention “wins”. \n \n Symbols as keys: Even though   ignores properties whose keys are symbols,   accepts symbols as keys. \n Coercion of keys: The keys of the [key,value] pairs are coerced to property keys: Values other than strings and symbols are coerced to strings. \n Iterables vs. Arrays:\n \n  returns an Array (which is consistent with   etc.). Its [key,value] pairs are 2-element Arrays. \n  is flexible: It accepts iterables (which includes Arrays and is consistent with   etc.). Its [key,value] pairs are only required to be objects that have properties with the keys   and   (which includes 2-element Arrays). \n \n \n Only enumerable data properties are supported: If you want to create non-enumerable properties and/or non-data properties, you need to use   or  . \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/12/creating-arrays.html", "title": "Creating and filling Arrays of arbitrary lengths in JavaScript", "content": "Creating and filling Arrays of arbitrary lengths in JavaScript dev javascript  Rewrote the section on performance. Switched from   to   (because the former argument can get large). New sections: “Recommended patterns”, “Acknowledgements”. The best way of creating an Array, is via a literal: Alas, that isn’t always an option, e.g. when creating large Arrays. This blog post examines what to do in those cases. Arrays without holes tend to perform better   # In most programming languages, an array is a contiguous sequence of values. In JavaScript, an Array is a dictionary that maps indices to elements. It can have   – indices between zero and the length, that are not mapped to elements (“missing indices”). For example, the following Array has a hole at index 1: Arrays without holes are also called   or  . Dense Arrays tend to perform better, because they can be stored contiguously (internally). Once there is at least one hole, the internal representation has to change. Two options are: \n A dictionary. Then lookup takes more time and storage overhead is greater. \n A contiguous data structure, with sentinel values for holes. Then checking if a value is a hole or not, takes extra time. \n In either case, if an engine encounters a hole, it can’t just return  , it must traverse the prototype chain and search for a property whose name is the index of the hole. That costs even more time. In some engines, such as V8, the switch to a less performant data structure is permanent. They won’t switch back, even if all holes are plugged. For more on how V8 represents Arrays, consult “ Elements kinds in V8 ” by  Mathias Bynens . Creating Arrays   #  constructor   # One common way of creating an Array with a given length, is to use the   constructor: This approach is convenient, but it has two downsides: \n The holes make this Array slightly slower, even if you completely fill it with values later on. \n Holes are rarely good initial “values” for elements. E.g., zeros are much more common. \n  constructor plus   method   # The   method changes an existing Array and fills it with a specified value. That helps with initializing an Array after creating it via  :  If you   an Array with an object, all elements refer to the same instance (i.e., the object isn’t cloned): We’ll later encounter a way of filling (via  ) that doesn’t have this issue.  method   # This time, we have created and filled an Array without putting holes in it. Therefore, using the Array after its creation should be faster than with the Array constructor. Alas,   the Array is slower, because engines may have to reallocate the contiguous internal representation several times – as it grows. Filling Arrays with     #  converts iterables and Array-like values to Arrays. It treats holes as if they were   elements. We can use that to convert each hole to an  : The parameter   is an Array-like object with length 3 that contains only holes. It is also possible to instead use  , but that usually creates larger objects. Spreading into Arrays only works for iterable values and has a similar effect to  : Alas,   creates its result via  , so you still end up with a sparse Array. Mapping with     # You can use   to map, if you provide a mapping function as its second parameter. # \n Creating an Array with small integers: \n \n Creating an Array with unique (unshared) objects: \n \n # \n Creating an Array with ascending integers: \n \n Creating an arbitrary range of integers: \n \n Another way of creating an Array with ascending integers is via  , which also treats holes as if they were   elements:  returns an iterable. We use spreading to convert it to an Array. Cheat sheet: creating Arrays   # Filled with holes or  : \n \n→  \n \n→  \n \n→  \n Filled with arbitrary values: \n \n→  \n \n→  \n \n→   (unique objects) \n Ranges of integers: \n \n→  \n \n→  \n \n→  \n Recommended patterns   # I prefer the following approaches. My focus is on readability, not on performance. \n Do you need to create an empty Array that you’ll fill completely, later on? \n \n Do you need to create an Array initialized with a primitive value? \n \n Do you need to create an Array initialized with objects? \n \n Do you need to create a range of integers? \n \n If you are dealing with Arrays of integers or floats, consider   – which were created for this purpose. They can’t have holes and are always initialized with zeros. # \n \n For most situations, I wouldn’t worry too much about performance. Even Arrays with holes are quite fast. It makes more sense to worry about your code being easy to understand. \n \n \n Additionally, how and where engines optimize, changes. So what is fastest today, may not be tomorrow. \n \n Acknowledgements   # \n Thanks to Mathias Bynens and Benedikt Meurer for helping me get the V8 details right. \n Further reading   # \n Chapter “Arrays”  in “JavaScript for impatient programmers” \n Chapter “Typed Arrays: handling binary data”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/01/future-js.html", "title": "Future JavaScript: what is still missing?", "content": "Future JavaScript: what is still missing? dev javascript esnext In recent years, JavaScript has grown considerably in size. This blog post explores what’s still missing. Notes: I’m only listing the missing features that I find most important. Many others are useful, but there is also a risk of adding too much. My choices are subjective. Almost everything mentioned in this blog post is on TC39’s radar. That is, it also serves as a preview of a possible future JavaScript. For more thoughts on the first two issues, see  the section on language design . \n   \n     Values \n     \n       \n         Comparing objects by value \n       \n       \n         Putting objects into data structures \n       \n       \n         Large integers \n       \n       \n         Decimal computations \n       \n       \n         Categorizing values \n       \n     \n   \n   \n     Functional programming \n     \n       \n         Do-expressions \n       \n       \n         Matching: a destructuring  \n       \n       \n         Pipeline operator \n       \n     \n   \n   \n     Concurrency \n   \n   \n     Standard library \n     \n       \n         Modules instead of namespace objects \n       \n       \n         Helpers for iterables (sync and async) \n       \n       \n         Immutable data \n       \n       \n         Better support for date times \n       \n     \n   \n   \n     Features that may not be needed \n     \n       \n         The pros and cons of optional chaining \n       \n       \n         Do we need operator overloading? \n       \n     \n   \n   \n     Various smaller things \n   \n   \n     FAQ: future JavaScript \n     \n       \n         Will JavaScript ever support static typing? \n       \n       \n         Why can’t we clean up JavaScript, by removing quirks and outdated features? \n       \n     \n   \n   \n     Thoughts on language design \n     \n       \n         Other ideas \n       \n     \n   \n Values   # Comparing objects by value   # At the moment, JavaScript only compares primitive values such as strings   (by looking at their contents): In contrast, objects are compared   (each object has a unique identity and is only strictly equal to itself): It would be nice if there were a way to create objects that are compared by value: Another possibility is to introduce a new kind of class (with the exact details to be determined): Aside: The decorator-like syntax for marking the class as a value type is based on  a draft proposal . Putting objects into data structures   # As objects are compared by identity, it rarely makes sense to put them into (non-weak) ECMAScript data structures such as Maps: This problem can be fixed via custom value types. Alternatively, the management of Set elements and Map keys could become customizable. For example: \n \n Map via hash table: requires one operation for checking equality and another operation for creating hash codes. If you work with hash codes, you want your objects to be immutable. Otherwise, it’s too easy to break the data structure. \n \n \n Map via sorted tree: requires an operation for comparing two values, to manage the values it stores. \n \n Large integers   # JavaScript numbers are always 64-bit (double), which gives you 53 bits plus sign for integers. That means that beyond 53 bits, you can’t represent every number, anymore: This is a considerable restriction for some use cases. There is now  a proposal for BigInts , real integers whose precision grows as necessary: BigInts also support  , which gives you values with a fixed number of bits: Decimal computations   # JavaScript’s numbers are 64-bit floating point numbers (doubles), based on the IEEE 754 standard. Given that their representation is base-2, you can get rounding errors when dealing with decimal fractions: That is especially a problem in scientific computing and financial technology (fintech). A proposal for base-10 numbers is currently at  stage 0 . They may end up being used like this (note the suffix   for decimal numbers): Categorizing values   # At the moment, categorizing values is quite cumbersome in JavaScript: \n First, you have to decide whether to use   or  . \n Second,   has the well-known quirk of categorizing   as  . I’d also consider functions being categorized as   a quirk. \n \n Third,   does not work for objects from other   (frames etc.). \n It may be possible to fix this via a library (I’ll create a proof of concept, once I have time). Functional programming   # Do-expressions   # C-style languages make an unfortunate distinction between expressions and statements: Especially in functional languages, everything is an expression.  Do-expressions  let you use statements in all expression contexts:  works inside do-expressions, too: Do-expressions help eliminate the last main use case for Immediately Invoked Function Expressions (IIFEs): Attaching “static” data to a function. As an example, this is code that uses an IIFE to do so: With a do-expression, you don’t need an IIFE: Matching: a destructuring     # JavaScript makes it easy to work directly with objects. However, there is no built-in way of switching over cases, based on the structure of an object. That could look as follows (example from proposal): As you can see, the new   statement is similar to   in some ways, but uses destructuring to pick cases. This kind of functionality is useful whenever one works with nested data structures (e.g. in compilers).  The proposal for pattern matching  is currently at stage 1. Pipeline operator   # There are currently  two competing proposals  for the pipeline operator. Here, we are looking at   (the other proposal is called  ). The basic idea of the pipeline operator is as follows. Consider the following nested function calls. However, this notation usually does not reflect how we think about the computational steps. Intuitively, we’d describe them as: \n Start with the value  . \n Then apply   to it. \n Then apply   to the result. \n Then apply   to the result. \n Then assign the result to  . \n The pipeline operator lets us express this intuition better: In other words, the following two expressions are equivalent. Additionally, the pipeline operator supports   (similar to the method   of functions): The following two expressions are equivalent. One important benefit of the pipeline operator is that you can use functions as if they were methods – without changing any prototypes: Concurrency   # JavaScript has always had limited support for concurrency. The de-facto standard for concurrent processes is the Worker API, which is available in  web browsers  and  Node.js  (without a flag in v11.7 and later). Using it from Node.js looks as follows. Alas, Workers are relatively heavyweight – each one comes with its own realm (global variables etc.). I’d like to see a more lightweight construct in the future. Standard library   # One area where JavaScript is still clearly behind other languages is its standard library. It does make sense to keep it minimal, as external libraries are easier to evolve and adapt. However, there are a few core features that would be useful. Modules instead of namespace objects   # JavaScript’s standard library was created before the language had modules. Therefore, functions were put in namespace objects such as  ,  ,   and  : \n \n \n \n \n It would be great if this functionality could be put in modules. It would have to be accessed via special URLs, e.g. with the pseudo-protocol  : The benefits are: \n JavaScript would become more modular (which could speed up startup times and reduce memory consumption). \n Calling an imported function is faster than calling a function stored in an object. \n Helpers for iterables (sync and async)   # Benefits of  iterables  include on-demand computation of values and support for many data sources. However, JavaScript currently comes with very few tools for working with iterables. For example, if you want to filter, map or reduce an iterable, you have to convert it to an Array: If JavaScript had tool functions for iterables, you could filter iterables directly: These are a few more examples of tool functions for iterables: Notes: \n Consult Python’s  itertools  for examples of tool functions for iterators. \n For JavaScript, each tool function for iterables should come in two versions: one for synchronous iterables and one for asynchronous iterables. \n Immutable data   # It would be nice to have more support for non-destructively transforming data. Two relevant libraries are: \n Immer  is relatively lightweight and works with normal objects and Arrays. \n Immutable.js  is more powerful and heavyweight and comes with its own data structures. \n Better support for date times   # JavaScript’s built-in support for date times has many quirks. That’s why the current recommendation is to use libraries for all but the most basic tasks. Thankfully, work on  , a better date time API, is ongoing: Features that may not be needed   # The pros and cons of optional chaining   # One proposed feature that is relatively popular is  optional chaining . The following two expressions are equivalent. This feature is especially convenient for chains of properties: However, this feature also has downsides: \n Deeply nested structures are more difficult to manage. For example, refactoring is harder if there are many sequences of property names: Each one enforces the structure of multiple objects. \n Being so forgiving when accessing data hides problems that will surface much later and are then harder to debug. For example, a typo early in a sequence of optional property names has more negative effects than a normal typo. \n An alternative to optional chaining is to extract the information once, in a single location: \n You can either write a helper function that extracts the data. \n Or you can write a function whose input is deeply nested data and whose output is simpler, normalized data. \n With either approach, it is possible to perform checks and to fail early if there are problems. Further reading: \n “ Overly defensive programming ” by  Carl Vitullo \n Thread on Twitter  by  Cory House \n Do we need operator overloading?   # Early work is currently being done for  operator overloading , but infix function application may be enough (there currently is no proposal for it, though): The benefits of infix function application are: \n You can create operators other than those that are already supported by JavaScript. \n Compared to normal function application, nested expressions remain readable. \n This is an example of a nested expression: Interestingly, the pipeline operator also helps with readability: Various smaller things   # These are a few things that I’m occasionally missing, but that I don’t consider as essential as what I’ve mentioned previously: \n \n Chained exceptions: enable you to catch an error, wrap additional information around it and throw it again. \n \n \n \n Composable regular expressions : \n \n \n \n Escaping text for regular expressions (important for  ): \n \n \n \n  that supports negative indices ( proposal ): \n \n \n \n As-patterns for matching and destructuring  (proposal by Kat Marchán): \n \n \n \n Checking deep equality for objects (maybe: optionally parameterize with a predicate, to support custom data structures): \n \n \n \n Enums: One benefit of adding enums to JavaScript is that that would close a gap with TypeScript – which already has enums. There are currently two draft proposals (which aren’t at a formal stage, yet).  One is by Rick Waldron ,  the other one is by Ron Buckton . In both proposals, the simplest syntax looks like this: \n \n \n \n Tagged collection literals  (proposed – and withdrawn – by Kat Marchán): allow you to create Maps and Sets as follows: \n \n \n FAQ: future JavaScript   # Will JavaScript ever support static typing?   # Not anytime soon! The current separation between static typing at development time (via TypeScript or Flow) and pure JavaScript at runtime, works well. So there is no immediate reason to change anything. Why can’t we clean up JavaScript, by removing quirks and outdated features?   # A key requirement for the web is to never break backward compatibility: \n The downside is that the language has many legacy features. \n But the upsides outweigh this downside: Large code bases remain homogeneous; migrating to a new version is simple; engines remain smaller (no need to support multiple versions); etc. \n It is still possible to fix some mistakes, by introducing better versions of existing features. For more information on this topic, consult “ JavaScript for impatient programmers ”. Thoughts on language design   # As a language designer, no matter what you do, you will always make some people happy and some people sad. Therefore, the main challenge for designing future JavaScript features is not to make everyone happy, but to keep the language as consistent as possible. However, there is also disagreement on what “consistent” means. So, the best we can probably do is to establish a consistent “style”, conceived and enforced by a small group of people (up to three). That does not preclude them being advised and helped by many others, but they should set the general tone. Quoting  Fred Brooks : A little retrospection shows that although many fine, useful software systems have been designed by committees and built as part of multipart projects, those software systems that have excited passionate fans are those that are the products of  , great designers. An important duty of these core designers would be to say “no” to features, to prevent JavaScript from becoming too big. They would also need a robust support system, as language designers tend to be exposed to considerable abuse (because people care and don’t like to hear “no”).  One recent example  is Guido van Rossum quitting his job as chief Python language designer, due to the abuse he received. Other ideas   # These are ideas that may also help design and document JavaScript: \n \n Creating a roadmap that describes a vision for what’s ahead for JavaScript. Such a roadmap can tell a story and connect many separate pieces into a coherent whole. The last such roadmap, that I’m aware of, is “ Harmony Of My Dreams ” by Brendan Eich. \n \n \n Documenting design rationales. Right now, the ECMAScript specification documents   things work, but not  . One example: What is the purpose of enumerability? \n \n \n A canonical interpreter. The semi-formal parts of the specification are already almost executable. It’d be great if they could be treated and run like a programming language. (You’d probably need a convention to distinguish normative code from non-normative helper functions.) \n \n  Thanks to Daniel Ehrenberg for his feedback on this blog post! comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/semicolon-insertion.html", "title": "Automatic semicolon insertion in JavaScript", "content": "Automatic semicolon insertion in JavaScript dev javascript jslang What JavaScript would be like with significant newlines \nIn JavaScript, automatic semicolon insertion allows one to omit a semicolon at the end of a line. While you always should write semicolons, knowing how JavaScript handles their omission is important knowledge, because it helps you understand code without semicolons and because it has effects even in code with semicolons.\n \n\n Background: JavaScript syntax \n \n \n     Expression: everything that becomes a value when evaluated. Examples:\n \n     \n     Statement: everything that “does something”. A program is always a sequence of statements. Examples:\n \n        Note that the right hand side of the assignment is an expression.\n     \n \n     Loops:  ,   (   ) \n     Branching:  ,  ,  \n     Function declarations (  function expressions) \n \n\n  A semicolon on its own is an   and does nothing. Empty statements can appear anywhere a statement is expected. They are useful in situations where a statement is demanded, but not needed. In such situations, blocks are usually also allowed, but an empty block is longer than a semicolon. Example: The following two statements are equivalent.\n \n    \n  Any expression can become a statement. Then it has to be terminated by a semicolon. Example:\n The rules of automatic semicolon insertion (ASI) \n  The parser treats every new token as part of the current statement, unless there is a semicolon that terminates it. The following examples show code where you might think a semicolon should be inserted, but isn’t. This illustrates the risks of omitting semicolons.\n \n \n \n  In many browsers, the code below assigns   to  , because   is interpreted as the argument of an invocation of the function in the previous line.\n \n\n  ASI is applied in the following cases.\n \n      If a newline is encountered and followed by a token that cannot be added to the current statement, a semicolon is inserted.\n         \n\n         \n \n        This triggers ASI and becomes\n \n     \n      The following syntactic constructs forbid a newline (“LineTerminator”) at a certain position. If there is a newline at that position, a semicolon is inserted. The ECMAScript standard calls the grammar rules below  .\n         \n        For PostfixExpression, the rationale is avoiding the modification of a value on the previous line. For  ,  ,   and  , the rationale is that if they are used without an argument, they should not refer to the next line if one forgets a semicolon.\n         \n         \n \n        Triggers ASI and becomes\n \n         \n \n        Triggers ASI and becomes\n \n         \n \n        Triggers ASI and is interpreted as an empty   statement, followed by a block (with the label   and the expression statement  ), followed by an empty statement (after the closing brace). Thus, if you want to return an object literal, do it as follows.\n \n     \n      Missing semicolons are added before a closing brace and at the end of a program. The following example would be syntactically incorrect without ASI.\n \n        ASI turns this code into\n \n     \n \n      Semicolons are not inserted inside the head of a for loop. This is obvious, because inserted (line-terminating) semicolons are different from the (argument-separating) head semicolons. \n      Semicolons are not inserted if they would be parsed as empty statements. Example:\n \n        Normally, ASI would be triggered, because   cannot follow the   head. However, adding a semicolon after the head would create an empty statement and is thus not done. Accordingly, the above code causes a syntax error. However, if one manually inserts a semicolon, the result   syntactically correct.\n \n        Note that this rule is   necessary in the following example, where there is no danger of ASI, because the opening brace   follow the   head.\n \n     \n Recommendations \n     Always add semicolons and avoid the headaches of semicolon insertion, at least for your own code. Yes, you will have to type more. But for me, semicolons   the readability of code, because I’m so used to them. \n     Don’t put postfix   (or postfix  ) and its operand in separate lines. \n     If the following statements have an argument, don’t put it in a separate line:  ,  ,  ,  . \n     For consistency (with  ), if an opening brace or bracket is part of a statement, don’t put it in a separate line.\n \nCompare:\n \n     \n Related reading ECMAScript Language Specification, 5th edition , section 7.9. [Source of this post and of some of the examples.] \n JavaScript Semicolon Insertion  [In-depth coverage, inspiration for the section on empty statements and the   example.] comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/angry-birds-and-flash.html", "title": "Why the Angry Birds webapp needs Flash", "content": "Why the Angry Birds webapp needs Flash angry birds dev gaming webdev Web gaming technologies: Angry Birds’ cross-compiled Java versus native JavaScript \nShortly after the Angry Birds webapp came out on 2011-05-11 [1], people were disappointed that it needed Flash. This post examines why that is.\n \n \nIf you start the  Angry Birds webapp  in a browser that does not support Flash, you are greeted with the following message.\n\n explains \nThere was speculation the Flash requirement was done for nefarious purposes (to block iOS) or because Chrome includes Flash, but the reality is, it was done   because Chrome has some bugs, and HTML5   just isn’t good for games or professional music applications.\n WebGL announced \n     http://chromium.googlecode.com/svn/trunk/samples/audio/ \n     \n    [...]\n     \n    As a side note, the Apple Safari binary is built from the same audio engine\n    code in WebKit.  Not surprisingly, the experience in both the browsers is\n    very similar when using the audio API.\n \n Google I/O, day 2: summary of the Chrome keynote comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/copy-link-bookmarklet.html", "title": "Bookmarklet: copy a link for Twitter and editors", "content": "Bookmarklet: copy a link for Twitter and editors bookmarklet dev hack blogging \nProblem: You have found an interesting web page and would like to copy its link, for use with Twitter or an editor. That means you need to perform several steps: First, you copy the URL. Second, you go back to copy the title (which might be tricky to get at). Third, you construct the link from the copied pieces.\n \n \nNote that Twitter provides a  bookmarklet  for publishing a link, but it relies on the Twitter web application which does not handle multiple accounts well. The solution shown here can be used with Twitter desktop applications.\n\n Features \n     It opens in a new window and does not change the page to be linked. Note: the URL will be replaced by the bookmarklet code. In some browsers you can undo that change (Firefox: go to address bar, hit Escape). \n     It offers three formats:\n         \n             Twitter:  \n                The Twitter name and the hashtag are optional and have to be specified per host (see below).\n             \n             HTML source code:  \n             An actual HTML link that you can copy in your web browser and paste to WYSIWYG editors such as the Blogger post editor. \n         \n     \n     Any text that you have selected will also be shown on the result page. \n     Configuration: Per host, you can configure what text to remove from the title and what Twitter name or hashtag to add. Example:\n \n        Explanation: If the host is   then\n         \n             the suffix “ - Mac Rumors” is removed from the title. \n             the Twitter name @MacRumors is added before the URL. \n             the hashtag “#mac” is appended after the URL. \n         \n     \n Installation and usage \n     Try it out: Click the link below right now, if you want to see how the bookmarklet works. \n     Install: Drag  this link  to your bookmarks. \n     Tip: use a  keyword  for quick access. \n Go to an interesting page. Optional: select text that you want to copy together with the link. Invoke the bookmark. source code Related reading Bookmarklets: simple plugins for your browser Implementing bookmarklets in JavaScript  [comprehensive how-to] comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/replying-to-digests.html", "title": "Making it easier to reply to email digests", "content": "Making it easier to reply to email digests dev hack \n      Replying to one of the messages in a digest is difficult.\n         \n             You need to copy the subject and the text you want to reply to. \n             Your answer will not appear correctly threaded in the mailing list archives, because threading relies on the correct message ID being provided via the In-Reply-To header. \n         \n     \n      To avoid digests, you could automatically file messages from a mailing list to a common folder (by filtering who sends them). Alas, many mobile devices do not support that kind of filtering and make it difficult to access folders other than the inbox. \n      one mailto link embedded next to each message in the digest.\n         \n             Clicking that link opens a new message in your email client, with Subject, To, and In-Reply-To already filled in. \n             Supporting In-Reply-To: Most email clients don’t support the In-Reply-To header in mailto links, they simply ignore it [if you are aware of any that do support it, let me know]. The work-around is to additionally put the ID of the message one replies to in the body of the message. Then you can manually add an In-Reply-To header and fill in the correct value. \n         \n     \n \nDemo of a a message plus a mailto link (clicking on the link should open a new message in your default email client):\n Reply  \nRelated reading:\n RFC 2368 - The mailto URL scheme \n Generate emails with mailto URLs and Python  [includes a quick intro to the syntax of mailto links] Enabling In-Reply-To headers in Mozilla apps:  How to Add an Arbitrary Custom Header to Email in Mozilla Thunderbird, Mozilla SeaMonkey or Netscape comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/web-game-tech.html", "title": "Web gaming technologies: Angry Birds’ cross-compiled Java versus native JavaScript", "content": "Web gaming technologies: Angry Birds’ cross-compiled Java versus native JavaScript angry birds dev gaming webdev java Cross-compiled Java ForPlay \n Desktop Java \n HTML5 Browsers \n Android \n Flash  \n GWT details \nIt is written in Java, developed and debugged as a Java desktop app, and then cross-compiled at the end step via GWT. Many things in the native version have been converted to more web friendly data formats, for example, data that was in XML or LUA format was converted to JSON.\n Summary \n    GWT does more than make awesome Enterprise Apps, it's a great tool for games too. Learn to write 2D and 3D games using HTML5 and GWT, leverage and port existing game libraries and physics engines, share game code between GWT and Android, publish to the Chrome Web Store, and of course, see demos of really neat GWT games in action. \n Native JavaScript Summary \n    HTML5 provides the foundation for rich and interactive experiences. Which is great, but we really want to build and play games! Learn the basics of building an HTML5 game and explore the related technologies. We'll write a simple game and give you the tools and techniques to create your own worlds and fun.\n Related reading \n Why the Angry Birds webapp needs Flash FunctionSource: HTML5 Audio Issues; Why Some Flash Snuck Into Angry Birds  [original source of this article] YouTube - Google I/O 2011: Kick-Ass Game Programming with Google Web Toolkit YouTube - Google I/O 2011: Super Browser 2 Turbo HD Remix: Introduction to HTML5 Game Development Super Browser 2 Turbo HD Remix: Introduction to HTML5 Game Development  [slides] comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/load-source-in-node.html", "title": "Tip: load source from a file in the Node.js shell", "content": "Tip: load source from a file in the Node.js shell dev nodejs repl javascript jslang Node.js interactive shell module \nFile test.js:\n \n     Execute code each time the Node.js REPL starts \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/implementing-bookmarklets.html", "title": "Implementing bookmarklets in JavaScript", "content": "Implementing bookmarklets in JavaScript bookmarklet dev javascript clientjs separate post Preparation and techniques \n \n  You don’t want to mess up the environment of the web site “in which” your bookmarklet is executed. For example, by using an  Immediately Invoked Function Expression  (IIFE) the variable   won’t become global, below.\n strict mode \n  If you don’t return (or finish with!)  , the result replaces the current web page. [Note: Webkit browsers such as Chrome and Safari never replace a page, only non-Webkit browsers such as Firefox do.]\n \n     Automatic if you use an IIFE: The result of a function is   unless you return something. \n     Chain of statements: Make   the last statement. \n     Single expression: use the   operator  to “mask” the result of an expression. It evaluates its operand and returns  . The first bookmarklet below replaces the current web page. The second one doesn’t.\n javascript:window.open(\"http://www.whitehouse.gov/\") javascript:void window.open(\"http://www.whitehouse.gov/\") \n     \n Collect input \n  Standard DOM provides several methods that let you retrieve HTML elements from the current page.\n \n     \n      [attribute  ] \n     \n     \n ECMAScript 5 \n  jQuery is very helpful for extracting information from a web page. But you want to avoid the jQuery instance that you load from clashing with a jQuery instance that the page uses. The following code shows you how to do that.\n \n \nThe following code snippet prepends the text   to each   tag in the current web page. You can run it in Firefox on a web page that has many of those tags (for example:  spiegel.de ).\n Producing output \n \n \n \n Minify the bookmarklet code \n     Variable names can be minified. \n     Property names cannot be minified. \n “copy link” bookmarklet \n     Mini-templating: The HTML in the output window is produced by inserting the property values of   into a text string, via the   method. Embedded references to the property values look like this:   refers to property  . \n     Doing something with the currently selected text:   is only used if the browser has implemented it. \n Escaping \n     The link: Most modern browsers don’t place any limits on the characters of a   URL. If you want to make sure that it works in old browsers, you can URL-encode the “body” of a bookmarklet:\n \n        Try out the link inside the single quotes in a browser, it correctly brings up an alert.\n     \n     The link in HTML: You face a different problem if you make the bookmarklet URL the value of an attribute in HTML. With URL-encoding nothing needs to be done, but if you use unencoded JavaScript, you need to escape some characters that are illegal inside the quotes of an attribute value.\n \n        The following table shows you what to escape:\n         \n     \n     Composing URLs with query parameters in a bookmarklet: use   for the parameter values.\n \n     \n Invoking a bookmarklet via a browser keyword Browser keywords \n     Keyword name:  \n     Keyword URL:  \n Tip: use JavaScript as a calculator in Firefox and Chrome Update 2011-06-11 great thread comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/with-statement.html", "title": "JavaScript’s with statement and why it’s deprecated", "content": "JavaScript’s with statement and why it’s deprecated dev javascript jslang Syntax and semantics The with statement is deprecated IIFE The rationale of the deprecation \n     Performance: one cannot optimize the access to   (or to any other variable used inside  ), because one cannot predict whether   will refer to a real variable or to a property inside the   argument. That can change with each call. \n     Security: you cannot determine what an identifier refers to by looking at its syntactic surroundings (its  ). According to Brendan Eich that was the actual reason why   was deprecated, not performance considerations. Quoting a  tweet  of his:\n \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2019/01/symbol-prototype-description.html", "title": "ES2019:  Symbol.prototype.description", "content": "ES2019:  dev javascript es2019 The proposal “ ” (by Michael Ficarra) is at  stage 4  and therefore part of ECMAScript 2019. This blog post explains how it works. When creating a symbol via the factory function  , you can optionally provide a string as a description, via a parameter: Until recently, the only way to access the description was by converting the symbol to a string: The proposal introduces the getter   to access the description directly: comments powered by Disqus."},
{"url": "https://2ality.com/2011/05/void-operator.html", "title": "The void operator in JavaScript", "content": "The void operator in JavaScript dev javascript jslang  I updated the content to reflect the status quo. evaluates   and returns  . Examples: Thus, if we could manually implement   as a function, it would look as follows:  The operator is associated closely with its operand. We should therefore put parentheses around its operand if it contains more than a single token. For example,   binds as  .  The following subsections describe three use cases for the   operator: Use case:   as  Use case: bookmarklets Use case: links that execute JavaScript code Use case:   as     # As expressions,  ,  , and   are mostly equivalent, but there is one major difference: \n \n  is a keyword and can’t be used as a variable name. That means that we can’t change its definition either: \n \n \n \n  is a normal variable name. We can’t change its value but we can shadow it – as we’ll see soon. \n \n  is a property of the global object: For more information on property attributes and property descriptors, see  “JavaScript for impatient programmers” . Because property   is neither writable nor configurable, we can’t change its value. This is what happens in strict mode (in non-strict mode, the assignment will fail silently): We can, however, shadow its original value via a variable declaration: Or via a parameter: Thoughts: \n \n Before ECMAScript 5, it was possible to redefine the global property   and   was useful as a “safer  ”. However that’s not an issue anymore. \n \n \n Shadowing   should never be a problem because we control shadowing in our own code. \n \n \n Therefore, we can safely use the more self-descriptive   and don’t need   as an alternative. \n \n Use case: bookmarklets   # Bookmarklets  are URLs with JavaScript programs that are \"executed in the address bar\". If a bookmarklet returns a result that is not  , the content of the currently shown web page is replaced with it. It is such a perfect use case for the   operator. Compare [This difference only exists on non-Webkit browsers. E.g., Safari and Chrome don't exhibit it, Firefox does.]: \n  displays   as the current document. \n  does not change the current document.   \"hides\" the result of the expression  . \n Similarly: \n  replaces the content of the current page. \n  does not change the content of the current page. \n A more involved example: The following bookmarklet lets one submit the\nURL of the current web page to the site  : This bookmarklet does not change the current page and displays the\nconfirmation of a successful submission in a new window/tab. Use case: links that execute JavaScript code   # A discouraged, but possible, use case is to embed a link in a webapp that invokes a JavaScript function. If the function returns void (which also happens if it does not have a return statement at all), then everything is OK. On the other hand, if the function that is called returns a value, we need to prevent the page content from being changed, via the   operator. (This difference only exists on non-Webkit browsers. E.g., Safari and Chrome don't exhibit it, Firefox does.) In the following example, function   returns a number. comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/javascript-calculator.html", "title": "Tip: use JavaScript as a calculator in Firefox and Chrome", "content": "Tip: use JavaScript as a calculator in Firefox and Chrome browser firefox hack javascript computers clientjs chrome The basic idea javascript:alert(7*45) \n      a short description what the keyword does. For example, you can call the calculator keyword “JavaScript calculator”. \n      the command used to invoke the keyword. For the calculator keyword this value is, obviously,  . \n      the URL that defines what the keyword does. Usually, this URL has a place holder   where the argument is to be filled in. For example, you could define a keyword for a Google search via the URL\n \n        If a keyword does not need an argument then you omit the %s.\n     \n Creating the calculator keyword in Google Chrome \n      JavaScript calculator \n      js \n      javascript:alert(%s) \n Creating the calculator keyword in Firefox javascript:7*45 \n     Execute the menu command “Bookmarks → Show All Bookmarks”. Then use the menu with the sprocket symbol to perform “New Bookmark...”.\n         \n             Alternatively, “New Bookmark...” is also available via a the context menu (=right-click) of the bookmarks toolbar. \n         \n     \n     Enter the data:\n         \n              JavaScript calculator \n              javascript:%s \n              js \n         \n     \n JavaScript you can use \n     Arithmetic operators: addition (+), subtraction (-), multiplication (*), division (/), modulo (%).\n \n     \n     Properties and methods of the global object   [2]:\n         \n             \n             \n             \n             \n         \n     \n     Converting to and from hexadecimal, binary, etc.\n \n        You need to put an integer in parenthesis to invoke a method on it. Otherwise the dot will be mistaken for a decimal point. Alternatively, you can type two dots or append  .\n     \n Related reading Browser keywords: using the address bar as a command line Math - MDN Docs Implementing bookmarklets in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2018/08/impatient-js.html", "title": "Behind the scenes of my latest book on JavaScript", "content": "Behind the scenes of my latest book on JavaScript book javascript This blog post takes you behind the scenes of my latest book, “ JavaScript for impatient programmers ” (which I’ll occasionally abbreviate as “Impatient JS”). It describes: \n How I chose what to write about. \n My techniques for explaining topics. \n Tools I used for creating ebooks and other artifacts. \n How I unit-tested the code shown in the book and in its quizzes. \n \n   \n     Previewing “JavaScript for impatient programmers” \n   \n   \n     Content: teaching JavaScript as efficiently as possible \n     \n       \n         What’s in the book? \n       \n       \n         Techniques for teaching topics \n       \n     \n   \n   \n     Artifacts: delivering the content \n     \n       \n         The book \n       \n       \n         Quiz: from Markdown to quiz app \n       \n       \n         Exercises \n       \n       \n         Builds: preview vs. full version \n       \n     \n   \n   \n     Testing code \n     \n       \n         Unit-testing the book \n       \n       \n         Unit-testing quizzes \n       \n       \n         Unit-testing exercises \n       \n       \n         Is it worth it? \n       \n       \n         Other checks \n       \n     \n   \n   \n     Any feedback? \n   \n Previewing “JavaScript for impatient programmers”   # Available previews : \n Book:\n \n Read HTML online  ( , minus a few bonus chapters) \n Download PDF, EPUB, MOBI (50%) \n \n \n Quizzes:  try online  (50%) \n Exercises:  download ZIP file  (50%) \n Content: teaching JavaScript as efficiently as possible   # My idea for “Impatient JS” was: What would a book look like that teaches   JavaScript to programmers, as efficiently as possible? In this section, I explain how I picked and presented the content. What’s in the book?   # Focusing on current JavaScript has one big advantage: You can tell a simpler, more consistent story, because recent features have eliminated many quirks and simplified many operations. The book does not explain old features that were superseded by newer and better features, but it includes references that cover them. It is also satisfying that we can finally explore the full range of asynchronous programming in JavaScript: from callbacks to Promises to async functions to async iteration. To keep the right balance between “too terse” and “too verbose”, I only mention the history of a feature when it helps understand that feature. Techniques for teaching topics   # The following subsections describe techniques I’ve used for teaching topics. # If possible, readers should not just passively receive information, they should also be able to practice what they have learned. Two convenient formats for that are exercises and quizzes. \n The exercises are based on unit tests for  the mocha test framework . This has three advantages:\n \n The computer becomes the teacher and corrects the reader. Not having a human in the loop even makes some things easier: no more feeling self-conscious about making mistakes. \n Readers learn about unit testing. \n A certain degree of error checking is automatic. That is, the risk of either the exercise or its solution being wrong, decreases. \n \n \n For the quizzes, I found it important to not just slightly confuse readers with the questions, but to also dispel that confusion via explanations afterwards. That’s especially important for beginners, whose knowledge still isn’t that solidified. \n # Two common ways of writing books about languages are: \n Tutorials: are read linearly, from beginning to end and teach the language step by step. \n Reference manuals: cover a broad range of topics and make it easy to randomly access what you are interested in. \n “Impatient JS” combines elements of both. For example: \n \n It covers the highlights of the standard library in a tutorial fashion, complemented by an exhaustive quick reference of the remaining functionality. The idea is that for much of the standard library, it is enough to know what’s there and to look up the details on demand. \n \n \n The language is introduced step by step, so that chapters can be read consecutively (like a tutorial). But the book also keeps everything related to a given topic in one place (like a reference), via a trick: Some sections and chapters are marked as “advanced”. Readers can initially skip those sections and can become productive as quickly as possible. Once they are more familiar with the language, they can proceed to the advanced content. \n \n # One technique I like is to explain everything twice: First, state something (somewhat abstractly) in English, then prove it via code. For example: If you state “the multiplication operator always coerces its operands to numbers”, you can follow up with a REPL interaction: The redundancy helps readers: Exploring different aspects deepens the understanding. And by using different modes of explanation, you increase the chance of reaching your readers. # As important as practicing in front of a computer is, it should also be possible to read a computer book without a computer. To that effect, I attempt to guess what readers would want to try out and try it out for them. For example, if you write “reading an unknown property produces the value  ”, then readers are probably curious how that works in practice. If you show them, they don’t need a computer to try it out. One way of doing so is via a REPL interaction: This principle is related to the previous principle (explaining everything twice). But its goal is different. # These are techniques that I’ve found useful: \n \n Sections: help partition text logically. It’s important to keep a balance between sections that are too small and sections that are too large. \n \n \n Bullet lists: are easy to scan and great for enumerating items. If the items in a bullet list become too large, you can turn the bullet list into a section and the items into subsections. \n \n \n Tables: can be considered two-dimensional bullet lists. They present information even more compactly. They are especially well suited for summarizing traits of things. The table at the end of this subsection is taken from the chapter “ Callable values ”. \n \n \n Type notations: are yet another way of describing something. For example, you may write “  is a function with a single parameter, a string, that returns a number”. Then you can follow it up with: \n \n Once again, we are explaining the same thing twice: once in English and once in a formal notation. I’m using TypeScript’s type notation, which I explain in a chapter at the end of the book.  A recent blog post of mine  is an older version of that chapter. \n \n  Capabilities of the four kinds of functions. # Some information is easier to convey visually, especially if structure or processes are involved. For example, the diagram below is from a chapter at the end of the book, that gives an overview of web development in general. The diagram depicts a typical webpack workflow. Artifacts: delivering the content   # Several artifacts are used for delivering the content (the book, the exercises and the quizzes). Let’s look at what those artifacts are and how they are produced. The following diagram gives an overview.   and   are tools I wrote for myself (I’m currently considering if and how I could open-source them).   is an open-source document converter. The book   # The book is written as Markdown, with one Markdown file per chapter. The output formats are: \n EPUB and MOBI for various ebook readers. \n PDFs in two versions:\n \n A screen version has links for internal cross-references. For example: \n“Consult   for more information.” \n While a print version has page numbers. For example: \n“Consult the next chapter (page 93) for more information.” \n \n \n A website (HTML). \n # All of the book artifacts are created via Pandoc, combined with filters (plug-ins) written in the programming language Lua. The website is created by a Node.js script that splits and post-processes Pandoc’s one-file HTML output. For images, I distinguish: \n Vector images: The format I use for vector images depends on the output format:\n \n For HTML and EPUB, I use SVG images. \n For PDF, I use PDF images. \n For MOBI, I use JPG images. \n \n \n Bitmap images: For bitmap images, I use the same JPG or PNG file, everywhere. \n # Pandoc parses its input into an abstract syntax tree. Filters operate on that syntax tree and can transform it. In addition to structured text, the abstract syntax tree can also contain “raw” HTML and LaTeX that is passed on to the next output stage without any changes. The Lua filters that I wrote often have two modes: \n If Pandoc produces a PDF (via LaTeX), the filters convert some of the Markdown to LaTeX. \n If Pandoc produces HTML, they convert some of the Markdown to HTML. \n As an example, consider the following input Markdown: Pandoc does not have built-in support for boxes with content. The idea is to use a Pandoc “ fenced div ” with a pre-defined CSS class to express a box. In the previous example,   plus the pre-defined class   starts the box; the three colons at the end, finish the box. A filter converts this div into an actual box. This is the output in HTML mode, after the input was processed by the filter: The filter did the following things: \n The first line and the last line were converted to HTML (it actually works slightly differently, but this explanation is easier to understand): \n The class   was only used to select the image for the icon. The actual CSS class for boxes is  . \n The heading was converted into bold text. \n For LaTeX, the filter embeds LaTeX. This time, the syntax for embedding is more verbose: Quiz: from Markdown to quiz app   # Each quiz is defined via a Markdown file. A question looks like this: Quizzify converts the Markdown to a client-side, React-based program. You can check out the result  online . Exercises   # # Exercises have two formats that I call “test” and “exercise”: \n For a “test”, readers need to implement the tested file. \n For an “exercise”, readers need to modify the file itself. \n The following code is an (abridged) “exercise”: # When it comes to exercises, the file structures for authoring and deployment are different. The tool Exbuild transforms the former to the latter when creating the ZIP file with the code. Why are the structures different? \n For authoring, you want everything is one place and you want to test the solutions. \n For deployment, you want the solutions to be in a separate folder (so that readers can look them up if they get stuck) and all tests to fail until readers solve the exercises. \n Therefore, for a “test”, the test is deployed in the   directory, the tested file is deployed in the   directory. Optionally, there may also be a   file with a skeleton of the solution; to be completed by readers. An “exercise” always involve a   file with mistakes that readers have to fix or blanks that readers have to fill in. The non-template file contains the solution that readers should end up with. Builds: preview vs. full version   # Not only are there many different artifacts – each one of them has to be created in two versions: \n The full version contains all of the content. \n The preview version contains a subset of the content (currently about half the book). \n This is handled by Pantools, Quizzify and Exbuild via   (Pantools is the Node.js app that manages Pandoc). Each build has a name and specifies: \n Where to put the produced artifact. \n What files (chapters) to include:\n \n For the book, you directly specify file names. \n For quizzes, you specify the name of a book build. Then quizzify extracts the names of quiz files from the book files (which are mentioned there, but not shown in the published books). \n For exercises, you do the same. \n \n \n When you create an artifact, you specify which build to use. Testing code   # All three kinds of content contain JavaScript code: \n The book contains examples with JavaScript code. \n The quiz asks questions about JavaScript code. \n The exercises are JavaScript code. \n The best way of avoiding typos in code is to run it in unit tests. Unit-testing the book   # For the book, I wrote my own tool,  , that extracts Markdown code blocks and turns them into  mocha  unit tests. # Take, for example, the following Markdown content: The comment tells Marktest to put the provided line of source code before the text of the code block. Text in half-brackets (such as  ) is not shown in the ebooks and only added to the unit test. Thanks to the  , the test created by Marktest is a proper asynchronous test (because it returns a Promise): The line number mentioned in the test name helps with debugging when there are errors. I’ve indented the output to make it easier to read. Marktest currently does not indent code, to avoid breaking it. # REPL interactions are also supported by Marktest. For example: REPL interactions are converted into a series of invocations of  : # Marktest has more features. For example: \n Ignoring code blocks. \n Giving code blocks IDs and including them elsewhere. This is helpful whenever code is spread out across multiple code blocks. \n Moving imports to the top levels of test files. \n Writing code blocks to files so that imports work. \n Unit-testing quizzes   # To understand how unit-testing a quiz works, let’s use the following question (written in Markdown) as an example: Unit-testing the correct answer 4 is straightforward – we simply wrap both code an assertion in a  : For incorrect answers, we cannot simply switch from   to  , because the answer may also be incorrect due to the code throwing an exception. Therefore, we wrap the whole body of the   in an   – which means that we expect the wrapped code to throw an exception. That exception can come from either the code or the failure of  . Unit-testing exercises   # Unit-testing the exercises is relatively simple because the file structure which is authored is the same as one where a reader has successfully completed all exercises. Therefore, we just need to run all tests (i.e., all “tests” and all “exercises”). Is it worth it?   # Making sure that the code in the book and the quizzes is testable is more work. That raises the question: is it worth that work? On the minus side, seeing   etc. in the code takes some getting used to. Compare: On the plus side: \n Everything is more explicit with assertions. \n You can state things that would be difficult to state by other means. Especially   is quite powerful in this regard. \n Readers learn to read assertions, which is a useful skill for unit-testing. \n The biggest benefit is that automatic testing detects many small and large issues in code. And that is very valuable. \n Other checks   # My tools also perform a few other checks, such as: \n Does a mentioned quiz file or exercise file really exist? \n Is the   command mentioned at the beginning of an exercise correct? \n Any feedback?   # I’m interested in feedback: \n Is everything in the book easy to understand? Even for people who are not yet familiar with JavaScript? \n What are teaching techniques and tools that you like? \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/02/js-backward-compatibility.html", "title": "JavaScript’s a mess – and that’s a good thing", "content": "JavaScript’s a mess – and that’s a good thing dev javascript esnext JavaScript never removes old features – new versions are always backward compatible. I wish we could clean it up, but staying compatible has too many benefits, as I’ll explain in this blog post. The benefits of backward compatibility   # These are benefits of staying backward compatible: \n It is trivially easy to migrate to new language versions. For example, all old code was already compatible with ES6 when it came out.\n \n Only ES modules are relatively difficult to adopt – but they kind of do break backward compatibility. \n \n \n It avoids versioned code. If you allow some code to be “old” and some code to be “new”:\n \n Language engines and tools become more complicated. \n Programmers need to be aware of versions. \n You can’t move code around, anymore (if a code base is mixed). \n \n \n Tips for dealing with JavaScript’s expanding feature set   # \n Teaching and learning: you can mostly ignore old features, apart from what they look like and – roughly – what they do. \n Let linters help you with using the language properly. \n Let Prettier help you with formatting source code properly. \n A cleaner JavaScript   # If you want to program in as clean a JavaScript as possible, there is much you can ignore (some suggestions are more radical than others): \n . Use   and  , instead. \n . Use only arrows and method definitions. Benefit: handling   becomes much simpler ( details ). \n Promises. Use only  async functions . Learn what to watch out for (you can’t ignore Promises as completely as  ). \n Iterating over objects. Use Maps, instead. \n Loops:   (avoid always),   (avoid if you can). Use  , instead. \n . Use rest parameters ( ), instead. \n . Use the spread operator ( ), instead. \n Constructor functions. Use classes, instead. \n IIFEs. Use blocks, instead. \n Wish   # \n  vs.   is too complicated.  This blog post  describes a library for simplifying things. \n Further reading   # \n Chapter:  One JavaScript: avoiding versioning in ECMAScript 6 \n Chapter:  Core ES6 features  [What ES5 features are replaced by – better – ES6 features?] \n Chapter:  Async functions \n Blog post:  A different way of understanding   in JavaScript \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/02/ecmascript-2019.html", "title": "ECMAScript 2019: the final feature set", "content": "ECMAScript 2019: the final feature set dev javascript es2019  The feature set of ECMAScript 2019 is now final ( source ) and described in this blog post. A word on ECMAScript versions   # Note that since  the TC39 process  was instituted, the importance of ECMAScript versions has much decreased. What really matters now is what stage a proposed feature is in: Once it has reached stage 4, it can be used safely. But even then, you still have to check if your engines of choice support it. The features of ES2019   # Major new features: \n  (Michael Ficarra, Brian Terlson, Mathias Bynens) \n  (Darien Maillet Valentine) \n Minor new features: \n  (Sebastian Markbåge) \n  (Michael Ficarra) \n Optional catch binding  (Michael Ficarra) \n  is now required to be stable ( ECMAScript spec ) (Mathias Bynens). \n Changes that are mostly internal: \n Well-formed   (Richard Gibson) \n JSON superset  (Richard Gibson) \n  revision  (Michael Ficarra) \n Quoting  @v8js on Twitter : As of V8 v7.3 / Chrome 73, all of these ES2019 features are available by default. Enjoy! FAQ   # What do the stages mean?   # They refer to maturity stages of the so-called “TC39 process”. Check chapter “ The TC39 process for ECMAScript features ” in “Exploring ES2016 and ES2017” for more information. How is [my favorite proposed feature] doing?   # If you are wondering what stages various proposed features are in, consult  the readme of the ECMA-262 GitHub repository . Is there an official list of ECMAScript features?   # Yes, the TC39 repo lists  finished proposals  and mentions in which ECMAScript versions they are introduced. Further reading   # The following books of mine are free to read online: \n ECMAScript 5: “ Speaking JavaScript ” \n ECMAScript 6: “ Exploring ES6 ” \n ECMAScript 2016 & 2017: “ Exploring ES2016 and ES2017 ” \n ECMAScript 2018 & 2019: “ Exploring ES2018 and ES2019 ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/02/numeric-separators.html", "title": "ES2021: numeric separators", "content": "ES2021: numeric separators dev javascript esnext es2021 The proposal “ Numeric Separators ” by Sam Goto and Rick Waldron lets us use   as a separator in numeric literals. This blog post explains how that works. What are numeric literals?   # JavaScript has several  : \n Decimal literals:  ,  ,  \n Binary integer literals:  \n Octal integer literals:  \n Hexadecimal integer literals:  \n Interestingly, unary minus ( ) is an operator and not part of numeric literals (apart from signed exponents in decimal literals). Grouping digits in numeric literals   # Grouping digits to make long numbers more readable has a long tradition. For example: \n At the end of 2016, Munich had 1,464,301 inhabitants. \n The distance between Earth and Sun is 149,600,000 km. \n The proposal allows underscores as separators in numeric literals: With other bases, grouping is important, too: You can also use the separator in fractions and exponents: Restrictions   # The key restriction to keep in mind is: You can only put underscores between two digits. Therefore, the following numeric literals are illegal. Furthermore, you can never use more than one underscore in a row: The motivation behind these restrictions is to keep things simple. Bigints and numeric separators   # The proposed  arbitrary-precision integers (bigints)  enable you to represent larger numbers numerically. Thus, numeric separators are especially helpful with them: Bigints are often used to represent money in the financial technical sector. Separators can help here, too: Parsing numbers with separators   # The following functions for parsing numbers will not support separators: \n \n \n \n For example: The rationale is that numeric separators are for code. Other kinds of input should be processed differently. A helper function for parsing numbers with separators   # One technique for parsing numbers with separators is to remove non-digit characters: This is how you use this function: Tips   # Don’t forget about exponential notation   # With trailing zeros, exponential notation may be more convenient than grouping zeros. Compare: Numbers aren’t always the best choice to represent numeric(ish) data   # Some data such as phone numbers, credit card numbers and social security numbers, are in some ways numbers, in others not: There may be non-numeric prefixes and separators and leading digits are significant. They should also never be represented in exponential notation. Therefore – avoid: comments powered by Disqus."},
{"url": "https://2ality.com/2018/03/javascript-typescript-reasonml.html", "title": "JavaScript vs. TypeScript vs. ReasonML", "content": "JavaScript vs. TypeScript vs. ReasonML dev javascript typescript reasonml In this blog post, I describe the pros and cons of three programming languages/dialects: JavaScript, TypeScript and ReasonML. My descriptions are based on recent experiences with TypeScript and ReasonML on a few smaller real-world projects and on years of experience with JavaScript. Before we take a look at the languages, let’s first consider the pros and cons of static typing, given that TypeScript and ReasonML are statically typed and JavaScript isn’t. The pros and cons of static typing   # Pros: \n Documentation: For most code, I find it very helpful if the types of parameters are documented. Then I know what to expect as a caller and as a callee.\n \n But it goes further than that. When I revisited an old JavaScript code base to add static types, I had forgotten how it worked. With the types, it is now laid out much more clearly how everything works. For example, in order to add type annotations for the parameters of a function, I often had to visit its call sites. That is, the information “how is this function used?” is hinted at by the types. \n I’d also consider auto-completion in editors as “better documentation”. It means you have to consult docs much less when working with an API (good doc comments help, too). For example, when I started doing more DOM programming in 2006, I did it via GWT (which is based on Java and was an attractive solution back then, for several reasons). Exploring and learning the DOM API was fun, due to auto-completion in Eclipse. \n \n \n A quick way to check the types of parameters. I knew I was ready to try static typing in JavaScript once I added programmatic type checks to several functions – that code felt like unnecessary boilerplate. \n It helps with refactoring (adding cases to enums, etc.). \n Cons: \n It takes time to learn. \n It is an additional layer of complexity. You are basically writing the code again, on a different level. \n It constrains your freedom of expression. Things can get complicated if you get into generics, co- and contra-variance (e.g., an Array of strings is not a subtype of an Array of objects), etc. \n It does not prevent defects. At least that’s what  current research  says. In my experience, you do catch a certain class of errors (e.g. missing null checks). But I may have caught them even earlier, if I had written unit tests instead of adding static types. In order to detect serious defects, you need tests. \n You lose some interactivity and compiling takes time. On the other hand, it’s become almost impossible to avoid compilation in the JavaScript ecosystem. \n ReasonML   # \n If you want to experience the best of what static typing has to offer, use ReasonML (or OCaml, which it is based on). For example, almost every language feature is designed so that you need the least amount of type annotations (by supporting  ). \n It is impressive, how far along everything already is (especially the editor support), but several important pieces are still being worked on: better support for Promises, iteration and async iteration; an improved standard library called Belt; improved JavaScript interop (which is already decent, but still more complicated than I’d like); better support for Unicode strings. \n ReasonML has impressively short build times. It’s considerably faster than TypeScript, which is a definite usability advantage. \n It has some bindings for JavaScript libraries, but the selection is still limited: see  Reason Package Index . \n You have the option to go native. For example, Jared Forsyth has written  the game Gravitron  in ReasonML that runs natively on Android, iOS, web and macOS. \n For more information on ReasonML, consult my book “ Exploring ReasonML and functional programming ” (free to read online). TypeScript   # \n TypeScript’s type system is more lightweight than I expected it to be. It feels more like FP than like Java. For example, it works structurally and not nominally: If you create an interface, that interface “matches” all objects whose shape is described by that interface. You can introduce interfaces at any time, without having to touch existing code. \n The type system is also quite powerful and intuitive. You can statically type a lot of idiomatic JavaScript, thanks to  union types ,  intersection types ,  discriminated union types , etc. \n Editor support (via Visual Studio Code, WebStorm, etc.) is outstanding. \n Many npm packages either come with static type definitions or have external ones that are dead-simple to install. Consult  DefinitelyTyped  for more information. \n Naturally, JavaScript interop is excellent. With one exception: simulating named parameters via object literals is unnecessarily complicated to type statically ( more information ). \n Conclusion: TypeScript occupies a nice middle ground between JavaScript and ReasonML. I’d be interested in hearing how well it does for large projects. JavaScript   # \n The whole ecosystem is a constant source of innovation and experimentation ( Babel , etc.). \n You have the broadest selection of compatible libraries, via npm. \n You can move as quickly as possible and keep everything as dynamic as you want. \n Have the option to explore and create code without a build step. \n For more information on JavaScript language features, consult my series of books, “ Exploring JS ”, which is free to read online. Conclusion: the JavaScript ecosystem is stronger than ever   # Static typing or not is an emotional topic. My advice is: \n Use whatever makes you happy and productive. \n Do acknowledge both strengths and weaknesses of what you are using. \n Personally, I’ve started to use some kind of static typing once a project grows beyond a certain size (or if I expect it to eventually grow that big). The strength and variety of the JavaScript ecosystem is amazing at the moment: You can switch between JavaScript, ReasonML and TypeScript, as needed (and with varying degrees of work). They share some tools, many libraries, and much syntax. For example, when I needed a quick templating solution in ReasonML, I used the JavaScript-based  EJS library , via npm. Lastly, note that there are many other good options out there:  the static type checker Flow ,  the functional programming language Elm , etc. comments powered by Disqus."},
{"url": "https://2ality.com/2018/02/string-prototype-matchall.html", "title": "ES2020:  String.prototype.matchAll", "content": "ES2020:  dev javascript es feature es2020 The proposal “ ” by Jordan Harband is currently at  stage 3 . This blog post explains how it works. Before we look at the proposal, let’s review the status quo. Getting all matches for a regular expression   # At the moment, there are several ways in which you can get all matches for a given regular expression.  with     # If a regular expression has the   flag, you call   multiple times to get all matches. After the last match, it returns  . Before that, it returns a   for each match. Such an object contains captured substrings and more. In the following example, we collect all captures of group 1 in the Array  : Without the flag  ,   always only returns the first match: This is bad news for  , because it will never finish if   doesn’t have the flag  .  with     # If you use   with a regular expression whose flag   is set, you get all full matches for it in an Array (in other words, capture groups are ignored): If   is not set,   works like  :  with     # You can use a trick to collect captures via  : We use a function to compute the replacement values. That function receives all capture information. However, instead of computing replacement values, it collects the data it is interested in, in the Array  : For regular expressions without the flag  ,   only visits the first match.    #  returns   as long as a regular expression matches:    # You can split a string and use a regular expression to specify the separator. If that regular expression contains at least one capture group then   returns an Array in which the substrings are interleaved with whatever the first group captures: Problems with current approaches   # Current approaches have several disadvantages: \n \n They are verbose and unintuitive. \n \n \n They only work if   is set. Sometimes we receive a regular expression from somewhere else, e.g. via a parameter. Then we have to check that this flag is set if we want to be sure that all matches are found. \n \n \n In order to keep track of progress, all approaches (except  ) change the regular expression: property   records where the previous match ended. This makes using the same regular expression at multiple locations risky. And while it’s generally not recommended, it’s a shame that you can’t inline the regular expression when using   multiple times (because the regular expression is reset for each invocation): \n \n \n \n \n Due to property   determining where matching continues, it must always be zero when we start collecting matches. But at least   and friends reset it to zero after the last match. This is what happens if it isn’t zero: \n \n \n Proposal:     # This is how you invoke  : Given a string and a regular expression,   returns an iterable over the match objects of all matches. You can also use the spread operator ( ) to convert the iterable to an Array: Flag   must be set: With  , function   becomes shorter and easier to understand: Let’s use spread and   to make this function more concise: Another option is to use  , which does the conversion to an Array and the mapping at the same time. Therefore, you don’t need the intermediate value  :  returns an iterator, not a restartable iterable   #  returns an iterator, not a true restartable iterable. That is, once the result is exhausted, you need to call the method again and create a new iterator. In contrast,   plus   returns an iterable (an Array) over which you can iterate as often as you want. Implementing     #  could be implemented via   as follows: Making a local copy ensures two things: \n  isn’t changed. \n  is zero. \n Using  : FAQ   # Why not  ?   # On one hand,   does work like batch version of  , so the name   would make sense. On the other hand,   changes regular expressions and   doesn’t. That explains why the name   was chosen. Further reading   # \n Chap. “ Iterables and iterators ” in “Exploring ES6” \n Sect. “ The spread operator ( ) ” in “Exploring ES6” \n Sect. “ ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/04/async-iter-nodejs.html", "title": "Reading streams via async iteration in Node.js", "content": "Reading streams via async iteration in Node.js dev javascript nodejs async  Using the library   to read lines from stdin. Node.js 10 was released on April 24, 2018. This version provides experimental support for  asynchronously iterating  over readable streams. This blog post explains how that works. Reading streams asynchronously   # In this section, we examine two ways of reading data from a stream asynchronously: via callbacks and via asynchronous iteration. Reading asynchronously via callbacks   # To read the contents of a file asynchronously, you can use callbacks, as follows. First, you create  a readable stream : \n The option   determines how the stream delivers its content:\n \n If it is  , the stream delivers  buffers . \n If it is a string such as  , it delivers strings, by interpreting the stream’s data according to the specified encoding. \n \n \n The option   determines the maximum size (in bytes) of each delivered buffer or string. \n Second, you receive the data by listening to the events   and  : Reading asynchronously via async iteration   # Starting with Node.js v10, you can also use  asynchronous iteration  to read a file asynchronously. Readable streams have a property whose key is  , which enables the   loop to iterate over their chunks. However, this kind of loop is only available within async functions and async generators. That’s why we have to use an async function: Processing async iterables via async generators   # So far, we have seen how you can use async functions as sinks of async iterables. With async generators, you can go one step further: They can be the source of an async iterable. Or they can transform an async iterable (as both sink and source). The latter works as follows. The async generator: \n Consumes an async iterable via  . \n Returns an async iterable and feeds data into it via  . \n That is, if you chain async generators, you can process input similarly to Unix piping. Let’s look at a pipe with two async generators. Generator #1: from chunks to lines   # The following function takes an async iterable over strings and returns an async iterable over lines: Generator #2: from lines to numbered lines   # This function takes lines and numbers them: Connecting the generators   # The   function reads a text file via a readable stream and applies the two async generators to it, therefore numbering the lines in that file. One intriguing trait of processing data asynchronously is that the processing steps become intertwined: As soon as the first chunk arrives, it is split into lines and the lines are numbered. Therefore, the code can handle very large files, because it processes them in chunks of 1024 bytes. Reading stdin   # In the following example, we use  the library   to read lines from stdin: Conveniently, this code processes individual lines as soon as you hit return: Conclusion   # Having async iterables in Node.js is great. It’s a considerable improvement over callback-based processing. Based on async iteration, we can now have combinators such as   and   for asynchronous data. Further reading   # \n : documentation on how readable streams support asynchronous iteration in Node.js 10. \n Chapter “ Asynchronous iteration ” in “Exploring ES2018 and ES2019” \n Chapter “ Async functions ” in “Exploring ES2016 and ES2017” \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/01/iterators-reasonml.html", "title": "ReasonML: external and internal iteration", "content": "ReasonML: external and internal iteration dev reasonml advanced Table of contents for this series of posts: “ What is ReasonML? ” This blog post explains patterns and techniques for external and internal iteration in ReasonML. The GitHub repository   has the source code of the examples. Iteration   # Many algorithms operate on series of values. We can apply such algorithms to any data structure that lets us   over its elements (visit them sequentially, one element at a time). Examples of such algorithms: \n Counting the number of items in a series. \n Computing the average of all numbers in a series. \n Two ways of implementing iteration are: externally and internally. (In this blog post, I’m using the term   for an iterated value and the term   for a value stored in a data structure.) External iteration   # With external iteration, we ask for each element of the data structure (pull). In OOP languages such as JavaScript, that looks as follows. We first create an iterator   for the data structure  . Then we invoke   repeatedly until the result signals us that all values were visited, via  . Internal iteration   # With internal iteration, the data structure feeds us its elements (push). In OOP languages such as JavaScript, that looks as follows. The parameter of   is a callback that successively receives each element and logs it to the console. Abstractions for iterations   # The next step for us will be to introduce abstractions for iteration: \n We have already seen an  , an abstraction for external iteration. However, for ReasonML, we want an abstraction that follows the style of functional programming (not object-oriented programming). \n It is not yet clear what an abstraction for internal iteration should look like. But, as we will see, there is one. \n Abstractions for iteration have two benefits: \n Algorithms that operate on series of values can use such abstractions as their inputs. Then they automatically work with all data structures that support the abstractions (instead of having to be implemented for each data structure separately). \n  are operations consuming and/or producing iteration abstractions. A combinator works with any data source that supports its iteration abstraction. It also computes on demand: To process the lines in a large text file without some kind of iteration abstraction (think  ), we need to read them all into a data structure (e.g. a list or an array) and then work with that data structure. If the lines are handled via nested combinators, processing can start much earlier – as soon as the first line is available. Combinators for iteration abstractions are similar to combinators for lists (which are also linear) such as  ,   and  . \n It is interesting that iteration abstractions (such as iterators and streams) are based on mutable state at their core: the same entity produces different results when you access it in the same manner several times. However, they also feel quite functional, due to combinators. Abstracting external iteration in ReasonML   # In OOP, the abstraction for external iteration is an object, the so-called  . In ReasonML, we also call the abstraction an iterator, but we use a nullary function that we call repeatedly to produce the iterated values. As an example, let’s use the conversion function   (which is explained soon) to create an iterator   for a list  :  returns values of type  , a variant with two constructors: \n Elements   of   are returned as  . \n The end of the iteration is indicated via  . \n The following type is for iterators that produce values of type  : Within the ReasonML/OCaml ecosystem, iterators are also called   and   (due to them being producers of data, muddling the difference between interface and implementation). To better understand how generators work, let’s look at code that produces and consumes them. Converting lists to generators   # This is how   can be implemented: The last thing   does (in line A), is return the generator, a nullary function. That function uses the     (think mutable variable) to store the next iteration value. If the list, pointed to by  , is not yet empty, the generator returns  . Otherwise, it returns  . Converting generators to lists   # The inverse process, collecting iteration values in a list, works as follows. We repeatedly call   and collect its results in the accumulator parameter   that we return once   is finished. The resulting list is in the wrong order, which is why we reverse it via  . The following code is a test for  .  is a hand-written generator that uses the ref cell   to produce a series of values. The last line checks if   properly converts   to a list. The assertion is based on  the   API . Generator combinator:     # Let’s implement our first combinator: A function   whose input is a generator and whose output is the number of items in that generator: We use the helper function   to loop over all elements in the generator  . While we are doing so, we increment the counter  . Once the generator is finished, we return  . Generator combinator:     # The generator combinator   has as input a function   and a generator   and returns a new generator. Each item of the result is derived from an item of   by applying   to it: This is a test for  : The result is the function  . It derives its results from  : If   is done then so are we (line A). Otherwise, we need to apply   to the iterated value   (line B). Generator combinator:     # The combinator   copies only those elements of its input generator to its output generator for which its callback parameter   returns  : This is a test for  : With  , you pass on whatever the input generator   produces (line A), with one exception: If   returns   for an iteration value, you immediately advance to the next result of   (line B). Abstracting internal iteration in ReasonML   # Let’s briefly review what internal iteration looks like. The following code is an implementation of  .  uses the helper function   to loop over the elements of   and apply   to them. This is what using   looks like: Given that   does not return anything, it must do its work via side effects. Each step prepends a new item   in front of the existing items in   (line A). That’s why the final result is the original list in reverse.  is elegant (if you need or want to use side effects), but it has one disadvantage: It is not an abstraction that can be returned by combinators. An abstraction for internal iteration   # So what do we want from an abstraction for internal iteration? \n It should work much like  . \n It should be a type of value that data structures can be mapped to and that combinators can work with. \n The solution is as follows. A function that creates an internal iterator for a data structure simply returns the function   that performs internal iteration (a partially applied  , if you will). That gives us the following type for   (internal iterators): A sequence is a function that takes a callback of type   and feeds it values of type  . Converting lists to sequences   # Let’s examine how the type   works, by implementing a function that returns a sequence for a list: As you can see, this is a curried version of  . The following code tests  . Combinators for sequences   # Let’s take a brief look at how combinators are implemented for internal iterators. On one hand, computing results is more difficult than with external iterators – you need to rely on side effects to compute and return the result: On the other hand, producing an output iterator is simpler, because you decide when you send data to it: Libraries for iteration   # These are three OCaml libraries supporting iteration: \n  supports   (external iterators).\n \n Tip for reading the docs: check out included modules and sub-modules, they provide much interesting functionality. \n \n \n  supports   (external iterators). \n  supports   (internal iterators). \n In the following section, we’ll use the   library to demonstrate more iteration concepts. Folding iterators   # One important operation for processing iterators is  . We’ll use the   library to explore how that works. The following function   counts the number of items produced by a generator  : This is a test for a generator with zero items: This is a test for a generator with two items:  works much like  : \n The first parameter is a function that maps the current state and an iteration value to the next state. States are arbitrary values whose type depends on the algorithm. In this case, the states are ints, because the last computed state is also the result of  . \n The second parameter is the first state. \n The third parameter is the generator that   operates on. \n As you can see, we are not even interested in the current iteration value  . We only need to count how often   is called and use the states to do so. Implementing iterators for trees   # So far, we have only looked at iterating over linear data structures. Iterating over non-linear data structures is more challenging. Take, for example, a tree (the same data structure we have used in  the blog post on variants ): Writing an external iterator for trees is not trivial. You could, for example, manually manage a stack of nodes to visit. Here, we explore an alternative technique that we will develop in three steps. We start by implementing internal iteration over trees. Iterating internally over trees   # The following function is similar, in spirit, to  : The code is straightforward – we use recursion to visit all nodes in the tree. Note that   is also how we’d implement internal iteration. The only change would be to nest two functions: \n The parameter of the first one is  . \n The parameter of the second one is  . \n Iterating, continuation passing style   # The next step is to convert the previous version to  continuation-passing style  (CPS): Instead of returning the results, we pass them on to callbacks. These callbacks are named  , because they determine how computation continues. Line A is a good example of how CPS works:   “returns” to us via its second parameter, a continuation. In CPS, the callee can delay (or avoid) returning a value to the caller. That’s why this style is used for asynchronous computations (e.g. by Node.js). External iteration for trees   # For external iteration, we want the following: \n Use the algorithm of  . \n But instead of calling   in line A, we want to pause and return a value. When the iterator is called again, it should continue its execution where it previously paused. \n This is how   and generators work in, for example, JavaScript, Python and C#. We can simulate this behavior by storing the continuation in a ref cell  : The all that remains to be done is to define how everything starts and to return the actual external iterator. This is how you use  : Infinite iterators   # Iterators don’t have to be finite. For example: You obviously would not want to iterate over the items of this iterator (it would take a very long time). Infinite iterator are, however, useful for a few things. First, you can use them to produce finite iterations of arbitrary length, via  .   returns a generator with the first   items of generator  . Second,   combines two iterations into a single iteration of pairs. And an infinite iterator can fill in one component of each pair: This works, because   stops as soon as one of the two iterators is finished. You can also add indices to iteration values via  . Detecting the first or last iterated value   # Occasionally, when working with series of values, you need to distinguish the first or the last value. Alas, that is normally not possible: all iterated values are treated the same. Let’s examine this issue by implementing  , a function that concatenates a series of strings into a single string. Optionally, it inserts separator strings between adjacent iteration values. Detecting the first element by indexing iteration values   # The first solution is to index each iteration value   by mapping it to a pair  . Then it is easy to determine which is the first element – it has the index 0:  works like this: We are using   (which we have already encountered in this blog post) to process the generator  . You may wonder if we could have simply checked whether the intermediate result   was empty and only added a separator if it wasn’t. But that would mean that we wouldn’t properly add a separator after an initial empty string (or after and between several initial empty strings). Detecting the last element via     # The   library has a clever way of supporting look-ahead for generators, via its function  . That function maps each iteration value   to a pair: \n The first component of the pair is  . \n The second component is the next iteration value, still wrapped in  . \n That means that the last iteration value   is mapped to the following pair: Let’s apply   to an iterator with two strings: The first pair in line A looks ahead to the second value,  . The second pair enables you to determine that   is the last iteration value. With this capability, we can again implement   via  : A practical example   # As a practical example, consider the following task. Given this text in Markdown syntax: We’d like to split this text into  , records with two fields. Each section in the text produces one: \n The field   contains the heading of the section. \n The field   is a list with the lines of the section (including the line with the heading). \n The result looks as follows. To implement this functionality, we use a more powerful variant of  :  . The callback   of this function works similarly to  ’s callback: \n Its parameters are also the current state and the current iteration value. \n Its result, however, is a pair  :\n \n  is the next state (the only value returned by  ’s callback). \n  is the iteration value added to the output iterator. \n \n \n That means that we can use the states to assemble chunks. As long as a chunk isn’t ready yet, our output is  . Once the chunk in   is finished, our output is  . You can check out the complete source code in the file   in the repository. It also includes an imperative version of the chunking algorithm that is less elegant. Conclusion   # This is a summary of iteration as we have explored it in this blog post: Iterators are incredibly useful when processing series of values. It is fascinating that using them feels functional, even though they are an abstraction based on mutable state. It also noteworthy that once you work with combinators, there is not much of a difference between external and internal iterators. For example, the following two test files are the same (apart from the the modules to be tested). \n \n \n Further reading   # \n “ Generators, iterators, control and continuations ” by Gabriel Scherer. \n “ Is there any way to write infinite lists using lazy evaluation in OCaml? ” on reddit. \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/04/type-notation-typescript.html", "title": "Understanding TypeScript’s type notation", "content": "Understanding TypeScript’s type notation dev javascript typescript chapter “The essentials of TypeScript” This blog post is a quick introduction to TypeScript’s notation for static types. \n   \n     What you’ll learn \n   \n   \n     Trying out the code examples \n   \n   \n     Specifying the comprehensiveness of type checking \n   \n   \n     Types \n   \n   \n     Type annotations \n   \n   \n     Type inference \n   \n   \n     Specifying types via type expressions \n   \n   \n     Type aliases \n   \n   \n     Typing Arrays \n     \n       \n         Arrays as lists \n       \n       \n         Arrays as tuples \n       \n     \n   \n   \n     Function types \n     \n       \n         A more complicated example \n       \n       \n         Result types of function declarations \n       \n       \n         Optional parameters \n       \n       \n         Rest parameters \n       \n     \n   \n   \n     Union types \n     \n       \n         By default,   and   are not included in types \n       \n       \n         Making omissions explicit \n       \n     \n   \n   \n     Optional vs. default value vs.  \n   \n   \n     Typing objects \n     \n       \n         Typing objects-as-records via interfaces \n       \n       \n         TypeScript’s structural typing vs. nominal typing \n       \n       \n         Object literal types \n       \n       \n         Optional properties \n       \n       \n         Methods \n       \n     \n   \n   \n     Type variables and generic types \n     \n       \n         Example: a container for values \n       \n     \n   \n   \n     Example: a type-parameterized class \n     \n       \n         Example: Maps \n       \n       \n         Type variables for functions \n       \n       \n         A more complicated function example \n       \n     \n   \n   \n     Conclusion: understanding the initial example \n   \n   \n     Further reading \n   \n What you’ll learn   # After reading this post, you should be able to understand what the following code means: If you think this is cryptic – then I agree with you. But (as I hope to prove) this notation is relatively easy to learn. And once you understand it, it gives you immediate, precise and comprehensive summaries of how code behaves. No need to read long descriptions in English. Trying out the code examples   # TypeScript has  an online playground . In order to get the most comprehensive checks, you should switch on everything in the “Options” menu. This is equivalent to running the TypeScript compiler in   mode. Specifying the comprehensiveness of type checking   # I recommend to always use TypeScript with the most comprehensive setting,  . Without it, programs are slightly easier to write, but we also lose many benefits of static type checking. Currently, this setting switches on the following sub-settings: \n : If TypeScript can’t infer a type, we must specify it. This mainly applies to parameters of functions and methods: With this settings, we must annotate them. \n : Complain if the type of   isn’t clear. \n : Use JavaScript’s strict mode whenever possible. \n :   is not part of any type (other than its own type,  ) and must be explicitly mentioned if it is a acceptable value. \n : stronger checks for function types. \n : If a property can’t have the value  , then it must be initialized in the constructor. \n More info: chapter “ Compiler Options ” in the TypeScript Handbook. Types   # In this chapter, a type is simply a set of values. The JavaScript language (not TypeScript!) has only eight types: Undefined: the set with the only element  Null: the set with the only element  Boolean: the set with the two elements   and  Number: the set of all numbers BigInt: the set of all arbitrary-precision integers String: the set of all strings Symbol: the set of all symbols Object: the set of all objects (which includes functions and arrays) All of these types are  : we can use them at runtime. TypeScript brings an additional layer to JavaScript:  . These only exist when compiling or type-checking source code. Each storage location (variable, property, etc.) has a static type that predicts its dynamic values. Type checking ensures that these predictions come true. And there is a lot that can be checked   (without running the code). If, for example the parameter   of a function   has the static type  , then the function call   is illegal, because the parameter   has the wrong static type. Type annotations   # A colon after a variable name starts a  : the   after the colon describes what values the variable can have. For example, the following line tells TypeScript that   will only ever store numbers: You may wonder if   being initialized with   doesn’t violate the static type. TypeScript gets around this problem by not letting us read   before we assign a value to it. Type inference   # Even though every storage location has a static type in TypeScript, we don’t always have to explicitly specify it. TypeScript can often infer it. For example, if we write: Then TypeScript infers that   has the static type  . Specifying types via type expressions   # The type expressions after the colons of type annotations range from simple to complex and are created as follows. Basic types are valid type expressions: \n Static types for JavaScript’s dynamic types:\n \n ,  \n ,  ,  \n \n . \n \n \n TypeScript-specific types:\n \n  (not technically a type in JS) \n  (the type of all values) \n Etc. \n \n \n Note that “  as a value” and “  as a type” are both written as  . Depending on where we use it, it is interpreted as a value or as a type. The same is true for  . There are many ways of combining basic types to produce new,  . For example, via   that combine types similarly to how the set operators   ( ) and intersection ( ) combine sets. More on this topic soon. Type aliases   # With   we can create a new name (an alias) for an existing type: Typing Arrays   # Arrays are used in the following two roles in JavaScript (and sometimes a mix of the two): \n Lists: All elements have the same type. The length of the Array varies. \n Tuple: The length of the Array is fixed. The elements do not necessarily have the same type. \n Arrays as lists   # There are two ways to express the fact that the Array   is used as a list whose elements are all numbers: Normally, TypeScript can infer the type of a variable if there is an assignment. In this case, we actually have to help it, because with an empty Array, it can’t determine the type of the elements. We’ll get back to the angle brackets notation ( ) later. Arrays as tuples   # If we store a two-dimensional point in an Array then we are using that Array as a tuple. That looks as follows: The type annotation is needed for Arrays-as-tuples because TypeScript infers list types, not tuple types: Another example for tuples is the result of  : an Array with one [key, value] pair for each property of  . The inferred type is an Array of tuples. Function types   # This is an example of a function type: This type comprises all functions that accept a single parameter, a number, and return a string. Let’s use this type in a type annotation: Again, we don’t need a type annotation here because TypeScript is good at inferring function types: A more complicated example   # The following example is more complicated: We are using a function type to describe the parameter   of  . Due to this type annotation, TypeScript rejects the following function call. But it accepts the following function call: Result types of function declarations   # It’s recommended to annotate all parameters of a function (except for callbacks where more type information is available). We can also specify the result type: TypeScript is good at inferring result types, but specifying them explicitly is occasionally useful. #  is a special result type for functions: It tells TypeScript that the function always returns   (explicitly or implicitly): Optional parameters   # A question mark after an identifier means that the parameter is optional. For example: TypeScript only lets us make the function call in line A if we make sure that   isn’t   (which it is if the parameter was omitted). # TypeScript supports  parameter default values : Default values make parameters optional. We can usually omit type annotations, because TypeScript can infer the types. For example, it can infer that   and   both have the type  . If we wanted to add type annotations, that would look as follows. Rest parameters   # We can also use  rest parameters  in TypeScript parameter definitions. Their static types must be Arrays: Union types   # In JavaScript, variables occasionally have one of several types. To describe those variables, we use  . For example, in the following plain JavaScript code,   is either of type   or of type  : In TypeScript,   has the type  . The result of the type expression   is the set-theoretic union of the types   and   (while interpreting them as sets). By default,   and   are not included in types   # In many programming languages,   is part of all object types. For example, whenever the type of a variable is   in Java, we can set it to   and Java won’t complain. Conversely, in TypeScript,   and   are handled by separate, disjoint types. We need type unions such as   and  , if we want to allow them: Otherwise, we get an error: Note that TypeScript does not force us to initialize immediately (as long as we don’t read from the variable before initializing it): Making omissions explicit   # Let’s rewrite function  : This time, we don’t want the parameter   to be optional. It should always be mentioned. If callers don’t want to provide a function, they have to explicitly pass  . That is implemented as follows. Note that, once again, we have to check if   is actually a function (line A), before we can make the function call in line B. Without the check, TypeScript would report an error. Optional vs. default value vs.     # The following three parameter declarations are quite similar: \n Parameter is optional:  \n Parameter has a default value:  \n Parameter has a union type:  \n If the parameter is optional, it can be omitted. In that case, it has the value  : If the parameter has a default value, that value is used when the parameter is either omitted or set to  : If the parameter has a union type, it can’t be omitted, but we can set it to  : Typing objects   # Similarly to Arrays, objects play two roles in JavaScript (that are occasionally mixed and/or more dynamic): \n \n Records: A fixed number of properties that are known at development time. Each property can have a different type. \n \n \n Dictionaries: An arbitrary number of properties whose names are not known at development time. One type per kind of key (mainly: string, symbol). \n \n We’ll ignore objects-as-dictionaries in this blog post. As an aside, Maps are usually a better choice for dictionaries, anyway. Typing objects-as-records via interfaces   # Interfaces describe objects-as-records. For example: We can also separate members via commas: TypeScript’s structural typing vs. nominal typing   # One big advantage of TypeScript’s type system is that it works  , not  . That is, interface   matches all objects that have the appropriate structure: Conversely, in Java’s nominal type system, we must explicitly declare with each class which interfaces it implements. Therefore, a class can only implement interfaces that exist at its creation time. Object literal types   #  are anonymous interfaces: One benefit of object literal types is that they can be used inline: Optional properties   # If a property can be omitted, we put a question mark after its name: In the following example, both   and   match the interface  : Methods   # Interfaces can also contain methods: The type system doesn’t distinguish between methods and properties whose values are functions. However, the distinction is still meaningful for humans: It expresses how we expect properties to be set up and used. Type variables and generic types   # With static typing, we have two levels: \n Values exist at the  . \n Types exist at a  . \n Similarly: \n Normal functions exist at the base level, are factories for values and have parameters representing values. Parameters are declared between parentheses: \n \n Parameterized types exist at the meta level, are factories for types and have parameters representing types. Parameters are declared between angle brackets: \n \n Example: a container for values   #  is a  . One or more type variables can be introduced between angle brackets. Example: a type-parameterized class   # This time, the class   has the type parameter  . (Single uppercase letters such as   are often used for type parameters.) When we instantiate the class, we also provide a value for the type parameter: Example: Maps   # Maps are typed generically in TypeScript. For example: Thanks to type inference (based on the argument of  ), we can omit the type parameters: Type variables for functions   # Functions (and methods) can introduce type variables, too: We use this function as follows. Due to type inference, we can once again omit the type parameter: A more complicated function example   # The type variable   appears three times in this code: \n : introduce the type variable \n : use the type variable, pick it up from the argument. \n : pass on   to the   constructor. \n That means: we don’t have to explicitly specify the type   of  . It is inferred from parameter  : Conclusion: understanding the initial example   # Let’s use what we have learned to understand the piece of code we have seen earlier: This is an interface for an Array whose elements are of type   that we have to fill in whenever we use this interface: \n \n method   has zero or more parameters (defined via the rest operator). Each of those parameters has the type  . That is, it is either an Array of   values or a single   value. \n \n \n method   introduces its own type variable,  .   expresses the fact that the following entities all have the same type (which we don’t need to specify, it is inferred automatically): \n \n Parameter   of   (which is a function) \n Result of  \n Optional parameter   of  \n Result of  \n \n  also gets a parameter   whose type has the same type   as the Array elements, a parameter   that is a number and a parameter   with   values. \n \n Further reading   # \n Book (free to read online):  “JavaScript for impatient programmers” \n “ ECMAScript Language Types ” in the ECMAScript specification. \n “ TypeScript Handbook ”: is well-written and explains various other kinds of types and type operators that TypeScript supports. \n The TypeScript repository has  type definitions for the complete ECMAScript standard library . Reading them is an easy way of practicing the type notation. \n comments powered by Disqus."},
{"url": "https://2ality.com/2018/04/npm-install-directory.html", "title": "Tip: npm-installing directories", "content": "Tip: npm-installing directories dev javascript nodejs npm Quick tip: npm lets you install directories, which is occasionally useful for organizing projects. For example, as a temporary step before uploading packages to npm (think lightweight  ). An example project   # As an example, let’s assume, we are writing a suite of Node.js-based CLI tools: Each of  ,   and   is an npm package with its own   and  . npm-installing the directory     # npm lets you do: Then npm does the following: \n It installs the dependencies of  . \n It adds a symlink to   in  . \n It adds an entry to the dependencies: \n \n Et voilà! Now  ’s “sibling dependency” on   will be (re)created whenever you do an   for  . comments powered by Disqus."},
{"url": "https://2ality.com/2018/04/extracting-loops.html", "title": "Coding recipe: extracting loop functionality (via callbacks and generators)", "content": "Coding recipe: extracting loop functionality (via callbacks and generators) dev javascript coding In this blog post, we look at two ways of extracting the functionality of a loop: internal iteration and external iteration. The loop   # As an example, take the following function  : The loop starting in line A logs file paths. It is a combination of a   loop and recursion (the recursive call is in line B). What if you find the functionality of the loop (iterating over files) useful, but don’t want to log? Internal iteration   # The first option for extracting the loop functionality is  : This way of iterating is similar to the Array method  :   implements the loop and invokes its   for every iteration value (line A). External iteration   # An alternative to internal iteration is  : We implement an iterable and a generator helps us with it: With internal iteration,   called us (“push”). This time, we call it (“pull”). Note that in generators, you must make recursive calls via   (line A): If you just call   then it returns an iterable. But what we want is to   every item in that iterable. That’s what   does. One nice trait of generators is that processing is just as interlocked as with internal iteration: Whenever   has created another  , we get to look at it immediately, then   continues. It’s a form of simple cooperative multitasking, with   pausing the current task and switching to a different one. Further reading   # \n Chapter “ Iterables and iterators ” in “Exploring ES6”. \n Chapter “ Generators ” in “Exploring ES6”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/javascript-equality.html", "title": "Equality in JavaScript", "content": "Equality in JavaScript dev javascript jslang When is it OK to use == in JavaScript? \nThere are two operators for comparing values in JavaScript: strict equality   and “normal” (or lenient) equality  . Many style guides (correctly) tell programmers to avoid lenient equality and always use strict equality. This post explains why.\n \n \nWhere appropriate, related sections in the ECMAScript 5 language specification [1] are mentioned in square brackets.\n\n Two ways of comparing \n     The strict equality operator   only considers values equal that have the same type. \n     The lenient equality operator   tries to convert values of different types, before comparing like strict equality. \n \n     The conversion rules are counter-intuitive and do things you might not expect. \n     As the operator is so forgiving, type errors can remain hidden longer. \n Strict equals === \n \n \n Two (primitive) numbers:\n \n  for any number  . Thus equality is not reflexive in\n  JavaScript, because   is not equal to itself.\n Two booleans, two strings (primitive): obvious results\n Two objects (including arrays and functions):  \n  only if   and y are the same object(!). That is, if you\n  want to compare different objects, you have to do it manually.\n Equals == \n One number, one string: convert the string to a number\n A boolean and a non-boolean: convert the boolean to a number and\n  then perform the comparison.\n Comparing a string or a number to an object: try to convert the\n  object to a primitive and then make the comparison.\n Related reading ECMAScript Language Specification, 5th edition. JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/erich-gamma-microsoft.html", "title": "Erich Gamma (Eclipse) joins Microsoft to work on JavaScript tools", "content": "Erich Gamma (Eclipse) joins Microsoft to work on JavaScript tools dev javascript windows 8 microsoft Heise Quote \nErich will continue to live and work out of Zurich, Switzerland where we will be opening a small Visual Studio development lab with Erich as the lead.\n \n     The Visual Studio Zurich Lab [...] will be focused on [...] next generation tools and experiences for developers focused on cloud and browser applications. \n     This is a great job for someone who is eager to apply the latest web development technologies to create a new generation of development tools. \n     Key Responsibilities: [...] Support to grow a user community around the new set of tools. \n     Job Requirements include: [...] Familiarity with JavaScript and web client programming preferred. \n COM CLR \nThings really have changed at Microsoft, starting with them shifting their focus on the web from Silverlight to HTML5 [2], continuing with new Windows 8 apps being written in JavaScript [3] (though other ways may follow).\n \nRelated reading:\n “ Design Patterns ” [ amazon.com ] by Erich Gamma, Richard Helm, Ralph Johnson, John Vlissides. Microsoft: Our strategy with Silverlight has shifted Windows 8: Microsoft restarts its operating system efforts (an analysis) Dr. Erich Gamma muss seinen Vortrag leider absagen « Architecture Day comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/esnext-txjs.html", "title": "ECMAScript.next: the “TXJS” update by Eich", "content": "ECMAScript.next: the “TXJS” update by Eich esnext dev javascript \n      Follow-up post – “ ECMAScript.next: new details, reacting to Dart complaints ” \n      More and updated material on proxies, array comprehensions, and classes. Moved private name objects to new post. \n TXJS conference \nApproved for ECMAScript.next (look at the ECMAScript Wiki [2] for details):\n \n     ,  ,   are block-scoped [3] \n     Destructuring assignment:\n \n     \n     Parameter default values:\n \n     \n     Rest parameter:\n \n     \n     Spread operator:\n \n     \n     Proxies: A   is an object with an attached handler. The object itself is completely empty, but the handler is informed of any access (getting a property, setting a property, invoking a method, etc.). That is useful for many applications: logging method invocations, data binding, invoking remote services, etc.\n \n     \n     Weak maps:  \n     Modules [4]:\n \n     \n     Iterators, generators:\n \n     \n     Array comprehensions:\n \n     \n     Binary data:\n \n     \n     Class literals have been accepted. They are syntactic sugar for creating a prototype and a constructor. Eich mentions that he in principle likes that class literals were accepted, but is still not completely happy, because in addition to making some things easier, they also add new complexity and don’t really feel “JavaScript-y” [this is me very freely paraphrasing him]. An alternative proposal has been made [5], but is not a candidate, any more.\n \n        New and helpful things:   for subclassing,   calls for the constructor and methods, having a single construct for defining a class (instead of piecing things together).\n     \n     Quasi-literals [6]: enable embedded domain-specific languages. The basic idea is to make it easy to enter custom syntax which is parsed by a function (the  ) to produce data. This custom syntax is entered as text, but expressions can be inserted. The text is given to the handler as a sequence of tokens. For each token, one can determine whether it came from literal text or from an expression. These tokens are thus very similar so a syntax tree, but there is no nesting. One can nest quasis, by putting them inside  , but then they will be evaluated before being passed to a handler. Having two types of tokens gives the handler the option to transform inserted values, e.g. to escape special characters.\n        Example quasi literals:\n         \n             Secure content generation (handler  ):  \n             Text localization:  \n             Query languages, e.g. one using CSS selectors:  \n             Inserting literal text into regular expressions:  \n             Raw strings:  \n         \n     \n ECMA TC39: the Good, the Bad, and the Ugly harmony:proposals  [all proposals that have been accepted for ECMAScript.next] JavaScript variable scoping and its pitfalls A first look at the upcoming JavaScript modules Prototypes as the new class declaration \n        More information on this idea:  Prototypes as classes – an introduction to JavaScript inheritance \n     Quasi-literals: embedded DSLs in ECMAScript.next comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/object-literal-comma.html", "title": "Quick JavaScript tip: trailing commas inside an object literal", "content": "Quick JavaScript tip: trailing commas inside an object literal dev javascript jslang \nRelated reading:\n Standard ECMA-262: ECMAScript Language Specification What’s new in ECMAScript 5 ECMAScript 5 compatibility table comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/constructor-property.html", "title": "What’s up with the “constructor” property in JavaScript?", "content": "What’s up with the “constructor” property in JavaScript? dev javascript jslang The constructor property \n     Get the class of an object: Remember that constructor functions can be considered classes in JavaScript. Thus, getting the constructor of an object gives you its class. For example, the following two instances of   have the same class:\n \n     \n     Create a new instance: Given an object, you can create a new instance that has the same class.\n \n        This is mainly useful if you have several subclasses and want to clone an instance.\n     \n     Invoking a super-constructor: You need the   property at (*), below.\n \n        Assigning the super-prototype to   avoids the hardcoded use of the superclass name in the sub-constructor. It can be used to similar effect in methods:\n \n     \n Where does the constructor property come from? Related reading: Relevant sections in the  ECMAScript 5 language specification :\n         \n     An easy way to understand JavaScript’s prototypal inheritance JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/coffeescript-classes.html", "title": "Translating CoffeeScript classes to JavaScript", "content": "Translating CoffeeScript classes to JavaScript dev javascript coffeescript jslang Classes in Coffeescript here The translation Understanding the generated code Copy class methods from the superclass to the subclass. There is no other way to inherit such methods in JavaScript. Ensure that the object   has the prototype  . You do this by creating a temporary constructor   and giving it the right value for  . The code fragment is equivalent to the following ECMAScript 5 [1] code:\n \n        The   property [2] is correctly set up in the default prototype. As we assign our own prototype object, we need to set up that property manually.\n     Given a superclass   and a subclass  , you normally have to refer to   by name in the methods of  . By assigning   to  , you avoid this kind of hardcoding. The   constructor function uses   to that effect. \nThe invocation of the super-constructor is a typical JavaScript technique: You invoke the super-constructor as a function (no  !) and give it the current  , so that it adds its properties, but does not create a new instance.\n\n Related reading What’s new in ECMAScript 5 What’s up with the “constructor” property in JavaScript? JavaScript variable scoping and its pitfalls  [explains IIFEs and hoisting] \n Lightweight JavaScript inheritance APIs  [various ways of simplifying JavaScript inheritance] CoffeeScript versus paren-free JavaScript ECMAScript.next: prototypes as classes  [a proposal to simplify inheritance for the next version of JavaScript] comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/prototypes-as-classes.html", "title": "Prototypes as classes – an introduction to JavaScript inheritance", "content": "Prototypes as classes – an introduction to JavaScript inheritance esnext dev javascript jslang \n     [2011-11-04] “ Myth: JavaScript needs classes ” introduces a more concise name for “prototypes as classes”:  . An   is a factory for instances, constructors are  .\n     \n     [2012-01-08] “ JavaScript inheritance by example ” is a more hands-on introduction, complementing this post.\n     \n     [2012-07-29] Classes  have been accepted  for ECMAScript.next. \n     [2012-10-03] Since this article has been written, it was decided that ECMAScript will have the  special property   instead of the   operator.\n     \n \n \n \n \n  The core idea of “prototypes as classes” is that prototypes are better classes than constructor functions. That is, if you have a class   and create instances via  , then   should be the prototype of the instances, not their constructor function.  Sect. 3  shows constructor functions as classes side by side with prototypes as classes, which should make it obvious which one is the better choice.  Sect. 5  presents a library that lets you use prototypes as classes in today’s JavaScript.\n \nRead on for a gentle introduction to this idea.\n\n Introduction \n     Sect. 1: Explain prototypes as classes via NextScript. First review the basics of prototypes (which are the same in JavaScript and NextScript). Then explain prototypes as classes in more detail. \n     Sect. 2 : For comparison, show how current JavaScript does classes and subclassing – via constructor functions as classes. \n     Sect. 3 : Show constructor functions as classes side by side with prototypes as classes to explain the benefits of the latter approach. \n     Sect. 4 : ECMAScript.next might get prototypes as classes, in a way that maximizes compatibility with legacy code. ECMAScript.next will also have more powerful object literals, which would benefit prototypes as classes. \n     Sect. 5 : The   library lets you use prototypes as classes in current JavaScript. Its succinctness is a partial validation of the approach.  \n Prototypes \n      An object can optionally have a  , by pointing to another object via the internal property  . The value of that property can be retrieved via  . The prototype object can again have a prototype. The sequence of objects that are each other’s prototype is called the  . \n      If NextScript cannot find a property in an object, it keeps looking in the prototype, then the prototype’s prototype etc. While it does so,   always points to the beginning of the prototype chain. \n [4] \n  Both the instance-of relationship and the subclass-of relationship is expressed via the has-prototype relationship in NextScript:\n \n      the prototype object   of an object   plays the role of a class;   is an instance of  . \n      a prototype object   can have a superclass   by making the object   its prototype. \n Prototypes as classes \n      A class   is an object. It contains data that is shared by all instances (mainly methods). A special method called “ ” sets up the instance-specific data (mainly data properties). \n      Creating a new instance via   desugars to the following ECMAScript 5 code (internally):\n \n        That is, the following happens:\n         \n             Create a new object   whose prototype is  . \n             Call  \n         \n        After these steps,   is an instance of its prototype object  . When looking for a property   via  , it should be obvious that both the unique instance data and the shared prototype data can be found, due to how prototypes work. If a method is found in the prototype and executed, the value of the   variable is still  , which enables the method to access the instance data.\n     \n     \n \n        checks whether   is in the prototype chain of  . It is syntactic sugar for\n \n     \n      The class of an object is its prototype. Example: Are   and   (direct) instances of the same class?\n \n     \n Subclassing \n     Inherit prototype properties:  ’s prototype is  . \n     Inherit instance properties:   calls   before setting up its own instance data. \n \nExample: Subclass   extends superclass  .\n Super-calls [4] \n       . To find the method, we look for the first object in the prototype chain of   that has a property   and invoke that property’s value. During this invocation,   is bound to  , the object where the search began.\n       . This invocation must be made from a method  . The search for   starts at the   of   (the prototype of the object that holds  ). During the execution of  ,   has the same value as it did in  . \n Classes in JavaScript (ECMAScript 5) \n      A class is a constructor function  .   points to an object with the instance methods.   itself sets up the instance data properties. \n        does the following:\n         \n             Create a new object   whose prototype is  . \n             Call   with   pointing to the newly created instance. \n         \n     \n        checks whether   is in the prototype chain of  . \n      via the   property. Example: Are   and   (direct) instances of the same class?\n \n     \n      A new constructor   extends an existing constructor   in two steps:\n         \n             Inherit prototype properties: Let   have the prototype  . \n             Inherit instance properties: Let constructor   call constructor   as a function (no   operator!) and hand in   so that   adds its properties to the new instance of   (without creating a new instance itself). \n         \n     \n [3] Comparing JavaScript and NextScript prototypal inheritance  In JavaScript, an instance   has two relationships with its class  :   is the instance of   and has the prototype  . In NextScript, there is only the prototype relationship between instance and class. As a result,   becomes easier to understand.\n         \n      In JavaScript, there is an indirection involved in subclassing. To let constructor   subclass constructor  , you must make   the prototype of  . In NextScript, you directly connect a subclass to its superclass. As a result, it is also easier to determine whether one class is a subclass of another one.\n         \n      In JavaScript, a super-constructor and a sub-constructor are only related via the values of their   properties. Prototypes as classes are directly related.\n         \n      When calling an overridden method in a superclass, you access the method in the super-prototype in JavaScript (i.e, not the superclass).\n         \n      In JavaScript, if a class has a method then a subclass does not inherit it. In NextScript, class methods are automatically inherited, due to the prototype relationship.  When it comes to creating a new instance, there are two concerns:\n         Instantiation: Create a new instance, give it the proper prototype. Initialization: Set up the instance variables. \n        In JavaScript, a constructor function either plays both roles or just role #2 (when called from a sub-constructor). In NextScript, the method   is only responsible for initialization (it could be renamed to   to make that fact more explicit). As a result, initialization chaining in NextScript is conceptually simpler than constructor chaining in JavaScript.\n      To use a generic method, you have to refer to a prototype. The following example shows how to turn the pseudo-array   in an array via the   method of class  .\n         \n     ECMAScript.next: ensuring compatibility with legacy code \n      My initial idea  [1]  is similar to the hypothetical NextScript as described above. \n      Afterwards, Allen Wirfs-Brock suggested how things could be adapted so that the existing “class protocol” wouldn’t have to be changed  [2] . This proposal might make it into ECMAScript.next.\n         \n        Given a non-function object   (a “class object”, the prototype as a class):\n         \n             Make sure that   points to  . This step is needed for the   operator to work as described below. \n             In the following two cases, treat non-function objects   differently, while not changing the behavior for functions:\n                 \n                     Interpret   as syntactic sugar for  . \n                     Interpret   as syntactic sugar for  \n                 \n             \n         \n     \n      It might make sense to let a new-style class inherit from an old-style class. There are two ways to do this:\n         \n             Manually: The subclass extends  . Constructor chaining and super-method calls should work as expected. \n             Automatically: Extend the prototype operator   so that, when it encounters a function   as its left-hand side, it makes   the prototype and not  . \n         \n     \n       Class literals  have been proposed for ECMAScript.next. They look much like prototypes-as-classes, but are internally translated to constructor functions. It might be impossible to only have prototypes-as-classes in JavaScript (as that might break too much existing code). If so, then class literals avoid the hassle of having to support both prototypes-as-classes and constructor functions. \n \nAlas, as things stand right now, it is not likely that prototypes as classes will ever make it into JavaScript.\nMy current favorite are class literals that desugar to prototypes-as-classes, e.g.\n \n     It will be easier for IDEs to find your classes and support auto-completion etc. \n     It gives you the option to introduce more inheritance-related features in the future (e.g. traits). \n     They look familiar to people coming from class-based languages. Prototypes as classes ensure that the syntactic sugar is conceptually very similar to what is going on under the hood. \n Improved object literals in ECMAScript.next Object Literal Extensions \n     The prototype operator   (borrowed by NextScript above). \n     Super references (also borrowed by NextScript). \n     A shorter notation for methods:\n \n     \n     Object literal shorthand: The following\n \nis syntactic sugar for\n \n     \n A library for current JavaScript proto-js \n      Instead of\n \nyou write\n \nCredit for this idea goes to Irakli Gozalishvili and his prototype-centric inheritance library “ selfish ”. He comments:\n \n     \n      Instead of\n \nyou write\n \n        Subclasses of   automatically inherit its class method  , because   is part of their prototype chain.\n     \n      Instead of\n \nyou write\n \n        This is a built-in JavaScript method. One just exploits the fact that the prototype of an instance is also its class.\n     \n Related reading Classes: suggestions for improvement  [Initial idea to allow   for non-function objects] \n Prototypes as the new class declaration  [Proposal for ensuring the compatibility with the current protocol] What’s up with the “constructor” property in JavaScript? Harmony: Object Literal Extensions Lightweight JavaScript inheritance APIs  [Especially Resig’s Simple Inheritance looks almost like NextScript] A brief history of ECMAScript versions (including Harmony and ES.next) comments powered by Disqus."},
{"url": "https://2ality.com/2011/07/taking-break.html", "title": "Programming: the benefits of taking a break", "content": "Programming: the benefits of taking a break dev software engineering \n      Once, I worked really hard on a feature. For two weeks, 12 hours a day, I put in a lot of effort. After those two weeks, I took a break and came up with several ideas that made much of the work unnecessary. \n      Being tired has a similar effect as being drunk. At the end of a day, I often kid myself that I’ll just get this one thing finished quickly to have a fresh start the next day. In reality, I usually need to clean up yesterday’s messes then. If instead I find the discipline to postpone, it only takes me a fraction of the time to accomplish the same task – with better results. \n      If you want to write quality code, code reviews (including their   version, pair programming), are invaluable. If I let things that I have written lie for a few days, I have forgotten enough about them that I approach them with a fresh mind. I’m almost my own code reviewer, which allows me to really improve the understandability of my code. \n      Don’t forget that the latter is part of the former and adheres to biological principles. Especially people working with computers tend to focus too much on their brain and neglect the rest of their body. The brain needs oxygen, rest and nutrients to function at optimal capacity, so you need to breathe, sleep and eat properly. \n      You can view programming as solving a puzzle in a problem domain, as finding the best tools, techniques, and libraries to write your code. If you take a break from coding, you can attack the problem domain from a different angle – by discussing it with other people. It doesn’t matter whether you do so via talking face to face, via social websites, via email, via Twitter, or via other tools. Swapping experiences gives you a new perspective on your code without doing actual coding. In a way, web searches are a uni-directional way of communicating, but they have become too much part of the coding routine to be considered a separate activity. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/06/ecmascript.html", "title": "A JavaScript glossary: ECMAScript, TC39, etc.", "content": "A JavaScript glossary: ECMAScript, TC39, etc. esnext dev javascript jslang A little ECMAScript glossary \n      Sun (now Oracle) had a trademark on the name “Java” and therefore also on the name “JavaScript”. That led to Microsoft calling its JavaScript dialect “JScript”. Thus, when it came to finding an official name for the language, “JavaScript” could not be used.\n    “ECMAScript” was chosen, because the corresponding standard is hosted by Ecma International (see below). Usually, the terms “ECMAScript” and “JavaScript” are interchangeable. If JavaScript means “ECMAScript as implemented by Mozilla and others” then ECMAScript is the standard and JavaScript one of its implementations. The term “ECMAScript” is also used to describe language versions: ECMAScript 3, ECMAScript 5, etc. \n      The  Ecma International  (a standards organization) has created the ECMA-262 standard which is the official specification of the ECMAScript language. \n      If one talks about ECMAScript 5, one means the 5th edition of ECMA-262, the current edition of this standard. \n     Technical Committee 39  maintains the ECMAScript language standard (and more). Members of the committee are all major browser vendors and other companies interested in the web. Those companies send delegates to meetings which are also attended by invited experts.\n     \n History of ECMAScript versions \n      This is the version of ECMAScript that most browsers support today. It introduced many features that have become an inherent part of the language:\n         [1] \n     \n      ECMAScript 4 was developed as the next version of JavaScript, with a prototype written in ML. However, TC39 could not agree on its feature set. To prevent an impasse, the committee met at the end of July 2008 and came to an accord, summarized in four points  [2] :\n         Develop an incremental update of ECMAScript (which became ECMAScript 5). Develop a major new release, which was to be more modest than ECMAScript 4, but much larger in scope than the version after ECMAScript 3. This version has been code-named  , due to the nature of the meeting in which it was conceived. Features from ECMAScript 4 that would be dropped: packages, namespaces, early binding. Other ideas were to be developed in consensus with all of TC39. \n        Thus: The ECMAScript 4 developers agreed to make Harmony less radical than ECMAScript 4, the rest of TC39 agreed to keep moving things forward.\n     \n      This version brings several enhancements to the standard library and even updated language semantics via a  .  [3] \n      It quickly became apparent that the plans for Harmony were too ambitious, so its features were split into two groups: Group one are features that are considered for the next version after ECMAScript 5. This version has the code name ECMAScript.next and will probably become ECMAScript 6. Group two are Harmony features that are not considered ready or high-priority enough for ECMAScript.next. Those will still make it into ECMAScript, e.g. as part of ECMAScript.next.next. The current goal is to have ECMAScript.next finished by 2013, with parts of it making it into web browsers (especially Firefox) before then. \n Summary \n \n \n     ECMAScript.next is the code name of the next version of ECMAScript. Using that term implies that one is discussing features that may or may not be added to the final standard.\n     \n     ECMAScript 6 is the actual (final) name of ECMAScript.next. Using that term implies that one is talking about features that will definitely be in the standard.\n     \n     ECMAScript Harmony is a superset of ECMAScript.next and means “features coming up after ECMAScript 5”. According to Eich, it comprises ECMAScript 6 and ECMAScript 7.\n     \n References ECMAScript - Wikipedia, the free encyclopedia ECMAScript Harmony  (archived email) What’s new in ECMAScript 5 JavaScript: how it all began Posts on ECMAScript.next \n         \n             Best overview of planned features: “ ECMAScript.next: the ‘TXJS’ update by Eich ” \n         \n     comments powered by Disqus."},
{"url": "https://2ality.com/2011/07/firefox-sourcemap.html", "title": "SourceMap on Firefox: source debugging for languages compiled to JavaScript [update: WebKit, too]", "content": "SourceMap on Firefox: source debugging for languages compiled to JavaScript [update: WebKit, too] dev firefox javascript coming to WebKit \nMore and more languages are compiled to JavaScript. Mozilla has plans to let you debug those languages in their source code (no need to look at JavaScript).\n \n \nExamples of languages that are compiled to JavaScript:\n \n     Google Web Toolkit (GWT): compiles Java to JavaScript which allows one to use Java on both server and client and to do web development with a great IDE (as in “Eclipse without plugins”). \n     Minification [1]: tranforms a JavaScript program into a more compact version of itself without changing what it does. The measure taken here are: stripping out comments and newlines, using shorter variables names, etc. \n     CoffeeScript [2]: is an improved version of JavaScript with a syntax for people who hate braces. \n     Google Traceur [3]: compiles a variant of ECMAScript.next to JavaScript, on the fly. \n Exceptions report lines in the generated code, not in the original. Output in the console links back to generated code. You have to debug the generated code. SourceMap \nRelated reading:\n What is the JavaScript equivalent of Java bytecode? Blog posts  on CoffeeScript. Google’s Traceur: compile ECMAScript.next to JavaScript on the fly comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/pattern-matching-reasonml.html", "title": "Pattern matching in ReasonML: destructuring,  switch ,  if  expressions", "content": "Pattern matching in ReasonML: destructuring,  ,   expressions dev reasonml Table of contents for this series of posts: “ What is ReasonML? ”  Complete rewrite of how patterns are introduced. In this blog post, we look at three features that are all related to pattern matching: destructuring,  , and   expressions. Digression: tuples   # To illustrate patterns and pattern matching, we’ll use tuples. Tuples are basically records whose parts are identified by position (and not by name). The parts of a tuple are called  . Let’s create a tuple in  : The first component of this tuple is the boolean  , the second component is the string  . Accordingly, the tuple’s type is  . Let’s create one more tuple: Pattern matching   # Before we can examine destructuring,   and  , we need to learn their foundation: pattern matching.  are a programming mechanism that helps with processing data. They serve two purposes: \n Check what structure data has. \n Extract parts of data. \n This is done by   patterns against data. Syntactically, patterns work as follows: \n ReasonML has syntax for creating data. For example: tuples are created by separating data with commas and putting the result in parentheses. \n ReasonML has syntax for processing data. The syntax of patterns mirrors the syntax for creating data. \n Let’s start with simple patterns that support tuples. They have the following syntax: \n A variable name is a pattern.\n \n Examples:  ,  ,  \n \n \n A literal is a pattern.\n \n Examples:  ,  ,  \n \n \n A tuple of patterns is a pattern.\n \n Examples:  ,  ,  \n \n \n The same variable name cannot be used in two different locations. That is, the following pattern is illegal:  Equality checks   # The simplest patterns don’t have any variables. Matching such patterns is basically the same as an equality check. Let’s look at a few examples: So far, we have used the pattern to ensure that the data has the expected structure. As a next step, we introduce variable names. Those make the structural checks more flexible and let us extract data. Variable names in patterns   # A variable name matches any data at its position and leads to the creation of a variable that is bound to that data. The special variable name   does not create variable bindings and can be used multiple times: Alternatives in patterns   # Let’s examine another pattern feature: Two or more subpatterns separated by vertical bars form an  . Such a pattern matches if one of the subpatterns matches. If a variable name exists in one subpattern, it must exit in all subpatterns. Examples: The   operator: bind and match at the same time   # Until now, you had to decide whether you wanted to bind a piece of data to a variable or to match it via a subpattern. The   operator lets you do both: it’s left-hand side is a subpattern to match, its right-hand side is the name of a variable that the current data will be bound to. There are many more ways of creating patterns   # ReasonML supports more complex data types than just tuples. For example: lists and records. Many of those data types are also supported via pattern matching. More on that in upcoming blog posts. Pattern matching via   (destructuring)   # You can do pattern matching via  . As an example, let’s start by creating a tuple: We can use pattern matching to create the variables   and   and bind them to   and  , respectively: The variable name   also works and does not create variables: If a pattern doesn’t match, you get an exception: We get two kinds of feedback from ReasonML: \n At compile time: A warning that there are   tuples that the pattern doesn’t cover. We’ll look at what that means when we learn   expressions. \n At runtime: An exception that matching failed. \n Single-branch pattern matching via   is called  . Destructuring can also be used with function parameters (as we’ll see in an upcoming blog post).    #  matched a single pattern against data. With a   expression, we can try multiple patterns. The first match determines the result of the expression. That looks as follows:  goes through the branches sequentially: the first pattern that matches   leads to the associated expression becoming the result of the   expression. Let’s look at an example where pattern matching is simple: If the   value is more than a single entity (variable name, qualified variable name, literal, etc.), it needs to be in parentheses: Warnings about exhaustiveness   # When you compile the previous example or enter it in  , you get the following compile-time warning: That means: The operand   has the type   and the branches do not cover all elements of that type. This warning is very useful, because it tells us that there are cases that we may have missed. That is, we are warned about potential trouble ahead. If there is no warning,   will always succeed. If you don’t fix this issue, ResonML throws a runtime exception when an operand doesn’t have a matching branch: One way to make this warning go away is to handle all elements of a type. I’ll briefly sketch how to do that for recursively defined types. These are defined via: \n One or more (non-recursive) base cases. \n One or more recursive cases. \n For example, for natural numbers, the base case is zero, the recursive case is one plus a natural number. You can cover natural numbers exhaustively with   via two branches, one for each case. How exactly this works will be described in an upcoming blog post. For now, it’s enough to know that, whenever you can, you should do exhaustive coverage. Then the compiler warns you if you miss a case, preventing a whole category of errors. If exhaustive coverage is not an option, you can introduce a catch-all branch. The next section shows how to do that. Variables as patterns   # The warning about exhaustiveness goes away if you add a branch whose pattern is a variable: We have created the new variable   by matching it against the   value. That new variable can be used in the expression of the branch. This kind of branch is called “catch-all”: it comes last and is evaluated if all other branches fail. It always succeeds and matches everything. In C-style languages, catch-all branches are called  . If you just want to match everything and don’t care what is matched, you can use an underscore: Patterns for tuples   # Let’s implement logical And ( ) via a   expression: This code can be simplified by using an underscore and a variable: The   operator   # The   operator also works in   patterns: Alternatives in patterns   # Using alternatives in subpatterns looks as follows. Alternatives can also be used at the top level: Guards for branches   #  (conditions) for branches are a  -specific feature: they come after patterns and are preceded by the keyword  . Let’s look at an example: The first branch is only evaluated if the guard   is  .  expressions   # ReasonML’s   expressions look as follows (  can be omitted): For example: Given that scope blocks are also expressions, the following two   expressions are equivalent: In fact,   pretty-prints the former expression as the latter. The   expression and the   expression must have the same type. Omitting the   branch   # You can omit the   branch – the following two expressions are equivalent. Given that both branches must have the same type,   must have the type   (whose only element is  ). For example,   evaluates to   and the following code works: In contrast, this doesn’t work: The ternary operator ( )   # ReasonML also gives you the ternary operator as an alternative to   expressions. The following two expressions are equivalent. The following two expressions are equivalent, too.   even pretty-prints the former as the latter. I don’t find the ternary operator operator very useful in ReasonML: its purpose in languages with C syntax is to have an expression version of the   statement. But   is already an expression in ReasonML. comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/functions-reasonml.html", "title": "ReasonML: functions", "content": "ReasonML: functions dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” This blog post explores how functions work in ReasonML. Defining functions   # An anonymous (nameless) function looks as follows: This function has a single parameter,  , and the body  . You can give that function a name by binding it to a variable: This is how you call  : Functions as parameters of other functions (high-order functions)   # Functions can also be parameters of other functions. To demonstrate this feature, we briefly use  , which will be explained in detail in a later blog post.   are, roughly, singly linked lists and similar to immutable arrays. The list function   takes  , applies   to each of its elements and returns the results in a new list. For example: Functions that have functions as parameters or results are called  . Functions that don’t are called  .   is a higher-order function.   is a first-order function. Blocks as function bodies   # A function’s body is an expression. Given that scope blocks are expressions, the following two definitions for   are equivalent. Single parameters without parentheses   # If a function has a single parameter and that parameter is defined via an identifier, you can omit the parentheses: Avoiding warnings about unused parameters   # ReasonML compilers and editor plugins warn you about unused variables. For example, for the following function, you get the warning “unused variable y”. You can avoid the warning by prefixing the names of unused variables with underscores: You can also use the variable name  , multiple times: Recursive bindings via     # Normally, you can only refer to  -bound values that already exist. That means that you can’t define mutually recursive and self-recursive functions via  . Defining mutually recursive functions   # Let’s examine mutually recursive functions first. The following two functions   and   are mutually recursive. You must use the special   to define them: Notice how   connects multiple   entries that all know each other.  There is no semicolon before the  . The semicolon at the end indicates that   is finished.  and   are defined in terms of each other: \n An integer   is even if   is odd. \n An integer   is odd if   is even. \n Obviously, this can’t go on forever, so we need to define base cases in   (lines B and C). We also take care of negative integers there (line A). Let’s use these functions: Defining self-recursive functions   # You also need   for functions that call themselves recursively, because when the recursive call appears, the binding does not exist, yet. For example: Terminology: arity   # The arity of a function is the number of its (positional) parameters. For example, the arity of   is 1. The following adjectives describe functions with arities from 0 to 3: \n A   function is a function with arity 0. \n A   function is a function with arity 1. \n A   function is a function with arity 2. \n A   function is a function with arity 3. \n Beyond arity 3, we talk about 4-ary functions, 5-ary functions, etc. Functions whose arity can vary, are called  . The types of functions   # Functions are the first time that we get in contact with complex types: types built by combining other types. Let’s use ReasonML’s command line   to determine the types of two functions. Types of first-order functions   # First, a function  : Therefore, the type of   is: The arrow indicates that   is a function. Its parameters are two ints. Its result is a single int. The notation   is also called the   of  . It describes the types of its inputs and its outputs. Types of higher-order functions   # Second, a higher-order function  : You can see that the parameter of   is itself a function and has the type  . This is how   is used: Type annotations and type inference   # In some statically typed programming languages, you have to provide type annotations for all parameters and the return value of a function. For example: The first two occurrences of   are type annotations for the parameters   and  . The last   declares the result of  . However, ReasonML allows you to omit the return type. It then uses   to deduce the return type from the types of the parameters and the function’s body: However, ReasonML’s type inference is even more sophisticated than that. It does not only deduce types top-down (from the parameters to the body to the result). It can also deduce types bottom-up. For example, it can infer that   and   are ints, due to them being operands of the int operator  : In other words: most type annotations in ReasonML are optional. Type annotations can lead to more specific inferred types   # Even if type annotations are optional, providing them sometimes increases the specificity of types. Consider, for example, the following function  : All the types that ReasonML infers are  . These start with apostrophes and mean “any type”. They are explained in more detail later. If we annotate the parameters, we get more specific types: We also get more specific types if we only annotate the return value: Best practice: annotate all parameters   # The coding style I prefer for functions is to annotate all parameters, but to let ReasonML infer the return type. Apart from improving type checking, annotations for parameters are also good documentation (which is automatically checked for consistency). There are no functions without parameters   # There are no nullary functions in ReasonML, but you will rarely notice when using it. For example, if you define a function that has no parameters, ReasonML adds a parameter for you, whose type is  : Recall that the type   only has the single element  , which means “no value” (it’s roughly similar to   in many C-style languages). When calling functions, omitting parameters is the same as passing   as a single parameter: The following interaction is another demonstration of this phenomenon: If you call a unary function without parameters,   underlines   and complains about that expression having the wrong type. Notably, it does not complain about missing parameters (it doesn’t partially apply either – details later). To summarize, ReasonML does not have nullary functions, but it hides that fact both when defining and when calling functions. Why no nullary functions?   # Why doesn’t ReasonML have nullary functions? That is due to ReasonML always performing   (explained in detail later): If you don’t provide all of a function’s parameters, you get a new function from the remaining parameters to the result. As a consequence, if you could actually provide no parameters at all, then   would be the same as  . That is, the former wouldn’t do anything. Destructuring function parameters   # Destructuring can be used wherever variables are bound to values: in   expressions, but also in parameter definitions. The latter is used in the following function, which computes the sum of the components of a tuple: The double parentheses around   indicate that   is a function with a single parameter, a tuple whose components are   and  . It is not a function with the two parameters   and  . Its type is: When it comes to type annotations, you can either annotate the components: Or you can annotate the whole parameter: Labeled parameters   # So far, we have only used  : the position of an actual parameter at the call site determines what formal parameter it is bound to. But ReasonML also supports  . Here, labels are used to associate actual parameters with formal parameters. As an example, let’s examine a version of   that uses labeled parameters: In this function definition, we used the same name for the label   and the parameter  . You can also use separate names, e.g.   for the label and   for the parameter: At call sites, you can abbreviate   as just  : One nice feature of labels is that you can mention labeled parameters in any order: Compatibility of function types with labeled parameters   # There is one unfortunate caveat to being able to mention labeled parameters in any order: function types are only compatible if labels are mentioned in the same order. Consider the following three functions.  works as expected with  : However, with  , we get an error, because the labels are in the wrong order: Optional parameters   # In ReasonML, only labeled parameters can be optional. In the following code, both   and   are optional. Let’s examine what this relatively complicated code does. Why the   as the last parameter? That is explained in the next section. What does the   expression do?   and   were declared to be optional via  . As a consequence, both have the type  .   is a  . Details will be explained in an upcoming blog post. For now, I’ll give a brief preview. The definition of   is:  is used as follows when you call  : \n If you omit the parameter   then   will be bound to  . \n If you provide the value   for   then   will be bound to  . \n In other words,   wraps values and the   expression in the example unwraps them. With optional parameters, you need at least one positional parameter   # Why does   have a parameter of type   (an empty parameter, if you will) at the end? The reason has to do with partial application (which is explained in detail later). In a nutshell, two things are in conflict here: \n With partial application, if you omit parameters, you create a function that lets you fill in those remaining parameters. \n With optional parameters, if you omit parameters, they should be bound to their defaults. \n To resolve this conflict, ReasonML fills in defaults for all missing optional parameters when it encounters the first positional parameter. Before it encounters a positional parameter, it still waits for the missing optional parameters. That is, you always need a positional parameter to trigger the call. Since   doesn’t have one, we added an empty one. The pattern   forces that parameter to be  , via destructuring. Another reason for the empty parameter is that, otherwise, we wouldn’t be able to trigger both defaults, because   is the same as  . The advantage of this slightly weird approach is that you get the best of both worlds: partial application and optional parameters. Type annotations for optional parameters   # When you annotate optional parameters, they must all have   types: The type signature of   is: It’s unfortunate that the definition differs from the type signature in this case. The rationale is that we want to distinguish two things: \n External types: You normally call   with ints and not with   values. \n Internal types: Internally, you need to process   values. \n In the next section, we use parameter default values for  . Then the internal types are different, but the external types (and therefore the type of  ) are the same. Parameter default values   # Handling missing parameters can be cumbersome: In this case, all we want is for   and   to be zero if they are omitted. ReasonML has special syntax for this: This new version of   is used exactly the same way as before: whether or not we handle missing parameters ourselves or automatically (via default values) is hidden from users of the function. Type annotations with parameter default values   # If there are default values, you annotate parameters as follows: The type of   is: Passing   values to optional parameters (advanced)   # Internally, optional parameters are received as elements of the   type (  or  ). Until now, you could only pass those values by either providing or omitting parameters. But there is also a way to pass those values directly. Before we get to use cases for this feature, let’s try it out first, via the following function.  has two optional parameters. Let’s start by providing   and omitting  , via elements of  : The syntax for passing   values is: If   is a variable whose name is  , you can abbreviate: the following two syntaxes are equivalent. So what is the use case? It’s one function forwarding an optional parameter to another function’s optional parameter. That way, it can rely on that function’s parameter default value and doesn’t have to define one itself. Let’s look at an example: The following function   has an optional parameter, which is passes on to  ’s two optional parameters:  does not have to specify a parameter default value, it can use  ’s defaults. Partial application   #  is a mechanism that makes functions more versatile: If you omit one or more parameters at the end of a function call  ,   returns a function that maps the missing parameters to  ’s final result. That is, you     to its parameters in multiple steps. The first step is called a   or a  . Let’s see how that works. We first create a function   with two parameters: Then we partially call the binary function   to create the unary function  : We have only provided  ’s first parameter,  . Whenever we call  , we provide  ’s second parameter,  : Why is partial application useful?   # Partial application lets you write more compact code. To demonstrate how, we’ll work with a list of numbers: Next, we’ll use the standard library function  .   takes  , applies   to each of its elements and returns them as a new list. We use   to add 2 to each element of  : With partial application we can make this code more compact: Which version is better? That depends on your taste. The first version is – arguably – more self-descriptive, the second version is more concise. Partial application really shines with the pipe operator ( ) for function composition (which is explained later). Partial application and labeled parameters   # So far, we have only see partial application with positional parameters, but it works with labeled parameters, too. Consider, again, the labeled version of  : If we call   with only the first labeled parameter, we get a function that maps the second parameter to the result: Providing only the second labeled parameter works analogously. That is, labels don’t impose an order here. That means that partial application is more versatile with labels, because you can partially apply any labeled parameter, not just the last one. # How about optional parameters? The following version of   has only optional parameters: If you mention only the label   or only the label  , partial application works as before (with the addition of the positional parameter of type  ): However, if you provide the positional parameter, you don’t apply partially. The defaults are filled in immediately: Even if you take one or two intermediate steps, the   is always needed to trigger the actual function call. One intermediate step looks as follows. Two intermediate steps: Currying (advanced)   # Currying is one technique for implementing partial application for positional parameters. Currying a function means transforming it from a function with an arity of 1 or more to a series of unary function calls. For example, take the binary function  : To curry   means to convert it to the following function: Now we have to invoke   as follows: What have we gained? Partial application is easy now: And now the surprise: all functions in ReasonML are automatically curried. That’s how it supports partial application. You can see that if you look at the type of the curried  : On other words:   is the same as   and the following two types are equivalent: Let’s conclude with a function that curries binary functions. Given that currying functions that are already curried is meaningless, we’ll curry a function whose single parameter is a pair. Let’s use   with a unary version of  : The type at the end tells us that we have successfully created a binary function. The reverse-application operator ( )   # The operator   is called   or  . It lets you chain function calls:   is the same as  . That may not look like much, but it is quite useful when combining function calls. Example: piping ints and strings   # Let’s start with a simple example. Given the following two functions. If we use them with traditional function calls, we get: First we apply   to 4, then   (a function in the standard library) to the result, etc. The pipe operator lets us write code that is closer to the description that I have just given: Example: piping lists   # With more complex data and currying, we get a style that is reminiscent of chained method calls in object-oriented programming. For example, the following code works with a list of ints: These functions will be explained in detail in an upcoming blog post. For now, it is enough to have a rough idea of how they work. The three computational steps are: We see that in all of these functions, the primary parameter comes last. When we piped, we first filled in the secondary parameters via partial application, creating a function. Then the pipe operator filled in the primary parameter, by calling that function. The primary parameter is similar to   or   in object-oriented programming languages. Caveat: piping into unary functions   # When you use partial application to create the operands for the pipe operator, there is one mistake that is easy to make. See if you can spot that mistake in the following code. The problem is that we are trying to partially apply zero parameters. That doesn’t work, because   is the same as  . And  ’s single parameter is of type   (not of type  ). If you omit the parentheses after  , everything works as intended: Tips for designing function signatures   # These are a few tips for designing the type signatures of functions: \n Primary parameters should be positional:\n \n If a function has a single primary parameter, make it a positional parameter and put it at the end. That supports the pipe operator for function composition. \n Some functions have multiple primary parameters that are all similar. Turn these into multiple positional parameters at the end. An example would be a function that concatenates two lists into a single list. In that case, both positional parameters are lists. \n Exception to this rule: If there are two or more primary parameters that are different, all of them should be labeled. \n \n \n All other parameters should be labeled\n \n If a function has only a single parameter, it tends to be unlabeled, even if it is not strictly primary. \n \n \n A function should always have at least one positional parameter.\n \n Rationale: If you want to be able to transparently add optional parameters later on, you need a positional parameter. Being able to do this without changing call sites helps with evolving APIs. \n If no positional parameter make sense, simply use  : \nWe match   as a positional parameter via destructuring, but never use that value. \n Note that ReasonML automatically adds the parameter   to nullary functions, anyway. \n \n \n The idea behind these rules is to make code as self-descriptive as possible: The primary (or only) parameter is described by the name of the function, the remaining parameters are described by their labels. As soon as a function has more than one positional parameter, it usually becomes difficult to tell what each parameter does. Compare, for example, the following two function calls. The second one is much easier to understand. The listed rules should also influence the name of the function. See how it works with labeled parameters (if there are any) and without them: Are function calls pleasant to read? Does the function name work as a description of the positional parameter? ReasonML’s naming style reminds me of invoking commands in Unix shells. Source of this section: Sect. “ Suggestions for labeling ” in the OCaml Manual. Single-argument match functions   # ReasonML provides an abbreviation for unary functions that immediately switch on their parameters. Take, for example the following function. This function is used as follows: If you use the   operator to define  , the code becomes shorter: (Advanced)   # All remaining sections are advanced. Operators   # One neat feature of ReasonML is that operators are just functions. You can use them like functions if you put them in parentheses: And you can define your own operators: By putting an operator in parentheses, you can also easily look up its type: Rules for operators   # There are two kinds of operators: infix operators (between two operands) and prefix operators (before single operands). The following   can be used for both kinds of operators: Additionally, the following keywords are infix operators: Additionally, the following keywords are prefix operators: Source of this section: Sect. “ Prefix and infix symbols ” in the OCaml Manual. Precedences and associativities of operators   # The following tables lists operators and their associativities. The higher up an operator, the higher its precedence is (the stronger it binds). For example,   has a higher precedence than  . Legend: \n  means   followed by other operator characters. \n Applications: function application, constructor application, tag application \n Source of this table: Sect. “ Expressions ” in the OCaml manual When does associativity matter?   # Associativity matters whenever an operator is not  . With a commutative operator, the order of the operands does not matter. For example, plus ( ) is commutative. However, minus ( ) is not commutative. Left associativity means that operations are grouped from the left. Then the following two expressions are equivalent: Minus ( ) is left-associative: Right associativity means that operations are grouped from the right. Then the following two expressions are equivalent: We can define our own right-associative minus operator. According to the operator table, if it starts with an   symbol, it is automatically right-associative: If we use it, we get a different result than normal minus: Polymorphic functions   # Recall the definition of   from a previous blog post: making the same operation work for several types. There are multiple ways in which polymorphism can be achieved. OOP languages achieve it via  .   is another popular kind of polymorphism. ReasonML supports  : Instead of using a concrete type such as   for a parameter or a result, you use a  . If the type of a parameter is a type variable, values of any type are accepted (in case you are interested: such type variables are  ). Type variables can be viewed as parameters of the function type; hence the name  . A function that uses type variables is called a  . Example:     # For example,   is the   that simply returns its parameter: The type for   that ReasonML infers is interesting: It can’t detect a type for  , so it uses the type variable   to indicate “any type”. All types whose names start with apostrophes are type variables. ReasonML also infers that the return type of   is the same as the type of its parameter. That is useful information and helps with inferring the type of  ’s result. In other words:   is generic and works with any type. Example:     # Let’s look another example: a generic function   for accessing the first component of a pair (a 2-tuple).  uses destructuring to access the first component of that tuple. Type inference tells us that the return type is the same as the type of the first component. We can use an underscore to indicate that we are not interested in the second component: With a type-annotated component,   looks as follows: Example:     # As a quick preview, I’m showing the signature of another function that I’ll explain properly in an upcoming blog post. Overloading vs. parametric polymorphism   # Note how overloading and parametric polymorphism are different: \n \n Overloading provides different implementations for the same operation. For example, some programming languages let you use   for arithmetic, string concatenation and/or array concatenation. \n \n \n Parametric polymorphism specifies a single implementation that works with several types. \n \n ReasonML does not support variadic functions   # ReasonML does not support variadic functions (e.g. via  ). That is, you can’t define a function that computes the sum of an arbitrary number of parameters: Instead, you are forced to define one function for each arity: You have seen a similar technique with currying, where we couldn’t define a variadic function   and had to go with a binary  , instead. You’ll occasionally see it in libraries, too. An alternative to this technique is to use lists of ints. comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/basic-types-reasonml.html", "title": "ReasonML: basic values and types", "content": "ReasonML: basic values and types dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” In this blog post, we’ll look at ReasonML’s support for booleans, integers, floats, strings, characters and the unit type. We’ll also see a few operators in action. To explore, we’ll use the interactive ReasonML command line  , which is part of the package   ( the manual explains how to install it ). Interactions in     # Interactions in   look as follows. Two observations: \n You must end the expression   with a semicolon in order for it to be evaluated. \n  always prints out the types of the results it computes. That is especially helpful later on, with more complicated types, e.g. the types of functions. \n ReasonML is statically typed – what does that mean?   # Values in ReasonML are statically typed. What does   mean? On one hand, we have the term  . In this context,   means “set of values”. For example   is the name of the type of all boolean values: the (mathematical) set  . On the other hand, we make the following distinction in the context of the life cycle of code: \n Static: at compile time, without running the code. \n Dynamic: at runtime, while the code is running. \n Therefore   means: ReasonML knows the types of values at compile time. And types are also known while editing code, which supports intelligent editing features. Get used to working with types   # We have already encountered one benefit of static typing: editing support. It also helps with detecting some kinds of errors. And it often helps with documenting how code works (in a manner that is automatically checked for consistency). In order to reap these benefits, you should get used to working with types. You get help in two ways: \n ReasonML often   types (writes them for you). That is, a passive knowledge of types gets you surprisingly far. \n ReasonML gives descriptive error messages when something goes wrong that may even include tips for fixing the problem. That is, you can use trial and error to learn types. \n No ad hoc polymorphism (yet)   #  may sound brainy, but it has a simple definition and visible practical consequences for ReasonML. So bear with me. ReasonML does not currently support ad hoc polymorphism where the same operation is implemented differently depending on the types of the parameters. Haskell, another functional programming language supports ad hoc polymorphism via  . ReasonML may eventually support it via the similar  . ReasonML not supporting ad hoc polymorphism means that most operators such as   (int addition),   (float addition) and   (string concatenation) only support a single type. Therefore, it is your responsibility to convert operands to proper types. On the plus side, ReasonML will warn you at compile time if you forget to do so. That’s a benefit of static typing. Comments   # Before we get into values and types, let’s learn comments. ReasonML only has one way of writing comments: Conveniently, it is possible to nest this kind of comment (languages with C-style syntax are often not able to do that): Nesting is useful for commenting out pieces of code: Booleans   # Let’s type in a few boolean expressions: Numbers   # These are integer expressions: Floating-point expressions look as follows: Strings   # Normal string literals are delimited by double quotes: ReasonML strings are encoded as UTF-8 and not compatible with JavaScript’s UTF-16 strings. ReasonML’s support for Unicode is also worse than JavaScript’s – already limited – one. As a short-term workaround, you can use BuckleScript’s JavaScript strings in ReasonML: These strings are produced via multi-line string literals annotated with  , which are only treated specially by BuckleScript. In native ReasonML, you get normal strings. Characters   # Characters are delimited by single quotes. Only the first 7 bits of Unicode are supported (no umlauts etc.):  is syntactic sugar for  . The unit type   # Sometimes, you need a value denoting “nothing”. ReasonML has the special value   for this purpose.   has its own type,   and is the only element of that type: In contrast to   in C-style languages,   is not an element of any other type. Among other things, the type   is used for functions with side effects that don’t return anything. For example: The function   takes a string as an argument and prints that string. It has no real result. Converting between basic types   # ReasonML’s standard library has functions for converting between the basic types: All of the conversion functions are named as follows. More operators   # Comparison operators   # The following are comparison operators. They are part of the few operators that work with several types (they are  ). You cannot, however, mix operand types: Equality operators   # ReasonML has two equality operators. Double equals (equality by value) compares values and does so even for reference types such as lists. In contrast, triple equals (equality by reference) compares references:  is the preferred equality operator (unless you really want to compare references). comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/variants-reasonml.html", "title": "ReasonML: variant types", "content": "ReasonML: variant types dev reasonml Table of contents for this series of posts: “ What is ReasonML? ”  (short:  ) are a data type supported by many functional programming languages. They are an important ingredient in ReasonML that is not available in C-style languages (C, C++, Java, C#, etc.). This blog post explains how they work. Variants as sets of symbols (enums)   # Variants let you define sets of symbols. When used like this, they are similar to enums in C-style languages. For example, the following type   defines symbols for six colors. There are two elements in this type definition: \n The name of the type,  , which must start with a lowercase letter. \n The names of   ( ,  , ...), which must start with uppercase letters. Why constructors are called constructors will become clear, once we use variants as data structures. \n The names of constructors must be unique within the current scope. That enables ReasonML to easily deduce their types: Variants can be processed via   and pattern matching: Here, constructors are used both as patterns (left-hand sides of  ) and values (right-hand sides of  ). This is   in action: Tip: replacing booleans with variants   # In ReasonML, variants are often a better choice than booleans. Take for example, this function definition. (Remember that in ReasonML, the main parameter goes at the end, to enable currying.) This is how   is invoked: It’s not clear what the boolean at the end does. You can improve this function via a labeled parameter. Even more self-descriptive is to introduce a variant for the value of  : Using the variant   has two advantages: \n It is immediately clear what “not showing details” means. \n It is easy to add more modes later on. \n Associating variant values with data   # Sometimes, you want to use variant values as keys for looking up data. One way of doing so is via a function that maps variant values to data: This technique has one disadvantage: it leads to redundancies, especially if you want to associate multiple pieces of data with the same variant value. We’ll explore alternatives in a future blog post. Variants as data structures   # Each constructor can also hold one or more values. These values are identified by position. That is, individual constructors are similar to tuples. The following code demonstrates this feature. Type   is a variant with a single constructor. It holds two floating point numbers. A   is another variant. It is either: \n a   defined by two corner points or \n a   defined by a center and a radius. \n With multiple constructor parameters, them being positional and not labeled becomes a problem – we have to describe elsewhere what their roles are.   are an alternative in this case (to be described in a future blog post). This is how you use the constructors: Due to each constructor name being unique, ReasonML can easily infer the types. If constructors hold data, pattern matching via   is even more convenient, because it also lets you access that data: Let’s use  , continuing our previous interactive   session: Self-recursive data structures via variants   # You can also define recursive data structures via variants. For example, binary trees whose nodes contain integers:  values are constructed like this:  looks as follows: 1 has the two child nodes 2 and 3. 2 has two empty child nodes. Etc. Processing self-recursive data structures via recursion   # To demonstrate processing self-recursive data structures, let’s implement a function  , which computes the sum of the integers stored in the nodes. This kind of recursion is typical when working with variant types: A limited set of constructors is used to create data. In this case:   and  . The same constructors are used as patterns to process the data. That ensures that we handle whatever data is passed to us properly, as long as it is of type  . ReasonML helps by warning us if   doesn’t cover   exhaustively. That protects us from forgetting cases that we should consider. To illustrate, let’s assume we forgot   and wrote   like this: Then we get the following warning. As mentioned in the blog post on functions, introducing catch-all cases means that you lose this protection. That’s why you should avoid them if you can. Mutually recursive data structures via variants   # Recall that with  , we had to use   whenever recursion was involved: \n A single self-recursive definition was done via  . \n Multiple mutually recursive definitions were done via   and connected via  . \n  is implicitly  . That allowed us to do self-recursive definitions such as  . For mutually recursive definitions, we also need to connect those definitions via  . The following example again defines int trees, but this time with a separate type for nodes.  and   are mutually recursive, which is why they need to be defined within the same   declaration, separated via  . Parameterized variants   # Let’s recall our original definition of int trees: How can we turn this definition into a generic definition for trees whose nodes can contain any type of value? To do so, we have to introduce a variable for the type of a  ’s content.   are prefixed with apostrophes in ReasonML. For example:  . Therefore, a generic tree looks as follows: Two things are noteworthy. First, the content of a Node, which previously had the type  , now has the type  . Second, the type variable   has become a parameter of the type  .   passes that parameter on to its subtrees. That is, we can choose a different node value type for each tree, but within a tree, all node values must have the same type. We can now define a type for int trees via a type alias, by providing  ’s type parameter: Let’s use   to create a tree of strings: Due to type inference, you do not need to provide a type parameter. ReasonML automatically infers that   has the type  . The following generic function prints any kind of tree: This function uses recursion to iterate over the nodes of its parameter  . Given that   works with arbitrary types  , we need a type-specific function to convert values of type   to strings. That is what parameter   is for. This is how we can print our previously defined  : Useful standard variants   # I will briefly show two commonly used standard variants. A future blog post will give tips for using them. Type   for optional values   # In many object-oriented languages, a variable having type   means that the variable can be either   or a string value. Types that include   are called  . Nullable types are problematic in that it’s easy to work with their values while forgetting to handle  . If – unexpectedly – a   appears, you get the infamous   pointer exceptions. In ReasonML, types are never nullable. Instead, potentially missing values are handled via the following parameterized variant:  forces you to always consider the   case. ReasonML’s support for   is minimal. The definition of this variant is part of the language, but the core standard library has no utility functions for working with optional values, yet. Until they are, you can use BuckleScript’s  . Type   for error handling   #  is another standard variant for error-handling in OCaml: Until ReasonML’s core library supports it, you can use BuckleScript’s  . Example: evaluating integer expressions   # Working with trees is one of the strengths of ML-style languages. That’s why they are often used for programs involving syntax trees (interpreters, compilers, etc.). For example, the syntax checker Flow by Facebook is written in OCaml. Therefore, as a concluding example, let’s implement an evaluator for simple integer expressions. The following is a data structure for integer expressions. This is what an expression encoded with this variant looks like: And finally, this is the function the evaluates integer expressions. comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/let-scopes-reasonml.html", "title": "ReasonML:  let  bindings and scopes", "content": "ReasonML:   bindings and scopes dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” In this blog post, we look at how to introduce new variables and scopes in ReasonML. Normal   bindings   # Variables are defined as follows: Each   (variable-value pair) that is created in this manner is   – you cannot assign a different value to the variable. The norm is for the value to also be immutable, but it doesn’t have to be. Given that the binding is immutable, it is logical that you have to immediately initialize the variable. You can’t leave it uninitialized. Redefining variables   # ReasonML does not prevent you from redefining variables: This is not in conflict with the immutability of bindings: It works more like shadowing in nested scopes than like changing the value of a variable. Being able to redefine variables is especially useful in interactive command lines. Type annotations   # You can also annotate the variable with a type: Declaring types is occasionally necessary with more complicated types, but redundant with simple types. Creating new scopes via scope blocks   # The   of a variable is the syntactic construct in which it exists. Blocks enable you introduce new scopes. They start and end with curly braces ( ): The block starts in line A and ends in line B. The interior of a block has the same structure as the top level of a file: it is a sequence of expressions that are separated by semicolons. Why is there a semicolon after the closing curly brace in line B? A block is just another expression. Its value is the value of the last expression inside it. That means you can put code blocks wherever you can put expressions: Another example: This continues a common theme in ReasonML: most things are expressions. comments powered by Disqus."},
{"url": "https://2ality.com/2018/01/lists-arrays-reasonml.html", "title": "ReasonML: lists and arrays", "content": "ReasonML: lists and arrays dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” In this blog post, we look at two ReasonML data structures –   and  : \n Lists are an immutable data structure for sequences of elements that all have the same type. It is especially well-suited for being processed via pattern matching. \n Arrays are a mutable data structure with random access whose elements all have the same type. It is especially well suited for large amounts of data and whenever you need random access. \n The following table compares the two data structures. Brief excursion: type signatures   # In this blog post, you’ll see many type signatures such as this one: Type signatures may still seem cryptic to you. But you’ll profit from learning how to read them. Let’s explore what the type signature tells us about   – without us knowing what   is or does (which will be explained later). Insights: \n \n  is a function. \n \n ’s first parameter is a function from type   to type  . The leading apostrophe indicates that   and   are  : They accept any types. But once a variable has accepted a particular type, it henceforth only accepts that type. \n \n ’s second parameter is a list whose elements are of type  . \n \n ’s result is a list whose elements are of type  . \n Standard library functionality for lists and arrays   # ReasonML currently has two standard modules for lists and arrays: \n  with functions such as: \n \n  with functions such as: \n \n Each function in those modules is also available in a labeled version, via the following two modules: \n  with functions such as: \n \n  with functions such as: \n \n You can use a trick and “replace” the normal modules with their labeled versions by opening  the module  : This module has the submodules  ,  ,   and   which are aliases for the global   etc. Therefore, if you open it, you override the current implementations of   etc. Lists   # Lists in ReasonML are a typically functional data structure in that their type is defined recursively and that they are immutable. Let us explore what that means. The structure of lists   # #  is a self-recursive parameterized variant. If you were to define it yourself, this is what it would look like: The names   and   (“construct”) are historical and originated with the Lisp programming language. You nest   to create lists:  has the type parameter  . It is passed on to   and its recursive use of  . That means two things: First, the elements of   can have any type. Second, they must all have the same type. In the previous interaction with ReasonML, you can see that it automatically inferred that for  ,   is  .  is a singly-linked list. In memory, it may look like this: The two parts of a cons pair are called: \n  (or  ): It is the first value of the current list. \n  (or  ): It points to another list with the remaining elements. \n # ReasonML has special syntax for lists. The two constructors are: \n The empty list  . \n The cons pair  . \n Therefore, pattern matching works like this: This is one way of recreating the list   from the previous section: You can see that   suggests the following, more compact, syntax, which is equivalent: Let’s use pattern matching to compute the length of any list  : We recurse over the two constructors: \n An empty list has length 0. \n A non-empty list has this length: 1 plus the length of the tail. \n The type parameter   makes function   generic. But we are never interested in the type of the elements, only in the structure of the list. The following interaction uses   with various lists: # ReasonML has no built-in support for printing complex data structures. But BuckleScript lets you use JavaScript’s  . It’s best to use this function like this: Before we print the list  , we convert it to an array. But why? It leads to nicer output, because ReasonML lists are represented as nested 2-element arrays in JavaScript (an encoding of cons pairs). # The triple dot constructor is also called  . This operator lets you prepend zero or more elements before an existing list: Alas, this operator only works at the end. In JavaScript, you can use it anywhere, but in ReasonML, you can’t: ReasonML has its own operator for concatenating lists: Note that concatenating lists is comparatively slow, because you must prepend each element of the first operand to the second operand: (This implementation can be improved. We’ll see how in an upcoming blog post.) This is how you use  : This is, once again, type inference at work: \n First, ReasonML inferred the types of   etc. to be  . \n Then it inferred the type of, e.g., the first input list to be  : \n \n Then it checked that   and   had the same value for the type parameter  . \n Lastly, it used the type data of   and   to infer the type   of the result of  . \n Examples: creating lists   #  creates a list of ints:  is a keyword in ReasonML and therefore not a legal variable name. That’s why the parameter   has the underscore in its name. Let’s try out  :  creates a list filled with the value  : ReasonML uses the type of   to infer the type of the result: Examples: reading lists   # #  computes the total of all the ints in a list: #  retrieves a list element by index: We can eliminate the   expression if we use a   clause and an additional case for  . The resulting flat structure is slightly easier to read: A few things are noteworthy in this code: \n Failure is handled via the variant type  :\n \n  means we have failed. \n  means we have succeeded, with the result  . \n \n \n Index 0 refers to the current head (2nd case). \n If we reach the end of the list  , we have failed. This first case of   is triggered if either   is empty or if we reach its end before   is 0. \n The standard library has   that works like  , but it throws an exception for illegal indices, it does not use  . Examples: changing lists   # Given that lists are immutable – how do you change them? To find an answer, consider that, so far, we have seen two kinds of algorithms: \n Algorithms that read data from lists by recursing over their structures. For example:  ,  , etc. \n Algorithms that created lists by recursively building new structures. For example:  ,  , etc. \n To change a list, we combine both approaches: We create a completely new list and include data from the existing list or derive data from it, as needed. # The following is a first example of a function that changes an existing list. The first case means that we are done. The third case makes an exact copy of the existing list. The second case removes elements that are equal to  . This is   in action: #  replaces values: The first case means we are finished. The third case makes an exact copy. The second case makes a replacement. We can make   more compact via an internal helper function  : This is   in action: #  removes list elements: Let’s use  : For the last result of  , ReasonML can’t infer the element type and leaves the type parameter   unbound. Standard library functions for lists   # ReasonML’s standard library is still in flux. Therefore, We are only looking at a few highlights here. You can read up on the rest (as it currently exists) via  the documentation for  .    # Signature:  takes a list with elements of type  , applies the function   to each element and returns the results in another list. This function is a classic tool for processing lists of data.  is a version of   that passes both the current element and the element’s index to the callback  . We can use   to non-destructively update lists: The parameter   passes on all elements unchanged, except for the element at index  . This is   in use:    # This is the function’s signature:  applies the function   to each element of its positional parameter. If it returns  , the element is included in the result. If it returns  , it isn’t. It is used as follows.    # Signature:  returns   if   returns true for each element of the list. For example:  stops processing as soon as   returns  . Then the result is guaranteed to be  .   is named after the mathematical operator ∀.  is related to  : It returns   if its callbacks returns   for at least one of the elements of its list.   is named after the mathematical operator ∃.    # Signature:  converts a list of lists  , to a list, by concatenating the elements of  . That is, the following three expressions are equivalent: This is how   is used: If you are wondering about arbitrarily nested lists, recall that, in ReasonML, all elements must have the same type. Therefore, if one list element is itself a list then all elements must be lists: Let’s continue by looking at use cases for  . #  lets you filter and map at the same time. As an example, consider the trying to extract the first elements of several lists stored in a list. You could: \n First filter out empty lists (which don’t have first elements) via  . \n Then map each non-empty list to its head via  . \n Or you could use   and do both at the same time: First, we map each non-empty list to a list with its head and each empty list to an empty list. Then we flatten the result. This looks as follows: These steps are equivalent to: It is instructive to compare   to a function   that uses   to express failure: That is,   expresses “  does not have a head”: With  , we used the empty list instead of   and a one-element list instead of  . # Let’s assume that we have created a list of people and their children: If we want to collect the children in a list,   almost gives us what we want, but not quite: Alas, this is a list of lists of strings, not a list of strings. We can fix this by applying   to this nested list: Now we get the desired result: # Sometimes, you create lists where some elements are added or omitted depending on a condition (  in the following example): This is how   is used:    # Signature:  works as follows: \n Input: a list of type   (last parameter) \n Result: a value of type  \n To compute the result,   depends on its parameter, the function  . It calls   for each element   of its input list:  is what has already been computed. The first intermediate result is  . The last   is the result of  . Let’s look at a concrete example. # We have already encountered the function   which computes the total of a list of ints. Let’s implement that function via  : To understand how   works, consider the following expression: To compute the result  , the following steps are taken:  is the result of  . # Another way of looking at   is that takes a binary operator   and turns it into an n-ary operator for lists. An example in mathematics for going from binary to n-ary is the binary operator   also existing as an n-ary version (the operator Σ).   went from   to Σ. It could also be written like this: I find   easiest to understand if it works in this mode – with an   that is   (order of parameters doesn’t matter). But there is much you can do with it – read on for an example. # The function   uses it to find a value in a list: Converting lists to arrays via     # Signature:  call   for every element of its list. The arguments are the index of the element and the element. It returns  , which means that anything useful that   does, it does via side effects. The following function uses   to fill an array. It does so as a side effect, by writing to an array  :  is a required parameter, because   needs it (why is explained later).  in action: Arrays   # Arrays are much like lists: all of their elements have the same type and they are accessed by position. But they are also different: \n Arrays are mutable. Lists are immutable. \n Arrays can’t be resized. With a list, you can efficiently prepend elements and retrieve tails. (BuckleScript lets you resize arrays, but you lose cross-platform compatibility if you do so.) \n Arrays provide fast indexed access. Lists are processed via recursion and pattern matching. \n Creating arrays   # The following subsections explain three common ways of creating arrays. # # Signature: The first parameter specifies the length of the result. The second parameter specifies the value it is to be filled with. Why is the second parameter mandatory? The result of   must only contain values of type  . ReasonML has no  , so you must pick a member of type  , manually. This is how   works: # Signature: The first parameter specifies the length of the result. The function   maps an index to an initial value at that index. For example: Getting the length of an array   #  returns the length of an array: Reading and writing array elements   # This is how you read and write array elements: Pattern matching and arrays   # Pattern-matching arrays is similar to matching tuples, not to matching lists. Let’s start with tuples and lists (we can ignore the exhaustiveness warnings, because we are working with fixed data): We’ll destructure an array next: Similar to tuples, the pattern must have the same length as the data (that’s what the exception is about): Converting between lists and arrays   # This is how you convert between lists and arrays: \n From array to list (module  ): \n \n From list to array (module  ): \n \n Sometimes you have data in an array that would be easier to process in a list. Then you can convert it to a list (and convert it back to an array afterwards, should that be needed). Processing arrays   # The standard library is still in flux. Therefore, I’ll only demonstrate a few highlights for now. #  for arrays works similar to the same function for lists: #  is also similar to its list version: This is how   is used: Once again, we have used   to go from a binary operation ( ) to an n-ary operation ( ). In addition to  , we also use the integer constant  . Both are part of module   and therefore available without qualification.  is a binary function that works for most types:  is the lowest possible int value (its exact value depends on the platform that you are using): #  works like  , but it starts with the last element. Its type signature is: One use case for this function is converting an array to a list. That list has to be constructed as follows (i.e., you have to start with the last array element): The function looks like this: This is   in action: # All array functions return arrays that have the same length as the input arrays. Therefore, if you want to remove elements, you have to take a detour via lists:  in use: comments powered by Disqus."},
{"url": "https://2ality.com/2018/01/records-reasonml.html", "title": "ReasonML: records", "content": "ReasonML: records dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” This blog post examines how ReasonML’s records work. What are records?   # A record is similar to a tuple: it has a fixed size and each of its parts can have a different type and is accessed directly. However, where the parts of a tuple (its  ) are accessed by position, the parts of a record (its  ) are accessed by name. By default, records are immutable. Basic use   # Defining record types   # Before you can create a record, you must define a type for it. For example: We have defined the record type   which has two fields,   and  . Names of fields must start with lowercase letters. Within the same scope, no two records should have the same field name. The reason for this restrictive rule is that field names are used to determine the type of a record. In order to achieve this task, each field name is associated with exactly one record type. It is possible to use the same field name in more than one record, but then usability suffers: The last record type with a field name “wins” w.r.t. type inference. As a consequence, using the other record types becomes more complicated. So I prefer to pretend reusing field names isn’t possible. We’ll examine how to work around this limitation later on. # Is it possible to nest record types? For example, can we do the following? No we can’t. We’d get a syntax error. This is how to properly define  : With  , field name and field value are the same. Then you can abbreviate both as just  . That is called  : Creating records from scratch   # This is how you create a record from scratch: Note how the field names were used to infer that   has the type  . Punning works here, too: Accessing field values   # Field values are accessed via the dot ( ) operator: Non-destructive updates of records   # Records are immutable. To change the value of a field   of a record  , we must create a new record  .   has a new value, all other fields of   have the same values as in  . That is achieved via the following syntax: The triple dots ( ) are called the  . They must come first and can be used at most once. However, you can update more than one field (not just a single field  ). This is an example of using the spread operator: Pattern matching   # All the usual pattern matching mechanisms work with records, too. For example: This is what destructuring via   looks like: You can use punning: Destructuring of parameters works, too: # During pattern matching, you can omit all fields you are not interested in, by default. For example: For  , we are not interested in the field   and only mention field  . However, it’s better to be explicit about omitting fields: The underscore after   tells ReasonML: we are ignoring all remaining fields. Why is it better to be explicit? Because now you can let ReasonML warn you about missing field names, by adding the following entry to  : The initial version now triggers the following warning: I recommend to go even further and make missing fields an error (compilation doesn’t finish): Consult the BuckleScript manual for  more information on configuring warnings . Checking for missing fields is especially important for code that uses all current fields: If you were to add another field to   (say,  ) then you want ReasonML to warn you about  , so that you can update it. Recursive record types   # Variants were the first example that we have seen of recursively defined types. You can use records in recursive definitions, too. For example: The variant   recursively relies on the definition of the record type  . This is how you create elements of type  : Parameterized record types   # In ReasonML, types can be parameterized by type variables. You can use those type variables when defining record types. For example, if we want trees to contain arbitrary values, not just ints, we make the type of the field   polymorphic (line A): Records in other modules   # Each record is defined within a scope (e.g. a module). Its field names exist at the top level of that scope. While that helps with type inference, it makes using field names more complicated than in many other languages. Let’s see how various record-related mechanisms are affected if we put   into another module,  : Creating records from other modules   # If we try to create a record of type   as if that type were in the same scope, we fail: The reason is that   and   don’t exist as names within the current scope, they only exist within module  . One way to fix this is by qualifying at least one of the field names: Another way to fix this is by qualifying the whole record. It is interesting how ReasonML reports the inferred type – both the type and the first field name are qualified: Lastly, you can also open   and therefore import   and   into the current scope. Accessing fields from other modules   # If you don’t open  , you can’t use unqualified names to access fields: The warning goes away if you qualify the field name  : Locally opening   works, too: Pattern matching and records from other modules   # With pattern matching, you face the same issue as with accessing fields normally – you can’t use the field names of   without qualifying them: If we qualify  , everything is OK: Alas, qualifying the pattern doesn’t work: We can locally open   for the whole   binding. However, it isn’t an expression, which prevents us from wrapping it in parentheses. We must additionally wrap it in a code block (curly braces): Using the same field name in multiple records   # I initially promised that we’d be able to use the same field name in multiple records. The trick for doing so is putting each record in a separate module. For example, here are two record type,   and   that both have the field  . But they reside in separate modules and the name clash is not a problem: FAQ: records   # Is there a way to dynamically specify the name of a field?   # In JavaScript, there are two ways in which you can access a field (called   in JavaScript): In ReasonML, field names are always static. JavaScript objects play two roles: they are both records and dictionaries. In ReasonML, use records if you need a record, use Maps if you need a dictionary. comments powered by Disqus."},
{"url": "https://2ality.com/2018/01/functors-reasonml.html", "title": "ReasonML: functors", "content": "ReasonML: functors dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” Functors are mappings from modules to modules. This blog post explains how they work and why they are useful. The code of the examples is available on GitHub, in  repository  .  Functors are an advanced topic. You can get by initially without knowing how to write them. I explain the basics of   them whenever that is required elsewhere. What are functors?   #  is a term from category theory, where it refers to a mapping between categories. In ReasonML, there are two ways of looking at a functor: \n A function whose parameters are modules and whose result is a module. \n A module (the result) that is parameterized (configured) via modules (the parameters). \n You can only define a functor as a submodule (it can’t be the top-level element in a file). But that is not a problem, because you usually want to deliver a functor inside a module, where it can sit next to the interfaces for its parameters and (optionally) its result. The syntax of functors looks as follows. The functor   has as parameters one or more modules   etc. Those modules must be typed via interfaces   etc. The result type   (another interface) is optional. The body of a functor has the same syntax as a normal module, but it can refer to the parameters and their contents. A first functor   # Defining the functor     # As our first example, we define a functor   that exports a function   that repeats its parameter, a string. The parameter of the functor configures how often the string is repeated. Before we can define the functor, we need to define an interface   for its parameter: This is what the functor looks like:  is a functor: Its parameter   is a module, its result (in curly braces) is also a module.  is a relatively boring ReasonML function. The only new aspect is the default value for  , which comes from the parameter module  . An interface for the result of     #  does not currently define the type of its result. That means that ReasonML infers that type. If we want more control, we can define an interface   for the result: Afterwards, we just need to add   to the definition of  : Using     # Next, we use   in a separate file,  . First, we define a module for the parameter of the functor: The type   is not needed, as long as   has the exact same structure as that interface. But it makes it immediately clear, what the purpose of   is. Now we are ready to use the functor   to create a module for us: The following code calls  , which works as expected: Instead of defining module   separately, we could have also inlined it: The structure of the module     # The way we have structured module   is a common pattern for using functors. It has the following parts: \n : the functor. \n One or more interfaces for the parameters of   (in our case,  ). \n : an interface for the result of  . \n That is,   packages the functor   and everything it needs. Functors for data structures   # One common use case for functors is implementing data structures: \n \n The parameters of the functor specify the elements managed by the data structure. Due to the parameters being modules, you can not only specify the types of the elements, but also helper functions that the data structure may need for managing them. \n \n \n The result of the functor is a module that is tailor-made for the specified elements. \n \n For example,  the data structure   (which we’ll look at in more detail later) must be able to compare its elements. Therefore, the functor for sets has a parameter with the following interface:  is the type of the elements of the set,   is used to compare those elements.   is similar to the type variable   of the polymorphic type  . : a first version of a functor for printable pairs   # Let’s implement a very simple data structure: pairs with arbitrary components that can be   (converted to string). In order to print pairs, we must be able to print their components. Which is why components must be specified via the following interface. We once again use the name   for the functor that produces the modules with the actual data structures: This functor has two parameters:   specifies the first component of a printable pair,   specifies the second component. The modules returned by   have the following parts: \n  is the type of the data structure supported by this functor. Notice how it refers to the functor parameters   and  . \n  is the function for creating values of type  . \n  is a function for working with printable pairs. It converts a printable pair to a string. \n # Let’s use the functor   to create a printable pair whose first component is a string and whose second component is an int. First, we need to define the arguments for the functor: Next, we use the functor to create a module  : Lastly, we create and print a pair: # The current implementation has one flaw, we can create elements of type   without using  : To prevent that, we need to make the type   abstract, via an interface: This is how we define   to have the type  : Note that   is the type of the whole functor. : an interface just for the result   # It is more common to define an interface only for the result of a functor (not for the complete functor, as we did before). That way, you can reuse that interface for other purposes. For the ongoing example, such an interface would look as follows. Now we can’t refer to the parameters   and   of the functor, anymore. Therefore, we need to introduce two new types   and  , which we need to define the type of  . This function previously had the following type: How do we connect   and   with   and  , then? We do so via so-called  , equations that modify interfaces. They are used like this: The following two equations are sharing constraints: The   hints at those constraints changing the interface  . And they do, indeed. The interface of the result of   is now: There is one more thing we can improve:   and   are redundant. It would be better if the result interface referred to   and   directly (like it did when we had an interface for the complete functor). That is done via  . : destructive substitutions   #  work much like sharing constraints. However: \n A sharing constraint   provides more information for  . \n A destructive substitution   replaces all occurrences of   inside   with  . \n This is what   looks like if we use destructive substitutions: The destructive substitutions remove   and   from  . Therefore, we don’t need to define them in  ’s body, anymore, and can always directly refer to   and  . Due to the destructive substitutions, the definition inside   matches what the interface requires. The result signature of   is now: Example: using the functor     # The standard module   for sets of values follows the conventions I have already explained: \n  is the functor that produces the actual module for handling sets. \n  is the interface for  ’s parameter: \n \n  is the interface for  ’s result. \n This is how you create and use a module for string sets: Conveniently, ReasonML’s standard library comes with a module   that works as a parameter for  , because it has both   and  . Therefore, we could have also written: Functors for extending modules   # Functors can also be used to extend existing modules with functionality. Used in this manner, they are similar to multiple inheritance and mixins (abstract subclasses). As an example, let’s extend an existing module that can only add single elements to its data structure with a function for adding all elements of a given data structure.   is a functor for doing so: The function   uses   to iterate over the elements of   and add them to  , one at a time.   is always bound to what has already been computed (first  , then the result of adding the first   to  , etc.). In this case, we let ReasonML infer the type of the result of   and don’t provide an interface for it. If we were to do that it would have the name   and have the abstract type   (for the parameters and the result of  ). It would be used like this: From the source code, we can deduce what   needs and collect that in the interface  :  for sets of strings   # We take   that have have previously defined and use it to create  : The new module   contains both the module   and the result of applying the functor   to the module  . We are doing multiple inheritance between modules, if you will. This is   in action: Could we simplify  ?   # At the moment, we need to combine the base module   with the extension   to create  : What if we could create it as follows? There are two reasons why we don’t do that. First, we want to keep the parameter for   and the base of   separate. We’ll need that separation when we use   for lists. Second, there is no way to implement   so that it extends its parameter. In theory, that would look like this: In practice, including   only includes what is inside the interface  . That’s generally not enough. Data structures: polymorphic data types vs. functors   # There are two kinds of data structures provided by ReasonML’s standard library: \n  and others are implemented as polymorphic data types whose element types are specified via type variables. \n  and others are implemented via functors. The element types are specified via modules. \n  for lists of strings   # Alas,   works best with data structures implemented via functors. If we want to use it for lists, we must bind the type variable of   to a concrete type (in this case,  ). That leads to the following parameter for  : [This is the simplest solution I could come up with – suggestions for improvements welcome.] Afterwards, this is how we create and use a module that supports all list operations plus  : Material   # \n Chap. “ The module system ” in the OCaml manual \n Chap. “ Functors ” in “Real World OCaml” \n “ Modules ” (OCaml.org tutorial) \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/modules-reasonml.html", "title": "ReasonML: basic modules", "content": "ReasonML: basic modules dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” In this blog post, we explore how modules work in ReasonML. Installing the demo repository   # The demo repository for this blog post is available on GitHub:  . To install it, download it and: That’s all you need to do – no global installs necessary. If you want more support for ReasonML than just running its code, consult “ Getting started with ReasonML ”. Your first ReasonML program   # This is where your first ReasonML program is located: In ReasonML, each file whose name has the extension is   is a module. The names of modules start with capital letters and are camel-cased. File names define the names of their modules, so they follow the same rules. Programs are just modules that you run from a command line.  looks as follows: This code may look a bit weird, so let me explain: We are executing the two lines inside the curly braces and assigning their result to the pattern  . That is, no new variables are created, but the pattern ensures that the result is  . The type of  ,  , is similar to   in C-style languages. Note that we are not defining a function, we are immediately executing   and  . To compile this code, you have two options (look at   for more scripts to run): \n Compile everything, once:  \n Watch all files and incrementally compile only files that change:  \n Therefore, our next step is (run in a separate terminal window or execute the last step in the background): Sitting next to  , there is now a file  . You can run this file as follows. Other versions of     # As an alternative to our approach (which is a common OCaml convention), we could have also simply put the two lines into the global scope: And we could have defined a function   that we then call: Two simple modules   # Let’s continue with a module   that is used by another module,  : Module   looks like this: Module   looks like this: As you can see, in ReasonML, you can use modules by simply mentioning their names. They are found anywhere within the current project. Submodules   # You can also nest modules. So this works, too: Externally, you can access   via  . Let’s nest further: Controlling how values are exported from modules   # By default, every module, type and value of a module is exported. If you want to hide some of these exports, you must use  . Additionally, interfaces support   (whose internals are hidden). Interface files   # You can control how much you export via so-called  . For a module defined by a file  , you put the interface in a file  . For example: If, e.g., you omit   from the interface file, it won’t be exported. The interface of a module is also called its  . If an interface file exists, then docblock comments must be put there. Otherwise, you put them into the   file. Thankfully, we don’t have to write interfaces by hand, we can generate them from modules. How is described  in the BuckleScript documentation . For  , I did it via: Defining interfaces for submodules   # Let’s assume,   doesn’t reside in its own file, but exists as a submodule: How do we define an interface for this module? We have two options. First, we can define and name an interface via  : That interface becomes the type of module  : Second, we can also inline the interface: Abstract types: hiding internals   # You can use interfaces to hide the details of types. Let’s start with a module   that lets you put strings “into” logs. It implements logs via strings and completely exposes this implementation detail by using strings directly: From this code, it isn’t clear that   and   actually return logs. This is how you use  . Note how convenient the pipe operator ( ) is in this case: The first step in improving   is by introducing a type for logs. The convention, borrowed from OCaml, is to use the name   for the main type supported by a module. For example:  In line A we have defined   to be simply an alias for strings. Aliases are convenient in that you can start simple and add more features later. However, the alias forces us to annotate the results of   and   (which would otherwise have the return type  ). The full interface file looks as follows. We can replace line A with the following code and   becomes   – its details are hidden. That means that we can easily change our minds in the future and, e.g., implement it via an array. Conveniently, we don’t have to change  , it still works with the new module. Importing values from modules   # There are several ways in which you can import values from modules. Importing via qualified names   # We have already seen that you can automatically import a value exported by a module if you qualify the value’s name with the module’s name. For example, in the following code we import  ,   and   from module  : Opening modules globally   # You can omit the qualifier “ ” if you open   “globally” (within the scope of the current module): To avoid name clashes, this operation is not used very often. Most modules, such as  , are used via qualifications:  ,  , etc. Global opening can also be used to opt into different implementations for standard modules. For example, module   might have a submodule  . Then   will override the standard   module. Opening modules locally   # We can minimize the risk of name clashes, while still getting the convenience of an open module, by opening   locally. We do that by prefixing a parenthesized expression with   (i.e., we are qualifying that expression). For example: # Conveniently, operators are also just functions in ReasonML. That enables us to temporarily override built-in operators. For example, we may not like having to use operators with dots for floating point math: Then we can override the nicer   operators via a module  : Whether or not you actually should do this in production code is debatable. Including modules   # Another way of importing a module is to   it. Then all of its exports are added to the exports of the current module. This is similar to inheritance between classes in object-oriented programming. In the following example, module   is an extension of module  . It has the new function  , in addition to all functions of  .  comes from BuckleScript’s standard library and is not explained here. You can include as many modules as you want, not just one. Including interfaces   # Interfaces are included as follows (  extends  ): Similarly to modules, you can include more than one interface. Let’s create an interface for module  . Alas, we can’t include the interface of module   by name, because it doesn’t have one. We can, however, refer to it indirectly, via its module (line A): Renaming imports   # You can’t really rename imports, but you can alias them. This is how you alias modules: This is how you alias values inside modules: Namespacing modules   # In large projects, ReasonML’s way of identifying modules can become problematic. Since it has a single global module namespace, there can easily be name clashes. Say, two modules called   in different directories. One technique is to use  . Take, for example, the following project: There are two modules   in this project whose names are only distinct because they were prefixed with   and  , respectively: To make naming less unwieldy, there is one   per namespace. The first one looks like this:  is used as follows: The global open lets us use   without a prefix. There are two more use cases for this technique: \n You can override modules with it, even modules from the standard library. For example,   could contain a custom   implementation, which would override the built-in   module inside  : \n \n You can create nested modules while keeping submodules in separate files. For example, in addition to opening  , you can also access   via  , because it is nested inside  . Of course,   works, too, but is discouraged, because it is an implementation detail. \n The latter technique is used by BuckleScript for  ,  , etc., in file   (which is in OCaml syntax): Namespace modules in OCaml   # Namespace modules are used extensively in OCaml at Jane Street. They call them  , but I prefer the name  , because it doesn’t clash with the npm term  . Source of this section: “ Better namespaces through module aliases ” by Yaron Minsky for Jane Street Tech Blog. Exploring the standard library   # There are two big caveats attached to ReasonML’s standard library: \n It is currently work in progress. \n Its naming style for values inside modules will change from snake case (  and  ) to camel case (  and  ). \n At the moment, much functionality is still missing. \n API docs   # ReasonML’s standard library is split: most of the core ReasonML API works on both native and JavaScript (via BuckleScript). If you compile to JavaScript, you need to use BuckleScript’s API in two cases: \n Functionality that is completely missing from ReasonML’s API. Examples include support for dates, which you get via BuckleScript’s  . \n ReasonML API functionality that is not supported by BuckleScript. Examples include modules   (due to JavaScript’s strings being different from ReasonML’s native ones) and   (with native APIs). \n This is the documentation for the two APIs: \n ReasonML API docs \n BuckleScript API docs \n Module     # Module   contains the core standard library and is always automatically opened for each module. It contains functionality such as the operators  ,  ,   and functions such as   and  . If something in this module is ever overridden, you can still access it explicitly via, e.g.,  . If there is a file   in your project, it overrides the built-in module and is opened instead. Standard functions with labeled parameters   # The following modules exist in two versions: an older one, where functions have only positional parameters and a newer one, where functions also have labeled parameters. \n ,  \n ,  \n ,  \n ,  \n As an example, consider: Two more modules provide labeled functions: \n Module   has the submodules  ,  ,  ,  , which are aliases to   etc. In your modules, you can open   to get a labeled version of   by default. \n Module   has three submodules with labeled functions:  ,   and  . \n Installing libraries   # For now, JavaScript is the preferred platform for ReasonML. Therefore, the preferred way of installing libraries is via npm. This works as follows. As an example, assume we want to install the BuckleScript bindings for Jest (which include Jest itself). The relevant npm package is called  . First, we need to install the package. Inside  , you have: Second, we need to add the package to  : Afterwards, we can use module   with   etc. More information on installing libraries: \n BuckleScript’s build system is explained in Chap. “ Build system support ” of the BuckleScript Manual. \n ReasonML’s manual explains  how to find ReasonML libraries on npm .\n \n Useful npm keywords include:  ,  ,  \n \n \n Further reading   # \n Creating your own ReasonML projects: Sect. “ Template projects ” in “ Getting started with ReasonML ”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/07/test262.html", "title": "test262 – ensuring that JavaScript implementations comply with the ECMAScript specification", "content": "test262 – ensuring that JavaScript implementations comply with the ECMAScript specification dev javascript jslang test262 http://test262.ecmascript.org/ \n    The test suite has been created by the Ecma Technical Committee 39, with committee members including Mozilla, Microsoft, Google and many others helping to make the suite a resource that helps developers provide fine-tuned feedback on support for the standard.\n     \n    Over 10,000 tests cover the specification today. Test suites are an integral part of the process needed to create interoperable cross-platforms standards.\n Base64 test262: Industry JavaScript Standards Test Available Press release 30 June 2011 - ISO/IEC and Ecma International ratify “ES5.1”, the latest ECMAScript specification of Ecma International A brief history of ECMAScript versions (including Harmony and ES.next) comments powered by Disqus."},
{"url": "https://2ality.com/2018/01/polymorphic-variants-reasonml.html", "title": "ReasonML: polymorphic variant types", "content": "ReasonML: polymorphic variant types dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” In this blog post, we look at  , which are a more flexible version of  normal variants . But that flexibility also makes them more complicated. [Aside: this blog post was challenging to write and is based various resources on the web. Corrections and tips welcome!] What are polymorphic variants?   # Polymorphic variants are similar to normal variants. The biggest difference is that constructors are not tied to types anymore; they exist independently. That makes polymorphic variants more versatile and leads to interesting consequences for the type system. Some of those consequences are negatives – they are the price you pay for the versatility. Let’s start with the following normal variant and then turn it into a polymorphic variant. The polymorphic version of   is defined like this: The constructors of a polymorphic variant must be wrapped in square brackets and their names must start with backticks followed by either lowercase letters or uppercase letters: As usual, types such as   must start with lowercase letters. Polymorphic constructors exist on their own   # You can only use a non-polymorphic constructor if it is part of a non-polymorphic variant: In contrast, you can just use polymorphic constructors. There is no need to define them beforehand: Note that   has an interesting type:  . We’ll examine what that means later. Polymorphic constructors existing on their own, enables using the same constructor more than once: In contrast, with normal variants, you should avoid multiple variants within the same scope having the same constructor. You can even use the same polymorphic constructor with different arities and/or type parameters: Extending polymorphic variants   # When defining a polymorphic variant, you can extend an existing variant. In the following example,   extends  : As you can see, case matters here:   being lowercased indicates that its constructors are inserted. Extending multiple variants is also possible: The namespace of polymorphic constructors is global   # The names of non-polymorphic constructors are part of their scopes (e.g. their modules), whereas the namespace of polymorphic constructors is global. You can see that in the following example: In the last line, the parameter of   is created via a constructor that is not from  ’s scope. Due to the global namespace of polymorphic constructors, the parameter is compatible with the type  . Type compatibility   # How does ReasonML determine if the type of an actual parameter (function call) is compatible with the type of the formal parameter (function definition)? Let’s look at examples. We start by creating a type and a function whose single parameter is of that type. Next, we create a new type   that has the same polymorphic constructors as   and call   with a value whose type is  : Normally, the type of the formal parameter   and the actual parameter   have to be the same. But with polymorphic variants, it’s enough if your types have the same constructors. If, however, the type of an actual parameter   has less constructors, then ReasonML won’t let you do the function call: The reason is that   makes precise demands on what it needs:   the constructors  ,   and  . Therefore, the type   is not enough. # Interestingly, the following does work: Why? Because ReasonML didn’t infer a fixed type for  , it inferred the    . This constraint is a so-called   and means: “all types that have at least the constructor  ”. This constraint is compatible with  , the type of  . # We can also use constraints as the types of parameters. For example, the following call to   fails, because the parameter’s type,  , has too many constructors: This time, we call   and specify the type   of the parameter directly (no intermediate   binding). We can make the function call work without changing the function call, by only changing  : Now   has a lower bound and accepts all types that have at least the given three constructors. You can also define constraints by referring to variants. For example, the following definition of   is basically equivalent to the previous one. We’ll take a deeper look at type constraints later on. Writing extensible code with polymorphic variants   # One key benefit of polymorphic variants is that code becomes more extensible. The type and code we want to extend   # As an example, take the following type definitions for shapes. They are polymorphic versions of the example in  the preceding blog post . Based on these type definitions, we can write a function that computes the area of a shape: Extending  : a failing first attempt   # Let’s say we want to extend   with one more shape – triangles. How would we do that? We can simply define a new type   that reuses the existing polymorphic constructors   and  , and adds the constructor  : Now we also need to extend  . The following function is our first attempt at writing that extension: Alas, this code doesn’t work: In lines A and B,  ’s type   is not compatible with the type   of  ’s parameter. We get the following error message: Fixing   via an   clause   # Thankfully, we can fix the problem by using the   clause for the last two cases: How does   help us? With polymorphic variants, it picks the most general type possible. That is: \n  has the type  \n  has the type  \n Both of these types are compatible with  , the type of  ’s parameter. The final solution   # There is one more improvement we can make. Given the following variant: Then the following two patterns are equivalent: If we use the hash for the type  , we get: Let’s use   with two shapes: We have therefore successfully extended both the type   and the function   operating on it. Best practices: normal variants vs. polymorphic variants   # In general, you should prefer normal variants over polymorphic variants, because they are slightly more efficient and enable stricter type checking. Quoting the OCaml manual: [...] polymorphic variants, while being type-safe, result in a weaker type discipline. That is, core language variants do actually much more than ensuring type-safety, they also check that you use only declared constructors, that all constructors present in a data-structure are compatible, and they enforce typing constraints to their parameters. However, polymorphic variants have a few clear strengths. If any of those matter in a given situation, you should use polymorphic variants: \n \n Reuse: A constructor (possibly along with code processing it) is useful for more than one variant. Constructors for colors fall into this category, for example. \n \n \n Decoupling: A constructor is used in multiple locations, but you don’t want those locations to depend on a single module where the constructor is defined. Instead, you can simply use the constructor without defining it. \n \n \n Extensibility: You expect a variant to be extended later on. Similar to how   was an extension of  , earlier in this post. \n \n \n Conciseness: Due to the global namespace of polymorphic constructors, you can use them without qualifying them or opening their modules (see next subsection). \n \n \n Use constructors without prior definitions: You can use polymorphic constructors without defining them beforehand via variants. That is occasionally convenient for throw-away types that are only used in single locations. \n \n Thankfully, it is relatively easy to move to a polymorphic variant from a normal variant if the need arises. Conciseness: normal variants vs. polymorphic variants   # Let’s compare the conciseness of normal variants and polymorphic variants. For the normal variant  , you need to qualify   in line A (or open its module): For the polymorphic variant  , no qualification is necessary for   in line A: Not having to qualify didn’t really have much of an effect in this example, but it matters if you use the constructors many times. Preventing typos with polymorphic variants   # One issue with polymorphic variants is that you get less warnings about typos, because you can use constructors without defining them. For example, in the following code,   is misspelled as   in line A: You do get a warning if you add a type annotation for the parameter  : If you return polymorphic variant values from a function, you can specify the return type of that function, too. But that also adds weight to your code, so be sure you really benefit. If you type all parameters, many if not most problems should be caught. (Advanced)   # All of the following sections cover advanced topics. Type constraints for type variables   # Before we can take a closer look at constraints for polymorphic variants, we first need to understand general constraints for type variables (of which the former is a special case). At the end of a type definition, there can be one or more  . These have the following syntax: These constraints are used to   the type variables in the preceding type definition. This is a simple example: How does ReasonML handle constraints? Before we can look into that, let’s first understand   and how it builds on pattern matching. Pattern matching goes in one direction: One term without variables is used to fill in the variables in another term. In the following example,   is the term without variables and   is the term with variables:  is pattern matching that works in both directions: both terms can have variables, and variables on both sides are filled in. As an example, consider: ReasonML simplified as much as possible: the original complex constraint with variables on both sides of the equals sign was converted to two simple constraints with variables only on the left-hand sides. This is an example where things can be simplified so much that no constraint is needed, anymore: Type constraints for polymorphic variants   # The type constraints we have seen earlier in this blog post are actually just type constraints that are specific to polymorphic variants. For example, the following two expressions are equivalent: On the other hand, the following two type expressions are also equivalent (but you can’t use   in   bindings and parameter definitions): That is, with all the polymorphic variant constraints that we have used so far, there was always an implicit (hidden) type variable. We can see that if we try to use such a constraint to define a type  : We fix this as follows. Note the final type computed by ReasonML. Upper and lower bounds for polymorphic variants   # For the remainder of this blog post, we refer to   as simply   or  . Type constraints consist of either or both of the following: \n \n A lower bound: indicates what elements a type must contain at least. For example:   accepts all types that include the constructors   and  . In other words: taken as a set, the constraint accepts all types that are supersets of it. \n \n \n An upper bound: indicates what elements a type must contain at most. For example:   accepts the following types:  ,  ,  . \n \n You can use type constraints for: \n Type definitions \n  bindings \n Parameter definitions \n For the latter two, you must use the short form (without  ). What do type constraints match?   # Lower bounds   # Let’s examine how the lower bound   works by using it as the type of a function parameter  : Values of type   and   are accepted: However, values of type   are not accepted, because that type doesn’t contain both of the constructors of the constraint. Upper bounds   # The following interaction experiments with the upper bound  : Inferred type constraints   # If you use polymorphic constructors, ReasonML infers type constraints for you. Let’s look at a few examples. Lower bounds   # The value   has the inferred type   which is compatible with all types that have at least the constructor  . With a tuple, you get two separate inferred type constraints: On the other hand, the elements of a list must all have the same type, which is why the two inferred constraints are merged: This list is accepted whenever the expected type is a list with elements whose type includes at least the constructors   and  . If you try to use the same constructor with parameters of different types, you get an error, because ReasonML can’t merge the two inferred types: Upper bounds   # So far, we have only seen lower bounds being inferred. In the following example, ReasonML infers an upper bound for the parameter  : Due to the   expression,   can handle at most the two constructors   and  . The inferred type becomes more complex if   returns its parameter: The type parameter   is used to express that the type of the parameter and the type of the result are the same. Things change if we use   clauses, because they decouple the input type from the output type: The limits of ReasonML’s type system   # Some things go beyond the capabilities of ReasonML’s type system: The return type of   is: “the type of   or the type  ”. However, there is no way to express that via a constraint. More complex constraints   # Type constraints can become quite complex. Let’s start with two simple functions: Both inferred types include upper bounds, caused by   statements. Let’s use the same variable   as a parameter for both functions: To type  , ReasonML merges the following two types: The result contains the following constructor. That stands for “a constructor  ” whose type parameter has both type   and type  . Such a constructor doesn’t exist, meaning that you can’t call  , because there is no value that is compatible with the type of its parameter. Type inference uses unification (which is bi-directional)   # When ReasonML computes types via inference, and determines that two types  ,   must be equal (e.g. the type of an actual parameter and the type of a formal parameter), it uses unification to solve the equation  . I’ll demonstrate that via several functions. Each of those functions returns its only parameter. The type   it specifies for the parameter is different from the type   it specifies for the result. ReasonML will try to unify   and  , allowing us to observe that unification is bi-directional. Two constraints   # If both parameter type and result type are constraints, ReasonML tries to merge the constraints. The unified type remains polymorphic – it contains the type variable  . The type variable is used to express: “whatever the type of   eventually is, the result has the same type”. One monomorphic type, one constraint   # If one of the two types is monomorphic (has no type variables) and the other one a constraint then the constraint is only used to check the monomorphic type. Due to unification, both types end up being monomorphic. Two monomorphic types   # If both types are monomorphic then they must have the same constructors. Monomorphic type vs. constraint   # One more demonstration of the difference between monomorphic type and constraint. Consider the following two functions: Let’s compare the two functions: \n  has a parameter whose type   is monomorphic (it has no type variables). \n  has a parameter whose type   is a constraint. The definition itself doesn’t look polymorphic, but the computed signature does – there is now a type variable,  . \n Let’s see what happens if we call these functions with arguments whose type is a new polymorphic variant that has the same constructors as  : With  , the type of  , and therefore the result, is fixed. That is, it stays  : We were only able to call  , because   and   are the same. In contrast, with  , the type of   is polymorphic and more flexible. During unification,   is bound to  . The result of the function call has type   (the value of  ). Material   # Polymorphic variants and how to use them: \n Sect. “ Polymorphic variants ” in the OCaml manual. \n Daniel Bünzli’s tips for when to use polymorphic variants  (on Stack Overflow) \n “ Code reuse through polymorphic variants ” by Jacques Garrigue (2000). \n Type variable constraints: \n What can be done with the “constraint” keyword in OCaml?  (on Stack Overflow) \n Why does the constraint clause exist in type definitions?  (on reddit) \n Chapter “ Polymorphic Variants ” in “OCaml Book” by Hongbo Zhang \n Sect. “ Type definitions ” in the OCaml manual. \n The semantics of polymorphic variants: \n Simple Type Inference for Structural Polymorphism  [PDF] by Jacques Garrigue (2002). \n Row polymorphism  [PDF] by Leo White (2015). \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/08/array-prototype-performance.html", "title": "JavaScript performance: Array.prototype versus []", "content": "JavaScript performance: Array.prototype versus [] dev javascript jslang \n  Inspired by a comment from Kevin Roberts, I’ve added a third way of accessing generic methods, and a conclusion.\n \n\n Explanations     \n  Some methods are  . While they are directly available to instances of their prototype, they can also be borrowed by other instances. To borrow a generic method, one invokes one of the following two methods on it:\n \n     \n     \n \nExample: invoking   generically, on the array-like   object.\n \n    is often used as a shortcut for  . That is, you access a prototype property via an instance.\n \n     Pro: More compact. \n     Con: Does not really describe one’s intent. You are not trying to invoke an instance method, you are borrowing a function from the prototype. \n     Con: Slightly slower (see below). \n Timing several ways of accessing generic methods Conclusion comments powered by Disqus."},
{"url": "https://2ality.com/2011/07/array-from.html", "title": "ECMAScript.next: Array.from() and Array.of()", "content": "ECMAScript.next: Array.from() and Array.of() esnext dev javascript jslang ECMAScript 6’s new array methods \nOn July 9th, Brendan Eich  announced  that Rick Waldron had prototyped [1] two new methods for  ECMAScript.next :   and Array.of(). Both methods are also useful in current JavaScript.\n\n \n\n Array.from() \n     Array-like objects: Some objects in JavaScript are  , they have indexed access and a   property like arrays, but none of the array methods. Array-like objects include the special variable   (giving indexed access to all arguments that were passed to a function) and most DOM results. Not having the standard array methods is especially unfortunate under ECMAScript 5, which has goodies such as  . The canonical way of converting an array-like object to an array can be seen above.   simply makes this functionality available as a built-in method.\n     \n     Generic methods: Some methods are  . While they are directly available to instances of their prototype, they can also be borrowed by other instances. To borrow a generic method, one invokes one of the following two methods on it:\n         \n             \n             \n         \n        The borrowing instance is the first argument and becomes the value of  . Generic methods have to be written so that they require   to only have a minimal set of methods. For example, most generic array methods only need   to provide   and indexed access.   is generic and allows one to turn any part of an array-like object into an array.\n         \n        Example: invoking   generically, on the array-like   object.\n \n        Interaction:\n \n     \n     [] as a shortcut:   is often used as a shortcut for Array.prototype.foo. That is, you access a prototype property via an instance. I normally prefer not to make this shortcut, because it is less explicit and less performant [3] (though many JavaScript engines optimize the access to   so it is not much slower). Thus, I would have written this method as follows:\n \n     \n Array.of() Related reading Array goodies from twitter rap with David Herman  [refers to a  tweet  wrapping things up] A brief history of ECMAScript versions (including Harmony and ES.next) JavaScript performance: Array.prototype versus [] comments powered by Disqus."},
{"url": "https://2ality.com/2011/07/js-properties.html", "title": "JavaScript properties: inheritance and enumerability", "content": "JavaScript properties: inheritance and enumerability dev javascript jslang Properties in JavaScript \nThis post examines how inheritance and enumerability affect operations on properties in JavaScript.\n \n\n Kinds of properties \n      An object can point to its  , via an internal property. The   is the sequence of objects that starts with an object, continues with its prototype, the prototype’s prototype, etc. Many operations consider all properties in a prototype chain, some operations only consider the   properties that are stored in the first object of the prototype chain. \n      You can hide properties from some operations by making them non-enumerable. Enumerability is one of the three attributes of a property: writability, enumerability, configurability  [1] . \n Accessing properties \n        Get property names:\n         \n     \n        Get/detect property names:\n \n        Get property value:\n \n        Set property values, delete properties (only affects the first object in the prototype chain):\n \n     \n        Get property names:\n \n     \n        Detect property name:\n \n        Read property value:\n \n     Using an object as a map [2] Enumerability and the standard library Best practices [3] \n \n \n     If you use an object as a map, only work with own properties, e.g. via the ECMAScript 5 method   or via  . \n     Iterating over objects and arrays: see  [4] . \n \n     When adding properties to built-in prototypes  [5] , use   and similar methods to make them non-enumerable. That will give you some protection against breaking   loops in legacy code. \n     With your own types, you don’t have to be as careful, because you can expect new code to ignore inherited properties when using objects as maps. \n \n     ECMAScript.next will have a  dedicated type  for maps. We thus won’t have to (ab)use objects as maps, any more. \n Related reading \n John Resig - ECMAScript 5 Objects and Properties The pitfalls of using objects as maps in JavaScript es5-shim: use ECMAScript 5 in older browsers Iterating over arrays and objects in JavaScript “ Everything is Permitted: Extending Built-ins ” [video]. Talk by Andrew Dupont at JSConf 2011. Inspired this post. Thanks to Brendan Eich for the pointer. comments powered by Disqus."},
{"url": "https://2ality.com/2011/08/json-api.html", "title": "JavaScript’s JSON API", "content": "JavaScript’s JSON API dev javascript jslang Overview \n Compound: objects of JSON data, arrays of JSON data\n Atomic: strings, numbers, booleans,  \n \n Strings must always be double-quoted, string literals such as   are illegal.\n Property names must be double-quoted.\n \n     Douglas Crockford discovered JSON in 2001 [1]. He gave it a name and put up a specification at  json.org . Quote:\n         \n     \n     The JSON specification has been translated to many human languages and there are now libraries for many programming languages that support parsing and generating JSON. \n     Initially, Crockford wanted JSON to have the name “JavaScript Markup Language” [1], but the acronym JSML was already taken by the “ JSpeech Markup Language ”. \n Grammar source The JSON API Node visitors \n      iterates over a value before stringifying it. \n      iterates over the result of parsing a JSON text. \n \n     : the parent of the current node. The root value has a special parent, an object whose only property has the empty string as its name and the root as its value. \n     : a key where the current node is located inside its parent.   is always a string. It is the empty string if there is no parent. \n     : the current node. \n \n  The special root node comes first, in a prefix iteration (parent before children). The last values are the results of the function calls.\n \n    > JSON.parse('{\"a\":1, \"b\":2}', nodeVisitor)\n    {\"a\":1,\"b\":2}#\"a\"#1\n    {\"a\":1,\"b\":2}#\"b\"#2\n    {\"\":{\"a\":1,\"b\":2}}#\"\"#{\"a\":1,\"b\":2}\n     \n \n    > JSON.parse('\"hello\"', nodeVisitor)\n    {\"\":\"hello\"}#\"\"#\"hello\"\n     \n JSON.stringify(value, [replacer], [space]) \n     : There are two ways this parameter can influence stringification:\n         \n             Node visitor (see above): replaces nodes in the tree of values. Example:\n \n                Interaction:\n \n             \n             Whitelist of property names: hides all properties (of non-array objects) that are not in the list. Example:\n \n                returns\n \n             \n         \n     \n\n     : Without this parameter, the result of   is a single line of text.\n \n        With it, newlines are inserted and each level of nesting via arrays and objects increases indentation. There are two ways to specify how to indent:\n         \n             Number: Multiply the number by the level of indentation and indent the line by as many spaces. Numbers smaller that 0 are interpreted as 0, numbers larger than 10 are interpreted as 10.\n \n             \n             String: To indent, repeat the given string once for each level of indentation. Only the first 10 characters of the string are used.\n \n             \n         \n     \n \n Root position: the empty string.\n Property value: the property name.\n Array elemen: the element index as a string.\n JSON.parse(text, [reviver]) Related reading Video: Douglas Crockford — The JSON Saga  [2009-07-02] comments powered by Disqus."},
{"url": "https://2ality.com/2011/08/javascript-media-type.html", "title": "What is the correct media type for JavaScript source code?", "content": "What is the correct media type for JavaScript source code? dev javascript clientjs Brendan Eich The correct JavaScript media type RFC 4329 \n         \n         \n     machineghost Stack Overflow Gezim Hoxha Uses of the media type (internet) media type \n     When serving code via a web server. \n     As the value of an optional attribute of the script tag:\n \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/currying-vs-part-eval.html", "title": "Currying versus partial application (with JavaScript code)", "content": "Currying versus partial application (with JavaScript code) dev javascript advancedjs jslang Currying Partial application \n  Binding the first argument of function   to   produces the function  . Compare their definitions to see that we have simply filled in the first argument.\n \n  The function   partially applies binary functions. It has the signature\n more details \n Currying versus partial application \n     Currying   produces nested unary (1-ary) functions. The transformed function is still largely the same as the original. \n     Partial application produces functions of arbitrary arity. The transformed function is different from the original – it needs less arguments. \n Related reading Partial application  on Wikipedia [partial source of this post] comments powered by Disqus."},
{"url": "https://2ality.com/2011/08/universal-modules.html", "title": "How to write and unit-test universal JavaScript modules (browser, Node.js)", "content": "How to write and unit-test universal JavaScript modules (browser, Node.js) dev javascript jsmodules jslang Bridging the module gap between Node.js and browsers \nNode.js has a very nice  module system  that is easy to understand, yet distinguishes between the   of a module and things that should be private to it. This post explains how the code of a Node.js module can be modified so that it works on both Node.js and web browsers. It also explains how to unit-test such code.\n \n\n Writing a universal module Node.js modules Making Node.js code universal \n     Enabling strict mode: The first line enables   [1] under ECMAScript 5 and does nothing under older versions of JavaScript.\n     \n     An immediately invoked function definition (IIFE): We define a function and immediately invoke it [2]. This serves two purposes:\n         \n             It keeps non-exported data private in browsers, where Node.js does not do this for us. \n             It conditionally creates the variable   which exists on Node.js, but must be created in a browser. Creating a new scope with a new variable   in it is the only way of doing this, you cannot add a variable to an existing scope if it isn’t there, yet. That is, you cannot do the following:\n \n                Reason: JavaScript is   – a variable always exists inside the complete (inner-most) enclosing function. Additionally, variable declarations are   – moved to the beginning of the function. Thus, the   declaration (but not the assignment!) at (*) is moved before the   statement and   will always be undefined when the check is performed. Note that the code would work without hoisting, but not with block-scoping, because then the   declared at (*) would only exist inside the then-block.\n             \n         \n     \n     : Does the variable   exist? \n     : At the global level,   refers to the global object. Therefore, the assignment creates the global variable   (which holds the module in a browser). \n Using a universal module Unit-testing a universal module Node.js: unit-testing via the module assert assert Browser: unit-testing via jQuery’s QUnit QUnit Related reading JavaScript’s strict mode: a summary JavaScript variable scoping and its pitfalls Modules and namespaces in JavaScript pattern for module targeting browser and nodejs .  comments powered by Disqus."},
{"url": "https://2ality.com/2011/08/jsdoc-intro.html", "title": "An introduction to JSDoc", "content": "An introduction to JSDoc dev javascript jslang jstools Speaking JavaScript JSDoc: Generating API Documentation Tweet Michael Mathews 2ality.com/2011/08/jsdoc-intro.html \nAs a tool, JSDoc takes JavaScript code with special   comments and produces HTML documentation for it. For example: Given the following code.\n Quick start \n     Download the  latest jsdoc_toolkit . Unpack the archive into, say,  . \n     Make the script   executable and tell it where to look for the JSDoc binary and the template (which controls what the result looks like).\n \n        Now you can move the script anywhere you want to, e.g. a bin/ directory. For the purpose of this demonstration, we don’t move the script.\n     \n     Use   on a directory of JavaScript files:\n \n         \n             Input:   – a directory of JavaScript files (see below for an example). \n             Output:   – where to write the generated files. \n         \n     \n Introduction: What is JSDoc? \n  In order to output anything, JSDoc always needs a  , a mix of JavaScript and specially marked-up HTML that tells it how to translate the parsed documentation to HTML. JSDoc comes with a built-in template, but there are others that you can download [3].\n\n Terminology and conventions of JSDoc \n     Doclet: JSDoc calls its comments   which clashes with JavaDoc terminology where such comments are called   and a   is similar to a JSDoc template, but written in Java. \n     Variable: The term   in JSDoc often refers to all documentable entities which include global variables, object properties, and inner members. \n     Instance properties: In JavaScript one typically puts methods into a prototype to share them with all instances of a class, while fields (non-function-valued properties) are put into each instance. JSDoc conflates shared properties and per-instance properties and calls them  . \n     Class properties, static properties: are properties of classes, usually of constructor functions. For example,   is a class property of  . \n     Inner members: An inner member is data nested inside a function. Most relevant for documentation is instance-private data nested inside a constructor function.\n \n     \n Syntax \n     JSDoc comment: is a JavaScript block comment whose first character is an asterisk. This creates the illusion that the token   starts such a comment. \n     Tags: Comments are structured by starting lines with  , keywords that are prefixed with an @ symbol.   is an example above. \n     HTML: You can freely use HTML in JSDoc comments; for example, <tt> to display a word in a monospaced font. \n     Type annotations: You can document the type of a value by putting the type name in braces after the appropriate tags. Variations:\n         \n     \n     Name paths: are used to refer to variables inside JSDoc comments. The syntax of such paths is as follows.\n \n     \n A word on types \n     Primitive types: boolean, number, string. The values   and   are also considered primitive. \n     Object types: All other types are  , including arrays and functions. \n \n     The wrapper type of   is  . \n     The wrapper type of   is  . \n     The wrapper type of   is  . \n \n     Primitive value  : via  .\n \n        Compare: an instance of the wrapper type is an object.\n \n     \n     Object value  : via  . Example:\n \n     \n Basic tags \n     : marks a JSDoc comment that describes the whole file. Example:\n \n     \n     : Who has written the variable being documented? \n     : indicates that the variable is not supported, any more. It is a good practice to document what to use instead. \n     : contains a code example, illustrating how the given entity should be used.\n \n     \n \n     : points to a related resource.\n \n     \n     : works like  , but can be used inside other tags. \n     : a resource that the documented entity needs. The resource description is either a name path or a natural language description. \n \n     : indicates the version of the documented entity. Example:\n \n     \n     : indicates since which version the documented entity has been available. Example:\n \n     \n Documenting functions and methods \n     : describes the parameter whose name is  . Type and description are optional. Examples:\n \n        Advanced features:\n         \n             Optional parameter:  \n \n             \n             Optional parameter with default value:\n \n             \n         \n     \n     : describes the return value of the function or method. Either type or description can be omitted. \n     : describes an exception that might be thrown during the execution of the function or method. Either type or description can be omitted. \n Inline type information (“inline doc comments”) Documenting variables and fields \n     : What type does the documented variable have? Example:\n \n        This tag can also be used to document the return type of functions, but   is preferable in this case.\n     \n\n     : A flag that indicates that the documented variable has a constant value. \n\n     : What is the default value of a variable? Example:\n \n     \n     : Document an instance property in the class comment. Example:\n \n        Without this tag, instance properties are documented as follows.\n \n        Which one of those styles to use is a matter of taste.   does introduce redundancies, though.\n     \n Documenting classes \n      You must mark a constructor function, otherwise it will not be documented as a class. That is, capitalization alone does not mark a function as a constructor.\n \n          is a synonym for  , but it also allows you to describe the class – as opposed to the function setting up an instance (see tag documentation below for an example).\n     \n\n      You need two markers. First, you need to tell JSDoc that a given variable holds a class. Second, you need to mark an object literal as defining a class. The latter is done via the   tag.\n \n     \n\n      If one of the methods in an object literal performs the task of a constructor (setting up instance data, [8]), you need to mark it as such so that fields are found by JSDoc. Then the documentation of the class moves to that method.\n \n     \n \n     : marks a function as a constructor. \n     : marks a variable as a class or a function as a constructor. Can be used in a constructor comment to separate the description of the constructor (first line below) from the description of the class (second line below).\n \n     \n     : marks a method in an object literal as taking up the duties of a constructor. That is, setting up instance data. In such a case, the class must be documented there. Works in tandem with  . \n     : specifies to which class the following object literal contributes. There are two ways of contributing.\n         \n              – the object literal contributes instance properties to  . \n              – the object literal contributes class properties to  . \n         \n     \n Inheritance, namespacing \n     : indicates that the documented class is the subclass of another one. Example:\n \n     \n     : a synonym for  . \n     : One can use objects to simulate namespaces in JavaScript. This tag marks such objects. Example:\n \n     \n Meta-tags Rarely used tags \n     : ignore a variable. Note that variables without   comments are ignored, anyway. \n     : A variable is just a reference to somewhere else; it is documented there. Example:\n \n     \n     : Provide a description, the same as all of the text before the first tag.\n     \n \n     : override the parsed name and use the given name, instead. \n     : the documented variable is a member of the specified object. \n Related reading jsdoc-toolkit - A documentation generator for JavaScript : JSDoc homepage on Google Code. Includes a link to the downloads. JSDoc wiki : the official documentation of JSDoc and source of this post. JSDoc wiki –  TemplateGallery : lists available JSDoc templates. JSDoc wiki –  TagReference : a handy cheat-sheet for JSDoc tags. Lightweight JavaScript inheritance APIs Modules and namespaces in JavaScript JavaScript values: not everything is an object Prototypes as classes – an introduction to JavaScript inheritance comments powered by Disqus."},
{"url": "https://2ality.com/2011/08/spreading.html", "title": "Spreading arrays into arguments in JavaScript", "content": "Spreading arrays into arguments in JavaScript dev javascript jslang \nSometimes, one needs to   the elements of an array, to use them as the arguments of a function call. JavaScript allows you to do that via  , but that does not work for constructor invocations. This post explains spreading and how to make it work in the presence of the new operator. \n \n\n Spreading spread operator Spreading function arguments Spreading constructor arguments A manual work-around more details \n  We want to hand an array to  . So we again use   to turn an array into arguments for a function call.\n \n     1st argument:   has the value  , as in  , above. \n     2nd argument: The arguments for   are created by prepending   to the array  . \n A library method their suggestion A seemingly simpler solution comments powered by Disqus."},
{"url": "https://2ality.com/2017/09/native-esm-node.html", "title": "Using ES modules natively in Node.js", "content": "Using ES modules natively in Node.js dev javascript esnext jsmodules nodejs \n  Warning: This blog post is outdated! Consult “ ECMAScript modules in Node.js: the new plan ” for the latest information. \n  Major rewrite of Sect. “Checklist: things to watch out for”. New FAQ entries. \n Starting with version 8.5.0, Node.js supports ES modules natively, behind a command line option. Most of the credit for this new functionality goes to  Bradley Farias . This blog post explains the details. Demo   # The demo repository has the following structure: : : Running the demo: Checklist: things to watch out for   # Module specifiers of ES modules: \n All module specifiers are now URLs – which is new for Node.js. \n Peer files: are best referred to via relative paths with the file extension  . That way, specifiers remain compatible with the web. If you omit the extension, path resolution works similarly to CJS modules; if the same file exists as both   and  , the former wins.\n \n Example:  \n \n \n Libraries: are best referred to via bare paths without file extensions. That is most compatible with how libraries are delivered at the moment.\n \n Example:  \n How to best make npm-installed libraries available in browsers (without using a bundler) remains to be seen. One possibility is to introduce RequireJS-style configuration data mapping bare paths to real paths. At the moment, bare paths as module specifiers are illegal in browsers. \n \n \n Features of ES modules: \n \n No dynamic importing of modules. But  the dynamic   operator  is being worked on and should be available relatively soon. \n \n \n No metavariables such as   and  . However, there is a proposal to bring similar functionality to ES modules – “ ” by Domenic Denicola: \n \n \n Interoperability with CJS modules: \n \n ES modules can import CJS modules, but they always only have a default export – the value of  . Letting a CJS module make named exports (e.g. via a pragma at the beginning of the file) is on the roadmap, but may take a while. If you can help,  please do so . \n \n \n \n You can’t use   inside ES modules. The main reasons for this are: \n \n Path resolution works slightly differently: ESM does not support   and  . And its specifiers always being URLs also leads to a few minor differences. \n ES modules are always loaded asynchronously, which ensures maximal compatibility with the web. This style of loading doesn’t mix well with synchronously loading CJS modules via  . \n Forbidding sync module loading also keeps the door open for top-level   in ES modules (a feature that is currently under consideration). \n \n \n \n CJS modules can’t   ES modules. Similarly to what was mentioned in the previous item, synchronously loading asynchronous modules is problematic. You’ll probably be able to use the Promise-based   operator to load ES modules, though. \n \n ES modules on older versions of Node.js   # If you want to use ES modules on Node.js versions prior to 8.5.0, take a look at   by John-David Dalton. Tip: if you don’t switch on any of the unlockables (extra features), you’ll stay 100% compatible with native ES modules on Node.js. FAQ   # When will ES modules be available without the command line option?   # The current plan is to make ES modules available by default in Node.js 10 LTS. Do   files work with browsers?   # They do, but they have to be served with the correct Media Type (  or  ). Work on standardizing   and upgrading tools and libraries is  ongoing . Is the file extension   required for ES modules?   # Yes it is – on Node.js. Browsers don’t care about file extensions, only about Media Types (see previous question). Why is the file extension   required on Node.js?   # Node.js has to be able to detect whether a file contains a CJS module or an ES module. Several alternatives were considered before one of them was chosen. You can read about the alternatives in  a separate blog post . Each one has pros and cons. In my opinion,   was the right choice (but you can make up your own mind if you read the linked blog post). Further reading   # More information on ES modules in Node.js and browsers: \n “ Making transpiled ES modules more spec-compliant ” [using ES modules natively vs. transpiling them via Babel] \n “ Module specifiers: what’s new with ES modules? ” [Why  ? How are module specifiers resolved? Etc.] \n “ Modules ” [in-depth chapter on ES modules in “Exploring ES6”] \n Upcoming ECMAScript proposals: \n ES proposal:   – dynamically importing ES modules \n ES proposal:   – module metadata \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/11/proxy-method-calls.html", "title": "Tracing method calls via Proxies", "content": "Tracing method calls via Proxies dev javascript js proxies In this blog post, I explain how you can trace method calls via ECMAScript Proxies. The techniques I show are relevant whenever you want to intercept and forward method calls via Proxies. Required knowledge: You should be loosely familiar with Proxies. If not, please consult chapter “ Metaprogramming with proxies ” in “Exploring ES6”. The object to be traced   # For our examples, we’ll use the following class. Tracing “get” operations   # Let’s start by tracing whenever someone reads properties. The following tool function lets us do that. We can try it out on an instance of  : Why use  ?   # Why are we using the first one of the following two expressions and not the second one? Answer: The difference matters with getters. Then you want to invoke the getter that is stored in  , but you want its   to be set to  . That allows you to continue with tracing, because   still points to the proxy. More on that at the end of this blog post. Tracing method calls   # Tracing method calls is more complicated, because Proxies don’t have traps for method calls, but instead translate them to a “get” and a function call. In principle,   and   are two different kinds of dot operators. The second one is an abbreviation for: As a consequence, you must trace method calls by returning appropriate values from “get” traps: If the property value is a function, we return a function that traces and forwards both   and the arguments (line A). Otherwise, we simply return the target’s property value. The following code traces a call to  .  remains the Proxy   # The way we have set up things ensures that   continues to point at the Proxy. Even if a traced method calls other traced methods. And even if a traced method returns  . You can see that in the following example – both method calls   and   are being traced. comments powered by Disqus."},
{"url": "https://2ality.com/2017/11/import-meta.html", "title": "ES proposal:  import.meta  – module metadata", "content": "ES proposal:   – module metadata dev javascript esnext es proposal jsmodules The proposal “ ” by Domenic Denicola is currently at  stage 3 . This blog post explains how it works. Module metadata   # When it comes to working with a module, you are normally interested in what’s inside it. But occasionally, you need information   the module – its metadata. One example of module metadata for Node.js modules is the global variable   which contains the path of the directory in which the current module is stored. The proposal introduces the pseudo-property   which holds an object with metadata for the current module. Let’s look at uses cases for module metadata. Use case: Path to module   # In Node.js, you can store data supporting a CommonJS module next to that module and get to it as follows: The key piece is the module metadata   in line A. This is how you can achieve something similar in a cross-platform way (on Node.js, you need a polyfill for  the   API ). Note the metaproperty   (line A), which contains the URL of the current module. Use case: Is the current module the execution entry point?   # On Node.js, a CommonJS module can play two roles: \n If the module is imported, it acts as a library. \n If the module is executed, it acts as an executable. For example, it could provide supporting tool functionality or run a demo. \n You can handle the two roles as follows. At the moment, no concrete metaproperty has been proposed, but   would work: Use case: Parameterizing modules via HTML attributes   # Browsers will have the metaproperty   that gives modules access to the script element that loaded them. HTML: Non-module scripts get this information via  . The object in     # As of now: \n The object in   will be extensible (you are able to add properties). \n All properties will be writable, configurable and enumerable (you are able to change or delete them). \n The rationale for keeping everything mutable is to enable polyfilling of upcoming features. Note that, by default, module metadata can only be accessed by the module. That is, unless the module passes the metadata object elsewhere, it is local. What platforms support  ?   # \n Chrome:  64+ \n Safari:  Safari Technology Preview Release 42 \n Edge: ? \n Firefox: ? \n Node.js:  pending V8 implementation \n Babel:  parsable \n Further reading   # \n Blog post “ Using ES modules natively in Node.js ” \n Blog post “ ES proposal:   – dynamically importing ES modules ” \n Chapter “ Modules ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/11/getting-started-reasonml.html", "title": "Getting started with ReasonML", "content": "Getting started with ReasonML dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” In this blog post, I give tips for getting started with the programming language  ReasonML . Installation   # There are two things to install: \n : Installs BuckleScript and enables you to compile ReasonML to JavaScript. The installation is described in  the ReasonML Guide . \n : Needed to support ReasonML in editors, but also contains various tools, including the interactive ReasonML command line  . The installation is described in  the ReasonML Guide . Editor support is provided by two parts:\n \n On one hand, a so-called  language server  provides services for working with ReasonML code. \n On the other hand, editor plugins and similar extension mechanisms communicate with the server to provide the actual support. \n \n \n Quickly trying out ReasonML   # The ReasonML online playground   # The ReasonML website contains  an online playground  that is very useful for seeing how the language works and what the corresponding JavaScript and OCaml code is. It can also convert from OCaml to ReasonML (more on that later). The playground’s examples give you a first taste of the language. , the interactive ReasonML command line   #  is an interactive command line for ReasonML and started via   from a shell. Once it runs, interacting with it looks as follows. You can already see that everything has a static type in ReasonML. Don’t forget the semicolon at the end – it triggers evaluation! You can quit   via Ctrl-D or via  Template projects   # There are two template projects to get you started. They are created via   (which is part of  ): \n Node.js code : \n \n Web development (React) : \n \n Important tip: converting OCaml to ReasonML   # Given that most material relevant for ReasonML uses OCaml’s syntax, it’s very useful to be able to convert from OCaml’s syntax to ReasonML’s. There are two ways of doing so: \n The online playground “ Try Reason ”. \n The tool   (“ReasonML format”) that is part of  . Get documentation via  \n More documentation on ReasonML   # In addition to this series of blog posts, what material is there for learning ReasonML? \n The ReasonML Guide  is very well written, but brief. It covers most of the language.\n \n The API documentation  is accessible from the Guide and describes ReasonML’s preliminary standard library. \n BuckleScript cheat sheet \n \n \n OCaml’s manual  complements ReasonML’s documentation, but is also terse. \n Real World OCaml  (by Yaron Minsky, Jason Hickey, Anil Madhavapeddy) gives a more comprehensive introduction to OCaml. \n Awesome ReasonML  is a page with ReasonML resources. \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/08/less-building-in-web-dev.html", "title": "Easing the pain of building in JavaScript", "content": "Easing the pain of building in JavaScript dev javascript esnext jstools In principle, JavaScript is a very dynamic and interactive programming language. However, that has changed significantly in recent years. Now, modern web development requires extensive build and compilation steps. That is unfortunate for two reasons. First, it makes development less pleasant. Second, it makes web development harder to learn. This blog post covers ideas and tools for easing some of the pain of building. Static vs. dynamic   # Quick refresher – in the context of this blog post: \n Static means: at compile time, before deployment. \n Dynamic means: at runtime, after deployment. \n Benefits of building   # The reason why there are so many build steps in modern web development is that they bring lots of benefits. They have advanced the status quo. These are a few examples: \n Linting and static type checking signals errors early in development. \n Tree-shaking leads to less code being deployed. \n Source-to-source compliation via, e.g., Babel and TypeScript lets you use modern language features on older engines. \n Vision: less building   # So how do we get both: the benefits of building and a quick turn-around during development? These are a few ideas: \n Writing code: perform static checks incrementally, as people are editing code, and show errors inside IDEs. \n Running code during development:\n \n Development servers can perform incremental building. For example, files could be compiled on the fly via Babel. \n Live-reloading (the browser reloads whenever files are changed) also makes development more interactive. \n \n \n Deployment: perform as many build steps as are needed to minimize and optimize the code to deploy. \n Some tools offer a hybrid approach: compile dynamically at development time, compile statically for deployment. For example: \n Vue can compile its templates dynamically. \n Polymer’s  lit-html  explores templating via tagged template literals. These could be compiled statically for deployment. \n babel-standalone  can dynamically transpile JavaScript in browsers. Michael Jackson  has used it  together with unpkg.com to transpile React apps, Angular apps and others. \n Macros (e.g. as supported in JavaScript via  Sweet.js ) are another way of supporting non-native syntax. Macros can be applied dynamically and statically. \n Conclusion   # Having ES modules in browsers already helps with building less. In the future, I’m looking forward to ideas for making web development not just more powerful, but also more interactive and dynamic. For teaching web development to non-programmers, I’d like to introduce features incrementally: First HTML, then CSS, then JavaScript, then the DOM, then frameworks, etc. It helps if build tools can be introduced as late as possible, if newcomers can be productive without them (or if they become as invisible as possible). comments powered by Disqus."},
{"url": "https://2ality.com/2017/11/currying-in-js.html", "title": "Currying is not idiomatic in JavaScript", "content": "Currying is not idiomatic in JavaScript dev javascript  I worded a few things more carefully, to make it clear that I don’t hate functional programming (I’m a fan).  I added subsections to Sect. “ Currying is in conflict with some of JavaScript’s foundations ”. In this blog post I explain why, in my opinion, currying is in conflict with some of JavaScript’s foundations. Recommended reading if you are not sure what   and   mean (and what the difference is between them): “ Currying versus partial application ” How do you mean “not idiomatic”?   # The slightly agressive title may lead some people to misread the tone of this blog post. So let me be clear: I love functional programming. My main points are: \n A few core JavaScript features are in conflict with currying. \n There are alternatives to currying (especially an upcoming proposal) that, in my opinion, are superior when it comes to performing partial application. These are not in conflict. \n One of JavaScript’s best traits is how many different styles of programming it can accomodate. Thus: if you like currying a lot and none of the mentioned alternatives work for you, feel free to use currying. If you do so, be consistent within your own code. And be prepared for your code being slightly at odds with the rest of the ecosystem. Currying   # Currying is a popular technique in functional programming. It helps with partial application. The idea is as follows: If you don’t provide all parameters for a function, it returns a function whose input are the remaining parameters and whose output is the result of the original function. If, for example, you wanted to add 2 to all elements of an Array and had a binary function  , you could do it as follows: As an aside, functional programming languages with automatic currying often have plus operators that can be used this way. You have two options for implementing   in a way that supports currying. Simple currying   # ES6 arrow functions  make it easy to write curried functions manually: That means that you have to invoke   as follows: This is currying: a function with an arity greater than one is transformed into a nested series of functions. Most functional programming languages with automatic currying have syntax where there is no difference between   and  . Overloaded currying   # Some libraries provide functions that are overloaded. Each of those overloaded functions behaves differently depending on the number of parameters you provide: \n If you only provide a single parameter, it works as if it were curried. \n If you provide all parameters, it works like a normal function call. \n If you provide more than one parameter (and not all parameters), it returns a function that is bound to those parameters. \n This style of currying can be implemented as follows. Alternatively, one could write a helper function that transforms normal functions to this style. Summary   # Currying is a technique for transforming functions so that they help with partial application. Currying is in conflict with some of JavaScript’s foundations   # If you want currying in JavaScript, you therefore have two options: \n Use real currying.\n \n Pro: easier to type statically. \n Con: non-idiomatic syntax for function calls. \n \n \n Use overloaded currying.\n \n Pro: nicer syntax. \n Con: harder to get static types right. \n \n \n Then you are faced with a few disadvantages that I’ll explain next. I’m assuming that you’ll transform some built-in functions and methods to suit your style of currying. Note: not all of these disadvantages are equally important. Named parameters   # In JavaScript, named parameters can be simulated via object literals (details: section “ Simulating named parameters ” in “Exploring ES6”). I like this way of handling parameters a lot, because it leads to code that is much more self-descriptive. Not all JavaScript libraries for currying support named parameters. Note: languages that support both built-in currying and named/labeled parameters don’t have this issue. For example: ReasonML. It’s not clear what’s a function call and what isn’t   # Normally, if you put parentheses behind a function, you execute that function. With currying, you have to know the arity of a function   in order to know whether   calls that function or returns a partially applied version of it. The same syntax triggers two different operations. Compare that to two alternatives for doing partial application (described later): You can see clearly that   has the arity 2 and that one more value still needs to be provided. With named parameters, you lose even more information if you curry. Compare: Static type systems (TypeScript, Flow, ...) prevent you from making mistakes here, but the alternatives are still easier to read. Currying clashes with parameter default values   # Parameter default values  tell functions what values to use if parameters are omitted. For example: In this case, parameter default values are not terribly useful. But in general, they enable you to add parameters transparently – without breaking existing callers. This technique is especially useful with named parameters and I have used it a few times to keep functions and method as generally applicable as possible. With parameter default values, omitting a parameter means using the default. With currying, omitting a parameter means returning a partially applied function. Therefore, the two are in conflict. Currying-friendly functions   # With currying, it’s important that the parameters of functions start with options and end with the main operand. JavaScript functions tend not to do that. For example, the signature of   is: That makes it impossible to prefill the radix like this: What alternatives are there for partial application?   # When it comes to currying, what people usually really want is partial application. Let’s take the following example of overloaded currying and explore alternatives.   .  arrow functions.   an upcoming proposal for partial application . Note: the syntax is still in flux and the proposal is at an early stage. The nice thing about this proposal is that it works well with arbitrary signatures and has a very descriptive syntax. Further reading   # \n Currying versus partial application (with JavaScript code) \n Arrow functions vs.  \n Uncurrying “this” in JavaScript \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/11/about-reasonml.html", "title": "What is ReasonML?", "content": "What is ReasonML? dev reasonml  Read the book “ Exploring ReasonML ”, instead (free online). This blog post gives a brief high-level explanation of Facebook’s new programming language,  ReasonML . Blog posts in this series   # \n What is ReasonML [this blog post] \n Getting started with ReasonML \n What is planned for ReasonML? \n \n Basic values and types \n  bindings and scopes \n Pattern matching: destructuring,  ,   expressions \n Functions \n Basic modules \n Variant types \n Polymorphic variant types \n Lists and arrays \n Records \n Functors \n \n External and internal iteration \n What is ReasonML?   # ReasonML is a new object-functional programming language created at Facebook. In essence, it is a new C-like syntax for the programming language OCaml. The new syntax is intended to make interoperation with JavaScript and adoption by JavaScript programmers easier. Additionally, it removes idiosyncrasies of OCaml’s syntax. ReasonML also supports JSX (the syntax for HTML templates inside JavaScript used by Facebook’s React framework). Due to ReasonML being based on OCaml, many people use the two names interchangeably. The following diagram shows how ReasonML fits into the OCaml ecosystem. At the moment, ReasonML’s default compilation target is JavaScript (browsers and Node.js). This is what ReasonML code looks like (example taken from  ReasonML’s online playground ). The benefits of OCaml   # ReasonML’s foundation, OCaml, brings the following benefits: \n It is an established language (created in 1996) that has proven itself in many projects. Facebook itself is using it in several projects (e.g. Flow). \n Its core is a functional programming language with a full-featured type system. But it also supports object-orientation and mutable state. \n It can be compiled to either bytecode, fast native code or JavaScript. \n Compilation to JavaScript is fast. Quoting the blog post “ Messenger.com Now 50% Converted to Reason ”:\n Full rebuild of the Reason part of the codebase is ~2s (a few hundreds of files), incremental build (the norm) is <100ms on average. The BuckleScript author estimates that the build system should scale to a few hundred thousands files in the current condition. \n \n Improving OCaml   # The ReasonML team also aims to improve the OCaml ecosystem: \n Better tooling (testing, documentation, editor support, etc.). \n Better interoperation with JavaScript. The ReasonML-to-JavaScript compiler is already very fast and produces relatively readable code. \n Better standard library (there is a fair amount of competition in this space in OCaml, without a clear winner). Here, the goal is also to use camel-cased names ( ,  ). OCaml uses snake-casing for lowercase names ( ) and camel-casing for uppercase names ( ). \n Conclusion   # ReasonML feels much like what you’d get if you cleaned up JavaScript and turned it into a statically typed functional programming language. I’m ambivalent about JSX in ReasonML – it has pros and cons. I’m glad that ReasonML doesn’t reinvent the wheel and is strictly based on the established OCaml. OCaml’s pragmatism means that you don’t get some of the more fancy functional features (that, e.g., Haskell has), but it also leads to fast compilation, efficient code and decent error messages. comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/alternate-this.html", "title": "A different way of understanding  this  in JavaScript", "content": "A different way of understanding   in JavaScript dev javascript In this blog post, I take a different approach to explaining   in JavaScript: I pretend that arrow functions are the real functions and ordinary functions a special construct for methods. I think it makes   easier to understand – give it a try. Two kinds of functions   # In this post, we focus on two different kinds of functions: \n Ordinary functions:  \n Arrow functions:  \n Ordinary functions   # An ordinary function is created as follows. Each ordinary function has the implicit parameter   that is always filled in when it is called. In other words, the following two expressions are equivalent (in strict mode). If you nest ordinary functions,   is shadowed: Inside  ,   does not refer to the   of  , because   has its own  . If   were an explicit parameter, the code would look as follows: Note that   shadowing the   of   is also how variables work in nested scopes: Due to ordinary functions always having the implicit parameter  , a better name for them would have been “methods”. Arrow functions   # An arrow function is created as follows (I’m using a block body so that it looks similar to a function definition): If you nest an arrow function inside an ordinary function,   is not shadowed: Due to how arrow functions behave, I also occasionally call them “real functions”. They are similar to functions in most programming languages – much more so than ordinary functions. Note that the   of an arrow function can not be influenced via  . Or in any other way – it is always determined by the scope surrounding the arrow function when it was created. For example: Ordinary functions as methods   # An ordinary function becomes a method if it is the value of an object property: One way of accessing the properties of an object is via the dot operator ( ). This operator has two different modes: \n Getting and setting properties:  \n Calling methods:  \n The latter is equivalent to: You can see that, once again,   is always filled in when ordinary functions are invoked. JavaScript has special, convenient, syntax for defining methods: Common pitfalls   # Let’s take a look at common pitfalls, through the lens of what we have just learned. Pitfall: accessing   in callbacks (Promises)   # Consider the following Promise-based code where we log  , once the asynchronous function   is finished. The problem is that   in line A fails, because   doesn’t refer to the   of   – it is shadowed by the   of the callback. In other words: we have used an ordinary function when we should have used an arrow function. If we do so, everything works well: Pitfall: accessing   in callbacks ( )   # Similarly, the following code fails in line A, because the callback shadows the   of method  . Again, we can fix it by using an arrow function: Pitfall: using methods as callbacks   # The following class is for a UI component. In line (A),   registers an event handler for clicks. Alas, if that handler is ever triggered, you’ll get an error: Why? In line A, we have used the normal dot operator, not the special method call dot operator. Therefore, the function stored in   becomes the handler. That is, roughly the following things happen. As a consequence,   fails in line B. So how can we fix  ? The problem is that the dot operator for calling a method is not simply a combination of first reading the property and then calling the result. It does more. Therefore, when we extract a method, we need to provide the missing piece ourselves and fill in a fixed value for  , via the function method   (line A): Now,   is fixed and won’t be changed via normal function calls. Rules for staying safe   # The easiest way of avoiding problems with   is by avoiding ordinary functions and always using either method definitions or arrow functions. However, I do like function declarations syntactically. Hoisting is also occasionally useful. You can use those safely if you don’t refer to   inside them. There is  an ESLint rule  that helps you with that. Don’t use   as if it were a parameter   # Some APIs provide parameter-like information via  . I don’t like that, because it prevents you from using arrow functions and goes against the initially mentioned easy rule of thumb. Let’s look at an example: the function   passes an API object to its callback via  . This function could easily be rewritten: Further reading   # \n Blog post “ JavaScript’s this: how it works, where it can trip you up ” [an in-depth look at  ] \n Chapter “ Callable entities in ECMAScript 6 ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/future-reasonml.html", "title": "What is planned for ReasonML?", "content": "What is planned for ReasonML? dev reasonml Table of contents for this series of posts: “ What is ReasonML? ” This blog post takes a brief look of a few key pieces of  ReasonML  that are still being worked on: \n Better support for writing asynchronous code that is compatible with JavaScript Promises.\n \n One option is to provide special syntax (see  issue on GitHub ). \n Another option is to add support to  OCaml’s concurrency library Lwt  (it’s one of the branches). \n \n \n Better support for polymorphism. At the moment, different types mean different function or operator names for ReasonML (for example, there is   for ints and   for floats). Haskell has type classes to solve this problem. A similar approach is being worked on for OCaml (and therefore ReasonML):  modular implicits . \n A better standard library. Many things are being explored in this area (see repository  reasonml-community/belt ). OCaml has a fair amount of fragmentation here, so standardization will be welcome. \n Better support for Unicode. At the moment, OCaml has no support for Unicode whatsoever and OCaml characters are 8 bit in size. You can get some Unicode support via BuckleScript’s custom string literals (which compiles to JavaScript strings): \nIn the future, ReasonML may add more support for OCaml. They could, e.g., treat strings as UTF-8 with tool functions for accessing grapheme clusters and code points. Compilation to JavaScript will present challenges (e.g. accessing characters/units), because JavaScript is basically UTF-16. \n Long(er) term, ReasonML also has a compelling story for multicore code, via  OCaml’s algebraic effects . \n For more information on what’s planned for ReasonML, consult its  Frequently Asked Questions . I’m excited about what’s in store. Better async support is especially important to me, as it will make Node.js development much more pleasant. Is there anything that you’d like to have that’s not on this list? comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/alex-russell-dart.html", "title": "Google’s Alex Russell on JavaScript versus Dart", "content": "Google’s Alex Russell on JavaScript versus Dart esnext dev javascript google dart blog post @MunichJS \nRelated reading:\n Google Dart to “ultimately ... replace JavaScript” A brief history of ECMAScript versions (including Harmony and ES.next) ECMAScript.next: the “TXJS” update by Eich comments powered by Disqus."},
{"url": "https://2ality.com/2017/12/for-await-of-sync-iterables.html", "title": "for-await-of  and synchronous iterables", "content": " and synchronous iterables dev javascript esnext es proposal This blog post describes how   handles synchronous iterables.   is a core construct of asynchronous iteration. You can read up on it in the blog post “ ES proposal: asynchronous iteration ”. Note: you can run the examples in Node.js 9.2+ via: Refresher: asynchronous iterables   # Asynchronous iterables return asynchronous iterators, whose method   returns Promises for   objects: Synchronous iterables and     # Synchronous iterables return synchronous iterators, whose method   returns   objects.   handles synchronous iterables by converting them to asynchronous iterables. Each iterated value is converted to a Promise (or left unchanged if it already is a Promise) via  . That is,   works for iterables over Promises and over normal values. The conversion looks like this: Two more ways of looking at the conversion are: \n \n  becomes  \n \n \n The following object \n \n is converted to \n \n \n Therefore, the following two statements are roughly similar. The second statement is faster, because   only creates the Promise for the Array after all Promises in   are fulfilled. And   has to await that Promise. In contrast,   starts processing as soon as the first Promise is fulfilled.  in action   # Iterating over a sync iterable over Promises: Iterating over a sync iterable over normal values: Further reading   # \n Blog post “ ES proposal: asynchronous iteration ” \n Chapter “ Iterables and iterators ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/es6-8.html", "title": "A first look at what might be in ECMAScript 7 and 8", "content": "A first look at what might be in ECMAScript 7 and 8 esnext dev javascript mentions \n     ECMAScript 6:  modules  and  shallow continuations . These things have been known for a while – see [1]. \n     ECMAScript 7:  guards , contracts,  event loop concurrency . \n     ECMAScript 8: macros, parallel arrays (SIMD) [ background ]. \n \n     Easily create embedded domain-specific languages (for HTML fragments, queries, GUI definitions, etc.). \n     Invent new more concise syntax for specific tasks (this one is mainly for – gifted – library authors). If you wanted to, you could also call the result a domain-specific language. \n     Any new syntax introduced after ECMAScript 8 can be retrofitted to previous versions via macros. \n \nRelated reading:\n ECMAScript.next: the “TXJS” update by Eich Does JavaScript have a bytecode, like Java? comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/google-dart.html", "title": "Google Dart to “ultimately ... replace JavaScript”", "content": "Google Dart to “ultimately ... replace JavaScript” esnext dev javascript google dart \n      “ Google Dart – overview and comments ” (with all the information from the official Dart launch at the GOTO conference) \n      “ Google’s Alex Russell on JavaScript versus Dart ” \n     2011-09-14: Rewrote of the section “What does it all mean?” and added new material on universal virtual machines. Added Crockford quote under “Other voices on Dart”. Added a conclusion. \n     2011-09-13: More on Eich’s comments at Hacker News. \n GOTO Aarhus 2011 Conference Dart, a new programming language for structured web programming Google’s strategy for JavaScript Google email \n Harmony (low risk/low reward): continue working in conjunction with TC39 (the EcmaScript standards body) to evolve Javascript \n Dash (high risk/high reward): Develop a new language (called Dash) [...] \n Dart (originally Dash) \n      – Dash is designed with performance characteristics in mind, so that it is possible to create VMs that do not have the performance problems that all EcmaScript VMs must have. \n      – Dash is designed to keep the dynamic, easy-to-get-started, no-compile nature of Javascript that has made the web platform the clear winner for hobbyist developers. \n     – Dash is designed to be more easily tooled (e.g. with optional types) for large-scale projects that require code-comprehension features such as refactoring and finding callsites. Dash, however, does not require tooling to be effective--small-scale developers may still be satisfied with a text editor. \n \n     Dedicated VM: as a substitute for JavaScript, in all browsers. \n     Server: with the goal to enable “Google-scale” web applications where front end and back end are written in the same programming language. \n     Cross-compiler: that compiles Dart to ECMAScript 3 on the fly, for compatibility with non-Dart browsers. Compare to Google Traceur [2] which compiles ECMAScript.next [1] to ECMAScript 3, in a similar manner. \n \nWe expect Brightly itself to be the first application written in Dash.\n What does it all mean? \n     Keep the ECMAScript.next-to-JavaScript compiler Traceur up to date. \n     Create an IDE that is as good at ECMAScript.next as it is at Dart. \n \n\n  The three goals for Dart are spot-on. I love that they are focusing on toolability, an area in which JavaScript currently has severe deficiencies, especially compared to Java. The goal of “developer usability” ensures that the language will remain lightweight. There are brilliant people working on it – that have both compiler expertise and language design expertise:\n email \n    Brad Abrams, Erik Arvidsson, Lars Bak, Darin Fisher, Dimitri Glazkov, Dan Grove, Peter Hallam, Bruce Johnson, Alex Komoroske, John Lenz, Kasper Lund, Mark Miller, Ivan Posva, Alex Russell, and Joel Webber, who collectively represent TC39 (the EcmaScript standards body), WebKit, Parkour, Brightly, JSPrime, JS++, Closure, JSCompiler, V8, Dash, Joy, and GWT, among others.\n Newspeak PDF Strongtalk \n\n  Let’s first recap how uniquely open JavaScript really is – there is no other programming language that is as open:\n \n     With ES-262 (ECMAScript), JavaScript has a very precise, easy-to-read specification. Doing such a specification well is much work, but it is essential for ensuring that all JavaScript engines remain compatible. Ironically, back in the day when Netscape had a browser monopoly and Microsoft had to catch up, Microsoft pushed for this kind of standardization to initially happen. All major browser vendors and the public collaborate to evolve ECMAScript. However, the core group working on the design is relatively small, works together well, and prototypes most of the proposals. That avoids many “design by committee” problems. \n     There are several competing implementations. That might sound like a disadvantage, but it isn’t: It leads to a robustness of the JavaScript ecosystem and pushes innovation. For example, Firefox borrowed ideas from Google’s V8 to make their JavaScript faster. \n Android email \n     Do not develop in the open. Instead, make source code available after innovation is complete \n     Lead device concept: Give early access to the software to partners who build and distribute devices to our specification (ie, Motorola and Verizon). They get a non-contractual time to market advantage and in return they align to our standard. \n \n    \n  If you are a competing browser vendor, your prospects for adopting Dart are as follows:\n \n     It is difficult to integrate into your existing infrastructure (as you couldn’t give early feedback). \n     Its development is mainly controlled by Google. \n     You give Google a head start of over two years. \n \n    Lars has promised to “sweet talk” the other browser vendors and, while we are all eager to see this, we recognize this is a very difficult road. Our approach is to make an absolutely fantastic VM/Language and development environment and build great apps that fully leverage it in order to help other browsers see the wisdom in following. Once Dash has had a chance to prove its stability and feasibility, we are committed to making Dash an open standard with involvement from the broader web community.\n not been approached \n    We fully intend to cooperate fully with standards processes--the problem is that the current standard processes are limited to  . Any effort with the historic baggage that Javascript has will be extremely limited. We need to make a clean break, make progress, and then engage the community.\n \n\n  Yes and no. To run either Dart or CoffeeScript [3] on a JavaScript engine, you will have to perform a translation step. However, CoffeeScript intentionally stays close to JavaScript semantics which means that it is a   (only local transformations), while Dart will probably need a compiler (that makes sophisticated non-local transformations). Source-code-level debugging is in store for CoffeeScript [4], but it’ll be much harder to implement for Dart. Thus, Google Chrome with a dedicated Dart VM will probably be the best way to run Dart for a long time and that could considerably fragment the open web.\n \n\n \nBrendan Eich  has talked  about this. Byte codes are always tightly coupled with the language they support, so finding an approach that everyone is happy with is practically impossible. Intellectual property rights are another challenge. Years ago, the Java Virtual Machine had the potential to become the “web virtual machine”. But things went differently and Sun ignored the client-side of the web while Ajax took off. Source code is the byte code of JavaScript, possibly with more compact syntax representations in the future. It seems weird, but it works  surprisingly well .\n\n Other voices on Dart Brendan Eich \nThey’re wrong, and I’m glad that at least   — specifically its ability to evolve soon enough and well enough to enable both more predictable performance and programming in the large.\n \nThere’s a better-is-better bias among Googlers, but the Web is a brutal, shortest-path, Worse-is-Better evolving system.\n \nI’ve spent the last 16 years betting on the Web. Evolving systems can face collapses, die-offs, exigent circumstances. I don’t see JS under imminent threat of death due to such factors, though. Ironic that Google would put a death mark on it.\n \n Gilad Bracha  [one of the people behind Dart]:\n More from Eich More from Eich \n    The leaked Google doc's assertion that this is impossible and that a \"clean break\" is required to make significant improvements is nonsense, a thin rationale for going it alone rather than cooperating fully.\n     ... \n    Dart is GBScript to NaCl/Pepper's ActiveG.\n More from Eich \n    The precise point now, here on planet earth and not wherever you are, is that Google is not that new monopoly. Not yet, not likely for years even in their wildest dreams.\n     \n    If Google were the monopoly Netscape was, sure: Dart would be the new JS. The two would co-exist for a long while but \"replacement\" would be conceivable so long as market power held up.\n     \n    Since Google does not have monopoly power, and with the non-standardizing tactics of that leaked memo, Dart is unlikely to be adopted by other browsers. It's fragmenting. It's an invitation to others to inject their own would-be replacements and build a Tower of Babel.\n interview \nCrockford: Google has not shared any information with me. Of the little bits they have leaked, some of it looks good. Some of it looks very, very bad. It is too early to draw any conclusions.\n Conclusion References A brief history of ECMAScript versions (including Harmony and ES.next) Google’s Traceur: compile ECMAScript.next to JavaScript on the fly  [see the section on “Caveats” regarding a lack of community involvement] CoffeeScript – overrated? SourceMap on Firefox: source debugging for languages compiled to JavaScript [update: WebKit, too] A Windows 8 keynote review by a JavaScript programmer and Apple user comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/jshint.html", "title": "JSHint – a JavaScript code quality checker", "content": "JSHint – a JavaScript code quality checker dev javascript jslang jstools JSHint What it is \n     detects anti-patterns and potential errors. Example: Using an assignment in the condition of an   statement.\n \n     \n     enforces best practices and coding styles. Example: The names of constructors must be capitalized. \n TextMate bundle \n  JSHint is based on Douglas Crockford’s  JSLint  whose initial release was in 2002. In 2011, Anton Kovalyov released JSHint and  explains  why he forked Crockford’s tool:\n Installation \n     Install  npm , the Node Package Manager \n     Use npm to install  node-jshint :\n \n        In most Unix installations, you have to prefix the above command with a   (“execute as super-user”), so that everything can be put where it needs to be.\n     \n JSHint GitHub page Example example \nRunning JSHint on   with the previously mentioned command produces the following errors:\n The then-clause of the   statement must be a block. Missing   before  . Missing semicolon after the assignment. The return statement cannot be broken up into two lines [2]. Accessing the undeclared variable  . Inline options \n     Global variables (setting  ):\n \n        Consequence: The global variable   can be read and written,   can only be read.\n     \n     Other settings (see below for a list):\n \n     \n Config file settings Controlling how it runs Debugging Firefox-only ECMAScript 5 and standard-compliance Predefined globals \n Style Correctness Related reading JSHint homepage node-jshint on GitHub JavaScript’s JSON API Automatic semicolon insertion in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/ie10-first-look.html", "title": "Internet Explorer 10 Preview – a first look by Sencha", "content": "Internet Explorer 10 Preview – a first look by Sencha dev internet explorer javascript windows 8 first look Sacha Storz \n     A Windows 8 keynote review by a JavaScript programmer and Apple user \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/find-grep.html", "title": "Unix shell: search for a text via “find” and “grep”", "content": "Unix shell: search for a text via “find” and “grep” dev unix shell \nExample: Find all JavaScript files in the current directory and search for the word “foo”. The easiest way to do this is to execute the command\n \n     Assemble a list of all JavaScript files in the current directory:\n \n     \n     Insert that list after “foo”: backquotes. \n     Go through a list of files, search for the text “foo”:\n \n        The option   ensure that the search is case-insensitive.\n     \n \n     The command after   is invoked for each file name that matches the pattern “*.js”, after the curly braces {} have been replaced with the name. The escaped semicolon “\\;” tells   where the command ends. \n     The option   tells grep to print the file name when it finds the text (something it doesn’t normally do if it searches a single file). \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/esnext-capitoljs.html", "title": "ECMAScript.next: new details, reacting to Dart complaints", "content": "ECMAScript.next: new details, reacting to Dart complaints esnext dev javascript talk CapitolJS RiverTrail News about ECMAScript.next features previous coverage \n     dom.js  Currently, the DOM is a C++ API, specified in the C++-centric WebIDL (Web Interface Definition Language) and clumsily bound to JavaScript. This makes it both slow and difficult to use. It is widely considered the part of the web stack that most needs fixing [1]. Implementing the DOM in pure JavaScript is a first step towards improving it. dom.js is an attempt to comply 100% with the WebIDL specification. And it needs ECMAScript.next features (Proxies and WeakMaps) to achieve that goal. Quoting Eich:\n          \n         An  episode  of “A Minute With Brendan Eich” provides background information on dom.js.\n     \n      The next version of ECMAScript will almost certainly be called ECMAScript 6. However, it is still better to use the term ECMAScript.next for the  set of features  currently under discussion at the Ecma TC39 wiki. The reason is that much can still change and saying that a feature is “in ECMAScript 6” might be confusing. Instead, Allen Wirfs-Brock suggests to only use that phrase for features that appear in the draft ECMAScript 6 specification that he is currently writing. Consult [2] for the difference between ECMAScript.next and ECMAScript Harmony (the former is a subset of the latter). \n    \n      Initially, private properties were part of the class literal proposal, but they are now handled by a combination of two constructs.\n         \n           private name objects .\n \n        Private names are hidden from mechanisms such as\n         \n             \n             \n         \n         \n          computed keys in object literals.\n \n        Putting an expression in square brackets allows you to compute the name of a property in an object literal.\n     \n      There are currently two competing proposals.\n         Arrow function syntax , inspired by CoffeeScript.\n \n             Block lambdas .\n \n             \n        So far, TC39 has only decided that the proposals are mutually exclusive, they won’t both be adopted. But it is not clear if either one will make it into ECMAScript and if so, which one. Eich prefers block lambdas:\n         \n            [...] JS syntax is not a problem for some (perhaps many) users. For others, it’s a hardship. Adding block-lambdas helps that cohort, adds value for code generators (see Harmony Goals above), and on balance improves the language in my view. It won my straw show-of-hands poll at CapitolJS against all of arrows, vaguer alternatives, and doing nothing.\n         \n        I agree with Eich’s choice. When used as an argument for a function, a block lambda has   –   in a block lambda refers to the object on which the surrounding method has been invoked. That will eliminate a frequent source of errors that sometimes even tricks experts. With block lambdas, JavaScript newbies will automatically do the right thing.\n     \n Dart versus ECMAScript.next \n      The performance of JavaScript engines is still improving, much can be done via type inference, and there is a proposal for optional runtime guards (that can help static optimization).\n     \n      This does hurt JavaScript performance and there is currently no proposal for fixing this. Eich mentions the following idea:\n         \n             Suffixes:  \n             Promotion rules as in C, but with dynamic types [convert to higher precision depending on the current operation]. \n         \n        Eich finds this too problematic and prefers a pragma to control arithmetic –   etc.:\n         \n        I don’t find this solution particularly intuitive. Maybe one could use an object-oriented solution that is compiled to something more efficient.\n \n        The above is a bit like the pragma, but allows one to mix different arithmetics.\n     \n      Eich makes several points (quoted verbatim):\n         \n             My suggestion is to prototype in SpiderMonkey and V8 some of the strawman proposals that did not make ES6 now, and see if any deserve promotion to ES6. \n             Coordinated strawman prototyping in SpiderMonkey and V8 is a tall order. Perhaps we need a separate jswg.org, as whatwg.org is to the w3c, to run ahead? I’ve been told I should be BDFL [Benevolent Dictator For Life] of such an org. Would this work? Comments welcome. \n             [...] would the jswg.org have to produce a JS’ to JS compiler, or even patches for the three open source engines? I’d need to organize some savvy, socially adept hackers to do the latter.\n             \n         \n        I think that TC39 is moving fast enough with ECMAScript.next. Remember that the rest of the world is still catching up with ECMAScript 5 and getting over their opinion that JavaScript is a toy language. The stability created by not going too fast has its own merits and ECMAScript is currently progressing much faster than Java ever did.\n     \n References Google’s Alex Russell on JavaScript versus Dart JavaScript: how it all began Google Dart to “ultimately ... replace JavaScript” comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/html-square-root.html", "title": "Displaying a square root with HTML", "content": "Displaying a square root with HTML dev html5 webdev math \n \nThe following HTML source\n \n\n MathML \nThe following HTML source\n \nRelated reading:\n \n     Displaying math in HTML  [mentions  MathJax  which allows you to use MathML in older browsers] \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/09/quasi-literals.html", "title": "Template strings: embedded DSLs in ECMAScript 6", "content": "Template strings: embedded DSLs in ECMAScript 6 dsl esnext dev template literals javascript In ECMAScript 6,    [1]  are a syntactic construct that facilitates the implementation of embedded  domain-specific languages  (DSLs) in JavaScript. They were originally called “quasi-literals”. This blog post explains how they work.  This blog post is slightly outdated. The terminology has changed: \n Template literal (was: template string):  \n Tagged template (was: tagged template string):  \n Tag function (was: template handler):   from previous item \n Introduction   # The idea is as follows: A   (short: a template) is similar to a string literal and a regular expression literal in that it provides a simple syntax for creating data. The following is an example. This is just a compact way of writing (roughly) the following function call: Thus, the name before the content in backquotes is the name of a function to call, the  . The handler receives two different kinds of data: \n  such as  . \n  such as   (delimited by a dollar sign and braces). A substitution can be any expression. \n Literal sections are known statically, substitutions are only known at runtime. Examples   # Template strings are quite versatile, because they become function calls and because the text that that function receives is structured. Therefore, you only need to write a new function to support a new domain-specific language. The following examples are taken from  [2]  (which you can consult for details): Raw strings   # Raw strings are string literals with multiple lines of text and no interpretation of escaped characters. Parameterized regular expression literals   # There are two ways of creating regular expression instances. \n Statically, via a regular expression literal. \n Dynamically, via the   constructor. \n If you use the latter way, it is because you have to wait until runtime so that all necessary ingredients are available: You are usually concatenating regular expression fragments and text that is to be matched verbatim. The latter has to be escaped properly (dots, square brackets, etc.). A regular expression handler   can help with this task: Query languages   # Example: This is a DOM query that looks for all   tags whose CSS class is   and whose target is a URL with the given domain. The template handler   ensures that the arguments are correctly escaped, making this approach safer than manual string concatenation. Text localization (L10N)   # There are two components to L10N. First the language and second the locale (how to format numbers, time, etc.). Given the following message. The handler   would work as follows. First, The literal parts are concatenated to form a string that can be used to look up a translation in a table. An example for a lookup string is: An example for a translation to German is: The English “translation” would be the same as the lookup string. Second, the result from the lookup is used to display the substitutions. Because a lookup result includes indices, it can rearrange the order of the substitutions. That has been done in German, where the visitor number comes before the site name. How the substitutions are formatted can be influenced via annotations such as  . This annotation means that a locale-specific decimal separator should be used for  . Thus, a possible English result is: In German, we have results such as: Secure content generation   # With template strings, one can make a distinction between trusted content coming from the program and untrusted content coming from a user. For example: The literal sections come from the program, the substitutions   and   come from a user. The template handler   can ensure that no malicious cade is injected via the substitutions. For HTML, the ability to nest template strings is useful: Explanation: The rows of the table are produced by an expression – the invocation of the method  . The result  of that invocation is an array of strings that are produced by recursively invoking a template string.   concatenates those strings and inserts them into the given frame. The cells for each row are produced in the same manner. More examples   # \n Using ES6 template strings for regular expressions \n React JSX via ECMAScript 6 template strings \n Implementing a handler   # The following is a template string: This is transformed internally to a function call (adapted from  [2:1] ): The parameters of the handler are split into two categories: \n The   where you get the literal parts both with escapes such as   interpreted (“cooked”) and uninterpreted (“raw”). The number of literal parts is always one plus the number of substitutions. If a substitution is first in a literal, it is prefixed by an empty literal part. If substitution is last, it is suffixed by an empty literal part (as in the example above). \n \n The substitutions, whose values become trailing parameters. The idea is that the same literal might be executed multiple times (e.g. in a loop); with the callSiteID, the handler can cache data from previous invocations. (1) is potentially cacheable data, (2) changes with each invocation. Conclusion   # As you can see, there are many applications for template strings. You might wonder why ECMAScript 6 does not introduce a full-blown macro system. That is because it is quite difficult to create a macro system for a language whose syntax is as complex as JavaScript’s. Work on macros is ongoing (see Mozilla’s  sweet.js ), but will take time. With luck, we will see macros in ECMAScript 8  [3]  (which could arrive as early as 2018).  Thanks to Brendan Eich, Mark S. Miller, Mike Samuel, and Allen Wirfs-Brock for answering my template-string-related questions on the es-discuss mailing list. References   # ECMAScript 6 specification: “ Template Literals ”  ↩︎ \n ECMAScript Quasi-Literals  [proposal for ECMAScript 6]  ↩︎   ↩︎ \n A first look at what might be in ECMAScript 7 and 8   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/dart-launch.html", "title": "Google Dart – overview and comments", "content": "Google Dart – overview and comments dev google dart webdev officially presented \n Information on Dart \n     Dart home page \n     Dart on Google Code \n     Live transcript of the Dart presentation at the GOTO conference \n Dart in a nutshell \n     Currently, Dart is not a JavaScript replacement, but rather a “better Java” plus a next-generation GWT. \n     The language is less like JavaScript and more like an improved version of Java: reified generics, first-class functions, optional types (no type errors, just warnings), getters and setters, no primitive types. \n     It is still part of the HTML5 world and includes a DOM library. \n     There is IDE support, via an Eclipse plug-in. \n An overview of the language Functions Classes \n     Methods: see  , above \n     Operators\n \n     \n     Fields\n \n     \n     Getters, setters\n \n     \n     Constructors\n         \n             Normal constructors\n \n                Prefixing   to parameters means that they will be automatically assigned to fields. This has been one of the proposed feature for JavaScript class literals.\n             \n             Named constructors. Without overloading, you need a way to distinguish between alternate constructors.\n \n             \n             Factory constructors are a way to mark constructors so that no instance is produced automatically. Then you can return cached instances or instances of a subclasses.\n \n             \n         \n     \n Interfaces \n  An interface can specify a   which can be considered its default implementation. You can now directly instantiate the interface, its constructors delegate to the constructors of the factory class. If you use normal constructors then that is not much different from a normal class (but you don’t get the multiple inheritance of interfaces). Things become interesting with factory constructors, because you can create your own instance (including an instance of a subclass). I’ve seen interfaces being abused in Java code, to the point where there wasn’t a single class that didn’t implement an interface, so we’ll see where this goes. This feature does not provide  mixin  functionality. That is, if you implement an interface, you don’t get default method implementations via the factory class.\n\n Isolates actor Generics Strings \n     Triple quotes for multi-line strings\n \n     \n      for variable interpolation:\n \n     \n      for expression interpolation:\n \n     \n Miscellaneous features \n     There is a standard library with collection classes (List, Set, Queue, Map, etc.) and a DOM API. \n     Equality is handled via the   operator and delegates to the   interface (for non-null values). \n     You cannot access JavaScript directly from Dart. In the future, there might be a way to run JavaScript code in an isolate and communicate with it via message passing. In GWT, integrating native JavaScript is easy. Whether that ease will ever come to Dart will depend on how Google eventually positions it – as a JavaScript replacement or as a Java/GWT replacement. \n Running Dart Technical Overview \n     Translate Dart code to JavaScript that can run in any modern browser: Chrome, Safari 5+, and Firefox 4+ (more browser support coming shortly). \n     Execute Dart code directly in a VM on the server side.     \n     Use Dartboard to write, modify, and execute small Dart programs within any browser window. \n Dart is not finished yet \n     Enums \n     Possibly: a reflection API \n     Possibly: pattern matching (think: a more powerful switch for objects). Useful for isolates to better handle messages. \n     “The Dart VM is not currently integrated in Chrome but we plan to explore this option.” [source:  Google Code blog ] \n More information on the web Features and details @dalmaer http://code.google.com/p/dart/people/list @pmuellr Tongue in cheek @mrspeaker @jordansissel @jashkenas Hack.java @maccman How does Dart fit into the current programming language landscape? tweet \n     If you like Java and can’t get yourself to like JavaScript, you program Dart. \n     If you like Ruby and can’t get yourself to like JavaScript, you program CoffeeScript. \n     If you like JavaScript, you program JavaScript. \n \n     Currently, Dart is almost like GWT (which is not a bad thing): Running “natively” on a virtual machine on the server, compiled to JavaScript on the client. \n     Basing the Dart IDE on Eclipse makes sense, because you get a lot of functionality (such as Git support) for free and because it is familiar to Java programmers. \n     Dart seems like an upgrade of Java, like a cleaned up version. It even carries over some negative Java-isms, such as fields automatically becoming part of the local scope. \n \n     Main Dart killer features: optional types, actor-like concurrency via  . However, you can do a lot via type inference in JavaScript, class literals will come to ECMAScript.next [2] and web workers are becoming more sophisticated all the time. Dart foregoes some of JavaScript’s quirks, but then again, so does ECMAScript.next.\n     \n     In many ways, Dart feels   than JavaScript. For example, JavaScript object literals are a very powerful feature. Dart is more static and only has classes. \n     Dart seems to have decent tooling, but it’s based on Eclipse. In contrast, many JavaScript IDEs that are currently in development are based on web technologies. Writing an IDE for a language in the language itself has many advantages. \n     At the moment, Dart isn’t even faster than JavaScript on V8. Presumably, that will change in the future. But this goes to show how fast JavaScript has become and that it didn’t need static types to get there. \n     Not a JavaScript replacement? Quote from the talk:\n \nI’m not sure what that means. Will Dart target these platforms by compiling to JavaScript or by compiling to the native mobile environments? It almost makes you wonder whether Google really knows what to do with Dart.\n     \n     Google could have gotten the same results by supporting ECMAScript.next [2] (plus possibly some advanced, not yet standardized features) and Traceur [3]. \n \nTentative pointers in that direction are Google not yet committing to integrating the Dart VM into Chrome and saying that Dart doesn’t target JavaScript, but a “fragmented mobile platform”. That is a marked change in tone from the openly anti-JavaScript document that was published last year [1]. And it is also a very weak message about what Dart actually is. Google will have to eventually give clear answers. By missing the opportunity to do so during today’s event, they have weakened the impact of the launch.\n \nIf you want to see a truly innovative language, take a look at  Newspeak : Its elegant syntax has the well-known Smalltalk advantages and there are fresh new ideas regarding modularity and IDEs (check out the paper on Hopscotch). Gilad Bracha, one of its creators, is part of the Dart team, which is why I expected more from that language.\n\n Related reading Google Dart to “ultimately ... replace JavaScript”  [the prelude to the GOTO Dart presentation] ECMAScript.next: the “TXJS” update by Eich Google’s Traceur: compile ECMAScript.next to JavaScript on the fly comments powered by Disqus."},
{"url": "https://2ality.com/2017/07/promise-prototype-finally.html", "title": "ES2018:  Promise.prototype.finally()", "content": "ES2018:  dev javascript esnext es2018 promises The proposal “ ” by Jordan Harband is at  stage 4 . This blog post explains it. How does it work?   #  works as follows: ’s callback is always executed. Compare: \n ’s callback is only executed if   is fulfilled. \n ’s callback is only executed if   is rejected. Or if  ’s callback throws an exception or returns a rejected Promise. \n In other words: Take the following piece of code. This piece of code is equivalent to: Use case   # The most common use case is similar to the most common use case of the synchronous   clause: cleaning up after you are done with a resource. That should always happen, regardless of whether everything went smoothly or there was an error. For example:  is similar to   in synchronous code   # In synchronous code, the   statement has three parts: The   clause, the   clause and the   clause. In Promises: \n The   clause very loosely corresponds to invoking a Promise-based function or calling  . \n The   clause corresponds to the   method of Promises. \n The   clause corresponds to the new Promise method   introduced by the proposal. \n However, where   can   and  , returning has no effect inside the callback  , only throwing. That’s because the method can’t distinguish between the callback returning explicitly and it finishing without doing so. Availability   # \n The npm package   is a polyfill for  . \n V8 5.8+ (e.g. in Node.js 8.1.4+): available behind the flag   ( details ). \n Further reading   # \n “ Promises for asynchronous programming ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/07/npm-packages-via-babel.html", "title": "A minimal setup for Babel-based npm packages", "content": "A minimal setup for Babel-based npm packages dev javascript esnext npm jsmodules babel This blog post describes a minimal setup for producing npm packages via Babel. You can see that setup in action in the GitHub repository for  . The core structure   # There are two two sets of files: \n Directory   has the (untranspiled) actual source code of the library.\n \n Property   in   points to  \n Directory   contains AVA-based tests for the files in  . \n \n \n Directory   has transpiled versions of the ESM files, so that they have the CommonJS format and support the features that the currently running Node.js can handle.\n \n Property   in   points to  \n \n \n This structure enables two use cases: \n Node.js apps use the files in  . \n Web apps (via webpack etc.) use the files in  . They transpile those files via   to the feature set supported by their target platforms. Details of how to do that are described in  a separate blog post . \n One issue we have only partially tackled is how to polyfill parts of the standard library that may be missing. That will be the topic of an upcoming blog post.    #  is not committed to git. We only generate it on demand before publishing the package on npm.    # When publishing to npm, we do need to include  . That’s why we need   in addition to  .    # The main parts of     # The following scripts are available: \n  generates the files in  . \n  ensures that   is always built before we publish to npm. \n  runs tests via AVA. \n Accordingly, we have the following dependencies (at development time only): \n  is needed for the unit tests. \n  provides the command  . \n  lets AVA execute the tests via Babel. \n  is the Babel preset we use for transpilation. \n \n  is the package entry point for the CommonJS format (which includes normal modules running on Node.js). \n  is the package entry point for the ESM format (which includes webpack; depending on how you set it up). \n More information on these two properties: “ Setting up multi-platform npm packages ”. \n Configuring Babel   # For Babel, we use   in the typical way, to produce code for the currently running Node.js. Configuring AVA   # For AVA, we require  , which transpiles all tests and their imports via Babel.   means that AVA uses the configuration shown in the previous section. Conclusion   # This was a quick tour of a minimal repository for authoring npm packages via Babel. An important aspect is that it lets clients of the package use   (as described in “ Delivering untranspiled source code via npm ”). To that end, it does not use   100% correctly, but with the upside of broad support and of not introducing yet another   property. Further reading   # \n Free online book: “ Setting up ES6 ” \n Delivering untranspiled source code via npm \n : a preset that configures Babel for you \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/07/regexp-dotall-flag.html", "title": "ES2018:  s  ( dotAll ) flag for regular expressions", "content": "ES2018:   ( ) flag for regular expressions dev javascript esnext es2018 regexp The proposal “  ( ) flag for regular expressions ” by Mathias Bynens is at  stage 4 . This blog post explains how it works. Overview   # Currently, the dot ( ) in regular expressions doesn’t match line terminator characters: The proposal specifies the regular expression flag   that changes that: Limitations of the dot ( ) in regular expressions   # The dot ( ) in regular expressions has two limitations. First, it doesn’t match astral (non-BMP) characters such as emoji: This can be fixed via the   ( ) flag: Second, the dot does not match line terminator characters: That can currently only be fixed by replacing the dot with work-arounds such as   (“all characters except no character”) or   (“either whitespace nor not whitespace”). Line terminators recognized by ECMAScript   #  in ECMAScript affect: \n The dot, in all regular expressions that don’t have the flag  . \n The anchors   and   if the flag   ( ) is used. \n The following for characters are considered line terminators by ECMAScript: \n U+000A LINE FEED (LF) ( ) \n U+000D CARRIAGE RETURN (CR) ( ) \n U+2028 LINE SEPARATOR \n U+2029 PARAGRAPH SEPARATOR \n There are additionally some newline-ish characters that are not considered line terminators by ECMAScript: \n U+000B VERTICAL TAB ( ) \n U+000C FORM FEED ( ) \n U+0085 NEXT LINE \n Those three characters   matched by the dot without a flag: The proposal   # The proposal introduces the regular expression flag   (short for “singleline”), which leads to the dot matching line terminators: The long name of   is  :  vs.     # \n  only affects the dot. \n  only affects   and  . \n FAQ   # Why is the flag named  ?   #  is a good description of what the flag does, so, arguably,   or   would have been better names. However,   is already an established name (Perl, Python, Java, C#, ...). comments powered by Disqus."},
{"url": "https://2ality.com/2017/07/class-fields.html", "title": "ES proposal: class fields", "content": "ES proposal: class fields dev javascript esnext es proposal classes section “Public slots (properties) vs. private slots” The ECMAScript proposal “ Class Fields ” by Daniel Ehrenberg and Jeff Morrison is currently at stage 3. This blog post explains how it works. Overview   # Field declarations: Private fields have names starting with a   and are only visible within the body of the class: Declaring fields   # With this proposal, objects now have two kinds of fields: \n Properties, whose keys are strings or symbols. \n Private fields that have names. More on private fields later. \n Fields can be configured as follows: \n Location of property:\n \n Static: prefix  \n Instance: no prefix \n \n \n Visibility and name. A field can be either:\n \n A public property with a fixed name \n A public property with a computed key \n A private field with a fixed name \n \n \n Initializer: optional \n Initializers   # With an initializer, you create a property and assign it a value at the same time. In the following code,   is an initializer: This class is equivalent to: Initializers are executed before the constructor   # Location of the field   # Instance fields   # Without any prefix, a declaration creates an instance field: Class fields   # Declarations with the prefix   create fields for classes:  has the properties   and  , because it is also a function. Private visibility   # Kinds of privacy in JavaScript   # In ES6 and later, you can already implement two kinds of privacy: \n Soft privacy (that you can work around): put data into properties whose keys are symbols ( details ). \n \n Hard privacy (that is mostly safe; for complete safety, you have to take additional precautions): data is in the values of WeakMaps whose keys are the objects that the private data is associated with ( details ). \n \n Private fields are basically a more convenient way of doing hard privacy. From underscores to private fields   # Another common technique is to indicate which properties are considered private by prefixing their names with underscores: This technique doesn’t give you any protection, but it is more convenient than using symbols or WeakMaps. Such code can be changed to use the new private field feature in two steps: Replace each underscore with a hash symbol. Declare all private fields at the beginning of the class.  does not have any instance properties: Private fields are similar to hard privacy via WeakMaps   # In the spec, private fields are managed via a data structure that is attached to objects. That is, private fields are roughly handled as follows. A consequence of this approach is that you can only access private fields if you are inside the body of a class; access to   does not give you access to private data. In other words, you need to know the right symbol to access the data (  in the example is not fully protected, but the corresponding data structure in the spec is). More information in the spec: Sect. “ Private Names and references ” Not yet supported   # Two elements of classes cannot yet be private: \n Method definitions \n Setters and getters \n An upcoming proposal  that fills this gap is currently at stage 2. Trying out this proposal   # If you switch on stages 2+ in  the Babel REPL , you can play with class fields (however, private fields are not supported, yet). FAQ   # Why the  ? Why not declare private fields via  ?   # First, the   clearly indicates that private fields are   properties. They are a completely different mechanism. Second, if you declared private fields via   and if they looked like normal properties, property lookup would become more complicated: If   is a direct(!) instance of  ,   is a private field. Otherwise, it refers to a normal property. Further reading   # \n Chapter “ Classes ” in “Exploring ES6”\n \n Particularly section “ Private data for classes ” \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/08/promise-callback-data-flow.html", "title": "Passing data between Promise callbacks", "content": "Passing data between Promise callbacks dev javascript esnext async promises In Promise-based code, there are usually many callbacks, each one having a separate scope for variables. What if you want to share data between those callbacks? This blog post describes techniques for doing so. The problem   # The following code illustrates a common problem with Promise callbacks: The variable   (line A) exists in one scope, but needs to be accessed in other scopes (line B, line C). In this code, we are using  , which is a proposed ECMAScript feature. It works analogously to the   clause of   statements. Solution: side effects   # The first solution we’ll look at is to store the value to be shared,   , in a variable in a scope surrounding all callback scopes (line A). Due to its outer location,   is available in line B and line C. Solution: nested scopes   # The synchronous version of the original example looks like this: With synchronous code, the solution to making   available in line A is usually to move the variable declaration to a surrounding scope: We can do something similar with Promises – if we nest Promise chains: There are two Promise chains: \n The first Promise chain starts in line A.   is the asynchronously delivered result of  . \n The second Promise chain is nested inside the   callback starting in line B. It starts in line C. Note the   in line C, which ensures that both chains are eventually merged correctly. \n The nesting gives all callbacks in the second chain access to  . You may have noticed that, in both the sync and the async code, synchronous exceptions thrown by   won’t be handled by   (clause or callback).  A follow-up blog post on   shows how to fix that for the async code. In the sync code, you can move   into the   clause. Solution: multiple return values   # The following code demonstrates another approach for passing data between callbacks. However, it doesn’t always work. In particular, you can’t use it for the ongoing database example. Let’s look at an example where it does work. We are facing a similar problem: A Promise chain where the intermediate value   should be passed from the callback starting in line A to the callback starting in line B. We solve this problem by using   to pass multiple values from the first callback to the second one: Note that returning an Array in line A does not work, because the   callback would receive an Array with a Promise and a normal value.   uses   to ensure that all Array elements are Promises and fulfills its result with an Array of their fulfillment values (if none of the Promises is rejected). One limitation of this approach is that you can’t pass data into the callbacks of   and  . Lastly, this technique would benefit from a version of   that worked with objects (not just Arrays). Then you could label each of the multiple return values. Further reading   # \n Chapter “ Promises for asynchronous programming ” in “Exploring ES6” has tips for chaining Promises and more. \n ES proposal:  \n ES proposal:  \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/07/re-template-tag.html", "title": "Composing regular expressions via  re-template-tag", "content": "Composing regular expressions via  dev javascript regexp template literals I’ve written the small library   that provides a template tag function for composing regular expressions. This blog post explains how it works. The basics   # The library implements the template tag   for regular expressions: Install: Import: Use: The following two expressions produce the same regular expression. A tour of the features   # The unit tests  are a good tour of the features of re-template-tag. Main features   # You can use   to assemble a regular expression from fragments: Any strings you insert are escaped properly: Flag-less mode: Details and advanced features   # You can use the backslash as you would inside regular expression literals: Regular expression flags (such as   in the previous example) can also be computed: Why is this useful?   # \n You can compose regular expressions from fragments and document the fragments via comments. That makes regular expressions easier to understand. \n You can define constants for regular expression fragments and reuse them. \n You can define plain text constants via strings and insert them into regular expressions and they are escaped as necessary. \n  and named capture groups   #  profits from the upcoming regular expression feature “ named capture groups ”, because it makes the fragments more independent. Without named groups: With named groups: comments powered by Disqus."},
{"url": "https://2ality.com/2017/08/promise-try.html", "title": "ES proposal:  Promise.try()", "content": "ES proposal:  dev javascript esnext es proposal async promises  I added an FAQ. The proposal “ ” by Jordan Harband is currently at  stage 1 . This blog post explains how it works.    # To understand what   does, consider the following code: If   throws a synchronous exception then so does  . But we want the latter function to deliver all errors via Promises. To avoid this problem, we can use  : Now errors thrown in line B will lead to the rejection of the Promise returned in line A.   has two additional benefits: \n The code is structured more consistently: all functionality is now located inside callbacks. \n You control what Promise implementation is used. Whatever kind of thenable is returned by  , it will be converted to an instance of  . \n Work-arounds   # Until we get  , we can use the following work-around:  creates a Promise that is fulfilled with  . That result does not matter to us. What does matter is that we have just started a Promise chain and can put the code to try into the callback starting in line A. Another work-around is to use the   constructor: FAQ   # Why not just use async functions?   # If you can use async functions, they are the better choice and automatically convert all exceptions thrown inside their bodies to rejections. Alas, sometimes you need to work with Promises directly and then   is useful. Why not just use  ?   #  is relatively small syntactic sugar and easy to polyfill. Compared to using the   constructor, it has the following advantages: \n The code inside its callbacks is consistent with   callbacks and can be moved more easily. \n It is more self-descriptive and slightly more concise. \n Further reading   # \n Chapter “ Promises for asynchronous programming ” in “Exploring ES6” has tips for chaining Promises and more. \n ES proposal:  \n Passing data between Promise callbacks \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/amd.html", "title": "The power of the Asynchronous Module Definition", "content": "The power of the Asynchronous Module Definition dev javascript jsmodules jslang Bridging the module gap between Node.js and browsers \nThis post explains Asynchronous Module Definition (AMD), a standard for defining modules in JavaScript and contrasts it with the currently very popular CommonJS synchronous modules.\n \n \nCurrently,  CommonJS-style  synchronous modules are very popular. For example, they are used in Node.js. Such a module looks as follows.\n Asynchronous Module Definitions \n     Asynchronous: AMDs have been designed to support asynchronicity and most AMD-compatible script loaders take advantage of it. Thus, AMD modules can be loaded in parallel. Once the last imported module has finished loading, the importing module can be evaluated. It is ironic that the Node.js module system is synchronous. \n     Work in browsers: Browser modules have to be asynchronous and AMDs are. \n     No globals: AMDs avoid global variables from being created, because there is always a wrapping function. Note, though, that CommonJS-compliant module loaders usually also (invisibly) wrap modules they load in a function. \n     No more namespacing: AMDs obviate the need for namespacing such as foo.bar.myModule, via a global variable and nested objects. The namespacing is in the path to the file, a local variable is short and convenient handle. \n \n     RequireJS  [includes support for using AMDs on Node.js] \n     curl \n “ AMD is better for the web than CommonJS modules ” by Miller Medeiros. [The post goes into greater detail regarding AMD features such as loading non-script resources.] Modules and namespaces in JavaScript  [explains several module patterns and gives an in-depth perspective on modularity in JavaScript] A first look at the upcoming JavaScript modules  [thankfully, these will make all current module systems obsolete, in the long run] comments powered by Disqus."},
{"url": "https://2ality.com/2017/08/optional-catch-binding.html", "title": "ES2019: optional catch binding", "content": "ES2019: optional catch binding dev javascript es2019 error handling The proposal “ Optional catch binding ” by Michael Ficarra is at  stage 4  and therefore part of ECMAScript 2019. This blog post explains how it works. Overview   # The proposal allows you to do the following: That is useful whenever you don’t need the binding (“parameter”) of the   clause: If you never use the variable  , you may as well omit it, but JavaScript doesn’t let you do  . Furthermore, linters that check for unused variables complain in such cases. Use cases   # There are two general reasons for omitting the   binding: \n If you want to completely ignore the error. \n You don’t care about the error or you already know what it will be, but you do want to react to it. \n My recommendation is to avoid doing that: \n Instead of completely ignoring an error, at least log it to the console. \n Instead of assuming you know what the error will be, check for unexpected types of exceptions and re-throw them. \n If you can’t and don’t want to avoid it, I suggest encapsulating your code, e.g. inside a function, and to document it well. Next, we’ll take a look at use cases for omitting   bindings and at risks and alternatives. Use case:     # With  , there is one predictable kind of exception – if the input is not legal JSON: That’s why it can make sense to use it like this: There is one problem with this approach: errors in line A that are not related to parsing will be silently ignored. For example, you may make a typo such as  . Cases like this have bitten me a few times in the past. Therefore, I now prefer to conditionally re-throw the errors I catch: Use case: property chains   # When accessing nested properties that may or may not exist, you can avoid checking for their existence if you simply access them and use a default if there is an exception: I prefer explicit checks. For example: This code can be shortened if you consider that the   operator returns the first falsy operand or the last operand (if there is no falsy operand): However, this shorter version is also more obscure. Use case:     # Node.js has the API function   that checks whether an error is thrown inside  . It could be implemented as follows. This function is an example of wrapping and documenting code that ignores caught exceptions. Use case: feature detection   # The following code snippet demonstrates how to detect whether a given feature exists: Use case: even logging fails   # If even logging doesn’t work then, as a last resort, you have no choice but to ignore exceptions (because further logging could make things worse). Again, we encapsulate and document the slightly unorthodox code. Further reading   # \n Stack Exchange: “ Is it ever ok to have an empty catch statement? ” \n GitHub issue (repo of proposal): “ Why? ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/08/type-right.html", "title": "Beyond  typeof  and  instanceof : simplifying dynamic type checks", "content": "Beyond   and  : simplifying dynamic type checks dev javascript esnext es proposal typedjs This blog post describes a technique for making   applicable to more values (on the right-hand side). Specifically, for primitive values. Background:   vs.     # In JavaScript, you have to choose when it comes to checking the type of a value. The rough rule of thumb is: \n  checks if a value is an element of a primitive type: \n \n  checks if a value is an instance of a class or a constructor function: \n(Additionally,   and   are occasionally useful.) \n This is already less than ideal, because you have to keep the difference between primitive values and objects in mind, which you can often ignore, otherwise. Alas, a few quirks make things even more complicated: \n  is  , not  . This is considered  a bug . \n  distinguishes between objects and functions (which are also objects): \nThis quirk, combined with the previous quirk means that there is no simple way to check for object-ness via  . \n Not all objects are instances of  : \n \n Enabling   for primitive values   # Given the class  , the following code configures for which values   the expression   returns  . It does so by implementing a static method for   whose key is  the public symbol  . Dynamic type checking via the TypeRight library   # TypeRight  is a minimal library for dynamic type checking. Among other features, it uses the approach shown in the previous example to implement the following pseudo-classes. Their only purpose is to be right-hand sides of the   operator: \n \n \n \n \n \n \n TypeRight does not currently provide a class for checking if a value is an object, but that could easily be added. Building on these foundations, you can use TypeRight to check if the parameters of a function have the proper types: Other approaches for simplifying type checks   # Two proposals for handling type checks are currently at  stage 0 . That means that they describe ideas that may or may not be explored further in the future. Pattern matching   # The proposal “ ECMAScript Pattern Matching Syntax ”, by Brian Terlson and Sebastian Markbåge, introduces the key   to make values “matchable”: The property could either be generated automatically or added manually, as follows (line A).  and     # The proposal “  and  ” by James M. Snell introduces several mechanisms for type checking.  checks if   and   refer to the same builtin constructor. It takes into consideration that   and   may come from  the current realm or another realm :  can be seen as an extension   that works for both primitive values and built-in classes: Further reading   # \n Sect. “ The   property of instances ” in “Speaking JavaScript” \n Sect. “ Pitfall:  ” in “Speaking JavaScript” \n Sect. “ : Categorizing Primitives ” in “Speaking JavaScript” \n Sect. “ Pitfall: objects that are not instances of Object ” in “Speaking JavaScript” \n Sect. “ Property key  ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/08/typing-import-statements.html", "title": "Tips for typing import statements in JavaScript", "content": "Tips for typing import statements in JavaScript dev javascript esnext jsmodules vscode   New section on auto-importing . This blog post gives tips for typing import statements more quickly, including a helpful text snippet for Visual Studio Code. \n   \n     Does JavaScript’s   statement have the wrong syntax? \n   \n   \n     Auto-importing \n   \n   \n     Manually typing   statements \n   \n   \n     A code snippet for faster entry \n   \n   \n     Further reading \n   \n Does JavaScript’s   statement have the wrong syntax?   # People occasionally complain that JavaScript’s import statement has it backwards. The syntax is: They argue that it should be: As an aside, that’s how Python does imports. Why? It would make auto-expansion easier: We’d first type the module specifier   and then the imported values  . During the latter step, the IDE has the necessary context for helping us out. The reasons for the different order in JavaScript are: \n It’s the same order as variable declarations. \n It’s the same order as using   in Node.js modules. \n Given that we only write code once but read it many times, the focus should be on which version is easier to read. And there, I slightly prefer JavaScript’s current syntax. Auto-importing   # These days, I mostly write TypeScript and I mostly use Visual Studio Code (VSC). There, auto-importing has gotten really good: If there is a value I want to import, I type its name, auto-expand it (Control-Space on macOS) and VSC imports it for me. I neither have to know the name of the module nor get its relative path right. Additionally, I use the “Organize Imports” command (which has a keyboard shortcut that you can look up via the Command Palette) to: \n Remove unused imports. \n Show modules and imported values in a consistent order. \n Manually typing   statements   # When typing import statements manually: I import nothing via   and auto-expand the module specifier: \n I go back and auto-expand the imported values: \n A code snippet for faster entry   # To create a snippet for Visual Studio Code that helps with   statements, follow these steps: Execute the menu command   (Mac:  ). Pick the language “JavaScript”. Add this property to the JSON file: \n Explanation: \n Initially, place the cursor after   (position  ). The placeholder we’ll see at that position is  . \n The next time we press the   key, the cursor will jump to after   (position  ). \n The last tab stop is after the semicolon (position  ). \n Now editing works as follows: Use auto-expansion. Use auto-expansion.  A similar snippet is now built into Visual Studio Code for   files (previously, only TypeScript was supported ( more information ). Further reading   # \n Creating your own Snippets in Visual Studio Code \n Chapter “Modules”  in “JavaScript for impatient programmers” \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/logo-js.html", "title": "logo.js – JavaScript has a (semi-)official logo", "content": "logo.js – JavaScript has a (semi-)official logo dev javascript @voodootikigod logo.js \n \nIn his words:\n \n      to be exact, it is not a JavaScript logo but a JS logo. \n      Can you explain the difference? \n      One of the two is a trademark owned by Oracle Inc. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/class-pattern.html", "title": "A JavaScript class pattern that starts with a function", "content": "A JavaScript class pattern that starts with a function dev javascript jslang \nExample usage:\n trailing commas \nThis is the code that makes the above work:\n \nRelated reading:\n “ Class Definition Pattern Using Object Extension Literals ” by Allen Wirfs-Brock [inspiration for this blog post] comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/umodules-imports.html", "title": "Universal modules (browser, Node.js): imports and universal tests", "content": "Universal modules (browser, Node.js): imports and universal tests dev javascript jsmodules jslang Bridging the module gap between Node.js and browsers \nThis post explains how to write modules that are universal – they run on browsers and Node.js. A  previous post  showed a simple way of doing so, this post presents a more sophisticated solution that also handles modules importing other modules. Additionally, we use the unit test framework Jasmine to write tests for those modules that are equally universal.\n \n\n The universal module pattern \n     Find a module format that works on browsers and Node.js. \n     Browsers: allow one to use existing script loaders such as Require.js. \n     Node.js: let universal modules load Node.js modules, let Node.js modules load universal modules. Then you can use a universal module from normal Node code, without even knowing about universal modules.\n     \n \n  The legal names of universal modules are a subset of Node’s. The file extension \".js\" is always omitted. There are three kinds of names:\n \n      a single identifier, without dots or slashes.\n        Example:  . \n        Such names can refer to built in “core” modules. If not, Node searches directories relative to the current module. For example, if the current module is   and imports the module  , then Node searches for the following files:\n \n        The browser AMD loader that comes with the universal_modules project lets you map global module names to paths (as searching the file system in the above manner makes less sense in a browser). That allows one to use a single name for a module that has a browser-specific and a Node-specific implementation. See below for details.\n     \n      \"./\" or \"../\" (repeated one or more times), followed by a sequence of identifiers separated by slashes. Examples: \"./bar\", \"./bar/baz\", \"../bar\", \"../../bar\". \n        Their names interpreted as paths relative to the path of the current module. Example: resolving relative module names.\n \n     \n      a slash followed by one or more identifiers separated by slashes. Examples: \"/bar\", \"/bar/baz\". \n        The given name is used as an absolute path to find the JavaScript file.\n     \n \n  Download the  universal modules project . Copy the directory   to your project.\n\n Using universal modules \n    uses that module from a browser:\n Load   so that you can define and import universal modules. Set up global names (optional): You use   to resolve global module names.\n         \n             The result of a resolution is either a path to a script to be loaded or an object (which   the module). \n             The resolution can be performed by an object (mapping module names to paths or objects) or a function (taking a module name and returning a path or an object). \n         \n     Define a module that imports  . \n  is run from a command line via\n Explaining the universal module pattern \n    \n  On Node.js, we need to connect the AMD to the native module system. Possible solutions:\n \n     \n \n        In browsers, there already is a   function. Therefore, we check whether it exists. If not, we create a Node.js version of  . To do so, we use the module   (“universal modules for Node.js”, see below for details on its contents). Each Node.js module needs a custom definition of  , because that function must use the module-specific   function and   object. For  , it is obvious why it is module-specific: If you are in a module A and load another module B via a module-relative path, then   must know A’s absolute path to compute B’s absolute path. Node.js provides modules with   functions that have this knowledge. Note that newer versions of Node.js allow one to access both   and   via the module-specific variable  , but we also want to support older versions (where there is only  ).\n         \n        Main problem with this approach: Hoisting [5] can prevent this from working – it means that the above code is usually interpreted as\n \n        Then   will always be  .\n     \n    \n     \n \n        The main drawback of this approach is that using a global variable this way is especially inelegant in a module system like Node’s which is all about local state. Constantly giving it a new value is even worse.\n     \n    \n     Immediately Invoked Function Expression  For example:\n \n        The above is almost the same as defining a local variable, above. But this time, we create a new scope for that variable to live in. This is a very clean solution. However, it is a bracket around the AMD. It would be nicer if we could do with just a prefix.\n     \n     \n \n        Granted, this changes the nature of   (from a function to a method), but it is still just a prefix. If the global function   already exists, we create a temporary object with that function as a single method. Otherwise, we let module   create such an object, via its   function.\n     \n AMD support for browsers \n     RequireJS \n     curl \n universal modules project \n     The basic way of loading a script is inspired by  Nicholas C. Zakas : You insert a script tag into the DOM to trigger the asynchronous loading of a script.\n \n     \n      you cannot easily pass arguments to a script you load. But you need to do so to resolve relative module paths, as modules don’t know their own path. Only the script that loads them does. This assumes that it all starts in an HTML file whose path is   (“here”, against which relative paths   be resolved). \n          Store the unevaluated module data somewhere when the script is executed. Next, process that data via the   handler of the script tag (which is guaranteed to run directly after the script has been loaded). That handler is set by the loader, so one can pass parameters on to it.\n     \n      The very first   must execute the module right away, it cannot store it away for later processing, because there is no   handler and thus no later processing. \n          Count how many modules are currently being loaded. If that count is zero then the module can be evaluated at once.\n     \n AMD support for Node.js universal modules project \n     Its input are the values of   and   from the module that invokes it (the “client module”). You need those values to perform imports and exports for the client. Why imports are needed is not immediately obvious – it is because relative module names must be resolved with the client as the base. \n     Its output is an object with a   method that works for the client module. \n \n     Step 1: Convert the names of the imported modules to objects, via  . \n     Step 2: Call the body of the module that is to be defined, hand in the module objects. \n     Step 3: If the AMD exports anything, then copy the exports to the   object. \n Universal unit tests \n\n   \n \n\n   \nThe pertinent lines are:\n Related reading \n The power of the Asynchronous Module Definition Modules and namespaces in JavaScript  [explains several module patterns and gives an in-depth perspective on modularity in JavaScript] A first look at the upcoming JavaScript modules  [thankfully, these will make all current module systems obsolete, in the long run] JavaScript’s strict mode: a summary JavaScript variable scoping and its pitfalls Universal unit testing (browser, Node.js) with Jasmine comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/node-print-json.html", "title": "Printing objects on Node.js", "content": "Printing objects on Node.js dev nodejs javascript Display a value as JSON data \n  a single line of JSON.\n Use util.inspect() \n  Use   directly.\n \n  Use  , which internally calls  . Drawback: Stops after a nesting depth of 2.\n Further reading JavaScript’s JSON API comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/string-concatenation.html", "title": "String concatenation in JavaScript", "content": "String concatenation in JavaScript dev javascript jslang  operator Joining an array of strings Which one is faster? StringBuilder References “ Re: String concatenation ” – email by Brendan Eich stating that + is faster on modern JavaScript engines. “ Ropes: an Alternative to Strings (1995) ” by Hans-J. Boehm , Russ Atkinson , Michael Plass. chapter “Strings” of ”JavaScript for impatient programmers” comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/enums.html", "title": "Enums for JavaScript", "content": "Enums for JavaScript dev javascript advancedjs jslang thread Using an enum The implementation enums project \n      implements the symbols that an enum holds. Symbols are immutable. \n      implements enums. Each enum is an object that maps symbol names to symbol instances. Enums are immutable. \n \n     The prototype of symbols is frozen (immutable). \n     The prototype of symbols has no prototype. Normally,   would have the prototype   (which comes with several standard methods etc.). But   is mutable which we want to avoid. \n     Instances of   are frozen. \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/strict-mode-hatred.html", "title": "JavaScript: Why the hatred for strict mode?", "content": "JavaScript: Why the hatred for strict mode? dev javascript jslang strict mode \n \nThe funniest example of strict mode hatred is in the RiverTrail code base, where  NBody.js  starts as follows:\n Work-arounds for missing features \n      This statement causes performance and security problems [2]. Work-around: Instead of\n \n        you can use an IIFE [3] and write\n \n     \n      This property was removed due to security concerns (unsafe code should not be able to access its caller). There is no replacement for it, you’ll have to introduce an additional parameter. \n      This property offers a convenient way of accessing the current function inside the function itself, without referring to a global variable or a variable in the surrounding scope.\n \n        A   looks like a function declaration (a statement), but is in fact an expression. It gives the function a name that is only accessible from within the function. That allows you to rewrite the above code as follows:\n \n     \n      This has always been more of a bug than a feature – you could access the global object via   in non-method functions. This can lead to accidentally creating global variables (e.g. if you call a constructor without  ). The following is an example of legitimate use:\n \n        Strict mode does not allow the above –   is   in non-method functions. You can use the following work-around:\n \n        But you might not even need to access the global object inside the IIFE:\n \n     \n      Now 0100 really is 100 and not 64. And 08 is not an error, any more. I can’t imagine that anyone misses octals. \n Related reading JavaScript’s strict mode: a summary JavaScript’s with statement and why it’s deprecated JavaScript variable scoping and its pitfalls comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/real-world-twitter.html", "title": "Real-world Twitter", "content": "Real-world Twitter mobile app iphone computers “Big Words \n \n\nSummary of the app:\n \n     Display a text on your mobile device, in as large a font as possible. \n     Prepare multiple pages, swipe between them. \n     Universal app: works on both iPhone and iPad. \n \n     Pass messages in situations where you cannot talk. \n     In presentations: “You have 5mins left”. \n     Put a comment into a picture (obviously, the iPhone you display the message on cannot be the device you take the picture with). \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/jasmine.html", "title": "Universal unit testing (browser, Node.js) with Jasmine", "content": "Universal unit testing (browser, Node.js) with Jasmine dev javascript jsmodules jslang jstools Bridging the module gap between Node.js and browsers \nThis post gives a quick introduction to the JavaScript unit test framework  . It has the advantage of allowing tests to be run both in browsers and on Node.js.\n \n\n The example project Writing tests Matchers Jasmine documentation Running tests on Node.js npm Running tests in the browser \n Related reading Jasmine homepage jasmine-node on GitHub comments powered by Disqus."},
{"url": "https://2ality.com/2017/05/es-module-specifiers.html", "title": "Module specifiers: what’s new with ES modules?", "content": "Module specifiers: what’s new with ES modules? dev javascript esnext jsmodules \n  Warning: This blog post is outdated! Consult “ ECMAScript modules in Node.js: the new plan ” for the latest information. \n  Complete rewrite of Sect. “ Why a new filename extension for ES modules? ”. \n This blog post describes how module specifiers (the path-like IDs of modules) change with ECMAScript modules (ESM). There are a few subtle differences, compared to the familiar CommonJS module (CJS) style. Why a new filename extension for ES modules?   # Node.js will support ES modules via the new filename extension  . Many web developers would have preferred to stick with  . Let me make the case why   is the better approach. The core thing to keep in mind is: In order to distinguish between CommonJS modules and ES modules, you need   kind of metadata. Browsers face a similar problem, having to distinguish between scripts and modules. They attach the metadata via the attribute   in   elements. Let’s start with approaches that would enable us to keep  . Approaches for keeping     # Specify which files are ESM via  . One interesting aspect of this approach is that its file system layout is different from all other approaches: ESM versions of CJS files are kept in a separate directory whose structure mirrors the structure of the CJS directory.\n \n Cons: It doesn’t work with stand-alone files. And you have to look elsewhere to find out what a given file is. \n \n Detection via parsing : It is possible to parse a file with a grammar that covers both scripts (incl. CommonJS modules) and ES modules. After parsing, one inspects the resulting abstract syntax tree to find out what kind of file one is dealing with.\n \n Con: There are files that could be either CJS or ESM – files that neither import nor export. For example, polyfills that install things into global variables. These must be interpreted differently depending on whether they are CJS or ESM. \n Con: Additionally, this kind of detection affects performance negatively. \n \n A pragma at the beginning of the file (similar to strict mode, e.g.  ). You could combine this approach with detection via parsing and only use a pragma where a file is ambiguous.\n \n Cons: The precedent for pragmas is strict mode. With strict mode, I know that I should use it, but I’m usually too lazy to do so and I don’t like the clutter it adds to my files. Therefore, my conclusion is that the user experience of pragmas is bad. A pragma is something we would use now to distinguish between CJS and ESM. But CJS would disappear in the long run, leaving us with meaningless clutter in legacy files (and possibly current files, too). I’d be OK with pragmas for CJS (i.e., legacy files), but that probably wouldn’t be useful. \n \n One issue with approaches #2 and #3 is that you can’t keep an ESM and a CJS version of a file next to each other (unless you also use approach #1). It feels wrong to me that either human or machine should have to put that much effort into finding out what kind of file they are dealing with. The filename extension     # Using a different filename extension is a simple way of attaching metadata to files. There are many precedents for putting slightly different JavaScript into files with different filename extensions. For example: \n  for React code with JSX \n  for TypeScript files \n  for files to be compiled via Babel (initially popular, now getting out of fashion) \n Why is keeping   desirable?   # Whatever filename extension for modules we’ll end up with, it will be the dominant extension for JavaScript in the future. Thus, moving away from   is visually undesirable. Another argument in favor of keeping   is that tools need to be adapted in order to recognize   files as containing JavaScript. However, I’d argue that most tools need to be changed significantly to meaningfully handle ESM, anyway. Looking at the pros and cons of all approaches, using   is not the best solution, it’s the least bad solution. Module specifiers   # Module specifiers are path-like identifiers for modules. For example: The string   is a module specifier. How do module specifiers change with ESM?   # The key change with ES modules is: All ES module specifiers must be valid URLs In particular, if the filename of a module has an extension then its specifier must have one, too. That is exactly like non-module   elements work today. The following   statements all have legal module specifiers: For compatibility with CommonJS and in preparation for future features, relative paths that don’t start with   or   are not allowed: Best practices   # These are two best practices for writing module specifiers: \n Referring to ES modules stored in local files: include the filename extensions. This applies to both browsers and Node.js. \n \n Browsers don’t care about filename extensions, only about MIME types. Given the importance of npm for client-side development, also switching to   in browsers will help with keeping JavaScript code cross-platform compatible. \n Note that the module specifier   may (among others) refer to:  ,  ,  \n \n \n Referring to ES modules in  : \n \n Node.js: omit the filename extension. The specifier works regardless of whether a module is ESM or CJS. \n Browsers: it’ll be interesting to see how   code will handle   (not much will change for code compiled by tools such as webpack, because such tools can resolve paths at compile time). One option is to map   paths to actual paths via a configuration file (similar to how AMD does it). Another option is to link into   directories. \n \n It’s unclear if   specifiers will eventually have filename extensions, too. Support for   in tools   # Adding support for   to tools is ongoing. For example: \n Babel: https://github.com/babel/babel/pull/5624 \n Babili/babel-minify already supports  : https://github.com/babel/babili/blob/2b1b16ac05596e65ec77c56a1e3e1b7882991341/packages/babili/src/fs.js#L6 \n AVA: https://github.com/avajs/ava/issues/631#issuecomment-299106074 \n Visual Studio Code: https://github.com/Microsoft/vscode/pull/25747 \n For Visual Studio Code, I added this to my workspace settings:  Thanks to  Bradley Farias  for answering my module-specifier-related questions. Further reading   # \n More information on ES modules in Node.js: “ Making transpiled ES modules more spec-compliant ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/04/conditional-literal-entries.html", "title": "Conditionally adding entries inside Array and object literals", "content": "Conditionally adding entries inside Array and object literals dev javascript esnext pattern This blog post shows how you can conditionally add elements inside Array literals and properties inside object literals. Conditionally adding elements inside Array literals   # The following code shows how a boolean   determines whether or not the element   is added to the Array  . This trick works, because the spread operator ( ) for Array literals does nothing if its operand is an empty Array: Conditionally adding properties inside object literals   # You can use  the proposed spread operator for properties  in the same manner. Again, a boolean   determines whether the property   is added to the object  : The spread operator for object literals does nothing if its operand is an object without enumerable own properties: Is it worth it?   # Using the spread operator in this manner leads to slightly cryptic code. Here it is again, for ease of reference: The crypticity can be worth it if you want to create the Array with a single expression. Different approaches   # Less cryptic would be to create the Array with the unconditional elements first and to then conditionally insert elements, via  . But that leads to error-prone code, because you have to manage indices properly (insert the last one of multiple elements first, etc.). An elegant and self-descriptive solution is to use   to construct the Array: Variations of the original approach   # A variation of the original approach is to use spread and a helper function: In line A, the triple dots are  the rest operator  which collects the remaining arguments in an Array and assigns it to  . Another alternative is to conditionally insert either elements or  s and to then filter the latter values out: Further reading   # \n Sect. “ The spread operator ( ) ” in “Exploring ES6” \n ES proposal: Rest/Spread Properties \n Sect. “ Rest parameters ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/04/mastodon.html", "title": "Mastodon: like Twitter, but open and federated", "content": "Mastodon: like Twitter, but open and federated computers decentralized mastodon “Getting started with Mastodon” Mastodon  is like Twitter, but federated and based on open protocols. This blog post explains what that means and what it is like to use Mastodon. It also gives tips for using it. Social media: why are federated services better than centralized ones?   # To technical users, federation is an easy sell. I find it surprisingly hard to explain the benefits to non-technical users, though. And that’s because centralized services are usually easier to use: It’s easier to get started as a new user and easier to find things (users, data, etc.) – simply because everything exists within a single system. Let’s quickly review the differences between centralized and federated services: \n Centralized (Twitter, Facebook): a single service manages the data of all users and their communications. \n Federated (email): multiple services manage user data and collaborate to enable users to communicate with each other. \n So what are the benefits of federated services? \n Freedom: No single company controls server and client. You can choose both. \n Competition: between multiple implementations of servers and clients is good for innovation. For example, many important parts of Twitter originated in third-party clients (which have since seen their freedom reduced by Twitter). [ source 1 ,  source 2 ]\n \n Things that were invented by Twitter’s users [ source ]: @-replies, hashtags, retweets \n \n \n Robustness: If Twitter disappears, nobody is able to tweet anymore. Compare this with email: an email server disappearing doesn’t mean email is dead. The network will survive. \n No ads: One of the guiding principle of Mastodon is that there must be no ads. \n Mastodon: welcome to the fediverse!   # Mastodon is based on the OStatus suite of protocols (explained later in this article). Servers based on OStatus include: \n GNU Social \n Friendica \n buddycloud \n Mastodon is also based on OStatus. All OStatus servers can talk to each other. The network of those servers is called the  . How does Mastodon work?   # Getting started is relatively simple: Find a Mastodon server to join.  A page on   lists servers by community (Regional, Technology, etc.). Go to the server, sign up. You only need to enter: email address, local user name and password. You get an email with a link that you need to click to authenticate yourself. Most servers now review applications, which means you may have to wait after finishing these steps. Referring to Mastodon accounts   # Within a toot, you refer to accounts on the local server via  . Accounts on other servers can be mentioned via  . When a toot is displayed, only local names (e.g.   and  ) are shown, which reduces visual clutter. Two formats are common for writing down account IDs: I’m not sure #1 is a good idea, because it is easily confused with email addresses. If you use that format, you should prefix an  , like Mastodon does in profiles. A short glossary of Mastodon terms   # \n Instance: a Mastodon server. \n Toot: a post, a tweet. \n Tooting: posting, tweeting. \n Boosting: sharing a post in your timeline, retweeting. \n Fediverse: the network of all servers that Mastodon servers can communicate with. \n Yes, these do sound corny. I wish they could find a better word for “toot”. Additionally, I think boosting shouldn’t be its own term, it should be either sharing or retooting. Timelines   # The following are three important Mastodon timelines: \n Home: works much like timelines on Twitter and Facebook. Here you see all toots from people you follow. \n Local timeline: all toots from people hosted by the current server. \n Federated timeline: the local timeline plus toots from other – federated – servers that are seen by users on the current server. That is, if you follow someone on another server, their public tweets appear in the federated timeline. \n The local and federated timelines tend to get really busy. I’m ignoring them and using Mastodon like Twitter. Servers form communities   # Many Mastodon servers form communities and thus bring back a sense of location to social networking. The administrators of servers also serve as moderators. Therefore, picking a server enables you to choose levels and ways of protection and filtering. It also lets you choose what people you want to be “surrounded with”. But you also have the option of mostly ignoring the community aspect of servers and to use Mastodon like Twitter. Privacy   # For each toot, you can specify how widely it should be distributed: \n Direct: only mentioned users see it. \n Private: only followers see it. \n Unlisted: everyone sees it, but it doesn’t show up in local and federated timelines. \n Public: it shows up everywhere. \n This kind of per-toot privacy setting is nice, because you don’t need separate accounts, like on Twitter. However, it comes with several big caveats: \n The administrators of servers can see everything – all your toots even the direct ones. This sounds scary, but is not much different from services such as Twitter and Facebook that don’t provide end-to-end encryption. Administrators even have complete access to your account and could impersonate you (etc.). So you should really trust them. \n Any server who accesses your account can see all your toots. \n You can’t delete toots that were federated to other servers. \n It is best to assume that all your toots can be read by everyone, forever. Moderation   # Admins can block users and have two ways of blocking instances (and therefore communities): \n Silencing: People on a silenced server can still be followed by people on the local server, but they don’t show up in federated timelines and can’t @-mention people who don’t follow them. \n Suspending: The server is completely banned. You can follow people on that server, but you’ll never see any of their toots. \n Some servers publish what they block. For example,  this is toot.cafe’s list of blocked instances . The role of search engines   # Search engines could play an important role for federated social networks and help with two of their weaknesses: \n Searching content \n Finding users \n They would simply crawl Mastodon servers the way they crawl the web. It may even be a kind of social network that Google is willing to support: They are not in control, but neither is Facebook. And the data is openly accessible. Tips for using Mastodon   # First steps   # \n Pick a local user name that is as unique as possible. This makes it easier to keep the name when moving to a different server. \n To follow someone, use the search function to find them. Searching for a user’s real name will only work if they are on the same server or cached on that server. Otherwise, you need a user’s URI or global ID. \n Do write a biography. Surprisingly few people do so, but it helps to give you a rough image of who someone is. For example, you could just mention stuff you are interested in and where you are located. \n Don’t animate your avatar image. Mastodon lets you do that, but it’s very distracting. \n To introduce yourself, write a toot hashtagged with  . At least users at the local instance can search for it, it may also get propagated elsewhere. \n Finding people to follow   # Tips for finding people to follow: \n Use the  Mastodon bridge : On this site, you log in via Twitter and via Mastodon and then see which of the people you follow are also on Mastodon. Obviously, they only appear in that list if they have used the bridge. \n Like on Twitter, you can start with a few people and then find more, over time, via boosted toots. \n Take a look at the local and federated timelines. \n Writing toots   # \n Use content warnings (“cw” icon): These warnings mean you must click to see the actual content of a toot. The social norm on Mastodon is to use content warnings for:\n \n Animated graphics: which are distracting and can even cause seizures for some people. \n Politics: Many people find discussing politics depressing at the moment. With a content warning, you give people the option to ignore. \n \n \n I’ve also seen people use content warnings when they vent about stuff. I like that idea, because venting is rarely useful information. Various other tips   # \n Clicking on the date of a post leads you to a separate page. Click on the text/body of the post to see its thread.\n \n Paste a post’s URI into the search field to force-fetch its thread. \n \n \n Moving to a different server is easy: just register there. However, you lose all your follows and your followers. The former can be exported. The latter can be notified via the following trick:\n \n Change your display name to “(Old account)”. \n Mention your new ID in your profile and in your last post. \n \n \n Likes, dislikes, wishes   # Things I like about Mastodon   # \n Having a federated service is awesome. I’ve waited years for an open alternative to Twitter. And Mastodon could really be it. \n It’s amazing how well federation works. I am following several people from other servers and I am not able to tell that they are hosted somewhere else. Let’s hope federation will scale to millions of followers. \n Posts on Mastodon can be up to 500 characters long. It’s good to have more room to express your thoughts. The limit ensures that posts don’t become too verbose. \n The web app is responsive and works well on desktops, tablets and phones. Once again, the web excels as an app platform. \n Things that can be improved   # \n Mastodon’s nomenclature is unnecessarily weird: a post on it is called a “toot”; writing a post is called “tooting”; mentioning/retweeting a post is called “boosting”. \n Data from profiles from other servers never seems completely up-to-date, especially the number of followers. The same holds for toot data (number of boosts and likes, etc.).\n \n If you want to see the exact figures and all replies, you need to display profiles and toots in external web pages. \n Given that this information is collected at the tooter’s server, in a single location, I’d expect that this issue will eventually be solved. \n \n \n It’s relatively difficult to keep track of what toots and notifications you’ve already seen. Most Twitter clients do this better. \n Wishes   # Feature wishes: \n Automatic posting, either from Twitter to Mastodon or from Mastodon to Twitter. That would it make easer to fill Mastodon with content, while still taking care of one’s Twitter audience (which most people can’t afford to abandon). \n Notifications don’t scale as well as they do on Twitter, where they are more aggregated. I’d like to have an extra view for mentions (which are the most important kind of notification). \n For now, the Mastodon bridge works for finding users. In the long run, there should be a centralized service that helps here. This could be achieved via a registry and by crawling web sites for embedded microdata. \n It’d be great if toots could be commented like you can on Twitter. An embedded toot URL should:\n \n Send a notification to the author of the referenced toot. \n Show the content of the embedded toot inside the embedding toot. \n \n \n Advanced features: \n I’m missing features provided by TweetDeck: scheduling tweets and teams (a single account being shared by several people). \n There could be automated support for migrating to a different server. \n End-to-end encryption would be nice to have. But I’m not sure how compatible it is with its approach to networking. Before that, we’ll probably get tools for encrypting single toots. \n The OStatus suite of protocols (Mastodon’s foundation)   # In principle, every OStatus user publishes Atom (which is similar to RSS) feeds of microposts and every OStatus client is like an RSS reader. Several standards and protocols complement Atom and enable more functionality: \n Activity Streams : an XML vocabulary that lets you express activities on social objects (“Jane posted a photo to the ‘Interesting Food’ album”) within Atom. \n Atom Threading Extensions : to represent threaded discussions within Atom. \n Portable Contacts : for exchanging contact information. \n PubSubHubbub : lets you subscribe to feeds. Whenever a feed is updated, you get notified. This means updates reach you much faster. Wordpress and others also support this protocol. \n Salmon : sends items from Atom feeds to parties that are affected by them. For example: a user mentioned in a post is sent that post; a reply to a post is sent to the author of that post; a user is told if they have a new follower. The notifications “swim upstream”; hence the name “Salmon”. Salmon is based on Activity Streams. \n Webfinger : lets you look up information about people via URIs. The information is encoded as JSON and can provide data such as homepage, telephone number or avatar image. \n Mastodon being compatible with OStatus means that you can seamlessly follow users from other OStatus-based social networks. Conclusions   # Mastodon is the first federated social network that feels viable to me. On one hand, it’s UX is decent – all previous federated social network I’ve tried were awkward to use. On the other hand, the recent increase in popularity helps, too. Three critical issues will be: Will Mastodon scale as its popularity grows? Will Mastodon remain financially viable? Will anti-harassment measures work? In all three cases, things will evolve and lessons will be learned. But it’s great that we are making progress in the area of federated social networks. Monetization is interesting, because there are no ads in Mastodon, nor will there ever be. If you want to support its development, you should donate to its author Gargron:  via Patreon, PayPal or Bitcoin . Some people running Mastodon servers are also accepting donations. Some are promising to pass on money to Mastodon, once their costs are covered. I’d also be OK with servers charging for hosting accounts. I think corporate support can coexist with the open source nature of Mastodon. It may even be beneficial to its long-term survival. Resources   # \n Mastodon’s GitHub repository \n Blog by Eugen Rochko , Mastodon’s creator. \n “ Mastodon is dead in the water ” by John Henry. Mentions a few potentially negative aspects of Mastodon. None of those seem unfixable to me. We’ll also have to wait and see how everything evolves. \n  Thanks to all the people on Mastodon who answered my Mastodon-related questions as I continue to learn more about it! Among others:  @Gargron ,  @nolan ,  @KitRedgrave  and  @HedgeMage . comments powered by Disqus."},
{"url": "https://2ality.com/2017/04/transpiling-dependencies-babel.html", "title": "Transpiling dependencies with Babel", "content": "Transpiling dependencies with Babel dev javascript esnext npm jsmodules babel This post is part of a series of three: Current approaches: “ Setting up multi-platform npm packages ” Motivating a new approach: “Transpiling dependencies with Babel” Implementing the new approach: “ Delivering untranspiled source code via npm ” Figuring out the best strategy for transpiling with Babel is tricky. This blog post proposes a new strategy, made possible by  Babel’s  . The vision   # For a while, the best approach for building web apps via webpack was: \n App code: transpiled via Babel and  :\n \n Input: JavaScript with stage 4 features or older, in ES modules. \n Output: ES5 in CommonJS modules. \n \n \n Dependencies: are already transpiled. \n Then Babel introduced  , which lets you adapt the code you generate to the platforms it will run on. Now, the best approach would be: \n App code: transpiled via Babel and  .\n \n Input: JavaScript with stage 4 features or older, in ES modules. \n Output: whatever JavaScript runs best on the target platforms. \n \n \n Dependencies: must be delivered as both...\n \n Transpiled code that runs natively on Node.js (meaning CommonJS modules, at the moment). \n Untranspiled code that is transpiled along with your own code. \n \n \n The benefits of this new approach are: \n ES modules enable tree-shaking (which, in general, is impossible with CommonJS modules). \n The output is upgraded automatically as the target platforms evolve (thanks to  ). \n You can target multiple platforms. \n Implementing the vision   # How can we deliver both transpiled and untranspiled code in npm packages? The status quo   # Three properties in   currently let you deliver multiple versions of the same code (for more information, consult “ Setting up multi-platform npm packages ”): \n : points to a CommonJS module (or UMD module) with JavaScript as modern as Node.js can currently handle. \n : swaps out some of the   code so that it works in browsers. \n : the same code as  , but in ES modules. \n : untranspiled ES6 code. Introduced by Angular. \n Alas, none of these properties help with delivering untranspiled code beyond ES6 ( ) or beyond what’s currently supported in Node.js ( ). Proposal:     #  is an abbreviation for “property   in  ”. I propose to use   as follows: \n : source code using stage 4 features (or older), not transpiled, in ES modules. \n  continues to be used the same way. Its code can be generated from the untranspiled code. \n Most   use cases should be handleable via  . \n  can be handled via an extended version of   (see next section). \n The next blog post in this series  describes how to implement this approach. This is an excerpt of a   using the new property: Extended versions of     # An extended version of   could be a JSON object with two properties: \n : points to the untranspiled code. \n : points to browser-specific untranspiled code. \n This would look as follows: Other solutions   # webpack can be configured to recognize alternatives to   ( via  ). That enables you to refer to untranspiled code via  . Note that that is not exactly how   is supposed to be used, but it lets you use packages with that property. And the following solutions become possible: \n webpack contributor Sean Larkin always transpiles all dependencies. This increases build times, but has the advantage of being easy to configure. \n Jason Miller proposes to tell webpack to transpile only packages that have  , via clever use of   and  . He documented his approach in  a Gist . \n Sam Verschueren has written  the Babel plugin  , which only transpiles packages that depend on Node.js versions newer than 0.10 (with features beyond ES5). To do so, it checks  . This plugin could be adapted to support the new approach outlined in this blog post. \n Yet another quick-and-dirty approach is to use file extensions: \n  is never transpiled. \n  is always transpiled, even in npm-installed dependencies. It’s best not to use  the upcoming file extension  , so that future code doesn’t break packages using this approach. \n This approach is especially handy if your own app is spread out across multiple npm packages. Further reading   # \n : a preset that configures Babel for you \n Setting up multi-platform npm packages \n Making transpiled ES modules more spec-compliant  (more information on  ) \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/04/flatmap.html", "title": "ES2019: Functional pattern – flatMap", "content": "ES2019: Functional pattern – flatMap dev javascript es2019  The following new Array methods were just added to ECMAScript 2019 (based on  a proposal by Michael Ficarra, Brian Terlson, Mathias Bynens ): \n The new Array method   is equivalent to the function   described in this blog post. \n The new Array method   is equivalent to the function   described in this blog post. \n In this blog post, we look at the operation  , which is similar to the Array method  , but more versatile.    # Both   and   take a function   as a parameter that controls how an input Array is translated to an output Array: \n With  , each input Array element is translated to exactly one output element. That is,   returns a single value. \n With  , each input Array element is translated to zero or more output elements. That is,   returns an Array of values. \n This is an implementation of  :  is simpler if   is only allowed to return Arrays, but we don’t impose this restriction here, because non-Array values are occasionally useful (see  the section on   for an example). To demonstrate how   works, we use the helper function  : This is   in action: This is   in action: What is   good for? Let’s look at use cases! Use case: filtering and mapping at the same time   # The result of the Array method   always has the same length as the Array it is invoked on. That is, its callback can’t skip Array elements it isn’t interested in. The ability of   to do so is useful in the next example:   returns an Array where each element is either a wrapped value or a wrapped error.  enables us to extract just the values or just the errors from  : Use case: mapping to multiple values   # The Array method   maps each input Array element to one output element. But what if we want to map it to multiple output elements? That becomes necessary in the following example: The React component   is invoked with two attributes. The attributes are: \n An Array of tags, each tag being a string. \n A callback for handling clicks on tags. \n  is rendered as a series of links separated by commas: In line A, we are conditionally inserting the Array element   via the spread operator ( ). This trick is explained in  another blog post . Due to  ,   is rendered as a single flat Array. The first tag contributes one element to this Array (a link); each of the remaining tags contributes two elements (comma and link). Other versions of     # Arbitrary iterables   #  can be generalized to work with arbitrary iterables:  function works with Arrays: In line A, we translate the iterable returned by   into an Array, via the spread operator ( ). One nice trait of   is that it works incrementally: as soon as the first input value is available, output is produced. In contrast, the Array-based   needs all of its input to produce its output. That can be demonstrated via the infinite iterable created by the generator function  : In line A, we extract the first 5 values of   via destructuring. Implementing   via     # You can use the Array method   to implement a simple version of  : I prefer the original version of  , because it is easier to understand. Related to  :     #  is an operation that concatenates all the elements of an Array: It can be implemented as follows: Using   and flattening the result is the same as using  . That is, the following two expressions are equivalent: Similarly, using   with the   ( ) is the same as using  . That is, the following two expressions are equivalent: The next subsections cover use cases for  . Use case: conditionally inserting values into an Array   # The following code only inserts   if   is  : For more information on conditionally inserting Array elements, consult the blog post “ Conditionally adding entries inside Array and object literals ”. Use case: filtering out failures   # In the following example,   only returns the texts that could be downloaded.  first maps each URL to a Promise resolving to either: \n An Array with the successfully downloaded text (line C) \n An empty Array (line D) \n  (line A) converts the Array of Promises into a Promise that resolves to a nested Array.   (line A) unwraps that Promise and   un-nests the Array (line B). Note that we couldn’t have used   here, because of the barrier imposed by the Promises returned by  : when it returns a value, it doesn’t know yet if it will be a text or an empty Array. Further reading   # \n “ A collection of Scala ‘flatMap’ examples ” by Alvin Alexander \n Sect. “ Transformation Methods ” (which include  ) in “Speaking JavaScript”. \n Conditionally adding entries inside Array and object literals  [loosely related to what is covered in this blog post] \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/05/regexp-lookbehind-assertions.html", "title": "ES2018: RegExp lookbehind assertions", "content": "ES2018: RegExp lookbehind assertions dev javascript esnext es2018 regexp The proposal “ RegExp Lookbehind Assertions ” by Gorkem Yakin, Nozomu Katō, Daniel Ehrenberg is part of ES2018. This blog post explains it. A   is a construct inside a regular expression that specifies what the surroundings of the current location must look like, but has no other effect. It is also called a  . The only lookaround assertion currently supported by JavaScript is the  , which matches what follows the current location. This blog post describes a proposal for a  , which matches what precedes the current location. Lookahead assertions   # A lookahead assertion inside a regular expression means: whatever comes next must match the assertion, but nothing else happens. That is, nothing is captured and the assertion doesn’t contribute to the overall matched string. Take, for example, the following regular expression It matches the string  , but the overall matched string does not include the b’s: Furthermore, it does not match a string that doesn’t have two b’s: A negative lookahead assertion means that what comes next must   match the assertion. For example: Lookbehind assertions   # Lookbehind assertions work like lookahead assertions, but in the opposite direction. Positive lookbehind assertions   # For a positive lookbehind assertion, the text preceding the current location must match the assertion (but nothing else happens). As you can see,   is only replaced if it is preceded by a dollar sign. You can also see that the dollar sign is not part of the total match, because the latter is completely replaced by  . Achieving the same result without a lookbehind assertion is less elegant: And this approach doesn’t work if the prefix should be part of the previous match: Negative lookbehind assertions   # A negative lookbehind assertion only matches if the current location is   preceded by the assertion, but has no other effect. For example: There is no simple (general) way to achieve the same result without a lookbehind assertion. Conclusions   # Lookahead assertions make most sense at the end of regular expressions. Lookbehind assertions make most sense at the beginning of regular expressions. The use cases for lookaround assertions are: \n \n  (especially if the regular expression has the flag  ) \n  (note the space at the beginning of  ): \n \n Other than those use cases, you can just as well make the assertion a real part of the regular expression. Further reading   # \n V8 JavaScript Engine: RegExp lookbehind assertions \n Section “ Manually Implementing Lookbehind ” in “Speaking JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/05/regexp-named-capture-groups.html", "title": "ES2018: RegExp named capture groups", "content": "ES2018: RegExp named capture groups dev javascript esnext es2018 regexp The proposal “ RegExp Named Capture Groups ” by Gorkem Yakin, Daniel Ehrenberg is at  stage 4 . This blog post explains what it has to offer. Before we get to named capture groups, let’s take a look at numbered capture groups; to introduce the idea of capture groups. Numbered capture groups   # Numbered capture groups enable you to take apart a string with a regular expression. Successfully matching a regular expression against a string returns a match object  . Putting a fragment of the regular expression in parentheses turns that fragment into a  : the part of the string that it matches is stored in  . Prior to this proposal, all capture groups were accessed by number: the capture group starting with the first parenthesis via  , the capture group starting with the second parenthesis via  , etc. For example, the following code shows how numbered capture groups are used to extract year, month and day from a date in ISO format: Referring to capture groups via numbers has several disadvantages: Finding the number of a capture group is a hassle: you have to count parentheses. You need to see the regular expression if you want to understand what the groups are for. If you change the order of the capture groups, you also have to change the matching code. All issues can be somewhat mitigated by defining constants for the numbers of the capture groups. However, capture groups are an all-around superior solution. Named capture groups   # The proposed feature is about identifying capture groups via names: Here we have tagged the previous capture group #1 with the name  . The name must be a legal JavaScript identifier (think variable name or property name). After matching, you can access the captured string via  . The captured strings are not properties of  , because you don’t want them to clash with current or future properties created by the regular expression API. Let’s rewrite the previous code so that it uses named capture groups: Named capture groups also create indexed entries; as if they were numbered capture groups: Destructuring  can help with getting data out of the match object: Named capture groups have the following benefits: \n It’s easier to find the “ID” of a capture group. \n The matching code becomes self-descriptive, as the ID of a capture group describes what is being captured. \n You don’t have to change the matching code if you change the order of the capture groups. \n The names of the capture groups also make the regular expression easier to understand, as you can see directly what each group is for. \n You can freely mix numbered and named capture groups. Backreferences   #  in a regular expression means: match the string that was previously matched by the named capture group  . For example: The backreference syntax for numbered capture groups works for named capture groups, too: You can freely mix both syntaxes:  and named capture groups   # The string method   supports named capture groups in two ways. First, you can mention their names in the replacement string: Second, each replacement function receives an additional parameter that holds an object with data captured via named groups. For example (line A): These are the parameters of the callback in line A: \n  contains the whole matched substring,  \n ,  ,   are matches for the numbered groups 1–3 (which are created via the named groups  ,  ,  ). \n  specifies where the match was found. \n  contains the complete input string. \n The last parameter is new and contains one property for each of the three named capture groups  ,   and  . We use destructuring to access those properties. \n The following code shows another way of accessing the last argument: We receive all arguments via the rest parameter  . The last element of the Array   is the object with the data from the named groups. We access it via the index  . Named groups that don’t match   # If an optional named group does not match, its property is set to   (but still exists): Implementations   # \n The Babel plugin   by Dmitry Soshnikov supports named capture groups. \n V8 6.0+ has  support behind a flag . \n The relevant V8 is not yet in Node.js (7.10.0). You can check via: In Chrome Canary (60.0+), you can enable named capture groups as follows. First, look up the path of the Chrome Canary binary via the   URL. Then start Canary like this (you only need the double quotes if the path contains a space): Further reading   # \n Chapter “ Regular Expressions ” in “Speaking JavaScript” \n Chapter “ New regular expression features ” in “Exploring ES6” \n Chapter “ Destructuring ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/06/pkg-esnext.html", "title": "Delivering untranspiled source code via npm", "content": "Delivering untranspiled source code via npm dev javascript esnext npm jsmodules babel webpack This post is part of a series of three: Current approaches: “ Setting up multi-platform npm packages ” Motivating a new approach: “ Transpiling dependencies with Babel ” Implementing the new approach: “Delivering untranspiled source code via npm” The idea of   is brilliant: write JavaScript with stage 4 features (or earlier stages, if you want to take that risk) and transpile it so that it is an exact fit for your target platform(s). However, at the moment,   only works for your own app, but not for your dependencies, which are normally already transpiled. This blog post shows how package authors and package users can use the   property   to work with untranspiled source code in npm packages. The code is available in the repository   on GitHub.  I wish there were no need for a new property, but, as I explain  elsewhere ,   and   do not work for this use case: \n  is restricted to what is currently supported by Node.js. \n  is only for untranspiled ES6 code (and not ES2016+ code). \n In other words: both properties are close to what we want, but if we want to comply completely with their specifications then we can’t use them. Package authors   # If your npm package has untranspiled source code, you point to it via  :  is usually transpiled from  . E.g., via   and  . Package users   # As a package user, you can work with   by adapting   in two locations. First, you need to make sure that webpack finds source code pointed to via  : Second, you need to tell Babel that it should transpile all of the app code, but only those   files in dependencies whose   files have the property  . A preliminary solution   # If you are a consumer of npm packages, you can adopt a preliminary solution until your dependencies support   (or another solution becomes popular): transpile   in the same manner. For example, by changing line A in the previous code to: Due to   pointing to an ES module, it is safe to transpile. Transpiling CommonJS modules is more tricky: strict mode and possibly other transpilation hazards can break things. Further reading   # \n : a preset that configures Babel for you \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/05/util-promisify.html", "title": "Node.js 8:  util.promisify()", "content": "Node.js 8:  dev javascript nodejs esnext async promises Node.js 8  has a new utility function:  . It converts a callback-based function to a Promise-based one.  in action   # If you hand the path of a file to the following script, it prints its contents. Note how, in line A, the script uses   to convert the callback-based function   to the Promise-based function  . The following interaction shows how the script is used: Using an async function   # The same functionality, but implemented via an async function: Promisifying functions whose callbacks have more than two parameters   # The callbacks of the following functions receive more than one result value (in addition to the error value): \n \n \n \n \n \n \n If you promisify one of these functions, it returns an object of values (not a single value). For example, the callback of   has the following callback parameters: \n \n \n \n Its promisified version fulfills its Promise with an   object:  handles non-standard callbacks via the internal symbol  . Given that non-standard callbacks are not recommended, you should never need this mechanism for your own functions. Custom promisified functions   # The API of   comes with the symbol  , which lets you attach a promisified version to a callback-based function. In the following example,   is the promisified version of  . Standard functions with custom promisified versions   # At the moment, two standard functions have promisified versions:  needs help here, because these functions have the callback as the first parameter – against Node.js conventions: \n \n \n A polyfill for older versions of Node.js   # Jordan Harband has created  a polyfill for  . It works as follows. Requirements: \n Engine must support at least ES5 \n A global   constructor \n Warning: still work in progress \n Installation: There are two main ways of using this polyfill. First: retrieve either the built-in implementation (Node 8) or a polyfill (older versions of Node). Second: patch module   on older versions of Node. Further reading   # \n Node.js documentation:  \n Blog post “ Two ES6 features that help with CommonJS modules ” \n Chapter “ Promises for asynchronous programming ” in “Exploring ES6” \n Chapter “ Async functions ” in “Exploring ES2016 and ES2017” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/07/regexp-unicode-property-escapes.html", "title": "ES2018: RegExp Unicode property escapes", "content": "ES2018: RegExp Unicode property escapes dev javascript esnext es2018 regexp The proposal “ RegExp Unicode Property Escapes ” by Mathias Bynens is at  stage 4 . This blog post explains how it works. Overview   # JavaScript lets you match characters by mentioning the “names” of sets of characters. For example,   stands for “whitespace”: The proposal lets you additionally match characters by mentioning their Unicode character properties (what those are is explained next) inside the curly braces of  . Two examples: As you can see, one of the benefits of property escapes is is that they make regular expressions more self-descriptive. Additional benefits will become clear later. Before we delve into how property escapes work, let’s examine what Unicode character properties are. Unicode character properties   # In the Unicode standard, each character has   – metadata describing it. Properties play an important role in defining the nature of a character. Quoting  the Unicode Standard, Sect. 3.3, D3 : The semantics of a character are determined by its identity, normative properties, and behavior. Examples of properties   # These are a few examples of properties: \n : a unique name, composed of uppercase letters, digits, hyphens and spaces. For example:\n \n A:  \n 😀:  \n \n \n : categorizes characters. For example:\n \n x:  \n $:  \n \n \n : used for marking invisible spacing characters, such as spaces, tabs and newlines. For example:\n \n \\t:  \n π:  \n \n \n : version of the Unicode Standard in which a character was introduced. For example: The Euro sign € was added in version 2.1 of the Unicode standard.\n \n €:  \n \n \n : a contiguous range of code points. Blocks don’t overlap and their names are unique. For example:\n \n S:   (range U+0000..U+007F) \n Д:   (range U+0400..U+04FF) \n \n \n : is a collection of characters used by one or more writing systems.\n \n Some scripts support several writing systems. For example, the Latin script supports the writing systems English, French, German, Latin, etc. \n Some languages can be written in multiple alternate writing systems that are supported by multiple scripts. For example, Turkish used the Arabic script before it transitioned to the Latin script in the early 20th century. \n Examples:\n \n α:  \n א:  \n \n \n \n \n Types of properties   # The following types of properties exist: \n Enumerated property: a property whose values are few and named.   is an enumerated property. \n Closed enumerated property: an enumerated property whose set of values is fixed and will not be changed in future versions of the Unicode Standard. \n Boolean property: a closed enumerated property whose values are   and  . Boolean properties are also called  , because they are like markers that characters either have or not.   is a binary property. \n Numeric property: has values that are integers or real numbers. \n String-valued property: a property whose values are strings. \n Catalog property: an enumerated property that may be extended as the Unicode Standard evolves.   and   are catalog properties. \n Miscellaneous property: a property whose values are not Boolean, enumerated, numeric, string or catalog values.   is a miscellaneous property. \n Matching properties and property values   # Properties and property values are matched as follows: \n Loose matching: case, whitespace, underscores and hyphens are ignored when comparing properties and property values. For example,  ,  ,  ,   are all considered to be the same property. \n Aliases: the data files   and   define alternative ways of referring to properties and property values.\n \n Most aliases have long forms and short forms. For example:\n \n Long form:  \n Short form:  \n \n \n Examples of property value aliases (per line, all values are considered equal):\n \n ,  \n ,  \n ,  ,  ,  \n ,  ,  ,  \n \n \n \n \n Unicode property escapes for regular expressions   # Unicode property escapes look like this: Match all characters whose property   has the value  : \n Match all characters that do not have a property   whose value is  : \n Match all characters whose binary property   is True: \n Match all characters whose binary property   is False: \n Forms (3) and (4) can also be used as an abbreviation for  . For example:   is an abbreviation for   In order to use property escapes, regular expressions must have the flag  . Prior to  ,   is the same as  . Details   # Things to note: \n Property escapes do not support loose matching. You must use aliases exactly as they are mentioned in   and  \n Implementations must support at least the following Unicode properties and their aliases:\n \n \n \n \n The binary properties  listed in the specification  (and no others, to guarantee interoperability). These include, among others:  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  . \n \n \n Examples   # Matching whitespace: Matching letters: Matching Greek letters: Matching Latin letters: Matching lone surrogate characters: Note that Unicode code points in astral planes (such as emojis) are composed of two JavaScript characters (a leading surrogate and a trailing surrogate). Therefore, you’d expect the previous regular expression to match the emoji 😀, which is all surrogates: However, with the   flag, property escapes match code points, not JavaScript characters: In other words, 😀 is considered to be a single character: Trying it out   # V8 5.8+ implement this proposal, it is switched on via  : \n Node.js:  \n \n Check Node’s version of V8 via  \n \n \n Chrome:\n \n Go to  \n Check the version of V8. \n Find the “Executable Path”. For example:  \n Start Chrome:  \n \n \n Further reading   # JavaScript: \n “ Unicode and JavaScript ” (in “Speaking JavaScript”) \n Regular expressions: “ New flag   (unicode) ” (in “Exploring ES6”) \n The Unicode standard: \n Unicode Technical Report #23:  The Unicode Character Property Model  (Editors: Ken Whistler, Asmus Freytag) \n Unicode® Standard Annex #44:  Unicode Character Database  (Editors: Mark Davis, Laurențiu Iancu, Ken Whistler) \n Unicode Character Database:  ,  ,  \n “ Unicode character property ” (Wikipedia) \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/javascript-classes.html", "title": "Myth: JavaScript needs classes", "content": "Myth: JavaScript needs classes esnext dev javascript \n     [2012-03-17] I completely rewrote this post and changed its name (which previously was “JavaScript does not need classes”). \n     [2012-07-29] Classes  have been accepted  for ECMAScript.next. \n     [2012-10-03] Since this article has been written, it was decided that ECMAScript will have the  special property   instead of the   operator.\n     \n     [2013-10-21] Instead of the extension operator, ECMAScript.next will have the function  .\n     \n Prototypal inheritance is simple singleton pattern \n , simpler than classes. What makes JavaScript so complicated is that this core idea is obscured by trying to make the creation of instances (of a given type) look like Java. The core idea of prototypal inheritance is: an object can point to another object and thus make it its  . If a property isn’t found in the object, the search continues in the prototype (and, if it has one, its prototype, etc.). That allows one to model   and   as “instances” of  :\n \nAbove, we have set up   and   manually, an   is a factory for instances. In class-based languages, classes are exemplars. In JavaScript, the standard exemplars are constructors (functions). But one can also use objects as exemplars. The following sections explain both kinds of exemplars.\n\n Instance factories: function exemplars Subtyping and constructors here libraries \nIt is interesting to note that even with subtyping, instances still are easy to understand: The following is the structure of the instance  .\n \n \nClass-based languages have two relationships:\n \n      is an inheritance relationship between an instance and a class. It lets the class provide the methods for the instance.\n     \n      is an inheritance relationship between a subclass and a superclass. It lets the subclass inherit the superclass’s methods.\n     \n Improving constructors: minor language additions proposed    (read as “is extended by”):\n \n        The constructor   extends the constructor  .\n     \n \n        adds properties to an object instead of replacing it:\n \n        Afterwards,   has the value\n \n      for object initializers:\n \nis an abbreviation for\n \n     Instance factories: object exemplars [1] \nFor the above to work, you only need to adapt the following things:\n \n     The inheritance operator   must work for objects, too. Then it sets the prototype of an object. \n      must accept objects as operands, not just functions. \n      must allow objects as its right-hand side, not just functions. \n      works the same for function exemplars and object exemplars: It looks for the super-property starting in the prototype of where the current method is located. \n \n  The main advantage of object exemplars is that they are a good fit for prototypal inheritance, because you can work directly with prototypes. In contrast, with constructors, there is always an indirection after the creation of an instance: You now always need the constructor to access the prototype. The following examples demonstrate this difference between function exemplars and object exemplars:\n \n      \n         \n     \n    \n     \n         \n     \n\n     \n         \n     \n\n     \n         \n     \n Syntactic sugar for exemplars: class declarations Maximally Minimal Classes \n      such as non-method properties in prototypes.\n     \n      Simply having a single standard way of doing inheritance (as opposed to numerous APIs) will be a boon in this department.\n     \n      Class declarations are a dedicated construct for exemplars that is easy to understand by beginners.\n     \n Desugar to function exemplars or to object exemplars? Conclusion Make it easier to work with constructors: As we have seen, only a few new language features can make a large difference.\n     Introduce object exemplars: use prototypes as classes.\n     Related reading \n Prototypes as classes – an introduction to JavaScript inheritance  [explains object exemplars in detail, under their former name “prototypes as classes”; includes a library for ECMAScript 5] ECMAScript.next: the “TXJS” update by Eich  [an overview of what’s currently planned for ECMAScript.next a.k.a. ECMAScript 6] comments powered by Disqus."},
{"url": "https://2ality.com/2011/10/javascript-overview.html", "title": "A quick overview of JavaScript", "content": "A quick overview of JavaScript dev javascript jslang Basic JavaScript: an introduction to the language \nThis post gives an overview of JavaScript that is as short as possible, but explains every major feature. Give the language a chance! You have to learn its quirks, but then it is fun to program in.\n \n\n Preliminaries JavaScript command line \nComments:\n Values \n     Booleans:   or  \n     \n     Numbers:  ,   (same number, there is no distinction between integers and floating point numbers)\n     \n     Strings:  ,  \n     \n     Functions:\n \n     \n     Objects: Objects store data in properties. Each property has a name and a value.\n \n        Don’t mistake JavaScript objects for simple maps (dictionaries)! They can be used as maps from strings to values, but they are also real objects. Object literals are one of JavaScripts standout features: They allow you to directly create objects – no classes necessary. That is true object-orientation: You can start with concrete objects and introduce abstractions later, as needed. The abstraction for an object factory is a class in most mainstream languages, in JavaScript it is the constructor function (see below).\n     \n     Arrays:\n \n     \n      (see below) \n      (see below) \n Primitives versus objects Not having a value \n     undefined \n     null \n     false \n     0 \n     \"\" \n Operators never use it \n \nBoolean operators:\n \n Conditionals Loops \n      leaves the loop. \n      starts a new loop iteration. \n Functions and variable declarations IIFE \n     The IIFE must be wrapped in parentheses. Otherwise, you will get a syntax error. (Explanation: Without parentheses, JavaScript assumes that you are starting a statement – a function declaration. Such a declaration must have a name and cannot be immediately invoked.) \n     Adding a trailing semicolon is safer. (Explanation: If not and you write two IIFEs in a row, the first one will be interpreted as something callable – which it isn’t – and the second one as its argument.) \n Array methods iteration methods Simple objects Pitfall: every function has its own  Pitfall: methods lose their   if passed around Constructors do it yourself use an API 10. Strict mode strict mode Where to go from here posts on JavaScript \n     JavaScript variable scoping and its pitfalls \n     Prototypes as classes – an introduction to JavaScript inheritance \n     A brief history of ECMAScript versions (including Harmony and ES.next) \n \n     The  JavaScript Guide  is an introduction to JavaScript. \n     The  JavaScript Reference  allows you to look up in-depth information on a given topic. \n JS Central my book comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/custom-latex.html", "title": "Customize LaTeX output from a shell (Unix)", "content": "Customize LaTeX output from a shell (Unix) latex hack computers answer Will Robertson Custom command from shell, fallback if missing Boolean flag from shell Example: Hide the solutions to exercises Example: Personalize a document More ideas comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/uncurrying-this.html", "title": "Uncurrying “this” in JavaScript", "content": "Uncurrying “this” in JavaScript dev javascript advancedjs jslang \nThis post explains applications of uncurrying and currying   in JavaScript. It has been triggered by a  tweet  of Brendan Eich’s.\n \n\n Uncurrying this Generic methods \n      property:  \n     Property access:  \n     Checking for the existence of a property:  \n Use cases for uncurrying this \n  Uncurrying   allows you to make a method prettier when it is applied generically. Example:\n proposal Implementing uncurryThis() \n     \n          What is really happening [by Eich, slightly modified]?\n \n     \n     \n          The uncurried version of a function is the same as invoking the   method on the original. We can borrow that method via  :\n \n     \n     \n          It is best to define standard methods without depending too much on external methods. Furthermore, bind() does not exist prior to ECMAScript 5. We thus rewrite version 2 as follows.\n \n        The above code is still in the vein of “borrowing the   method”.\n     \n The inverse is useful, too – currying this \n  Instead of writing\n \n  Implementing  :\n If you don’t want to extend built-ins Making uncurryThis() safe to use in the presence of untrusted code safe meta-programming comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/improving-typeof.html", "title": "Improving the JavaScript typeof operator", "content": "Improving the JavaScript typeof operator dev javascript jslang typeof versus instanceof following results \n  Use   to determine whether an object is an instance of a given type.   always returns   for primitive values.\n Beyond primitives Getting the type name: the [[Class]] property Fixing the JavaScript typeof operator \n     Conflates primitives and objects: It makes sense to use capitalization to distinguish between primitives and objects. For example:\n \n        The first string is a primitive, the second is an object. The former starts with a lowercase letter, the latter starts with an uppercase letter.\n     \n     The type of   should be  , not  . The value of [[Class]] for all error instances is always  :\n \n     \n     How it handles   and special global objects is (arguably) not optimal. Is   really an instance of  ? I would argue that these global objects are all instances of  . To check for them, you would compare via  :\n \n     \n     It does not work for primitives. They don’t have a [[Class]] property. If you generically invoke   on them, they temporarily borrow the value of their object wrapper types [3]:\n \n     \n Getting the type name: a hybrid approach \n     Use   for primitive values other than  . \n     Return   for  . \n     Return   for any object   (including functions!). \n Adam Tybor References JavaScript values: not everything is an object JavaScript performance: Array.prototype versus [] JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/janos.html", "title": "Web technology stacks – from LAMP to Janos", "content": "Web technology stacks – from LAMP to Janos dev nodejs javascript webdev LAMP – the incumbent \n     Linux: Unix, free. \n     Apache: a web server. \n     MySQL: a relational database \n     PHP: a programming language for web back ends. \n Janos – the challenger \n     Client-side JavaScript \n     Node.js \n     A NoSQL database (such as MongoDB or CouchDB) \n \n      Client-side JavaScript is much more important to the stack than many people realize. It changes the paradigm from client-server to something whose nature is more distributed: On one hand, clients perform more computations and might even communicate with other clients. On the other hand, servers are less responsible for the application logic and mostly become a data tier. An example:  FunctionSource  assembles its page dynamically in the browser, via JavaScript. As a result, clicking a link usually means that only a part of the page has to be replaced instead of sending the complete page from server to client. There is also a fallback – if a browser does not support JavaScript, the assembling code is executed on the server and the result sent to the client.\n         \n        The next step is already in development: With browsers gaining offline functionality such as embedded databases, the data tier is more about syncing databases than about the server managing the data and the client displaying it.\n     \n      Not having to switch languages when going from server to client is a big plus. You can reuse much code (validation code, domain logic, etc.) and don’t have to mentally switch between two languages during development. The ability to execute client-side code on the server enables fallbacks if a client does not support JavaScript (see example in the previous item).\n     \n      It is very fortunate for JavaScript programmers that two things have become popular: JSON as a data transfer format (for web services etc.) and NoSQL databases. Both are perfect fits for JavaScript: JSON uses JavaScript syntax. Schema-less databases make things as flexible on the database side as they are on the programming language side; you get the advantages of object-oriented databases without their messiness.\n     \n      I initially thought that the stack should include a “U” for a Unix-based operating system. But the truth is that operating system matters remarkably little, now that Node.js has a proper Windows port. \n Another proposed acronym @evanpro tweets comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/lobrow.html", "title": "Load Node.js modules in browsers via lobrow", "content": "Load Node.js modules in browsers via lobrow dev javascript jsmodules jslang Bridging the module gap between Node.js and browsers \nNode.js has the advantage of letting you use JavaScript on client and server. Thus, it is a major nuisance that you can’t put portable code into a file that can be loaded on both platforms. This post presents a solution.\n\n \n\n The problem Node.js modules Node.js documentation \nThe contents of  :\n lobrow lobrow \n     The second argument is optional. You can thus put all of your client-side logic into a module. \n      waits until all the modules listed in the array are ready and the   event has fired for  . If you don’t want to wait for  , you can use  , which has the same signature. \n \n  lobrow supports a subset of Node’s module names. The file extension \".js\" is always omitted. There are three kinds of names:\n \n      a single identifier, without dots or slashes.\n        Example:  . \n        Such names can refer to built in “core” modules. If not, Node searches directories relative to the current module. For example, if the current module is   and imports the module  , then Node searches for the following files:\n \n        lobrow lets you map global module names to paths (as searching the file system in the above manner makes less sense in a browser). That allows one to use a single name for a module that has a browser-specific and a Node-specific implementation. The value of   is used to resolve global module names:\n         \n             The result of a resolution is either a path to a script to be loaded or an object (which   the module). \n             The resolution can be performed by an object (mapping module names to paths or objects) or a function (taking a module name and returning a path or an object). \n         \n     \n      \"./\" or \"../\" (repeated one or more times), followed by a sequence of identifiers separated by slashes. Examples: \"./bar\", \"./bar/baz\", \"../bar\", \"../../bar\". \n        Their names interpreted as paths relative to the path of the current module. Example: resolving relative module names.\n \n     \n      a slash followed by one or more identifiers separated by slashes. Examples: \"/bar\", \"/bar/baz\". \n        The given name is used as an absolute path to find the JavaScript file.\n     \n How it works Limitations \n     Warning: lobrow is just a proof of concept. It has only been tested on Firefox, Chrome, and Safari. \n     If you comment out a require() invocation then its module will still be preloaded. Differentiating between active and inactive code would make the extraction process much more complicated. \n     Performance: Things become slow if there are many modules. For deployment, you can switch to one of the compilation solutions listed in the section “related work”. They compress multiple Node.js modules into a single file that can be loaded more quickly in browsers. \n \n     Chrome: needs to be started with the command line option  \n     Firefox: can only access files in the current directory (and below), but not in the parent directory of the main HTML file. \n Universal unit tests Jasmine Related work \n     Adapt Node.js modules by wrapping code around them:\n         \n             sea.js \n             RequireJS \n         \n     \n     Compile Node.js code (at the command line or on-demand via a server)\n         \n             Browserify \n             modul8 \n             require \n             Ender \n         \n     \n Conclusion comparatively clumsy solutions Asynchronous Module Definitions native modules Further reading Universal modules (browser, Node.js): imports and universal tests Universal unit testing (browser, Node.js) with Jasmine The power of the Asynchronous Module Definition A first look at the upcoming JavaScript modules comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/economic-inequality.html", "title": "Economic inequality is bad, even for the rich", "content": "Economic inequality is bad, even for the rich society life business How economic inequality harms societies \nThe difference in average income   countries has no influence on life expectancy. However, the difference in income   a country has a direct influence on life expectancy. Other things are influenced, as well: The more there is inequality, the more the following phenomena increase.\n \n     Illiteracy – language and math \n     Infant mortality \n     Homicides \n     Imprisonment [partially due to harsher sentencing] \n     Teenage births \n     Level of distrust [do you, in general, trust the people around you?] \n     Obesity \n     Mental illness – including drug and alcohol addiction \n     Social immobility [how much does your own wealth depend on your parents’ wealth?] \n \n     Japan: incomes are not that far apart before taxes, small wellfare state. \n     Sweden: incomes differ widely, taxes are used to redistribute the income, large wellfare state. \n \nWhat can be done?\n \n     Decrease income differences before tax:\n         \n             Increase company democracy – employee ownership etc. \n             Promote more directors from within companies. \n         \n     \n     Use taxes and benefits:\n         \n             Stop tax avoidance. \n             End tax havens. \n             Make taxation progressive again. \n         \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/significant-newlines.html", "title": "What JavaScript would be like with significant newlines", "content": "What JavaScript would be like with significant newlines dev javascript jslang \nBrendan Eich recently repeated that he regrets not having given JavaScript significant newlines. This post explains what that would be like.  Quote :\n \n ASI Current approach to optional semicolons [1] \nExample:\n \n     Example 1:\n \n        One of the intermediate evaluation steps is the function call  \n     \n     Example 2:\n \n        Evaluates, among other things, the expression  . The expression inside the square brackets is the binary  comma operator  applied to the operands   and  . That operator evaluates both operands and returns the value of the second one. Hence, the original expression is equivalent to   – the value of the property   of the string  .\n     \n     Example 3:\n \n        The above is interpreted as:\n \n     \n Significant newlines \nYou would still delimit blocks with curly braces (as opposed to indentation being significant, like in Python or Haskell). But the default for a newline would be to terminate a statement. You may continue in the following line if there is a trailing (binary) operator (which includes dot and comma) or if there are unclosed parentheses, square brackets or curly braces.\n Related reading Automatic semicolon insertion in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/web-audio-apis.html", "title": "Web audio APIs and the low-level approach", "content": "Web audio APIs and the low-level approach audio html5 webdev HTML5 Audio APIs - How Low can we Go? Audio Data API  Web Audio API JSMad pdf.js Broadway.js \n     Browser vendors: create low-level APIs that serve as a stable and universal foundation for libraries. \n     Library programmers: can experiment and come up with things that can’t be foreseen during the creation of a browser API. \n Component Model  Examples comments powered by Disqus."},
{"url": "https://2ality.com/2017/02/babel-preset-env.html", "title": "babel-preset-env : a preset that configures Babel for you", "content": ": a preset that configures Babel for you esnext dev javascript babel  is a new preset that lets you specify an environment and automatically enables the necessary plugins. The problem   # At the moment, several presets let you determine what features Babel should support: \n ,  , etc.: incrementally support various versions of ECMAScript.   transpiles what’s new in ES6 to ES5,   transpiles what’s new in ES2016 to ES6, etc. \n : supports all features that are either part of an ECMAScript version or at stage 4 (which basically means the same thing). \n The problem with these presets is that they often do too much. For example, most modern browsers support ES6 generators. Yet, if you use  , generator functions will always be transpiled to complex ES5 code. The solution   #  works like  , but it lets you specify an environment and only transpiles features that are missing in that environment. Note that that means that you need to install and enable plugins and/or presets for experimental features (that are not part of  ), yourself. On the plus side, you don’t need   presets, anymore. Browsers   # For browsers you have the option to specify either: \n \n Browsers via  browserslist  query syntax. For example: \n \n \n Support the last two versions of browsers and IE 7+. \n \n \n \n Support browsers that have more than 5% market share. \n \n \n \n \n \n Fixed versions of browsers: \n \n \n Node.js   # If you compile your code for Node.js on the fly via Babel,   is especially useful, because it reacts to the currently running version of Node.js if you set the target   to  : If you want to see this target in action, take a look at my GitHub repository  . Additional options for     # This section gives a brief overview of additional options for  . For details, consult  the preset’s readme file .  (string, default:  )   # This option lets you configure to which module format ES6 modules are transpiled: \n Transpile to popular module formats:  ,  ,  ,  \n Don’t transpile:  \n ,   (Array of strings, default:  )   # \n  always enables certain plugins (e.g. to override a faulty native feature). It has the same effect as enabling plugins separately. \n  prevents certain plugins from being enabled. \n  (boolean, default:  )   # Babel comes with a polyfill for new functionality in the standard library.   can optionally import only those parts of the polyfill that are needed on the specified platform(s). There are two ways of using the polyfill: \n  polyfills ES5, ES6+ as needed.\n \n Install polyfill:  \n Activate polyfill:  \n \n \n  polyfills   and the regenerator runtime (to emulate generators on ES5).\n \n Install polyfill:  \n Activate polyfill:  \n \n \n Either of the two import statements is transpiled to an environment-specific sequence of more fine-grained imports. For example: Things to note: \n You should activate the polyfill exactly once in your program, e.g. in a “main” module. \n  means that less code is downloaded to the browser (bundle sizes become smaller). However, it does not save RAM, because the polyfill only installs what is missing. \n For more on polyfilling the standard library, consult chapter “ Babel: configuring standard library and helpers ” in “Setting up ES6”.  (boolean, default:  )   # Logs the following information via  : \n Targeted environments \n Enabled transforms \n Enabled plugins \n Enabled polyfills \n Check the next section for sample output. Example   # The following example is taken from the preset’s readme file: Modules are not transpiled. We can, e.g., rely on webpack to handle imports and exports for us. The   output is as follows: Where does   get its information?   # \n The features supported by a given JavaScript engine are determined via kangax’s  compat-table . \n Features are mapped to plugins via the file  . \n browserslist  enables queries such as   and  . \n What’s next?   # Giving plugins access to their “environment”   # Plans for the future include giving plugins the ability to examine what is possible in the current “environment”. That would have two benefits: \n \n Some plugins ( such as the one for the object spread operator ) currently have options telling them whether to use native functionality or polyfills. If they were aware of their “environment”, the plugins wouldn’t need those options. \n \n \n Babel-based minifiers can determine whether it’s OK to output, e.g., arrow functions. \n \n Simplifying presets   # \n \n Presets based on ECMAScript versions (  etc.) are mostly made obsolete by  . The Babel team is considering eliminating them in future Babel releases (e.g. via a deprecation process). \n \n \n Presets based on stages of the TC39 process (  etc.) are also candidates for removal, as things related to stages are in constant flux. You can’t really rely on anything in this space, because the stage of a proposal can change within 2 months. Therefore, directly referring to plugins of experimental features is the better approach. \n \n Acknowledgements   # \n Thanks to  Henry Zhu  for all the useful input for this blog post. \n Further reading   # \n Readme file of  \n “ Setting up ES6 ” (explains how to configure Babel 6+) \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/02/ecmascript-2018.html", "title": "ECMAScript 2018: the final feature set", "content": "ECMAScript 2018: the final feature set dev javascript esnext es2018 es proposal Exploring ES2018 and ES2019  Buy it now and get all future updates. The feature set of  ECMAScript 2018  was finalized during the latest TC39 meeting (23-25 January 2018). This blog post describes it. A word on ECMAScript versions   # Note that since  the TC39 process  was instituted, the importance of ECMAScript versions has much decreased. What really matters now is what stage a proposed feature is in: Once it has reached stage 4, it can be used safely. But even then, you still have to check if your engines of choice support it. The features of ES2018   # Major new features: \n Asynchronous Iteration  (Domenic Denicola, Kevin Smith) \n Rest/Spread Properties  (Sebastian Markbåge) \n New regular expression features: \n RegExp named capture groups  (Gorkem Yakin, Daniel Ehrenberg) \n RegExp Unicode Property Escapes  (Mathias Bynens) \n RegExp Lookbehind Assertions  (Gorkem Yakin, Nozomu Katō, Daniel Ehrenberg) \n  ( ) flag for regular expressions  (Mathias Bynens) \n Other new features: \n  (Jordan Harband) \n Template Literal Revision  (Tim Disney) \n FAQ   # Is there an official list of ECMAScript features?   # Yes, the TC39 repo lists  finished proposals  and mentions in which ECMAScript versions they are introduced. What do the stages mean?   # They refer to maturity stages of the so-called “TC39 process”. Check chapter “ The TC39 process for ECMAScript features ” in “Exploring ES2016 and ES2017” for more information. How is [my favorite proposed feature] doing?   # If you are wondering what stages various proposed features are in, consult  the readme of the ECMA-262 GitHub repository . Further reading   # The following books of mine are free to read online: \n ECMAScript 5: “ Speaking JavaScript ” \n ECMAScript 6: “ Exploring ES6 ” \n ECMAScript 2016 & 2017: “ Exploring ES2016 and ES2017 ” \n ECMAScript 2018 & 2019: “ Exploring ES2018 and ES2019 ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/03/csp-vs-async-generators.html", "title": "Communicating Sequential Processes: an alternative to async generators", "content": "Communicating Sequential Processes: an alternative to async generators dev javascript esnext async In this blog post I present Communicating Sequential Processes (CSP) and how they can be used as an alternative to async generators. In the process, we will also take a look at the ECMAScript proposal that async generators are a part of: “ asynchronous iteration ” Asynchronous iteration   # Let’s start by refreshing our knowledge of asynchronous iteration. It consists of three parts: Async iteration protocol: a combination of the protocol for synchronous iteration and Promises (which enable asynchronicity). : a version of the   loop that works with data that is async iterable. Async generators: generators whose yielded values are delivered via async iteration. The next sections take a look at each of these parts. Afterwards, I’ll explain CSP and how it is an alternative to #3. Async iteration protocol   # Synchronous iteration is supported by many languages. What all approaches have in common is that you need two things: \n A way to deliver values \n A way to signal the end of the sequence of values \n However, they differ in the specifics. For example: \n \n Java : iterators have two methods:   returns values.   returns a boolean indicating whether there are more values. \n \n \n Python : values are delivered via the iterator method  . That method raises the exception   if it is called after the last value. \n \n \n Swift : iterators have a single method   that returns   after the last value. \n \n For JavaScript, the idea was to use a single method without an exception, much like Swift does. However, unlike Swift, TC39 wanted to avoid bugs caused by end-of-iteration values being stored in collections. That’s why in JavaScript, the iterator method   always returns  . For values,   is  . After the last value,   is  . You could say that the end-of-sequence value is truly metadata and kept out of band. In async iteration, the   objects are delivered via Promises. That does make everything even more complex, but the added complexity is necessary to fully support asynchronicity. Moreover, since Promises are a standard mechanism, async functions help when working with async iteration.    # The   loop looks as follows. It is based on the async iteration protocol and can be used inside async functions and async generators: Asynchronous generators   # As of ES2017, we already have the following  invokable entities  in JavaScript: \n Function expressions, function declarations \n Arrow functions \n Method definitions \n Classes \n Async function expressions, async function declarations, async arrow functions, async method definitions \n Async generators would add to this already long list: \n Asynchronous generator function declarations \n Asynchronous generator function expressions \n Asynchronous generator method definitions \n The core idea of async generators is: \n Receive input via  , like async functions \n Produce output via  , like generators, but via async iteration, not via sync iteration. \n It would be nice if we didn’t need to introduce yet another callable entity to JavaScript. In the next section, I present  , which can be implemented via just a library in ES2017 and are an alternative to async generators. Communicating Sequential Processes (CSP)   # CSP are a pattern for concurrent programming that involves two key abstractions: \n \n Processes: are tasks that are, in general, executed concurrently. The code defining a Process is executed sequentially. \n \n \n Channels: are first-in first-out (FIFO) queues that are used for communication between Processes. You put an element into a Channel via the operation   and take an element out of a channel via the operation  . \n \n async-csp: a JavaScript implementation of CSP   # For this blog post, I’m using the CSP library  async-csp  by  @dvlsg : \n \n It implements   as a class and   and   as Promise-based methods. \n \n \n Processes are simply async functions that use   to block on   and  .   leads to a Process yielding execution to other JavaScript code, including other Processes, leading to a relatively coarse-grained cooperative form of multitasking. \n \n Async generators vs. CSP   # In this section, I’ll compare async generators with CSP and you’ll see that they are quite similar. Example: reading and processing a file asynchronously   # The GitHub repository   contains code that processes a file asynchronously in the following steps: : read the contents of a file asynchronously. : split the result into lines. : number the resulting lines. : log the numbered lines to the console. Starting processing   #  You can’t directly feed asynchronous input from legacy sources into async generators. You need a data structure that is asynchronously iterable.   is such a data structure that I implemented as a simple utility class. The following function starts asynchronous processing by reading a file, feeding its contents to an   and returning that queue: The queue is created in line A. Input is added to it in line B. Errors are added like normal queue elements (line C), but are thrown when they are taken out of the queue. Once the stream ends, the queue is closed (line D). .   augments the library’s   with error handling. Similarly to the previous code,   starts asynchronous processing: This piece of code works almost the same as the previous one. Note the special method   in line A. Transforming a sequence of values   # In this post, we are skipping the relatively complex   and advancing to  , which is a good demonstration of a function that takes asynchronous input, transforms it and produces asynchronous output.  receive input via   and produce output via  : You can see that   is really useful, but you need to have an async iterable. . The CSP version of   receives its input via one channel and produces its output via another channel: We’ll see later how functions that have the signature can be composed to produce a single channel. For now, it is enough to see that a function with such a signature is easy to understand and that you only need things that ES2017 already has (async functions, Promises) plus library code. I opted against using   for   andd  . Whether or not that works depends on the Channel implementation one is using. Putting everything together   # Function   puts everything together. . Since each of the functions that are involved produce and possibly consume async iterables, simple function application is enough to connect them. The result is an asynchronous iterable   (line A) whose contents can be logged via  . . The custom tool function   (line A) connects a channel (created via  ) with functions that have two channels as parameters (input and output). The result is yet another channel whose contents can be logged via  . Conclusions   # I hope that the example showed that CSP are an interesting alternative to async generators. I’ve drawn a few more conclusions from working with both CSP and async generators: \n \n If we do get async generators, they should come bundled with an asynchronously iterable data structure, because it is essential for connecting async iteration with legacy sources of async data. WHATWG streams are such a data structure, but they are not an ECMAScript feature. \n \n \n Async generators do error handling well. With CSP, you need to manually feed errors into channels. \n \n \n I like that CSP focus on the Channel as their core abstraction. It is something tangible and a location where lots of configuration will occur (buffering, handling backpressure, etc.). \n \n \n CSP would benefit from two parts of the async iteration proposal:   could implement the async iteration protocol (via a method  ), which would enable the handy   and interoperability with tools based on async iteration (incl. async generators). \n \n Further reading   # \n \n Sync iteration: chapter “ Iterables and iterators ” in “Exploring ES6” \n \n \n Chapter “ Promises for asynchronous programming ” in “Exploring ES6” \n \n \n Chapter “ Callable entities in ECMAScript 6 ” in “Exploring ES6” \n \n \n Chapter “ Async functions ” in “Exploring ES2016 and ES2017” \n \n \n Async iteration: post “ ES proposal: asynchronous iteration ” on 2ality \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/03/text-as-clocks.html", "title": "Exercise: text as Unicode clock faces", "content": "Exercise: text as Unicode clock faces dev javascript unicode In this blog post, we explore how arbitrary ASCII text can be encoded as Unicode clock faces: I’m explaining ideas by  Maggie Pint  and  @FakeUnicode . Unicode clock faces   # The following times are available as clock faces in Unicode: \n Full hours:\n \n CLOCK FACE ONE OCLOCK (U+1F550): 🕐 \n CLOCK FACE TWO OCLOCK (U+1F551): 🕑 \n ··· \n CLOCK FACE TWELVE OCLOCK (U+1F55B): 🕛 \n \n \n Half-hours:\n \n CLOCK FACE ONE-THIRTY (U+1F55C): 🕜 \n CLOCK FACE TWO-THIRTY (U+1F55D): 🕝 \n ··· \n CLOCK FACE TWELVE-THIRTY (U+1F567): 🕧 \n \n \n Interpreting clock faces as Unicode characters   # The idea is as follows: the clock faces give you hex digits from 0 to F (you get the range 0–7 twice). Therefore, two clocks encode an 8-bit hex number, which can be interpreted as a Unicode character. If you want to, you can stop reading here and implement   yourself. The next subsection gives you a little help. The subsection after that gives you solutions. Encoding and decoding via   and     # For decoding clock-encoded text, we can get help from  : You can see that each 21-bit code points is encoded as two 16-bit code units. For example, the code point U+1F554 is encoded as  : The pair of clocks gives you the two hex digits 4 and 8. Once you have them, you can use  :    # Thus, a compact way of decoding clock faces is: A more self-descriptive version looks like this: Alternatively, you can use   to group characters, but I liked the more universal  . Encoding text as clock faces   # If you want to produce clock text, you can use the following function. I’m using the spread operator ( ) to  split the string   into code units . Further reading   # \n Chapter “ Unicode and JavaScript ” in “Speaking JavaScript” \n Chapter “ Unicode in ES6 ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/01/shared-array-buffer.html", "title": "ES proposal: Shared memory and atomics", "content": "ES proposal: Shared memory and atomics dev javascript esnext es proposal concurrency The ECMAScript proposal “ Shared memory and atomics ” by Lars T. Hansen has reached stage 4 this week and will be part of ECMAScript 2017. It introduces a new constructor   and a namespace object   with helper functions. This blog post explains the details. \n  Complete rewrite of Sect. 4, “Atomics: safely accessing shared data”. \n Parallelism vs. concurrency   # Before we begin, let’s clarify two terms that are similar, yet distinct: “parallelism” and “concurrency”. Many definitions for them exist; I’m using them as follows: \n Parallelism (parallel vs. serial): execute multiple tasks simultaneously \n Concurrency (concurrent vs. sequential): execute several tasks during overlapping periods of time (and not one after another). \n Both are closely related, but not the same: \n Parallelism without concurrency: single instruction, multiple data (SIMD). Multiple computations happen in parallel, but only a single task (instruction) is executed at any given moment. \n Concurrency without parallelism: multitasking via time-sharing on a single-core CPU. \n However, it is difficult to use these terms precisely, which is why interchanging them is usually not a problem. Models of parallelism   # Two models of parallelism are: \n \n Data parallelism: The same piece of code is executed several times in parallel. The instances operate on different elements of the same dataset. For example: MapReduce is a data-parallel programming model. \n \n \n Task parallelism: Different pieces of code are executed in parallel. Examples: web workers and the Unix model of spawning processes. \n \n A history of JS parallelism   # \n \n JavaScript started as being executed in a single thread. Some tasks could be performed asynchronously: browsers usually ran those tasks in separate threads and later fed their results back into the single thread, via callbacks. \n \n \n Web workers brought task parallelism to JavaScript: They are relatively heavweight processes. Each worker has its own global environment. By default, nothing is shared. Communication between workers (or between workers and the main thread) evolved: \n \n At first, you could only send and receive strings. \n Then, structured cloning was introduced: copies of data could be sent and received.  Structured cloning works for most data  (JSON data, Typed Arrays, regular expressions,   objects,   objects, etc.). It can even handle cyclic references between objects correctly. However, error objects, function objects and DOM nodes cannot be cloned. \n Transferables move data between workers: the sending party loses access as the receiving party gains access to data. \n \n \n \n Computing on GPUs (which tend to do data parallelism well) via  WebGL :  It’s a bit of a hack and works as follows. \n \n Input: your data, converted into an image (pixel by pixel). \n Processing: OpenGL pixel shaders can perform arbitrary computations on GPUs. Your pixel shader transforms the input image. \n Output: again an image that you can convert back to your kind of data. \n \n \n \n SIMD (low-level data parallelism): is supported via  the ECMAScript proposal SIMD.js . It allows you to perform operations (such as addition and square root) on several integers or floats at the same time. \n \n \n PJS (codenamed River Trail): the plan of this ultimately abandoned project was to bring high-level data parallelism (think map-reduce via pure functions) to JavaScript. However, there was not enough interest from developers and engine implementers. Without implementations, one could not experiment with this API, because it can’t be polyfilled. On 2015-01-05, Lars T. Hansen  announced  that an experimental implementation was going to be removed from Firefox. \n \n The next step:     # What’s next? For low-level parallelism, the direction is quite clear: support SIMD and GPUs as well as possible. However, for high-level parallelism, things are much less clear, especially after the failure of PJS. What is needed is a way to try out many approaches, to find out how to best bring high-level parallelism to JavaScript. Following the principles of the extensible web manifesto, the proposal “shared memory and atomics” (a.k.a. “Shared Array Buffers”) does so by providing low-level primitives that can be used to implement higher-level constructs. Shared Array Buffers   # Shared Array Buffers are a primitive building block for higher-level concurrency abstractions. They allow you to share the bytes of a   object between multiple workers and the main thread (the buffer is shared, to access the bytes, wrap it in a Typed Array). This kind of sharing has two benefits: \n You can share data between workers more quickly. \n Coordination between workers becomes simpler and faster (compared to  ). \n Creating and sending a Shared Array Buffer   # You create a Shared Array Buffer the same way you create a normal Array Buffer: by invoking the constructor and specifying the size of the buffer in bytes (line A). What you share with workers is the buffer. For your own, local, use, you normally wrap Shared Array Buffers in Typed Arrays (line B).  Cloning a Shared Array Buffer is the correct way of sharing it, but some engines still implement an older version of the API and require you to transfer it: In the final version of the API, transferring a Shared Array Buffer means that you lose access to it. Receiving a Shared Array Buffer   # The implementation of the worker looks as follows. We first extract the Shared Array Buffer that was sent to us and then wrap it in a Typed Array (line A), so that we can use it locally. Atomics: safely accessing shared data   # Problem: Optimizations make code unpredictable across workers   # In single threads, compilers can make optimizations that break multi-threaded code. Take, for example the following code: In a single thread, the value of   never changes while the loop runs (if   is an Array or Typed Array that wasn’t patched in some manner). Therefore, the code can be optimized as follows: However, in a multi-threaded setting, this optimization prevents us from using this pattern to wait for changes made in another thread. Another example is the following code: In a single thread, you can rearrange these write operations, because nothing is read in-between. For multiple threads, you get into trouble whenever you expect the writes to be done in a specific order: These kinds of optimizations make it virtually impossible to synchronize the activity of multiple workers operating on the same Shared Array Buffer. Solution: atomics   # The proposal provides the global variable   whose methods have three main use cases. #  methods can be used to synchronize with other workers. For example, the following two operations let you read and write data and are never rearranged by compilers: \n \n \n The idea is to use normal operations to read and write most data, while   operations ( ,   and others) ensure that the reading and writing is done safely. Often, you’ll use custom synchronization mechanisms, such as locks, whose implementations are based on  . This is a very simple example that always works, thanks to   (I’ve omitted setting up  ): # Using a   loop to wait for a notification is not very efficient, which is why   has operations that help: \n \n \nwaits for a notification at  , but only if   is  . \n \n \n \nwakes up   workers that are waiting at  . \n \n # Several   operations perform arithmetic and can’t be interrupted while doing so, which helps with synchronization. For example: \n \n Roughly, this operation performs: Problem: torn values   # Another problematic effect with shared memory is   (garbage): when reading, you may see an intermediate value – neither the value before a new value was written to memory nor the new value. Sect “Tear-Free Reads” in the spec states that there is no tear if and only if: \n \n Both reading and writing happens via Typed Arrays (not DataViews). \n \n \n Both Typed Arrays are   with their Shared Array Buffers: \n \n \n \n Both Typed Arrays have the same number of bytes per element. \n \n In other words, torn values are an issue whenever the same Shared Array Buffer is accessed via: \n One or more DateViews \n One or more unaligned Typed Arrays \n Typed Arrays with different element sizes \n To avoid torn values in these cases, use   or synchronize. Shared Array Buffers in use   # Shared Array Buffers and the run-to-completion semantics of JavaScript   # JavaScript has so-called  : every function can rely on not being interrupted by another thread until it is finished. Functions become transactions and can perform complete algorithms without anyone seeing the data they operate on in an intermediate state. Shared Array Buffers break run to completion (RTC): data a function is working on can be changed by another thread during the runtime of the function. However, code has complete control over whether or not this violation of RTC happens: if it doesn’t use Shared Array Buffers, it is safe. This is loosely similar to how async functions violate RTC. There, you opt into a blocking operation via the keyword  . Shared Array Buffers and asm.js and WebAssembly   # Shared Array Buffers enable emscripten to compile pthreads to asm.js. Quoting  an emscripten documentation page : [Shared Array Buffers allow] Emscripten applications to share the main memory heap between web workers. This along with primitives for low level atomics and futex support enables Emscripten to implement support for the Pthreads (POSIX threads) API. That is, you can compile multithreaded C and C++ code to asm.js. Discussion on how to best bring multi-threading to WebAssembly is  ongoing . Given that web workers are relatively heavyweight, it is possible that WebAssembly will introduce lightweight threads. You can also see that threads are  on the roadmap for WebAssembly’s future . Sharing data other than integers   # At the moment, only Arrays of integers (up to 32 bits long) can be shared. That means that the only way of sharing other kinds of data is by encoding them as integers. Tools that may help include: \n \n  and  : The former converts strings to instances of  . The latter does the opposite. \n \n \n stringview.js : a library that handles strings as arrays of characters. Uses Array Buffers. \n \n \n FlatJS : enhances JavaScript with ways of storing complex data structures (structs, classes and arrays) in flat memory (  and  ). JavaScript+FlatJS is compiled to plain JavaScript. JavaScript dialects (TypeScript etc.) are supported. \n \n \n TurboScript : is a JavaScript dialect for fast parallel programming. It compiles to asm.js and WebAssembly. \n \n Eventually, there will probably be additional – higher-level – mechanisms for sharing data. And experiments will continue to figure out what these mechanisms should look like. How much faster is code that uses Shared Array Buffers?   # Lars T. Hansen has written two implementations of the Mandelbrot algorithm (as documented in his article “ A Taste of JavaScript’s New Parallel Primitives ” where you can try them out online): A serial version and a parallel version that uses multiple web workers. For up to 4 web workers (and therefore processor cores), speed-up improves almost linearly, from 6.9 frames per seconds (1 web worker) to 25.4 frames per seconds (4 web workers). More web workers bring additional performance improvements, but more modest ones. Hansen notes that the speed-ups are impressive, but going parallel comes at the cost of the code being more complex. Example   # Let’s look at a more comprehensive example. Its code is available on GitHub, in the repository  .  And you can run it online. Using a shared lock   # In the main thread, we set up shared memory so that it encodes a closed lock and send it to a worker (line A). Once the user clicks, we open the lock (line B). In the worker, we set up a local version of the lock (whose state is shared with the main thread via a Shared Array Buffer). In line B, we wait until the lock is unlocked. In lines A and C, we send text to the main thread, which displays it on the page for us (how it does that is not shown in the previous code fragment). That is, we are using   much like   in these two lines. It is noteworthy that waiting for the lock in line B stops the complete worker. That is real blocking, which hasn’t existed in JavaScript until now (  in async functions is an approximation). Implementing a shared lock   # Next, we’ll look at an ES6-ified version of  a   implementation by Lars T. Hansen  that is based on  . In this section, we’ll need (among others) the following   function: \n \nIf the current element of   at   is  , replace it with  . Return the previous (or unchanged) element at  . \n The implementation starts with a few constants and the constructor: The constructor mainly stores its parameters in instance properties. The method for locking looks as follows. In line A, we change the lock to   if its current value is  . We only enter the then-block if the lock is already locked (in which case   did not change anything). In line B (inside a   loop), we check if the lock is locked with waiters or not unlocked. Given that we are about to wait, the   also switches to   if the current value is  . In line C, we wait if the lock value is  . The last parameter,  , means that waiting never times out. After waking up, we continue the loop if we are not unlocked.   also switches to   if the lock is  . We use   and not  , because we need to restore this value after   temporarily set it to   and woke us up. The method for unlocking looks as follows. In line A,   gets the value that   had   1 was subtracted from it. The subtraction means that we go (e.g.) from   to   and from   to  . If the value was previously   then it is now   and everything is fine (there is no one to wake up). Otherwise, the value was either   or  . In the former case, we are now unlocked and must wake up someone (who will usually lock again). In the latter case, we must fix the illegal value created by subtraction and the   simply does nothing. Conclusion for the example   # This gives you a rough idea how locks based on   work. Keep in mind that multithreaded code is notoriously difficult to write, because things can change at any time. Case in point:   is based on a paper documenting a futex implementation for the Linux kernel. And the title of that paper is “ Futexes are tricky ” (PDF). If you want to go deeper into parallel programming with Shared Array Buffers, take a look at   and  the document it is based on (PDF) . The API for shared memory and atomics   #    # Constructor: \n \nCreate a buffer for   bytes. \n Static property: \n \nReturns   by default. Override to control what   returns. \n Instance properties: \n \n \nReturns the length of the buffer in bytes. \n \n \n \nCreate a new instance of   and fill it with the bytes at the indices from (including)   to (excluding)  . \n \n    # The main operand of   functions must be an instance of  ,  ,  ,  ,   or  . It must wrap a  . All functions perform their operations atomically. The ordering of store operations is fixed and can’t be reordered by compilers or CPUs. # \n \n \nRead and return the element of   at  . \n \n \n \nWrite   to   at   and return  . \n \n \n \nSet the element of   at   to   and return the previous value at that index. \n \n \n \nIf the current element of   at   is  , replace it with  . Return the previous (or unchanged) element at  . \n # Each of the following functions changes a Typed Array element at a given index: It applies an operator to the element and a parameter and writes the result back to the element. It returns   of the element. \n \n \nPerform   and return the original value of  . \n \n \n \nPerform   and return the original value of  . \n \n \n \nPerform   and return the original value of  . \n \n \n \nPerform   and return the original value of  . \n \n \n \nPerform   and return the original value of  . \n \n # Waiting and waking requires the parameter   to be an instance of  . \n \n \nIf the current value at   is not  , return  . Otherwise go to sleep until we are woken up via   or until sleeping times out. In the former case, return  . In the latter case, return  .   is specified in milliseconds. Mnemonic for what this function does: “wait if   is  ”. \n \n \n \nWake up   workers that are waiting at  . \n \n # \n \nThis function lets you ask the JavaScript engine if operands with the given   (in bytes) can be manipulated without locking. That can inform algorithms whether they want to rely on built-in primitives (  etc.) or use their own locking.   always returns  , because that’s what all currently relevant supports. \n FAQ   # What browsers support Shared Array Buffers?   # At the moment, I’m aware of: \n Firefox (50.1.0+): go to   and set   to  \n Safari Technology Preview (Release 21+): enabled by default. \n Chrome Canary (58.0+): There are two ways to switch it on.\n \n Via   (“Experimental enabled SharedArrayBuffer support in JavaScript”) \n \n \n \n Further reading   # More information on Shared Array Buffers and supporting technologies: \n \n “ Shared memory – a brief tutorial ” by Lars T. Hansen \n \n \n “ A Taste of JavaScript’s New Parallel Primitives ” by Lars T. Hansen [a good intro to Shared Array Buffers] \n \n \n “ SharedArrayBuffer and Atomics Stage 2.95 to Stage 3 ” (PDF), slides by Shu-yu Guo and Lars T. Hansen (2016-11-30) [slides accompanying the ES proposal] \n \n \n “ The Basics of Web Workers ” by Eric Bidelman [an introduction to web workers] \n \n Other JavaScript technologies related to parallelism: \n “ The Path to Parallel JavaScript ” by Dave Herman [a general overview of where JavaScript is heading after the abandonment of PJS] \n “ Write massively-parallel GPU code for the browser with WebGL ” by Steve Sanderson [fascinating talk that explains how to get WebGL to do computations for you on the GPU] \n Background on parallelism: \n “ Concurrency is not parallelism ” by Rob Pike [Pike uses the terms “concurrency” and “parallelism” slightly differently than I do in this blog post, providing an interesting complementary view] \n  I’m very grateful to Lars T. Hansen for reviewing this blog post and for answering my  -related questions. comments powered by Disqus."},
{"url": "https://2ality.com/2017/03/2ality-redesign.html", "title": "Coming up: a redesign of 2ality", "content": "Coming up: a redesign of 2ality 2ality I’ll soon migrate 2ality to a different hosting solution. This blog post tells you what you need to know. For readers, not much changes   # These are the major changes: \n The URLs stay the same, but the domain   will become the default, whereas it was   up to now (  will forward to the default). \n The new design is cleaner and simpler and responsive. It should work better on mobile devices. It also provides a stable foundation for future enhancements. \n The RSS feed will continue to be at  feeds.feedburner.com/2ality . The switch should go smoothly; in case there are problems, you now know why. \n A few more details   # I’ve been meaning to move away from Blogger for years. I’ve always wanted the site to be statically generated, but the last pieces only fell into place over the last year: \n Using isomorphic React for static site generation significantly simplified my code. \n I’m hosting the site on Amazon S3, because it’s relatively cheap and because I’m familiar with it. \n I’m working on a blog post explaining more of the technologies behind the new approach and why I changed things. Stay tuned. comments powered by Disqus."},
{"url": "https://2ality.com/2017/03/es-integer.html", "title": "ES2020: BigInt – arbitrary precision integers", "content": "ES2020: BigInt – arbitrary precision integers dev javascript es2020 numbers  This blog post is slightly outdated. Tread carefully. The ECMAScript proposal “ BigInt: Arbitrary precision integers in JavaScript ” by Daniel Ehrenberg is currently at stage 3. This blog post gives an overview.  Update to reflect the name change from   to  . Rationale   # Given that the ECMAScript standard only has a single type for numbers (64-bit floating point numbers) it’s amazing how far JavaScript engines were able to go in their support for integers: fractionless numbers that are small enough are stored as integers (usually within 32 bits, possibly minus bookkeeping information). However, JavaScript can only safely represent integers with up to 53 bits plus a sign. Sometimes, you need more bits. For example: \n Twitter uses 64-bit integers as IDs for tweets ( source ). In JavaScript, these IDs have to be stored in strings. \n Financial technology uses so-called   (integers with arbitrary precision) to represent sums of money. \n Core parts of the proposal   # The proposal is about adding a new primitive type for big ints to JavaScript. Given that implicit integers (Array indices etc.) will continue to exist separately, they will be called BigInts. Core parts of the proposal are: \n Literals for BigInts: Each literal is a series of digits, suffixed with an  . For example:  \n  returns   for BigInt values: \n \n Operators such as   and   are overloaded and work with BigInts. The number of bits used to store values is increased as necessary, automatically. \n There is a wrapper constructor   for BigInts, which is similar to   for Numbers and other wrapper constructors. \n Next, we will look at a first example and then will examine all aspects of the proposal in detail. A first example   # This is what using BigInts looks like (example taken from the proposal’s readme): BigInt literals   # Like Number literals, BigInt literals support several bases: \n Decimal:  \n Hexadecimal:  \n Binary:  \n Octal:  \n Negative BigInts are produced by prefix the unary minus operator:  Operator overloading   # The general rule for binary operators is: You can’t mix Numbers and BigInts: If one operand is a BigInt, the other one can’t be a Number. If you do mix them, a   is thrown: The reason for this rule is that there is no general way of coercing a Number and a BigInt to a common type: Numbers can’t represent BigInts beyond 53 bits, BigInts can’t represent fractions. Therefore, the exceptions warn you about typos that could change the results of computations in unexpected ways. To see why, let’s look at an example: 9007199254740991 is the highest integer that Numbers can represent safely. You can see that if you try adding 1 to the “unsafe” 9007199254740992 If   were interpreted as a Number (due to coercion), you would get wrong results. Additionally, disallowing mixed operand types keeps operator overloading simple, which is helpful should overloading be extended further in the future. The following sections explain what operators are available for BigInts. Arithmetic and ordering   # \n \n Binary  ,  binary  ,  ,   work as expected. \n \n \n ,   round towards zero (think  ). \n \n \n \n Ordering operators  ,  ,  ,   work as expected. \n \n \n Unary   works as expected. Unary   is not supported for BigInts, because much code (incl. asm.js) relies on it coercing its operand to Number. \n \n Bit operators   # For bit operators, A negative sign is interpreted as an infinite two’s complement. E.g.: \n  is   (ones extend infinitely to the left) \n  is   (ones extend infinitely to the left) \n That is, a negative sign is more of an external flag and not represented as an actual bit. The following bit operators exist: \n \n Bitwise operators  ,  ,   for BigInts work analogously to their Number versions. \n \n \n Signed shift operators  ,   for BigInts work analogously to their Number versions. Note that here, too, both operands need to be BigInts. \n \n Bit operators for Numbers limit their operands to 32 bits. All operators (except for unsigned right shift  ) interpret the highest (31st) bit as a sign: You can shift a positive Number left so that the highest (31st) bit is set and it becomes negative: With BigInts, that can never happen, because they are not limited to specific number of bits and there is therefore no sign bit. There is no unsigned right shift operator   for BigInts, because its semantics are: “shift in” a zero, replace the highest bit with a zero. First, there is no highest bit. Second, with the infinite sequence of ones prefixing negative values, you’d have to insert a zero somewhere, which makes no sense. Thus, preserving the sign is the natural (and only) thing to do for BigInts and there is no   operator. One last illustration of how negative bit operands work: For both Numbers and BigInts, however often you signed-shift   to the right, the result is always  : Equality   # Lenient equality ( ) and inequality ( ) are coercing operators, which makes them difficult to adapt to BigInts. At the moment, comparing Numbers and BigInts throws an exception: Alas, lenient equality coerces booleans to Numbers, meaning that exceptions are thrown, too: Strict equality ( ) and inequality ( ) only consider values to be equal if they have the same type. Therefore, adapting them to BigInts is simple: The wrapper constructor     # Similar to Numbers, BigInts have the associated wrapper constructor  . It works as follows: \n \n : convert arbitrary values   to BigInt. This works similarly to  , but: \n \n A   is thrown if   is either   or  . \n Instead of returning   for Strings that don’t represent BigInts, a   is thrown. \n \n \n \n : throws a  . \n \n This is what using   looks like:  methods   #  holds the methods “inherited” by primitive BigInts: \n \n \n \n Utility functions   # \n \n \nCasts   to   bits (unsigned). This influences how the value is represented internally. \n \n \n \nCasts   to   bits (signed). \n \n \n \nWorks similarly to  , but throws a   instead of returning  : \n \n For comparison, this is what   does: \n \n \n Casting and 64-bit integers   # Casting allows you to create integer values with a specific number of bits. If you want to restrict yourself to just 64-bit integers, you have to always cast: Coercing BigInts to other primitive types   # This table show what happens if you convert BigInts to other primitive types: Still under discussion: Should the result of   applied to a BigInt should have the suffix  ? At the moment, it works like this: TypedArrays and DataView operations for 64-bit values   # BigInts make it possible to add 64 bit support to Typed Arrays and DataViews: \n New Typed Array constructors:\n \n \n \n \n \n New DataView methods:\n \n \n \n \n \n BigInts and JSON   # BigInts in JSON data will probably be handled similarly to other unsupported data such as symbols: Future   # There will probably be a library with functions and constants for BigInts (think  , but for BigInts instead of Numbers). Implementors of JS engines are optimistic that BigInts will be able to efficiently support integers with various bit sizes. But one could, in principle, introduce subtypes of   ( ,  , ...). Beyond BigInts   # We’ll probably eventually see support for: \n Custom value types (compared by value; think: primitive types user-defined via classes) \n Operator overloading \n Custom number literal syntax \n The following features may be added to JavaScript and could be based on these mechanisms. \n Decimal data type : for base-10 arithmetic, which is useful for representing sums of money and results of scientific measurements. \n Rational data type : representing fractions (1/3 etc.) without rounding. \n Complex numbers \n Vectors and matrices \n And more \n FAQ: BigInts   # How do I decide when to use Numbers and when to use BigInts?   # My recommendations: \n Use Numbers for up to 53 bits and for Array indices. Rationale: They already appear everywhere and are handled efficiently by most engines (especially if they fit into 31 bits). Appearances include:\n \n \n \n \n \n Use BigInts for large numeric values: If your fraction-less values don’t fit into 53 bits, you have to choice but to move to BigInts. \n All existing web APIs return and accept only Numbers and will only upgrade to BigInt on a case by case basis Why not just increase the precision of Numbers in the same manner as is done for BigInts?   # One could conceivably split   into   and  , but that would add many new complexities to the language (several Integer-only operators etc.). I’ve sketched the consequences in  a Gist . Conclusions   # It is great to see support for integers beyond 53 bits being planned for JavaScript. Supporting various bit sizes via the single type   is an interesting experiment. It’d be great if it worked out. With BigInts, we get a glimpse at what JavaScript would be like if it had had exceptions from the start (they were introduced in ES3): using the wrong operands for some of the operators throws exceptions now. Further reading   # \n Blog post “ Feature watch: ECMAScript 2018 ” \n Section “ Bitwise Operators ” in “Speaking JavaScript” \n  Thanks to Daniel Ehrenberg for reviewing this blog post. comments powered by Disqus."},
{"url": "https://2ality.com/2017/03/es6-commonjs.html", "title": "Two ES6 features that help with CommonJS modules", "content": "Two ES6 features that help with CommonJS modules dev javascript esnext commonjs nodejs Even without ES modules, ES6 is a joy to use in Node.js. Two ES6 features eliminate some of the redundancy of CommonJS syntax. Importing and destructuring   # Destructuring  can make importing more concise. Without destructuring: With destructuring: Exporting and property value shorthands   # Exporting can profit from  property value shorthands . Without property value shorthands: Using property value shorthands: Over the years, I’ve tried various other ways of being less redundant when exporting, but this approach seems cleanest to me. Further reading   # \n Chap. “ Destructuring ” in “Exploring ES6” \n Sect. “ Property value shorthands ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/04/setting-up-multi-platform-packages.html", "title": "Setting up multi-platform npm packages", "content": "Setting up multi-platform npm packages dev javascript esnext npm jsmodules babel This post is part of a series of three: Current approaches: “Setting up multi-platform npm packages” Motivating a new approach: “ Transpiling dependencies with Babel ” Implementing the new approach: “ Delivering untranspiled source code via npm ” This blog post explains ways of targeting multiple platforms via the same npm package. Before we get into the actual topic, let’s quickly review common JavaScript module formats. Overview   # This following table gives an overview of standard properties in   that are used for pointing to source code. Note: “ES5+” means “whatever language features are supported by the JavaScript engines you are targeting”. Background: JavaScript module formats   # At the moment, these are the most common JavaScript module formats: \n AMD (asynchronous module definition): an asynchronous module format for browsers. \n CJS (CommonJS): a synchronous module format designed for servers (such as Node.js). Due to the popularity of Node.js and npm, CJS has become the most widely used format for browsers, too. But it has to be compiled to asynchronous code there. Tools that do that include webpack and Browserify. \n ESM (ECMAScript modules): With ES6, modules became a built-in part of JavaScript. ESM modules are designed to work both synchronously and asynchronously, enabling them to be a universal module format. Support for ESM in browsers is slowly appearing. Support in Node.js is work in progress and estimated to be production-ready by early 2018 (preliminary support may appear earlier). \n UMD (Universal Module Definition)   # The idea of UMD is that you can implement a JavaScript module in such a manner that it supports (up to) three formats at the same time: AMD, CJS and delivery via a global variable. This is a UMD module that supports AMD and CJS ( source ): Documentation: \n “ UMD (Universal Module Definition) patterns for JavaScript modules ” by Addy Osmani, Evan Carroll, Anders D. Johnson, James Burke and others \n “ When sniffing for exports, make sure exports is not an HTMLElement ” by Chris Dickinson explains how to best detect if Node.js is running (e.g.: checking whether   is a function may not work if   is being used). \n The problem   # You can only deliver source code for a single platform via an npm package.  Property   of   lets you specify exactly what platform that is: However, that doesn’t help you with the following use cases, where you need source code for multiple platforms per package: Browsers: deliver both a native version (e.g. in ES5 via CJS) and a “bleeding edge” version (e.g. latest ECMAScript version via an ES module), to be transpiled by Babel. Node.js: deliver the same module for several versions of Node.js. Browsers: allow new libraries to age gracefully – transpile only as long your target platforms don’t support the features, yet. We want the same convenience that   affords us. There are two dimensions at play here: \n On one hand, there is a distinction between code that is to be transpiled and “native” code. \n On the other hand, native code may have to run on platforms with different capabilities. \n The next section covers solutions for use case 1. Solutions   # The following subsections explain properties in   that can be used to point to alternate versions of the same code. When I use the term “native features”, it means: language features supported by the platforms you are targeting. : native features, CJS   #  is the standard mechanism for pointing to the module code inside a package if you want to override the default path,  . It is supported everywhere. This is an example: : native features, ESM   # This property helps tools such as the tree-shaking module bundler Rollup that depend on the ESM format. Other than that, only native language features are supported. That is,   is just   with a different module format: Documentation: \n “ pkg.module ” by Rich Harris \n : ES6, ESM   # Angular v4 delivers each package in three formats: \n UMD: via property  \n ES5/ESM: via property  \n ES6/ESM: via property  \n This is what  its   looks like: I like the idea of this property. But its name and semantics mean that it’ll age relatively quickly. Documentation: \n “ Angular 4.0.0 Now Available ” by Stephen Fluin \n : the precursor of     # The property   is now deprecated. It was superseded by  . : browser-specific code   # The idea of the property   is that: \n  provides Node.js code \n  provides browser-specific code \n The simplest mode of   is as an alternative to  : An advanced mode lets you replace specific files: Documentation: \n “ package-browser-field-spec ” by Roman Shtylman \n Support by bundlers   # Comments: \n webpack lets you configure where it looks for source code (see next section), so getting it to support   is simple. \n Rollup specializes in the ESM format. If you want it to handle CJS modules, you need  a plugin . \n jspm has  its own configuration mechanisms  (property   and others). \n webpack   # For webpack, you can configure where it searches for module code inside packages via the   option: The default value of this property depends on the value of  . If   is  ,   or unspecified then the default is: If   has any other value (including  ) then the default is: Documentation: \n “ ” in the webpack documentation \n Conclusion   # Support for multi-platform packages has come a long way. The main challenge ahead is to make sure transpiling external dependencies is as “auto-updating” and hassle-free as  . Further reading   # \n Chapter “ Modules ” in “Exploring ES6” \n : a preset that configures Babel for you \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/proto-intro-video.html", "title": "Video: Prototypal inheritance in JavaScript", "content": "Video: Prototypal inheritance in JavaScript talk dev javascript jslang video MunichJS TNG \n \n       Prototypal inheritance in JavaScript \n      This talk explains JavaScript’s prototypal inheritance via a simple example. Topics covered: objects, prototypes, constructors, extending constructors.\n     \n      40m40s \n       proto_intro.pdf \n \nThe video isn’t perfect, but it should be useful as an introduction. Audio quality is very good and you can download the slides and look at them separately from the video. Oh, and the location of the talk explains the reaction of the audience when I mention Firefox.\n \nRelated posts:\n \n     Prototypes as classes – an introduction to JavaScript inheritance \n     JavaScript does not need classes \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/node-repl-start.html", "title": "Execute code each time the Node.js REPL starts", "content": "Execute code each time the Node.js REPL starts dev nodejs repl javascript \nI have not found a way to perform the code execution via a configuration file, but you can make it happen via the following trick: Write a script that executes the code and then programmatically starts a REPL. Example: The following are the contents of a file called  .\n Node.js documentation \n     Tip: load source from a file in the Node.js shell \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/nodejs-v08-roadmap.html", "title": "The Node.js v0.8 roadmap", "content": "The Node.js v0.8 roadmap dev nodejs javascript roadmap Isolates (child processes) github.com/joyent/node/issues/2133 Paddy Byers \nchild_process.fork() spawns an entirely new instance of node. That means that, in addition to being a separate javascript execution environment, it gets to have all of the node functionality; to load modules, and to use all of the system functionality that you get as a result. It also has its own event loop so it is a fully-fledged and independent entity with its own lifecycle- not a slave of some other event thread. It can in turn spawn new instances, and can outlive the instance that created it.\n     \nSo the objectives are different and the functionality beyond pure javascript is different. However, they provide an \"equivalent\" kind of separation of javascript state and flow control, and similar methods of communication between parent and child.\n Domains github.com/joyent/node/issues/2134 Addons github.com/joyent/node/issues/2136 addons comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/module-gap.html", "title": "Bridging the module gap between Node.js and browsers", "content": "Bridging the module gap between Node.js and browsers dev nodejs javascript jsmodules amdefine: use AMD modules on Node.js \nOne of the advantages of Node.js is that you can use the same programming language – JavaScript – on both server and client. When it comes to modularizing code that is portable between the two platforms, one is presented with a major challenge: they approach modularity differently. This post examines four solutions for writing cross-platform modules.\n \n\n Synchronous versus asynchronous modules \n  In browsers, things work differently. Loading can take a long time, so modules (scripts) are always loaded asynchronously: you give the order for loading a file plus a callback that is used to inform you when the file has been loaded. Hence, there is no (synchronous) waiting. That also means that you cannot load an import in the middle of your module, like on Node.js. The  Asynchronous Module Definition  (AMD) standard has been developed with asynchronicity in mind: the module becomes a callback that is invoked once all imports have loaded. The above Node.js module looks as follows as an AMD:\n optimizer \nNote that the above example demonstrates the core AMD syntax. The  complete AMD standard  has more features.\n \n  At their core, the two module formats are not dramatically different: specify a path to a file, assign the result of evaluating it to a variable. The following sections examine two approaches for using either module standard on both platforms:\n \n     Use boilerplate to ensure compatibility. \n     Transform “pure” modules on the fly or via compilation. \n Compatibility via boilerplate \n     \n \n        This pattern relies on the peculiarities of   in a brittle manner. For example, it will cease to work if the code is wrapped in a function. Thus, it should be avoided.\n     \n    \n     \n \n        Approach: Wrap all of the code into an immediately-invoked function expression, check whether   already exists and if not, provide a value for it.\n     \n     \n \n        Approach: turn   into a method call by prepending an object with a suitable method inside. Advantage: shorter and only a prefix (easier to remove, easier to add via copy/paste).\n     \n \n \n \n     The pseudo-modules \"require\", \"exports\" and \"module\" provide a Node.js-style API. \n     The default for a missing module name array is  . \n \n     Disadvantages: boilerplate, source code must be parsed in browsers. \n     Advantage: works with script tags. \n \n \n \n     Disadvantage: boilerplate. \n     Advantage: no parsing on browsers, works with script tags. \n Pure Node.js or AMD modules \n     Disadvantage: lobrow needs to parse the code and is limited by its use of XMLHttpRequest (compared to script tags). \n     Advantage: no boilerplate. \n \n     Disadvantage: need for adapter on Node.js. \n     Advantage: can use script tags, no boilerplate. \n Structuring modules \n \n \n     Node.js\n         \n     \n     AMDs\n \n     \n \n \n \n     Node.js\n \n     \n     AMDs\n \n     \n \nAlternatively, one could put the exported values inside the object literal that is initially assigned to  :\n Conclusion support for module loader plugins modules built in References RequireJS, a JavaScript file and module loader Load Node.js modules in browsers via lobrow Browserify – make node-style require() work in the browser modules-webmake - Bundle CommonJS modules for web browser node-amd-loader, an AMD loader for Node.js Execute code each time the Node.js REPL starts Modules and namespaces in JavaScript  [patterns] comments powered by Disqus."},
{"url": "https://2ality.com/2017/03/static-site-generation.html", "title": "The new 2ality blog setup: statically generated via isomorphic React, hosted on Amazon S3", "content": "The new 2ality blog setup: statically generated via isomorphic React, hosted on Amazon S3 dev javascript nodejs static site generation 2ality The new setup for the 2ality blog was literally years in the making: First, I experimented with various approaches. Then fine-tuning took a while, too. In this blog post I explain the details. Why static site generation?   # For years, using Google’s Blogger as the host of my blog worked well, but I wanted a simpler design and more control. I could have gone with a server-side blogging app such as  Ghost . But I decided in favor of static site generation for several reasons: \n Hosting content via Amazon Web Services is relatively cheap. \n Much safer w.r.t. hacking. If you host the blogging app yourself, missing a security-critical update is a constant risk. \n More robust (unless AWS goes down ;-) \n Now I’m fully in control of my content, which enables future improvements and helps with little things such as batch-editing files. Why write your own static site generator?   # I tried several static site generators, but there was always something missing. I found that customizing them until I got what I wanted was more work than writing my own generator. Let me make it clear that the impulse to roll your own is usually not a good one, but when it comes to static site generation, you can rely on so many libraries that a generation framework does not bring that much to the table. Whatever the solution, it had to be tweakable in JavaScript, because that’s the language I’m currently most comfortable with. An abandoned first approach   # I first experimented with assembling the site via nested Handlebar templates. I quickly encountered two problems: I didn’t like having so much logic encoded in custom syntax in external files. More importantly, however, there were pockets of interactive content that I wrote in React and that had to be maintained and built separately and then inserted into the static content. Static site generation via isomorphic React   # Static site generation via isomorphic React involves the following steps: Every blog post is represented as a JSON(-compatible) object containing the content as HTML plus metadata such as the title and tags. At generation time, one uses React to render that data as HTML, which is then written to disk. So far, we are still in traditional static site generation territory. This approach differs in that the HTML contains annotations. These annotations allow React to install itself into the page on the client, turning it into a dynamic web app. React needs the JSON data mentioned in the first step, which is why this data is included in the HTML file. The HTML file is uploaded to a static web server. When a user goes to the post’s web page, they immediately see content (due to the static HTML). The React-based dynamic web app starts up in the background. But even if JavaScript is switched off, most of the blog still works. This approach neatly fixes the aforementioned problems related to static site generation: You can use familiar React syntax when writing your templates (again, not that big of a deal, but nice if you know React). It is very easy to make any part of a page interactive, in a way that is integrated well into the page-as-an-app. Additionally, graceful degradation is automatic. Let’s take a look at code. For each page, you need the following parts: \n : one specific kind of page (and page layout), implemented as a React component that renders a JSON object as HTML. Invoked both at generation time and at runtime (on the client). \n : a site-global frame with links etc. that is wrapped around each page. \n : generates the page and writes it to disk. \n : is used by  . Blanks to be filled in include the static React-generated content and the JSON data. \n : site-global frame around pages   # I’ve omitted the React components   and  . This component receives the aforementioned JSON object, via the property  . The   shows a widget with the top ten most popular posts during the last 30 days and that widget renders its contents via data stored in  . : React component for the page content   # The   component wraps the   around the core of the page and passes on the JSON  : The core of the page displays the HTML: The last part of the file has to do with it doing double duty: At generation time,   is used to render HTML. In the browser, the file is run as a script and renders   into a   with the ID  . Step 2 is performed by the following code: The JSON object   comes from a global variable. How it gets there is shown in the subsection on  . : writing the file to disk   # The following function is only executed at build time:  applies   to its parameter and returns the resulting string. : template for HTML page   # EJS templates  can be visually a bit jarring, but are convenient in that the templating logic is expressed in JavaScript. I’ve written  a blog post about how you can improve their syntax , but I’m not using that technique here. There are four blanks to be filled in: \n : escapes and display the title of the page. \n : displays the unescaped HTML generated statically via React. \n : inserts the JSON data into the page (unescaped). \n  points to the webpack-built bundle whose entry point is  . Each kind of page has its own bundle. \n The full generation algorithm   # Basic idea: \n All of the data of a website is stored in a project directory  \n The actual content is stored in Markdown files in  . \n The output is written to a directory  . \n To produce the output, one iterates over all files in  : \n Content files are translated to HTML. For now, I only have content stored in Markdown files that is translated to HTML and wrapped in React components. In the future, I may support other content, e.g. JSON data. \n All other files are copied verbatim. \n Files starting with a dot or an underscore are ignored. \n How a Markdown file is translated to HTML is determined via its path, not via metadata stored inside it. Paths are described via  , patterns with wildcard characters. \n Blog posts: show up in index pages, the archive and the RSS feed.\n \n Input:  \n Output:  \n Path glob:  \n \n \n Solo pages: are independent web pages.\n \n Input:  \n Output:  \n Path glob:  \n \n \n So far, we have only looked at  , where output is produced from single files. Additionally, there are so-called   that produce HTML files via input collected from multiple pages. Summaries include index pages (  etc.) and the RSS feed. In-file metdata   # In order to minimize in-file metadata, I decided against using a markup language (JSON, YAML, etc.). This is what the preamble of the blog post   looks like: I wanted the files to look nice in Markdown preview, which is why the metadata is wrapped in a comment and the title of the post is a normal Markdown heading. Summaries   # During generation, I collect the metadata of all blog posts in a big Array in RAM. That data is then used to generate so-called  : \n Index files show the pages in reverse chronological order and allow you to browse through the site:  ,  , etc. \n An Atom feed can be used to subscribe to site updates:  ,  , etc.\n \n The current year is in  . The remaining feed entries are grouped by year, to make the file structure stable and help with caching. \n \n \n The Archive page lets you interactively browse the blog’s contents. A JSON file with all of the blog’s metadata is still reasonably small, enabling me to use static generation for this feature, too. \n Other features   # \n \n Top 10 blog posts: I show a widget in a side bar that displays that top 10 most popular blog posts during the last 30 days. I collect the data for the top 10 at generation, from Google Analytics. How I do that is described in  a separate blog post . I download the data at most once a day and cache it in-between. \n \n \n Comments are handled by Disqus. Migrating Disqus from Blogger to my static site was remarkably easy, because Disqus lets you specify a canonical URL for each page, via JavaScript. Blogger was hosted at  , my new site is hosted as  . Thus, the new site tells Disqus to use the domain   and all existing comments are where you’d expect them to be. \n \n \n I’m using Google Custom Search for content-related searches. For now, I’m simply linking to an external page. I may customize and embed it in the future. \n \n CSS: tips and techniques   # Making sites responsive is hard and involves lots of trial and error. Safari’s and Chrome’s responsive design modes helped. But they came with their own challenges. For example, what you see in Desktop Safari for the iPad screen size is not what you see on an actual iPad (the layout is different). Tips and techniques: \n \n Google Fonts  is a great resource with lots of web fonts. There are articles on the web that provide recommendations for   – Google Fonts that go together well for headings and bodies. \n \n \n Flexbox: helps a lot with responsive layout. Alas, if you want to responsively rearrange items across axes, you are out of luck. I’m looking forward to CSS grid in this regard. \n \n \n Displaying code: is challenging in the context of responsive design, because code becomes nearly unreadable if its lines are wrapped. But you need those lines to get narrower for some screen sizes. The solution is to scroll horizontally: \n \n \n \n Then I still had the occasional long word (e.g. a camel-cased JavaScript identifier) wreck my layout. Here, the solution was to wrap more aggressively: \n \n \n \n Giving elements the width 100% occasionally caused problems, too, which I fixed via: \n \n \n Libraries I used   # So much help comes from the rich ecosystem of npm packages. These are the most important ones I used: \n I built via npm scripts and webpack. \n I’m using mocha for unit tests. \n I’m planning to use the headless browser library  Nightmare  and a manual checker (“no comments in Markdown should appear in the output”) to make sure that the statically generated output is OK. Things are easier to check with static generation, but I still want to make sure I don’t accidentally break anything. \n : for templating. I like its simplicity. \n : for file system operations like recursively copying or removing directories. \n : for matching globs against file system paths. \n : for promisifying callback-based Node.js functions. \n : for parsing Markdown and rendering it to HTML. I especially liked how easy it was to add features I was missing via plugins:\n \n markdown-it-footnote \n markdown-it-anchor \n markdown-it-attrs \n \n \n : to statically syntax-highlight code snippets inside Markdown content.   makes it easy to plug in the syntax highlighter of your choice. \n Deployment   # For deploying the content to Amazon S3, I used  s3cmd . This tool makes synching directories with S3 easy. As a plus, it only uploads files that changed, which it determines not by date, but by looking at the actual content of a file. That is tremendously helpful for static site generation, where files are often written to disk even though nothing changes. Conclusions   # So far, I’m very happy with the new approach. But there are still a few challenges: \n Even with over 1100 blog posts, static generation is still reasonably fast. What takes time is uploading the generated files. \n Everything would be fine, if files were only regenerated if I change the contents of a blog post, but they are also   regenerated at least once a day, when I retrieve new “top 10 blog posts” data. It would be nice if such frequently changing content could be factored out. Maybe that will be possible if HTML imports become more widely supported (I’d still want my HTML to work statically). I wrote down my thoughts on this topic in the blog post “ Modular HTML pages ”. \n At the moment, I’m still duplicating the HTML data: for each page, it exists once in JSON and once statically embedded. \n Plans for the future: \n \n I enjoy how easy it is to change something: If I want a different page frame, I simply edit  . A next step will be to separate the parts that can be reused between projects from those that can’t. It won’t be easy to do so while keeping the current ease of use. \n \n \n I’ll also probably write command line tools for managing tags (searching, summarizing, renaming, merging, ...). \n \n Further reading:   # \n Modular HTML pages \n Using the Google Analytics Core Reporting API from Node.js \n comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/keyword-parameters.html", "title": "Named parameters in JavaScript and ECMAScript 6", "content": "Named parameters in JavaScript and ECMAScript 6 esnext dev javascript jslang section “Named parameters” \n  When calling a method in a programming language, the actual parameters (specified by the caller) have to be mapped to the formal parameters (of a method definition). There are two common ways to do so:\n \n    are mapped by position: The first actual parameter is mapped to the first formal parameter etc. \n    use   (labels) to perform the mapping. Names are associated with formal parameters in a method definition and label actual parameters in a method call. It does not matter in which order named parameters appear, as long as they are correctly labeled. The following sections explain why named parameters are useful and give examples.\n   \n \n  The optional parameters of a method are sometimes called its  . Positional parameters are awkward if parameters can be omitted anywhere (not just at the end). Then any subset of the options can be active and one often has to insert blanks such as   for the inactive ones. Named parameters help with options in two ways: They clearly describe what parameters are active and they allow one to simply drop the inactive ones.\n \n  JavaScript does not have native support for named parameters like Python and many other languages. But there is a reasonably elegant simulation: provide optional parameters via an object literal. The result is a so-called   that is assigned to a single formal parameter. Using this technique, an invocation of   looks as follows:\n reminder points out comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/js-type-inference.html", "title": "Type inference to make JavaScript as fast as statically typed languages?", "content": "Type inference to make JavaScript as fast as statically typed languages? jsengine dev firefox javascript Type Inference brings JS improvements to Firefox Beta JavaScript JITs comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/ff8-html5-context-menus.html", "title": "HTML5 context menus in Firefox 8+", "content": "HTML5 context menus in Firefox 8+ dev firefox html5 webdev HTML5 context menus in Firefox (Screencast and Code) \nExample: The following HTML source code defines a section with a context menu. The menu has two items and a sub-menu with two items.\n \n \nThe article also covers:\n \n     How to check whether a browser supports context menus. \n     How to dynamically enable/disable menu items depending on what state and app is currently in (active selection etc.): A menu fires a   event every time it opens. \n     A CSS cursor called   is available to give a visual clue as to where context menus are available. \n demo page comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/node-v063.html", "title": "Node.js v0.6.3: NPM included", "content": "Node.js v0.6.3: NPM included dev nodejs javascript Node v0.6.3 NPM jasmine-node comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/v8-incremental-gc.html", "title": "V8’s incremental garbage collector: shorter pauses, better interactive performance", "content": "V8’s incremental garbage collector: shorter pauses, better interactive performance v8 jsengine dev javascript chrome A game changer for interactive performance comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/css-trbl.html", "title": "Mnemonics for remembering the CSS order of top right bottom left", "content": "Mnemonics for remembering the CSS order of top right bottom left css dev html webdev \nExample: The four CSS properties\n \n      is a mnemonic for trbl, the first characters of top, right, bottom, left. \n      an alternative to tar ball, suggested by Josh Feuerstein and Rick Waldron. \n      means that you enumerate the sides of a rectangle, starting at 12 o’clock, continuing clockwise. Suggested by Franz Graf. \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/10/async-function-tips.html", "title": "Tips for using async functions (ES2017)", "content": "Tips for using async functions (ES2017) dev javascript esnext This blog post gives tips for using async functions. If you are unfamiliar with them, you can read chapter “ Async functions ” in “Exploring ES2016 and ES2017”. Know your Promises   # The foundation of async functions is  Promises . That’s why understanding the latter is crucial for understanding the former. Especially when connecting old code that isn’t based on Promises with async functions, you often have no choice but to use Promises directly. For example, this is a “promisified” version of  : The API of   is based on callbacks. Promisifying it via an async function would mean that you’d have to fulfill or reject the Promise returned by the function from within callbacks. That’s impossible, because you can only do so via   and  . And you can’t   the result of a function from within a callback.   has similar constraints. Therefore, the common coding style for async functions will be: \n Use Promises directly to build asynchronous primitives. \n Use those primitives via async functions. \n  chapter “ Promises for asynchronous programming ” in “Exploring ES6”. Async functions are started synchronously, settled asynchronously   # This is how async functions are executed: The result of an async function is always a Promise  . That Promise is created when starting the execution of the async function. The body is executed. Execution may finish permanently via   or  . Or it may finish temporarily via  ; in which case execution will usually continue later on. The Promise   is returned. While executing the body of the async function,   resolves the Promise   with  , while   rejects   with  . The notification of a settlement happens asynchronously. In other words: the callbacks of   and   are always executed after the current code is finished. The following code demonstrates how that works: You can rely on the following order: Line (A): the async function is started synchronously. The async function’s Promise is resolved via  . Line (C): execution continues. Line (B): Notification of Promise resolution happens asynchronously. Returned Promises are not wrapped   # Resolving a Promise is a standard operation.   uses it to resolve the Promise   of an async function. That means: Returning a non-Promise value fulfills   with that value. Returning a Promise means that   now mirrors the state of that Promise. Therefore, you can return a Promise and that Promise won’t be wrapped in a Promise: Intriguingly, returning a rejected Promise leads to the result of the async function being rejected (normally, you’d use   for that): That is in line with how Promise resolution works. It enables you to forward both fulfillments and rejections of another asynchronous computation, without an  : The previous code is roughly similar to – but more efficient than – the following code (which unwraps the Promise of   only to wrap it again): Don’t forget     # One easy mistake to make in async functions is to forget   when making an asynchronous function call: In this example,   is set to a Promise, which is usually not what you want in async functions.  can even make sense if an async function doesn’t return anything. Then its Promise is simply used as a signal for telling the caller that it is finished. For example: The   in line (A) guarantees that   is completely finished before the remainder of   is executed. You don’t need   if you “fire and forget”   # Sometimes, you only want to trigger an asynchronous computation and are not interested in when it is finished. The following code is an example: Here, we don’t care when individual writes are finished, only that they are executed in the right order (which the API would have to guarantee, but that is encouraged by the execution model of async functions – as we have seen). The   in the last line of   ensures that the function is only fulfilled after the file was successfully closed. Given that returned Promises are not wrapped, you can also   instead of    : Both versions have pros and cons, the   version is probably slightly easier to understand. Parallelism   # The following code make two asynchronous function calls,   and  . However, these two function calls are executed sequentially. Executing them in parallel tends to speed things up. You can use   to do so: Instead of awaiting two Promises, we are now awaiting a Promise for an Array with two elements. No   in callbacks   # Remember that   only affects the innermost async function that surrounds it and can only be used directly inside async functions. That is a problem if you want to use one of the Array utility functions  ,  , etc., which rely on callbacks.    # Let’s start with the Array method  . In the following code, we want to download the files pointed to by an Array of URLs and return them in an Array. This does not work, because   is syntactically illegal inside normal arrow functions. How about using an async arrow function, then? There are two issues with this code: \n The result is now an Array of Promises, not an Array of strings. \n The work performed by the callbacks isn’t finished once   is finished, because   only pauses the surrounding arrow function and   is resolved asynchronously. That means you can’t use   to wait until   is finished. \n We can fix both issues via  , which converts an Array of Promises to a Promise for an Array (with the values fulfilled by the Promises): The callback for   doesn’t do much with the result of  , it only forwards it. Therefore, we don’t need an async arrow function here, a normal arrow function will do: There is one small improvement that we still can make: This async function is slightly inefficient – it first unwraps the result of   via  , before wrapping it again via  . Given that   doesn’t wrap Promises, we can return the result of   directly:    # Let’s use the Array method   to log the contents of several files pointed to via URLs: Again, this code will produce a syntax error, because you can’t use   inside normal arrow functions. Let’s use an async arrow function: This does work, but there is one caveat: the Promise returned by   is resolved asynchronously, which means that the callbacks are not finished when   returns. As a consequence, you can’t await the end of  . If that’s not what you want, you can convert   into a   loop: Now everything is finished after the   loop. However, the processing steps happen sequentially:   is only called a second time   the first call is finished. If you want the processing steps to happen in parallel, you must use  :  is used to create an Array of Promises. We are not interested in the results they fulfill, we only   until all of them are fulfilled. That means that we are completely done at the end of this async function. We could just as well return  , but then the result of the function would be an Array whose elements are all  . Immediately Invoked Async Function Expressions   # Sometimes, it’d be nice if you could use   at the top level of a module or script. Alas, it’s only available inside async functions. You therefore have several options. You can either create an async function   and call it immediately afterwards: Or you can use an Immediately Invoked Async Function Expression: Another option is an Immediately Invoked Async Arrow Function: Unit testing with async functions   # The following code uses  the test-framework mocha  to unit-test the asynchronous functions   and  : However, this test always succeeds, because mocha doesn’t wait until the assertions in line (B) and line (C) are executed. You can fix this by returning the result of the Promise chain, because mocha recognizes if a test returns a Promise and then waits until that Promise is settled (unless there is a timeout). Conveniently, async functions always return Promises, which makes them perfect for this kind of unit test: There are thus two advantages to using async functions for asynchronous unit tests in mocha: the code is more concise and returning Promises is taken care of, too. Don’t worry about unhandled rejections   # JavaScript engines are becoming increasingly good at warning about rejections that are not handled. For example, the following code would often fail silently in the past, but most modern JavaScript engines now report an unhandled rejection: comments powered by Disqus."},
{"url": "https://2ality.com/2016/10/understanding-promises.html", "title": "Three ways of understanding Promises", "content": "Three ways of understanding Promises dev javascript esnext This blog post covers three ways of understanding  Promises . This is an example of invoking a Promise-based function  : So what is a Promise? \n Conceptually, invoking   is a blocking function call. \n A Promise is both a container for a value and an event emitter. \n Conceptually: calling a Promise-based function is blocking   #  is  an async function . Its body expresses well what’s going on   – how we usually think about asynchronous computations: \n Line (A): Wait until   is finished. \n Line (B): Then log its result  . \n Prior to ECMAScript 6 and generators, you couldn’t suspend and resume code, which is why, for Promises, you put everything that happens after the code is resumed into a callback. Invoking that callback is the same as resuming the code. A Promise is a container for an asynchronously delivered value   # If a function returns a Promise then that Promise is like a blank into which the function will (usually) eventually fill in its result, once it has computed it. You can simulate a simple version of this process via an Array: With Promises, you don’t access the eventual value via   (as in line (A)), you use method   and a callback. A Promise is an event emitter   # Another way to view a Promise is as an object that emits events. Registering the event listener (line (B)) can be done after calling  , because the callback handed to   (line (A)) is executed asynchronously, after this piece of code is finished. Normal event emitters specialize in delivering multiple events, starting as soon as you register. In contrast, Promises specialize in delivering exactly one value and come with built-in protection against registering too late: the result of a Promise is cached and passed to event listeners that are registered after the Promise was settled. Further reading   # \n Chapter “ Promises for asynchronous programming ” in ”Exploring ES6” \n Chapter “ Async functions ” in “Exploring ES2016 and ES2017” \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/11/computing-tag-functions.html", "title": "Computing tag functions for ES6 template literals", "content": "Computing tag functions for ES6 template literals dev javascript esnext template literals This blog post describes what you can do with functions that return tag functions for ES6 template literals. For an introduction to template literals, tagged template literals and tag functions, consult chapter “ Template literals ” in “Exploring ES6”. Calling values via template literals   # The common way of calling a value in JavaScript is to append arguments in parentheses: In ES6, you can additionally call values via template literals:  is now a tag function whose first parameter is an Array with template strings and whose remaining parameters are the substitutions. Functions that return tag functions   # If the value you call via a template literal is a function that returns a tag function then you can use arguments for the former function to parameterize the latter function. For example: In the following interaction,   returns a tag function that repeats its template literal   times: This is an implementation of  : Tag functions that return tag functions   # You can even create tag functions that return tag functions, enabling you to chain template literals. For example, this is a tag function   that lets you chain three template literals: This is how you’d implement  : The following tag function   lets you create chains of arbitrary length, but you have to signal the end of the chain via an empty parameter list: This works, because template literals always provide at least one argument: Real-world example: styled-components   # styled-components  by  Glen Maddern  and  Max Stoiber  provides “visual primitives for the component age”. It lets you style React and React Native components via CSS in tagged template literals. Example from the website: Further reading   # \n Chapter “ Template literals ” in “Exploring ES6”. \n More on functions that return functions: “ Currying versus partial application (with JavaScript code) ”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2017/01/import-operator.html", "title": "ES2020:  import()  – dynamically importing ES modules", "content": "ES2020:   – dynamically importing ES modules dev javascript es2020 jsmodules section “Loading modules dynamically via  ” The ECMAScript proposal “ ” by Domenic Denicola is at stage 4 and part of ECMAScript 2020. It enables dynamic loading of ECMAScript modules and is explained in this blog post. ECMAScript modules are static   # ECMAScript modules are completely static: you must specify what you import and export at compile time and can’t react to changes at runtime. That has several advantages, especially w.r.t. tooling,  which are explained in “Exploring ES6”. The static structure of imports is enforced syntactically in two ways. Consider the following example: First, this import declaration can only appear at the top level of a module. That prevents you from importing modules inside an   statement or inside an event handler. Second, the     is fixed; you can’t compute it at runtime (via a function call etc.). The proposal enables dynamic module imports   # The proposed operator for loading modules dynamically works as follows: The operator is used like a function: \n \n The parameter is a string with a module specifier that has the same format as the module specifiers used for   declarations. In contrast to the latter, the parameter can be any expression whose result can be coerced to a string. \n \n \n The result of the “function call” is a Promise. Once the module is completely loaded, the Promise is fulfilled with it. \n \n Even though it works much like a function,   is an operator: In order to resolve module specifiers relatively to the current module, it needs to know from which module it is invoked. Normal functions have no straightforward way of finding that out. Use cases   # Loading code on demand   # Some functionality of web apps doesn’t have to be present when they start, it can be loaded on demand. Then   helps, because you can put such functionality into modules. For example: Conditional loading of modules   # Sometimes you may want to load a module depending on whether a condition is true. For example, to load a polyfill on legacy platforms. That looks as follows. Computed module specifiers   # For applications such as internationalization, it helps if you can dynamically compute module specifiers: Tips   # Accessing exports via destructuring   # Destructuring helps with accessing a module’s exports: Accessing default exports   # For default exports, you need to know that   is a keyword. Using it as a property name via the dot notation is OK: However, you can’t use it as a variable name: Dynamically loading multiple modules   # You can dynamically load multiple modules at the same time via  : Async functions and     #  returns Promises, which means that you can use it via  async functions  (which are part of ECMAScript 2017) and get nicer syntax: At the top-level of a module or script, you may find Immediately Invoked Async Arrow Functions useful: Support for     # \n \n Node.js: Guy Bedford’s  node-es-module-loader  provides a Node.js executable that supports ES6 module syntax and  . \n \n \n webpack v1:  babel-plugin-dynamic-import-webpack  is a Babel plugin that transpiles   to  . \n \n \n webpack v2 ( v2.1.0-beta.28  and later): supports  code splitting via  \n \n Further reading   # \n Chapter “ Modules ” in “Exploring ES6” \n Chapter “ Promises for asynchronous programming ” in “Exploring ES6” \n Chapter “ Async functions ” in “Exploring ES2016 and ES2017” \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/11/proxying-builtins.html", "title": "Pitfall: not all objects can be wrapped transparently by proxies", "content": "Pitfall: not all objects can be wrapped transparently by proxies dev javascript esnext js proxies A proxy object  can be seen as intercepting operations performed on its target object – the proxy wraps the target. The proxy’s handler object is like an observer or listener for the proxy. It specifies which operations should be intercepted by implementing corresponding methods (  for reading a property, etc.). If the handler method for an operation is missing then that operation is not intercepted. It is simply forwarded to the target. Therefore, if the handler is the empty object, the proxy should transparently wrap the target. Alas, that doesn’t always work, as this blog post explains. Wrapping an object affects     # Before we dig deeper, let’s quickly review how wrapping a target affects  : If you call   directly,   points to  : If you invoke that method via the proxy,   points to  : That’s done so that the proxy continues to be in the loop if, e.g., the target invokes methods on  . Objects that can’t be wrapped transparently   # Normally, proxies with an empty handler wrap targets transparently: you don’t notice that they are there and they don’t change the behavior of the targets. If, however, a target associates information with   via a mechanism that is not controlled by proxies, you have a problem: things fail, because different information is associated depending on whether the target is wrapped or not. For example, the following class   stores private information in the WeakMap   ( more information on this technique ): Instances of   can’t be wrapped transparently:  is different from the wrapped  . The following implementation does not have this problem: Wrapping instances of built-in constructors   # Instances of most built-in constructors also have a mechanism that is not intercepted by proxies. They therefore can’t be wrapped transparently, either. I’ll demonstrate the problem for an instance of  : The mechanism that is unaffected by proxies is called  . These slots are property-like storage associated with instances. The specification handles these slots as if they were properties with names in square brackets. For example, the following method is internal and can be invoked on all objects  : However, access to internal slots does not happen via normal “get” and “set” operations. If   is invoked via a proxy, it can’t find the internal slot it needs on   and complains via a  . For   methods,  the language specification states : Unless explicitly stated otherwise, the methods of the Number prototype object defined below are not generic and the   value passed to them must be either a Number value or an object that has a   internal slot that has been initialized to a Number value. Arrays can be wrapped transparently   # In contrast to other built-ins, Arrays can be wrapped transparently: The reason for Arrays being wrappable is that, even though property access is customized to make   work, Array methods don’t rely on internal slots – they are generic. A work-around   # As a work-around, you can change how the handler forwards method calls and selectively set   to the target and not the proxy: The drawback of this approach is that none of the operations that the method performs on   go through the proxy. Further reading   # \n Comprehensive introduction to ES6 proxies: chapter “ Metaprogramming with proxies ” in “Exploring ES6”. \n  Thanks to Allen Wirfs-Brock for pointing out the pitfall explained in this blog post. comments powered by Disqus."},
{"url": "https://2ality.com/2016/12/macbook-pro-touch-bar.html", "title": "A programmer evaluates the MacBook Pro (Touch Bar)", "content": "A programmer evaluates the MacBook Pro (Touch Bar) computers apple I got my new MacBook Pro this week. These are my first impressions of the machine. I’ve moved from a MacBook Air 13\" to a MacBook Pro 13\". My dream notebook would have been a 13\" version of the 12\" MacBook. It’s a shame that Apple didn’t introduce such a machine, but I understand the decision to keep things simple. Accordingly, I changed the planning for my setup: \n from iMac plus MacBook \n to MBP plus LG UltraFine 5K display (as a docking station). \n One benefit of this switch is that I won’t have to wait until new iMacs come out in order to have a large high-resolution display at home. Various observations   # \n It feels heavier than the MacBook Air, probably due to its shape. Objectively, the difference in weight is negligible (MBA weighs 1.35kg, MPB weighs 1.37kg). \n The speakers are surprisingly good for a notebook. \n Force feedback for clicking the trackpad is an amazing illusion. I could swear that the trackpad moves. \n Keyboard   # \n The keyboard is unusual, but I managed to type well on it right away, without a learning curve. \n I miss the half-size left and right arrow keys. The full-size keys look odd and, ironically, it makes the arrow keys harder to hit blindly (in my experience). \n I absolutely love the fingerprint scanner. It also serves as a power button. \n You can’t use the power button to put the device to sleep. But you can add a “sleep” key to the Control Strip in the Touch Bar. \n Touch Bar   # The Touch Bar doesn’t add much to the device. To me, it’s mainly a single row of programmable keys whose labels change on the fly. \n \n Apple makes the distinction between app-specific keys and the so-called Control Strip (with keys for controlling sound volume, screen brightness, etc.). \n \n \n You can configure the app strip via an app’s “View” menu. \n \n \n You can configure the Control Strip via “System Preferences → Keyboard”. \n \n Tab “Keyboard” lets you configure the Control Strip. You can also configure what the Touch Bar displays (always function keys, etc.) and what happens if you hold the “fn” key (e.g., show function keys). \n Tab “Text” lets you switch off typing suggestions in the Touch Bar. \n Tab “Shortcuts” lets you configure in which apps the Touch Bar should always display the function keys. \n \n \n \n The Touch Bar is switched off after a period of inactivity. But I rarely noticed that in practice, because it is switched on as soon as you type a key or use the trackpad. You can also switch it on by tapping on it. \n \n \n Hitting Touch Bar keys properly is harder than normal keys. Long-term, Apple should support force feedback. \n \n \n Esc key: it’s always there when you need it, so its elimination is not   much of a problem. But it is harder to hit than a normal key. It’s not left-aligned, which looks weird. But you can tap to its left and still trigger it. vi users are probably affected the most by this change. They have the option to remap the Esc key to, e.g., Caps Lock. \n \n Screen   # \n It’s nice to have the high “Retina” resolution. In general, the display is much better than the MBA’s. The smaller bezel helps, too. \n The system preference panel “Displays” lets you scale the UI. I opted for making it as small as possible. As a result, the screen feels larger. \n Touch screen or not?   # I agree with Apple that you rarely want to touch the screen if you have keyboard and trackpad. That doesn’t mean that it’s not occasionally useful. And it makes you wonder why the keyboard for the iPad Pro doesn’t have a trackpad. There are also brilliant hybrid designs like the Lenovo Yoga’s. Hybrids don’t make good tablets. But they add a versatility to the device that’s very useful during travel. At the moment, I’m bringing both MacBook and iPad to most of my travels. With a Yoga, I’d only need a single device. The idea of a hybrid Apple device is especially compelling if you consider that the MacBook 12\" is about as heavy as the first iPad. I also agree with Apple that desktop apps make poor touch apps. But I do think that adding cursor support to iPad apps would work well. Apple should do so and also enable them to run on Macs. USB-C and adapters   # Observations about USB-C: \n Yes, it’s quite inconvenient that you need adapters for everything and all-new adapters, to boot (I have quite a few USB-A and Thunderbolt-2 adapters). \n On the plus side, the versatility of USB-C is amazing. With 4 ports that are all the same, you never run out of ports and can choose either side to plug in. Even power can be plugged into any of the four ports. \n Connecting via a single cable to a docking station like the LG UltraFine is great, too. Afterwards, you can use the LG’s loudspeakers, webcam, microphone and 3 USB-C ports. The LG also charges the laptop. \n Due to the MBP only having USB-C ports, planning for all scenarios is challenging. I avoided buying things that don’t make sense with a docking station. On the plus side, it’s nice that all adapters work on both docking station and MacBook. I bought the following adapters: \n Apple’s USB-C Digital AV Multiport Adapter: for HDMI and USB-C, while traveling. I previously had a VGA adapter, too, but decided against buying one for now. I’m betting on HDMI being supported well enough everywhere by now. \n Sharkoon’s Ethernet adapter / USB-A hub : for an Ethernet RJ45 port and 3 USB-A ports, at home. I’ll leave this adapter connected to the LG UltraFine. \n USB-C lightning cable for iPhone and iPad. Mainly for traveling, when I don’t have a USB-A power supply with me. It’s nice that I now have the choice of plugging the cable into either notebook or the notebook’s power supply. \n A dual USB stick: with a USB-A connector at one end and a USB-C connector at the other end. \n There is only one thing that makes me angry about Apple’s switch to USB-C-only: many of its devices (iPhone, Siri Remote, Magic Keyboard, Magic Trackpad) only come bundled with USB-A Lightning cables, but not with USB-C ones. And Apple doesn’t let you exchange a USB-A cable for a USB-C one – I’ve tried. Thus, if you disagree with how Apple handles this,  please give them feedback online . Thunderbolt   # I also bought a Thunderbolt 2 to Thunderbolt 3 adapter, to connect my MacBook Pro with my (legacy) iMac. That gave me two advantages: \n Target disk mode: turns the iMac into an external hard drive for the MacBook Pro. File transfers are incredibly fast (50 GB within minutes). \n Target display mode: lets me use the iMac as an external display. For now, I’m putting the MacBook Pro in front of the iMac and continue to use the MBP’s keyboard. That way, I don’t lose the fingerprint scanner. \n A remote for my Mac   # With my iMac, I have used the Apple Remote and Remote Buddy, which meant that the iMac became my TV, my DVD player and my Hi-Fi. Alas, the Apple Remote uses infrared and therefore doesn’t work with the MacBook Pro. I went looking for a Bluetooth remote. It had to: \n Look decent. \n Be as simple as possible: not too many buttons, no display. \n Be rechargeable. \n In the end, nothing came close to the Siri Remote. It think it is stupid of Apple not to support it on Macs out of the box. But it does work, if you use extra software: \n Sirimote: is free and offers basic support. \n Better Touch Tool: is cheap and offers highly configurable support. I have configured it to, e.g., press left arrow if I swipe left on the Siri Remote’s trackpad. Additionally, BTT lets me control the MBP’s cursor via the SR’s trackpad. \n Alas, neither solution lets you display how much battery charge is left. But given how long a charge lasts, that’s not too much of an issue. I miss the slick UI of Remote Buddy, but apparently, support for the Siri Remote is in the works. They recommend to subscribe to their newsletter if you want to know when it’s finished. Conclusion   # The MacBook Pro is more an evolutionary than a revolutionary upgrade over my MacBook Air. I would have loved to have an even lighter device (like the MacBook 12\", which does not have enough ports and computing power for me). On the upside, I now have a maximally powerful machine with me when I travel. comments powered by Disqus."},
{"url": "https://2ality.com/2016/11/trace-globals-proxy.html", "title": "Controlling access to global variables via an ES6 proxy", "content": "Controlling access to global variables via an ES6 proxy dev javascript esnext js proxies The following function   traces the global variables that are accessed while evaluating a piece of JavaScript code. The way this works is as follows: \n The   statement wrapped around the code (line A) means that every variable access that “leaves” the scope of the code becomes a property access of  . \n The proxy observes what properties are accessed via its handler, which traps the operations “get” (line B) and “set” (line C), \n Unsing  : Explanations: \n We don’t return what   does, which is why the result is  . \n  shows up, because   checks its operand for a property with this key to determine which properties it should not expose as variables to its body.  This mechanism is explained in “Exploring ES6” . \n This is very hacky!   is a deprecated sloppy mode feature that is used in conjunction with a brand new ES6 feature.  Vue.js,  explained by qgustavor on reddit . Further reading   # \n Chapter “ Metaprogramming with proxies ” in ”Exploring ES6”. \n Section “ Property key  ” in Exploring ES6”. \n Blog post “ ES proposal: global ” (demonstrates how to properly access the global object) \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/11/concat-array-literal.html", "title": "Why does this work?  [].concat[1,2,3]", "content": "Why does this work?  dev javascript In this blog post, we look at a syntactic puzzle. This is just for fun; there is nothing useful you can do with what we examine. It may, however, make you more aware of how JavaScript works, syntactically. Question   # What do you need to do to get the following result? And why does it work? Answer   # This expression looks very similar to: But, actually, something completely different is going on: \n \n First, the result of   is computed. The result is the function stored in  . \n \n \n Then the operand of the square bracket operator is evaluated. It consists of  the comma operator  (in this context, the comma is an operator, like  ) applied to three numbers: \n \n \n \n Lastly, property   of the function returned by   is accessed. \n \n Normally, that produces  : If, however, you make the following assignment, you’ll get the result shown at the beginning: comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/movie-lines.html", "title": "Movie titles and lines in JavaScript", "content": "Movie titles and lines in JavaScript dev javascript humor #MovieLinesInCode Best of #MovieLinesInCode \n    \n@johnnypixel, paraphrased:\n comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/footnotes.html", "title": "Handling footnotes and references in HTML", "content": "Handling footnotes and references in HTML dev html webdev Requirements \n     On screen, one wants to show the footnote text as close as possible to the number pointing to the footnote. Whatever solution one chooses, it should also work on touch devices. Hence, a hover-only approach is not feasible. \n     In print, footnotes should be shown, as well. Hence, a tooltip-only solution is not acceptable. \n     Lastly, things should degrade gracefully if JavaScript is switched off. \n The HTML5 spec recommendations for footnotes HTML5 specification \n    attribute.\n Wikipedia-style highlighting of the currently active footnote Using the html_footnotes library \n  An   is either a footnote or a reference (citation). The markers in the main text referring to those annotations are called  .\n \n     A   is a number written in parentheses. Example:  \n     A   is a number written in square brackets. Example:  \n \n  The library consists of CSS to style annotations and pointers and of JavaScript that post-processes the HTML so that less code has to be written.\n comments powered by Disqus."},
{"url": "https://2ality.com/2017/01/babel-esm-spec-mode.html", "title": "Making transpiled ES modules more spec-compliant", "content": "Making transpiled ES modules more spec-compliant dev javascript esnext babel jsmodules A proposed “spec mode” for Babel makes transpiled ES modules more spec-compliant. That’s a crucial step in preparing for native ES modules. You’ll also learn how ES modules and CommonJS modules will interoperate on Node.js and how far along ES module support is on browsers and Node.js.  follow-up blog post: \n Module specifiers: differences between CJS and ESM \n Transpiling ES modules to CommonJS via Babel   # At the moment, the main way to use ES modules on Node.js and browsers is to transpile them to CommonJS modules via Babel. The benefit of this approach is that integration with the CommonJS ecosystem, including npm modules, is seamless. On the flip side, the code that Babel currently generates does not comply with the ECMAScript specification. That is a problem, because code that works with Babel now, won’t work as native modules. That’s why Diogo Franco has created  a pull request  that adds a so-called “spec mode” to  . Modules transpiled in this mode conform as closely to the spec as is possible without using ES6 proxies. The downside is that the only way to access normal (untranspiled) CommonJS modules is via a default import. Spec mode is switched on like this: How does the spec mode work?   # In this section, I explain where current transpilation deviates from ES module semantics and how the spec mode fixes that. ES module imports are live views of exports   # In an ES module, the imports are live views of the exported values. Babel simulates that in CommonJS in two steps.  keep variables and exports in sync. Whenever you update an exported variable  , Babel currently also updates the corresponding property  , as you can see in lines A, B and C. The marker property   lets importing modules know that this is a transpiled ES module (which matters especially for default exports). Spec mode stays much closer to the specification by implementing each export as a getter (line A) that returns the current value of the exported variable. This looks as follows. Each property in the second argument of   is defined via a  . For example,   is a non-enumerable data property whose value is   and   is an enumerable getter. If you use spec mode without transpiling   (as I’m doing in this blog post), exports will also handle the temporal dead zone correctly (you can’t access an export before its declaration was executed). The object stored in   is an approximation of an ECMAScript module record, which holds an ES module plus its metadata.  The transpiled non-spec-mode Babel code always refers to imports via the imported module. It never stores their values in variables. That way, the live connection is never broken. For example: Spec mode handles this step the same way. In ES modules, imported namespace objects are immutable and have no prototype   # Without spec mode, the transpiled Babel code lets you change properties of imported namespace objects and add properties to them. Additionally, namespace objects still have   as their prototype when they shouldn’t have one. As previously shown, spec mode fixes this by freezing   and by creating this object via  . In ES modules, you can’t access and change     # Without spec mode, Babel lets you add things to   and work around ES module exporting: As previously shown, spec mode prevents this by freezing  . In ES modules, you can only import what has been exported   # In non-spec mode, Babel allows you to do the following: In spec mode, Babel checks during importing that all imports have corresponding exports and throws an error if they don’t. An ES module can only default-import CommonJS modules   # The way it looks now, ES modules in Node.js will only let you default-import CommonJS modules: That is unfortunate, because it often does not reflect what is really going on – whenever a CommonJS module simulates named exports via an object. As a result, turning such a module into an ES module means that import statements have to be changed. However, it can’t be helped (at least initially), due to how much the semantics of both kinds of module differ. Two examples: \n \n The previous subsection mentioned a check for declarative imports – they must all exist in the modules one imports from. This check must be performed   the body of the module is executed. You can’t do that with CommonJS modules, which is why you can only default-import them. \n \n \n  may not be an object; it could be  ,  , a primitive value, etc. A default import makes it easier to deal with these cases. \n \n In non-spec mode, all imports shown in the previous code fragment work. Spec mode enforces the default import by wrapping imported CommonJS modules in module records, via the function  : ES module specifiers are URLs   # ES modules treat all module specifiers as URLs (much like the   attribute in   elements). That leads to a variety of issues: ending module specifiers with   may become common, the   character leads to URL-decoding, etc. # Importing modules statically (  statements) or dynamically (  operator) resolves module specifiers roughly the same as   ( source ): The following non-local dependencies will not be supported by ES modules on Node.js: \n \n \n \n \n  won’t be supported, either. As far as URL protocols go, Node.js will support at least  . Browsers support all protocols, including  . # In browsers, the resolution of module specifiers will probably continue to work as they do when you use CommonJS modules via Browserify and webpack: \n You will install native ES modules via npm. \n A module bundler will transpile modules. At the very least it will convert Node.js-style specifiers ( ) to URLs ( ). It may additionally combine multiple ES modules into either a single ES module or a custom format. \n As an alternative to transpiling modules statically, it is conceivable that you’ll be able to customize a module loader in a manner similar how RequireJS does it: mapping   to  , etc. \n If we are already transpiling module specifiers, it’d be nice if we could also have variables in them. The main use case being going from: to: Open issue: distinguishing ES modules from other JavaScript files   # With ES modules, there are now two kinds of files in JavaScript: \n Modules: can declaratively import modules, live in a module-local scope, etc. \n Scripts: cannot declaratively modules, live in global scope, etc. \n For more information consult Sect. “ Browsers: asynchronous modules versus synchronous scripts ” in “Exploring ES6”. Both files are used differently and their grammars differ. However, as of now, there is overlap: some files can be either scripts or modules. For example: In order to execute this file correctly, you need to know whether it is a script (in which case it logs  ) or a module (in which case it logs  ). # In browsers, it is always clear whether a file is a script or a module. It depends on how one refers to it: \n Script:  \n Module:  \n Module:  \n # In Node.js, the plan is to allow declarative imports of CommonJS files. Then one has to decide whether a given file is an ES module or not. Two approaches for doing so were rejected by the Node.js community: \n Marking ES modules via  \n Using metadata in   to specify which modules are ESM, as outlined in “ In Defense of .js ”. \n Two other approaches are currently being discussed: \n Ensure that ES modules and scripts have non-overlapping grammars ( details ). \n Give modules the dedicated file name extension   ( details ). \n The former approach is currently being favored, but I prefer the latter approach, because detection would not require “looking into” files. The downside is that JavaScript tools (editors etc.) would need to be made aware of the new file name extension. But they also need to be updated to handle ES modules properly. How long until we have native ES modules?   # Native ES modules in browsers   # \n Firefox:  in development \n Chrome:  in development \n Edge:  available behind a flag in EDGE 15 Preview Build 14342+ \n Webkit:  available in Safari Technology Preview 21+ \n Native ES modules in Node.js   # James M. Snell recently  tweeted  where Node.js is w.r.t. supporting ES modules: \n Prerequisite: Several issues need to be sorted out before Node.js can support ES modules – mainly: async vs. sync loading, timing, and the ability to support CommonJS modules. \n Once these obstacles are removed, the JavaScript engines that Node.js is based on (esp. V8) need to implement the spec changes. \n Given the time needed for the spec changes and the implementation, support for ES modules in Node.js will, at the earliest, be  . Experimental previews may happen before then, but nothing that is officially supported. \n Interoperability looks as follows: \n ES module (ESM):\n \n Import declaratively via  : ESM and CommonJS (default export only) \n Import programmatically via  : ESM and CommonJS (module record property  ) \n Import programmatically via  : ESM (module record) and CommonJS \n \n \n CommonJS module:\n \n Import programmatically via  : ESM and CommonJS (module record property  ) \n Import programmatically via  : ESM (module record) and CommonJS \n \n \n Further reading   # Sources of this blog post   # \n “ Wondering where we are with regard to ES6 module support for Node.js? ” (tweets by @jasnell) \n “ Add a spec mode to transform-es2015-modules-commonjs ” (pull request by Diogo Franco) \n “ ES6 Module Interoperability ” (Node.js enhancement proposal by Bradley Farias) \n More information on ES modules   # \n “ Native ECMAScript modules – the first overview ” (article by Serg Hospodarets) \n “ Modules ” (chapter in “Exploring ES6”) \n “ ES proposal:   – dynamically importing ES modules ” (2ality blog post) \n “ The future of bundling JavaScript modules ” (chapter in “Setting up ES6”) \n  Thanks to  Bradley Farias  and  Diogo Franco  for reviewing this blog post. comments powered by Disqus."},
{"url": "https://2ality.com/2017/01/messagechannel.html", "title": "Communicating between Web Workers via  MessageChannel", "content": "Communicating between Web Workers via  dev javascript clientjs concurrency Occasionally, you want Web Workers to communicate with each other. Doing so is not obvious as most Web Worker examples are about communicating between the main thread and a Web Worker. There, one uses   to send messages directly to the Worker. Alas, that doesn’t work for communicating between two Workers, because you can’t pass references to Workers around.    # The solution is to establish a channel between the Workers: We are creating a new   and sending references to its two ports to two Workers. Every port can both send and receive messages. Note the second parameter of  : It specifies that   and   should be transfered (not copied) to the Workers. We can do that because   implements the interface  . Posting messages   #  posts messages and looks as follows: The tool function   for inlining Worker code is explained later. The Worker performs the following steps: \n Line A: Listen to messages sent to you from the main thread. \n Line B: The first and only such message is an object whose property   holds the  . \n Line C: Send data over the channel, via  . \n Receiving messages   #  first receives its port and then uses it to receive messages: In line A, we could also have used  . But then you need to explicitly call   before you can receive messages. Unfortunately, the setter is more magical here than the method. The nice thing about receiving messages is that the channel buffers posted messages. Therefore, there is no need to worry about race conditions (sending too early or listening too late). Inlining Web Workers   # The following tool function is used for inlining Web Workers. For older browsers, using separate source files is safer, because creating Workers from blobs can be buggy and/or unsupported. Further reading   # \n “ The Basics of Web Workers ” by Eric Bidelman for HTML5 Rocks \n “ ” on MDN \n  Tips on Twitter from @mourner, @nolanlawson and @Dolphin_Wood helped with this blog post. comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/css4-selectors.html", "title": "What’s new in CSS 4 selectors", "content": "What’s new in CSS 4 selectors css dev html webdev \n     Determining the subject of a selector . Currently, if a selector consists of several compound selectors, the last one is considered its  . The subject determines what elements the rule applies to. CSS 4 allows one to make any compound selector the subject, by prepending a dollar sign. For example:\n \n        Here, if one hovers over a list element, the whole list will turn green. This is a great and dearly needed feature.\n     \n     Pseudo-class :nth-match() . Lets you apply a rule to every n-th match for a given selector list.\n \n        Previously, you could only access every n-th child. This selector gives you more flexibility.\n     \n     UI states pseudo-classes  allow you to style elements depending on their user interface state. Examples:  ,   (radio elements, checkbox elements, menu items, etc.),   (for input elements with range limitations).\n     \n     The matches-any pseudo-class  . Example:\n \n        The above selector is an abbreviation for\n \n     \n     The contextual reference element pseudo-class ‘:scope’.  When you use selectors to query for elements, you can start your search in a list of elements that is iterated over, one element at a time.   is a placeholder for the current element. Example:\n \n        The above returns all list items that are direct children of unordered lists that are direct children of the elements in  .\n     \n Discover What’s New in CSS 4 [selectors] comments powered by Disqus."},
{"url": "https://2ality.com/2011/11/super-references.html", "title": "A closer look at super-references in JavaScript and ECMAScript 6", "content": "A closer look at super-references in JavaScript and ECMAScript 6 esnext dev javascript jslang ECMAScript 6 specification draft \nThis post examines how super-references work in JavaScript and how they will be simplified by ECMAScript 6. To understand this post, it helps to be familiar with JavaScript inheritance. If you are not, consult  [2] .\n \n\n Extending constructors in JavaScript \nLet’s look at the following JavaScript code where the constructor   extends the constructor  . The extension is performed via a custom function   (whose code will be shown later).\n Super-references \n \n  is the first member in a chain of prototypes. Its direct prototype is   whose prototype is  .\nSuper-references (including super-calls) are a feature of ECMAScript 6 which allows one to write   much more succinctly:\n \nLets put the above intuitive description into an algorithm: To make the super-call  , the following steps are performed:\n Determine  , the prototype of the object in which the current method is located. Search for  : start at  , traverse the prototype chain until you find an object that has a property  , return the value of that property. Call the function you have found, but leave   as it was before. Rationale: the overridden version of   that is to be invoked needs to be able to access  ’s properties. Determine   (hard-coded):\n \n     Search for  .\n \n        Note that we also find a describe if there isn’t one in   directly, but in one of its prototypes.\n     Execute the method, but keep the current  :\n \n     [3] [2] Determining super \n  When you look for a method you let it know in which object you found it, similar to how   is handed to a method. When resolving a super-reference, the value of   is the prototype of that object. The drawback of this approach is that it incurs runtime costs for all methods, not just for those that are making super-references. These costs prevent dynamic super-references from being viable for ECMAScript 6.\n \n  The   of a method is the object it is stored in.   is always the prototype of the home object of the current method. To enable static super-references, ECMAScript 6 gives each relevant method an internal property [[HomeObject]] pointing to the method’s home object. That property’s value can be accessed while the method is executed, in order to compute  . There are three ways to set up [[HomeObject]]:\n \n     Declaratively: Methods in in an object literal have a special, more compact syntax in ECMAScript 6. If you use that syntax, [[HomeObject]] will be set up automatically.\n     \n     Declaratively: If you use ECMAScript 6 classes  [5] , [[HomeObject]] will be set up automatically.\n     \n     Imperatively: If you add methods to an object via   or    [6]  then those functions ensure that [[HomeObject]] is configured appropriately.\n     \n Simulating static super-references [4] gist Related reading Object Initializer super references Prototypes as classes – an introduction to JavaScript inheritance What’s up with the “constructor” property in JavaScript? JavaScript’s strict mode: a summary ECMAScript.next: classes ECMAScript.next: TC39’s September 2012 meeting comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/strict-equality-exemptions.html", "title": "When is it OK to use == in JavaScript?", "content": "When is it OK to use == in JavaScript? dev javascript jslang \nShort answer: never. This post looks at five possible exemptions from the rule to always use === and explains why they aren’t.\n \n \nJavaScript has two operators for determining whether two values are equal  [1] :\n \n     The strict equality operator   only considers values equal that have the same type. \n     The “normal” (or lenient) equality operator   tries to convert values of different types, before comparing like strict equality. \n Case 1: You know what you are comparing with [2] \n     Consistency: You don’t get any benefits from using   here, so why deviate from the simple rule of avoiding it? \n     Simplicity and performance: In general,   is the simpler operation, because it doesn’t convert its operands. The performance landscape across JavaScript engines is uneven  [3] , but on most browsers   is as fast or faster than  . \n Case 2: comparing with undefined and null Case 3: comparing strings and numbers Case 4: comparing objects to primitives [4] \n     Is it really about comparing either a wrapped string or a string to the right-hand side? It seems unlikely, but if so, you should be very careful about documenting what is going on.\n     \n     Do you want to convert   to a string? Then you can write more explicitly\n \n        \n     \n     Do you want to extract a wrapped primitive? Then you should consider\n \n     \n Case 5: JavaScript is flexible – my code should be, too \n     Even the standard conversions might not always work the way you need them too. Examples:\n \n     \n     Lenient equality works differently from how conversions are normally performed:\n \n     \n     An explicit conversion plus strict equality results in more descriptive code. Compare: Flexibility via lenient equality.\n \n        Alternative: Flexibility via an explicit conversion and strict equals.\n \n     \n     Who says your code has to be flexible? It can be argued that JavaScript’s default flexibility is a bug rather than a feature. Writing defensive code more quickly exposes bugs. A defensive version of   looks as follows:\n \n        If you want to pass anything but a primitive number to this function, you must perform a conversion first.\n     \n Conclusion Related reading Equality in JavaScript: === versus == Improving the JavaScript typeof operator jsPerf: == versus === JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/nodejs-shell-scripting.html", "title": "Write your shell scripts in JavaScript, via Node.js", "content": "Write your shell scripts in JavaScript, via Node.js jsshell dev nodejs javascript shell jsshell \nDo you know JavaScript and want to write a shell script? Then you should give  Node.js  a try. It is easy to install and shell scripts are a great way to get to know it. This post explains the basics.\n\n \n\n Accessing arguments nomnom optimist Reading a text file one solution Writing a text file Cross-platform considerations Determining the line break string. Working with paths module  Running the script Other topics \n        works just like in browsers.   is a global object, not a module, so there is nothing to  . \n        is a  readable stream . The previously linked solution for  reading lines  from a stream works here, too.   is a global object.\n     \n      via  . \n Related reading Tip: load source from a file in the Node.js shell Execute code each time the Node.js REPL starts comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/shim-vs-polyfill.html", "title": "What is the difference between a shim and a polyfill?", "content": "What is the difference between a shim and a polyfill? dev javascript clientjs jslang \n  A   is a library that brings a new API to an older environment, using only the means of that environment.\n \n  In October 2010, Remy Sharp  blogged  about the term “polyfill” [via Rick Waldron]:\n tooled-up.com HTML5 Cross Browser Polyfills es5-shim comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/fake-operator-overloading.html", "title": "Fake operator overloading in JavaScript", "content": "Fake operator overloading in JavaScript dev javascript jslang What is {} + {} in JavaScript? \nThis post describes how to do a limited version of operator overloading in JavaScript.\nWith the technique described here, you’ll be able to implement a type   that can be used as follows:\n Letting operators call methods \n  All operators that   (convert) their operands to primitives. The following two objects allow you to test which ones do:\n Implementing StringBuilder def.js – fake operator overloading used for an inheritance API def.js \n     As a constructor: Then it simply produces a new instance. \n     As a function: Then it must return an object that works as a fake operand. \n Perform the function call   which creates a new constructor   and returns a function  .   could be called, like in (I). In which case it would add properties to  . But here it is used as a fake operand –   has added the method   which will be invoked in step 3.   is also stored in a global variable (hidden inside a closure).\n      is invoked as a function and stores two values inside  :\n         \n              holds  ’s argument \n              refers to  \n         \n     The operator calls   which first lets   (which is still accessible via  ’s closure) inherit from   and then calls   to add the properties stored in  .\n     Triggering even more calls Detecting the operator \n     Addition:  \n     Multiplication:  \n source code How useful is fake operator overloading? Related reading ECMAScript 5.1 language specification , Sect. 9.3, “ToNumber”. JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/subtyping-builtins.html", "title": "Subclassing builtins in ECMAScript 5", "content": "Subclassing builtins in ECMAScript 5 esnext dev javascript jslang Terminology \n     Subclassing a builtin  : Create a sub-constructor   of a given built-in constructor  .  ’s instances are also instances of  .\n     \n     Extending a builtin  : Adding new methods to  .\n     \n Obstacle 1: instances with internal properties [2] \n     Wrapper constructors: Instances of  ,   and   wrap primitives. They all have the internal property [[PrimitiveValue]] whose value is returned by  . Additionally,   instances support indexed access of characters.\n         \n             Boolean: internal property [[PrimitiveValue]] \n             Number: internal property [[PrimitiveValue]] \n             String: internal property [[PrimitiveValue]], custom method [[GetOwnProperty]], normal property length. [[GetOwnProperty]] accesses the wrapped primitive string when an array index is used.\n             \n         \n     \n    \n     Array: The custom internal method [[DefineOwnProperty]] intercepts properties being set. It ensures that the   property works correctly, by keeping   up to date when array elements are added or removed and by removing excess elements when   is made smaller.\n     \n     Date: internal property [[PrimitiveValue]] stores the time represented by a date instance.\n     \n     Function: internal property [[Call]] (the code to execute when the instance is called) and possibly others.\n     \n     RegExp: internal property [[Match]] in addition to non-internal properties. Quoting the ECMAScript specification:\n         \n     \n \n    is a sub-constructor of of  . It has a getter   that returns the actual elements in an array, ignoring holes (where   counts holes). The trick used to implement   is that it creates an array instance and copies its methods to it. Credit: inspired by a blog post by Ben Nadel  [3] .\n Obstacle 2: a constructor that can’t be called as a function \n  Inside the sub-constructor, create a new super-instance and copy its properties to the sub-instance.\n Another solution: delegation Subclassing builtins via __proto__ and in ECMAScript 6 blog post \n     Via the  special property   that is supported by more and more browsers and will most probably be part of ECMAScript 6.\n     \n     Via canonical subclassing patterns: which work for builtins in ECMAScript 6, thanks to changes that have been made.\n     \n     Via  class definitions , where you can extend any builtin.\n     \n References ECMAScript 5.1 specification , Chap. 15 [details on builtins: instance properties etc.] Prototypes as classes – an introduction to JavaScript inheritance “ Extending JavaScript Arrays While Keeping Native Bracket-Notation Functionality ” by Ben Nadel comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/duolingo.html", "title": "Duolingo: using free online language lessons to translate texts", "content": "Duolingo: using free online language lessons to translate texts foreign languages education life History: putting crowds to work Massive-scale online collaboration reCAPTCHA \n \n  reCAPTCHA shows two words and lets people decipher them. The results are checked for accuracy in two ways: First, of the two words, one is already known to the system, the other one is new (obviously, they are always shown in random order). Second, the same words are always transcribed by several people which lets reCAPTCHA use the most frequent transcription.\n \n  reCAPTCHA is used by many sites and processes 100 million words a day leading to 2.5 million books being transcribed per year. 750,000,000 distinct people have solved recaptchas – 10% of humanity. Compare that to previous “big projects” where crowds had to be organized, for example building the pyramids or flying to the moon. Those always involved a maximum of 100,000 thousand people, because more couldn’t be coordinated. Duolingo has been inspired by the idea of what could be achieved if one could organize just 100 million people.\n\n Duolingo Duolingo project \n     Lack of bilinguals: participants have to speak two languages well in order to be able to help. \n     Lack of motivation: translating is a lot of work. Why should you want to help? \n \n  Surprisingly, Duolingo is good at two tasks. On one hand, it teaches languages as well as leading educational software. It provides the added benefit of letting students work with real content. On the other hand, translations are as accurate as those produced by professional translators. And it’s fast: Duolingo translates the English Wikipedia to Spanish in 5 weeks with 100,000 users, in 80 hours with 1 million users. Currently, the Spanish Wikipedia has 20% of the size of the English Wikipedia. Letting humans translate the remaining 80% would cost at the very least 50 million dollars.\n \n  Currently, learning a language is an expensive proposition. Duolingo enables even poor people to afford a good course. They pay with their time, not with money.\n\n Related reading Foreign languages: four ways to avoid learning vocabulary Crowdsourcing language translations comments powered by Disqus."},
{"url": "https://2ality.com/2016/05/six-nifty-es6-tricks.html", "title": "Six nifty ES6 tricks", "content": "Six nifty ES6 tricks dev javascript esnext In this blog post, I show six tricks enabled by new ES6 features. At the end of each section, I point to related material in my book “ Exploring ES6 ” (which is free to read online). Enforcing mandatory parameters via parameter default values   # ES6 parameter default values are only evaluated when they are actually used. That lets you enforce that a given parameter be provided: The function call   is only made if the parameter   is missing. Interaction: \n Sect. “ Required parameters ” in “Exploring ES6” \n Iterating over Array indices and elements via the   loop   # Method   lets you iterate over the elements of an Array. It also gives you each element’s index, should you want it: The ES6   loop is a loop that supports ES6 iteration (via iterables and iterators) and destructuring. If you combine destructuring with the new Array method  , you get:  returns an iterable over index-element pairs. The destructuring pattern   gives us direct access to both components of each pair. The parameter of   is a so-called  , which brings string interpolation to JavaScript. \n Chap. “ Destructuring ” in “Exploring ES6” \n Chap. “ Iterables and iterators ” in “Exploring ES6” \n Sect. “ Iterating with a destructuring pattern ” in “Exploring ES6” \n Chap. “ Template literals ” in “Exploring ES6” \n Iterating over Unicode code points   # Some Unicode   (roughly, characters) comprise two JavaScript characters. For example, emojis: Strings implement ES6 iteration. If you iterate over them, you get encoded code points (one or two JavaScript characters). For example: That gives you a way to count the number of code points in a string: The spread operator ( ) inserts the items “in” its operand into an Array. \n Chap. “ Unicode in ES6 ” in “Exploring ES6” \n Sect. “ The spread operator ( ) ” in “Exploring ES6” \n Swapping variable values via destructuring   # If you put two variables into an Array and then destructure that Array “into” the same variables, you can swap their values without needing an intermediate variable: It is conceivable that JavaScript engines will optimize this pattern in the future so that no Array is created. \n Chap. “ Destructuring ” in “Exploring ES6” \n Simple templating via template literals   # ES6 template literals are more like string literals than like traditional text templates. But you can use them for templating if you return them from functions: The function   (an  arrow function ) maps the Array   to a string. Let’s use   on the Array  : \n Blog post “ Handling whitespace in ES6 template literals ” \n Sect. “ Text templating via untagged template literals ” in “Exploring ES6” \n Chap. “ Arrow functions ” in “Exploring ES6” \n Simple mixins via subclass factories   # If an ES6 class   another class, that class is specified dynamically, via an arbitrary expression (not statically via an identifier): That allows you to implement a mixin as a function that maps a class   to a new class (with the mixin methods) whose superclass is  . For example, the following two functions   and   are mixins: You can use them to compose a class   as follows. \n Sect. “ Simple mixins ” in “Exploring ES6” \n Further reading   # Two chapters of “Exploring ES6” give a good overview of ECMAScript 6: \n An overview of what’s new in ES6 \n First steps with ECMAScript 6  [features that are easy to adopt] \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/06/taking-a-break.html", "title": "Taking a break", "content": "Taking a break 2ality For health reasons, I’m taking June–August off from work (Twitter, blogging, etc.). See you in September! To tide you over, you can read (and buy, to support my work) my books, which are free to read online: \n Speaking JavaScript \n Exploring ES6 \n Setting up ES6 \n Exploring ES2016 and ES2017 \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/09/better-ejs.html", "title": "Improving the syntax of EJS templates", "content": "Improving the syntax of EJS templates dev javascript I really like the way  EJS templates  work, because the meta-language (loops, if-then-else, etc.) is just JavaScript. This blog post describes ideas for improving their syntax. EJS templates   # This is an example of an EJS template: I see two problems with this template: It outputs empty lines for line 2 and 4. The delimiters   and   make the template look cluttered. Suppressing whitespace   # The first problem can be fixed by using the delimiters   and   which suppress any whitespace generated by that line: Better control flow syntax   # If control flow syntax is enabled by a single character at the beginning of a line then the template looks much nicer: The way to get this syntax is via a work-around – use a regular expression to convert: to: For example: This regular expression allows the   to be indented: One more improvement   # Additionally,  there is an issue  for letting people change the delimiter   to something different. Then the template could look like this: I find that easier to read, given that the delimiters are surrounded by HTML with lots of angle brackets. comments powered by Disqus."},
{"url": "https://2ality.com/2016/10/rest-spread-properties.html", "title": "ES2018: Rest/Spread Properties", "content": "ES2018: Rest/Spread Properties dev javascript esnext es2018  This proposal has reached stage 4 and will be part of ECMAScript 2018. The ECMAScript proposal “ Rest/Spread Properties ” by Sebastian Markbåge enables: \n \n The rest operator ( ) in object destructuring. At the moment, this operator only works for Array destructuring and in parameter definitions. \n \n \n The spread operator ( ) in object literals. At the moment, this operator only works in Array literals and in function and method calls. \n \n The rest operator ( ) in object destructuring   # Inside object destructuring patterns, the rest operator ( ) copies all enumerable own properties of the destructuring source into its operand, except those that were already mentioned in the object literal. If you are using object destructuring to handle named parameters, the rest operator enables you to collect all remaining parameters: Syntactic restrictions   # Per top level of each object literal, you can use the rest operator at most once and it must appear at the end: You can, however, use the rest operator several times if you nest it: The spread operator ( ) in object literals   # Inside object literals, the spread operator ( ) inserts all enumerable own properties of its operand into the object created via the literal: Note that order matters even if property keys don’t clash, because objects record insertion order: If keys clash, order determines which entry “wins”: Common use cases for the object spread operator   # In this section, we’ll look at things that you can use the spread operator for. I’ll also show how to do these things via  , which is very similar to the spread operator (we’ll compare them in more detail later). Cloning objects   # Cloning the enumerable own properties of an object  : The prototypes of the clones are always  , which is the default for objects created via object literals: Cloning an object  , including its prototype: Note that   inside object literals is only a mandatory feature in web browsers, not in JavaScript engines in general. True clones of objects   # Sometimes you need to faithfully copy all own properties of an object   and their attributes ( ,  , ...), including getters and setters. Then   and the spread operator don’t work. You need to use  property descriptors : If you additionally want to preserve the prototype of  , you can use  :  is explained in “Exploring ES2016 and ES2017”. Pitfall: cloning is always shallow   # Keep in mind that with all the ways of cloning that we have looked at, you only get shallow copies: If one of the original property values is an object, the clone will refer to the same object, it will not be (recursively, deeply) cloned itself: Various other use cases   # Merging two objects   and  : Filling in defaults for user data: Non-destructively updating property  : Specifying the default values for properties   and   inline: Spreading objects versus     # The spread operator and   are very similar. The main difference is that spreading defines new properties, while   sets them. What exactly that means is explained later. The two ways of using     # There are two ways of using  : First, destructively (an existing object is changed): Here,   is modified;   and   are copied into it. Second, non-destructively (no existing object is changed): Here, a new object is created via an empty object literal and   and   are copied into it. At the end, this new object is returned and assigned to  . The spread operator is very similar to the second way of using  . Next, we’ll look at where the two are similar and where they differ. Both spread and   read values via a “get” operation   # Both operations use normal “get” operations to read property values from the source, before writing them to the target. As a result, getters are turned into normal data properties during this process. Let’s look at an example:  has the getter   (its   has the properties   and  ): But it its clones   and  ,   is a normal data property (its property descriptor has the properties   and  ): Spread defines properties,   sets them   # The spread operator defines new properties in the target,   uses a normal “set” operation to create them. That has two consequences. # First,   triggers setters, spread doesn’t: The previous piece of code installs a setter   that is inherited by all normal objects. If we clone   via  , the inherited setter is triggered: With spread, it isn’t:  also triggers own setters during copying, it does not overwrite them. # Second, you can stop   from creating own properties via inherited read-only properties, but not the spread operator: The previous piece of code installs the read-only property   that is inherited by all normal objects. As a consequence, you can’t use assignment to create the own property  , anymore (you only get an exception in strict mode; in sloppy mode, setting fails silently): In the following code, we successfully create the property   via an object literal. This works, because object literals don’t set properties, they   them: However,   uses assignment for creating properties, which is why we can’t clone  : Cloning via the spread operator works: Both spread and   only consider own enumerable properties   # Both operations ignore all inherited properties and all non-enumerable own properties. The following object   inherits one (enumerable!) property from   and has two own properties: If you clone  , the result only has the property  . The properties   and   are not copied: comments powered by Disqus."},
{"url": "https://2ality.com/2016/09/template-literal-revision.html", "title": "ES2018: Template Literal Revision", "content": "ES2018: Template Literal Revision dev javascript esnext es2018 template literals The ECMAScript proposal “ Template Literal Revision ” by Tim Disney reached stage 4 and will be part of ECMAScript 2018. It proposes to give the innards of tagged template literals more syntactic freedom. Tag functions and escape sequences   # With tagged template literals, you can make a function call by mentioning a function before a template literal:  is a so-called  . Tag functions receive two versions of the fixed string pieces ( ) in a template literal: \n Cooked: escape sequences are interpreted.   becomes  . \n Raw: escape sequences are normal text.   becomes  . \n The following tag function illustrates how that works: Using the tag function: For more information on tag functions, consult Sect. “ Implementing tag functions ” in “Exploring ES6”. Problem: some text is illegal after backslashes   # The problem is that even with the raw version, you don’t have total freedom within template literals in ES2016. After a backslash, some sequences of characters are not legal anymore: \n  starts a Unicode escape, which must look like   or  . \n  starts a hex escape, which must look like  . \n  plus digit starts an octal escape (such as  ). Octal escapes are forbidden in template literals and strict mode string literals. \n That prevents tagged template literals such as: Solution   # The solution is drop all syntactic restrictions related to escape sequences. Then illegal escape sequences simply show up verbatim in the raw representation. But what about the cooked representation? Every template string with an illegal escape sequence is an undefined element in the cooked Array: comments powered by Disqus."},
{"url": "https://2ality.com/2016/09/keynote-setup.html", "title": "Apple Keynote: combining mirroring and Presenter Display", "content": "Apple Keynote: combining mirroring and Presenter Display computers presenting apple mac ios This blog post describes a new setup for presenting with Apple’s Keynote app that I’ve experimented with. It involves: \n A Mac running Keynote \n An iOS device (iPhone or iMac) \n The wish   # For presentations, mirroring the laptop’s display with the projector’s is perfect, because: \n It is easy to do interactive demos (e.g. switch to a REPL, run some JavaScript code). \n You can use the cursor as a virtual laser pointer (there is a preference under “Slideshow” to show the cursor in that mode). \n But there are several pieces of information that would be nice to have while presenting: \n The next slide, for smoother segues \n Remaining time (countdown) \n Presenter notes (I don’t use them, but many people do) \n Therefore, many people don’t mirror displays and Keynote’s Presenter Display. But then you lose the previously mentioned advantages. The best of both worlds   # It’d be cool to have mirroring plus extra information displayed somewhere, but I don’t even know how exactly that would work. Non-solution: Keynote Remote   # Keynote Remote  displays presenter information on an iOS device. The information stays in sync with the currently displayed slide. However, there are several problems: \n You need Wi-Fi, laptop and iOS device need to be on the same network. Some sources on the internet say, Bluetooth works, too, but I couldn’t get it to work. You can turn your laptop into a hotspot, but then you can’t access the internet and everyone can access the hotspot (it’s public)! \n Needs to be restarted if you take Keynote out of full screen. The work-around is simple:: restart the slide mode from the iOS device. But it’s one more thing to remember. \n Limited configurability: you can’t configure the presenter information much. \n Solution: turn your iOS device into an external display   # Duet Display  lets you turn an iPhone or an iPad into an external display. It does so via a wire, so there is no finicky Wi-Fi or Bluetooth involved. Now you have three displays: \n Your laptop \n Your iOS device \n The projector \n And now the kicker: in your Mac’s Display preferences, you can alt-drag one display on top of another one so that only two of the three displays are mirrored. Thus, the projector mirrors your laptop, while your iOS device can show the presenter information. Tips: \n On the presenter display, you can rearrange the location and size of everything (especially useful for clock and timer). \n You can tap on the iOS device to click. \n Keeping track of time: unfortunately, the timer is reset whenever you leave the slide show mode. That leaves the current time as the better alternative. \n Further tools   # \n Attach your iOS device to your laptop’s display via  Ten One’s Mountie . \n Simulate a projector via an iMac:\n \n Turn your Mac or PC into an AirPlay receiver via  AirServer Universal . Alas, I couldn’t get this solution to work with partial mirroring (all-display mirroring worked). \n Use your iMac as an external display via  Target Display Mode . \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/09/three-useful-babel-presets.html", "title": "Three useful Babel presets", "content": "Three useful Babel presets dev javascript babel esnext As of version 6, Babel supports  , sets of features that can be enabled together. This blog post looks at three new useful Babel presets (and, as a bonus, two presets especially for Node.js). Complementing or replacing     # These two presets are useful complements to   (for ES6): \n  gives you one of the two features of ES2016:  the exponentiation operator . The other feature,  , is supported via  the standard library polyfill . \n  gives you:\n \n :  optional trailing commas  in parameter lists and function/method calls. \n :  async functions . This is the one feature after ES6 that I’m most looking forward to. \n \n \n Note that if you want all of ES2017 (as much as it is supported by Babel) then you need three presets:  ,   and  . Alternatively, there is also a meta-preset: \n  will always contain all the “yearly” presets. At the moment, those are:  ,   and  . \n Bonus: minimal presets for Node.js   # \n \n  replaces  . It checks the Node.js version and only enables plugins whose functionality is missing (not much in recent versions). \n \n \n  replaces  . It determines what plugins are needed via feature detection. As the repository’s readme states: that only makes sense for Node.js, but not for browsers. \n \n More information   # \n Configuring Babel: “ Setting up ES6 ” \n Tracking ES2017: “ Feature watch: ECMAScript 2017 ” (accepted and upcoming features) \n ES2016 and ES2017: “ Exploring ES2016 and ES2017 ” \n ECMAScript features supported by Node.js:  node.green \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/08/function-prototype-tostring.html", "title": "ES2019:  Function.prototype.toString  revision", "content": "ES2019:   revision dev javascript es2019 The ECMAScript proposal “  revision ” (by Michael Ficarra) is at  stage 4  and therefore part of ECMAScript 2019. It brings two major improvements  compared to ES2016 : \n Whenever possible – source code: If a function was created via ECMAScript source code,   must return that source code. In ES2016, whether to do so is left up to engines. \n \n Otherwise – standardized placeholder: In ES2016, if   could not (or would not) create syntactically valid ECMAScript code, it had to return a string for which   throws a  . In other words,   must not be able to parse the string. This requirement was forward-incompatible – whatever string you come up with, you can never be completely sure that a future version of ECMAScript doesn’t make it syntactically valid. In contrast, the proposal standardizes a placeholder: a function whose body is  . Details are explained in the next section. \n The algorithm   # The proposal distinguishes: \n \n Functions defined via ECMAScript code:   must return their original source code. \n  may return code that is only syntactically valid within its syntactic context: \n \n The following two kinds of line breaks are converted to Unix-style  : \n \n Windows:  \n Classic macOS:  \n \n \n \n Built-in function objects, bound function exotic objects and callable objects which were not defined via ECMAScript code:   must return a so-called   string, which looks as follows. \n \n The parameters can be omitted. If the function is a “ well-known intrinsic object ” (such as  ,  ,  , etc.) then the initial value of its   property must appear in the result. Examples: \n \n \n \n Functions created dynamically via the constructors   and  : engines must create the appropriate source code and attach it to the functions. This source code is then returned by  . \n \n \n In all other cases (the receiver   is not callable): throw a  . \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/09/global.html", "title": "ES proposal:  global", "content": "ES proposal:  dev javascript esnext es proposal section “ ” The ECMAScript proposal “ ” by Jordan Harband is currently at stage 3. It provides a new standard way of accessing the global object. Referring to the global object   # The following are a few popular ways of referring to the global object: \n Global variables:\n \n Global variable  : is the classic way of referring to the global object. But it doesn’t work in Node.js and in Web Workers. \n Global variable  : is available in Web Workers and browsers in general. But it isn’t supported by Node.js. Some people take   appearing in code, as a sign that that code works in both Web Workers and normal browser settings. \n Global variable  : is only available in Node.js. Until now! \n \n \n :\n \n  in global scope: refers to the global object. The only problem is that Node.js modules and ES6 modules have their own scopes, which means that this approach doesn’t work there. \n  during a function call in sloppy mode: If you call a function via a function call (and not a method call), its   refers to the global object in non-strict mode. In strict mode, it is  . \n : works in both strict mode and sloppy mode, because the parameters of   are always evaluated in sloppy mode. There is one important caveat:  ,  , etc. are not available if you use CSP (Content Security Policy). That makes this approach unsuited in many cases. \n \n \n The proposal   # The ECMAScript proposal standardizes the global variable   for accessing the global object. It also standardizes that the global object must have   in its prototype chain. The following is already true in web browsers today: Best practices   # The global object is now considered a mistake that JavaScript can’t get rid of, due to backward compatibility. It affects performance negatively and is generally a confusing feature. ECMAScript 6 moves away from the global object by providing three new ways for declaring variables that don’t create global properties in global scope (as   declarations and function declarations do): \n  declarations \n  declarations \n Class declarations \n In other words: all properties of the global object are global variables, but not all global variables are properties of the global object. For example (executed in global scope): It is normally preferable to refer to global variables as variables and not as properties of, e.g.,  . That has always worked on all JavaScript platforms. Furthermore, starting with ES6 (and even before), most JavaScript code lives in modules and will thus never be in global scope. Therefore,   will mostly be relevant for polyfills. A polyfill   # The proposal’s author, Jordan Harband, has written  a polyfill  for it. Using it with CommonJS syntax: Using it with ES6 module syntax: The package always uses the “most native” approach available (  on Node.js etc.,   in normal browser contexts, etc.). Computing a reference to the global object   # Internally, the polyfill uses the function   to compute a reference to the global object. This is how that is achieved: More information on the global object   # \n An introduction to JavaScript’s global object in “Speaking JavaScript”. \n ES6 and the global object in “Exploring ES6”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/10/asynchronous-iteration.html", "title": "ES2018: asynchronous iteration", "content": "ES2018: asynchronous iteration dev javascript esnext async es2018 chapter “Asynchronous iteration” This blog post explains the ECMAScript proposal “ Asynchronous Iteration ” by Domenic Denicola and Kevin Smith. It has reached stage 4 on 2018-01-25 and is part of ECMAScript 2018. Asynchronous iteration   # With ECMAScript 6, JavaScript got built-in support for synchronously iterating over data. But what about data that is delivered asynchronously? For example, lines of text, read asynchronously from a file or an HTTP connection. This proposal brings support for that kind of data. Before we go into it, let’s first recap synchronous iteration. Synchronous iteration   # Synchronous iteration was introduced with ES6 and works as follows: \n Iterable: an object that signals that it can be iterated over, via a method whose key is  . \n Iterator: an object returned by invoking   on an iterable. It wraps each iterated element in an object and returns it via its method   – one at a time. \n IteratorResult: an object returned by  . Property   contains an iterated element, property   is     the last element (  can usually be ignored then; it’s almost always  ). \n I’ll demonstrate via an Array: Asynchronous iteration   # The problem is that the previously explained way of iterating is  , it doesn’t work for asynchronous sources of data. For example, in the following code,   cannot deliver its asynchronous data via synchronous iteration: The proposal specifies a new protocol for iteration that works asynchronously: \n Async iterables are marked via  . \n Method   of an async iterator returns Promises for IteratorResults (vs. IteratorResults directly). \n You may wonder whether it would be possible to instead use a synchronous iterator that returns one Promise for each iterated element. But that is not enough – whether or not iteration is   is generally determined asynchronously. Using an asynchronous iterable looks as follows. Function   is explained later. It converts its synchronously iterable parameter into an async iterable. Within an asynchronous function, you can process the results of the Promises via   and the code becomes simpler: The interfaces for async iteration   # In TypeScript notation, the interfaces look as follows.    # The proposal also specifies an asynchronous version of  the   loop :  :  and rejections   # Similarly to how   works in async functions, the loop throws an exception if   returns a rejection: Note that we have just used an Immediately Invoked Async Function Expression (IIAFE, pronounced “yaffee”). It starts in line (A) and ends in line (B). We need to do that because   doesn’t work at the top level of modules and scripts. It does work everywhere where   can be used. Namely, in async functions and async generators (which are explained later).  and sync iterables   #  can also be used to iterate over sync iterables:  converts each iterated value via   to a Promise, which it then awaits. That means that it works for both Promises and normal values. Asynchronous generators   # Normal (synchronous) generators help with implementing synchronous iterables. Asynchronous generators do the same for asynchronous iterables. For example, we have previously used the function   which converts a   into an asynchronous iterable. This is how you would implement this function via an async generator: Note the asterisk after  : \n A   is turned into a   by putting an asterisk after  . \n An   is turned into an   by doing the same. \n How do async generators work? \n A normal generator returns a generator object  . Each invocation   returns an object   that wraps a yielded value. \n An async generator returns a generator object  . Each invocation   returns   an object   that wraps a yielded value. \n Queuing   invocations   # The JavaScript engine internally queues invocations of   and feeds them to an async generator once it is ready. That is, after calling  , you can call again, right away; you don’t have to wait for the Promise it returns to be settled. In most cases, though, you do want to wait for the settlement, because you need the value of   in order to decide whether to call   again or not. That’s how the   loop works. Use cases for calling   several times without waiting for settlements include:  Retrieving Promises to be processed via  . If you know how many elements there are in an async iterable, you don’t need to check  .  Async generators as sinks for data, where you don’t always need to know when they are done.  Thanks to @domenic and @zenparsing for these use cases.  in async generators   # You can use   and   inside async generators. For example: One interesting aspect of combining   and   is that   can’t stop   from returning a Promise, but it can stop that Promise from being settled: Let’s take a closer look at line (A) and (B): \n The   in line (B) fulfills a Promise. That Promise is returned by   immediately. \n Before that Promise is fulfilled, the operand of   (the Promise returned by   in line (A)) must be fulfilled. \n That means that these two lines correspond (roughly) to this code: If you want to dig deeper – this is a   of how async generators work: This code assumes that   is always called without arguments. A complete implementation would have to queue arguments, too.  in async generators   #  in async generators works analogously to how it works in normal generators – like a recursive invocation: In line (A),   calls  , which means that all elements yielded by   are yielded by  : The operand of   can be any async iterable. Sync iterables are automatically converted to async iterables, just like for  . Errors   # In normal generators,   can throw exceptions. In async generators,   can reject the Promise it returns: Converting exceptions to rejections is similar to how async functions work. Async function vs. async generator function   # Async function: \n Returns immediately with a Promise. \n That Promise is fulfilled via   and rejected via  . \n Async generator function: \n Returns immediately with an async iterable. \n Every invocation of   returns a Promise.   fulfills the “current” Promise with  .   rejects the “current” Promise with  . \n Examples   # The source code for the examples is available via the repository   on GitHub. Using asynchronous iteration via Babel   # The example repo uses   to run its code. This is how it configures Babel in its  : Example: turning an async iterable into an Array   # Function   collects all elements of   in an Array. I don’t use   in this case, I invoke the async iteration protocol manually. I also don’t close   if I’m finished before the iterable is  . This is the test for  : Note how nicely async functions work together with the mocha test framework: for asynchronous tests, the second parameter of   can return a Promise. Example: a queue as an async iterable   # The example repo also has an implementation for an asynchronous queue, called  . It’s implementation is relatively complex, which is why I don’t show it here. This is the test for  : Example: reading text lines asynchronously   # Let’s implement code that reads text lines asynchronously. We’ll do it in three steps. Step 1: read text data in chunks via the Node.js   API (which is based on callbacks) and push it into an   (which was introduced in the previous section). Step 2: Use   to iterate over the chunks of text and   lines of text. Step 3: combine the two previous functions. We first feed chunks of text into a   via   and then convert that   into an async iterable over lines of text via  . Lastly, this is how you’d use   from within a Node.js script: WHATWG Streams are async iterables   # WHATWG streams  are async iterables, meaning that you can use   to process them: The specification of asynchronous iteration   # The spec introduces several new concepts and entities: \n Two new interfaces ,   and  \n New well-known intrinsic objects :  ,  ,  ,  ,  . \n One new well-known symbol :  \n No new global variables are introduced by this feature. Async generators   # If you want to understand how async generators work, it’s best to start with Sect. “ AsyncGenerator Abstract Operations ”. They key to understanding async generators is to understand how queuing works. Two internal properties of async generator objects play important roles w.r.t. queuing: \n  contains the state the generator is currently in:  ,  ,  ,   (it is   before it is fully initialized) \n  holds pending invocations of  . Each queue entry contains two fields:\n \n : the parameter of  ,   or   that lead to the entry being enqueued. The type of the completion ( ,  ,  ) indicates which method call created the entry and determines what happens after dequeuing. \n : the   of the pending Promise. \n \n \n The queue is managed mainly via two operations: \n \n Enqueuing happens via  . This is the operation that is called by  ,   and  . It adds an entry to the AsyncGeneratorQueue. Then   is called, but only if the generator’s state isn’t  : \n \n Therefore, if a generator calls  ,   or   from inside itself then the effects of that call will be delayed. \n  leads to a suspension of the generator, but its state remains  . Hence, it will not be resumed by  . \n \n \n \n Dequeuing happens via  .   is invoked after enqueuing, but also after settling a queued Promise (e.g. via  ), because there may now be new queued pending Promises, allowing execution to continue. If the queue is empty, return immediately. Otherwise, the current Promise is the first element of the queue: \n \n If the async generator was suspended by  , it is resumed and continues to run. The current Promise is later settled via   or  . \n If the generator is already completed, this operation calls   and   itself, meaning that all queued pending Promises will eventually be settled. \n \n \n Async-from-Sync Iterator Objects   # To get an async iterator from an object  , you call   (  is a symbol). If   doesn’t have a method  ,   retrieves a sync iterator via method   and converts it to an async iterator via  . The   loop   #  works almost exactly like  , but there is an   whenever the contents of an IteratorResult are accessed. You can see that by looking at Sect. “ Runtime Semantics: ForIn/OfBodyEvaluation ”. Notably, iterators are closed similarly, via  , towards the end of this section. Alternatives to async iteration   # Let’s look at two alternatives to async iteration for processing async data. Alternative 1: Communicating Sequential Processes (CSP)   # The following code demonstrates the CSP library  :  defines a “process” that is instantiated twice (in line (B) and in line (C), via  ). The processes are connected via the “channel”  , which is created in line (A) and passed to   via its second parameter. A channel is basically a queue. How does CSP compare to async iteration? \n The coding style is also synchronous. \n Channels feels like a good abstraction for producing and consuming async data. \n Making the connections between processes explicit, as channels, means that you can configure how they work (how much is buffered, when to block, etc.). \n The abstraction “channel” works for many use cases: communication with and between web workers, distributed programming, etc. \n Alternative 2: Reactive Programming   # The following code demonstrates Reactive Programming via  the JavaScript library RxJS : In line (A), we create a stream of click events via  . These events are then filtered so that there is at most one event per second. Every time there is an event,   counts how many events there have been, so far. In the last line, we log all counts. How does Reactive Programming compare to async iteration? \n The coding style is not as familiar, but there are similarities to Promises. \n On the other hand, chaining operations (such as  ) works well for many push-based data sources (DOM events, server-sent events, etc.). \n Async iteration is for pull streams and single consumers. Reactive programming is for push streams and potentially multiple consumers. The former is better suited for I/O and can handle backpressure. \n There is an ECMAScript proposal for Reactive Programming, called “ Observable ” (by Jafar Husain). Is async iteration worth it?   # Now that I’ve used asynchronous iteration a little, I’ve come to a few conclusions. These conclusions are evolving, so let me know if you disagree with anything. \n \n Promises have become   primitive building block for everything async in JavaScript. And it’s a joy to see how everything is constantly improving: more and more APIs are using Promises, stack traces are getting better, performance is increasing, using them via async functions is great, etc. \n \n \n We need   kind of support for asynchronous sequences of data. It wouldn’t necessarily have to be a language mechanism; it could just be part of the standard library. At the moment, the situation is similar to one-time async data before Promises: various patterns exist, but there is no clear standard and interoperability. \n \n \n Async iteration brings with it considerable additional cognitive load: \n \n There are now normal functions, generator functions, async functions and async generator functions. And each kind of function exists as declaration, expression and method. Knowing what to use when is becoming more complicated. \n Async iteration combines iteration with Promises. Individually, each of the two patterns takes a while to fully figure out (especially if you include generators under iteration). Combining them significantly increases the learning curve. \n \n \n \n Operations are missing: Sync iterables can be converted to Arrays via the spread operator and accessed via Array destructuring. There are no equivalent operations for async iterables. \n \n \n Converting legacy APIs to async iteration isn’t easy. A queue that is asynchronously iterable helps, but the pieces don’t fit together as neatly as I would like. In comparison, going from callbacks to Promises is quite elegant. \n \n Further reading   # \n “ Streams API FAQ ” by Domenic Denicola (explains how streams and asynchronous iteration are related; and more) \n “ Why Async Iterators Matter ” (slides by Benjamin Gruenbaum) \n Background: \n Iterables and iterators  (chapter on sync iteration in “Exploring ES6”) \n Generators  (chapter on sync generators in “Exploring ES6”) \n ES proposal: async functions  (blog post) \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/objects-as-maps.html", "title": "The pitfalls of using objects as maps in JavaScript", "content": "The pitfalls of using objects as maps in JavaScript dev javascript jslang Pitfall 1: inheritance and reading properties \n  The   operator checks whether an object has a property with a given name, but it considers inherited properties:\n \n \n\nThe normal way of getting properties accesses all properties:\n Pitfall 2: overriding and invoking methods Pitfall 3: the special property __proto__ \nMark S. Miller mentions real-world implications of this pitfall, in the email “ Why we need to clean up __proto__ ” (which inspired this post):\n support thread StringMap.js Best practices \n     StringMap.js  by Google’s  es-lab \n     stringmap.js  by Olov Lassus \n     The author’s  strmap  project \n Related reading JavaScript properties: inheritance and enumerability Iterating over arrays and objects in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/roles-objects-arrays.html", "title": "The multiple roles of JavaScript objects and arrays", "content": "The multiple roles of JavaScript objects and arrays dev javascript jslang Objects and arrays are dual data structures Objects: records versus maps \n     Record:\n         \n             Fixed shape (keys known beforehand) \n             Every (key, value) entry has a different meaning \n             Literal names: Use names literally. Example:  \n         \n     \n     Map (dictionary), from strings to arbitrary values:\n         \n             Flexible shape (keys generally unknown beforehand) \n             Every (key, value) entry has a similar meaning \n             Computed names: There is usually one level of indirection, you don’t use names directly. Example:   (with   being a variable that holds the actual key) \n         \n     \n Arrays: tuples versus lists \n     Tuple:\n         \n             Fixed length \n             Access elements directly by index \n         \n        Example: returning multiple values from a function or method.\n     \n     List:\n         \n             Dynamic length \n             Iterate over all elements \n         \n     \n Similarities Mixing the domains “program definition” and “application data” \n     Program definition domain: The object is a data structure holding program logic. One mostly uses them in their capacity as records in this domain.\n     \n     Application data domain: The object is a data structure holding application data. Objects are used as both records and maps here. JSON data is part of this domain.\n     \n Mixing domains with the [] operator Object Model Reformation: Decoupling [ ] and Property Access Related reading “ decoupling [ ] and property access for collections ” (by Allen Wirfs-Brock) points out the two domains program definition and application data. “ An array destructing specification choice ” (by David Herman) mentions record versus map and tuple versus list. comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/jsdev.html", "title": "Crockford’s JSDev: switching off privacy for testing", "content": "Crockford’s JSDev: switching off privacy for testing dev javascript jslang jstools introduced JSDev \n  You put development-only code into comments and start those comments with tags that indicate what the code is for. For example:\n \n  You use JSDev to produce the development-time variant of the code. Quoting Crockford:\n \n  Obviously this technique has other uses, for any kind of development-only code: logging, performance tracking, etc.\n comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/js-api-names.html", "title": "Why do some JavaScript methods have such long names?", "content": "Why do some JavaScript methods have such long names? dev javascript jslang mentioned \nThe assumption was that the meta level operations would be used by library writers to create new app level operations that normally would have short everyday names. Also, the long names minimized the chance that the names would conflict with existing libraries or applications.\n comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/gh-pages.html", "title": "GitHub: serve files to the web, with a single branch", "content": "GitHub: serve files to the web, with a single branch dev git GitHub Pages \nSteps:\n \n     Create a new repository called   on GitHub.\n     \n     Create the repository locally:\n \n     \n     Create the gh-pages branch. Given that a branch is mainly a reference to a commit, you first must create a commit. The option   allows you to do so without adding any files.\n         \n     \n     Switch to the gh-pages branch.\n \n     \n     Add files, commit changes as usual. \n     Push everything to GitHub.\n \n        If you now go to GitHub, you see that the repository only has a single branch (popup menu “Current branch”).\n     \n     The files in your repository are now online at\n \n     \n     Whenever you clone your repository, you are automatically in the gh-pages branch:\n \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/js-inheritance-by-example.html", "title": "JavaScript inheritance by example", "content": "JavaScript inheritance by example dev javascript jslang \nThis blog post illustrates several JavaScript inheritance topics via an example: We start with naive implementations of a constructor   and its sub-constructor   and then improve them, step by step.\n\n \n\n Objects Constructors \n     as a function:  \n     as a constructor:  \n [1] Extending [2] [3] [4] Setting the prototype of an object property descriptors Subtyping [5] \n     It shouldn’t matter whether we call   before or after we are adding methods to the prototype. \n      should ensure that the   property is set correctly. \n Referring to super-properties Conclusion, what to read next \nVia our running example, we have seen how to go from objects to constructors, how to extend objects, how to set an object’s prototype and how to create sub-constructors. You can read the following blog posts to deepen your understanding of JavaScript inheritance:\n \n     Why I recommend to use constructors (even though they are far from perfect): “ In defense of JavaScript’s constructors ”\n     \n     Patterns for creating objects: “ Exemplar patterns in JavaScript ” \n     How to keep object data private: “ Private data for objects in JavaScript ” \n     Properties in depth (attributes, property descriptors, etc.): “ Object properties in JavaScript ”\n     \n References What’s up with the “constructor” property in JavaScript? JavaScript properties: inheritance and enumerability The pitfalls of using objects as maps in JavaScript es5-shim: use ECMAScript 5 in older browsers A closer look at super-references in JavaScript and ECMAScript.next comments powered by Disqus."},
{"url": "https://2ality.com/2011/12/es6-shim.html", "title": "es6-shim – ECMAScript 6 functionality on ECMAScript 5", "content": "es6-shim – ECMAScript 6 functionality on ECMAScript 5 esnext dev javascript jslang \nPaul Miller’s  es6-shim  gives you functionality that will be in ECMAScript 6 (code-named ECMAScript.next), on ECMAScript 5 engines. It was initially based on a project of mine, but adds much new functionality, Node.js compatibility, and (not least) tests.\n \n\n Highlights tests \n     Strings\n \n     \n      – makes   more useful.\n \n     \n      – an improved version of   (which will likely become an operator called   in ECMAScript 6).\n \n     \n      – gives you a dictionary with arbitrary keys.\n \n          and   are (coerced to) the same key with arrays.\n        Note that each object is considered different from any other object. Hence, the following map entry cannot be easily retrieved:\n \n     \n Installation [2] Related posts ECMAScript.next: the “TXJS” update by Eich  [what will be in ECMAScript 6, code-named ECMAScript.next] Execute code each time the Node.js REPL starts comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/numbering-headingshtml.html", "title": "Automatically numbering headings via CSS", "content": "Automatically numbering headings via CSS css dev html Number the headings \n     The above CSS resets the counter for the first numbering level called   when it enters the body. Just to be safe, we reset it again at h1. \n     The pseudo-class   allows us to insert content before the inside of a tag. \n     The character   is a non-breaking space in CSS. Hence there are always two non-breaking spaces after the last dot of each heading number. \n Switch off numbering for some headings Non-numbered headings by default Numbering is on by default: You can switch it off, e.g. by putting a class   in a surrounding tag. That can be achieved by replacing the single selector\n \n        with two selectors:\n \n     Numbering is off by default: Then you prefix the   rules with a condition, e.g. whether the class   is present in a surrounding tag:\n \n     Conclusion demo file online comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/esnext-features.html", "title": "The first ECMAScript.next features in Firefox and Chrome", "content": "The first ECMAScript.next features in Firefox and Chrome esnext dev javascript ECMAScript 6 support in Mozilla \nThe next version of ECMAScript (code-named ECMAScript.next  [1] ) will be standardized by 2013. This post enumerates the first features that are currently being tested in Firefox and Chrome.\n\n \n\n Firefox ES6 planning page \n     Mostly done:  weak maps ,  simple maps and sets \n     The  old proxy spec  has mostly been implemented, but not the newer  direct proxy spec \n     for...of  is partially finished \n     The implementation of  modules  is starting \n V8 (Chrome, Node.js) post code search elaborates \n         block scoping ,  let ,  const ,  block functions \n         [old] proxies , though not  direct proxies  yet \n         maps and sets \n         weak maps \n         typeof null reform \n     Related reading A brief history of ECMAScript versions (including Harmony and ES.next) ECMAScript.next: the “TXJS” update by Eich es6-shim – ECMAScript 6 functionality on ECMAScript 5 comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/js-fatigue-fatigue.html", "title": "JavaScript fatigue fatigue", "content": "JavaScript fatigue fatigue dev Enough with the fatigue – tips against feeling overwhelmed: \n Don’t try to know everything – it’s impossible in modern web development. Given that there is always more to know, it doesn’t matter that much what you learn (unless you have a specific need).\n \n Go for depth in areas you love. \n Go for breadth and on-demand learning in areas you are merely interested in or think you should know more about. \n \n \n Wait for the critical mass. You can often afford to get started by reading the opinions of people you trust and wait it out until new ideas prove themselves. \n Stick to things you understand: don’t use more than 1–2 new technologies per project.\n \n It’s important to retain at least some feeling of control. \n Every technology that people need to learn before they can use your project raises the barrier of entry and makes it more difficult to find collaborators, colleagues and employees. \n \n \n Do exploratory toy projects: I like creating small projects that explore technologies or aspects of technologies. \n Diversify in life: Specializing is good, but it’s also good to have regular activities not related to tech and/or brain. The advantage is that if you are frustrated in one area of your life, you have others to fall back on. \n Even with the last of the previous tips, I find it important to remain human. Don’t overdo discipline, be nice to yourself, don’t become a life improvement machine. Periods of boredom and doing nothing are important for recuperating and inspiration. When in doubt about what to learn next, you can always go back to fundamentals: \n JavaScript, CSS, etc. (which technologies are fundamental depends on your work) \n Non-technological skills: time management, social skills (communication, team building, …), health (posture, breathing properly, moving well, eating well, …), management processes and so on. \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/js-name-clashes.html", "title": "Examples of name clashes in JavaScript’s standard library", "content": "Examples of name clashes in JavaScript’s standard library dev javascript esnext The main use case for  ES6 symbols  is that you can use them as property keys that can’t clash with other property keys. In case you think that name clashes don’t matter, here are three examples of where name clashes caused problems in the evolution of the JavaScript standard library: \n \n When the new method   was created, it broke existing code where   was used with an Array and shadowed a variable   in an outer scope ( bug report 1 ,  bug report 2 ). Therefore, a mechanism was introduced to hide properties from   ( ). \n \n \n  clashed with a method added by MooTools and had to be renamed to   ( bug report ). \n \n \n The upcoming   also clashed with a method added by MooTools and had to be renamed to   ( bug report ). \n \n In contrast,  adding iterability to an object via the property key   can’t cause problems, because that key doesn’t clash with anything. These examples demonstrate what it means to be a web language: backward compatibility is crucial, which is why compromises are occasionally necessary when evolving the language. As a side benefit, evolving old JavaScript code bases is simpler, too, because new ECMAScript versions never (well, hardly ever) break them. comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/ecmascript-2017.html", "title": "ECMAScript 2017 (ES8): the final feature set", "content": "ECMAScript 2017 (ES8): the final feature set dev javascript esnext es2017 Exploring ES2016 and ES2017  At the TC39 meeting in January 2017, the last feature of ECMAScript 2017, “ Shared memory and atomics ” advanced to stage 4. That means that its feature set is now complete, as listed below. The features of ECMAScript 2017   # Major new features: \n Async Functions (Brian Terlson) \n Shared memory and atomics (Lars T. Hansen) \n Minor new features: \n Object.values/Object.entries (Jordan Harband) \n String padding (Jordan Harband, Rick Waldron) \n  (Jordan Harband, Andrea Giammarchi) \n Trailing commas in function parameter lists and calls (Jeff Morrison) \n FAQ   # What do the stages mean?   # They refer to maturity stages in the so-called “TC39 process”. Check chapter “ The TC39 process for ECMAScript features ” in “Exploring ES2016 and ES2017” for more information. How is [my favorite proposed feature] doing?   # If you are wondering what stages various proposed features are in, consult  the readme of the ECMA-262 GitHub repository . Further reading   # The following books by me are free to read online: \n ECMAScript 5: “ Speaking JavaScript ” \n ECMAScript 6: “ Exploring ES6 ” \n ECMAScript 2016 & 2017: “ Exploring ES2016 and ES2017 ” \n ECMAScript 2018 & 2019: “ Exploring ES2018 and ES2019 ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/typeof-use-cases.html", "title": "What is JavaScript’s typeof operator used for?", "content": "What is JavaScript’s typeof operator used for? dev javascript jslang \nYou should be familiar with the difference between primitives and objects  [1] .\n\n Checking whether a variable exists and has a value \n  This is a rare use case, so there might not be a need for a better solution. One could introduce a dedicated operator:\n Checking that a value is neither undefined nor null default operator Distinguishing between objects and primitives \n  The above function is a pretty good solution. The following way of detecting an object is also frequently used:\n What is the type of a primitive value? [2] Is a value a function? Summary \n      (e.g. as  ): either as a function or as one or more operators (#2) \n      (#3) \n      (#4) \n     A cross-frame mechanism for checking whether an object is an instance of a given constructor (#5) \n References JavaScript values: not everything is an object Improving the JavaScript typeof operator comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/object-getownpropertydescriptors.html", "title": "ES proposal:  Object.getOwnPropertyDescriptors()", "content": "ES proposal:  dev javascript esnext es proposal The ECMAScript proposal “ ” by Jordan Harband and Andrea Giammarchi is part of  ECMAScript 2017 . This blog post explains it. Overview   #  accepts an object   and returns an object  : \n For each own (non-inherited) property of  , it adds a property to   whose key is the same and whose value is the former property’s  . \n Property descriptors describe the   of a property (its value, whether it is writable, etc.). For more information, consult Sect. “ Property Attributes and Property Descriptors ” in “Speaking JavaScript”. This is an example of using  : This is how you would implement  : Use cases for     # Use case: copying properties into an object   # Since ES6, JavaScript already has a tool method for copying properties:  . However, this method uses simple get and set operations to copy a property whose key is  : That means that it doesn’t properly copy properties with non-default attributes (getters, setters, non-writable properties, etc.). The following example illustrates this limitation. The object   has a getter whose key is  : Using   to copy property   to object   fails: Fortunately, using   together with   works: Use case: cloning objects   # Shallow cloning is similar to copying properties, which is why   is a good choice here, too. This time, we use   that has two parameters: \n The first parameter specifies the prototype of the object it returns. \n The optional second parameter is a property descriptor collection like the ones returned by  . \n Use case: cross-platform object literals with arbitrary prototypes   # The syntactically nicest way of using an object literal to create an object with an arbitrary prototype   is to use the special property  : Alas, that feature is only guaranteed to be there in browsers. The common work-around is   and assignment: But you can also use  : Another alternative is  : Pitfall: copying methods that use     # A method that uses   is firmly connected with its   (the object it is stored in). There is currently no way to copy or move such a method to a different object. Further reading   # JavaScript design process: \n An explanation of the TC39 process and its stages.  This process governs the design and evolution of JavaScript. \n List of proposals that are currently at stage 3 or 4. \n  and property descriptors: \n ECMAScript proposal “ ”  by Jordan Harband and Andrea Giammarchi \n Sect. “ Property Attributes and Property Descriptors ” in “Speaking JavaScript”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/arrow-functions-vs-bind.html", "title": "Arrow functions vs.  bind()", "content": "Arrow functions vs.  dev javascript esnext coding ES6 arrow functions are often a compelling alternative to  . Extracting methods   # If an extracted method is to work as a callback, you must specify a fixed  , otherwise it will be invoked as a function (and   will be   or the global object). For example: An alternative is to use an arrow function:  via parameters   # The following code demonstrates a neat trick: For some methods, you don’t need   for a callback, because they let you specify the value of  , via an additional parameter.   is one such method: However, this code is easier to understand if you use an arrow function: Partial evaluation   #  enables you to do  , you can create new functions by filling in parameters of an existing function: Again, I find an arrow function easier to understand: Further reading   # \n Currying versus partial application (with JavaScript code) \n Uncurrying   in JavaScript \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/03/multi-platform-npm-packages.html", "title": "The need for multi-platform npm packages", "content": "The need for multi-platform npm packages dev javascript esnext npm jsmodules In this blog post, I argue that it should be possible to have multiple implementations of the same npm package (same name, same version). The problem   # At the moment, when you write an npm package, you can specify on what platforms it works, via the   property  .  For example : That means that you can only have a single implementation per package. However, there are use cases for multiple implementations of the same package: \n For Node.js you can already use many ES6 features. For browsers, you should stay 100% ES5. \n There are Node.js-specific polyfills of Browser APIs. For example,   polyfills the fetch API. \n The module bundler Rollup  needs the ES6 module format to achieve its superior file size savings. But that format doesn’t work anywhere else, yet. \n An idea for a solution   # I see two possible solutions: \n Allow the same package (same name, same version) to exist multiple times, targeting different platforms via property  . \n Allow packages with multiple versions of the properties   and  . \n The latter solution could lead to   files that look like this: Mixing selection criteria (meta-data) and data is not ideal. This is an alternative: The selection criteria should include: \n Browsers vs. Node.js \n Supported ECMAScript version \n Module format: native (ES6) vs. CommonJS vs. AMD \n Other solutions   # Ecosystems   # I have only seen  a brief mention of npm ecosystems , so far. I’m not sure how exactly they would work, but it sounds like they could solve the problem I’ve described here.    #  is a custom property that Rollup uses to point to an ES6 module version of the   file. The problem with this approach (apart from the less-than-ideal property name) is that it can only handle a single alternate implementation with a fixed format. More information on  : \n jsnext:main  (Rollup wiki) \n jsnext:main – should we use it, and what for?  (jsforum) \n jspm   # The package manager jspm extends   with, among others, the property   whose value can be   (for ECMAScript module),  ,   or  . Additionally, you have the option to nest jspm-specific properties via the custom property  . For example: More information: “ Configuring Packages for jspm ”. Feedback?   # Feedback welcome! Did I miss anything? Are other (better?) solutions out there? comments powered by Disqus."},
{"url": "https://2ality.com/2016/04/unhandled-rejections.html", "title": "Tracking unhandled rejected Promises", "content": "Tracking unhandled rejected Promises dev javascript esnext async promises In Promise-based asynchronous code, rejections are used for error handling. One risk is that rejections may get lost, leading to silent failures. For example: If   rejects the Promise it returns then that rejection will never be handled anywhere. Let’s look at how you can track unhandled rejections in browsers and in Node.js. Unhandled rejections in browsers   # Some browsers (only Chrome at the moment) report unhandled rejections.    # Before a rejection is reported, an event is dispatched that you can listen to: The event is an instance of   whose two most important properties are: \n : the Promise that was rejected \n : the value with which the Promise was rejected \n The following example demonstrates how this event works: The output of this code is:    # If a rejection is initially unhandled, but taken care of later then   is dispatched. You listen to it as follows:  is also an instance of  . The following code demonstrates  : This code outputs: Further reading   # The Chrome Platform Status site links to a “ Promise Rejection Events Sample ” that contains an explanation and code. Unhandled rejections in Node.js   # Node.js does not report unhandled rejections, but it emits events for them. You can register an event listener like this: The following code demonstrates how the event works:  Node.js v6.6.0+ reports unhandled rejections by default – you don’t need to register an event listener, anymore. Hat tip:  @PetrHurtak Further reading   # The Node.js documentation has  more information on the Event  . comments powered by Disqus."},
{"url": "https://2ality.com/2016/04/promise-trees.html", "title": "Trees of Promises in ES6", "content": "Trees of Promises in ES6 dev javascript esnext async promises This blog post shows how to handle trees of  ES6 Promises , via an example where the contents of a directory are listed asynchronously. The challenge   # We’d like to implement a Promise-based asynchronous function   whose result is an Array with the paths of the files in the directory  . As an example, consider the following invocation: One possible output is: The solution   # For our solution, we create Promise-based versions of the two Node.js functions   and  : We do so via  the library function  : Additionally, we need   which starts with the path   and resolves   relatively to it to produce a new path. Then it continues with resolving   relatively to the new path. Et cetera.  is implemented as follows: Two invocations of Promise-based functions are relatively straightforward: \n  (line A) returns an instance of  \n  (line C) returns an Array with filenames. \n The interesting part is when   calls itself, recursively, leading to an actual tree of Promises. It does so in several steps: \n \n First, it maps the names of the child files to Promises that fulfill with Arrays of grandchild paths (line E). \n \n \n It uses   to wait until all results are in (line D). \n \n \n Once all results are in, it flattens the Array of Arrays of paths into an Array (line F). That Array fulfills the last Promise of the chain that starts in line C. \n \n Note that synchronous programming constructs are used to compose Promises: \n The   statement in line B decides how to continue the asynchronous computation. \n The   method in line E is used to make recursive calls. \n Helper function     # The tool function   concatenates all the elements of   into a single Array (one-level flattening). For example: It can be implemented like this: Further reading   # \n Chapter “ Promises for asynchronous programming ” in ”Exploring ES6”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/05/template-literal-whitespace.html", "title": "Handling whitespace in ES6 template literals", "content": "Handling whitespace in ES6 template literals dev javascript esnext template literals In this blog post, we look at problems that arise when template literals contain whitespace: \n Breaking up long lines \n Dedenting content \n Joining Arrays \n Indenting inserted content \n I’m using the library  common-tags  by  Declan de Wet  (with “useful template literal tags for dealing with strings in ES6”) to demonstrate solutions for some of these problems. Breaking up long lines   # Occasionally, you have long lines that you want to break up. common-tag’s tag function   lets you do that: Dedenting content   # Template literals let you embed multi-line text content inside JavaScript. The main challenge is that the text must both have proper indentation and fit nicely into its JavaScript surroundings: This does not look good: The initial   is out of place at the end of the line and subsequent lines don’t respect JavaScript’s indentation. The output of   looks like this: As a work-around one can use   to gain more freedom w.r.t. the first and the last line: The output is the same and the embedded text looks nicer, but the indentation problem remains. A tag function like common-tag’s   can help: The idea is to determine which line has the smallest indent and to remove that indent from all lines. Additionally, leading and trailing whitespace is trimmed. Joining Arrays   # If you use template literals for templating, you often write code like this: The problem is that the output is not properly indented: That’s because the line breaks inserted via   are not followed by the correct indentation. common-tags has the tag function   which detects Arrays returned from substitutions ( ) and inserts them correctly. No need for  , anymore: Now the output looks like this: Indenting inserted content   # Alas, common-tags does not indent inserted strings correctly: Here, the output is: The line break between the   and the   is not followed by the correct indentation. Further reading   # \n Chap. “ Template literals ” in “Exploring ES6” \n Sect. “ Text templating via untagged template literals ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/bytecode-myth.html", "title": "JavaScript myth: JavaScript needs a standard bytecode", "content": "JavaScript myth: JavaScript needs a standard bytecode jsmyth dev javascript jslang The disadvantages of bytecode \n      A good bytecode is intimately tied to the language that is most frequently compiled to it. It is thus impossible to define a bytecode that works well with all languages, especially if you want to support both dynamic and static languages.\n     \n      The previous rule even applies to the competing implementations of the same language JavaScript. They are too different for a common bytecode to be found; Firefox, Safari and Internet Explorer each use different bytecode, Google’s V8 initially compiles directly to machine code. But wouldn’t it be possible to work towards the goal of a common bytecode or to adopt a single implementation in the long run? Doing so indeed would have some advantages. But having several implementations of the same languages is also useful, because different approaches can be tried. Competition between engines so far has been very good for the JavaScript ecosystem. V8 started a race that so far hasn’t ended and brought tremendous speed gains to JavaScript.\n     \n      it ties you to the current version of the language and to implementation details such as how data is encoded. Especially with regard to language versions, you need to be flexible on the web where you have many combinations of\n         \n        Quoting Brendan Eich  [1] :\n         \n     \n Source code is not that bad – it’s meta-bytecode \n      JavaScript source code is remarkable in how many closely compatible virtual machines there are for it (browser incompatibilities are another issue!). That is due to several factors: First, with  ECMA-262  (“ECMAScript”), JavaScript has a very well written language specification (especially compared to Dart’s which – to be fair – is evolving). Whenever you have a doubt about a language feature, you can turn to ECMA-262 and get a clear answer. Second, JavaScript engine vendors work closely together to evolve the language. Third, there is a test suite called  test262  that checks conformance of a JavaScript implementation. Hence, you can consider JavaScript source code to be meta-bytecode – a data format that unifies the different bytecode formats and V8’s machine code.\n     \n    \n      Keeping the delivery format of a new language version backward compatible is easier with source code than it is with bytecode.\n     \n    \n      JavaScript engines have become very efficient at parsing JavaScript source code. Coupled with increased CPU speed, the overhead caused by parsing is becoming less and less important.\n     \n    \n      There are two ways of making source code more compact. First, minification – a transformation of source code that maintains the semantics while decreasing the size. For example, minification removes comments and changes variable names to be shorter. Second, compression. After minification, one can apply a compression algorithm such as  gzip  to achieve further reductions in size.\n     \n\n      JavaScript source code having such a high level of abstraction makes it relatively easy to compile to. Furthermore, being a good compilation target is a consideration in JavaScript’s evolution. Examples of features that are partially motivated by that consideration are:  typed arrays  (supported by many modern browsers, proposed for a future ECMAScript version) and  SIMD  (which might be part of ECMAScript 8  [2] ). Lastly, JavaScript engines increasingly support this use case. For example, via    [3] : If a file A is compiled to a JavaScript file B, then B can be delivered with a source map. Whenever a source code location is reported for B (e.g. in an error message) then it can be traced back to A, via the source map. In the future, source maps will even allow one to debug JavaScript code in the original language.\n     \n The remaining bytecode advantage [4] \n     Faster parsing and well-formedness checking (including security checks). \n     Reduced program size (by approximately 10% compared to minification plus gzip compression). \n     Some JavaScript code is currently loaded synchronously via script tags embedded in HTML. With JSZap, the HTML parser can load such code asynchronously whenever the JSZap data indicates that it doesn’t interact with the DOM. The main example are libraries. This is mainly an optimization for older JavaScript applications. Modern applications load all library code asynchronously.\n     \n The Essence of Google Dart: Building Applications, Snapshots, Isolates Conclusion Related reading “ Bytecode Standard In Browsers ” – A Minute With Brendan Eich A first look at what might be in ECMAScript 7 and 8 SourceMap on Firefox: source debugging for languages compiled to JavaScript [update: WebKit, too] “ JSZap: Compressing JavaScript Code ”, by Martin Burtscher, Benjamin Livshits, Gaurav Sinha, Benjamin G. Zorn. Microsoft Research, 2010. comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/javascript-pervasiveness.html", "title": "The increasing pervasiveness of JavaScript – a few historic milestones", "content": "The increasing pervasiveness of JavaScript – a few historic milestones dev javascript jslang The Past, Present, and Future of JavaScript \n\nJavaScript is used in more and more places. It started out as a scripting language for web content and has migrated to many areas. This post presents the historic milestones of this process. Note: The milestones are about things that changed the public perception of what JavaScript could be used for. Some of these milestones would not have been possible without prior work by others. For example: Mozilla’s contributions in advancing the state of JavaScript cannot be overestimated. The following are the milestones, in chronological order:\n \n [1] [2] \n        Since the inception of Ajax, other data formats have become popular (JSON instead of XML), other protocols can be used (e.g. Web Sockets in addition to HTTP) and bi-directional communication is possible. But the basic techniques are still the same.\n     \n        The appeal of Node.js for JavaScript programmers goes beyond being able to program in a familiar language; you get to use the same language on both client and server. That allows you to do clever things such as a fallback for browsers that don’t run (a sufficiently sophisticated version of) JavaScript: assemble the pages on the server – with the same code that you are using on JavaScript-enabled clients (examples:  FunctionSource’s web server ,  Yahoo Cocktails ).\n        Node.js creator Ryan Dahl  mentions  the following reasons for choosing JavaScript:\n         \n             Because it’s bare and does not come with I/O APIs [hence all of them are new and non-blocking]. \n             Web developers use it already. \n             DOM API is event-based. Everyone is already used to running without threads and on an event loop. [Web developers are not scared of callbacks.] \n         CommonJS [3] \n        The introduction of the mobile operating system  webOS  (which originated at Palm and is now at HP) predates the introduction of Chrome OS, but the “browser as OS” idea is more apparent with the latter (which is why it was chosen as a milestone). webOS is both less and more. Less, because it is very focused on cell phones and tablets. More, because it has Node.js built in, to let you implement services in JavaScript. Another, more recent, entry in the web operating system category is Mozilla’s   (B2G). Its initial target are cell phones. The B2G website also mentions a benefit of web operating systems for the web: they advance the state of the art.\n         [4] [5] PhoneGap GnomeShell \n     Features for applications: Canvas for bitmap graphics (static or animated), WebGL for 3D graphics, etc. \n     Features for documents: SVG for vector graphics, MathML for typesetting math, etc. \n Conclusion \n     A quick overview of JavaScript \n     JavaScript links  on JS Central (maintained by me and Béla Varga) \n     Register to be notified  when my book on JavaScript comes out (which will be available online, for free) \n References JavaScript: how it all began JavaScript’s JSON API A few thoughts on Chromebooks and Chrome OS A Windows 8 keynote review by a JavaScript programmer and Apple user Write your shell scripts in JavaScript, via Node.js comments powered by Disqus."},
{"url": "https://2ality.com/2016/03/promise-rejections-vs-exceptions.html", "title": "Promise-based functions should not throw exceptions", "content": "Promise-based functions should not throw exceptions dev javascript esnext async promises This blog post gives tips for error handling in asynchronous, Promise-based functions. Operational errors vs. programmer errors   # In programs, there are two kinds of errors: \n \n  happen when a correct program encounters an exceptional situation that requires deviating from the “normal” algorithm. For example, a storage device may run out of memory while the program is writing data to it. This kind of error is expected. \n \n \n  happen when code does something wrong. For example, a function may require a parameter to be a string, but receives a number. This kind of error is unexpected. \n \n Operational errors: don’t mix rejections and exceptions   # For operational errors, each function should support exactly one way of signaling errors. For Promise-based functions that means not mixing rejections and exceptions, which is the same as saying that they shouldn’t throw exceptions. Programmer errors: fail quickly   # For programmer errors, it usually makes sense to fail as quickly as possible: Note that this is not a hard and fast rule. You have to decide whether or not you can handle exceptions in a meaningful way in your asynchronous code. Handling exceptions in Promise-based functions   # If exceptions are thrown inside the callbacks of   and   then that’s not a problem, because these two methods convert them to rejections. However, things are different if you start your async function by doing something synchronous: If an exception is thrown in line A then the whole function throws an exception. There are two solutions to this problem. Solution 1: returning a rejected Promise   # You can catch exceptions and return them as rejected Promises: Solution 2: executing the sync code inside a callback   # You can also start a chain of   method calls via   and execute the synchronous code inside a callback: An alternative is to start the Promise chain via the Promise constructor: This approach saves you a tick (the synchronous code is executed right away), but it makes your code less regular. Async functions and exceptions   # Brian Terlson points out  that  async functions  reflect a preference for not mixing exceptions and rejections: Originally, if an async function had a default value that threw an exception then the function would throw an exception. Now, the function rejects the Promise it returns. Further reading   # \n “ Error Handling in Node.js ” by Joyent \n ES proposal: async functions \n Promises for asynchronous programming  [chapter in “Exploring ES6”] \n  this post was inspired by  a post by user Mörre Noseshine  in the “Exploring ES6” Google Group. Im also thankful for the feedback to  a tweet  asking whether it is OK to throw exceptions from Promise-based functions. comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/underscore-on-nodejs.html", "title": "Trying out Underscore on Node.js", "content": "Trying out Underscore on Node.js underscorejs dev nodejs javascript Underscore Node Package Manager comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/exemplars.html", "title": "Exemplar patterns in JavaScript", "content": "Exemplar patterns in JavaScript dev javascript jslang Exemplars \n     Regular expression literals: produce instances of  :\n \n     \n     Array initializers: produce instances of  .\n \n     \n     Object initializers: look as follows.\n \n        Each object produced by an object initializer (without non-standard extensions) is a direct instance of  :\n \n     \n Function exemplars (constructors) Optional parameters \n     ,  \n     \n     ,  ,  \n     \n Option objects [1] [2] Chainable setters Initialization methods Static factory methods \n  The constructor throws an error if it isn’t called with a value that is only known to the factory methods. We keep the value secret by putting it inside an immediately-invoked function expression (IIFE,  [3] ).\n Creating instances of multiple types in a single location The new operator Invocation any expression, in parentheses, that evaluates to a function an identifier, optionally followed by one or more property accesses The new operator ignores a bound value for `this` The new operator doesn’t work with apply() [4] Object exemplars \n  The prototype object is now our exemplar, we want it to bear the name  , so that we can discard the constructor. This looks as follows.\n [5] library Topics not covered by this post \n     Subtyping  [6]  and how to subtype JavaScript’s built-ins  [7] . \n     Keeping instance data private. You can read “ Private data for objects in JavaScript ” for more information. \n References Trying out Underscore on Node.js Keyword parameters in JavaScript and ECMAScript.next JavaScript variable scoping and its pitfalls Spreading arrays into arguments in JavaScript Prototypes as classes – an introduction to JavaScript inheritance JavaScript inheritance by example Subtyping JavaScript built-ins comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/pdfjs.html", "title": "PDF.js: display PDF files in your browser, without native code", "content": "PDF.js: display PDF files in your browser, without native code browser library dev firefox javascript computers pdf \n     Try it out online , in any browser. \n     Install a  Firefox add-on  that uses PDF.js to display PDF files you come across on the web. It automatically stays current via Firefox auto-update. \n     PDF.js on GitHub . \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/01/object-plus-object.html", "title": "What is {} + {} in JavaScript?", "content": "What is {} + {} in JavaScript? dev javascript jslang Wat \nThe general rule for addition in JavaScript is simple: You can only add numbers and strings, all other values will be converted to either one of those types. In order to understand how that conversion works, we first need to understand a few other things. Whenever a paragraph (such as §9.1) is mentioned, it refers to the ECMA-262 language standard (ECMAScript 5.1).\n \nLet us start with a quick refresher. There are two kinds of values in JavaScript:   and    [1] . The primitive values are:  ,  , booleans, numbers, and strings. All other values are objects, including arrays and functions.\n\n Converting values Converting values to primitives via ToPrimitive() If   is primitive, return it as is. Otherwise,   is an object. Call  . If the result is primitive, return it. Otherwise, call  . If the result is a primitive, return it. Otherwise, throw a  . Converting values to numbers via ToNumber() \n \nAn object   is converted to a number by calling   and then applying ToNumber() to the (primitive) result.\n\n Converting values to strings via ToString() \n \nAn object   is converted to a number by calling   and then applying ToString() to the (primitive) result.\n\n Trying it out Addition Convert both operands to primitives (mathematical notation, not JavaScript):\n \n          is omitted and thus   for non-dates,   for dates. If either   or   is a string then convert both to strings and return the concatenation of the results.\n     Otherwise, convert both   and   to numbers and return the sum of the results.\n     Expected results \nAdding an array and an object also conforms to our expectations:\n \nMore examples where objects are converted to primitives:\n Unexpected results What does it all mean? Underscore Fake operator overloading in JavaScript References JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/taming-tabs.html", "title": "Taming tabs and bookmarks", "content": "Taming tabs and bookmarks browser info mgmt firefox computers Organizing many open tabs \n \n  Most browsers display tabs horizontally, at the top of the window. However, as their number increases, tabs become difficult to handle: They grow narrower and less of their title is displayed. And figuring out which tabs are related becomes harder, for example, which tabs were opened from the same page.\n \n \n  The obvious fix is to display tabs vertically. With wide screens being ubiquitous, horizontal space is more readily available than vertical space, so putting tabs there makes more sense. Additionally, if many tabs are open, one simply scrolls vertically, which is more natural than scrolling horizontally. And the tabs remain wide, their titles remain readable. The Firefox add-on “ Tree Style Tab ” provides one more service: It shows tabs as a tree (which you are free to rearrange) and makes new tabs the children of the tabs from which they were opened. That imposes some immediate order that is very useful. Reader rsanchez1 points out that Opera has another solution: A  Tab Stack  is a group of tabs that is created by dragging one tab onto another one.\n \nCurrent browsers implement one more helpful measure: Background tabs receive a greatly reduced amount of processing power. That is very noticeable under Firefox 10 which handles many open tabs gracefully, where previous versions slowed down the complete system.\n\n Encouraging the closing of tabs \n  Idea: Instead of the current forest, manage bookmarks as a stream that is ordered chronologically by date of last visit (inspiration: Gelernter’s lifestreams  [1] ). In order to bookmark a tab, you click on a star that appears when you hover above it. A modifier key allows you to star and close a tab at the same time. Another modifier key lets you additionally add tags. They can be quickly entered as a single comma-separated text string. Tagging is faster than placing a bookmark in a folder, because coming up with a tag name is faster than finding a folder. This process also lends itself well to keyboard navigation: Switch between tabs with Alt-Tab (Ctrl-Tab on Macs), hit a shortcut to close and tag, enter a single line of tags, hit return and be done.\n \nIt is important that simple bookmarking be complemented by powerful navigation features, such as “descending” into a tag: Text searches will only be among bookmarks that have the tag; the tags displayed for additional filtering will only be those that exist among the currently displayed bookmarks. The browsing history would include the tagged bookmarks and have more structure. There is much research on how to improve navigation and management of tagged entities, all of which applies here. Note that Firefox already supports most of this style of bookmarking, including tags. But it is still limited when it comes to navigating and managing those bookmarks.\n \n  If our inboxes and to-do lists are any indication then simple bookmarking would result in many bookmarks that you will never look at again. That phenomenon is a fact of life. To help, we take a cue from the brain and introduce aging (“forgetting”) to bookmarks: Bookmarks that haven’t been visited in a long time are considered less relevant. That relevancy will influence browsing (where more recent bookmarks show up first) and search (where older bookmarks are ranked lower). Aging is complemented by manual prioritization via tags: a tag “todo” will have more importance to a user than a tag “might read later”. But technical features can only go so far, a mental shift is required, as well: Users will have to accept that they will never revisit all of their bookmarks, they will have to become gracious about forgetting them.\n\n References Information management classics: Lifestreams (1996) comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/servo.html", "title": "Servo: a vision for the future of Firefox", "content": "Servo: a vision for the future of Firefox rust dev firefox computers servo mozilla \n     2012-06-28: Restructured much of the content, to make it easier to digest. \n     2012-06-27: New section “More information on Servo”. \n [1] pointed out Servo – the next Firefox [2] \n     Use Rust instead of C++ which is safer and better equipped for parallelism. \n     Try to parallelize as many stages of the rendering process as possible (ongoing research). \n     Implement the DOM mostly in JavaScript (which makes it faster, because there are less context switches). \n     Browser innovation only: For the foreseeable future, Servo will use Firefox’s JavaScript engine, Spidermonkey.\n     \n complete rewrite Why Servo isn’t written in C++ \n      one of the key issues for a web browser is to keep users safe from attacks. C++ is an inherently unsafe language (especially when it comes to memory management). \n      Single-core speeds are improving at a decreasing rate, hence multi-core parallelism is the best strategy for making the web faster. C++ is not ideally suited for parallel programming. \n [2] The Rust programming language Rust Goals described Rust website \n      Rust is a curly-brace, block-structured expression language. It visually resembles the C language family, but differs significantly in syntactic and semantic details.\n     \n      Its design is oriented toward concerns of “programming in the large”, that is, of creating and maintaining boundaries – both abstract and operational – that preserve large-system integrity, availability and concurrency.\n     \n      It supports a mixture of imperative procedural, concurrent actor, object-oriented and pure functional styles. Rust also supports generic programming and metaprogramming, in both static and dynamic styles.\n     \n Hacker News Actor-style language tutorial Rust versus Go Go Quoting answer Releases \n     Release 0.2 , 2012-03-29: \n        Version 0.2 should still be considered an alpha release, suitable for\nearly adopters and language enthusiasts.\n     \n     Release 0.1 , 2012-01-20: \n        This is the initial release of the compiler after a multi-year\ndevelopment cycle focusing on self-hosting, implementation of major features, and\nsolidifying the syntax.\n        Version 0.1 should be considered an alpha release, suitable for early adopters and\nlanguage enthusiasts. It's nifty, but it will still eat your laundry.\n     \n More information on Servo \n     2012-06-27: “ Mozilla’s next-generation web browser Servo is making progress ” on 2ality \n        [a progress report, updating to this blog post]\n     \n     2012-06-27: “ Servo, an experimental Gecko alternative ” by Paul Rouget \n        [compares Firefox and Servo]\n     \n     2012-03-28: “ Servo design - Baby Steps ” by Niko Matsakis \n        [architectural overview]\n     \n References Firefox Electrolysis project put on hold Future Tense  (slides from Brendan Eich’s talk during a Mozilla all-hands in April 2011) comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/jsdom.html", "title": "Transforming HTML with Node.js and jQuery", "content": "Transforming HTML with Node.js and jQuery jsshell jquery dev nodejs javascript jsdom jsdom The basics [1] jsdom_demo Caveats process.nextTick() \n  The examples in the jsdom readme load jQuery from a URL, causing internet traffic each time the code is run. A solution is to put a copy of jQuery next to the script and specify a file path instead of a URL, as seen above at (*).\n \n  Do you have to invoke   (or  ) every time you want to use jQuery? No, you can store   somewhere and use it again later. The initial startup is only callback-based to accommodate asynchronous script loading.\n\n Conclusion: What is this good for? References Write your shell scripts in JavaScript, via Node.js comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/nan-infinity.html", "title": "NaN and Infinity in JavaScript", "content": "NaN and Infinity in JavaScript numbers dev javascript jslang \nThis post looks at two special values that can be the result of operations that normally return numbers:   and  .\n \n\n NaN tweet Detecting NaN points out [1] specification Infinity beyond infinity References What is {} + {} in JavaScript? comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/classes-inner-names.html", "title": "ES6 classes have inner names", "content": "ES6 classes have inner names dev javascript esnext This blog post explains that classes have lexical inner names, just like named function expressions. The inner names of function expressions   # You may know that function expressions have lexical inner names: The name   of the named function expression becomes a lexically bound variable that is unaffected by which variable currently holds the function. The inner names of classes   # Interestingly, ES6 classes also have lexical inner names that you can use in methods (constructor methods and regular methods): (In the ES6 spec the inner name is set up by  the dynamic semantics of ClassDefinitionEvaluation .)  Thanks to Michael Ficarra for pointing out that classes have inner names. comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/locally-installed-npm-executables.html", "title": "Running locally installed npm executables", "content": "Running locally installed npm executables dev javascript nodejs One nice npm feature is that you can install packages with executables locally. This blog post explains how to run locally installed executables. Running executables from a nearby     # (An aside, on the topic of packages versus modules: npm packages may or may not contain Node.js modules.) If you require a module, Node.js looks for it by going through all   directories in ancestor directories ( ,  ,  , etc.). The first appropriate module that is found is used. Whenever you are somewhere in the file system,   tells you where it would install packages if you used  . That directory   may or may not exist, already; in the following example, directory   is empty. When executables are installed via npm packages, npm links to them: \n In local installs, they are linked to from a   directory. \n In global installs, they are linked to from a global   directory (e.g.  ). \n The command   lets you find out where the closest executables are: If your shell is bash then you can define the following command for running executables from that directory: Let’s try out that shell command: We install package   that comes with an executable. npm puts multiple packages into the closest   and links to the executable   from  : If we run   as a normal shell command, it fails, because we haven’t installed the package (and thus the executable) globally. However,   allows us to run  . Inside an npm package   # I’m using the repo   to demonstrate running executables from inside an npm package. This repo is installed as follows (feel free to read on without doing that): That package has the following  : \n \n : lists the executables provided by this package. It only matters if this package is installed via npm and then affects the   of an ancestor directory. \n \n \n : defines commands that you can execute via   if the current   is the one that is closest to your current working directory. Note that we can use   as if it were a globally installed shell command. That’s because npm adds local   directories to the shell path before it executes scripts. \n \n \n : lists packages that are installed by  , into  . As you can see, we have installed  . \n \n Let’s examine our surroundings (remember that we are still inside the directory  ): As expected, there is no shell command  , but we can run   via  : We can also execute   via  : As explained previously, the entries in   have no effect inside a package, which is why we can’t run   via  : We can, however, run the script whose name is  : Further reading   # For more information on the topic of local npm installs, consult Sect. “ npm and local installs ” in “Setting up ES6”. comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/book-setting-up-es6.html", "title": "My new book: “Setting up ES6”", "content": "My new book: “Setting up ES6” book esnext My latest book is called “ Setting up ES6 ”. It covers the following topics: \n A cheat sheet for deploying ECMAScript 6 \n Example setups (skeleton projects that you can download from GitHub):\n \n ES6 in browsers via webpack and Babel \n ES6 in Node.js via Babel (compiled dynamically or statically) \n \n \n How to configure Babel 6, including a clear explanation of how it interacts with CommonJS modules \n “ Setting up ES6 ” was conceived as a companion to my other book, “ Exploring ES6 ”: \n “ Exploring ES6 ” is supposed to remain relevant for a longer time, so that a print edition makes sense (which I still intend to publish, hopefully by mid-2016). \n “ Setting up ES6 ” will age more quickly. It mainly documents my attempts to understand how Babel 6 works. In a way, you could call it “Setting up Babel 6”. But it has a slightly broader scope, especially the first chapter on deploying ES6. \n Happy reading – the contents of “ Setting up ES6 ” are free to read online. If you like the book then you can support my work by buying the offline version (PDF, EPUB, MOBI). comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/private-data-classes.html", "title": "Managing the private data of ES6 classes", "content": "Managing the private data of ES6 classes dev javascript esnext This blog post explains four approaches for managing private data for ES6 classes: Keeping private data in the environment of a class  Marking private properties via a naming convention (e.g. a prefixed underscore) Keeping private data in WeakMaps Using symbols as keys for private properties Approaches #1 and #2 were already common in ES5, for constructors. Approaches #3 and #4 are new in ES6. Let’s implement the same example four times, via each of the approaches. Keeping private data in the environment of a class     # Our running example is a class   that invokes a callback   once a counter (whose initial value is  ) reaches zero. The two parameters   and   should be stored as private data. In the first implementation, we store   and   in the   of the class constructor. An environment is the internal data structure, in which a JavaScript engine stores the parameters and local variables that come into existence whenever a new scope is entered (e.g. via a function call or a constructor call). This is the code: Using   looks like this: Pro: \n The private data is completely safe \n The names of private properties won’t clash with the names of other private properties (of superclasses or subclasses). \n Cons: \n The code becomes less elegant, because you need to add all methods to the instance, inside the constructor (at least those methods that need access to the private data). \n Due to the instance methods, the code wastes memory. If the methods were prototype methods, they would be shared. \n More information on this technique: Sect. “ Private Data in the Environment of a Constructor (Crockford Privacy Pattern) ” in “Speaking JavaScript”. Marking private properties via a naming convention   # The following code keeps private data in properties whose names a marked via a prefixed underscore: Pros: \n Code looks nice. \n We can use prototype methods. \n Cons: \n Not safe, only a guideline for client code. \n The names of private properties can clash. \n Keeping private data in WeakMaps   # There is a neat technique involving WeakMaps that combines the advantage of the first approach (safety) with the advantage of the second approach (being able to use prototype methods). This technique is demonstrated in the following code: we use the WeakMaps   and   to store private data. Each of the two WeakMaps   and   maps objects to their private data. Due to how WeakMaps work that won’t prevent objects from being garbage-collected. As long as you keep the WeakMaps hidden from the outside world, the private data is safe. If you want to be even safer, you can store   and   in temporary variables and invoke those (instead of the methods, dynamically). Then our code wouldn’t be affected if malicious code replaced those methods with ones that snoop on our private data. However, we are only protected against code that runs after our code. There is nothing we can do if it runs before ours. Pros: \n We can use prototype methods. \n Safer than a naming convention for property keys. \n The names of private properties can’t clash. \n Con: \n Code is not as elegant as a naming convention. \n Using symbols as keys for private properties   # Another storage location for private data are properties whose keys are symbols: Each symbol is unique, which is why a symbol-valued property key will never clash with any other property key. Additionally, symbols are somewhat hidden from the outside world, but not completely: Pros: \n We can use prototype methods. \n The names of private properties can’t clash. \n Cons: \n Code is not as elegant as a naming convention. \n Not safe: you can list all property keys (including symbols!) of an object via  . \n Further reading   # \n Sect. “ Keeping Data Private ” in “Speaking JavaScript” (covers ES5 techniques) \n Chap. “ Classes ” in “Exploring ES6” \n Chap. “ Symbols ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/enumify.html", "title": "Enumify: better enums for JavaScript", "content": "Enumify: better enums for JavaScript dev javascript esnext technique In this blog post, I present  enumify, a library for implementing enums in JavaScript . The approach it takes is inspired by Java’s enums. Enum patterns   # The following is a naive enum pattern for JavaScript: This implementation has several problems: Logging: If you log an enum value such as  , you don’t see its name. Type safety: Enum values are not unique, they can be mixed up with other values. Membership check: You can’t easily check whether a given value is an element of  . We can fix problem #1 by using strings instead of numbers as enum values: We additionally get type safety if we use symbols as enum values: One problem with symbols is that you need to convert them to strings explicitly, you can’t coerce them (e.g. via   or inside template literals): We still don’t have a simple membership test. Using a custom class for enums gives us that. Additionally, everything becomes more customizable: However, this solution is slightly verbose. Let’s use a library to fix that. The library     # The library   lets you turn classes into enums. It is available on  GitHub  and  npm . This is how you would implement the running example via it: The enum is set up via  , a static method that   inherits from  . The library “closes” the class  : After  , you can’t create any new instances: Properties of enum classes   # # Enums get a static property  , which contains an Array with all enum values: The values are listed in the order in which they were added to the enum class. As explained later, you can also call   with an object (vs. an Array). Even then,   has the expected structure, because objects record the order in which properties are added to them. # The inherited tool method   maps names to values: This method is useful for parsing enum values (e.g. if you want to retrieve them from JSON data). Properties of enum values   # Enumify adds two properties to every enum value: \n \n : the name of the enum value. \n \n \n \n : the position of the enum value within the Array  . \n \n \n Advanced features   # #  also accepts an object as its parameter. That enables you to add properties to enum values. Another use case for this feature is defining commands for a user interface: The instance-specific method   executes the command.   enables us to list all available commands. # If you want all enum values to have the same method, you simply add it to the enum class: Arbitrary enum values   # One occasionally requested feature for enums is that enum values be numbers (e.g. for flags) or strings (e.g. to compare with values in HTTP headers). That can be achieved by making those values properties of enum values. For example: State machines via enums   # Enums help with implementing state machines. This is an example: Built-in enums for JavaScript?   # This is a Gist sketching what built-in enums could look like . For example: Enums in TypeScript   # TypeScript has built-in support for enums: This is how the enum is implemented: This code makes the following assignments: TypeScript’s enums have all the disadvantages mentioned for the first enum example earlier: No names for logging, no type safety and no membership tests. You can’t customize these enums, either. comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/exponentiation-operator.html", "title": "ES2016 feature: exponentiation operator ( ** )", "content": "ES2016 feature: exponentiation operator ( ) dev javascript esnext es2016 The exponentiation operator ( ) is an ECMAScript proposal by Rick Waldron. It is at stage 4 (finished) and part of  ECMAScript 2016 . An infix operator for exponentiation   #  is an infix operator for exponentiation: produces the same result as Examples: Further reading: \n Exponentiation Operator  (Rick Waldron) \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/esnext-news.html", "title": "ES.next News: a weekly email newsletter", "content": "ES.next News: a weekly email newsletter dev javascript esnext news media Today,  Johannes Weber   and I  are launching a new weekly email newsletter:  ES.next News . The concept is simple: you get 5 links related to ECMAScript 6/2015+ per week, via email. Subscribe now, it’s free: \n Email : one email per week, each Tuesday.  You can check out a sample issue . \n Twitter : all links that will be in the newsletter plus a few more, spread out all over the week. \n We see ES.next News as complementary to  JavaScript Weekly  (which we recommend, but are not affiliated with). The former is more focused, the latter is more comprehensive. Happy reading! comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/ecmascript-2016.html", "title": "The final feature set of ECMAScript 2016 (ES7)", "content": "The final feature set of ECMAScript 2016 (ES7) dev javascript esnext es2016 Exploring ES2016 and ES2017 We always knew that ECMAScript 2016 (ES2016) would be a small release. It turns out that it will be   small. Read on for a list of its features and an explanation why that is not a problem. The features of ES2016   # Any proposals that were at stage 4 on Thursday, 28 January 2016, will be in ES2016 ( source: ECMAScript standard editor Brian Terlson ). That means that ES2016 will contain just two new features (in addition to bug fixes and smaller improvements): \n  (Domenic Denicola, Rick Waldron) \n Exponentiation Operator (Rick Waldron) \n The draft of ECMAScript 2016  is online and will be ratified in 2016, probably in June. The new release process works   # ES2016 being so small demonstrates that  the new release process  works: \n New features are only included after they are completely ready and after there were at least two implementations that were sufficiently field-tested. \n Releases happen much more frequently (once a year) and can be more incremental. \n If you are disappointed that your favorite stage 3 feature did not make it into ES2016 – don’t worry: With  the new release process , it’s more about the stage a proposal is in than what release it is a part of. As soon as a proposal reaches stage 4, it is done and safe to use. You’ll still have to check whether the JavaScript engines that are relevant to you support the feature, but you have to do that with ES6 features, too. comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/async-functions.html", "title": "ES proposal: async functions", "content": "ES proposal: async functions dev javascript esnext es proposal async promises Async functions are an ECMAScript proposal by Brian Terlson. It is at stage 3 (candidate). Before I can explain async functions, I need to explain how Promises and generators can be combined to perform asynchronous operations via synchronous-looking code. Writing async code via Promises and generators   # For functions that compute their one-off results asynchronously, Promises, which are part of ES6, are becoming increasingly popular. One example is  the client-side   API , which is an alternative to XMLHttpRequest for retrieving files. Using it looks as follows: co is a library that uses Promises and generators to enable a coding style that looks more synchronous, but works the same as the style used in the previous example: Every time the callback (a generator function!) yields a Promise to co, the callback gets suspended. Once the Promise is settled, co resumes the callback: if the Promise was fulfilled,   returns the fulfillment value, if it was rejected,   throws the rejection error. Additionally, co promisifies the result returned by the callback (similarly to how   does it). Async functions   # Async functions are basically dedicated syntax for what co does: Internally, async functions work much like generators, but they are not translated to generator functions. Variants   # The following variants of async functions exist: \n Async function declarations:  \n Async function expressions:  \n Async method definitions:  \n Async arrow functions:  \n Further reading   # \n Async Functions  (Brian Terlson) \n Simplifying asynchronous computations via generators  (section in “Exploring ES6”) \n comments powered by Disqus."},
{"url": "https://2ality.com/2016/02/array-prototype-includes.html", "title": "ES2016 feature:  Array.prototype.includes", "content": "ES2016 feature:  dev javascript esnext es2016  is an ECMAScript proposal by Domenic Denicola and Rick Waldron. It is at stage 4 (finished) and part of  ECMAScript 2016 . The Array method     # The Array method   has the following signature: It returns   if   is an element of its receiver ( ) and  , otherwise:  is similar to   – the following two expressions are mostly equivalent: The main difference is that   finds  , whereas   doesn’t:  does not distinguish between   and   ( which is how almost all of JavaScript works ): Typed Arrays will also have a method  : Frequently asked questions   # \n \n \nThe latter was the initial choice, but that broke code on the web ( MooTools adds this method to  ). \n \n \n \n  is used for keys ( ),   is used for elements ( ). The elements of a Set can be viewed as being both keys and values, which is why there is a   (and no  ). \n \n \n The ES6 method  \nIf Array   worked exactly like string  , it would accept arrays, not single elements. But the two   follow the example of  ; characters are seen as a special case and strings with arbitrary lengths as the general case. \n \n Further reading   # \n  (Domenic Denicola, Rick Waldron) \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/twitter-pushstate.html", "title": "Twitter to eliminate their hashbang (#!) URLs", "content": "Twitter to eliminate their hashbang (#!) URLs app urls browser dev twitter webdev computers conversation It's About The Hashbangs @danwrong @timhaines @danwrong @timhaines @danwrong [1] \nRelated reading:\n “ The pushState() method ” on MDN comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/js-integers.html", "title": "Integers and shift operators in JavaScript", "content": "Integers and shift operators in JavaScript bitwise_ops numbers dev javascript jsint jslang Preparations Integers in JavaScript \n     Integer: a value in the range [−2 , +2 ]. Used for: most integer arguments (indices, dates, etc.). Higher and lower integers can be represented, but only the integers in the interval are contiguous  [1] .\n     \n     Uint16: 16 bit unsigned integers in the range [0, 2 −1]. Used for: character codes. \n     Uint32: 32 bit unsigned integers in the range [0, 2 −1]. Used for: array lengths. \n     Int32: 32 bit signed integers in the range [−2 , 2 −1]. Used for: bitwise not, binary bitwise operators, unsigned shift. \n Converting numbers to Integer Converting numbers to Uint32 ones’ complement twos’ complement Converting numbers to Int32 The shift operators \n     Signed shift left  \n     Signed shift right  \n     Unsigned shift right  \n Signed right shift Unsigned shift right Left shift \nAnother way to look at it is that for negative numbers, the highest digit is 1. The lower the remaining digits are, the lower the number is. For example, the lowest 4-digit negative number is\n Alternate implementations of ToUint32 and ToInt32 Lessons learned \n     Math.floor() converts its argument to the closest lower integer.\n \n     \n     Math.ceil() converts its argument to the closest higher integer.\n \n     \n     Math.round() converts its argument to the closest integer. Examples:\n \n        The result of rounding -3.5 is slightly unexpected.\n \n        Therefore,   is the same as\n \n     \n \nThe modulo operations performed by   and   are rarely useful in practice. The following equivalent to ToUint32 is sometimes used to convert any   to a non-negative integer.\n Reference How numbers are encoded in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/js-pitfalls.html", "title": "Major and minor JavaScript pitfalls and ECMAScript 6", "content": "Major and minor JavaScript pitfalls and ECMAScript 6 esnext dev javascript jslang \n     2.1. Function-scoped variables \n     2.2. Inadvertent sharing via a closure \n     2.7.   is weird \n \nJavaScript has many pitfalls. This post examines whether they make JavaScript “unfixable” as a language – as some argue. To do so, it separates the pitfalls into two categories: The ones that become harmless after learning about them and the ones that don’t. We’ll also look at how the upcoming  ECMAScript 6  fixes most problems.\n \nWarning: If you are new to JavaScript then don’t let this post be your introduction to it. Consult  other material  first.\n\n \n Major JavaScript pitfalls Dynamic  block lambdas Subtyping is difficult [1] [2] Minor JavaScript pitfalls Function-scoped variables [3] destructuring assignment Inadvertent sharing via a closure  loop Extracted methods can’t use  Creating global variables via  [4] Automatic creation of globals Comparison via == is weird [5]  is weird \n     Objects: It iterates over all property names, including (enumerable) inherited ones.\n \n        If, say,   wasn’t non-enumerable, it would also show up above, because by default, all objects inherit from  .\n     \n     Arrays:   seems to iterate over the array indices, but that is only because the   property is not enumerable. It actually iterates over all properties of an array.\n \n        For arrays, it would make much more sense to iterate (only) over the array elements and not their indices. ECMAScript 6’s   loop  will do that.\n     \n [6] [7] Array-like objects truthy and falsy values; having both   and  operators References JavaScript inheritance by example JavaScript does not need classes JavaScript variable scoping and its pitfalls JavaScript’s strict mode: a summary When is it OK to use == in JavaScript? JavaScript properties: inheritance and enumerability Iterating over arrays and objects in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/openurl.html", "title": "openurl – Node.js module for opening URLs", "content": "openurl – Node.js module for opening URLs jsshell dev nodejs javascript openurl \n http URLs: open the default browser \n mailto URLs: open the default email client \n file URLs: open a window showing the directory (on OS X) \n \nRelated reading:\n \n     Write your shell scripts in JavaScript, via Node.js \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/mailto-nodejs.html", "title": "Generate emails via mailto URLs on Node.js", "content": "Generate emails via mailto URLs on Node.js jsshell dev nodejs javascript mailto URL syntax \n recipients: comma-separated email addresses (no spaces; Outlook needs semicolons instead of commas) \n value: should be URL-encoded (e.g. space becomes %20) \n key: subject, cc, bcc, body \n mailto:joe@example.com,jane@example.com?subject=hello&body=How%20are%20you%3F Using mailto URLs on Node.js openurl \n     A simple way of sending emails in Java: mailto links \n     Generate emails with mailto URLs and Python \n Related post Write your shell scripts in JavaScript, via Node.js comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/lazylines.html", "title": "New Node.js module “lazylines”: read a text stream, line by line", "content": "New Node.js module “lazylines”: read a text stream, line by line jsshell dev nodejs javascript lazylines Examples Installation Related post \n     Write your shell scripts in JavaScript, via Node.js \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/11/configuring-babel6.html", "title": "Configuring Babel 6", "content": "Configuring Babel 6 dev javascript jstools babel esnext  This series of blog post has been turned into the book “ Setting up ES6 ” (which is free to read online). Babel 6 is much more configurable than Babel 5, but also more difficult to configure. This blog post gives tips. Follow-up blog posts: \n [2015-12-11]  Babel 6: configuring ES6 standard library and helpers \n [2015-12-12]  Babel 6: loose mode \n [2015-12-13]  Babel and CommonJS modules \n Installing Babel 6   # The following are a few important npm packages. All Babel packages reside in  a single repository on GitHub . Browsing their source code and their   files is instructive. \n \n : the core compilation machinery and plugin infrastructure for Babel. You will rarely need to install this package, because other packages such as   have it as a dependency, meaning that it will be automatically installed when they are installed. \n \n \n : a command line interface to  . It includes the following commands: \n \n  detects common problems with your Babel installation. \n  transpiles files or stdin via Babel. \n  a version of the Node.js executable   that transpiles everything via Babel. \n  prints all of Babel’s helper functions (such as   for subclassing) to the console. \n \n \n \n : lets you switch on Babel transpilation from within Node.js. After you do, all modules you require (minus code you want to ignore, e.g. packages installed via npm) are automatically transpiled. \n \n Configuration data   # Babel is often about compiling an input file, e.g. in the following two scenarios: \n \n Compiling a file via the command line tool  : \n \n \n \n Running a Node.js script written in ES6: \n \n \n The configuration data is an object of JSON data that is assembled from various sources (which are described later). Two configuration options have much influence on how the output is produced: plugins and presets. Plugins   # Roughly, plugins are functions that are applied to the input during compilation. Two important categories of plugins are: \n Syntax plugins enable Babel to parse syntactic entities beyond the built-in base syntax. They help with constructing an abstract syntax tree. Examples are:\n \n syntax-async-functions \n syntax-jsx \n \n \n Transform plugins modify the abstract syntax tree. Examples are:\n \n transform-async-to-generator \n transform-react-jsx \n transform-es2015-arrow-functions \n transform-es2015-classes \n \n \n If you want to compile something that isn’t part of the base syntax, you need both a syntax plugin and a corresponding transform plugin. However, each transform plugin that depends on a syntax plugin automatically activates that plugin. Plugins are installed via npm. Their package names are their names plus the prefix  : \n Plugin  :  \n Plugin  :  \n Presets   # In order to configure Babel’s output to your liking, you need to specify what plugins it should use. You can specify: \n Individual plugins \n , sets of plugins that support various compilation scenarios. \n The following are useful presets: \n es2015: compiles ES6 (as described by the ECMAScript spec) to ES5 \n stage-3: compiles  stage 3 ECMAScript proposals  to ES5 \n react: compiles JSX to JavaScript and removes Flow type annotations \n es2015-node5 : Contains just those plugins that are needed to upgrade Node.js 5 to full ES6. Therefore, a lot less is transpiled than with the   preset. Especially generators not being transpiled helps with debugging. \n Presets are installed via npm. Their package names are their names plus the prefix  . For example, this is how to install the preset  : Sources of configuration data   # The configuration data is always located relative to the input file: \n When ascending through parent directories, whichever of the following two files is found first is used. If they are both in the same directory then   is used.\n \n : The file’s contents are interpreted as JSON and used as Babel options. \n : Property   of the file’s JSON content is used as Babel options. This file only counts if it has the property  . \n \n \n : The “first” file in the parent directories is used. Its lines are turned into an Array and interpreted as the option  . \n Two properties in configuration data specify additional configuration data: \n Property   of maps the names of environments ( ,  , etc.) to objects with more configuration data. If   exists, the object corresponding to the current environment is merged with the configuration data that has already been assembled. Consult  the Babel documentation  for more information on environments. \n Property   contains a path pointing to a file with more configuration data. \n babel-node   # If you are using  , you can also specify the following options (and a few others) via the command line: \n \n \n : by default, any file that has the segment   in its path is not transpiled. \n The following command runs   via  , with the presets   and  , and the plugin   enabled. On Unix, if a file is executable and contains the following first line then you can directly execute it, via babel-node: You could specify presets etc. as options at the end of this line, but doing so via   seems cleaner. This is a minimal   for a project with an executable: There are several ways of running  : \n \n You can execute   directly (if it is executable and starts with the right prolog): \n \n \n \n You can execute   via   (as configured in  ): \n \n \n \n If you install package   globally, you get a command line command   (as specified via  ). \n \n \n If you install package   locally, as a dependency of another package, you can execute   via the   of that package, as if it was a globally installed command. That’s because npm adds the   entries of all dependencies to the shell path before executing   (alas, not the   entries in the same  ). \n \n webpack   # The following is an excerpt of   in the repo  react-starter-project . As you can see, babel-loader supports the property   for specifying Babel options. More information   # \n \n The Babel docs are excellent. For example,  this page explains the Babel options . The bar at the top gets you to other pages. \n \n \n Additionally, the following files in Babel’s source code are helpful for figuring out how it handles options: \n \n \n  contains the algorithm for finding and merging Babel options. \n \n \n  contains the parameter handling code for babel-node. \n \n \n babel-register for Node.js is hosted here. \n \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/02/concat-not-generic.html", "title": "Array.prototype.concat is not generic", "content": "Array.prototype.concat is not generic dev javascript jslang [1] \n§15.4.4.4 of the ECMAScript 5.1 specification states:\n \nLet’s check the assertion that   is generic: Its result must be the same regardless of whether   is a real array or just   (with a property   and indexed access to elements). We first try   with an array as  :\n “ Uncurrying `this` in JavaScript ” [explains what generic methods are] comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/displaying-numbers.html", "title": "Displaying numbers in JavaScript", "content": "Displaying numbers in JavaScript numbers dev javascript jslang \nThis post is part of a series on JavaScript numbers that currently comprises the following other post:\n \n     Integers and shift operators in JavaScript \n Displaying decimal numbers Fixed notation versus exponential notation Displaying decimal numbers \n     Use exponential notation if there are more than 21 digits before the decimal point. Example:\n \n     \n     Use exponential notation if the number starts with “0.” followed by more than five zeros. Example:\n \n     \n     Otherwise, use fixed notation. \n The ECMAScript 5.1 display algorithm in detail Preliminary definitions \n     The mantissa of 12.34 is 1234. \n     The mantissa of 0.00045 is 45 \n     The mantissa of 1000 is 1 \n     The mantissa of −27 is −27 \n \n     pointPos = 0: point is before the digits.\n \n     \n    \n     pointPos ≥ 1: point is after the 1st (2nd, etc.) digit. If pointPos is less than digitCount then then the point appears “inside” the mantissa:\n \n        If pointPos is the same as digitCount then the point appears after the last digit of the mantissa.\n \n        If pointPos is greater than digitCount then zeros are inserted after the mantissa and before the point.\n \n     \n    \n     pointPos ≤ −1: one (two, etc.) zeros appear after the point and before the mantissa.\n \n     \n The algorithm  digitCount ≤ pointPos ≤ 21 \n        Print the digits (without leading zeros), followed by pointPos−digitCount zeros.\n      0 < pointPos ≤ 21, pointPos < digitCount \n        Display the pointPos first digits of the mantissa, a point and then the remaining digitCount−pointPos digits.\n      −6 < pointPos ≤ 0 \n        Display a 0 followed by a point, −pointPos zeros and the mantissa.\n      pointPos ≤ -6 or pointPos > 21 \n        Display the first digit of the mantissa. If there are more digits then display a point and the remaining digits. Next, display the character   and a plus or minus sign (depending on the sign of pointPos−1), followed by the absolute value of pointPos−1. Therefore, the result looks as follows.\n         \n     Methods for converting numbers to string Number.prototype.toString(radix?) Number.prototype.toExponential(fractionDigits?) \nForce more precision when   would also use exponential notation. Results are mixed, because one reaches the limits of the precision that can be achieved when converting binary numbers to a decimal notation.\n \nGet exponential notation when numbers are not large enough.\n \nGet exponential notation when non-zero numbers are not small enough.\n Number.prototype.toFixed(fractionDigits?) Number.prototype.toPrecision(precision?) Conclusion \nIt is interesting to note that you can always append   to a number and it will be multiplied by 10 .\n comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/jquery-foundation.html", "title": "The jQuery Foundation has been created", "content": "The jQuery Foundation has been created jquery dev javascript clientjs Software Freedom Conservancy The Software Freedom Conservancy describes itself 27 projects \n     Boost \n     git \n     Samba \n     Selenium \n     Wine \n The jQuery Foundation announcement \n         supporting development of the jQuery Core, UI, and Mobile projects; \n         providing jQuery documentation and support; \n         and fostering the jQuery community. \n     comments powered by Disqus."},
{"url": "https://2ality.com/2015/11/trailing-comma-parameters.html", "title": "ES proposal: Trailing commas in function parameter lists and calls", "content": "ES proposal: Trailing commas in function parameter lists and calls dev javascript esnext es proposal The following ECMAScript proposal is at  stage 3 : “ Trailing commas in function parameter lists and calls ” by Jeff Morrison. This blog post explains it. Trailing commas in object literals and Array literals   # Trailing commas are ignored in object literals: And they are also ignored in Array literals: Why is that useful? There are two benefits. First, rearranging items is simpler, because you don’t have to add and remove commas if the last item changes its position. Second, it helps version control systems with tracking what actually changed. For example, going from: to: leads to both the line with   and the line with   being marked as changed, even though the only real change is the latter line being added. Proposal: allow trailing commas in parameter definitions and function calls   # Given the benefits of optional and ignored trailing commas, the proposed feature is to bring them to parameter definitions and function calls. For example, the following function declaration causes a SyntaxError in ECMAScript 6, but would be legal with the proposal: Similarly, the proposal would make this invocation of   syntactically legal: comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/babel6-helpersstandard-library.html", "title": "Babel 6: configuring ES6 standard library and helpers", "content": "Babel 6: configuring ES6 standard library and helpers dev javascript jstools babel esnext  Please read Chap. “ Babel: configuring standard library and helpers ” in “Setting up ES6”. This blog post explains how to configure how Babel 6 accesses its own helper functions and the ES6 standard library. The following GitHub repo lets you play with what’s explained here:  this series of posts on Babel 6  “ Configuring Babel 6 ” [explains the basics: configuration files, presets, plugins, etc.] External dependencies of transpiled code   # There are two external dependencies of the code produced by Babel that you’ll probably want to configure: \n \n On one hand, your code will usually invoke functionality of the ES6 standard library. For example: \n \n The default is to assume that this functionality is available via global variables. \n \n \n On the other hand, Babel has helper functions that are called from the transpiled code. The default is to   all invoked functions, which can result in redundancies, because it is done for each file, separately. \n \n There are two ways in which you can get the standard library and non-inlined (and non-redundant) helpers: via global variables and via a module. How is explained next. Standard library and helpers via global variables   # The standard library via global variables:     # The package   installs several things into global variables: \n \n ES5 polyfills  (whatever is missing from the ES5 standard library):  ,  , etc. \n \n \n ES6 polyfills :  ,  , etc. \n \n \n A few polyfills of ECMAScript feature proposals :  ,  , etc. \n \n \n The runtime for  Regenerator  (which is used by Babel to transpile ES6 generators to ES5). \n \n The polyfills are provided by  core-js . Install   via npm as a runtime dependency if you find that any of the aforementioned functionality is missing in your transpiled code. In Node.js 5, you may be able to get by without using it, because that version comes with much of the ES6 standard library and native generators. The helpers via a global variable:     # This package  transform the Babel output so that its helpers come from an object in a global variable and are not inserted into each file (possibly redundantly). Alas, the helpers can only be accessed via a global variable. If you want to access them via a module, you need  . But that plugin also affects how you access the standard library, which may not be what you want. As an example, consider the following ES6 code, before transpilation: If you transpile it with the   preset and without  , you get: Note the two helper functions   and  . If you additionally switch on the plugin  , you get this output: # In order to create a file that sets up the global variable  , you need to call the shell command   (which is installed via the package  ). This command supports three output formats: \n \n \nprints a Node.js module that puts the helpers into  . \n \n \n \nprints browser code that puts the helpers into the global variable  . \n \n \n \nprints a Universal Module Definition (UMD) that works as CommonJS module, AMD module and via a global variable. \n \n This invocation prints usage information: Standard library and helpers via a module:     # If you install this plugin and switch it on, both helpers and uses of the ES6 standard library are redirected to imports from the package   (which therefore becomes a runtime dependency). Babel helpers and     #  works well for the helpers. The previous ES6 example is transpiled to: The helpers   (line A) and   (line B) are now imported from  . The helper function   ensures that either plain CommonJS modules or transpiled ES6 modules can be used. Runtime library and     # However,   does not do as well for the ES6 runtime library. #  does properly detect function invocations: namespaced functions (such as   and  ) and constructors (such as   and  ). Take, for example, the following ES6 code: This code is transpiled to: Note the imports in line A and line B. # However,   does not detect method calls like those in the following ES6 code: This is transpiled to: There are no imports – the input code in basically untouched. The first method call is dynamically dispatched, so it’s not surprising that   doesn’t catch it. However, the second method call is direct and ignored, too. # Babel’s polyfilling is based on  the library core-js , which lets you access its functionality without global data being changed: These utility functions are made available by  . How can be looked up in the file   in its repository (roughly: the standard library of ES6 and later). This is an excerpt: That means that   provides  ,   and  . The last function is a version of   where   is “uncurried” (provided via the first parameter). This is how you use it: If you transpile, this code looks like this (note the import in line A):  Thanks to Denis Pushkarev (@zloirock) for his feedback on this blog post. comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/private-data.html", "title": "Private data for objects in JavaScript", "content": "Private data for objects in JavaScript esnext dev javascript jslang In September 2012 \nJavaScript does not come with dedicated means for managing private data for an object. This post describes five techniques for working around that limitation:\n \n Instance of a constructor – private data in environment of constructor Singleton object – private data in environment of object-wrapping IIFE Any object – private data in properties with marked names Any object – private data in properties with reified names Single method – private data in environment of method-wrapping IIFE \n  While everything is explained relatively slowly, you should probably be familiar with environments and IIFEs  [1]  and with inheritance and constructors  [2] .\n\n Instance of a constructor – private data in environment of constructor Crockford’s terminology  Data stored in the instance is publicly accessible.  Data stored in the environment is only accessible to the constructor and functions created inside it.  Private functions can access public properties, but public methods cannot normally access private data. We thus need special   methods – functions created in the constructor that are added to the instance. Privileged methods are public and can thus be seen by non-privileged methods, but they also have access to the private data.\n     Public properties Private data Privileged methods Analysis \n     Not very elegant: Mediating access to private data via privileged methods introduces an unnecessary indirection. Privileged methods and private functions both destroy the separation of concerns between the constructor (setting up instance data) and its   property (methods).\n     \n     Completely safe: There is no way to access the environment’s data from outside. Which makes this solution secure if you need to guarantee that (e.g. for security-critical code). On the other hand, private data not being accessible to the outside can also be an inconvenience: Sometimes you want to unit-test private functionality. And some temporary quick fixes depend on the ability to access private data. This kind of quick fix cannot be predicted, so no matter how good your design is, the need can arise.\n     \n     Possibly slower: Accessing properties in the prototype chain is highly optimized in current JavaScript engines. Accessing values in the closure might be slower. But these things change constantly, so you’ll have to measure, should this really matter for your code.\n     \n     Memory consumption: Keeping the environment around and putting privileged methods in instances costs memory. Again: Be sure it really matters for your code and measure.\n     \n Singleton object – private data in environment of object-wrapping IIFE [1] Any object – private data in properties with marked names Analysis \n     Natural coding style: With the popularity of putting private data in environments, JavaScript is the only mainstream programming language that treats private and public data differently. A naming convention avoids this slightly awkward coding style.\n     \n     Property namespace pollution: The more people use IDEs, the more it will be a nuisance to see private properties where you shouldn’t. Naturally, IDEs could adapt to that and recognize naming conventions and when private properties shouldn’t be shown.\n     \n     Private properties can be accessed from outside: Applications include unit tests and quick fixes. But it also gives you more flexibility as to who data should be private too. You can, for example, include subtypes in your private circle, or “friend” functions. With the environment approach, you always limit access to functions created inside the scope of that environment.\n     \n     Name clashes: private names can clash. This is already an issue for subtypes, but it becomes more problematic with some kind of multiple inheritance (e.g. via mixins or traits).\n     \n Any object – private data in properties with reified names ECMAScript.next and reified names private name objects \n     Hidden: Private properties don’t show up when examining an object with the usual tools ( ,  , etc.), they don’t pollute an object’s property name space.\n     \n     Inaccessible: Partially as a consequence of hiding, one can only access a private property if one “has” its name object. That makes it secure: One can control precisely who has access. That control is also an advantage compared to using environments for privacy: You can now grant someone access, e.g. a unit test to check that a private method works properly.\n     \n Analysis Single method – private data in environment of method-wrapping IIFE Analysis Conclusion \n Upcoming: my book on JavaScript (free online). \n\n References JavaScript variable scoping and its pitfalls JavaScript inheritance by example Exemplars: creating objects in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/babel6-loose-mode.html", "title": "Babel 6: loose mode", "content": "Babel 6: loose mode dev javascript jstools babel esnext Babel’s loose mode transpiles ES6 code to ES5 code that is less faithful to ES6 semantics. This blog post explains how that works and what the pros and cons are (spoiler: normally not recommended). this series of posts on Babel 6  “ Configuring Babel 6 ” [explains the basics: configuration files, presets, plugins, etc.] Two modes   # Many plugins in Babel have two modes: \n A normal mode follows the semantics of ECMAScript 6 as closely as possible. \n A loose mode produces simpler ES5 code. \n Normally, it is recommended to not use loose mode. The pros and cons are: \n Pros: The generated code is potentially faster and more compatible with older engines. It also tends to be cleaner, more “ES5-style”. \n Con: You risk getting problems later on, when you switch from transpiled ES6 to native ES6. That is rarely a risk worth taking. \n Switching on loose mode   # The preset   is the loose version of the standard ES6 preset,  .  The preset’s code  provides a good overview of what plugins have a loose mode and how to switch it on. This is an excerpt: This is a CommonJS module where you can use all of ECMAScript 5. If you configure Babel via   or   ( details ), you need to use JSON. You can either include the whole preset: Or you can include plugins individually: Example: the output of normal mode and loose mode   # Let’s see how the modes affect the transpilation of the following code. Normal mode   # In normal mode, the prototype methods of the class are added via   (line A), to ensure that they are non-enumerable, as required by the ES6 spec. Loose mode   # In loose mode, normal assignment is used to add methods (line A). This style is more like you’d hand-write code in ES5. comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/babel-commonjs.html", "title": "Babel and CommonJS modules", "content": "Babel and CommonJS modules dev javascript esnext babel jstools jsmodules This blog post examines how Babel ensures that code it transpiles interoperates properly with normal CommonJS modules. Consult chapter “ Modules ” in “Exploring ES6” for more information on ES6 modules. this series of posts on Babel  “ Configuring Babel 6 ” ES6 modules vs. CommonJS modules   # ECMAScript 6 modules   # Default export (single export): Named exports (multiple exports): It is possible to combine both styles of exports, they don’t conflict with each other. CommonJS modules   # Single export: Multiple exports: Single exports and multiple exports are mutually exclusive. You have to use either one the two styles. Some modules combine both styles as follows: Comparing the two modules formats   # ES6 modules have two advantages over CommonJS modules. First, their rigid structure makes them statically analyzable. That enables, e.g.,  tree shaking (dead code elimination)  which can significantly reduce the size of bundled modules. Second, imports are never accessed directly, which means that cyclic dependencies are always supported. In CommonJS, you must code like this, so that the exported entity   can be filled in later: In contrast, this style of importing does not work (neither do single exports via  ): More information on cyclic dependencies: Section “ Support for cyclic dependencies ” in “Exploring ES6”. How Babel compiles ES6 modules to CommonJS   # As an example, consider the following ES6 module. Babel transpiles this to the following CommonJS code: The following subsections answer questions you may have about this code: \n Why isn’t the default export done like a CommonJS single export? \n Why mark transpiled ES6 modules with the flag  ? \n Why isn’t the default export done like a CommonJS single export?   # Answer: There are three reasons for doing so. First, it is closer to ES6 semantics. Second, you prevent scenarios like the following. This is illegal in native ES6 and Babel shouldn’t let you do that. Third, you want to support doing a default export and named exports at the same time. You could treat a module with just a default export like a single-export CommonJS module: However, then the exports would change completely if you add a named export: Why mark transpiled ES6 modules with the flag  ?   # The flag enables Babel to treat non-ES6 CommonJS modules that have single exports as if they were ES6 modules with default exports. How that is done is examined in the next section. How Babel imports CommonJS modules   # Default imports   # This ES6 code: is compiled to this ES5 code: Explanations: \n \n : An ES6 CommonJS module is used as is (if it has a default export then it has a property named  ). A normal CommonJS module becomes the value of the property  . In other words, in the later case, the module’s exports become the default export. \n \n \n Note that the default export is always accessed via the exports object   (line A), never directly, like this: \n \n The reason for that is support for cyclic dependencies. \n \n \n  is done so that the invocation in line A is a function call, not a method call (with  ). \n \n Namespace imports   # This ES6 code: is compiled to this ES5 code: Explanations: \n \n : CommonJS exports are translated to an object where the named exports are the properties of the exports objects and the default exports is (yet again) the exports object. The module   is an example of where a normal CommonJS module mixes a single export with multiple exports and the Babel work-around translates such a module to the world of ES6: \n \n  accesses a default export,   accesses a named export. \n \n \n Babel creates a new object (line A), because it must not modify the original exports object. \n \n Named imports   # This ES6 code: is compiled to this ES5 code: Again, you can see that   is never accessed directly, always via  , which ensures that cyclic dependencies work. Recommendations   # You need to look very closely at what a module exports and then choose the appropriate way of importing. For example, conceptually, the Node.js module   is clearly a collection of named exports, not a single export (an object). Therefore, while both of the following two ways of importing this module work, the second one is the better choice. If you want to future-proof your normal CommonJS module, you should opt for either a single export or multiple named exports, but not for mixing styles (attaching named exports as properties of a single export). comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/references.html", "title": "Why is  (0,obj.prop)()  not a method call?", "content": "Why is   not a method call? dev javascript jslang This blog post explores  , a mechanism used by the ECMAScript language specification to explain the difference between the following two expressions: \n   \n     Method calls versus function calls \n   \n   \n     References, a data structure of the ECMAScript spec \n     \n       \n         References in the example \n       \n       \n         References and  \n       \n       \n         References in real-world code \n       \n     \n   \n   \n     Why does the ECMAScript language specification use references? \n   \n   \n     Conclusion \n   \n Method calls versus function calls   # Consider the following object: If you call  , you have a method call (  points to the object in which the method is stored): If you store   in a variable and then call it, you are making a function call: The effect is the same if you use the comma operator. Quick recap – the comma operator works like this: That is, both expressions are evaluated, the result of the whole expression is  . If you apply the comma operator to   before calling it, you are also making a function call: What the first operand is doesn’t matter at all, here, I use  , because its short. I’d expect many JavaScript engines to optimize and eliminate the evaluation of the first operand. However, only using parentheses does not change anything: So what is going on? The answer has to do with  . References, a data structure of the ECMAScript spec   # References  are a data structure that is used internally by the ECMAScript language specification. A reference has three components: Base value: is either  , a primitive value, an object or an environment record.   means that a variable name could not be resolved. Accessed via   (given a reference  ). Referenced name: is a string or a symbol. Accessed via   (given a reference  ). Strict reference: flag indicating whether or not the reference was created in strict mode. Accessed via   (given a reference  ). Examples of JavaScript expressions that produce references: \n Property reference: Evaluating   in strict mode produces the reference  . \n Identifier reference: Evaluating   in strict mode produces the reference  .   is the environment record where the variable   is stored. \n The flag for strict mode is necessary, because some operations cause an exception in strict mode, but fail silently in sloppy mode. For example: setting an unresolved variable in sloppy mode creates a global variable, setting it in strict mode throws a  . These are three operations (of several) for references: \n  if   is a value, the result is  . If   is a reference, the result is the value pointed to by the reference. This conversion from reference to referenced value is called  . \n  writes the value   to the reference  . \n  is only called if   is a property reference. For normal references, it returns the base value. For references created via  , it returns the additional component   that they have ( which is needed for super property references ). \n References in the example   # We are now ready to understand the examples we looked at earlier. The following expression produces a reference: If you  function-call  this reference   then   is set to  . If you wrap   in parentheses, nothing changes, parentheses only syntactically group things, but they don’t influence how something is evaluated (they are not an operator). That is, the result of the following expression is still a reference: If, however, you assign the reference returned by   to a variable, the reference is dereferenced: In other words: what is stored in   is a function, not a reference.  In the language spec , assignment operators use   to turn references into values. The comma operator also dereferences its operands. Consider this expression: The comma operator  uses   to ensure that the result of each operand is dereferenced if it is a reference. References and     # References only being temporary is also the reason why you need to use   if you want to turn a method into a callback (first line): If you simply did: Then the receiver ( ) would get lost, because   is dereferenced before it is stored in  . References in real-world code   # Babel uses the comma operator to avoid function calls being transpiled to method calls. Consider, for example, this ES6 module: Babel compiles it to this ES5 code: The comma operator trick in line A means there will be a function call, not a method call (  will not be  ). Why does the ECMAScript language specification use references?   # JavaScript engines, which are implementations of the ECMAScript language specification, don’t actually use references. That means that they are a device that helps with writing the spec. To see why, consider that they represent storage locations. Then consider that all of the following operations work with storage locations: \n \n Reading a value: \n \n \n \n Calling a function or a method: \n \n \n \n Assigning a value: \n \n \n \n Compound assignment operators. For example, the addition assignment operator ( ): \n \n \n \n : \n \n \n \n : \n \n \n Because each storage location is represented by the same construct, a reference, the specification only needs to describe a single version of each operation instead of several versions (e.g.:   for a variable,   for a property with a fixed key,   for a property with a dynamically computed key, etc.). Conclusion   # You don’t actually see references when you use JavaScript. But there are languages (e.g. Common Lisp) where references are first class values. That enables intriguing applications. You can, for example, implement functions that perform an assignment for you. comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/webpack-tree-shaking.html", "title": "Tree-shaking with webpack 2 and Babel 6", "content": "Tree-shaking with webpack 2 and Babel 6 dev javascript webpack babel jsmodules Rich Harris’ module bundler Rollup  popularized an important feature in the JavaScript world:  , excluding unused exports from bundles. Rollup depends on  the static structure of ES6 modules  (imports and exports can’t be changed at runtime) to detect which exports are unused. Tree-shaking for webpack is currently in beta. This blog post explains how it works. The project we are going to examine is on GitHub:  How webpack 2 eliminates unused exports   # webpack 2, a new version that is in beta, eliminates unused exports in two steps: \n \n First, all ES6 module files are combined into a single bundle file. In that file, exports that were not imported anywhere are not exported, anymore. \n \n \n Second, the bundle is minified, while eliminating dead code. Therefore, entities that are neither exported nor used inside their modules do not appear in the minified bundle. Without the first step, dead code elimination would never remove exports (registering an export keeps it alive). \n \n Unused exports can only be reliably detected at build time if the module system has a static structure. Therefore, webpack 2 can parse and understand all of ES6 and only tree-shakes if it detects an ES6 module. However, only imports and exports are transpiled to ES5. If you want all of the bundle to be in ES5, you need a transpiler for the remaining parts of ES6. In this blog post, we’ll use Babel 6. Input: ES6 code   # The demo project has two ES6 modules.  with helper functions: , the entry point of the web application: Note that the export   of module   is not used anywhere in this project. Output without tree-shaking   # The canonical choice for Babel 6 is to use the preset  : However,  that preset  includes the plugin  , which means that Babel will output CommonJS modules and webpack won’t be able to tree-shake: You can see that   is part of the exports, which prevents it being recognized as dead code by minification. Output with tree-shaking   # What we want is Babel’s  , but without the plugin  . At the moment, the only way to get that is by mentioning all of the preset’s plugins in our configuration data, except for the one we want to exclude.  The preset’s source is on GitHub , so it’s basically a case of copying and pasting: If we build the project now, module   looks like this inside the bundle: Only   is an export now, but   is still there. After minification,   looks like this (I’ve added line breaks and whitespace to make the code easier to read):  – no more function  ! Further reading   # \n webpack example:  \n Configuring Babel 6 \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/npm-install-tag-version.html", "title": "Installing past or future versions of npm packages", "content": "Installing past or future versions of npm packages dev javascript npm nodejs npm lets you install versions of packages other than the current one, via: Installing tags   # Tags are aliases for versions. You can look up available tags via: Example: Installing versions   # You can look up available versions via: Example: comments powered by Disqus."},
{"url": "https://2ality.com/2016/01/web-technologies-2015.html", "title": "Looking back on 2015: six exciting web technologies", "content": "Looking back on 2015: six exciting web technologies book esnext In 2015, there was an amazing amount of innovation related to the web platform. The following sections describe six technologies that I find exciting: \n Electron \n React Native \n Progressive web apps \n Visual studio code \n Rollup \n Web Assembly \n This blog post is a loose follow-up to “ Web platform: five technologies to look forward to in 2014 ”, which I wrote in early 2014. Electron   # Electron (by GitHub)  lets you build cross-platform desktop apps with web technologies. Its features include: \n Automatic updates \n Crash reporting \n Windows installers \n Debugging and profiling \n Native menus and notifications \n Electron was initially created for GitHub’s editor   and is now used by various companies, including Microsoft (Visual Studio Code, see below), Slack and Docker. Architecturally, Electron contains both a Node.js runtime and a minimal embedded Chromium browser. Electron apps run in several processes: A   runs the   script specified by the app’s   file. To display a user interface, that script can open windows. Each of those windows runs in a separate process (a so-called  ), just like a tab in a web browser. React Native   # With  React Native , you can build native apps for iOS and Android via React. The virtual DOM is still there and you still use JSX to create it, but the actual UI is built with native components such as UITabBar on iOS and Drawer on Android. You lay out those native components via Flexbox. On one hand that means that each of the following platforms has a slightly different UI layer now: the web, iOS, Android. On the other hand, you’ll be able to reuse much of your code, while having a native experience on each platform. Usually I’m skeptical of solutions that try to transplant a language that is native on one platform to another one. But a few months ago,  an iOS developer evaluated React Native  and stated: I may never write an iOS app in Objective-C or Swift again. This is remarkable if you consider that he had to learn both JavaScript and React before he could be productive with React Native. Another  interesting quote , by Andy Matuschak (who “helped build iOS 4.1–8 on the UIKit team”): I say with confidence as a former UIKit author: React's model for the UI layer is vastly better than UIKit's. React Native is a *huge* deal. Progressive web apps   # There are areas, where native apps have caught up with the web (deep linking, indexing).   are not really a technology, but rather an umbrella term for characteristics of modern web apps. These mean that web apps are catching up with native apps in some areas and moving ahead of them in others: \n \n Progressive enhancement: The app runs in as many environments as possible. If it needs a service, it should use whatever is available and degrade gracefully if nothing is there. \n \n \n Responsive user interface: The app adapts to various input methods (touch, speech, etc.) and output methods (different screen sizes, vibration, audio, braille displays, etc.). \n \n \n Connectivity-independence: The app works well offline and with intermittent or low-bandwith connectivity. \n \n \n App-like UI: The app adopts UI elements of native platforms, including a fast-loading user interface (which can be achieved by caching important assets via service workers). \n \n \n Continuous updates (“freshness”): The service worker API defines  a process for automatically updating apps to new versions . \n \n \n Secure communication: The app is served and communicates via HTTPS, to prevent snooping and attacks. \n \n \n App discovery: Meta-data such as  W3C web app manfests  enables search engines to find web apps. \n \n \n Push interaction (“re-engagement”): Features such as push notifications actively keep users up-to-date. \n \n \n Natively installable: On some platforms, you can install a web app so that it feels like a native app (icon on home screen, separate entry in app switcher, browser chrome optional). All without going through a native app store. \n \n \n Linkability: Easily share apps via URLs and run them without installation. \n \n I’m mentioning progressive web apps here, because I like all of the aforementioned techniques and technologies. But I’m not sure how much “progressive web apps” are different from simply “modern web apps”. One idea I oppose is  giving web apps install banners  (their killer feature is, after all, that they don’t need those). \n Progressive Web Apps  (site by Google) \n “ ‘Progressive apps’ are a bag of carrots ” by Andrew Betts. Andrew is critical of “progressive web apps” as a brand. The blog post starts with an interesting examination of that brand. \n Visual Studio Code   # Visual Studio Code  is a JavaScript code editor for whom the goal is to exist in the space between full IDEs and text editors. And, in my opinion, it succeeds nicely. A plus is that it’s written in JavaScript and based on Electron. In 2015, VSC became  open source  and gained   (an API for extending it via plugins). Rollup   # Rollup  is a  : it converts multiple ES6 modules into a single  , a module in either one of serveral formats (ES6, CommonJS, …). Rollup brings two innovations to the world of JavaScript modules: \n \n The bundle it outputs only includes those exports that are actually used, via a technique called “tree-shaking”. Three-shaking crucially depends on the static structure of ES6 modules. “Static structure” means that they are analyzable at compile time, without executing any of their code. Having this kind of dead code elimination is great, because we are now free to make modules as big or as tiny as makes sense, without having to worry about the sizes of bundles. \n \n \n It demonstrates that ES6 modules are a viable bundle format for ES6 modules (obviating the need for any kind of custom loading). \n \n \n The Rollup Guide \n Tree-shaking with webpack 2 and Babel 6 \n The future of bundling JavaScript modules \n Web Assembly   # Web Assembly is a binary format for a static formal language (derived from asm.js) that can be fed into JavaScript engines (that support it) to create fast executables. The formal language is higher-level than bytecode and therefore easier to evolve. The output lives inside the universe of JavaScript and therefore integrates well with it. Given how fast asm.js is, C++ compiled to Web Assembly will run roughly 70% as fast as when you compile it to native code. Web Assembly will probably eventually get support for JavaScript OOP. At that point, it will truly be a universal virtual machine for the web. \n WebAssembly: a binary format for the web \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/12/bundling-modules-future.html", "title": "The future of bundling JavaScript modules", "content": "The future of bundling JavaScript modules dev javascript esnext jsmodules jstools This blog post examines how the bundling of modules is affected by two future developments: HTTP/2 and native modules. Why we bundle modules   # Bundling modules means combining several files with modules into a single file. That is done for three reasons: Fewer files need to be retrieved in order to load all modules. Compressing the bundled file is slightly more efficient than compressing separate files. During bundling, unused exports can be removed, potentially resulting in significant space savings. JavaScript modules   # With ECMAScript 6, JavaScript finally got built-in modules (I’m calling them   for the remainder of this blog post). However, that feature is currently in a strange position: On one hand, ES6 fully standardized their syntax and much of their semantics. They have become a popular format for writing modules and their static structure enables the automatic omission of unused exports (also known as “tree-shaking” in the JavaScript world). On the other hand, standardizing how to load JavaScript modules is ongoing and no JavaScript engine supports them natively, yet. That means that, at the moment, the only way of using JavaScript modules is by compiling them to a non-native format. Popular solutions are: browserify, webpack, jspm and Rollup. Future developments and bundling   # Let’s look at two future developments and how they affect the bundling of JavaScript modules. Future development: HTTP/2   # HTTP/2 is slowly being rolled out. It mainly affects reason #1 for bundling: With HTTP/2, the cost per request has decreased considerably compared to HTTP/1, which means that there are practically no performance gains if you download a single file instead of multiple ones. That enables smaller, more incremental updates: With bundling, you always need to download the complete bundle. Without bundling, you only need to download the parts that have changed (while the other parts are often still in the browser cache). However, reasons #2 and #3 for bundling are not negated by HTTP/2. Therefore, mixed approaches may be adopted in the future, to optimize for both incremental updates and minimal total download size. Future development: native JavaScript modules   # Once engines support native JavaScript modules, will that affect bundling? Even AMD modules – which run natively in browsers – have  a custom bundle format  (along with a minimal loader). Will native JS modules be different? It looks like they will. Rollup lets you bundle multiple JS modules into a single JS module. Take, for example, these two JS modules: Rollup can bundle these two JS modules into the following single JS module (note the eliminated unused export  ): Initially, it wasn’t a given that JavaScript modules would work as a bundle format –  quoting Rollup’s creator Rich Harris : When I started writing Rollup, it was an experiment that I wasn't certain would succeed. The way imports are handled by JS modules helps with bundling:  they are not copies of exports, they are read-only views on them . Rollup’s site  has a nice interactive playground where you can try it out. Further reading   # \n “ Building for HTTP/2 ” by Rebecca Murphey (explains how best practices change – often radically – with this new version of HTTP) \n Chap. “ Modules ” in “Exploring ES6” (explains how ES6 modules work) \n “ Babel and CommonJS modules ” (explains how Babel ensures that transpiled ES6 modules interoperate properly with CommonJS modules) \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/popular-js-keywords.html", "title": "What are the most popular JavaScript keywords?", "content": "What are the most popular JavaScript keywords? dev javascript jslang Esprima most popular keywords \nThe five most popular ones are (by far):\n \n     19.2%:  \n     18.5%:  \n     18.2%:  \n     17.1%:  \n     12.6%:  \n \nFor more information, including a diagram of the distribution of the keywords, consult  Ariya Hidayat’s article .\n comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/stricter-equality.html", "title": "Stricter equality in JavaScript", "content": "Stricter equality in JavaScript dev javascript jslang \nMost JavaScript programmers are aware that “normal” equality ( ) should be avoided in favor of strict equality ( )  [1] . However, every now and then you need something even stricter than  : If you want to check for   or if you want to distinguish between   and  . This blog post explains the details and ECMAScript.next’s  [2]  solution, the “ ” operator.\n \n\n Checking for NaN [3] [3] Distinguishing between -0 and +0 Stricter equality in ECMAScript.next: the “is” operator “ ” operator ECMAScript.next proposal Why does the ECMAScript.next proposal use the name “egal”? ECMAScript.next proposal Equal Rights for Functional Objects or, The More Things Change, The More They Are the Same Trying out Object.is() [4] References Equality in JavaScript: === versus == ECMAScript.next: the “TXJS” update by Eich NaN and Infinity in JavaScript es6-shim – ECMAScript 6 functionality on ECMAScript 5 comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/signedzero.html", "title": "JavaScript’s two zeros", "content": "JavaScript’s two zeros numbers dev javascript jslang The signed zero \nIn JavaScript, all numbers are floating point numbers, encoded in double precision according to the  IEEE 754 standard  for floating point arithmetic. That standard handles the sign in a manner similar to sign-and-magnitude encoding for integers and therefore also has a  . Whenever you represent a number digitally, it can become so small that it is indistinguishable from 0, because the encoding is not precise enough to represent the difference. Then a signed zero allows you to record “from which direction” you approached zero, what sign the number had before it was considered zero. Wikipedia nicely sums up the pros and cons of  signed zeros :\n Hiding the zero’s sign Where the zero’s sign matters Adding zeros Multiplying by zero Dividing by zero Math.pow() Math.atan2() Math.round() Telling the two zeros apart original solution blog post Conclusion Related reading \n     Integers and shift operators in JavaScript \n     Displaying numbers in JavaScript \n Stricter equality in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/css-grid-layout-firefox.html", "title": "CSS Grid Layout is coming to Firefox in 2012", "content": "CSS Grid Layout is coming to Firefox in 2012 dev firefox webdev layout [1] [2] Firefox in 2011 – Firefox plans for 2012 \nIn case you are wondering whether “CSS Grid” is the same as “CSS Grid Layout”, there are several similarly named specifications floating around, but they really are just different versions of the same standard:\n “ CSS Grid Positioning Module Level 3 ” (5 September 2007) “ Grid Layout ” (22 March 2012) W3C Editor’s Draft: “ CSS Grid Layout ” (22 March 2012) mentions \nExample layout:\n \n         : assign a size so that the content fits comfortably. \n         : the minimum size is   (the smallest size that still allows the content to be shown); the maximum size is “1fr”, a  fraction value  indicating to assign 100% of the additional space that remains after all maximum sizes have been reached. \n     CSS Grid Layout References CSS3 Grid Layout is perfect for webapp GUIs A Windows 8 keynote review by a JavaScript programmer and Apple user comments powered by Disqus."},
{"url": "https://2ality.com/2012/03/converting-to-string.html", "title": "Converting a value to string in JavaScript", "content": "Converting a value to string in JavaScript dev javascript jslang section “Converting to string” Three approaches for converting to string \n     : The plus operator is fine for converting a value when it is surrounded by non-empty strings. As a way for converting a value to string, I find it less descriptive of one’s intentions. But that is a matter of taste, some people prefer this approach to  .\n     \n     : This approach is nicely explicit: Apply the function   to  . The only problem is that this function call will confuse some people, especially those coming from Java, because   is also a constructor. However, function and constructor produce completely different results:\n \n        The function produces, as promised, a string (a    [1] ). The constructor produces an instance of the type   (an object). The latter is hardly ever useful in JavaScript, which is why you can usually forget about   as a constructor and concentrate on its role as converting to string.\n     \n A minor difference between \"\"+value and String(value) Converting a primitives to string \n Converting objects to string [2] \n     ToPrimitive(Number): To convert an object   to a primitive, invoke  . If the result is primitive, return that result. Otherwise, invoke  . If the result is primitive, return that result. Otherwise, throw a  .\n     \n     ToPrimitive(String): Works the same, but invokes   before  .\n     \n The results are usually the same \n     ToPrimitive(Number) returns the result of applying ToString() to the result of   (the wrapped primitive). \n     ToPrimitive(String) returns the result of   (the result of applying ToString() to the wrapped primitive). \n Conclusion Related posts JavaScript values: not everything is an object  [primitives versus objects] What is {} + {} in JavaScript?  [explains how the + operator works] String concatenation in JavaScript  [how to best concatenate many strings] comments powered by Disqus."},
{"url": "https://2ality.com/2012/04/eval-variables.html", "title": "Handing variables to eval", "content": "Handing variables to eval eval dev javascript jslang [1] [2] \nLet’s assume we want to implement a function\n \n     Wrap a function expression (not a function declaration!) around   whose parameters are the variables listed in  . \n     Evaluate the function expression. \n     Call the resulting function with the property values of  , in the same order as the parameters. \n [3] \nNote that the usual security concerns about   apply here, too: You have to make sure that all ingredients come from trusted sources. But there are legitimate uses for this technique, e.g. for templating.\n \n \n JavaScript’s with statement and why it’s deprecated JavaScript’s strict mode: a summary es5-shim: use ECMAScript 5 in older browsers comments powered by Disqus."},
{"url": "https://2ality.com/2012/04/arrow-functions.html", "title": "ECMAScript 6: arrow functions and method definitions", "content": "ECMAScript 6: arrow functions and method definitions esnext dev javascript Callable entities in ECMAScript 6 \nIn JavaScript, one aspect of creating a function inside a method is difficult to get right: handling the special variable  . ECMAScript.next will make things easy by introducing two constructs: arrow functions and method definitions. This blog posts explains what they are and how they help.\n\n \n\n Terminology \n     A   exists on its own and is called directly. In general, “function” would be a better word, but that has a broader meaning in JavaScript. Hence, JavaScripters normally say “non-method function” to a subroutine. I’m only using the term “subroutine”, because I couldn’t find a better one (other possibilities are: callback, procedure).\n     \n     A   is part of an object   and called via an object (which isn’t necessarily the same object as  ).\n     \n \nFunctions work well as method implementations: They have a special variable called   that refers to the object via which the method has been invoked. In contrast to other free variables,   isn’t looked up in the surrounding lexical scopes, it is handed to the function via the invocation. As the function receives   dynamically, it is called  .\n     \nFunctions don’t work well as implementations of subroutines, because   is still dynamic. The subroutine call sets it to   in strict mode  [1]  and to the global object, otherwise. That is unfortunate, because the subroutine has no use for its own  , but it shadows the   of the surrounding method, making it inaccessible. For example:\n \n     You have to know how JavaScript’s quirky   works (which you should neither want to nor need to).\n     \n     You have to constantly be alert as to when to simulate lexical  . That choice should be automatic and not require extra thought. A simulation incurs a performance and memory cost, so you’ll want to avoid it if you don’t need it.\n     \n     There is more to type and more visual clutter.\n     \n Arrow functions \nSpecifying arguments:\n \nNote how much an arrow function with an expression body can reduce verbosity. Compare:\n Implementing lexical  Arrow functions versus normal functions parameter default values rest parameters \nApart from these simplifications, there is no observable difference between an arrow function and a normal function. For example,   and   can be used as before:\n Syntactic variants under discussion \n     \n \n        With JavaScript’s automatic semicolon insertion  [2] , there is a risk of such an expression being wrongly considered as continuing a previous line. Take, for example, the following code.\n \n        These two lines are interpreted as\n \n        However, arrow functions will usually appear in expression context, nested inside a statement. Hence, I wouldn’t expect semicolon insertion to be much of a problem. If JavaScript had significant newlines  [3]  (like CoffeeScript) then the problem would go away completely.\n     \n     \n \n        That’s a function with a single parameter that always returns  . It is a synonym for the   operator  [4] . I’m not sure how useful that is.\n     \n      JavaScript already has  , where you give a function a name so that it can invoke itself. That name is local to that function, it doesn’t leak into any surrounding scopes. Named arrow functions would work the same. For example:\n \n     \n Parsing arrow functions \nTo parse both of the above with a limited look-ahead, one uses a trick called  : One creates a grammar rule that covers both use cases, parses and then performs post-processing. If an arrow follows the closing parenthesis, some previously parsed things will raise an error and the parsed construct is used as the formal parameter list of an arrow function. If no arrow follows, other previously parsed things will raise an error and the parsed construct is an expression in parentheses. Some things can only be done in a parenthesized expression:\n rest parameter Possible arrow function feature: optional dynamic this \nShouldn’t there be a simpler solution for optional dynamic  ? Alas, two seemingly simpler approaches won’t work.\n\n Non-solution: switching between dynamic and lexical  \nAnother problem with switching between the two kinds of   is security-related: You can’t control how a function you write will be used by clients, opening the door to inadvertently exposed secrets. Example: Let’s pretend there are “thin arrow functions” (defined via  ) that switch between dynamic and lexical  , on the fly.\n Non-solution: Let   or   override the bound value of  . Arguing in favor of simplicity [5] Method definitions Need to define a subroutine? Use an arrow function and automatically have lexical  . Need to define a method? Use a normal function and automatically have dynamic  . [6] Method definitions in class declarations maximally minimal classes [7] Method definitions in object literals What do we really need? surveyed \n \nTerminology:\n \n     Arrow function candidates (AFCs) are function expressions without dynamic  ; they don’t refer to   in (the immediate scope of) the body.\n     \n     “Expression body” is a superset of “object literal body”. \n     Function expressions in an object literal that don’t refer to   are considered AFCs. In that case, the surrounding object is usually a namespace.\n     \n \nThese findings mean that JavaScript most urgently needs easy ways to define subroutines (with lexical  ) and methods. ECMAScript.next therefore makes the right choices. Another implication is that arrow functions with dynamic   are not that important, even for current JavaScript code. Lastly, having to parenthesize an object literal in an expression body is rarely an issue: only 0.14% of the function expressions return one.\n\n Conclusion \n     Constructor functions will (hopefully) be replaced by class declarations. \n     Functions as subroutines will be replaced by arrow functions. \n     Functions as methods will be replaced by method definitions. \n More material on arrow functions \n     “ What is the meaning of this? ” by Douglas Crockford \n     “ JavaScript Fat City ” by Angus Croll \n References JavaScript’s strict mode: a summary Automatic semicolon insertion in JavaScript What JavaScript would be like with significant newlines The void operator in JavaScript Uncurrying `this` in JavaScript A closer look at super-references in JavaScript and ECMAScript.next Myth: JavaScript needs classes comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/http-server-nodejs.html", "title": "Running a simple web server from a shell", "content": "Running a simple web server from a shell dev javascript nodejs The classic command  for running a simple web server from a shell is: As a result, files are served at  , with 8000 being the default if you omit the port. This command has the advantage that it is built into Python and that Python is built into Mac OS X. However, this command always serves the current working directory (the directory that you are currently in), there is no way to provide a directory as an argument. That’s a problem if the directory you want to serve is constantly being deleted and recreated. Node.js doesn’t have a similar built-in mechanism, but there is an npm package that you can install:  . A basic way of using the shell command that this package comes with is: Afterwards, files are served at  . \n If you omit the path,   is used, if it exists, and   otherwise. \n If you omit the port, 8080 is used. \n Why would you want to do this? Many styles of sites and web apps don’t run properly “over” the   protocol (accessed directly via the local file system). Therefore, you often need to serve them from   during development. comments powered by Disqus."},
{"url": "https://2ality.com/2012/04/html5-download.html", "title": "Offer files for download in HTML5: a[download]", "content": "Offer files for download in HTML5: a[download] dev html5 webdev \n  Normally, when you click on an   tag, the web browser visits the file it refers to. Sometimes, you instead want the file to be downloaded. Most browsers usually ask the user to confirm before starting the download. Previously, you had to send the following HTTP header to make that happen.\n \n  The new attribute   ensures that a file is downloaded and not displayed.\n \n  This feature is especially useful if you are working with URLs coming from   instances  (which include   instances  in the user’s file system) and   instances  (in browser-local sandboxed file systems). With  , their data becomes downloadable.\n \nSource: “ Downloading resources in HTML5: a[download] ” by Eric Bidelman for  .\n comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/why-tdz.html", "title": "Why is there a “temporal dead zone” in ES6?", "content": "Why is there a “temporal dead zone” in ES6? dev javascript esnext In ECMAScript 6, accessing a   or   variable before its declaration (within its scope) causes a  . The time span when that happens, between the creation of a variable’s binding and its declaration, is called the  . For more information, consult Sect. “ The temporal dead zone ” in “Exploring ES6”. Here, I’d like to answer two questions: \n Why is there a temporal dead zone? \n Why does   cause a   for a variable in the TDZ? \n Why is there a temporal dead zone?   # \n To catch programming errors: Being able to access a variable before its declaration is strange. If you do so, it is normally by accident and you should be warned about it. \n For  : Making   work properly is difficult.  Quoting Allen Wirfs-Brock : “TDZs ... provide a rational semantics for  . There was significant technical discussion of that topic and TDZs emerged as the best solution.”   also has a temporal dead zone so that switching between   and   doesn’t change behavior in unexpected ways. \n Future-proofing for guards: JavaScript may eventually have  , a mechanism for enforcing at runtime that a variable has the correct value (think runtime type check). If the value of a variable is   before its declaration then that value may be in conflict with the guarantee given by its guard. \n Why does   cause a   for a variable in the TDZ?   # If you access a variable in the temporal dead zone via  , you get an error, too: The rationale here is as follows:   is not undeclared, it is uninitialized. You should be aware of its existence, but aren’t. Therefore, being warned seems desirable. Furthermore, this kind of check is only useful for conditionally creating global variables. That’s something that only advanced JavaScript programmers should do and that can only be achieved via  . Additionally, there is hope that ES6 modules will eventually obviate the need for conditionally creating global variables. There is a way to check whether a variable exists that does not involve  : The former way of creating a global variable only works in global scope (and therefore not inside ES6 modules). Futher reading   # Sources of this blog post: \n “ Performance concern with let/const ” \n “ Bug 3009 – typeof on TDZ variable ” \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/04/number-encoding.html", "title": "How numbers are encoded in JavaScript", "content": "How numbers are encoded in JavaScript numbers dev javascript jsint jslang JavaScript numbers IEEE 754 standard \n \nThe components work as follows: If the sign bit is 0, the number is positive, otherwise negative. Roughly, the fraction contains the digits of a number, while the exponent indicates where the point is. In the following, we’ll often use binary numbers, which is a bit unusual when it comes to floating point. Binary numbers will be marked by a prefixed percentage sign (%). While JavaScript numbers are stored in binary, the default output is decimal  [1] . In the examples, we’ll normally work with that default.\n\n The fraction \nExamples:\n Representing integers \n \nSecond, for a full 53 bits, we still need to represent zero. How to do that is explained in the next section. Note that we have the full 53 bits for the magnitude (absolute value) of the integer, as the sign is stored separately.\n\n The exponent offset binary \nA few numbers in offset binary encoding:\n\n \n\n Special exponents [2] [3] \nSecond, an exponent of 0 is also used to represent very small numbers (close to zero). Then the fraction has to be non-zero and, if positive, the number is computed via\n Summary: exponents \nWith   =   − 1023, the exponent has a range of\n Decimal fractions \nIn contrast, representing a binary fraction as a decimal fraction is always possible, you just need to collect enough twos (of which every ten has one). For example:\n Comparing decimal fractions The maximum integer \n  You have 53 bits available for the magnitude (excluding the sign), but the fraction comprises only 52 bits. How is that possible? As you have seen above, the exponent provides the 53rd bit: It shifts the fraction, so that all 53 bit numbers except the zero can be represented and it has a special value to represent the zero (in conjunction with a fraction of 0).\n \n \n  Normally,   bit mean that the lowest number is 0 and the highest number is 2 −1. For example, the highest 8 bit number is 255. In JavaScript, the highest fraction is indeed used for the number 2 −1, but 2  can be represented, thanks to the help of the exponent – it is simply a fraction   = 0 and an exponent   = 53 (after conversion):\n \n  Examples:\n \n \nLooking at the row ( =53), it should be obvious that JavaScript numbers can have bit 53 set to 1. But as the fraction   only has 52 bits, bit 0 must be zero. Hence, only even numbers   can be represented in the range 2  ≤   < 2 . In row ( =54), that spacing increases to multiples of four, in the range 2  ≤   < 2 :\n IEEE 754 exceptions  An invalid operation has been performed. For example, computing the square root of a negative number. Returns NaN  [2] .\n \n      returns plus or minus infinity  [2] .\n \n      The result is too large to be represented. That means that the exponent is too high (  ≥ 1024). Depending on the sign, there is positive and negative overflow. Returns plus or minus infinity.\n \n      The result is too close to zero to be represented. That means that the exponent is too low (  ≤ −1023). Returns a denormalized value or zero.\n \n      An operation has produced an inexact result – there are too many significant digits for the fraction to hold. Returns a rounded result.\n \n     Conclusion \n  The web page “ IEEE-754 Analysis ” allows you to enter a number and look at its internal representation.\n\n Sources and related reading \n     “ IEEE Standard 754 Floating-Point ” by Steve Hollasch. \n     “ Data Types and Scaling (Fixed-Point Blockset) ” in the MATLAB documentation. \n     “ IEEE 754-2008 ” on Wikipedia. \n series Displaying numbers in JavaScript NaN and Infinity in JavaScript JavaScript’s two zeros comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/es6-influences.html", "title": "Influences on ECMAScript 6", "content": "Influences on ECMAScript 6 dev javascript esnext This is a list of a few ECMAScript 6 features and what their influences were: \n Iteration : Python (but with a modified protocol) \n Generators : Python \n Arrow functions : CoffeeScript \n : The name comes from C++ (the latest C standard borrowed it from C++), but it behaves more like Java’s  . \n : is old, became popular via BASIC.\n \n Also frequently appears in functional programming languages (Lisp, ML, etc.), but creates immutable bindings there. \n \n \n Template literals : E ( quasi literals ) \n Destructuring : Lisp (destructuring bind) \n Modules : CommonJS, AMD \n Species pattern  ( ): Smalltalk \n Promises : also often called  , are an old construct from concurrent programming languages. But ES6 Promises don’t block, they accept continuations via callbacks. \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/04/expand-urls.html", "title": "Node.js: expanding shortened URLs", "content": "Node.js: expanding shortened URLs dev nodejs The minimum request module Prettier with promises Q module Related reading \n     “ Unshorten  – A simple URL unshortener for Node.js” by Mathias Bynens. As far as I can tell, it follows at most one redirect, but that would be simple to fix.\n     \n     “\n Write your shell scripts in JavaScript, via Node.js ” tells you how you could, e.g., read the URLs to be expanded from a file.\n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/call-constructor-esprop.html", "title": "ES proposal: function-callable classes", "content": "ES proposal: function-callable classes dev javascript es proposal This blog post describes the proposed ECMAScript feature “ call constructor ” ( stage 1 ). Classes can’t be function-called in ES6   # In ECMAScript 6, classes can’t be function-called: For ES6, there was no categorical objection to classes being function-called. The error was only thrown so that handling function calls via classes could be added later. Function-callable constructors in ES6   # If you want to implement a constructor   that can be both function-called and constructor-called, you have no choice but to use a constructor function in ES6: Function-callable classes via the proposed call constructor   # The proposal is about allowing classes to handle function calls via the pseudo-method  : Things of note: \n A call constructor is not inherited by subclasses, you have to put it into each class you want to function-call. \n A   call is a compile-time error inside a call constructor (just like it is in normal methods). That is done to keep options open w.r.t. enabling   in call constructors in the future. \n Possible future additions to the proposal   # New meta-properties   # In a future version of the proposal,  two meta-properties will probably be added : \n  refers to the current class (a function). \n  refers to the super-class of the current class. \n  will help with forwarding from the call constructor to the constructor: A decorator for making classes function-callable   # Another possibility  is  a class decorator  that enables function-calling by forwarding from the call constructor to the constructor. For example: Internally, this class looks like the previous example. Further reading   # \n “ Call constructor proposal ” by Yehuda Katz and Allen Wirfs-Brock \n Chapter “ Classes ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/11/sequential-execution.html", "title": "Synchronous and asynchronous sequential execution of functions", "content": "Synchronous and asynchronous sequential execution of functions dev javascript esnext async This blog post examines three ways of executing function sequentially: \n Synchronously \n Asynchronously, via Promises \n Asynchronously, via the library co \n Synchronously   # Synchronous sequential execution is built into JavaScript and looks like this: Asynchronously, via Promises   # To execute Promise-based functions sequentially, you need to chain function calls via  , which is the Promise equivalent of the semicolon: If you are OK with executing the functions in an arbitrary order (the single-threaded version of “in parallel”), you can use  : Asynchronously, via the library co   # The library co  also works with Promise based functions. Its helper method,  , converts a generator function   into a function that returns a promisification of whatever   returns. The neat thing is that   can   a Promise (e.g. the result of a function call) and is suspended while the Promise is pending. If the Promise is fulfilled, the fulfillment value becomes the result of  . If the Promise is rejected, the rejection value is thrown as an exception. Let’s look at an example: co works very much like  async functions , a proposed ECMAScript feature (to appear in ES2016 or later), without being much more verbose. I prefer it to transpiling async functions via Babel, because their syntax may still change. Further reading   # \n Async Functions for ECMAScript  (ECMAScript proposal) \n “ Promises for asynchronous programming ” (chapter in “Exploring ES6”)\n \n “ Asynchronous programming (background) ” (background for the chapter on Promises) \n \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/reader-survey.html", "title": "Reader survey 2015", "content": "Reader survey 2015 2ality Dear readers! If you would, please fill out my  reader survey . It won’t take long and will help improve this blog. Last day of survey: Monday, November 9, 2015 Thank you! Axel comments powered by Disqus."},
{"url": "https://2ality.com/2015/11/string-padding.html", "title": "ES proposal: string padding", "content": "ES proposal: string padding dev javascript esnext es proposal The ECMAScript proposal “ String padding ” by Jordan Harband & Rick Waldron is part of  ECMAScript 2017 . This blog post explains it. Padding strings   # Use cases for padding strings include: \n Displaying tabular data in a monospaced font. \n Adding a count or an ID to a file name or a URL:  \n Aligning console output:  \n Printing hexadecimal or binary numbers that have a fixed number of digits:  \n    # This method (possibly repeatedly) prefixes the receiver with  , until its length is  : If necessary, a fragment of   is used so that the result’s length is exactly  : If the receiver is as long as, or longer than,  , it is returned unchanged: If   and   are the same,   becomes a mask into which the receiver is inserted, at the end: If you omit  , a string with a single space in it is used ( ): A simple implementation of     # The following implementation gives you a rough idea of how   works, but isn’t completely spec-compliant (for a few edge cases).    #  works similarly to  , but instead of inserting the repeated   at the start, it inserts it at the end: Only the last line of an implementation of   is different, compared to the implementation of  : FAQ: string padding   # Why aren’t the padding methods called   and  ?   # For bidirectional or right-to-left languages, the terms   and   don’t work well. Therefore, the naming of   and   follows the existing names   and  . comments powered by Disqus."},
{"url": "https://2ality.com/2015/11/stage3-object-entries.html", "title": "ES proposal: Object.entries() and Object.values()", "content": "ES proposal: Object.entries() and Object.values() dev javascript esnext es proposal The following ECMAScript proposal is at  stage 4 : “ Object.values/Object.entries ” by Jordan Harband. This blog post explains it.    # This method has the following signature: If a JavaScript data structure has keys and values then an   is a key-value pair, encoded as a 2-element Array.   coerces   to an Object and returns the entries of its enumerable own string-keyed properties, in an Array: Properties, whose keys are symbols, are ignored:  finally gives us a way to iterate over the properties of an object ( read here why objects aren’t iterable by default ): Setting up Maps via     #  also lets you set up a Map via an object. This is more concise than using an Array of 2-element Arrays, but keys can only be strings. FAQ:     # \n \n \nThe relevant precedent in this case is  , not, e.g.,  . \n \n \n \nAgain, this is done to be consistent with  . That method also ignores properties whose keys are symbols. Eventually, there may be a method   that returns all own properties. \n \n    #  has the following signature: It works much like  , but, as its name suggests, it only returns the values of the own enumerable string-keyed properties: comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/property-traversal-order-es6.html", "title": "The traversal order of object properties in ES6", "content": "The traversal order of object properties in ES6 dev javascript esnext The ECMAScript 6 specification defines in which order the properties of an object should be traversed. This blog post explains the details. Why specify the traversal order?   # Traditionally, a JavaScript object is basically a map from strings to arbitrary values. The inherent nature of such a data structure is for entries to be unordered, which explains why, for a long time, the order in which properties are traversed was left unspecified in JavaScript (to be handled by engines as they saw fit). However, most engines ended up having the same order and now code depends on it. Therefore, using a different order breaks web apps, which is why requiring an order makes sense. In general, there are two possible approaches for preventing code from breaking in the manner that I’ve just described: Specify an order that code can depend on. Specify that engines must make it impossible for code to rely on an order, by choosing a different order each time. The latter is hard, which is why the former approach was taken. An additional benefit is that it helps with programming tasks such as debugging and testing output, where a fixed order makes it easier to compare expected with actual results. For example,   will always produce the same result, as long as   is created in the same manner. Operations that traverse properties   # The following operations in ECMAScript 6 traverse the keys of properties (the only way in which you can currently iterate over properties): \n Own property keys:\n \n \n \n \n \n \n All (own   inherited) keys:\n \n \n  loop \n \n \n Traversing the own keys of an object   # Property keys are traversed in the following order: \n First, the keys that are integer indices (what these are is explained later), in ascending numeric order. \n Then, all other string keys, in the order in which they were added to the object. \n Lastly, all symbol keys, in the order in which they were added to the object. \n Many engines treat integer indices specially (even though they are still strings, at least as far as the ES6 spec is concerned). Therefore, it makes sense to treat them as a separate category of keys. Integer indices   # Roughly, an integer index is a string that, if converted to a 53-bit non-negative integer and back is the same value. Therefore: \n  and   are integer indices. \n  is not an integer index. Coverting it to an integer and back results in the different string  . \n  is not an integer index, because 3.141 is not an integer. \n In ES6, instances of   and Typed Arrays have integer indices. The indices of normal Arrays are a subset of integer indices: they have a smaller range of 32 bits. For more information on Array indices, consult “ Array Indices in Detail ” in “Speaking JavaScript”. Example   # The following code demonstrates the order in which the own keys of an object are iterated over: Explanation: \n  and   are integer indices, come first and are sorted numerically. \n  and   are normal string keys, come next and appear in the order in which they were added to  . \n  and   are symbols and come last, in the order in which they were added to  . \n Enumerating the string keys of all enumerable properties   # The   loop and its iterator-returning analog,   traverse the keys of all properties, not just the own ones. But they only consider enumerable string keys. Algorithm: In order to enumerate the property keys of an object  , ... \n \n Visit the keys of all own enumerable string keys of  , in the order described in the previous section. Ignore any keys that existed in previously processed objects (independently of whether those were keys of enumerable properties or not). \n \n \n Perform the previous step for the prototype of  , the prototype’s prototype, etc., until the end of the chain is reached. \n \n The ES6 spec contains  a recursive implementation  that stays close to  the ES6 meta object protocol . This is an iterative version of that implementation that is slightly easier to understand: The following code demonstrates that   and   ignore properties they encountered before, even if they weren’t enumerated. Conclusion   # Being able to rely on the order in which properties are traversed in ES6 will help with several tasks (such as testing). However, I expect that with ES6 Maps, one will traverse properties of objects less often. As an aside, the entries of Maps are ordered, too, by when they were added. The rationale for doing so is they same as the one for objects (as described earlier). Sources   # Two threads on es-discuss are instructive w.r.t. the traversal order of properties: \n Nailing object property order \n iteration order for Object \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/11/tc39-process.html", "title": "The TC39 process for ECMAScript features", "content": "The TC39 process for ECMAScript features dev javascript esnext es proposal This blog post explains the so-called  , which governs how ECMAScript features are designed, starting with ECMAScript 2016 (ES7). Related blog posts: \n The final feature set of ECMAScript 2016 (ES7) \n Feature watch: ECMAScript 2017 \n Who designs ECMAScript?   # Answer: TC39 (Technical Committee 39). TC39  is the committee that evolves JavaScript. Its members are companies (among others, all major browser vendors).  TC39 meets regularly , its meetings are attended by delegates that members send and by invited experts. Minutes of the meetings are  available online  and give you a good idea of how TC39 works. Occasionally (even in this blog post), you’ll see the term   referring to a human. Then it means: a delegate sent by a TC39 member company. It is interesting to note that TC39 operates by consensus: Decisions require that a large majority agrees and nobody disagrees strongly enough to veto. For many members, agreements lead to real obligations (they’ll have to implement features etc.). How is ECMAScript designed?   # Problem: ECMAScript 2015 (ES6) was too large a release   # The most recent release of ECMAScript, ES6, is large and was standardized almost 6 years after ES5 (December 2009 vs. June 2015). There are two main problems with so much time passing between releases: \n Features that are ready sooner than the release have to wait until the release is finished. \n Features that take long are under pressure to be wrapped up, because postponing them until the next release would mean a long wait. Such features may also delay a release. \n Therefore, starting with ECMAScript 2016 (ES7), releases will happen more frequently and be much smaller as a consequence. There will be one release per year and it will contain all features that are finished by a yearly deadline. Solution: the TC39 process   # Each proposal for an ECMAScript feature goes through the following  , starting with stage 0. The progression from one stage to the next one must be approved by TC39. #  A free-form way of submitting ideas for evolving ECMAScript. Submissions must come either from a TC39 member or a non-member who  has registered as a TC39 contributor .  The document must be reviewed at a TC39 meeting ( source ) and is then added to  the page with stage 0 proposals . #  A formal proposal for the feature.  A so-called   must be identified who is responsible for the proposal. Either the champion or a co-champion must be a member of TC39 ( source ). The problem solved by the proposal must be described in prose. The solution must be described via examples, an API and a discussion of semantics and algorithms. Lastly, potential obstacles for the proposal must be identified, such as interactions with other features and implementation challenges. Implementation-wise, polyfills and demos are needed.  By accepting a proposal for stage 1, TC39 declares its willingness to examine, discuss and contribute to the proposal. Going forward, major changes to the proposal are expected. #  A first version of what will be in the specification. At this point, an eventual inclusion of the feature in the standard is likely.  The proposal must now additionally have a formal description of the syntax and semantics of the feature (using the formal language of the ECMAScript specification). The description should be as complete as possible, but can contain todos and placeholders. Two experimental implementations of the feature are needed, but one of them can be in a transpiler such as Babel.  Only incremental changes are expected from now on. #  The proposal is mostly finished and now needs feedback from implementations and users to progress further.  The spec text must be complete. Designated reviewers (appointed by TC39, not by the champion) and the ECMAScript spec editor must sign off on the spec text. There must be at least two spec-compliant implementations (which don’t have to be enabled by default).  Henceforth, changes should only be made in response to critical issues raised by the implementations and their use. #  The proposal is ready to be included in the standard.  The following things are needed before a proposal can reach this stage: \n Test 262  acceptance tests (roughly, unit tests for the language feature, written in JavaScript). \n Two spec-compliant shipping implementations that pass the tests. \n Significant practical experience with the implementations. \n The ECMAScript spec editor must sign off on the spec text. \n  The proposal will be included in the ECMAScript specification as soon as possible. When the spec goes through its yearly ratification as a standard, the proposal is ratified as part of it. Don’t call them ECMAScript 20xx features   # As you can see, you can only be sure that a feature will be included in the standard once its proposal has reached stage 4. Then its inclusion in the next ECMAScript release is probable, but not 100% sure, either (it may take longer). Therefore, you can’t call proposals (e.g.) “ES7 features” or “ES2016 features”, anymore. My two favorite ways of writing headings for articles and blog posts are therefore: \n “ECMAScript proposal: the foo feature”. The stage of the proposal is mentioned at the beginning of the article. \n “ES.stage2: the foo feature” \n If a proposal is at stage 4, I’d be OK with calling it an ES20xx feature, but it’s safest to wait until the spec editor confirms what release it will be included in.   is an example of an ECMAScript proposal that had progressed until stage 2, but was ultimately withdrawn. Further reading   # The following were important sources of this blog post: \n The ecma262 (ECMA-262 is the ID of the ECMAScript standard) GitHub repository , which contains:\n \n A readme file with all proposals at stage 1 or higher \n A list of stage 0 proposals \n ECMA-262 frequently asked questions \n \n \n The TC39 process document \n Other things to read: \n \n Kangax’ ES7 compatibility table  shows what proposals are supported where and groups proposals by stage. \n \n \n More information on the ES6 design process: section “ How ECMAScript 6 was designed ” in “Exploring ES6” \n \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/06/for-of-ff13.html", "title": "ECMAScript.next: for-of, iterators, generators", "content": "ECMAScript.next: for-of, iterators, generators esnext dev javascript Iterables and iterators in ECMAScript 6 \nECMAScript.next’s   loop  will provide a new and quirk-free way of iterating over all kinds of data. This blog post explains how it works and how you can try out a prototype implementation in Firefox 13 and later.\n\n \n\n Iterating over data Iterating over arrays [1] Iterating over objects iterator proposal \n     : iterates over the names of all own (non-inherited) properties of  .\n     \n     : iterates over the values of all own properties of  .\n     \n     : iterates over all own properties, as   pairs.\n     \n\n     : iterates over the names of   properties of   (including inherited ones).\n     \n     : iterates over the values of   properties of  .\n     \n     : iterates over   properties, as   pairs.\n     \n Iterators iterators Generators generators Related reading Iterating over arrays and objects in JavaScript Bug 699565 – Implement Harmony for-of loops for...of - MDN comments powered by Disqus."},
{"url": "https://2ality.com/2012/06/underscore-templates.html", "title": "A closer look at Underscore templates", "content": "A closer look at Underscore templates underscorejs dev javascript jslang Underscore.js simple templating Preliminaries [1] Working with Underscore templates Inserting data \n     \n        Insert the result of an expression. The properties of the data object are all available as variables (see property  , above). No escaping happens, values are inserted verbatim.\n     \n     \n        Insert the result of an expression, but escape the following characters via  :\n \n        Example:\n \n     \n     \n        Evaluate the given code. This allows you to do loops and conditions (see next section).\n     \n Loops and conditions Printing content Referring to the data object Passing meta-data to a template Changing the syntax Pre-compilation The internals Style Mustache Conclusion Related Trying out Underscore on Node.js comments powered by Disqus."},
{"url": "https://2ality.com/2012/06/fluent-conference.html", "title": "Notes from the Fluent JavaScript conference", "content": "Notes from the Fluent JavaScript conference fluentconf dev javascript Conferences: JSConf and Fluent The audience Keynotes on YouTube \n     “ JavaScript at 17 ”: JavaScript creator Brendan Eich briefly went over the history of JavaScript, dispelled a few myths (for example: JavaScript parsers are faster than the Java bytecode verifier, so speed isn’t always an argument in favor of bytecode), and presented new projects such as the Sauerbraten game engine. He also showed the JavaScript part of the lightning talk “Wat” (whose  video  went viral in the JavaScript community a while ago). Thankfully, he didn’t explain it, which I had planned for my talk (see below).\n     \n     “ wtf.js: JavaScript as a First Language ”: Codecademy’s Ryan Bubinsky talked about the challenges of teaching people how to program via an online JavaScript course. The biggest challenge for beginners is to get started. Thus, it is important to get them hooked with something before diving into the (often boring) specifics. Another challenge are JavaScript’s cryptic error messages. The Codecademy talk “ FooLang.js ” describes how they solved this problem, by writing an interpreter for JavaScript (and other languages!) in JavaScript. The corresponding project is online at  repl.it .\n     \n     “ Enyo: A Truly Cross-platform JavaScript App Framework ”:  Enyo  was massively promoted at Fluent which makes me hopeful for its future. Well worth checking out.\n     \n     “ Don't Feed The Trolls ”: Nicole Sullivan talked about how to to best handle trolls (negative people on mailing lists etc.). Quote: “Some people are energized by conflict. If you aren’t, you’ll always lose.” It was nice to hear a meta-topic. I always find the psychology of software development interesting.\n     \n     “ Federated Wiki Mashes Data in Your Browser ”: Ward Cunningham was introduced as having created something that made it into the Oxford Dictionary (he is the inventor of the wiki). He talked about his newest project, the “ Smallest Federated Wiki ”. Quoting the website: “Our new wiki innovates three ways. It shares through federation, composes by refactoring and wraps data with visualization.”\n     \n     “ Your Script Just Killed My Site ”: Google’s Steve Souders talked about the challenges of integrating third party scripts into your website. He gives the example of Twitter support being loaded via a synchronous script tag. If the site is blocked, it can take up to 20 seconds until loading times out. One location where Twitter is blocked is in China, which meant that the corresponding website loaded very slowly there. The solutions are to load asynchronously or, at least, to put script tags after the content (e.g. directly before the </body> tag) so that the content is already shown while loading times out. Souders recommended  webpagetest.org  as a tool for performance-testing your website.\n     \n     Tim O’Reilly  mentioned  that his company supported JavaScript early on, even when most people still thought it was a toy language (arguably that is still the case). O’Reilly’s first JavaScript book came out in 1996 (David Flanagan’s “JavaScript: The Definitive Guide”), truly a long time ago.\n     \n     “ Javascript Development Workflow of 2013 ” by Paul Irish. Great overview of tools and techniques.\n     \n     “ Improving JavaScript ” [ slides ]: I talked about the difficulties of evolving a web language, JavaScript quirks and how ECMAScript 5 and ECMAScript.next fix them.\n     \n     “ Bookmarklets as Applications ”. Gary Flake talked about the challenges of implementing the technology behind his startup  Clipboard . It was recently  mentioned  on Hacker News (read for technical background). Clipboard lets you archive parts of a web page. I can see myself using it to store schedules etc.\n     \n     “ Turning to the Client Side ”. Lea Verou talked about moving more stuff from the server to the client. I’m glad this is happening, I much prefer client-side functionality to server-side functionality (where possible). The talk also included a social experiment: How do people react to a picture of a scantily clad man (as opposed to a woman in a bikini)? Quoting a tweet of hers: “I disagree with the whole idea that it [showing semi-nude people in presentations] is inappropriate. I just think it needs to be done to men too, equally.”\n     \n     “ Web vs. Apps ”: Ben Galbraith and Dion Almaer argued that it is increasingly difficult to define what actually distinguishes the two. When doing so, one must keep two aspects separate: The web as a delivery platform versus the web as a technology platform. For example, you can use HTML5 to write your app (web as technology platform), while deploying it via the iOS app store (native app as a delivery platform).\n     \n Talks \n     Peter Cooper talked about “ JavaScript Jumble ”. Among other things, Peter publishes the informative email newsletter  JavaScript Weekly  (you are probably already subscribing to it; if not, you should). He mentioned that while email might seem anachronistic, it has proven to be a very effective format for him (he has experience with other formats such as RSS), especially for advertising. At the moment, JavaScript weekly has over 26000 subscribers. \n     I went to Nicholas Zakas’ talk on “ Maintainable JavaScript ”. His book by the same name is a good collection of JavaScript best practices. His precision stands out in a world where there is too much sloppy and half-true information on JavaScript.\n     \n     Another smart guy is Ariya Hidayat, who talked about “ JavaScript Parser Infrastructure for Code Quality Analysis ”. His parser  Esprima  is an invaluable tool in the JavaScript world: It is fast, well documented and (as far as I am aware of) the only parser that keeps comments. That latter feature is essential for many generation tasks. Furthermore, Esprima allows you to parse source code, transform it and then write it to disk, while preserving whitespace and comments.\n     \n     My talk was about “Fake Operator Overloading” [ slides ]. In addition to the technique of fake overloading, it covered how JavaScript converts values to primitives, how the plus operator works and the reasons for the WAT results.\n     \n Related material Fluent 2012 @rauschma @fluentconf \nRelated 2ality blog posts:\n \n     More ideas for handling trolls: “ The art of giving and taking criticism ”.\n     \n     My keynote was based on the blog post “ Major and minor JavaScript pitfalls and ECMAScript 6 ”, but was updated with new information on arrow functions. \n     My talk was based on two blog posts:\n         \n             Fake operator overloading in JavaScript \n             What is {} + {} in JavaScript? \n         \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/04/declaring-module-exports.html", "title": "Declaring module exports (Node.js, AMD)", "content": "Declaring module exports (Node.js, AMD) dev nodejs javascript jsmodules clientjs jslang [1] Node.js versus AMD Patterns for declaring exports Pattern: fill object literal \n     Pro: Compact syntax. \n     Cons: You need to prefix “ ” to refer to exported values. Internal and exported values are separate; you cannot, e.g., put helper functions close to where they are used.\n     \n Pattern: set properties \n     Pro: You can freely mix internal and exported values. \n     Con: You need to prefix “ ” to refer to other exported values. \n Pattern: refer to exports in an object literal \n     Pro: Can refer to exported and internal values in the same manner. \n     Con: Redundant mention of exported identifiers (three times, in two different locations!). \n Pattern: set local variables and properties \n     Pro: Can refer to exported and internal values in the same manner. \n     Con: Some redundancy, but not as bad is in pattern #3. \n ECMAScript.next ECMAScript.next modules Conclusion References Bridging the module gap between Node.js and browsers comments powered by Disqus."},
{"url": "https://2ality.com/2012/06/continuation-passing-style.html", "title": "Asynchronous programming and continuation-passing style in JavaScript", "content": "Asynchronous programming and continuation-passing style in JavaScript async dev javascript advancedjs jslang Asynchronous programming and callbacks Converting to continuation-passing style Sequences of function invocations [1] Iterating over an array Mapping an array Iterating over a tree Pitfall: Execution continues after passing a result CPS and control flow \n  You call a function and it must return to you, it can’t escape the nesting that happens with function calls. The following code contains two such calls:   calls   which calls  .\n \n \n  A function determines where to go next. It can decide to continue “as ordered” or to do something completely different. The following code is the CPS version of the previous example.\n \n Return try-catch Generator [2] CPS and the stack Tail calls Trampolining The event queue and trampolining Conclusion Related reading JavaScript variable scoping and its pitfalls Trying out ECMAScript.next’s for...of loop in Firefox 13 comments powered by Disqus."},
{"url": "https://2ality.com/2012/06/dense-arrays.html", "title": "JavaScript: sparse arrays vs. dense arrays", "content": "JavaScript: sparse arrays vs. dense arrays underscorejs dev javascript jslang jsarrays Sparse arrays Dense arrays mentioned One more trick Useful in practice? Related posts Iterating over arrays and objects in JavaScript Trying out Underscore on Node.js comments powered by Disqus."},
{"url": "https://2ality.com/2012/06/servo-news.html", "title": "Mozilla’s next-generation web browser Servo is making progress", "content": "Mozilla’s next-generation web browser Servo is making progress browser computers servo mozilla [1] thread \nWe have a GitHub repository here:  github.com/mozilla/servo \n \nCurrently what we have builds on Mac and Linux. There's no fundamental reason why it won't work on Windows, but none of us have put in the effort necessary to bring it up. The sole platform (\"widget\" backend in Gecko terminology) is SDL, but there's an in-process planned move to GLUT [...] Neither of these backends are intended to be long-term solutions; for production we will want true platform-native backends for each platform.\n ... \nWhere possible, we reuse existing C and C++ libraries. This doesn't preclude the possibility of rewriting the functionality provided by these libraries in safe and parallel Rust code, but it helps us get off the ground. At the moment, these libraries are:\n \n     HarfBuzz (and its dependency Ragel), for text shaping. \n     Azure, for 2D graphics. \n     SDL (soon to be replaced with GLUT), as an abstraction layer over the native windowing system. \n     stb_image, for image decoding. This is a very simple image library, likely insecure and missing support for progressive JPEG, but it's extremely small and simple, devoid of dependencies, and in the public domain. \n     SpiderMonkey, for JavaScript support. \n     libuv, for networking. This is a library closely associated with node.js, which abstracts over the asynchronous I/O mechanisms on each platform. Most notably, it works on Windows, unlike nearly all of the alternatives. \n Servo: a vision for the future of Firefox comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/large-integers.html", "title": "Working with large integers in JavaScript", "content": "Working with large integers in JavaScript numbers dev javascript jsint jslang JavaScript only supports 53 bit integers [1] Example: Twitter JSON data Working with large integers in JavaScript strint Working with signs Comparisons \n     (positive, positive): Compare as explained above.\n     \n     (positive, negative): The first operand is greater than the second operand.\n     \n     (negative, positive): The second operand is greater than the first operand.\n     \n     (negative, negative): Compute the absolute values of the operands, compare them (as positive numbers), return the boolean negation of the result.\n     \n Addition and subtraction \n     Positive addition: both operands are positive \n     Positive subtraction: The first operator (minuend) is greater than the second operator (subtrahend) \n \n     (positive, positive): add the operands, as explained above.\n     \n     (negative, negative): add the absolute values of both operands, negate the result.\n     \n     (positive, negative): Subtract the absolute value of the smaller operand from the absolute value of the larger operand. Invert the sign if the larger operand is negative.\n     \n     (negative, positive): Handle the same as (positive, negative).\n     \n Multiplication Single-digit multiplication General multiplication For example Division Is  ? Then we are done,   is the remainder,   is the result.\n     Is   less or equal to the digits that start above it and continue until the leftmost digit of  ? Then subtract   from the digits above it as often as you can. Increment   by one for each subtraction. Continue with step 1.\n     Otherwise, perform a “shift”: Move   one digit to the right, multiply   by 10. Continue with step 2.\n     Using the strint library \n     : is x < y (“less than”)? \n     : is x ≤ y (“less or equal”)? \n     : is x > y (“greater than”)? \n     : is x ≥ y (“greater or equal”)? \n     : is x = y (“equals”)? \n     \n     \n     \n     \n     \n     \n     \n     \n References series on numbers How numbers are encoded in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/text-message-lengths.html", "title": "Text message lengths", "content": "Text message lengths psychology computers The advantages of a maximum message length Blaise Pascal Text messaging technologies Short Message Service (SMS): 160 characters control tasks Twitter: 140 characters \n     How Twitter Was Born Shortmail: 500 characters Shortmail What are good character limits? SMS message length \n    For one, they found that postcards often contained fewer than 150 characters.\n     \n    Second, they analyzed a set of messages sent through Telex, a then-prevalent telegraphy network for business professionals. Despite not having a technical limitation, Hillebrand said, Telex transmissions were usually about the same length as postcards. \n     \n    Just look at your average e-mail today, he noted. Many can be summed up in the subject line, and the rest often contains just a line or two of text asking for a favor or updating about a particular project.\n     \n     Why text messages are limited to 160 characters Tweet length Email message length Shortmail FAQ Plain Paragraph Length comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/amdefine.html", "title": "amdefine: use AMD modules on Node.js", "content": "amdefine: use AMD modules on Node.js dev nodejs javascript amdefine jsmodules clientjs jslang amdefine [1] \n     Install amdefine:\n \n        Optional: install into your project by making it a dependency in your package.json.\n     \n     Prefix your AMD with the following line (split into three lines below):\n \n        That line will be removed when packaging your AMDs for deployment via the  RequireJS optimizer .\n     \n readme \nIf you don’t want to force Node.js users of your module to install amdefine, there are alternatives  [2]  for writing AMDs that also work on Node.js. But they have other disadvantages.\n \n \n The power of the Asynchronous Module Definition Bridging the module gap between Node.js and browsers comments powered by Disqus."},
{"url": "https://2ality.com/2015/09/holes-arrays-es6.html", "title": "ECMAScript 6: holes in Arrays", "content": "ECMAScript 6: holes in Arrays esnext dev javascript This blog post describes how ECMAScript 6 handles holes in Arrays. Holes in Arrays   # Holes are indices “inside” an Array that have no associated element. In other words: An Array   is said to have a hole at index   if: \n 0 ≤   <  \n \n For example: The following Array has a hole at index 1. For more information, consult Sect. “ Holes in Arrays ” in “Speaking JavaScript”. ECMAScript 6: holes are treated like   elements   # The general rule for Array methods that are new in ES6 is: each hole is treated as if it were the element  . Examples: The idea is to steer people away from holes and to simplify long-term. Unfortunately that means that things are even more inconsistent now. Array operations and holes   #    #  converts holes to  : With a second argument, it works mostly like  , but does not ignore holes: Spread operator ( )   # Inside Arrays, the spread operator ( ) works much like   (but its operand must be iterable, whereas   can handle anything that’s Array-like).  methods   # In ECMAScript 5, behavior already varied slightly. For example: \n ,  ,   and   ignore holes. \n  skips but preserves holes. \n  and   treat holes as if they were   elements, but interprets both   and   as empty strings. \n ECMAScript 6 adds new kinds of behaviors: \n  creates holes when copying holes (i.e., it deletes elements if necessary). \n ,  ,   treat each hole as if it was the element  . \n  and   do the same. \n  doesn’t care whether there are elements at indices or not. \n The following table describes how   methods handle holes. Notes: \n ES6 methods have checkmarks (✓). \n JavaScript ignores a trailing comma in an Array literal:  \n Helper function used in the table:  \n Recommendations   # With regard to holes in Arrays, the only rule is now that there are no rules. Therefore, you should avoid holes if you can (they affect performance negatively, too). If you can’t then the table in the previous section may help. Further reading   # \n ECMAScript 5: Chapter “ Arrays ” in “Speaking JavaScript” \n ECMAScript 6: Chapter “ New Array features ” in “Exploring ES6” \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/concatenating-typed-arrays.html", "title": "Concatenating Typed Arrays", "content": "Concatenating Typed Arrays esnext dev javascript Typed Arrays  don’t have a method  , like Arrays do. The work-around is to use the method That method copies an existing Typed Array (or normal Array) into   at index  . Then you only have to make sure that   is big enough to hold all (Typed) Arrays you want to concatenate: comments powered by Disqus."},
{"url": "https://2ality.com/2015/09/proto-es6.html", "title": "__proto__  in ECMAScript 6", "content": " in ECMAScript 6 esnext dev javascript __proto__ The property   (pronounced “ dunder proto ”) has existed for a while in most JavaScript engines. This blog post explains how it worked prior to ECMAScript 6 and what changes with ECMAScript 6. For this blog post, it helps if you know what prototype chains are. Consult Sect. “ Layer 2: The Prototype Relationship Between Objects ” in “Speaking JavaScript”, if necessary.  prior to ECMAScript 6   # Prototypes   # Each object in JavaScript starts a chain of one or more objects, a so-called  . Each object points to its successor, its   via the internal property   (which is   if there is no successor). That property is called  , because it only exists in the language specification and cannot be directly accessed from JavaScript. In ECMAScript 5, the standard way of getting the prototype   of an object   is: There is no standard way to change the prototype of an existing object, but you can create a new object   that has the given prototype  :    # A long time ago, Firefox got the non-standard property  . Other browsers eventually copied that feature, due to its popularity. Prior to ECMAScript 6,   worked in obscure ways: \n \n You could use it to get or set the prototype of any object: \n \n \n \n However, it was never an actual property: \n \n \n Subclassing   via     # The main reason why   became popular was because it enabled the only way to create a subclass   of   in ES5: Array instances were exotic objects that couldn’t be created by ordinary constructors. Therefore, the following trick was used: Subclassing in ES6  works differently than in ES5 and supports subclassing builtins out of the box. Why   is problematic in ES5   # The main problem is that   mixes two levels: the object level (normal properties, holding data) and the meta level. If you accidentally use   as a normal property (object level!), to store data, you get into trouble, because the two levels clash. The situation is compounded by the fact that you have to abuse objects as maps in ES5, because it has no built-in data structure for that purpose. Maps should be able to hold arbitrary keys, but you can’t use the key   with objects-as-maps. In theory, one could fix the problem by using a symbol instead of the special name  , but keeping meta-operations completely separate (as done via  ) is the best approach. The two kinds of   in ECMAScript 6   # Because   was so widely supported, it was decided that its behavior should be standardized for ECMAScript 6. However, due to its problematic nature, it was added as a deprecated feature. These features reside in  Annex B in the ECMAScript specification , which is described as follows: The ECMAScript language syntax and semantics defined in this annex are required when the ECMAScript host is a web browser. The content of this annex is normative but optional if the ECMAScript host is not a web browser. JavaScript has several undesirable features that are required by a significant amount of code on the web. Therefore, web browsers must implement them, but other JavaScript engines don’t have to. In order to explain the magic behind  , two mechanisms were introduced in ES6: \n A getter and a setter implemented via  . \n In an object literal, you can consider the property key   a special operator for specifying the prototype of the created objects. \n    # ECMAScript 6 enables getting and setting the property   via a getter and a setter stored in  . If you were to implement them manually, this is roughly what it would look like: The getter and the setter for   in the ES6 spec: \n \n \n The property key   as an operator in an object literal   # If   appears as an unquoted or quoted property key in an object literal, the prototype of the object created by that literal is set to the property value: Using the string value   as a computed property key does not change the prototype, it creates an own property: The special property key   in the ES6 spec: \n  Property Names in Object Initializers \n Avoiding the magic of     # Define, don’t assign   # Remember that there are two ways to create own properties.  Use the assignment operator for a property that is not yet an own property: In three cases, no own property   is created, even if it doesn’t exist, yet: A read-only property   exists in the prototype chain. Then the assignment causes a   in strict mode. A setter exists in the prototype chain. Then that setter is called. A getter without a setter exists in the prototype chain. Then a   is thrown in strict mode. This case is similar to the first one.  Use   and   to always create a new own property if it doesn’t exist yet. None of the three scenarios listed for assignment prevent that. For more information, consult section “ Properties: Definition Versus Assignment ” in “Speaking JavaScript”. # In ECMAScript 6, if you define (not assign) the own property  , no special functionality is triggered and the getter/setter   is overridden: Objects that don’t have   as a prototype   # The   getter/setter is provided via  . Therefore, an object without   in its prototype chain doesn’t have the getter/setter, either. In the following code,   is an example of such an object – it does not have a prototype. As a result,   now works like any other property:  and dict objects   # If you want to use an object as a dictionary then it is best if it doesn’t have a prototype. That’s why prototype-less objects are also called  . In ES6, you don’t even have to escape the property key   for dict objects, because it doesn’t trigger any special functionality.  as an operator in an object literal lets you create dict objects more concisely: Note that in ES6, you should normally prefer  the built-in data structure   to dict objects, especially if keys are not fixed.  and JSON   # Prior to ES6, the following could happen in a JavaScript engine: With   being a getter/setter in ES6,   works fine, because it defines properties, it doesn’t assign them (if implemented properly,  an older version of V8 did assign ).  isn’t affected by  , either, because it only considers own properties. Objects that have an own property whose name is   work fine: Detecting support for ES6-style     # Support for ES6-style   varies from engine to engine. Consult kangax’ ECMAScript 6 compatibility table for information on the status quo: \n \n  in object literals \n The following two sections describe how you can programmatically detect whether an engine supports either of the two kinds of  . Feature:   as getter/setter   # A simple check for the getter/setter: A more sophisticated check: Feature:   as an operator in an object literal   # You can use the following check: Recommendations for     # It is nice how well ES6 turns   from something obscure into something that is easy to understand. However, I still recommend not to use it. It is effectively a deprecated feature and not part of the core standard. You can’t rely on it being there for code that should run on all engines. More recommendations: \n Use   to get the prototype of an object. \n Use   to create a new object with a given prototype. Avoid  . If you change the prototype of an existing object, it can become slower. \n I actually like   as an operator in an object literal. It is useful for demonstrating prototypal inheritance and for creating dict objects. However, the previously mentioned caveats do apply. \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/09/well-known-symbols-es6.html", "title": "Customizing ES6 via well-known symbols", "content": "Customizing ES6 via well-known symbols esnext dev javascript In ECMAScript 6, the object   has several properties that contain so-called   ( ,  , etc.). These let you customize how ES6 treats objects. This blog post explains the details. Warning   # Implementation of the features described here is work in progress. Consult the “ ECMAScript 6 compatibility table ” for what is supported where (spoiler: not much, in few engines). Background   # This section covers knowledge that is useful for the remainder of this post. Additionally, the following material may be of interest: \n Chapter “ Symbols ” in “Exploring ES6” \n Chapter “ Values ” (primitive values versus objects, etc.) in “Speaking JavaScript” \n Internal properties   # The ES6 specification uses   to describe how JavaScript works. These are only known to the spec and not accessible from JavaScript. They may or may not exist in an actual implementation of the language. The names of internal properties are written in double square brackets. For example: the link between an object and its prototype is the internal property  . The value of that property cannot be read directly via JavaScript, but you can use   to do so. Overriding inherited properties   # If an object   inherits a property   that is read-only then you can’t assign to that property: This is similar to how an inherited property works that has a getter, but no setter. It is in line with viewing assignment as changing the value of an inherited property. It does so non-destructively: the original is not modified, but overridden by a newly created own property. Therefore, an inherited read-only property and an inherited setter-less property both prevent changes via assignment. You can, however, force the creation of an own property via  : Overview: all well-known symbols in ES6   # All well-known symbols in ES6 are keys for properties. If you add a property to an object that has one of those keys, you change how ES6 treats that object. These are all well-known symbols in ES6: Customizing basic language operations:\n \n  (method) \ncustomizes  . \n  (method) \ncustomizes the coercion of an object to a primitive value. \n  (string) \ncustomizes the result returned by  . \n \n Iteration:\n \n  (method) \nA method with this key makes an object   (its elements can be iterated over language constructs such as the   loop and the spread operator ( )). Details: chapter “ Iterables and iterators ” of “Exploring ES6”. \n \n Forwarding calls from string methods to their parameters:\n \n \n \n \n \n \n Miscellaneous:\n \n  (Object) \nlets you hide some properties from the   statement. \n  (method) \nconfigures how built-in methods create objects that are similar to  . \n  (boolean) \nconfigures whether   adds the indexed elements of an object to its result (“spreading”) or the object as a single element. \n \n The following sections have more information on categories 1, 3 and 4. Customizing basic language operations   #  (method)   # A method with the key   lets an object   customize the behavior of the   operator. Signature of that method:  works as follows in ES6: \n If   is not an object, throw a  . \n If the method exists, call  , coerce the result to boolean and return it. \n Otherwise, compute and return the result according to the traditional algorithm (  must be callable,   in the prototype chain of  , etc.). \n # The only method in the standard library that has this key is: \n \n This is the implementation of   that all functions (including classes) use by default.  Quoting the spec : This property is non-writable and non-configurable to prevent tampering that could be used to globally expose the target function of a bound function. The tampering is possible because the traditional   algorithm,  , applies   to the target function if it encounters a bound function. Given that this property is read-only, you can’t use assignment to override it, as mentioned earlier. # As an example, let’s implement an object   whose “instances” are all objects, not just objects that are instances of   (and therefore have   in their prototype chains).  (method)   #  lets an object customize how it is   (converted automatically) to a primitive value. Many JavaScript operations coerce values to the types that they need. \n The multiplication operator ( ) coerces its operands to numbers. \n  coerces its parameters to numbers. \n  coerces its first parameter to a string. \n The following are the most common coercions: \n Boolean: Coercion returns   for truthy values,   for falsy values. Objects are always truthy (even  ). \n Number: Coercion converts objects to primitives first. Primitives are then converted to numbers (  →  ,   →  ,   →  , etc.). \n String: Coercion converts objects to primitives first. Primitives are then converted to strings (  →  ,   →  ,   →  , etc.). \n Object: The coercion   primitive values (booleans   via  , numbers   via  , etc.). \n Converting an arbitrary value to a primitive is handled via the spec-internal operation   which has three modes: \n Number: the caller needs a number. \n String: the caller needs a string. \n Default: the caller needs either a number or a string. \n The default mode is only used by: \n Equality operator ( ) \n Addition operator ( ) \n  (exactly one parameter!) \n If the value is a primitive then   is already done. Otherwise, the value is an object  , which is converted to a promitive as follows: \n Number mode: Return the result of   if it is primitive. Otherwise, return the result of   if it is primitive. Otherwise, throw a  . \n String mode: works like Number mode, but   is called first,   second. \n Default mode: works exactly like Number mode. \n This normal algorithm can be overridden by giving an object a method with the following signature: In the standard library, there are two such methods: \n \n \nprevents   from being called (which throws an exception). \n \n \n \nThis method implements behavior that deviates from the default algorithm. Quoting the specification: “Date objects are unique among built-in ECMAScript object in that they treat   as being equivalent to  . All other built-in ECMAScript objects treat   as being equivalent to  .” \n \n # The following code demonstrates how coercion affects the object  .  (string)   # In ES5 and earlier, each object had the internal own property   whose value hinted at its type. You could not access it directly, but its value was part of the string returned by  , which is why that method was used for type checks, as an alternative to  . In ES6, there is no internal property  , anymore, and using   for type checks is discouraged. In order to ensure the backwards-compatibility of that method, the public property with the key   was introduced. You could say that it replaces  .  now works as follows: \n Convert   to an object  . \n Determine the     of  . \n Return  . \n # The default values for various kinds of objects are shown in the following table. Most of the checks in the left column are performed by looking at internal properties. For example, if an object has the internal property  , it is callable. The following interaction demonstrates the default toString tags. # If an object has an (own or inherited) property whose key is   then its value overrides the default toString tag. For example: Instances of user-defined classes get the default toString tag (of objects): One option for overriding the default is via a getter: In the JavaScript standard library, there are the following custom toString tags. Objects that have no global names are quoted with percent symbols (for example:  ). \n Module-like objects:\n \n  →  \n  →  \n \n \n Actual module objects  :   →  \n Built-in classes\n \n  →  \n  →  \n  →  \n  →  \n  →  \n  →   etc. \n  →  \n  →  \n \n \n Iterators\n \n  →  \n  →  \n  →  \n \n \n Miscellaneous\n \n  →  \n  →  \n  →  \n \n \n All of the built-in properties whose keys are   have the following property descriptor: As mentioned in an earlier section, you can’t use assignment to override those properties, because they are read-only. Forwarding calls from string methods to their parameters   # In ES6, the four string methods that accept regular expression parameters do relatively little. They mainly call methods of their parameters: \n  calls  . \n  calls  . \n  calls  . \n  calls  . \n The parameters don’t have to be regular expressions, anymore. Any objects with appropriate methods will do. Miscellaneous   #  (Object)   #  lets an object hide some properties from the   statement. The reason for doing so is that it allows TC39 to add new methods to   without breaking old code. Note that current code rarely uses  , which is forbidden in strict mode and therefore ES6 modules (which are implicitly in strict mode). Why would adding methods to   break code that uses   (such as the widely deployed  Ext JS 4.2.1 )? Take a look at the following code. The existence of a property   breaks  , if you call it with an Array: Inside the   statement, all properties of   become local variables, shadowing even   itself. Therefore, if   has a property   then the statement in line * logs   and not  .  is used only once in the standard library: \n \n \n Holds an object with the following properties (which are therefore hidden from the   statement):  ,  ,  ,  ,  ,  ,  \n \n \n  (method)   #  lets you configure how methods of built-in objects create instances they return. One example is that you can configure what   returns. By default, it uses the same constructor that created   to create the return value, but you can override that by setting  . The details are explained in  the chapter on classes  of “Exploring ES6”.  (boolean)   #  lets you configure how   adds an object to its result. The default for Arrays is to “spread” them, their indexed elements become elements of the result: With  , you can override the default and avoid spreading for Arrays: For non-Arrays, the default is not to spread. You can use   to force spreading: The default in ES6 is to spread only Array objects. Whether or not something is an Array object is tested via   (or rather, the same operation that that method uses). Whether or not   is in the prototype chain makes no difference for that test (which is important, because, in ES5 and earlier, hacks were used to subclass   and those must continue to work; see blog post “  in ECMAScript 6 ”): The default can be overridden by adding a property whose key is   to the object itself or to one of its prototypes, and by setting it to either   or  . No object in the ES6 standard library has a property with the key  . This mechanism therefore exists purely for browser APIs and user code. Consequences: \n \n Subclasses of   are spread by default (because their instances are Array objects). \n \n \n A subclass of   can prevent its instances from being spread by setting a property to   whose key is  . That property can be a prototype property or an instance property. \n \n \n Other Array-like objects are spread by   if property   is  . That would enable one, for example, to turn on spreading for some Array-like DOM collections. \n \n \n Typed Arrays are not spread. They don’t have a method  , either. \n \n # \n In  the description of  , you can see that spreading requires an object to be Array-like (property   plus indexed elements). \n Whether or not to spread an object is determined via  the spec operation  . The last step is the default (equivalent to  ) and the property   is retrieved via a normal   operation, meaning that it doesn’t matter whether it is own or inherited. \n Spelling: Why   and not   (etc.)?   # The well-known symbols are stored in properties whose names start with lowercase characters and are camel-cased. In a way, these properties are constants and it is customary for constants to have all-caps names (  etc.). But the reasoning for their spelling is different: Well-known symbols are used instead of normal property keys, which is why their “names” follow the rules for property keys, not the rules for constants. comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/enumerability-es6.html", "title": "Enumerability in ECMAScript 6", "content": "Enumerability in ECMAScript 6 esnext dev javascript Enumerability is an   of object properties. This blog post explains how it works in ECMAScript 6. Let’s first explore what attributes are. Property attributes   # Each object has zero or more  . Each property has a key and three or more  , named slots that store the data of the property (in other words, a property is itself much like a JavaScript object or a record with fields in a database). ECMAScript 6 supports the following attributes (as does ES5): \n All properties have the attributes:\n \n : Setting this attribute to   hides the property from some operations. \n : Setting this attribute to   prevents several changes to a property (attributes except   can’t be change, property can’t be deleted, etc.). \n \n \n Normal properties (data properties, methods) have the attributes:\n \n : holds the value of the property. \n : controls whether the property’s value can be changed. \n \n \n Accessors (getters/setters) have the attributes:\n \n : holds the getter (a function). \n : holds the setter (a function). \n \n \n You can retrieve the attributes of a property via  , which returns the attributes as a JavaScript object: This blog post explains how the attribute   works in ES6. All other attributes and how to change attributes is explained in Sect. “ Property Attributes and Property Descriptors ” in “Speaking JavaScript”. Constructs affected by enumerability   # ECMAScript 5: \n  loop: iterates over the string keys of own and inherited enumerable properties. \n : returns the string keys of enumerable own properties. \n : only stringifies enumerable own properties with string keys. \n ECMAScript 6: \n : only copies enumerable own properties (both string keys and symbol keys are considered). \n : returns all property names that   iterates over. \n  and   are the only built-in operations where enumerability matters for inherited properties. All other operations only work with own properties. Use cases for enumerability   # Unfortunately, enumerability is quite an idiosyncratic feature. This section presents several use cases for it and argues that, apart from protecting legacy code from breaking, its usefulness is limited. Use case: Hiding properties from the   loop   # The   loop iterates over   enumerable properties of an object, own and inherited ones. Therefore, the attribute   is used to hide properties that should not be iterated over. That was the reason for introducing enumerability in ECMAScript 1. # Non-enumerable properties occur in the following locations in the language: \n \n All   properties of built-in classes are non-enumerable: \n \n \n \n All   properties of classes are non-enumerable: \n \n \n \n In Arrays,   is not enumerable, which means that   only iterates over indices. (However, that can easily change if you add a property via assignment, which is makes it enumerable.) \n \n \n The main reason for making all of these properties non-enumerable is to hide them (especially the inherited ones) from legacy code that uses the   loop or   (and similar operations that copy both inherited and own properties; see next section). Both operations should be avoided in ES6. Hiding them ensures that the legacy code doesn’t break. Use case: Marking properties as not to be copied   # # When it comes to copying properties, there are two important historical precedents that take enumerability into consideration: \n \n Prototype’s  \n \n \n \n jQuery’s   copies all enumerable own and inherited properties of   etc. into own properties of  . \n \n \n Problems with this way of copying properties: \n \n Turning inherited source properties into own target properties is rarely what you want. That’s why enumerability is used to hide inherited properties. \n \n \n Which properties to copy and which not often depends on the task at hand, it rarely makes sense to have a single flag for everything. A better choice is to provide the copying operation with a   (a callback that returns a boolean) that tells it when to consider a property. \n \n The only instance property that is non-enumerable in the standard library is property   of Arrays. However, that property only needs to be hidden due to it magically updating itself via other properties. You can’t create that kind of magic property for your own objects (short of using a Proxy). # In ES6,   can be used to merge the sources into the target. All own enumerable properties of the sources are considered (that is, keys can be either strings or symbols).   uses: \n Reading a value from a source: normal “get” operation ( ). \n Writing a value to the target: normal “set” operation ( ). \n That means that both getters and setters are triggered (the former are not copied, the latter are not overridden with new properties). With regard to enumerability,   continues the tradition of   and  .  Quoting Yehuda Katz : Object.assign would pave the cowpath of all of the extend() APIs already in\ncirculation. We thought the precedent of not copying enumerable methods in\nthose cases was enough reason for Object.assign to have this behavior. In other words:   was created with an upgrade path from   (and similar) in mind. Its approach is cleaner than  ’s, because it ignores inherited properties. \nPrototype methods are non-enumerable. You therefore can’t use   to copy methods from one prototype to another one. You could use it to copy methods from an object literal (which are enumerable) to a prototype. However, then the copied methods wouldn’t have the right enumerability. Furthermore, a method that uses   has a property that points to the object that hosts it.   does not correctly update that property. Marking properties as private   # If you make a property non-enumerable, it can’t by seen by   and the   loop, anymore. With regard to those mechanisms, the property is private. However, there are several problems with this approach: \n When copying an object, you normally want to copy private properties. That clashes making properties non-enumerable that shouldn’t be copied (see previous section). \n The property isn’t really private. Getting, setting and several other mechanisms make no distinction between enumerable and non-enumerable properties. \n When working with code either as source or interactively, you can’t immediately see whether a property is enumerable or not. A naming convention (such as prefixing property names with an underscore) is easier to discover. \n You can’t use enumerability to distinguish between public and private methods, because methods in prototypes are non-enumerable by default. \n Hiding own properties from     #  does not include properties in its output that are non-enumerable. You can therefore use enumerability to determine which own properties should be exported to JSON. This use case is similar to marking properties as private, the previous use case. But it is also different, because this is more about exporting and slightly different considerations apply. For example: Can an object be completely reconstructed from JSON? An alternative for specifying how an object should be converted to JSON is to use  : I find   cleaner than enumerability for the current use case. It also gives you more control, because you can export properties that don’t exist on the object. Naming inconsistencies   # In general, a shorter name means that only enumerable properties are considered: \n  ignores non-enumerable properties \n  lists all property names \n However,   deviates from that rule, it ignores enumerability and returns the keys of all properties. Additionally, starting with ES6, the following distinction is made: \n  are either strings or symbols. \n  are only strings. \n Therefore, a better name for   would now be  . Looking ahead   # It seems to me that enumerability is only suited for hiding properties from the   loop and   (and similar operations). Both are legacy features, you should avoid them in new code. As for the other use cases: \n I don’t think there is a need for a general flag specifying whether or not to copy a property. \n Non-enumerability does not work well as a way to keep properties private. \n The   method is more powerful and explicit than enumerability when it comes to controlling how to convert an object to JSON. \n I’m not sure what the best strategy is for enumerability going forward. If, with ES6, we had started to pretend that it didn’t exist (except for making prototype properties non-enumerable so that old code doesn’t break), we might eventually have been able to deprecate enumerability. However,   considering enumerability runs counter that strategy (but it does so for a valid reason, backward compatibility). In my own ES6 code, I’m not using enumerability, except for classes whose   methods are non-enumerable. Lastly, when using an interactive command line, I occasionally miss an operation that returns   property keys of an object, not just the own ones ( ) or not just string-valued enumerable ones ( ). Such an operation would provide a nice overview of the contents of an object. Feel free to disagree with what I have written in this blog post and let us know in the comments below. My opinion about enumerability is still evolving, because it’s such a confusing feature. comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/methods-vs-callbacks-es6.html", "title": "ES6: methods versus callbacks", "content": "ES6: methods versus callbacks esnext dev javascript There is a subtle difference between an object with methods and an object with callbacks. An object whose properties are methods   # The   of a method is the   of the method call (e.g.   if the method call is  ). For example, you can use  the WHATWG streams API  as follows: That is,   is an object whose properties  ,   and   are methods. Accordingly, these methods can use   to access object-local state (line *) and to call each other (line **). An object whose properties are callbacks   # The   of an arrow function is the   of the surrounding scope ( ). Arrow functions make great callbacks, because that is the behavior you normally want for callbacks (real, non-method functions). A callback shouldn’t have its own   that shadows the   of the surrounding scope. If the properties  ,   and   are arrow functions then they pick up the   of   (their surrounding scope): If the output in line * surprises you then consider the following code: Inside method  ,   and   work the same, because both arrow functions have the same surrounding lexical scope,  . The latter arrow function being surrounded by an object literal does not change that. Further reading   # Chapter “ Callable entities in ECMAScript 6 ” in ”Exploring ES6”. comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/intercepting-method-calls.html", "title": "Intercepting method calls via ES6 Proxies", "content": "Intercepting method calls via ES6 Proxies esnext dev javascript js proxies   Tracing method calls via Proxies This blog post explains how to use ES6 Proxies to intercept method calls to an object. Read chapter “ Meta programming with proxies ” in “Exploring ES6” for more information on Proxies. The problem   # You can intercept the operation   (getting property values) via a proxy and you can intercept the operation   (calling a function), but there is no single operation for method calls that you could intercept. That’s because method calls are viewed as two separate operations: First a   to retrieve a function, then an   to call that function. The solution   # If you want to intercept method calls, you must therefore intercept   and return a function that intercepts the function call. The following code (which works in Firefox) demonstrates how that is done. I’m not using a Proxy for the latter task, I’m simply wrapping the original method with a function. Let’s use the following object to try out  :  is a traced version of  . The first line after each method call is the output of  , the second line is the result of the method call. The nice thing is that even the call   that is made inside   is traced. That’s because   keeps referring to the proxy. This is not a very efficient solution. One could, for example, cache methods. Furthermore, Proxies themselves have an impact on performance. comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/es6-feature-lists.html", "title": "A list of ES6 feature lists", "content": "A list of ES6 feature lists esnext dev javascript \n “ ECMAScript 6 Features ” by Luke Hoban \n “ Learn ES2015: a detailed overview of ECMAScript 6 features ” (Babel docs) \n “ ECMAScript 6 Cheatsheet ” by Erik Moeller \n “ First steps with ECMAScript 6 ” by Axel Rauschmayer \n Complementary and indispensable: “ ECMAScript 6 compatibility table ” by kangax. comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/google-analytics-api.html", "title": "Using the Google Analytics Core Reporting API from Node.js", "content": "Using the Google Analytics Core Reporting API from Node.js dev nodejs javascript static site generation This blog post explains how to use the   by Google from Node.js. Let’s use that API to create a Node.js script   that downloads the top 10 most visited pages of your website. Preparations   # You must first make sure that you can access the Google Analytics API from the script and that the appropriate library for doing so is installed. Unlocking the Google Analytics API   # Go to the  Google Developers Console : \n Create a new project (e.g.  ). \n In section “APIs & auth → Credentials”, execute “Add credentials → Service account”.\n \n Download the resulting JSON file (e.g. “ ”). \n Put that file into a directory   that is inside one of the parent directories of the script that we’ll create later. That means that you can keep it out of the repository with  . For example, the following path is perfectly fine: \n \n \n \n The credentials that you created have an email address (which is displayed in the user interface and stored inside the JSON file). Copy that email address. \n Go to the Admin panel in Google Analytics: \n Analytics has three scopes:\n \n Account \n Property \n View \n \n \n Create a new user in scope “Property”, via “User Management”.\n \n That user has the email address that you copied previously. \n Its permissions are “Read & Analyze”. \n \n \n In scope “View”, go to “View Settings” and write down the “View ID” (e.g. 97675673) for later. \n Installing the Google API client library   # \n Google provides many public APIs. You need the “Analytics Core Reporting API”. \n All APIs are accessed via the  Google API client library . You want  the one for Node.js , which can be installed via npm: \n \n The script   # The first line of the script enables us to execute the script directly on Unix systems (if it is executable): The code shown in this section is ECMAScript 6, which is why we run the script via  babel-node . You can also omit this first line and run the script like this: Next, we import the Google API client library. Next, we import the key and define the view ID (prefixed with  ): Next, we authenticate (consult “ Authorizing and Authenticating ” for more information): Finally, we make the query (for consistency’s sake, all keys are quoted): We retrieve the top 10 most visited pages within the last 30 days: \n : what was measured? \n : what meta-data are we interested in? \n Dates: we must provide both a start and an end date. If we want the earliest possible start date (minus infinity, if you will), we can use  . \n : comma-separated keys of either metrics or dimensions. \n : we filter the   via a regular expression, so that only files with specific names are shown in the results. The property value is an  ES6 tagged template , which is why we can use the backslash directly, without escaping it. \n More information on the Analytics Core Reporting API: \n A general overview of the Core Reporting API \n Documentation on the   (the keys in the object object handed to  ) \n Common queries , which demonstrate how to use the keys documented by the previous item. \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/js-and-non-programmers.html", "title": "Explaining to non-programmers what JavaScript is", "content": "Explaining to non-programmers what JavaScript is dev javascript computers Many more people are aware of Java than of JavaScript, often because they were asked to install Java at some point in time.\n     That’s not necessarily a good thing for Java, because it is frequently associated with negative things. JavaScript has become such an implicit part of the web that people aren’t even aware that it exists. What is JavaScript? [1] [2] \nA more tongue-in-cheek explanation (borrowing from  @starian ):\n Consequences? [3] [4] [5] References Branding web technologies and the new HTML5 logo The cloud and how it changes mobile computing logo.js – JavaScript has a (semi-)official logo The increasing pervasiveness of JavaScript – a few historic milestones ECMAScript: ES.next versus ES 6 versus ES Harmony comments powered by Disqus."},
{"url": "https://2ality.com/2015/10/modular-html-pages.html", "title": "Modular HTML pages", "content": "Modular HTML pages dev html static site generation Static site generation: minimizing how much is re-generated   # When statically generating HTML content, you face an interesting challenge: If the page frame (the “chrome” of a page) contains information that changes frequently, you need to re-generate all pages every time it does. One example of such information is a top 10 list of the pages that were most popular during the last 30 days. A work-around is to save the information in a separate file and to load that information dynamically via JavaScript. You then have a choice: You can save a JSON file and transform that into HTML or you can save an HTML file and insert it without processing it. Apart from having to re-generate fewer files, you also save traffic, because the shared information only needs to be downloaded once and will be cached, afterwards. Similar: HTTP/2 and JavaScript modules   # This situation is similar to JavaScript modules. Currently, many modules are bundled (combined) into a single file, to avoid the cost of one connection per file, imposed by HTTP/1. That means you have to re-generate all of the code, even if only a small module changes. However, things change with HTTP/2: You don’t need a new connection for each module, you can send multiple files over the same connection (if the server is aware of what needs to be done). Therefore, having many small modules doesn’t cost you, connection-wise, anymore.  Modular HTML pages?   # Coming back to HTML pages: What if there was a way to declaratively compose HTML pages? You’d get both small incremental updates and traffic savings, but without having to use JavaScript. As far as I can tell,  HTML Imports  do not help with this use case. comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/combine-editing-repl.html", "title": "Combining code editing with a command line", "content": "Combining code editing with a command line dev hci javascript \nCurrently, you are forced to work with JavaScript code in either of two modes: You can either use a code editor and edit multiple lines or you can use an interactive command line and work with one line at a time (editing, evaluating). With jsrepl [ GitHub project ,  live demo ], I have prototyped a combination of both modes – no need to chose, any more.\n \n \nThe name is derived from the abbreviation  REPL  (read-eval-print loop) that is a common synonym for “command line” in the functional world. Node.js uses that term, too  [1] .\n\n How does jsrepl work? Multi-line evaluation: select text and hit Shift-Return.\n     Single-line evaluation: place the cursor in the line you want to evaluate and hit Shift-Return. If the cursor is at the end of a line, a newline will inserted.\n     \nVar declarations and function declarations work, but I had to use hacks to make them work  [2] , so you might not always get the results you expect.\n\n Prior art Macintosh Programmer’s Workshop \n References Execute code each time the Node.js REPL starts Implementing a command line with eval in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/computer-girls.html", "title": "Programming: initially a female profession", "content": "Programming: initially a female profession society life computers Researcher reveals how ‘Computer Geeks’ replaced ‘Computer Girls’ comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/evaluator-via-eval.html", "title": "Implementing a command line with eval in JavaScript", "content": "Implementing a command line with eval in JavaScript eval dev javascript jslang Writing an evaluator [1] Problem: declarations \nStep 1 – declare: We assign   to   (1) and rewrite the input so that, among other things, each var declaration assigns to   (3). That demonstrates one important aspect of  : it sees all variables in surrounding scopes. That is, if you invoke   inside your function, you expose all of its internals. The only way to keep those internals secret is to put the eval call in a separate function and call that function.\n \nStep 2 – access: Use a   statement so that the properties of   appear as variables to the eval-ed code. This is not an ideal solution, more of a compromise:   should be avoided  [2]  and can’t be used in the advantageous strict mode  [3] . But it is a quick solution for us now. A work-around is quite complex  [4] .\n Problem: exceptions Problem: console.log Problem: eval creates bindings inside the function [4] Keeping declarations in an environment \n     Non-strict mode: the environment of the surrounding function. \n     Strict mode: a newly created environment. \n Declarations via nested scopes \nThat gives us a strategy for keeping the environment of the function that calls   around. In the following code that function is called   and creates a new function that has to be used for the next call of  . Hence, declarations made in the former function are accessible in the later function.\n Declarations via a generator [5] \nCurrent versions of Firefox already support generators. Here is a demonstration of how they work in these versions (in ECMAScript.next, you will have to write  , but apart from that, the code is the same):\n Conclusion \nThe best solution for remembering declarations would be for   to have an optional parameter for an environment (to be reused), but that is not in the cards. Therefore, the only truly safe solution in pure JavaScript is to use a full-featured JavaScript parser such as  esprima  to rewrite critical parts of the input code. That is left as an exercise to the reader.\n\n References Combining code editing with a command line JavaScript’s with statement and why it’s deprecated JavaScript’s strict mode: a summary Handing variables to eval Asynchronous programming and continuation-passing style in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/esnext-classes.html", "title": "ECMAScript 6: classes", "content": "ECMAScript 6: classes esnext dev javascript Classes in ECMAScript 6 (final semantics) \nDuring the July 2012 meeting of TC39  [1] , classes have been accepted for ECMAScript 6, the upcoming version of the JavaScript language standard. This blog post explains how those classes work. It is based on Allen Wirfs-Brock’s annotated  slides .\n\n \n\n Overview [2] Details Grammar \n     Similar to functions, there are both class declarations and class expressions. Also similarly, the identifier of a class expression is only visible within the expression. \n     The value to be extended can be produced by an arbitrary expression. Which means that you’ll be able to write code such as the following:\n \n     \n     A class body can only contain methods, no data properties. Prototypes having data properties is generally considered an anti-pattern, so this just enforces a best practice.\n     \n     Semicolons are allowed between methods. \n     A method is a generator  [3]  if its name is prefixed with an asterisk (*). Such a method is translated to a property whose value is a generator function.\n     \n Various checks and features \n     Error checks: the class name cannot be   or  ; duplicate class element names are not allowed; the name   can only be used for a normal method, not for a getter, a setter or a generator method. \n     Class initialization is not hoisted:\n \n        That is usually not a problem, because you can still refer to the class everywhere. You just have to wait until the class definition has been evaluated, before you can use it:\n \n     \n     Instance methods cannot be used as constructors:\n \n        That shows that we are heading towards specialization: Whereas previously, the roles constructor, method and non-method function were all taken on by functions, ECMAScript 6 will have a dedicated syntactic construct for each role:\n         Constructors are created by classes. Non-method functions are created by arrow functions  [4] . Methods are created by method definitions (inside classes and object literals). \n        Each of these syntactic constructs produces functions, but ones that differ slightly from those that are produced by  : #1 functions have properties with different attributes (see below,   is frozen, etc.). #2 functions have a bound  . #3 functions have additional data to enable the use of    [2] .\n     \n     If there is no method   then the default is:\n         \n     \n     If you call a class as a function (without specifying  ) then   will be  . That’s also how functions as constructors work right now (in strict mode).\n     \n Extending \n     Don’t extend:  \n         \n             The prototype of   is   (as for all functions). \n             The prototype of   is  . \n         \n        That is the same as for functions. Note that the above is not equivalent to  , for the only reason that you normally want to avoid Foo inheriting methods such as  .\n     \n     Extend  :  \n         \n             The prototype of   is  . \n             The prototype of   is  . \n         \n        Prevent the methods of   from being available to instances of  .\n     \n     Extend a constructor:  \n         \n             The prototype of   is  . \n             The prototype of   is  . \n         \n        Therefore, class methods are inherited, too. For example: If there is a method   then that method is also available via  . That is how CoffeeScript implements inheritance  [5] .\n     \n     Extend a non-constructor:  \n         \n             The prototype of   is  \n             The prototype of   is  \n         \n     \n Mutability and property attributes \n      is neither writeable, nor configurable, nor enumerable. \n      is writeable and configurable, but not enumerable. \n      methods are writable and configurable, but not enumerable. Making them writable allows for dynamic patching. Getters and setters are enumerable (because they are similar to data properties). \n Conclusion When will you be able to use classes? [6] Traceur Advantages of classes [7] \n     Classes will make it easier for beginners to get started with JavaScript. \n     Classes will make subclassing easier for both beginners and experienced JavaScript programmers. Helper APIs such as  [8] , won’t be needed anymore. \n     Classes will allow you to subclass built-in classes/constructors such as   and    [9] . \n     Classes will help make code more portable between frameworks. Currently, many frameworks implement their own inheritance API, which makes it more difficult to reuse code. \n References ECMAScript: ES.next versus ES 6 versus ES Harmony A closer look at super-references in JavaScript and ECMAScript.next Asynchronous programming and continuation-passing style in JavaScript ECMAScript.next: arrow functions and method definitions Translating CoffeeScript classes to JavaScript The ECMAScript 6 schedule changes Prototypes as classes – an introduction to JavaScript inheritance Lightweight JavaScript inheritance APIs Subclassing builtins in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/tc39-july.html", "title": "ECMAScript.next: TC39’s July 2012 meeting", "content": "ECMAScript.next: TC39’s July 2012 meeting esnext tc39 dev javascript [1] \n     July 24, 2012 \n     July 25, 2012 \n     July 26, 2012 \n Introduction [2] Quasi literals are now called template strings [3] Tail calls tail calls [4] Unicode support several parts \n     A character escape with curly braces allows one to specify an arbitrary code point, which is represented as either one or two UTF-16 code units.\n \n        Escapes without braces are always a single UTF-16 code unit.\n     \n     Regular expressions can have a   flag that enables a Unicode mode with features such as curly-brace character escapes.\n     \n     Iterating over the code points in a string – which are sometimes one 16 bit character long, sometimes two characters. Two APIs are under consideration:\n         \n             : build a string from integer values. \n             : retrieve the n-th code point in a string. \n         \n     \n Parameter default values Forwarding an option to a parameter _.defaults() Forwarding a parameter to a parameter another example Forwarding an option to an option [5] References ECMAScript: ES.next versus ES 6 versus ES Harmony ECMAScript.next: classes Quasi-literals: embedded DSLs in ECMAScript.next Asynchronous programming and continuation-passing style in JavaScript Keyword parameters in JavaScript and ECMAScript.next comments powered by Disqus."},
{"url": "https://2ality.com/2012/07/apply-tricks.html", "title": "Apply and arrays: three tricks", "content": "Apply and arrays: three tricks underscorejs dev javascript advancedjs jslang jsarrays The apply method Trick 1: hand an array to a function that does not accept arrays Trick 2: eliminate holes in arrays Holes in arrays [1] Eliminating holes [2] Trick 3: flatten an array \nIf you want your code to be self-descriptive, you should consider alternatives, including implementing your own properly named function. Underscore has   which handles any level of nesting:\n References JavaScript: sparse arrays vs. dense arrays ECMAScript.next: Array.from() and Array.of() comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/underscore-extend.html", "title": "A closer look at _.extend and copying properties", "content": "A closer look at _.extend and copying properties underscorejs dev javascript jslang Underscore.js [1] _.extend source code Problem: for-in [2] for-in iterates over all properties, including inherited ones Why built-in methods are non-enumerable [3] for-in only iterates over enumerable properties Problem: assignment instead of definition [4] Assignment invokes setters Read-only prototype properties prevent assignment [4] [5] A better solution Ignoring inherited properties under ECMAScript 3 [6] A complete solution for ECMAScript 5 [7] References JavaScript inheritance by example Iterating over arrays and objects in JavaScript JavaScript properties: inheritance and enumerability  [and how it affects operations such as  ] Properties in JavaScript: definition versus assignment  [also explains property attributes and property descriptors] JavaScript’s strict mode: a summary The pitfalls of using objects as maps in JavaScript Subtyping JavaScript built-ins comments powered by Disqus."},
{"url": "https://2ality.com/2015/07/es6-module-exports.html", "title": "What do ES6 modules export?", "content": "What do ES6 modules export? esnext dev javascript CommonJS modules export values, while ES6 modules export immutable bindings. This blog post explains what that means. You should be loosely familiar with ES6 modules. If you aren’t, you can consult  the chapter on modules in “Exploring ES6” . CommonJS modules export values   # With CommonJS (Node.js) modules, things work in relatively familiar ways. If you import a value into a variable, the value is copied twice: once when it is exported (line A) and once it is imported (line B). If you access the value via the exports object, it is still copied once, on export: ES6 modules export immutable bindings   # In contrast to CommonJS modules, ES6 modules export  , live connections to values. The following code demonstrates how that works: If you import the module object via the asterisk ( ), you get similar results: Why export bindings?   # Given that exporting bindings is different from how data is normally transported in JavaScript – why do it this way? It has the benefit of making it easier to deal with cyclic dependencies. The following code is an example of a cyclic dependency:  imports   from  , which means that   is executed before  . But how can   access   then, if   hasn’t provided a value for it, yet?   imports a binding, which initially refers to an empty slot. Once   is executed, it fills in that slot. Therefore,   only has a problem if it uses   in the top level of its body, while it is executed. Using   in entities that are accessed after the evaluation of   are fine. One such entity is the function  . This may seem like an theoretical exercise, but cyclic dependencies can happen relatively easily in large code bases, especially during refactoring. Cycles tend to be longer (for example:   imports   imports   imports   imports  ), but the problem is the same. Consult the section “ Cyclic dependencies in CommonJS ” in “Exploring ES6” to find out how cyclic dependencies are handled in CommonJS. Exporting bindings   # How are bindings handled by JavaScript? Exports are managed via the data structure  . All export entries (except those for re-exports) have the following two names: \n Local name: is the name under which the export is stored inside the module. \n Export name: is the name that importing modules need to use to access the export. \n After you have imported an entity, that entity is always accessed via a pointer that has the two components   and  . In other words, that pointer refers to a binding inside a module. Let’s examine the export names and local names created by various kinds of exporting. The following table ( adapted from the ES6 spec ) gives an overview, subsequent sections have more details. Export clause   # \n Local name:  \n Export name:  \n \n Local name:  \n Export name:  \n Inline exports   # This is an inline export: It is equivalent to the following code: Therefore, we have the following names: \n Local name:  \n Export name:  \n Default exports   # There are two kinds of default exports: \n Default exports of   (function declarations, generator declarations) and class declarations are similar to normal inline exports in that named local entities are created and tagged. \n All other default exports are about exporting the results of expressions. \n # The following code default-exports the result of the expression  : It is equivalent to: If you default-export an expression, you get: \n Local name:  \n Export name:  \n The local name was chosen so that is wouldn’t clash with any other local name. Note that a default export still leads to a binding being exported. But, due to   not being a legal identifier, you can’t access that binding from inside the module. # The following code default-exports a function declaration: It is equivalent to: The names are: \n Local name:  \n Export name:  \n That means that you can change the value of the default export from within the module, by assigning a different value to  . (Only) for default exports, you can also omit the name of a function declaration: That is very similar to default-exporting an expression and therefore equivalent to: The names are: \n Local name:  \n Export name:  \n Default-exporting generator declarations and class declarations works similarly to default-exporting function declarations. Re-exports   # Re-exports are handled differently from normal exports. A re-export does not have a local name, it refers to the re-exported entity via that entity’s module and export name (shown in the column “Import name” below). Exported bindings in the spec   # This section gives pointers into the ECMAScript 2015 (ES6) language specification. Managing imported bindings: \n CreateImportBinding ()  creates local bindings for imports. \n GetBindingValue()  is used to access them. \n ModuleDeclarationInstantiation()  sets up the environment of a module (compare:  FunctionDeclarationInstantiation() ,  BlockDeclarationInstantiation() ). \n The export names and local names created by the various kinds of exports are shown in  table 42  in the section “ Source Text Module Records ”. The section “ Static Semantics: ExportEntries ” has more details. You can see that export entries are set up statically (before evaluating the module), evaluating export statements is described in the section “ Runtime Semantics: Evaluation ”. Be careful with ES6 transpilers   # ES6 transpilers compile ES6 modules to ES5. Due to the completely new way of passing on data (via bindings), you should expect the ES5 version to not always be completely compliant with the ES6 spec. Things are even trickier when transpiled ES6 code has to interoperate with native CommonJS or AMD modules. That being said, Babel hews pretty close to the spec,  as you can see in the GitHub repository for this blog post . comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/ids-are-global.html", "title": "DOM: element IDs are global variables", "content": "DOM: element IDs are global variables dom dev javascript clientjs The standard specifies \n     there is exactly one DOM element   whose property   has the value  .\n     \n     there is exactly one  DOM element   whose property   has the value  .  ’s tag must be one of: a, applet, area, embed, form, frame, frameset, iframe, img, object.\n     \n Firefox \n [Note: the code above can only be executed via a   tag, but not via the console. That is because the console handles global variables differently, so that the auto-creation process doesn’t work properly.]\n \nWhenever you read  , the   element is returned and a warning tells you not to do that. Obviously, the warning is correct: It’s fine to use this feature interactively, but you should not rely on it in actual code.\n\n Updates jsPerf test \n  Commenter tjvantoll mentions where HTML5 standardizes that element IDs become properties of  . In reaction to that, the post now describes what is specified there.\n comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/property-definition-assignment.html", "title": "Properties in JavaScript: definition versus assignment", "content": "Properties in JavaScript: definition versus assignment dev javascript jslang email Definition versus assignment \n  To assign to a property, one uses an expression such as\n [1] \nThe following two sections go into more detail regarding how definition and assignment work.   You should still be able to understand Sect. 4, “The consequences”, and later.\n\n Recap: property attributes and internal properties Kinds of properties \n     Named accessor properties: A property that exists thanks to a getter or a setter.\n     \n     Named data properties: A property that h    as a value. Those are the most common properties. They include methods.\n     \n     Internal properties: are used internally by JavaScript and not directly accessible via the language. However, there can be indirect ways of accessing them. Example: Every object has an internal property called [[Prototype]]. You cannot directly read it, but still retrieve its value, via  . While internal properties are referred to by a name in square brackets, they are nameless in the sense that they are invisible and don’t have a normal, string-valued property name.\n     \n Property attributes \n     All properties:\n         \n             [[Enumerable]]: If a property is non-enumerable, it can’t be seen by some operations, such as   and    [2] . \n             [[Configurable]]: If a property is non-configurable, none of the attributes (except [[Value]]) can be changed via a definition.\n             \n         \n     \n     Named data properties:\n         \n             [[Value]]: is the value of the property. \n             [[Writable]]: determines whether the value can be changed. \n         \n     \n     Named accessor properties:\n         \n             [[Get]]: holds a getter method. \n             [[Set]]: holds a setter method. \n         \n     \n Property descriptors \n Internal properties several internal properties \n [[Prototype]]: The prototype of the object. \n [[Extensible]]: Is this object  , can new properties be added to it? \n [[DefineOwnProperty]]: Define a property. See explanation below. \n [[Put]]: Assign to a property. See explanation below. \n The details of definition and assignment Defining a property DefineOwnProperty \n     If   does not have an own property whose name is  : Create a new property if the object is extensible, reject if it isn’t.\n     \n     Otherwise, there already is an own property and the definition changes that property. \n     If that property is not configurable then the following changes will be rejected:\n         \n             Converting a data property to an accessor property or vice versa \n             Changing [[Configurable]] or [[Enumerable]] \n             Changing [[Writable]] \n             Changing [[Value]] if [[Writable]] is  \n             Changing [[Get]] or [[Set]] \n         \n     \n     Otherwise, the existing own property is configurable and can be changed as specified. \n \nTwo functions for defining a property are   and  . For example:\n Assigning to a property Put \n     If there is a read-only property whose name is   somewhere in the prototype chain: reject.\n     \n     If there is a setter whose name is   somewhere in the prototype chain: call the setter.\n     \n     If there is no own property whose name is  : if the the object is extensible then create a new property.\n \n        If the object is not extensible then reject.\n     \n     Otherwise, there is an own property named   that is writable. Invoke\n \n        That updates the value of  , but keeps its attributes (such as enumerability) unchanged\n     \n The consequences Assignment calls a setter in a prototype, definition creates an own property Read-only properties in prototypes prevent assignment, but not definition [3] \n  With definition, we want to create a new own property:\n The assignment operator does not change properties in prototypes Methods: Allow methods to be patched, directly in the prototype, but prevent accidental changes via descendants of the prototype.\n     Non-method properties: The prototype provides shared default values for descendants. One can override these values via a descendant, but not change them.\n        This is considered an anti-pattern and discouraged. It is cleaner to assign default values in constructors.\n     Only definition allows you to create a property with arbitrary attributes The properties of an object literal are added via definition Attributes of methods Conclusion If you want to create a new property, use definition. If you want to change the value of a property, use assignment. define properties References Prototypes as classes – an introduction to JavaScript inheritance JavaScript properties: inheritance and enumerability Fixing the Read-only Override Prohibition Mistake  [a page on the ECMAScript wiki with background information on this issue] comments powered by Disqus."},
{"url": "https://2ality.com/2015/08/isomorphic-javascript.html", "title": "Is “Isomorphic JavaScript” a good term?", "content": "Is “Isomorphic JavaScript” a good term? dev javascript A recent trend in the web development world is to use JavaScript on the server to assemble pages there, with the same code that is used to manage them in the client. That lets you initially see content faster, especially on mobile devices and helps with search engines. How are we supposed to call code that runs on either server or client? Michael Jackson  doesn’t like a recent proposal : So Charlie Robbins suggested that the term “Isomorphic JavaScript” might be used to describe JavaScript code that “can execute both on the client and the server”. And nobody knew what the hell it meant, but now instead of just writing JavaScript the people were writing Isomorphic JavaScript. Michael proposes the term “Universal JavaScript”. In a comment to his blog post, Matti Schneider  defends  “Isomorphic JavaScript”: No. “Isomorphic”, in terms of topology, describes the relationship between a transformation applied to an element in one set, and another transformation applied to another element in another set, and how these transformations are “as comparable” as the sets on which they are applied are comparable. Maybe we should distinguish between: \n The technique of asssembling pages on either client or server. Here, “isomorphic” and “full stack” (as  proposed  by Rodrigo Medeiros) seem good choices. \n JavaScript that runs in all (or most) JavaScript environments, especially browsers and Node.js. Here, “universal” seems a good choice. \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/08/object-literals-es5.html", "title": "Five little-known facts about ES5 object literals", "content": "Five little-known facts about ES5 object literals dev javascript jslang This blog post describes five little known facts about ECMAScript 5 (ES5) object literals: ECMAScript 5 has getters and setters Trailing commas are legal You often don’t have to quote property keys You can use reserved words as unquoted property keys Using objects as dictionaries is surprisingly tricky ECMAScript 5 has getters and setters   # ECMAScript 5 supports getters and setters. You can create them either  via property descriptors  or via object literals: Let’s use   in a REPL: Trailing commas are legal   # Starting with ES5, it is legal to put a comma after the last property. That helps whenever you want to rearrange properties, especially if there is one property per line: You often don’t have to quote property keys   # The grammar rule for   in the ES5 specification states that a property name in an object literal is either: \n an identifier, \n a string literal, \n or a numeric literal. \n String literals as property names   # You can use arbitrary text as a property key if you quote it: Identifiers as property names   # If the property key is an identifier, it doesn’t have to be quoted in object literals. Identifiers must start with a Unicode letter, an underscore or a dollar sign. The ES5 spec describes Unicode letters as : Any character in the Unicode categories “Uppercase letter (Lu)”, “Lowercase letter (Ll)”, “Titlecase letter (Lt)”, “Modifier letter (Lm)”, “Other letter (Lo)”, or “Letter number (Nl)”. Thus, the following property names don’t have to be quoted: Numbers as property names   # You don’t have to quote property names in object literals if they are numeric literals. Numeric literals include the hexadecimal notation, but not a leading minus  ( , a dash), because that is not part of a numeric literal in JavaScript, it is an operator. The numbers represented by these numeric literals are converted to strings before they become property keys: In contrast to identifiers, numeric literals cannot be used after the dot operator: Recommendations   # My recommendations (for ES5 and later): \n \n For objects holding code, I only use identifiers as property names and never quote. \n \n \n For objects holding data, I often quote property names. \n \n \n The JSON data format requires you to quote property names – with double quotes! \n \n \n You can use reserved words as unquoted property keys   # In ECMAScript 3, you had to quote reserved words such as   or   if you wanted to use them as property names: In ECMAScript 5, that is not necessary, anymore: Using objects as dictionaries is surprisingly tricky   # ECMAScript 5 does not have a built-in data structure for dictionaries (which are also known as  ). Therefore, the programming construct   is a abused as a dictionary from strings to arbitrary values. In addition to keys having to be strings, that causes three problems. First, You cannot invoke methods on objects-as-dictionaries. The name of any method you invoke might be a key in the data: Second, you must be careful about inheritance. Getting the value of a property and the   operator include inherited properties, which is not what you want in this case: Third, the property key   triggers special behavior in many engines, which is why you can’t use it as a key for data. One work-around is to escape such keys (and their escaped versions): The dict pattern   # An object works best as a dictionary if its prototype is   (the so-called  ). That fixes problem 2: Problems 1 and 3 remain: you can’t invoke any methods on   (it doesn’t inherit any, anyway, because it has no prototypes) and you must escape  . ECMAScript 6 has the built-in data structure   which you should always use for data, especially if it has arbitrary keys. More information on the dict pattern: section “ The dict Pattern: Objects Without Prototypes Are Better Maps ” in “Speaking JavaScript”. Further reading on object literals   # \n Object literals in ECMAScript 5: section “ Object Literals ” in “Speaking JavaScript”. \n Object literals in ECMAScript 6: chapter “ New OOP features besides classes ” in “Exploring ES6”. \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/07/regexp-es6.html", "title": "New regular expression features in ECMAScript 6", "content": "New regular expression features in ECMAScript 6 esnext dev javascript This blog post explains new regular expression features in ECMAScript 6. It helps if you are familiar with ES5 regular expression features and Unicode. Consult the following two chapters of “Speaking JavaScript” if you aren’t: \n “ Regular Expressions ” \n “ Unicode and JavaScript ” \n Overview   # The following regular expression features are new in ECMAScript 6: \n \n The new flag   (sticky) anchors each match of a regular expression to the end of the previous match. \n \n \n The new flag   (unicode) handles surrogate pairs (such as  ) as code points and lets you use Unicode code point escapes (such as  ) in regular expressions. \n \n \n The new data property   gives you access to the flags of a regular expression, just like   already gives you access to the pattern in ES5: \n \n \n \n You can use the constructor   to make a copy of a regular expression: \n \n \n New flag   (sticky)   # The new flag   changes two things while matching a regular expression   against a string: \n Anchored to  : The match must start at   (the index after the previous match). This behavior is similar to the   anchor, but with that anchor, matches must always start at index 0. \n Match repeatedly: If a match was found,   is set to the index after the match. This behavior is similar to the   flag. Like  ,   is normally used to match multiple times. \n The main use case for this matching behavior is tokenizing, where you want each match to immediately follow its predecessor. An example of tokenizing via a sticky regular expression and   is given later. Let’s look at how various regular expression operations react to the   flag. The following tables give an overview. I’ll provide more details afterwards. Methods of regular expressions (  is the regular expression that a method is invoked on): Methods of strings (  is the string that a method is invoked on,   is the regular expression parameter):    # If   is not set, matching always starts at the beginning, but skips ahead until a match is found.   is not changed. If   is set, matching starts at   and skips ahead until a match is found.   is set to the position after the match. That means that you receive all matches if you loop until   returns  . If only   is set, matching starts at   and is anchored to that position (no skipping ahead until a match is found).   is updated similarly to when   is set. Setting both   and   is the same as only setting  .    #  works the same as  , but it returns   or   (instead of a match object or  ) when matching succeeds or fails:    #  ignores the flag   and   (which is not changed, either). Starting at the beginning of the string, it looks for the first match and returns its index (or   if there was no match): If you set the flag  ,   is still ignored, but the regular expression is now anchored to index 0.    #  has two modes: \n If   is not set, it works like  . \n If   is set, it returns an Array with the string parts that matched, or  . \n If the flag   is not set,   captures groups like  : If only the flag   is set then   returns all matching substrings in an Array (or  ). Matching always starts at position 0. If you additionally set the flag  , then matching is still performed repeatedly, while anchoring the regular expression to the index after the previous match (or 0).    # The complete details of    are explained in Speaking JavaScript . For ES6, it is interesting to see how things change if you use the flag  . With  , the string must start with a separator: Subsequent separators are only recognized if they immediately follow the first separator: That means that the string before the first separator and the strings between separators are always empty. As usual, you can use groups to put parts of the separators into the result array:    # Without the flag  ,   only replaces the first match: If only   is set, you also get at most one match, but that match is always anchored to the beginning of the string.   is ignored and unchanged. With   set,   replaces all matches: With   set,   replaces all matches, but each match is anchored to the end of the previous match: The parameter   can also be a function,  consult “Speaking JavaScript” for details . Example: using sticky matching for tokenizing   # The main use case for sticky matching is  , turning a text into a sequence of tokens. One important trait about tokenizing is that tokens are fragments of the text and that there must be no gaps between them. Therefore, sticky matching is perfect here. In a legal sequence of tokens, sticky matching and non-sticky matching produce the same output: If, however, there is non-token text in the string then sticky matching stops tokenizing, while non-sticky matching skips the non-token text: The behavior of sticky matching during tokenizing helps with error handling. Example: manually implementing sticky matching   # If you wanted to manually implement sticky matching, you’d do it as follows: The function   works like   in sticky mode. New flag   (unicode)   # The flag   switches on a special Unicode mode for a regular expression. That mode has two features: \n You can use Unicode code point escape sequences such as   for specifying characters via code points. Normal Unicode escapes such as   only have a range of four hexadecimal digits (which equals the basic multilingual plane). \n \n “characters” in the regular expression pattern and the string are code points (not UTF-16 code units). Code units are converted into code points. \n A later section has more information on escape sequences. I’ll explain the consequences of feature 2 next. Instead of Unicode code point escapes (e.g.,  ), I’m using two UTF-16 code units (e.g.,  ). That makes it clear that surrogate pairs are grouped in Unicode mode and works in both Unicode mode and non-Unicode mode. Consequence: lone surrogates in the regular expression only match lone surrogates   # In non-Unicode mode, a lone surrogate in a regular expression is even found inside (surrogate pairs encoding) code points: In Unicode mode, surrogate pairs become atomic units and lone surrogates are not found “inside” them: Actual lone surrogate are still found: Consequence: you can put code points in character classes   # In Unicode mode, you can put code points into character classes and they won’t be interpreted as two characters, anymore. Consequence: the dot operator ( ) matches code points, not code units   # In Unicode mode, the dot operator matches code points (one or two code units). In non-Unicode mode, it matches single code units. For example: Consequence: quantifiers apply to code points, not code units   # In Unicode mode, quantifiers apply to code points (one or two code units). In non-Unicode mode, they apply to single code units. For example: New data property     # In ECMAScript 6, regular expressions have the following data properties: \n The pattern:  \n The flags:  \n Individual flags:  ,  ,  ,  ,  \n Other:  \n As an aside,   is the only instance property now, all other data properties are implemented via internal instance properties and getters such as  . The property   (which already existed in ES5) contains the regular expression pattern as a string: The property   is new, it contains the flags as a string, with one character per flag: You can’t change the flags of an existing regular expression (  etc. have always been immutable), but   allows you to make a copy where the flags are changed: The next section explains another way to make modified copies of regular expressions.  can be used as a copy constructor   # In ES6 there are two variants of the constructor   (the second one is new): \n \n \nA new regular expression is created as specified via  . If   is missing, the empty string   is used. \n \n \n \n  is cloned. If   is provided then it determines the flags of the copy. \n \n The following interaction demonstrates the latter variant: Therefore, the   constructor gives us another way to change flags: Escape sequences in JavaScript   # There are three parameterized escape sequences for representing characters in JavaScript: \n \n Hex escape (exactly two hexadecimal digits):  \n \n \n \n Unicode escape (exactly four hexadecimal digits):  \n \n \n \n Unicode code point escape (1 or more hexadecimal digits):  \n \n \n Unicode code point escapes are new in ES6. The escape sequences can be used in the following locations: Identifiers: \n A 4-digit Unicode escape   becomes a single code point. \n A Unicode code point escape   becomes a single code point. \n String literals: \n Strings are internally stored as UTF-16 code units. \n A hex escape   contributes a UTF-16 code unit. \n A 4-digit Unicode escape   contributes a UTF-16 code unit. \n A Unicode code point escape   contributes the UTF-16 encoding of its code point (one or two UTF-16 code units). \n Template literals: \n In template literals, escape sequences are handled like in string literals. \n In tagged templates, how escape sequences are interpreted depends on the tag function. It can choose between two interpretations:\n \n Cooked: escape sequences are handled like in string literals. \n Raw: escape sequences are handled as a sequence of characters. \n \n \n Regular expressions: \n \n Unicode code point escapes are only allowed if the flag   is set, because   is interpreted as three times the character  , otherwise: \n \n \n Escape sequences in the ES6 spec   # Various information: \n \n The spec treats source code as a sequence of Unicode code points: “ Source Text ” \n \n \n Unicode escape sequences sequences in identifiers: “ Names and Keywords ” \n \n \n Strings are internally stored as sequences of UTF-16 code units: “ String Literals ” \n \n \n Strings – how various escape sequences are translated to UTF-16 code units: “ Static Semantics: SV ” \n \n \n Template literals – how various escape sequences are translated to UTF-16 code units: “ Static Semantics: TV and TRV ” \n \n # The spec distinguishes between BMP patterns (flag   not set) and Unicode patterns (flag   set). Sect. “ Pattern Semantics ” explains that they are handled differently and how. As a reminder, here is how grammar rules are be parameterized in the spec: \n If a grammar rule   has the subscript   then that means there are two versions of it:   and  . \n Parts of the rule can pass on the subscript via  . \n If a part of a rule has the prefix   it only exists if the subscript   is present. \n If a part of a rule has the prefix   it only exists if the subscript   is not present. \n You can see this parameterization in action in Sect. “ Patterns ”, where the subscript   creates separate grammars for BMP patterns and Unicode patterns: \n \n IdentityEscape: In BMP patterns, many characters can be prefixed with a backslash and are interpreted as themselves (for example: if   is not followed by four hexadecimal digits, it is interpreted as  ). In Unicode patterns that only works for the following characters (which frees up   for Unicode code point escapes):  \n \n \n RegExpUnicodeEscapeSequence:   is only allowed in Unicode patterns. In those patterns, lead and trail surrogates are also grouped to help with UTF-16 decoding. \n \n Sect. “ CharacterEscape ” explains how various escape sequences are translated to characters (roughly: either code units or code points). String methods using regular expressions delegate to regular expression methods   # The following string methods now delegate their work to regular expression methods: \n  calls  . \n  calls  . \n  calls  . \n  calls  . \n Support in engines and transpilers   # As usual, consult the compatibility table by kangax to find out what is supported where: \n  flags   and  \n New property  \n Further reading   # If you want to know in more detail how the regular expression flag   works, I recommend the article “ Unicode-aware regular expressions in ECMAScript 6 ” by Mathias Bynens. comments powered by Disqus."},
{"url": "https://2ality.com/2015/08/getting-started-es6.html", "title": "Getting started with ECMAScript 6", "content": "Getting started with ECMAScript 6 esnext dev javascript This blog post helps you to get started with ECMAScript 6 (ES6): \n It explains how you can interactively try out ES6. \n It lists ES6 features that are easy to adopt, along with how those features are coded in ES5. \n Trying out ECMAScript 6   # There are three simple ways to play with ES6:  use  the online Babel REPL , an interactive playground that compiles ES6 to ES5. There is nothing to install with this option.  use  , a version of the Node.js executable that understands ES6 (and internally compiles it to ES5). It can be installed via npm.  check  the ES6 compatibility table by kangax  to find out which ES6 features are supported natively where. More details on options 1 and 2 are given next. The Babel REPL   # The Babel REPL has four major sections: \n The top left pane contains the ES6 source code. \n The bottom left pane shows syntax errors discovered in the ES6 code. \n The top right pane contains the ES5 code that the ES6 code is compiled to. \n The bottom right pane shows output produced via  . \n babel-node   # The   executable can be installed via npm: You can use it in the same way as you would the Node.js executable  . Like  , an interactive REPL is started like this: Once you are in that REPL, you can execute ES6 code: Note that  babel-node does not currently support multi-line input . The Babel website has  more information the Babel CLI tools . The remaining sections of this post describe ES6 features that are easy to adopt. From   to  /    # ES6 has two new ways to declare variables: \n  is (roughly) a block-scoped version of  . \n  is like  , but creates  , variables whose values can’t be changed. \n You can generally replace each   with a   or a  . But you shouldn’t do so blindly, because the different kind of scoping can change how code behaves. As an example, look at the following ES5 code: That   returns   may be surprising. You can see why if you rewrite the code so that it more closely reflects what is actually going on: If you replace   with   in the initial version, you get different behavior: Thus, blindly replacing   with   or   is risky. My advice is: \n Only use  /  in new code. \n Leave old code as is or refactor it carefully. \n  chapter “ Variables and scoping ” in “Exploring ES6”. From IIFEs to blocks   # In ES5, you had to use an IIFE if you wanted to keep a variable local: In ECMAScript 6, you can simply use a block and a   declaration:  section “ Avoid IIFEs in ES6 ” in “Exploring ES6”. From concatenating strings to template literals   # With ES6, JavaScript finally gets literals for string interpolation and multi-line strings. String interpolation   # In ES5, you put values into strings by concatenating those values and string fragments: In ES6 you can use string interpolation via template literals: Multi-line strings   # Template literals also help with representing multi-line strings. For example, this is what you have to do to represent one in ES5: If you escape the newlines via backslashes, things look a bit nicer (but you still have to explicitly add newlines): ES6 template literals can span multiple lines: (The examples differ in how much whitespace is included, but that doesn’t matter in this case.)  chapter “ Template literals and tagged templates ” in “Exploring ES6”. From function expressions to arrow functions   # In current ES5 code, you have to be careful with   whenever you are using function expressions. In the following example, I create the helper variable   (line A) so that the   of   can be accessed in line B. In ES6, you can use arrow functions, which don’t shadow   (line A,  ): Arrow functions are especially handy for short callbacks that only return results of expressions. In ES5, such callbacks are relatively verbose: In ES6, arrow functions are much more concise: When defining parameters, you can even omit parentheses if the parameters are just a single identifier. Thus:   and   are both allowed.  chapter “ Arrow functions ” in “Exploring ES6”. Handling multiple return values   # Some functions or methods return multiple values via arrays or objects. In ES5, you always need to create intermediate variables if you want to access those values. In ES6, you can avoid intermediate variables via destructuring. Multiple return values via arrays   #  returns captured groups via an Array-like object. In ES5, you need an intermediate variable (  in the example below), even if you are only interested in the groups: In ES6, destructuring makes this code simpler: The empty slot at the beginning of the Array pattern skips the Array element at index zero. Multiple return values via objects   # The method   return a  , an object that holds multiple values in its properties. In ES5, even if you are only interested in the properties of an object, you still need an intermediate variable (  in the example below): In ES6, you can use destructuring:  is an abbreviation for:  chapter “ Destructuring ” in “Exploring ES6”. From   to   to     # Prior to ES5, you iterated over Arrays as follows: In ES5, you have the option of using the Array method  : A   loop has the advantage that you can break from it,   has the advantage of conciseness. In ES6, the   loop combines both advantages: If you want both index and value of each array element,   has got you covered, too, via the new Array method   and destructuring:  section “ The   loop ” in “Exploring ES6”. Handling parameter default values   # In ES5, you specify default values for parameters like this: ES6 has nicer syntax: An added benefit is that in ES6, a parameter default value is only triggered by  , while it is triggered by any falsy value in the previous ES5 code.  section “ Parameter default values ” in “Exploring ES6”. Handling named parameters   # A common way of naming parameters in JavaScript is via object literals (the so-called  ): Two advantages of this approach are: Code becomes more self-descriptive and it is easier to omit arbitrary parameters. In ES5, you can implement   as follows: In ES6, you can use destructuring in parameter definitions and the code becomes simpler: Making the parameter optional   # To make the parameter   optional in ES5, you’d add line A to the code: In ES6 you can specify   as a parameter default value:  section “ Simulating named parameters ” in “Exploring ES6”. From   to rest parameters   # In ES5, if you want a function (or method) to accept an arbitrary number of arguments, you must use the special variable  : In ES6, you can declare a rest parameter (  in the example below) via the   operator: Rest parameters are even nicer if you are only interested in trailing parameters: Handling this case in ES5 is clumsy: Rest parameters make code easier to read: You can tell that a function has a variable number of parameters just by looking at its parameter definitions.  section “ Rest parameters ” in “Exploring ES6”. From   to the spread operator ( )   # In ES5, you turn arrays into parameters via  . ES6 has the spread operator for this purpose.    # ES5 –  : ES6 – spread operator:    # ES5 –  : ES6 – spread operator:  section “ The spread operator ( ) ” in “Exploring ES6”. From   to the spread operator ( )   # The spread operator can also turn the contents of its operand into array elements. That means that it becomes an alternative to the Array method  . ES5 –  : ES6 – spread operator:  section “ The spread operator ( ) ” in “Exploring ES6”. From constructors to classes   # ES6 classes are mostly just more convenient syntax for constructor functions. Base classes   # In ES5, you implement constructor functions directly: In ES6, classes provide slightly more convenient syntax for constructor functions: Derived classes   # Subclassing is complicated in ES5, especially referring to super-constructors and super-properties. This is the canonical way of creating a sub-constructor of  ,  : ES6 has built-in support for subclassing, via the   clause:  chapter “ Classes ” in “Exploring ES6”. From custom error constructors to subclasses of     # In ES5, it is impossible to subclass the built-in constructor for exceptions,   (the chapter “ Subclassing Built-ins ” in “Speaking JavaScript” explains why). The following code shows a work-around that gives the constructor   important features such as a stack trace: In ES6, all built-in constructors can be subclassed, which is why the following code achieves what the ES5 code can only simulate:  section “ Subclassing built-in constructors ” in “Exploring ES6”. From function expressions in object literals to method definitions   # In JavaScript, methods are properties whose values are functions. In ES5 object literals, methods are created like other properties. The property values are provided via function expressions. ES6 has  , special syntax for creating methods:  section “ Method definitions ” in “Exploring ES6”. From objects to Maps   # Using the language construct   as a map from strings to arbitrary values (a data structure) has always been a makeshift solution in JavaScript. The safest way to do so is by creating an object whose prototype is  . Then you still have to ensure that no key is ever the string  , because that property key triggers special functionality in many JavaScript engines. The following ES5 code contains the function   that uses the object   as a map: In ES6, you can use the built-in data structure   and don’t have to escape keys. As a downside, incrementing values inside Maps is less convenient. Another benefit of Maps is that you can use arbitrary values as keys, not just strings. \n Section “ The dict Pattern: Objects Without Prototypes Are Better Maps ” in “Speaking JavaScript” \n Chapter “ Maps and Sets ” in “Exploring ES6” \n From CommonJS modules to ES6 modules   # Even in ES5, module systems based on either AMD syntax or CommonJS syntax have mostly replaced hand-written solutions such as  the revealing module pattern . ES6 has built-in support for modules. Alas, no JavaScript engine supports them natively, yet. But tools such as browserify, webpack or jspm let you use ES6 syntax to create modules, making the code you write future-proof. Multiple exports   # In CommonJS, you export multiple entities as follows: Alternatively, you can import the whole module as an object and access   and   via it: In ES6, multiple exports are called   and handled like this: The syntax for importing modules as objects looks as follows (line A): Single exports   # Node.js extends CommonJS and lets you export single values from modules, via  : In ES6, the same thing is done via  :  chapter “ Modules ” in “Exploring ES6”. What to do next   # Now that you got a first taste of ES6, what should you do next? I have two suggestions: \n In “ Exploring ES6 ”, each major feature of ES6 has its own chapter, which starts with an overview. Browsing the chapters is therefore a good way of getting a more complete picture of ES6. \n The chapter “ Deploying ECMAScript 6 ” describes the options you have for deploying ES6 in current JavaScript environments. \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/08/web-component-status.html", "title": "What happened to Web Components?", "content": "What happened to Web Components? dev webcomponents clientjs Three years ago, there was a lot of excitement surrounding Web Components: everybody talked about them, the frameworks Ember and Angular planned to integrate them or even be based on them, etc. By now, that excitement seems to have died down. This blog post examines what happened to Web Components. Spoiler: they are alive and well and slowly being adopted across browsers. Refresher: Web Components   # Web Components are a suite of specifications that help with implementing custom HTML elements: \n Custom elements: an API for registering your own implementations for HTML elements. \n Shadow DOM: Encapsulates and hides the innards of a custom element inside a nested document. The most important part of Web Components and hardest to polyfill. \n Templates: enable you to store HTML data inside an HTML document. The content of a   element is parsed without interpreting it (no loading of images etc.). \n HTML Imports: let you import other HTML documents into the current one. That way, HTML documents become bundles of HTML, CSS and JavaScript. You need such bundles to distribute custom elements and all of their dependencies. \n For more information on how Web Components work, you can read the introduction “ Bringing componentization to the web: An overview of Web Components ” by Travis Leithead and Arron Eicholz. Recent developments   # For a long time, it was mainly Google (and, to some degree, Mozilla) that pushed Web Components. In recent months, other parties became more involved. There were two face-to-face meetings  on 2015-04-24  and  on 2015-07-21  that were attended by employees from Mozilla, Microsoft, Google, Apple and others. During those meetings, two Web Component specifications moved closer to a cross-browser consensus: \n \n Shadow DOM: There is now broad agreement on how to standardize the Shadow DOM, which is great, because, as mentioned before, it is the spec that is most difficult to polyfill. \n \n \n Custom elements: Everyone agrees that custom elements are important, but getting the details right is difficult, especially when to activate a custom implementation – while creating the custom element in the DOM or later. \n \n What about the other two specifications? \n \n HTML Imports are still controversial, because there is much overlap with ES6 module loading. Especially Mozilla and Microsoft argue that further work on HTML Imports should wait until ES6 module loading is finished. \n \n \n Templates are not a very complex feature and already  broadly supported . The status for Microsoft Edge is: “ in development ”. \n \n More information: \n “ Update on standardizing shadow DOM and custom elements ” by Anne van Kesteren (2015-07-28): A high-level overview of the sticking points of the design of custom elements. \n “ The state of Web Components ” by Wilson Page (2015-06-09): A comprehensive overview of the state of standardization of the Web Components specifications. \n Web Components versus React   # When Sebastian Markbage (one of React’s creators) was asked about Web Components,  he answered : We’re not going to use it at all at Facebook.  We’re not going to build React on it because there’s a strong model difference – imperative in Web Components to declarative in React.  Web Components doesn’t have an idiomatic way to define things like where events go.  How do you pass data when everything is a string?  We see it more as an interop layer that lets various frameworks talk to each other. In talking to the Atom team, this doesn’t solve different framework idioms as it doesn’t have an opinion on how they relate. This sounds like React and Web Components are at odds with each other. However, in the talk “ The complementarity of React and Web Components ”, Andrew Rota disagrees: \n \n Web Components can be used as leaves in the tree of React Components, just like native DOM elements. \n \n \n React is getting better at supporting Web Components: \n \n Custom elements already work (elements with lowercase names are interpreted as DOM, replacing a whitelist of names). \n Support for custom attributes and custom events is work in progress. \n \n \n \n Andrew argues that Web Components should be: \n \n Small: atomic, not compound. React and other frameworks can be used to assemble Web Components. \n Completely encapsulated: For example, a Web Component should not put script tags into the surrounding document. \n As stateless as possible: avoid internal state, use events to communicate changes. \n \n These rules for designing Web Components help React, but they make sense in general. \n \n \n Using React inside a Web Component makes less sense, it goes against Web Components being as minimal as possible. \n \n Further information   # The Web Platform Podcast episode 54 (2015-07-28) asks a panel of experts: “ Are Web Components Ready Yet? ” (80min video). Watch that video to get more information and context on Web Components. Mentioned in the podcast, the work of  the CSS Houdini Group  will help with implementing Web Components in the future: The objective of the CSS-TAG [Technical Architecture Group]   ( ) is to jointly develop features that explain the “magic” of Styling and Layout on the web. Styling and layouting are currently mostly black boxes. The Houdini Group plans to expose the internals of those boxes and to let you customize what is going on there. comments powered by Disqus."},
{"url": "https://2ality.com/2015/08/logging-variables-tagged-template.html", "title": "Logging variables via an ES6 tagged template", "content": "Logging variables via an ES6 tagged template esnext dev javascript template literals This blog post shows how you can use a tagged template to log variables more efficiently. In order to understand it, you should be familiar with ECMAScript 6 template literals and tagged templates. For an introduction, consult chapter “ Template literals and tagged templates ” of “Exploring ES6”. The problem: redundancy   # If you want to log both name and value of a variable in a traditional manner, there is redundancy: Even a template literal doesn’t help: The solution: a tagged template   # The solution is to implement a custom tag function called  . A template tagged with that function eliminates the redundancy: The object literal   inside the substitution   is an abbreviation for (a so-called “ property value shorthand ”): Accordingly, the tag function   expects its substitutions to be objects: You can put multiple variable names inside a substitution: comments powered by Disqus."},
{"url": "https://2ality.com/2015/08/es6-map-json.html", "title": "Converting ES6 Maps to and from JSON", "content": "Converting ES6 Maps to and from JSON esnext dev javascript When you have key-value data whose keys you don’t know in advance, it’s generally better to store it in an ES6 Map than in an object. But how do you convert Maps to and from JSON? This blog post tells you. \n Maps:  chapter “Maps” of “JavaScript for impatient programmers” \n JSON:  chapter “Creating and parsing JSON” of “JavaScript for impatient programmers” \n Arbitrary Maps as JSON via Arrays of pairs   # If a Map contains arbitrary (JSON-compatible) data, we can convert it to JSON by encoding it as an Array of key-value pairs (2-element Arrays). Converting a Map to and from an Array of pairs   # The spread operator  lets you convert a Map to an Array of pairs: The   constructor lets you convert an Array of pairs to a Map: The conversion to and from JSON   # Let’s use this knowledge to convert any Map with JSON-compatible data to JSON and back: The following interaction demonstrates how these functions are used: String Maps as JSON via objects   # Whenever a Map only has strings as keys, you can convert it to JSON by encoding it as an object. Converting a string Map to and from an object   # The following two function convert string Maps to and from objects: Let’s use these two functions: The conversion to and from JSON   # With these helper functions, the conversion to JSON works as follows: This is an example of using these functions: comments powered by Disqus."},
{"url": "https://2ality.com/2015/09/typed-arrays.html", "title": "Typed Arrays in ECMAScript 6", "content": "Typed Arrays in ECMAScript 6 esnext dev javascript Typed Arrays are an ECMAScript 6 API for handling binary data. This blog post explains how they work. Overview   # Code example: Instances of   store the binary data to be processed. Two kinds of   are used to access the data: \n Typed Arrays ( ,  ,  , etc.) interpret the ArrayBuffer as an indexed sequence of elements of a single type. \n Instances of   let you access data as elements of several types ( ,  ,  , etc.), at any byte offset inside an ArrayBuffer. \n The following browser APIs support Typed Arrays ( details are mentioned later ): \n File API \n XMLHttpRequest \n Fetch API \n Canvas \n WebSockets \n And more \n Introduction   # For a long time, JavaScript was not very good at handling binary data. This changed with the introduction of the Typed Array API, whose main use cases are: \n Processing binary data: manipulating image data in HTML Canvas elements, parsing binary files, handling binary network protocols, etc. \n Interacting with native APIs: Native APIs often receive and return data in a binary format, which you could neither store nor manipulate well in traditional JavaScript. That meant that whenever you were communicating with such an API, data had to be converted from JavaScript to binary and back, for every call. Typed Arrays eliminate this bottleneck. One example of communicating with native APIs is WebGL, for which Typed Arrays were initially created. Section “ History of Typed Arrays ” of the article “ Typed Arrays: Binary Data in the Browser ” (by Ilmari Heikkinen for HTML5 Rocks) has more information. \n Two kinds of objects work together in the Typed Array API: \n Buffers: Instances of   hold the binary data. \n Views: provide the methods for accessing the binary data. There are two kinds of views:\n \n An instance of a Typed Array constructor ( ,  , etc.) works much like a normal Array, but only allows a single type for its elements and doesn’t have holes. \n An instance of   lets you access data at any byte offset in the buffer, and interprets that data as one of several types ( ,  , etc.). \n \n \n This is a diagram of the structure of the Typed Array API (notable: all Typed Arrays have a common superclass): Typed Arrays were a separate specification before they became part of the ECMAScript 6 standard. Element types   # The following element types are supported by the API: The element type   is special: it is not supported by   and only exists to enable  . This Typed Array is used by the   element (where it replaces  ). The only difference between   and   is how overflow and underflow are handled (as explained in the next section). It is recommended to avoid the former –  quoting Brendan Eich : Just to be super-clear (and I was around when it was born),   is   a historical artifact (of the HTML5 canvas element). Avoid unless you really are doing canvas-y things. Handling overflow and underflow   # Normally, when a value is out of the range of the element type, modulo arithmetic is used to convert it to a value within range. For signed and unsigned integers that means that: \n The highest value plus one is converted to the lowest value (0 for unsigned integers). \n The lowest value minus one is converted to the highest value. \n Modulo conversion for unsigned 8-bit integers: Modulo conversion for signed 8-bit integers: Clamped conversion is different: \n All underflowing values are converted to the lowest value. \n All overflowing values are converted to the highest value. \n Endianness   # Whenever a type (such as  ) is stored as multiple bytes,   matters: \n Big endian: the most significant byte comes first. For example, the   value 0xABCD is stored as two bytes – first 0xAB, then 0xCD. \n Little endian: the least significant byte comes first. For example, the   value 0xABCD is stored as two bytes – first 0xCD, then 0xAB. \n Endianness tends to be fixed per CPU architecture and consistent across native APIs. Typed Arrays are used to communicate with those APIs, which is why their endianness follows the endianness of the platform and can’t be changed. On the other hand, the endianness of protocols and binary files varies and is fixed across platforms. Therefore, we must be able to access data with either endianness. DataViews serve this use case and let you specify endianness when you get or set a value. Quoting Wikipedia on Endianness : \n Big-endian representation is the most common convention in data networking; fields in the protocols of the Internet protocol suite, such as IPv4, IPv6, TCP, and UDP, are transmitted in big-endian order. For this reason, big-endian byte order is also referred to as network byte order. \n Little-endian storage is popular for microprocessors in part due to significant historical influence on microprocessor designs by Intel Corporation. \n You can use the following function to determine the endianness of a platform. There are also platforms that arrange   (pairs of bytes) with a different endianness than bytes inside words. That is called mixed endianness. Should you want to support such a platform then it is easy to extend the previous code. Negative indices   # With the bracket operator  , you can only use non-negative indices (starting at 0). The methods of ArrayBuffers, Typed Arrays and DataViews work differently: every index can be negative. If it is, it counts backwards from the length. In other words, it is added to the length to produce a normal index. Therefore   refers to the last element,   to the second-last, etc. Methods of normal Arrays work the same way. Offsets, on the other hand, must be non-negative. If, for example, you pass   to: then you get a  . ArrayBuffers   # ArrayBuffers store the data,   (Typed Arrays and DataViews) let you read and change it. In order to create a DataView, you need to provide its constructor with an ArrayBuffer. Typed Array constructors can optionally create an ArrayBuffer for you.  constructor   # The signature of the constructor is: Invoking this constructor via   creates an instance whose capacity is   bytes. Each of those bytes is initially 0. Static   methods   # \n \nReturns   if   is an object and a view for an ArrayBuffer. Only Typed Arrays and DataViews have the required internal property  . That means that this check is roughly equivalent to checking whether   is an instance of a Typed Array or of  . \n  properties   # \n \n \nReturns the capacity of this ArrayBuffer in bytes. \n \n \n \nCreates a new ArrayBuffer that contains the bytes of this ArrayBuffer whose indices are greater than or equal to   and less than  .   and   can be negative (see Sect. “ Negative indices ”). \n \n Typed Arrays   # The various kinds of Typed Array are only different w.r.t. to the type of their elements: \n Typed Arrays whose elements are integers:  ,  ,  ,  ,  ,  ,  \n Typed Arrays whose elements are floats:  ,  \n Typed Arrays versus normal Arrays   # Typed Arrays are much like normal Arrays: they have a  , elements can be accessed via the bracket operator   and they have all of the standard Array methods. They differ from Arrays in the following ways: \n All of their elements have the same type, setting elements converts values to that type. \n They are contiguous. Normal Arrays can have   (indices in the range [0,  ) that have no associated element), Typed Arrays can’t. \n Initialized with zeros. This is a consequence of the previous item:\n \n  creates a normal Array without any elements (it only has holes). \n  creates a Typed Array whose 10 elements are all 0. \n \n \n An associated buffer. The elements of a Typed Array   are not stored in  , they are stored in an associated ArrayBuffer that can be accessed via  . \n Typed Arrays are iterable   # Typed Arrays implement a method whose key is   and are therefore iterable (consult chapter “ Iterables and iterators ” in “Exploring ES6” for more information). That means that you can use the   loop and similar mechanisms in ES6: ArrayBuffers and DataViews are not iterable. Converting Typed Arrays to and from normal Arrays   # To convert a normal Array to a Typed Array, you make it the parameter of a Typed Array constructor. For example: The classic way to convert a Typed Array to an Array is to invoke   on it. This trick works for all Array-like objects (such as  ) and Typed Arrays are Array-like. In ES6, you can use the spread operator ( ), because Typed Arrays are iterable: Another ES6 alternative is  , which works with either iterables or Array-like objects: The Species pattern   # Some methods create new instances that are similar to  . The species pattern lets you configure what constructor should be used to do so. For example, if you create a subclass   of   then the default is that   creates instances of  . If you want it to create instances of  , you can use the species pattern to make that happen. Details are explained in Sect “ The species pattern ” in “Exploring ES6”. ArrayBuffers use the species pattern in the following locations: \n \n Whenever an ArrayBuffer is cloned inside a Typed Array or DataView. \n Typed Arrays use the species pattern in the following locations: \n \n \n \n \n DataViews don’t use the species pattern. The inheritance hierarchy of Typed Arrays   # As you could see in the diagram at the beginning of this post, all Typed Array classes (  etc.) have a common superclass. I’m calling that superclass  , but it is not directly accessible from JavaScript (the ES6 specification calls it  ).   houses all methods of Typed Arrays. Static   methods   # Both static   methods are inherited by its subclasses (  etc.). # This method has the signature: It creates a new Typed Array that is an instance of   (the class on which   was invoked). The elements of that instance are the parameters of  . You can think of   as a custom literal for Typed Arrays: # This method has the signature: It converts the iterable   into an instance of   (a Typed Array). For example, normal Arrays are iterable and can be converted with this method: Typed Arrays are iterable, too: The optional   lets you transform the elements of   before they become elements of the result. Why perform the two steps   and   in one go? Compared to performing the first step separately, via  , there are two advantages: No intermediate Array or Typed Array is needed. When converting a Typed Array to a Typed Array whose elements have a higher precision, the mapping step can make use of that higher precision. To illustrate the second advantage, let’s use   to double the elements of a Typed Array: As you can see, the values overflow and are coerced into the   range of values. If map via  , you can choose the type of the result so that values don’t overflow: According to Allen Wirfs-Brock , mapping between Typed Arrays was what motivated the   parameter of  .  properties   # Indices accepted by Typed Array methods can be negative (they work like traditional Array methods that way). Offsets must be non-negative. For details, see Sect. “ Negative indices ”. # The following properties are specific to Typed Arrays, normal Arrays don’t have them: \n \nReturns the buffer backing this Typed Array. \n \nReturns the size in bytes of this Typed Array’s buffer. \n \nReturns the offset where this Typed Array “starts” inside its ArrayBuffer. \n \nCopies all elements of   to this Typed Array. The element at index 0 of   is written to index   of this Typed Array (etc.).\n \n If   is a normal Array, its elements are converted to numbers who are then converted to the element type   of this Typed Array. \n If   is a Typed Array then each of its elements is converted directly to the appropriate type for this Typed Array. If both Typed Arrays have the same element type then faster, byte-wise copying is used. \n \n \n \nReturns a new Typed Array that has the same buffer as this Typed Array, but a (generally) smaller range. If   is non-negative then the first element of the resulting Typed Array is  , the second   (etc.). If   in negative, it is converted appropriately. \n # The following methods are basically the same as the methods of normal Arrays: \n \nCopies the elements whose indices are between   (including) and   (excluding) to indices starting at  . If the ranges overlap and the former range comes first then elements are copied in reverse order to avoid overwriting source elements before they are copied. \n \nReturns an iterable over [index,element] pairs for this Typed Array. \n \nReturns   if   returns   for every element of this Typed Array. Otherwise, it returns  .   stops processing the first time   returns  . \n \nSet the elements whose indices range from   to   to  . \n \nReturns a Typed Array that contains every element of this Typed Array for which   returns  . In general, the result is shorter than this Typed Array. \n \nReturns the first element for which the function   returns  . \n \nReturns the index of the first element for which   returns  . \n \nIterates over this Typed Array and invokes   for each element. \n \nReturns the index of the first element that strictly equals  . The search starts at  . \n \nConverts all elements to strings and concatenates them, separated by  . \n \nReturns an iterable over the indices of this Typed Array. \n \nReturns the index of the last element that strictly equals  . The search starts at  , backwards. \n \nReturns the length of this Typed Array. \n \nReturns a new Typed Array in which every element is the result of applying   to the corresponding element of this Typed Array. \n \n  is fed one element at a time, together with the result that was computed so far and computes a new result. Elements are visited from left to right. \n \n  is fed one element at a time, together with the result that was computed so far and computes a new result. Elements are visited from right to left. \n \nReverses the order of the elements of this Typed Array and returns  . \n \nCreate a new Typed Array that only has the elements of this Typed Array whose indices are between   (including) and   (excluding). \n \nReturns   if   returns   for at least one element of this Typed Array. Otherwise, it returns  .   stops processing the first time   returns  . \n \nSorts this Typed Array, as specified via  . If   is missing, sorting is done ascendingly, by comparing via the less-than operator ( ). \n \n \n \nReturns an iterable over the values of this Typed Array. \n Due to all of these methods being available for Arrays, you can consult the following two sources to find out more about how they work: \n The following methods are new in ES6 and explained in chapter “ New Array features ” of “Exploring ES6”:  ,  ,  ,  ,  ,  ,  . \n All other methods are explained in chapter “ Arrays ” of “Speaking JavaScript”. \n  constructor   # Each Typed Array constructor has a name that follows the pattern  , where   is one of the element types in the table at the beginning. That means that there are 9 constructors for Typed Arrays:  ,  ,   (element type  ),  ,  ,  ,  ,  ,  . Each constructor has five   versions – it behaves differently depending on how many arguments it receives and what their types are: \n \n \nCreates a new Typed Array whose buffer is  . It starts accessing the buffer at the given   and will have the given  . Note that   counts elements of the Typed Array (with 1–4 bytes each), not bytes. \n \n \n \nCreates a Typed Array with the given   and the appropriate buffer (whose size in bytes is  ). \n \n \n \nCreates a Typed Array whose   is 0. It also creates an associated empty ArrayBuffer. \n \n \n \nCreates a new Typed Array that has the same length and elements as  . Values that are too large or small are converted appropriately. \n \n \n \nTreats   like an Array and creates a new TypedArray that has the same length and elements. Values that are too large or small are converted appropriately. \n \n The following code shows three different ways of creating the same Typed Array: Static   properties   # \n \n \nCounts how many bytes are needed to store a single element: \n \n \n  properties   # \n \nThe same as  . \n DataViews   #  constructor   # \n \nCreates a new DataView whose data is stored in the ArrayBuffer  . By default, the new DataView can access all of  , the last two parameters allow you to change that. \n  properties   # \n \n \nReturns the ArrayBuffer of this DataView. \n \n \n \nReturns how many bytes can be accessed by this DataView. \n \n \n \nReturns at which offset this DataView starts accessing the bytes in its buffer. \n \n \n \nReads a value from the buffer of this DataView. \n \n  can be:  ,  ,  ,  ,  ,  ,  ,  \n \n \n \n \nWrites   to the buffer of this DataView. \n \n  can be:  ,  ,  ,  ,  ,  ,  ,  \n \n \n Browser APIs that support Typed Arrays   # Typed Arrays have been around for a while, so there are quite a few browser APIs that support them. File API   # The file API  lets you access local files. The following code demonstrates how to get the bytes of a submitted local file in an ArrayBuffer.    # In newer versions of  the   API , you can have the results delivered in an ArrayBuffer: Fetch API   # Similarly to  ,  the Fetch API  lets you request resources. But it is based on Promises, which makes it more convenient to use. The following code demonstrates how to download the content pointed to by   as an ArrayBuffer: Canvas   # Quoting the HTML5 specification : The   element provides scripts with a resolution-dependent bitmap canvas, which can be used for rendering graphs, game graphics, art, or other visual images on the fly. The 2D Context of   lets you retrieve the bitmap data as an instance of  : WebSockets   # WebSockets  let you send and receive binary data via ArrayBuffers: Other APIs   # \n \n WebGL  uses the Typed Array API for: accessing buffer data, specifying pixels for texture mapping, reading pixel data, and more. \n \n \n The Web Audio API  lets you  decode audio data  submitted via an ArrayBuffer. \n \n \n Media Source Extensions : The HTML media elements are currently   and  . The Media Source Extensions API enables you to create streams to be played via those elements. You can add binary data to such streams via ArrayBuffers, Typed Arrays or DataViews. \n \n \n Communication with  Web Workers : If you send data to a Worker via  , either the message (which will be cloned) or the transferable objects can contain ArrayBuffers. \n \n \n Cross-document communication : works similarly to communication with Web Workers and also uses the method  . \n \n Extended example: JPEG SOF0 decoder   # The code of the following example is  on GitHub . And you can  run it online . The example is a web pages that lets you upload a JPEG file and parses its structure to determine the height and the width of the image and more. The JPEG file format   # A JPEG file is a sequence of   (typed data). Each segment starts with the following four bytes: \n Marker (two bytes): declares what kind of data is stored in the segment. The first of the two bytes is always 0xFF. Each of the standard markers has a human readable name. For example, the marker 0xFFC0 has the name “Start Of Frame (Baseline DCT)”, short: “SOF0”. \n Length of segment (two bytes): how long is this segment (in bytes, including the length itself)? \n JPEG files are big-endian on all platforms. Therefore, this example demonstrates how important it is that we can specify endianness when using DataViews. The JavaScript code   # The following function   is an abridged version of the actual code; I’ve removed a few error checks to reduce clutter.   receives an ArrayBuffer with the contents of the submitted JPEG file and iterates over its segments. This code uses the following helper functions (that are not shown here): \n  throws an error if the expected value (first parameter) doesn’t match the actual value (second parameter). \n  and   display messages on the page. \n  turns a number into a string with two hexadecimal digits. \n   parses the segment SOF0: More information on the structure of JPEG files: \n “ JPEG: Syntax and structure ” (on Wikipedia) \n “ JPEG File Interchange Format: File format structure ” (on Wikipedia) \n Availability   # Much of the Typed Array API is implemented by all modern JavaScript engines, but several features are new to ECMAScript 6: \n Static methods borrowed from Arrays:  ,  \n Prototype methods borrowed from Arrays:   etc. \n Iterable Typed Arrays \n Support for the species pattern \n An inheritance hierarchy where   is the superclass of all Typed Array classes \n It may take a while until these are available everywhere. As usual, kangax’ “ ES6 compatibility table ” describes the status quo. comments powered by Disqus."},
{"url": "https://2ality.com/2015/09/function-names-es6.html", "title": "The names of functions in ES6", "content": "The names of functions in ES6 esnext dev javascript  Sections for two caveats: “ the name of a function is always assigned at creation ” and “ minification ” The   property of a function contains its name: This property is useful for debugging (its value shows up in stack traces) and some metaprogramming tasks (picking a function by name etc.). Prior to ECMAScript 6 (ES6), this property was already supported by most engines. With ES6, it becomes part of the language standard and is frequently filled in automatically. Constructs that provide names for functions   # The following sections describe how   is set up automatically for various programming constructs. Variable declarations and assignments   # Functions pick up names if they are created via variable declarations: But even with a normal assignment,   is set up properly: With regard to names, arrow functions are like anonymous function expressions: From now on, whenever you see an anonymous function expression, you can assume that an arrow function works the same way. Default values   # If a function is a default value, it gets its name from its variable or parameter: Named function definitions   # Function declarations and function expression are  . This scenario has been supported for a long time: a function definition with a name passes it on to the   property. For example, a function declaration: The name of a named function expression also sets up the   property. Because it comes first, the function expression’s name   takes precedence over other names (e.g. the name   provided via the variable declaration): However, as in ES5, the name of a function expression is only a variable inside the function expression: Methods in object literals   # If a function is the value of a property, it gets its name from that property. It doesn’t matter if that happens via a method definition (line A), a traditional property definition (line B), a property definition with a computed property key (line C) or a property value shorthand (line D). The names of getters are prefixed with  , the names of setters are prefixed with  : Methods in class definitions   # The naming of methods in class definitions is similar to object literals: Getters and setters again have the name prefixes   and  , respectively: Methods whose keys are symbols   # In ES6, the key of a method can be a symbol. The   property of such a method is still a string: \n If the symbol has a description, the method’s name is the description in square brackets. \n Otherwise, the method’s name is the empty string ( ). \n Class definitions   # Remember that class definitions create functions. Those functions also have their property   set up correctly: Default exports   # All of the following statements set   to  : Other programming constructs   # \n \n Generator functions and generator methods get their names the same way that normal functions and methods do. \n \n \n  produces functions whose   is  .  A webkit bug  describes why that is necessary on the web. \n \n \n  produces a function whose   is  : \n \n \n Caveats   # Caveat: the name of a function is always assigned at creation   # Function names are always assigned during creation and never changed later on. That is, JavaScript engines detect the previously mentioned patterns and create functions that start their lives with the correct names. The following code demonstrates that the name of the function created by   is assigned in line A and not changed by the declaration in line B. One could, in theory, check for each assignment whether the right-hand side evaluates to a function and whether that function doesn’t have a name, yet. But that would incur a significant performance penalty. Caveat: minification   # Function names are subject to minification, which means that they will usually change in minified code. Depending on what you want to do, you may have to manage function names via strings (which are not minified) or you may have to tell your minifier what names not to minify. Changing the names of functions   # These are the attributes of property  : The property not being writable means that you can’t change its value via assignment: The property is, however, configurable, which means that you can change it by re-defining it: If the property   already exists then you can omit the descriptor property  , because missing descriptor properties mean that the corresponding attributes are not changed. If the property   does not exist yet then the descriptor property   ensures that   remains configurable (the default attribute values are all   or  ). The function property   in the spec   # \n The spec operation   sets up the property  . Search for its name in the spec to find out where that happens.\n \n The third parameter of that operations specifies a name prefix. It is used for:\n \n Getters and setters  (prefixes   and  ) \n  (prefix  ) \n \n \n \n \n Anonymous function expressions not having a property   can be seen by looking at  their runtime semantics :\n \n The names of named function expressions are set up via  . That operation is not invoked for anonymous function expressions. \n The names of function declarations are set up when entering a scope (they are hoisted!). \n \n \n When an arrow function is created , no name is set up, either (  is not invoked). \n Suport for the   property in engines   # In Kangax’ ES6 table , you can see that no engine currently fully supports  , not even Babel. Thus, the code in this blog post shows how things  , not how they are in any single engine.  “ Callable entities in ECMAScript 6 ” in “Exploring ES6”. comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/distributed-social-networks.html", "title": "Distributed social networks, an alternative to Facebook and Twitter", "content": "Distributed social networks, an alternative to Facebook and Twitter computers social federated social networks The details Facebook Twitter 1 Twitter 2 \n      The whole DSN is run via several servers. Just like there are many email servers out there. There is no single server that can shut down and render the whole network useless.\n     \n      The server is part of the user name. Again, similar to email.\n     \n       The protocols are open, meaning that it’s easy to write a client. Similar to email. Compare that to the fact that Twitter is now saying they don’t want third-party clients, any more  [1] . And to the fact that Facebook never had complete third-party clients.\n     \n      DSNs usually make it easy to migrate data, either to another server or to a backup.\n     \n      Many DSNs offer Facebook and Twitter integration. For example, automatic cross-posting so that an entry that you write on the DSN will also be sent to Twitter.\n     \n Wikipedia article Diaspora, a distributed social network Diaspora \nI like how it works, very intuitive, a bit like a slightly more ugly version of Google+ (which I’ve always found to be less confusing than Facebook). To make a backup or to move to another server, Diaspora lets you export your data (posts, contacts, etc.) and your photos.\n \nIf you want to follow me, use the search box in the top right corner to look for “Axel Rauschmayer”. Once found, there will be a drop-down menu “Add contact” where you can choose what   (group) to add me to.\n \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/jsreload.html", "title": "Reload a web browser when a file changes (Node.js, Grunt, Mac)", "content": "Reload a web browser when a file changes (Node.js, Grunt, Mac) jsshell dev nodejs javascript JSReload \nThis blog post explains how to use Node.js to reload a tab in Safari whenever a file changes. Alas, this solution only works on a Mac, because it relies on AppleScript to remotely control Safari. You can download it as project  JSReload  on GitHub.\n\n \n\n The problem The solutions A shell script (powered by Node.js) that watches a directory. It reloads Safari whenever one of the .html or .css files in the directory changes.\n    In some ways that’s better than TextMate, because you can edit a CSS file and the corresponding HTML file is reloaded in Safari.\n     A Grunt script that serves a different purpose: It watches a directory with AsciiDoc (.asc) files. When a file changes, that file is compiled to HTML and then Safari is reloaded.\n     Shell script [1] \nIt is unfortunate that we have to resort to JavaScript inside the AppleScript, but that seems to be the only way to reload. A pure AppleScript solution is to set the URL of the tab to what it already is. That also reloads, but then the viewport jumps to the beginning of the file. With a true reload, the current viewport position is preserved.\n\n Grunt Grunt Other browsers \n     Remote Control add-on for Firefox \n     Remote debugging protocol of the  Chrome Developer Tools \n Auto Reload Live.js Conclusion: an app wish \n     HTML: Watch all .html and .css files. If one of them changes, reload the browser window. \n     AsciiDoc: Watch all .asc files. If one of them changes, convert it to an HTML file and reload the browser window. \n     Markdown: Watch all .md, .mdown and .markdown files. If one of them changes, translate it to HTML and pipe the result to the browser window. \n vote for it Reference Write your shell scripts in JavaScript, via Node.js comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/instanceof-object.html", "title": "What object is not an instance of Object?", "content": "What object is not an instance of Object? dev javascript jslang \n Show answer \n \n What do we know about  ? v is an object [1] \n    Remember that JavaScript has two kinds of values: primitives and objects  [2] . Primitives are read-only – you can try to create or change properties, but those operations have no effect:\n v is not an instance of Object Finding an object without a prototype References Improving the JavaScript typeof operator JavaScript values: not everything is an object comments powered by Disqus."},
{"url": "https://2ality.com/2012/08/zen-of-python.html", "title": "The Zen of Python", "content": "The Zen of Python programming dev python \n     Go to  PEP (Python Enhancement Request) 20  on the web.\n     \n     Type the following in a Python command line:\n \n     \n The Zen of Python \n     (13) seems like a response to the Perl motto “ There’s more than one way to do it ”. \n     (14) Guido van Rossum is Dutch. \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/09/empty-regexp.html", "title": "The empty regular expression", "content": "The empty regular expression dev javascript jslang regexp The empty regular expression RegExp.prototype The regular expression that matches nothing Related blog post \n     JavaScript: an overview of the regular expression API \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/09/javascript-glass-half-full.html", "title": "JavaScript: the glass is half full", "content": "JavaScript: the glass is half full dev javascript jslang tragically important Four factors Is it freely available? Is it an elegant programming language? Is it useful in practice? That is: Can I write cross-platform GUI applications? Does it have enough libraries? Does it have good tools, especially a good Integrated Development Environment (IDE)? Is JavaScript freely available? ECMA-262 [1] Is JavaScript elegant? \nBut JavaScript has also many elegant parts. Brendan Eich’s  favorites  are:\n\n First-class functions Closures Prototypes Object initialisers and array initialisers [2] [3] [4] \nLanguage compatibility between JavaScript engines used to be a problem, but isn’t, any more, partly thanks to the  test262 suite  that tests engines for ECMAScript conformance. In contrast, browser and DOM differences still are a challenge. That’s why it is normally best to rely on frameworks for hiding those differences.\n \nWhether or not you accept CoffeeScript as a way of increasing JavaScript’s elegance is a matter of taste. For me, JavaScript is not broken enough to warrant a different syntax and an intermediate compilation step. ECMAScript.next might eventually play a role that is similar to CoffeeScript: It will fix most quirks and provide more syntactic convenience. Classes  [5]  are one example – a feature that has been field-tested via CoffeeScript. But ECMAScript.next will be a true superset of JavaScript and there will be no need for compilation on modern browsers.\n\n Is JavaScript useful? AppJS node-webkit PhoneGap \nWhen it comes to libraries, there is still an unfortunate schism between client-side JavaScript and server-side JavaScript. On the server side, things are already close to ideal: The  Node.js package manager  (npm) offers both ease of use and a tremendous selection of useful libraries. I’m hoping that we’ll ultimately have an npm-like solution that works for both client and server. But for that to happen, client and server must share more system APIs.\n \nJavaScript’s usefulness is helped by two recent technologies: Both JSON and NoSQL databases (such as  MongoDB  and  CouchDB ). Those databases usually tightly integrate JavaScript and JSON.\n \nLastly, there is shell scripting, which is practically its own platform. It solves problems that typically involve reading, creating and/or transforming files. Shell scripts are often throw-away code. It helps if you are fluent in the language that you write them in. Therefore, Bash and similar languages are not a good option for most people. It also helps if the language has many libraries (parsing file formats, manipulating images, etc.). JavaScript has become viable in this area, thanks to Node.js  [6] .\n\n Does JavaScript have good tools? \nIn the IDE space, JavaScript still has catching up to do. The gold standard for free IDEs is the Java-centric Eclipse. JavaScript being more dynamic than Java, more work and a different mindset are necessary to create an IDE. One promising new attempt is  Adobe Brackets . For me, a good IDE is essential for using a language to its fullest potential. After having gotten used to the comforts of Eclipse, I found it difficult to leave Java behind, even though it is not a very succinct language.\n\n The future [7] [5] \nGiven that it will be years until we can rely on ECMAScript.next being there in browsers, I expect people to develop in ECMAScript.next on a modern browser, but to deploy two versions: An ECMAScript.next version for modern browsers and a version compiled to ECMAScript 3 for older browsers. For simplicity’s sake, one could even deploy only the ECMAScript 3 version. The similarities to CoffeeScript are obvious, especially in the latter case. Hence, some of its techniques and work flows can probably be adopted.\n\n Conclusion described References ECMAScript: ES.next versus ES 6 versus ES Harmony JavaScript variable scoping and its pitfalls Iterating over arrays and objects in JavaScript Lightweight JavaScript inheritance APIs ECMAScript.next: classes Write your shell scripts in JavaScript, via Node.js Harmony proposal: modules comments powered by Disqus."},
{"url": "https://2ality.com/2012/09/expressions-vs-statements.html", "title": "Expressions versus statements in JavaScript", "content": "Expressions versus statements in JavaScript dev javascript jslang \nThis blog post looks at a syntactic distinction that is unfortunately quite important in JavaScript: the difference between expressions and statements.\n\n \n\n Statements and expressions Similar kinds of statements and expressions If statement versus conditional operator Semicolon versus comma operator Expressions that look like statements Object literal versus block \n     A block: a sequence of statements in curly braces.\n     \n     A label: you can prefix any statement with a label. Here the label is  . \n     A statement: the expression statement  .\n     \n [1] \n \nIt might surprise you that JavaScript has blocks that can exist on their own (as opposed to being part of a loop or an if statement).\nThe following code illustrates one use case for such blocks: You can give them a label and break from them.\n Function expression versus function declaration Using object literals and function expressions as statements eval Immediately invoked function expressions (IIFEs) [2] Concatenating IIFEs [3] Related posts What is {} + {} in JavaScript? The void operator in JavaScript Automatic semicolon insertion in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/09/javascript-quine.html", "title": "A quine in JavaScript", "content": "A quine in JavaScript dev javascript jslang Wikipedia following example Getting the source code A function expression that refers to itself An Immediately Invoked Function Expression (IIFE) [1] Adding the missing characters Another way of writing the IIFE Reference Expressions versus statements in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/09/web-audio-api.html", "title": "Support for the Web Audio API is growing", "content": "Support for the Web Audio API is growing dev html5 javascript clientjs [1] \n     Firefox: the Audio Data API is now  deprecated  on Firefox and the Web Audio API will be supported soon. Quoting “ Web Audio In Firefox ” by Robert O’Callahan:\n         \n            At some point we will revisit MediaStreams Processing to get the features that Web Audio is missing, e.g., seamless stitching together of an audio and video playlist from a series of clips. That is lower priority.\n         \n     \n     Safari 6:  supported , including  iOS 6 .\n     \n on Android [2] Turning the Web Up to 11 References Web audio APIs and the low-level approach Why the Angry Birds webapp needs Flash comments powered by Disqus."},
{"url": "https://2ality.com/2015/04/node-es6-transpiled.html", "title": "Using transpiled ES6 on Node.js", "content": "Using transpiled ES6 on Node.js esnext dev javascript  Please read Sect. “ Node.js setup: Statically transpiled ES6 via Babel ” in “Setting up ES6”. This blog post explains how to use ES6 on Node.js by transpiling it to ES5 via Babel. A  previous blog post  showed how to dynamically transpile ES6 at runtime (also via Babel). That is more convenient and should work for most projects, but occasionally you may want a simpler and faster setup for your runtime environment. Installation   # Installation consists of downloading the repository  node-es6-demo  and executing the following commands, which install all npm packages that the repository depends on: The repo has the following structure: Source maps   # Source maps help whenever a language is compiled to JavaScript. Compiling source code to source code is also called  . Examples of transpilation include: \n Minification (normal JavaScript to minified JavaScript) \n CoffeeScript \n ECMAScript 6 (ES6 to ES5) \n A source map is a file that accompanies the transpilation result and maps the lines of the result to lines in the transpiled files. This information can be used by error messages and debuggers to refer to lines in the original instead of the transpilation result. There are two ways to let tools know about a source map: Either the transpilation output refers to the source map file in its last line or it embeds the file’s contents in that line. For more information on source maps consult the article “ Introduction to JavaScript Source Maps ” by Ryan Seddon on HTML5 Rocks. The gulp file   # I am handling transpilation via the build tool  . It is configured via a file   in a project’s directory. Ours looks as follows: In order to make gulp do something you invoke it like this: Our gulpfile defines two tasks: \n  (line (A)) transpiles the ES6 files in   to ES5 files in  . \n  (line (D)) continuously watches the ES6 files and transpiles them whenever they are changed. \n If you call   without any arguments, the default task (line (E)) is triggered. In this file, the default task is  . Source maps are created due to the code in line (B) and line (C). If you omit the path in line (C), the source map is inlined in the output file (vs. stored in a separate file). Hopefully you now have a rough understanding of how the gulp file works. For open questions, consult  the gulp documentation . Transpilation   # The file   contains the ES6 code of the Node.js application: Alas, Node.js does not come with built-in support for source maps. But it can be enabled via a library, e.g. the npm package  . That library needs to be called at least once in an app. The first two lines in the previous code takes care of that. They also demonstrate that you can use any npm-installed package via ES6 syntax. The following gulp invocation transpiles  . Alternatively, you can use   or   to continuously watch the ES6 files and transpile them whenever they are changed. The results of the transpilation are in the directory  : You can see the ES5 version of   and the source map file  . The contents of the former file are: Running the transpiled code   # The transpiled code is a normal ES5 Node.js app and is run as usual: It produces the following output. Note that, thanks to the source map, the stack trace reports that the exception is thrown in line 6. That is the correct line in the ES6 file. comments powered by Disqus."},
{"url": "https://2ality.com/2015/04/deploying-es6.html", "title": "Deploying ECMAScript 6", "content": "Deploying ECMAScript 6 esnext dev javascript This blog post describes the options you have for deploying ECMAScript 6 in current JavaScript environments. It is selective w.r.t. the amount of tools it covers. If you want a comprehensive list of tools, I suggest you look at Addy Osmani’s “ ECMAScript 6 Tools ”. Consult the blog post “ Using ECMAScript 6 today ” for an overview of ES6 features. Using ECMAScript 6 today   # What options do you have for using ECMAScript 6 today? ECMAScript 6 features are continually appearing in engines. You can look up which ones are already supported where in Kangax’ “ ECMAScript 6 compatibility table ”. I’d expect first JavaScript engines to fully support ES6 in late 2015 or early 2016. It will take longer until all current engines do so. Especially if you take support for legacy engines into consideration, compiling ES6 to ES5 will be the only viable option for using ES6 for quite a while. Compiling from source code to source code is also called  . You can transpile ES6 either before deployment (statically) or at runtime (dynamically). The next section explains how that works, later sections describe other ES6 tools and libraries. The nice thing about ES6 is that it is a superset of ES5, which means that all of your ES5 code bases are already valid ES6. This helps tremendously with adopting ES6-specific features, because you can do so incrementally. Using ECMAScript 6 natively   # As soon as the first engine fully supports ES6 and until all non-ES6 engines go away, a hybrid approach could be used for client-side apps: \n The server has two versions of each file: the native ES6 version and its transpilation, an ES5 version. \n When the web app starts, feature detection is used to check whether ES6 is fully supported. If it is, the ES6 version of the app is used. Otherwise, the ES5 version is used. How exactly this process is going to work is not clear yet, no best practices have been established, so far. \n npm may eventually support two versions of the same module, which would enable you to deliver libraries as both ES5 and ES6 for Node.js, io.js and client-side module systems that are based on npm. Transpilation tools   # There are three essential choices that you have to make for transpilation: \n A transpiler (for your code) \n A package manager (to install existing libraries) \n A module system (for the complete app) \n Note that the choices are not completely independent, not every module system works with every package manager etc. The next sections explain each of these choices in more detail. Choosing a transpiler   # A transpiler compiles your ES6 code to ES5. Popular choices are: \n TypeScript : Is basically ECMAScript 6 plus optional type annotations. \n Traceur : is an ES6 transpiler by Google, the first popular one. Pronounced French, /tʁa.sœʁ/; an English approximation is “truh-SIR” ( source ,  listen to native French speakers pronounce this word ). \n Babel : is a newer ES6 transpiler that whose popularity has grown tremendously recently. Babel supports React’s JSX syntax in addition to ES6. Pronounced “babble”. \n You can transpile the code either: \n Statically (before deployment) \n Dynamically (at runtime) \n # As a build step, TypeScript, Traceur and Babel let you produce ES5 code in the following module formats. You can either invoke them directly or use a build tool (grunt, gulp, broccoli, etc.). \n AMD \n CommonJS \n ES6 module loader API: The ES6 code is transpiled to ES5 code that uses this API via  a polyfill . This format is not supported by TypeScript. \n In browsers, such ES5 modules are loaded via one of the module systems described later.\nOn Node.js, you can use the built-in module system (other options exist, e.g. webpack and the ES6 Module Loader Polyfill). # In browsers, you transpile dynamically via a library plus a custom  . This option exists for  Traceur  and  Babel . For Node.js, Babel has tools for on-the-fly compilation. These are described in  a separate blog post . Choosing a package manager   # You need a package manager for installing third-party libraries. These are three popular ones: \n npm  (CommonJS modules): is a package manager that was originally created for Node.js, but has grown in popularity for client-side development thanks to module packaging and loading tools such as browserify and webpack. \n Bower  (CommonJS or AMD modules): is a package manager for client-side code. \n jspm : is a package manager for SystemJS (see next bullet list). It can install modules from a variety of sources, including GitHub and npm. One key feature of jspm is that external modules can also be written in ES6 (and will be transpiled), not just your own modules. \n Choosing a module system   # Module systems bring support for modules to ES5 browsers (Node.js has a built-in module system). That way, you can build your app out of modules – your own and library modules. Popular module systems are: \n RequireJS : is a loader for AMD modules, which can be statically created via TypeScript, Traceur or Babel.   (based on Traceur and Babel) enable it to load ES6 modules. \n Browserify : packages CommonJS modules (including ones installed via npm) so that they can be loaded in browsers. Supports ES6 modules via   (plugins) based on Traceur and Babel. \n webpack : a packager and loader for either CommonJS modules (including ones installed via npm) or AMD modules (including ones installed via Bower). Supports ES6 modules via   (plugins) based on Traceur and Babel. \n SystemJS : A module system based on the ES6 Module Loader Polyfill that supports ES6 modules and the ES5 module formats CommonJS, AMD and “ES6 module loader API”. \n Example setups   # Separate blog posts describe three example setups: \n Writing client-side ES6 with webpack  (browsers, webpack, static transpilation) \n Using the ES6 transpiler Babel on Node.js  (Node.js, Babel, dynamic transpilation) \n Using transpiled ES6 on Node.js  (Node.js, Babel, gulp, static transpilation) \n Other useful ES6 tools and libraries   # \n \n Test tools (such as Jasmine and mocha) can mostly be used as is, because they work with the transpiled code and don’t have to understand the original ES6 code.  Babel’s documention  has information on how to use it with various test tools. \n \n \n The following linters all support ES6, but to varying degrees: \n \n JSLint  (focus: enforcing coding practices) \n JSHint  (focus: enforcing coding practices) \n ESLint  (focus: letting people implement their own style rules) \n JSCS  (focus: enforcing code style) \n \n \n \n Shims/polyfills enable you to use much of the ECMAScript 6 standard library in ES5 code: \n \n es6-shim \n Core.js  (used by Babel) \n \n \n \n ES6 parsers: \n \n Esprima \n Acorn \n \n \n ES6 REPLs   # There are many REPLs (command lines) out there for interactively playing with ES6. The obvious choices are the interactive online playgrounds of the following projects: \n TypeScript Playground \n Babel REPL \n Traceur Transcoding Demo \n Additionally, Babel brings ES6 support to the Node.js REPL via its   tool . What ES6 features can be transpiled?   # ECMAScript 6 has three kinds of features: \n Better syntax for existing features \n New functionality in the standard library \n Completely new features \n Better syntax for existing features   # For example: \n Classes \n Modules \n These can be relatively easily compiled to ES5. For example, this is an ES6 class: In  , Babel produces nicer ES5 code, at the cost of not being completely faithful to ES6 semantics. This is the previous code, transpiled in loose mode: New functionality in the standard library   # For example: \n New methods for strings, arrays \n Promises \n Maps, Sets \n These can be provided via a library. Much of that functionality (such as  ) is even useful for ES5. A later section lists a few such libraries. Completely new features   # These features can never be transpiled completely faithfully. But some of them have reasonable simulations, for example: \n  and  : are transpiled to   plus renaming where necessary, to avoid name clashes. That is, immutability is usually not guaranteed. \n Symbols: transpiled to objects with unique IDs that are used as property keys whenever the bracket operator coerces them to strings. Additionally, some property-enumerating functions (such as  ) have to be patched to ignore property keys coming from symbols. \n Generators: are compiled to state machines, which is a complex transformation. \n WeakMaps and WeakSets (keys are stored in values, which works, because WeakMaps and WeakSets don’t allow you to clear them or to iterate over their entries). \n Others are impossible to transpile (in a straightforward manner): \n Proxies \n Subclassable built-in constructors (e.g.   and  ) \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/03/babel-on-node.html", "title": "Using the ES6 transpiler Babel on Node.js", "content": "Using the ES6 transpiler Babel on Node.js esnext dev javascript  Please read Sect. “ Node.js setup: Dynamically transpiled ES6 via Babel ” in “Setting up ES6”. This blog post explains how to use  the ES6 transpiler Babel  with Node.js. You can  download the code shown in this post  on GitHub. For further information on ECMAScript 6, consult the ebook “ Exploring ES6 ”. Warning: The approach explained in this post is convenient for experiments and development. But it uses on-the-fly transpilation, which may be too slow for your production code. Then you can transpile as a build step ( as explained in the Babel documentation ). Running normal Node.js code via Babel   # The npm package   brings Babel support to Node.js: This package contains the shell script  , which is a Babel-ified version of  . It compiles everything from ES6 to ES5 that is run or required. For example, you can start a REPL via the following shell command: In the REPL, you can use ES6:  also lets you run Node.js scripts such as the following one. The following shell command runs  : The package   has many more features, which are all  documented  on the Babel website. For example, from within a normal Node module, you can install a “require hook”, which compiles all required modules via Babel (except, by default, modules in  ). Running Jasmine unit tests via Babel   # Another npm package,  babel-jest , is a preprocessor for  the Jasmine-based unit testing tool Jest . One way to install babel-jest is by mentioning it in the   of your  : Afterwards, you only need to execute the following command inside the directory of   and both babel-jest and a command line interface (CLI) for Jest will be installed. The configuration options for Jest are  documented  on its website. I have used   to specify that the tests are inside the directory   (the default is  ). Let’s add the following test file to that directory: Because we have specified   in  , we can run all tests inside   via the following command: comments powered by Disqus."},
{"url": "https://2ality.com/2015/04/numbers-math-es6.html", "title": "New number and Math features in ES6", "content": "New number and Math features in ES6 esnext dev javascript This blog post describes the new number and   features of  ECMAScript 6 . Overview   # You can now specify integers in binary and octal notation: The global object   gained a few new properties. Among others: \n  for comparing floating point numbers with a tolerance for rounding errors. \n A method and constants for determining whether a JavaScript integer is   (within the signed 53 bit range in which there is no loss of precision). \n New integer literals   # ECMAScript 5 already has literals for hexadecimal integers: ECMAScript 6 brings two new kinds of integer literals: \n \n Binary literals have the prefix   or  : \n \n \n \n Octal literals have the prefix   or   (yes, that’s a zero followed by the capital letter O; you’ll be fine if you use the first variant): \n \n \n Remember that the method   can be used to convert numbers back: Use case for octal literals: Unix-style file permissions   # In the Node.js  file system module , several functions have the parameter  . Its value is used to specify file permissions, via an encoding that is a holdover from Unix: \n Permissions are specified for three categories of users:\n \n User: the owner of the file \n Group: the members of the group associated with the file \n All: everyone \n \n \n Per category, the following permissions can be granted:\n \n r (read): the users in the category are allowed to read the file \n w (write): the users in the category are allowed to change the file \n x (execute): the users in the category are allowed to run the file \n \n \n That means that permissions can be represented by 9 bits (3 categories with 3 permissions each): The permissions of a single category of users are stored in 3 bits: That means that octal numbers are a compact representation of all permissions, you only need 3 digits, one digit per category of users. Two examples: \n 755 = 111,101,101: I can change, read and execute; everyone else can only read and execute. \n 640 = 110,100,000: I can read and write; group members can read; everyone can’t access at all. \n  and the new integer literals   #  has the following signature: It provides special support for the hexadecimal literal notation – the prefix   (or  ) of   is removed if: \n  is missing or 0. Then   is set to 16. \n  is already 16. \n For example: In all other cases, digits are only parsed until the first non-digit:  does not have special support for binary or octal literals! If you want to parse these kinds of literals, you need to use  : Alternatively, you can also remove the prefix and use   with the appropriate radix: New   constructor properties   # This section describes new properties that the constructor   has picked up in ECMAScript 6. Previously global functions   # Four number-related functions are already available as global functions and have been added (with no or little modifications) to  , as methods:  ,  ,   and  . # Is   an actual number (neither   nor   nor  )? The advantage of this method is that it does not coerce its parameter to number (whereas the global function does): # Is   the value  ? Making this check via   is hacky.   is the only value that is not equal to itself: Therefore, this expression is used to check for it Using   is more self-descriptive:  also has the advantage of not coercing its parameter to number (whereas the global function does): # The following two methods work exactly like the global functions with the same names. They were added to   for completeness sake; now all number-related functions are available there. \n \n \n Number.EPSILON   # Especially with decimal fractions, rounding errors can become a problem in JavaScript. For example, 0.1 and 0.2 can’t be represented precisely, which you notice if you add them and compare them to 0.3 (which can’t be represented precisely, either).  specifies a reasonable margin of error when comparing floating point numbers. It provides a better way to compare floating point values, as demonstrated by the following function.    # JavaScript has only floating point numbers (doubles). Accordingly, integers are simply floating point numbers without a decimal fraction.  returns   if   is a number and does not have a decimal fraction. Safe Integers   # JavaScript numbers have only enough storage space to represent 53 bit signed integers. That is, integers   in the range −2^53^ <   < 2^53^ are  . What exactly that means is explained momentarily. The following properties help determine whether a JavaScript integer is safe: \n \n \n \n The notion of   centers on how mathematical integers are represented in JavaScript. In the range (−2^53^, 2^53^) (excluding the lower and upper bounds), JavaScript integers are  : there is a one-to-one mapping between them and the mathematical integers they represent. Beyond this range, JavaScript integers are  : two or more mathematical integers are represented as the same JavaScript integer. For example, starting at 2^53^, JavaScript can represent only every second mathematical integer: Therefore, a safe JavaScript integer is one that unambiguously represents a single mathematical integer. # The two   properties specifying the lower and upper bound of safe integers could be defined as follows:  determines whether a JavaScript number is a safe integer and could be defined as follows: For a given value  , this function first checks whether   is a number and an integer. If both checks succeed,   is safe if it is greater than or equal to   and less than or equal to  . # How can we make sure that results of arithmetic computations are correct? For example, the following result is clearly not correct: We have two safe operands, but an unsafe result: The following result is also incorrect: This time, the result is safe, but one of the operands isn’t: Therefore, the result of applying an integer operator   is guaranteed to be correct only if all operands and the result are safe. More formally: implies that   is a correct result. # \n “ Clarify integer and safe integer resolution ”, email by Mark S. Miller to the es-discuss mailing list. \n Math   # The global object   has several new methods in ECMAScript 6. Various numerical functionality   # # Returns the sign of   as   or  . Unless   is either   or zero; then   is returned [1] . # Removes the decimal fraction of  . # Returns the cube root of   (∛x). Using 0 instead of 1 with exponentiation and logarithm   # A small fraction can be represented more precisely if it comes after zero. I’ll demonstrate this with decimal fractions. (Internally, JavaScript’s floating point numbers are base 2, but externally you see them as base 10. The same basic principles w.r.t. precision apply in either case.) Floating point numbers with base 10 are represented as   × 10^ ^. If a zero comes before the dot then small fractions have less significant digits. For example: \n (A) 0.000000234 = 2.34 × 10^−7^. Significant digits: 234 \n (B) 1.000000234 = 1.000000234 × 10^0^. Significant digits: 1000000234 \n Precision-wise, the exponent is not an issue here, the significant digits and the capacity of the mantissa are. That’s why (A) gives you higher precision than (B). You can see this in the following interaction: The first number (1 × 10^−16^) registers as different from zero, while the same number added to 1 registers as 1. # Returns  . The inverse of  . Therefore, this method provides higher precision whenever   has results close to 1. You can see the difference between the two in the following interaction: The former is the better result, which you can verify by using a library (such as  decimal.js ) for floating point numbers with arbitrary precision (“bigfloats”): # Returns  . The inverse of  . Therefore, this method lets you specify parameters that are close to 1 with a higher precision. We have already established that  . Therefore, it is no surprise that the following two calls of   produce the same result: In contrast,   produces different results: Logarithms to base 2 and 10   # # Computes the logarithm to base 2. # Computes the logarithm to base 10. Support for compiling to JavaScript   # Emscripten  pioneered a coding style that was later picked up by  asm.js : The operations of a virtual machine (think bytecode) are expressed in static subset of JavaScript. That subset can be executed efficiently by JavaScript engines: If it is the result of a compilation from C++, it runs at about 70% of native speed. # Rounds   to a 32 bit floating point value ( ). Used by asm.js to tell an engine to internally use a   value. # Multiplies the two 32 bit integers   and   and returns the lower 32 bits of the result. This is the only 32 bit basic math operation that can’t be simulated by using a JavaScript operator and coercing the result back to 32 bits. For example,   could be implemented as follows: In contrast, multiplying two large 32 bit integers may produce a double that is so large that lower bits are lost. Bitwise operations   # \n \n \nCounts the leading zero bits in the 32 bit integer  . \n \n \n Trigonometric methods   # \n \n \nComputes the hyperbolic sine of  . \n \n \n \nComputes the hyperbolic cosine of  . \n \n \n \nComputes the hyperbolic tangent of  . \n \n \n \nComputes the inverse hyperbolic sine of  . \n \n \n \nComputes the inverse hyperbolic cosine of  . \n \n \n \nComputes the inverse hyperbolic tangent of  . \n \n \n \nComputes the square root of the sum of squares of its arguments. \n \n While that is something that you normally don’t see, that means that   produces the result   and   produces the result  .  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/06/announcing-exploring-es6.html", "title": "Announcing “Exploring ES6”", "content": "Announcing “Exploring ES6” esnext book exploring es6 I’m glad to announce that the first version of my book “ Exploring ES6 ” is finally finished! It was much more work than I anticipated – the PDF has over 460 pages! I’m really happy with how it turned out. The complete contents of the book are  available online , for free.  The ebook version  (PDF, EPUB, MOBI) costs about $30 (depending on the VAT in your country, you can pay more to support my work).  is a  : you can buy it now and will receive free updates until it is completely done. That may take a while, possibly until 2016. Once the book is done, there will also be a print version. New material will often be published on 2ality, before it is added to the book. For all further information on ”Exploring ES6”, please consult  its website . comments powered by Disqus."},
{"url": "https://2ality.com/2015/03/es6-generators.html", "title": "ES6 generators in depth", "content": "ES6 generators in depth esnext dev javascript iteration  Please read chapter “ Generators ” in “Exploring ES6”. This blog post is part of a series on iteration in ES6: Iterables and iterators in ECMAScript 6 ES6 generators in depth Generators, a new feature of ECMAScript 6  [1] , are functions that can be paused and resumed. This helps with many applications: iterators, asynchronous programming, etc. This blog post explains how generators work and gives an overview of their applications. The following GitHub repository contains the example code:  generator-examples Overview   # Two important applications of generators are: \n Implementing iterables \n Blocking on asynchronous function calls \n The following subsections give brief overviews of these applications, more thorough explanations are provided later (plus discussions of other topics). Implementing iterables via generators   # The following function returns an iterable over the properties of an object, one   pair per property: How exactly   works is explained later. It is used like this: Blocking on asynchronous function calls   # In the following code, I use  the control flow library co  to asynchronously retrieve two JSON files. Note how, in line (A), execution blocks (waits) until the result of   is ready. That means that the code looks synchronous while performing asynchronous operations.  retrieves the file pointed to by  . Its implementation is shown later. I’ll also explain how   works. What are generators?   #  are functions that can be paused and resumed, which enables a variety of applications. As a first example, consider the following generator function whose name is  : Two things distinguish   from a normal function declaration: \n It starts with the “keyword”  . \n It is paused in the middle via  . \n Calling   does not execute it. Instead, it returns a so-called   that lets us control  ’s execution:  is initially suspended at the beginning of its body. The method   continues the execution of  , until the next  : As you can see in the last line,   also returns an object. Let’s ignore that for now. It will matter once we look at generators as iterators.  is now paused in line (A). If we call   again, execution resumes and line (B) is executed: Afterwards, the function is finished, execution has left the body and further calls of   have no effect. Ways of creating generators   # There are four ways in which you can create generators: \n Via a generator function declaration: \n \n \n Via a generator function expression: \n \n \n Via a generator method definition in an object literal: \n \n \n Via a generator method definition in a class definition (which can be a class declaration or a class expression  [2] ): \n \n Roles played by generators   # Generators can play three roles: \n Iterators (data producers): Each   can return a value via  , which means that generators can produce sequences of values via loops and recursion. Due to generator objects implementing the interface    [3] , these sequences can be processed by any ECMAScript 6 construct that supports iterables. Two examples are:   loops and the spread operator ( ). \n \n Observers (data consumers):   can also receive a value from   (via a parameter). That means that generators become data consumers that pause until a new value is pushed into them via  . \n \n Coroutines (data producers and consumers): Given that generators are pausable and can be both data producers and data consumers, not much work is needed to turn them into coroutines (cooperatively multitasked tasks). \n The next sections provide deeper explanations of these roles. Generators as iterators (data production)   # As explained before, generator objects can be data producers, data consumers or both. This section looks at them as data producers, where they implement both the interfaces   and   (shown below). Note that that means that the result of a generator function is both an iterable and an iterator. The full interface of generator objects will be shown later. A generator function produces a sequence of values via  , a data consumer consumes thoses values via the iterator method  . For example, the following generator function produces the values   and  : This interaction shows how to retrieve the yielded values via the generator object  : Ways of iterating over a generator   # As generator objects are iterable, ES6 language constructs that support iterables can be applied to them. The following three ones are especially important. First, the   loop: Second, the spread operator ( ), which turns iterated sequences into elements of an array (consult  [4]  for more information on this operator): Third, destructuring  [5] : Returning from a generator   # The previous generator function did not contain an explicit  . An implicit   is equivalent to returning  . Let’s examine a generator with an explicit  : The returned value shows up in the last object returned by  , whose property   is  : However, most constructs that work with iterables ignore the value inside the   object: , an operator for making recursive generator calls, does consider values inside   objects. It is explained later. Example: iterating over properties   # Let’s look at an example that demonstrates how convenient generators are for implementing iterables. The following function,  , returns an iterable over the properties of an object: This function enables you to iterate over the properties of an object   via the   loop: For comparison – an implementation of   that doesn’t use generators is much more complicated: Recursion via   (for output)   # The   operator lets you call another generator from within a generator, as if you made a function call. For now, I only explain how this works if both generators produce output, I’ll later explain how things work if input is involved. How can one generator recursively call another generator? Let’s assume you have written a generator function  : How would you call   from another generator function  ? The following approach does not work! Calling   returns an object, but does not actually execute  . That’s why ECMAScript 6 has the operator   for making recursive generator calls: Internally,   works roughly as follows: The operand of   does not have to be a generator object, it can be any iterable: # Most constructs that support iterables ignore the value included in the end-of-iteration object (whose property   is  ). Generators provide that value via  . The result of   is the end-of-iteration value: If we want to get to line (A), we first must iterate over all values yielded by  : # Iterating over a tree with recursion is simple, writing an iterator for a tree with traditional means is complicated. That’s why generators shine here: they let you implement an iterator via recursion. As an example, consider the following data structure for binary trees. It is iterable, because it has a method whose key is  . That method is a generator method and returns an iterator when called. The following code creates a binary tree and iterates over it via  : You can only   in generators   # A significant limitation of generators is that you can only yield while you are (statically) inside a generator function. That is, yielding in callbacks doesn’t work:  is not allowed inside non-generator functions, which is why the previous code causes a syntax error. In this case, it is easy to rewrite the code so that it doesn’t use callbacks (as shown below). But unfortunately that isn’t always possibe. The upsides of this limitation are explained later: they make generators easier to implement and compatible with event loops. Generators as observers (data consumption)   # As consumers of data, generator objects conform to the second half of the generator interface,  : As an observer, a generator pauses until it receives input. There are three kinds of input, transmitted via the methods specified by the interface: \n  sends normal input. \n  terminates the generator. \n  signals an error. \n Sending values via     # If you use a generator as an observer, you send values to it via   and it receives those values via  : Let’s use this generator interactively. First, we create a generator object: We now call  , which starts the generator. Execution continues until the first  , which is where the generator pauses. The result of   is the value yielded in line (A) ( , because   doesn’t have an operand). In this section, we are not interested in what   returns, because we only use it to send values, not to retrieve values. We call   two more times, in order to send the value   to the first   and the value   to the second  : The result of the last   is the value returned from  .   being   indicates that the generator is finished. Unfortunately,   is asymmetric, but that can’t be helped: It always sends a value to the currently suspended  , but returns the operand of the following  . # When using a generator as an observer, it is important to note that the only purpose of the first invocation of   is to start the observer. It is only ready for input afterwards, because this first invocation has advanced execution to the first  . Therefore, you can’t send input via the first   – you even get an error if you do: The following utility function fixes this issue: To see how   works, let’s compare a wrapped generator with a normal one: The wrapped generator is immediately ready for input: The normal generator needs an extra   until it is ready for input:  binds loosely   #  binds very loosely, so that we don’t have to put its operand in parentheses: This is treated as: Not as: As a consequence, many operators bind more tightly than   and you have to put   in parentheses if you want to use it as an operand. For example, you get a SyntaxError if you make an unparenthesized   an operand of plus: You do not need parens if   is a direct argument in a function or method call: You also don’t need parens if you use   on the right-hand side of an assignment: # The need for parens can be seen in the following grammar rules in the  ECMAScript 6 specification . These rules describe how expressions are parsed. I list them here from general (loose binding, lower precedence) to specific (tight binding, higher precedence). Wherever a certain kind of expression is demanded, you can also use more specific ones. The opposite is not true. The hierarchy ends with  , which means that you can mention any expression anywhere, if you put it in parentheses. The operands of an   are an   and a  . Therefore, using a (more specific)   as an operand is OK, but using a (more general)   isn’t.  and     # Let’s recap how   works (after the first invocation): The generator is currently suspended at a   operator. Send the value   to that  , which means that it evaluates to  . Proceed to the next   or  :\n \n  leads to   returning with  \n  leads to   returning with  \n \n  and   work similarly to  , but they do something different in step 2: \n  executes   at the location of  . \n  executes   at the location of  . \n  terminates the generator   #  performs a   at the location of the   that led to the last suspension of the generator. Let’s use the following generator function to see how that works. In the following interaction, we first use   to start the generator and to proceed until the   in line (A). Then we return from that location via  . # You can prevent   from terminating the generator if you yield inside the   clause (using a   statement in that clause is also possible): This time,   does not exit the generator function. Accordingly, the property   of the object it returns is  . You can invoke   one more time. Similarly to non-generator functions, the return value of the generator function is the value that was queued prior to entering the   clause. # Returning a value from a   generator (that hasn’t started yet) is allowed:  signals an error   #  throws an exception at the location of the   that led to the last suspension of the generator. Let’s examine how that works via the following generator function. In the following interaction, we first use   to start the generator and proceed until the   in line (A). Then we throw an exception from that location. The result of   (shown in the last line) stems from us leaving the function with an implicit  . # If you don’t catch the exception inside the generator, it is thrown by  . For example, the following generator function does not catch exceptions: If we use   to throw an instance of   at line (A), the method itself throws that error: # Throwing an exception in a   generator (that hasn’t started yet) is allowed: Example: processing asynchronously pushed data   # The fact that generators-as-observers pause while they wait for input makes them perfect for on-demand processing of data that is received asynchronously. The pattern for setting up a chain of generators for processing is as follows: \n \n First chain member: a normal function that has a parameter  , which is the generator object of the next element in the chain of generators. The function makes an asynchronous request and pushes the results to the target via  . \n \n \n Intermediate chain members: generators that have a parameter  . They receive data via   and send data via  . \n \n \n Last chain member: a generator that has no parameter   and only receives data. \n \n As an example, let’s chain generators to process a file that is read asynchronously. The code shown in this section is a Node.js script that is executed via    [6] . The following code sets up the chain, which starts with the normal function  , continues with the generators   and   and ends with the generator  : I’ll explain what these functions do when I show their code. The following helper function sets up a chain of generators: Starting with the last generator, each generator function is called and the resulting generator object is used to start the generator via an initial  . If a generator has a successor, it receives the successor’s generator object via the parameter  . The result of   is the generator object of the first generator function (in our example:  ).  is the non-generator function that starts everything. The chain of generators starts with  : Note an important pattern: \n  uses the generator object method   to signal the end of the sequence of chunks that it sends. \n  sends that signal while   is waiting for input via  , inside an infinite loop.   breaks from that loop. \n  uses a   clause to handle the end-of-sequence. \n The next generator is  : The last generator is  : The neat thing about this code is that everything happens lazily (on demand): lines are split, numbered and printed as they arrive; we don’t have to wait for all of the text before we can start printing. : the full story   # So far, we have only seen one aspect of  : it propagates yielded values from the callee to the caller. Now that we are interested in generators receiving input, another aspect becomes relevant:   also forwards input received by the caller to the callee. I’ll first explain the complete semantics of   by showing how you’d implemented it in JavaScript. Then I give simple examples where input received by the caller via  ,   and   is forwarded to the callee. The following statement: is roughly equivalent to: To keep things simple, several things are missing in this code: \n \n The operand of   can be any iterable value. \n \n \n  and   are optional iterator methods. We should only call them if they exist. \n \n \n If an exception is received and   does not exist, but   does then   is called (before throwing an exception) to give   the opportunity to clean up. \n \n \n  can refuse to close, by returning an object whose property   is  . Then the caller also has to refuse to close and   must continue to iterate. \n \n # The following generator function   invokes the generator function   via  .  logs values received via  , which allows us to check whether it receives the value   and   that we send to  . # Let’s use the following code to demonstrate how   works while   is delegating to another generator. We first create a generator object and advance until line (A). In that line, we throw an exception:  doesn’t catch the exception, which is why it is propagated into  , where it is logged before   finishes. # Let’s use the following code to demonstrate how   works while   is delegating to another generator. Destructuring closes an iterator via   if one doesn’t iterate until the end: Interestingly, the   is sent to   and forwarded to   (which it terminates early), but then also terminates   (which is what someone invoking   would expect). That is,   is propagated much like an exception. # There are two ways to think about  : \n As a function call from generator to generator. \n In order to understand  , it helps to ask yourself: what should happen if I copy-pasted the code of the callee function into the code of the caller function. \n Generators as coroutines (cooperative multitasking)   # We have seen generators being used as either sources or sinks of data. For many applications, it’s good practice to strictly separate these two roles, because it keeps things simpler. This section describes the full generator interface (which combines both roles) and one application where both roles are needed: cooperative multitasking, where tasks must be able to both send and receive information. The full generator interface   # The full interface of generator objects,  , handles both output and input and combines two interfaces that we have seen previously:   for output and   for input. This is the full interface of generator objects ( as described by the ECMAScript language specification ): Cooperative multitasking   # Cooperative multitasking is an application of generators where we need them to handle both output and input. Before we get into how that works, let’s first review the current state of parallelism in JavaScript  [7] . JavaScript runs in a single process. There are two ways in which this limitation is being abolished: \n \n Multiprocessing:   let you run JavaScript in multiple processes. Shared access to data is one of the biggest pitfalls of multiprocessing. Web Workers avoid it by not sharing any data. That is, if you want a Web Worker to have a piece of data, you must send it a copy or transfer your data to it (after which you can’t access it anymore). \n \n \n Cooperative multitasking: There are various patterns and libraries that experiment with cooperative multitasking. Multiple tasks are run, but only one at a time. Each task must explicitly suspend itself, giving it full control over when a task switch happens. In these experiments, data is often shared between tasks. But due to explicit suspension, there are few risks. \n \n Two use cases benefit from cooperative multitasking, because they involve control flows that are mostly sequential, anyway, with occasional pauses: \n Asynchronous computations: A task blocks (pauses) until it receives the result of a long-running computation. \n Streams: A task sequentially processes a stream of data and pauses if there is no data available. \n For binary streams, WHATWG is currently working on a  standard proposal  that is based on callbacks and promises. For streams of data, Communicating Sequential Processes (CSP) are an interesting solution. A generator-based CSP library is covered later in this blog post. For asynchronous computations, Promises  [8]  have become popular and are included in ECMAScript 6. # Several promise-based libraries simplify asynchronous code via generators. Generators are ideal as clients of promises, because they can be suspended until a result arrives. The following example demonstrates what that looks like if one uses  the library   by T.J. Holowaychuk. We need two libraries (if we run Node.js code via babel-node  [6:1] ):  is the actual library for cooperative multitasking,   is a polyfill for the new promise-based   API (a replacement of  ; read “ That's so fetch! ” by Jake Archibald for more information).   makes it easy to write a function   that returns the text of a file at a   via a Promise: We now have all the ingredients to use  . The following task reads the texts of two files, parses the JSON inside them and logs the result. Note how nicely synchronous this code looks, even though it makes an asynchronous call in line (A). A generator-as-task makes an async call by yielding a promise to the scheduler function  . The yielding pauses the generator. Once the promise returns a result, the scheduler resumes the generator by passing it the result via  . A simple version of   looks as follows. The limitations of cooperative multitasking via generators   #  are cooperatively multitasked tasks that have no limitations: Inside a coroutine, any function can suspend the whole coroutine (the function activation itself, the activation of the function’s caller, the caller’s caller, etc.). In contrast, you can only suspend a generator from directly within a generator and only the current function activation is suspended. Due to these limitations, generators are occasionally called    [9] . # The limitations of generators have two main benefits: \n \n Generators are compatible with  , which provide simple cooperative multitasking in browsers. I’ll explain the details momentarily. \n \n \n Generators are relatively easy to implement, because only a single function activation needs to be suspended and because browsers can continue to use event loops. \n \n JavaScript already has a very simple style of cooperative multitasking: the event loop  [7:1] , which schedules the execution of tasks in a queue. Each task is started by calling a function and finished once that function is finished (that’s a simplification of how things actually work, but it’ll do for now). Events,   and other mechanisms add tasks to the queue. This style of multitasking makes one important guarantee:  ; every function can rely on not being interrupted by another task until it is finished. Functions become transactions and can perform complete algorithms without anyone seeing the data they operate on in an itermediate state. Concurrent access to shared data makes multitasking complicated and is not allowed by JavaScript’s concurrency model. That’s why run to completion is a good thing. Alas, coroutines prevent run to completion, because any function could suspend its caller. For example, the following algorithm consists of multiple steps: If   was to suspend the algorithm, other tasks could run before the last step of the algorithm is performed. Those tasks could contain other parts of the application which would see   in an unfinished state. Generators preserve run to completion, they only suspend themselves and return to their caller.   and similar libraries give you most of the power of coroutines: \n They provide schedulers for tasks defined via generators. \n Tasks start with generators and can thus be fully suspended. \n A recursive (generator) function call is only suspendable if it is done via  . That gives callers control over suspension. \n Examples of generators   # This section gives several examples of what generators can be used for. Implementing iterables via generators   # In the blog post “ Iterables and iterators in ECMAScript 6 ”, I implemented several iterables “by hand”. In this section, I use generators, instead. #  converts a (potentially infinite) sequence of iterated values into a sequence of length  : The following is an example of using it: An implementation of   without generators is more complicated: Note that the iterable combinator   does not profit much from being implemented via a generator, because multiple iterables are involved (and   can’t be used). #  returns an iterable over all natural numbers: This function is often used in conjunction with a combinator: One last time, I show the non-generator implementation, so you can compare: # Arrays can be transformed via the methods   and  . Those methods can be generalized to have iterables as input and iterables as output. This is the generalized version of  : This is the generalized version of  : Generators for lazy evaluation   # The next two examples show how generators can be used to process a stream of characters. \n \n The input is a stream of characters. \n \n \n Step 1 – tokenize (characters → words): The characters are grouped into  , strings that match the regular expression  . Non-word characters are ignored, but they separate words. The input of this step is a stream of characters, the output a stream of words. \n \n \n Step 2 – extract numbers (words → numbers): only keep words that match the regular expression   and convert them to numbers. \n \n \n Step 3 – add numbers (numbers → number): produce a single number by computing the total of all numbers in a stream. \n \n The neat thing is that everything is computed   (incrementally and on demand): computation starts as soon as the first character arrives. For example, we don’t have to wait until we have all characters to get the first word. #  The following trick makes the code a bit simpler: the end-of-sequence iterator result (whose property   is  ) is converted into the sentinel value  . Let’s try out tokenization. Note that the spaces and the dot are non-words. They are ignored, but they separate words. We use the fact that strings are iterables over characters (Unicode code points). The final result is an iterable over words, which we turn into an array via the spread operator ( ).  This step is relatively simple, we only   words that contain nothing but digits, after converting them to numbers via  . The following example shows the transformation steps: characters → words → numbers.  This last step is performed by a normal function that pulls the results and reports their total. The final result shows us that there are 7 things in the input sentence. # Not much work is needed to convert the previous pull-based algorithm into a push-based one. The steps are the same. But instead of finishing via pulling, we start via pushing (in both cases, non-generator functions are used). As previously explained, if generators receive input via  , the first invocation of   on the generator object doesn’t do anything. That’s why we again use the following helper function: The following function   wraps the chain of generators. Its parameter   holds the generator object of the first generator in the chain.   pushes the contents of   to the  , via  . When a generator processes a stream, it needs to be aware of the end of the stream, so that it can clean up properly. For pull, we did this via a special end-of-stream sentinel. For push, the end-of-stream is signaled via  . Let’s test   via a generator that simply outputs everything it receives: Let’s send   three “characters” via a string (which is an iterable over Unicode code points).  Note how this generator reacts to the end of the stream (as signaled via  ) in two   clauses. We depend on   being sent to either one of the two  s. Otherwise, the generator would never terminate, because the infinite loop starting in line (A) would never terminate.  demonstrates that generators work well as implementations of linear state machines. In this case, the machine has two states: “inside a word” and “not inside a word”. Let’s tokenize a string:  This step is straightforward. Let’s log the numbers appearing in a string:  This time, we react to the end of the stream by pushing a single value and then closing the receiver. Let’s sum up the numbers appearing inside a string: As mentioned before, one benefit of a push-based approach is that it allows you to process data that you receive asynchronously. Cooperative multi-tasking via generators   # # In this example, we create a counter that is displayed on a web page. We improve an initial version until we have a cooperatively multitasked version that doesn’t block the main thread and the user interface. This is the part of the web page in which the counter should be displayed: This function displays a counter that counts up forever (well, until the number overflows): If you ran this function, it would completely block the user interface thread in which it runs and its tab would become unresponsive. Let’s implement the same functionality via a generator that periodically pauses via   (a scheduling function for running this generator is shown at the end): Let’s add one small improvement. We move the update of the user interface to another generator,  , which we call via  . As it is a generator, it can also take care of pausing. Lastly, this is a scheduling function that we can use to run  . Each execution step of the generator is handled by a separate task, which is created via  . That means that the user interface can schedule other tasks in between and will remain responsive. With the help of  , we get a (nearly) infinite count-up that doesn’t block the user interface: # If you call a generator function (or method), it does not have access to its generator object; its   is the   it would have if it were a non-generator function. A work-around is to pass the generator object into the generator function via  . The following Node.js script uses this technique, but wraps the generator object in a callback ( , line (A)). It must be run via    [6:2] . In line (A), we get a callback that we can use with functions that follow Node.js callback conventions. The callback uses the generator object to wake up the generator, as you can see in the implementation of  : # The library   brings Communicating Sequential Processes (CSP) to JavaScript, a style of cooperative multitasking that is similar to ClojureScript’s core.async and Go’s  .   has two abstractions: \n Processes: are cooperatively multitasked tasks and implemented by handing a generator function to the scheduling function  . \n Channels: are queues for communication between processes. Channels are created by calling  . \n As an example, let’s use CSP to handle DOM events, in a manner reminiscent of Functional Reactive Programming. The following code uses the function   (which is shown later) to create a channel that outputs   events. It then continuously retrieves the output via  , inside an infinite loop. Thanks to  , the process blocks until the channel has output.  is implemented as follows. This example is taken from the blog post “ Taming the Asynchronous Beast with CSP Channels in JavaScript ” by James Long. Consult this blog post for more information on CSP. Inheritance   # This is a diagram of how various objects are connected in ECMAScript 6 (it is based on  Allen Wirf-Brock’s diagram  in the ECMAScript specification): Legend: \n The white (hollow) arrows express the has-prototype relationship (inheritance) between objects. In other words: a white arrow from   to   means that  . \n Parentheses indicate that an object exists, but is not accessible via a global variable. \n An   arrow from   to   means that  .\n \n Remember that   is equivalent to  . \n \n \n A   arrow from   to   means that  . \n The diagram reveals two interesting facts: First, a generator function   works very much like a constructor (you can even invoke it via  ): The generator objects it creates are instances of it, methods added to   become prototype methods, etc.: Second, if you want to make methods available for all generator objects, it’s best to add them to  . One way of accessing that object is as follows:    # There is no   in the diagram, because no such object exists. But, given how   works and because   is a prototype of  , you could still say that   is an instance of  . All iterators in ES6 have   in their prototype chain. That object is iterable, because it has the following method. Therefore, all ES6 iterators are iterable (as a consequence, you can apply   etc. to them). The specification recommends to use the following code to access  : You could also use: Quoting the ECMAScript 6 specification: ECMAScript code may also define objects that inherit from  . The   object provides a place where additional methods that are applicable to all iterator objects may be added.  will probably become directly accessible in an upcoming version of ECMAScript and contain tool methods such as   and   ( source ). The value of   in generators   # A generator function combines two concerns: It is a function that sets up and returns a generator object. It contains the code that the generator object steps through. That’s why it’s not immediately obvious what the value of   should be inside a generator. In function calls and method calls,   is what it would be if   wasn’t a generator function, but a normal function: If you access   in a generator that was invoked via  , you get a   ( source: ES6 spec ): We have previously seen a simple work-around: wrap the generator in a normal function that hands the generator its generator object via  . Style consideration: whitespace before and after the asterisk   # Reasonable – and legal – variations of formatting the asterisk are: \n \n A space before and after it: \n \n \n \n A space before it: \n \n \n \n A space after it: \n \n \n \n No whitespace before and after it: \n \n \n Let’s figure out which of these variations make sense for which constructs and why. Generator function declarations and expressions   # Here, the star is only used because   (or something similar) isn’t available as a keyword. If it were, then a generator function declaration would look like this: Instead of  , ECMAScript 6 marks the   keyword with an asterisk. Thus,   can be seen as a synonym for  , which suggests writing generator function declarations as follows. Anonymous generator functions would be formatted like this: Concise generator method definitions   # When writing a concise generator method definitions, I recommend to format the asterisk as follows. There are three arguments in favor of writing a space after the asterisk. First, the asterisk shouldn’t be part of the method name. On one hand, it isn’t part of the name of a generator function. On the other hand, the asterisk is only mentioned when defining a generator, not when using it. Second, a concise generator method definition is an abbreviation for the following syntax. (To make my point, I’m redundantly giving the function expression a name, too.) If concise method definitions are about omitting the   keyword then the asterisk should probably be followed by a space. Third, generator method definitions are syntactically similar to getters and setters (which are already available in ECMAScript 5): The keywords   and   can be seen as modifiers of a normal concise method definition. Arguably, an asterisk is also such a modifier. Recursive     # The following is an example of a generator function yielding its own yielded values recursively: The asterisk marks a different kind of   operator, which is why the above way of writing it makes sense. Documenting generator functions and methods   # Kyle Simpson (@getify) proposed something interesting: Given that we often append parentheses when we write about functions and methods such as  , wouldn’t it make sense to prepend an asterisk when writing about generator functions and methods? For example: should we write   to refer to the generator function in the previous subsection? Let me argue against that. When it comes to writing a function that returns an iterable, a generator is only one of the several options. I think it is better to not give away this implementation detail via marked function names. Furthermore, you don’t use the asterisk when calling a generator function, but you do use parentheses. Lastly, the asterisk doesn’t provide useful information –   can also be used with functions that return an iterable. But it may make sense to mark the names of functions and methods that return iterables (including generators). For example, via the suffix  . Conclusion   # I hope that this blog post convinced you that generators are a useful and versatile tool. I like that generators let you implement cooperatively multitasked tasks that block while making asynchronous function calls. In my opinion that’s the right mental model for async calls. I hope that JavaScript goes further in this direction in the future. If one generator async-calls another generator, the indirection via promises is not needed. It could be avoided by  the generator-based async functions  that have been proposed for ECMAScript 2016. References   # Acknowledgement: items 1–3 are sources of this blog post. “ Exploring ES6: Upgrade to the next version of JavaScript ”, book by Axel  ↩︎ \n Classes in ECMAScript 6 (final semantics)   ↩︎ \n Iterables and iterators in ECMAScript 6   ↩︎ \n ” The spread operator ( ) ”, a section in the blog post “Destructuring and parameter handling in ECMAScript 6”.  ↩︎ \n Destructuring and parameter handling in ECMAScript 6   ↩︎ \n Using the ES6 transpiler Babel on Node.js   ↩︎   ↩︎   ↩︎ \n ECMAScript 6 promises (1/2): foundations  [explains the event loop and more]  ↩︎   ↩︎ \n ECMAScript 6 promises (2/2): the API   ↩︎ \n “ Why coroutines won't work on the web ” by David Herman  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/04/webpack-es6.html", "title": "Writing client-side ES6 with webpack", "content": "Writing client-side ES6 with webpack esnext dev javascript  Please read Sect. “ Browser setup: ES6 via webpack and Babel ” in “Setting up ES6”. webpack  is a client-side module builder and module loader. This blog post shows you how to write ECMAScript 6 code with it. The code shown here is on GitHub, in the project  . webpack features   # Notable webpack features include: \n Supported module formats: AMD, CommonJS\n \n Via   (plug-in): ES6 \n \n \n Supported package managers: Bower, npm \n Loaders for non-code: CSS, templates, … \n On-demand loading (chunked transfer) \n Built-in development server \n Installing webpack   # Install webpack: Enable support for ECMAScript 6 (via  Babel ): \n Per project:  \n In your home directory:  \n Globally:  \n Using webpack and ES6 in a project   # The demo project   has the following structure: The following command compiles the ES6 files   and   to a file  : After executing the previous command, you can open   in a web browser (directly from the file system if you’d like).   runs  , which means that you get to see what   is doing. In real-world projects, you probably won’t use webpack directly, but via build tools, such as grunt, gulp, etc. webpack.config.js   # This is the configuration file for webpack: Things work as follows: \n Input: is specified via the property  . This is where the execution of JavaScript code starts. \n Output: webpack bundles the entry file and everything it depends on into the output file   (which resides in the same directory as  ). \n Support for ES6: is enabled via a the module loader  .\n \n Property  : specifies what files the loader should be used for.\n \n Single test: regular expression or string with an absolute path \n Multiple tests: array of single tests (logical “and”) \n \n \n \n \n HTML   # The HTML file starts JavaScript via the bundle file that was created by webpack. ECMAScript 6 code   # The following two ECMAScript 6 files were packaged into  . : : Note that the paths follow Node.js conventions. Using npm packages   # You can install packages via npm and use them from your ES6 code, seamlessly. For example: First install  lodash . Then use it anywhere in your ES6 code: Alternatives to webpack   # If webpack is not your cup of tea, there are several capable alternatives for writing client-side ES6 code. For example: \n jspm \n Browserify  with  babelify \n webpack, jspm and Browserify can also use Traceur instead of Babel, if you want to. comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/proto.html", "title": "JavaScript: __proto__", "content": "JavaScript: __proto__ esnext dev javascript __proto__ jslang series \nThis blog post looks at the special property  , which allows you to get and set the prototype of an object. In order to understand this post, you should be familiar with JavaScript’s prototypal inheritance  [1] .\n\n \n\n The special property __proto__ \n  (pronounced “dunder proto”, from “double underscore”  [2] ) first appeared in Firefox and is an alias for  . Using  , the above code becomes:\n Checking whether __proto__ is supported Caveat: objects as maps [3] Two use cases Creating objects with a given prototype Subtyping built-in types [4] ECMAScript 6 \nIt is not yet certain that you’ll also be able to change the prototype of an existing object via  . The most important use case for that is to subtype  , which can be better supported by other means, e.g. via a function  .\n \nLastly, ECMAScript 6 will probably also provide ways for switching off   for some objects, possibly even for all objects.\n\n More material on the web \n     MDN: “ __proto__ ” \n     “ The magic __proto__ property ” by Asen Bozhilov \n References Prototypes as classes – an introduction to JavaScript inheritance How to pronounce __proto__ The pitfalls of using objects as maps in JavaScript Subtyping JavaScript built-ins comments powered by Disqus."},
{"url": "https://2ality.com/2015/06/tail-call-optimization.html", "title": "Tail call optimization in ECMAScript 6", "content": "Tail call optimization in ECMAScript 6 esnext dev javascript  Even though tail call optimization is part of the language specification,  it isn’t supported by many engines  and that may never change. The ideas are still interesting, however and explained in this blog post. ECMAScript 6 offers  , where you can make some function calls without growing the call stack. This blog post explains how that works and what benefits it brings. What is tail call optimization?   # To understand what tail call optimization (TCO) is, we will examine the following piece of code. I’ll first explain how it is executed without TCO and then with TCO. Normal execution   # Let’s assume there is a JavaScript engine that manages function calls by storing local variables and return addresses on a stack. How would such an engine execute the code?  Initially, there are only the global variables   and   on the stack. The block of stack entries encodes the state (local variables, including parameters) of the current scope and is called a  .  In line C,   is called: First, the location to return to is saved on the stack. Then  ’s parameters are allocated and execution jumps to its body. The stack now looks as follows. There are now two frames on the stack: One for the global scope (bottom) and one for   (top).  ’s stack frame includes the return address, line C.    is called in line B. Again, a stack frame is created that contains the return address and  ’s parameter.  In line A, the result   is returned.  ’s stack frame is removed and execution jumps to the return address, line B. (There are several ways in which returning a value could be handled. Two common solutions are to leave the result on a stack or to hand it over in a register. I ignore this part of execution here.) The stack now looks as follows:  In line B, the value that was returned by   is returned to  ’s caller. Again, the topmost stack frame is removed and execution jumps to the return address, line C.  Line C receives the value   and logs it. Tail call optimization   # If you look at the previous section then there is one step that is unnecessary – step 5. All that happens in line B is that the value returned by   is passed on to line C. Ideally,   could do that itself and the intermediate step could be skipped. We can make this happen by implementing the function call in line B differently. Before the call happens, the stack looks as follows. If we examine the call we see that it is the very last action in  . Once   is done, the only remaining action performed by   is to pass  ’s result to  ’s caller. Therefore,  ’s variables are not needed, anymore and its stack frame can be removed before making the call. The return address given to   is  ’s return address, line C. During the execution of  , the stack looks like this: Then   returns the value  . You could say that it returns that value for  , because it transports it to  ’s caller, line C. Let’s review: The function call in line B is a tail call. Such a call can be done with zero stack growth. To find out whether a function call is a tail call, we must check whether it is in a   (i.e., the last action in a function). How that is done is explained in the next section. Checking whether a function call is in a tail position   # We have just learned that tail calls are function calls that can be executed more efficiently. But what counts as a tail call? First, the way in which you call a function does not matter. The following calls can all be optimized if they appear in a tail position: \n Function call:  \n Dispatched method call:  \n Direct method call via  :  \n Direct method call via  :  \n Tail calls in expressions   # Arrow functions can have expressions as bodies. For tail call optimization, we therefore have to figure out where function calls are in tail positions in expressions. Only the following expressions can contain tail calls: \n The conditional operator ( ) \n The logical Or operator ( ) \n The logical And operator ( ) \n The comma operator ( ) \n Let’s look at an example for each one of them. # Both   and   are in tail position. #  is not in a tail position, but   is in a tail position. To see why, take a look at the following code, which is equivalent to the previous code: The result of the logical Or operator depends on the result of  , which is why that function call is not in a tail position (the caller does something with it other than returning it). However,   is in a tail position. #  is not in a tail position, but   is in a tail position. To see why, take a look at the following code, which is equivalent to the previous code: The result of the logical And operator depends on the result of  , which is why that function call is not in a tail position (the caller does something with it other than returning it). However,   is in a tail position. #  is not in a tail position, but   is in a tail position. To see why, take a look at the following code, which is equivalent to the previous code: Tail calls in statements   # For statements, the following rules apply. Only these compound statements can contain tail calls: \n Blocks (as delimited by  , with or without a label) \n : in either the “then” clause or the “else” clause. \n ,  ,  : in their bodies. \n : in its body. \n : only in the   clause. The   clause has the   clause as a context that can’t be optimized away. \n ,  : only in the   clause, which is a context of the other clauses that can’t be optimized away. \n Of all the atomic (non-compound) statements, only   can contain a tail call. All other statements have context that can’t be optimized away. The following statement contains a tail call if   contains a tail call. Tail call optimization can only be made in strict mode   # In non-strict mode, most engines have the following two properties that allow you to examine the call stack: \n : contains the arguments of the most recent invocation of  . \n : refers to the function that most recently called  . \n With tail call optimization, these properties don’t work, because the information that they rely on may have been removed. Therefore, strict mode forbids these properties ( as described in the language specification ) and tail call optimization only works in strict mode. Pitfall: solo function calls are never in tail position   # The function call   in the following code is not in tail position: The reason is that the last action of   is not the function call  , it is (implicitly) returning  . In other words,   behaves like this: Callers can rely on   always returning  . If   were to return a result for  , due to tail call optimization, then that would change  ’s behavior. Therefore, if we want   to be a tail call, we have to change   as follows. Tail-recursive functions   # A function is   if the main recursive calls it makes are in tail positions. For example, the following function is not tail recursive, because the main recursive call in line A is not in a tail position:  can be implemented via a tail-recursive helper function  . The main recursive call in line A is in a tail position. That is, some non-tail-recursive functions can be transformed into tail-recursive functions. Tail-recursive loops   # Tail call optimization makes it possible to implement loops via recursion without growing the stack. The following are two examples. # # comments powered by Disqus."},
{"url": "https://2ality.com/2015/06/web-assembly.html", "title": "WebAssembly: a binary format for the web", "content": "WebAssembly: a binary format for the web asmjs dev javascript webassembly \n \n [2015-07-02] New material in these sections: \n \n How do I create WebAssembly code? \n First experiences in practice \n Further reading \n \n \n \n [2015-06-24] I added  an FAQ  with three new questions: \n \n Does the web finally have a universal bytecode? \n Isn’t WebAssembly like Flash? \n Will WebAssembly make JavaScript faster? \n \n \n WebAssembly (short:  ) is a new binary format for the web, created by Google, Microsoft, Mozilla and others. It will be used for performance critical code and to compile languages other than JavaScript (especially C/C++) to the web platform. It can be seen as a next step for asm.js  [1] . asm.js   # Most JavaScript engines have the following compilation pipeline: JavaScript source → bytecode → machine code The idea of asm.js is to code JavaScript in such a way that engines produce machine code that is as efficient as possible. That is, you kind of try to bypass the first compilation step. The results are impressive: if one compiles C++ to asm.js one can reach 70% of native speed in web browsers. WebAssembly: the next step for asm.js   # Initially, WebAssembly is (roughly) a binary format for delivering asm.js code. The two main advantages of such a format are: \n \n Faster loading. Especially with large code bases and mobile devices, parsing becomes a bottleneck: “On mobile, large compiled codes can easily take 20–40s  ” ( WebAssembly FAQ ). First experiments show that WebAssembly can be loaded more than 20 times faster, because the work for parsing is minimal. \n \n \n Evolving WebAssembly is simpler: The way that asm.js is currently written is constrained by having to run fast as normal JavaScript (in legacy engines) and by having to support ahead of time compilation within JavaScript syntax. \n \n Legacy engines will be supported via a JavaScript library that translates WebAssembly (binary) to asm.js (source code).  First indications  are that that is reasonably fast. WebAssembly binaries are trees   # WebAssembly binaries will encode  abstract syntax trees . That is, they are not a linear format like stack- or register-based bytecode. Not surprisingly, the format looks much like asm.js: roughly, a statically typed version of JavaScript without objects. There will be  a text format for WebAssembly . It will mirror the semantics of the binaries and contain a tree of statements and expressions. WebAssembly does not replace JavaScript   # The previous diagram (which is a much simplified depiction of reality) should make it obvious that WebAssembly is not a replacement for JavaScript, it is a new feature of JavaScript engines that builds on their infrastructures. That means that  it will fit well into the web platform : \n It will have  the same evolution strategy as JavaScript : everything is always backward-compatible, there is no explicit versioning, code uses feature testing to determine how it should run. \n It will execute in the same semantic universe as JavaScript and allow synchronous calls to and from JavaScript (including browser APIs). \n Security will be handled like in JavaScript, via same-origin and permissions security policies. \n The nice thing is that WebAssembly removes the burden from JavaScript to be a good compilation target for other languages. For example, the following two methods were only added to ES6 to support asm.js well: \n  rounds   to a 32 bit float. \n  multiplies the two integers   and  . \n How will JavaScript and WebAssembly coexist?   # \n \n Performance critical functionality (games, video and image decoders, etc.) will be implemented via WebAssembly, either by hand-coding it or by yet-to-be-invented languages that are slightly higher-level. \n \n \n External code bases, especially those in C/C++, will be easy to port to the web platform, via WebAssembly. \n \n \n Other than that, JavaScript will continue to evolve and will probably remain the most popular way of implementing web apps. \n \n The future   # The initial focus is for WebAssembly to be a compilation target for C/C++. Longer term, more features supporting other languages will be added, including the ability to create garbage-collected data (currently, asm.js creates and manages its own heap). You’ll eventually be able to debug a WebAssembly binary via the source code that was compiled to it. That mechanism will be an evolution of source maps  [2]  that provide similar services for JavaScript. Frequently asked questions   # What is different this time?   # Why should WebAssembly succeed where previous attempts (such as Adobe Flash and Google Portable Native Client) have failed? There are three reasons: \n \n First, this is a collaborative effort, no single company goes it alone. At the moment, the following projects are involved: Firefox, Chromium, Edge and WebKit. \n \n \n Second, the interoperability with the web platform and JavaScript is excellent. Using WebAssembly code from JavaScript will be as simple as importing a module. \n \n \n Third, this is not about replacing JavaScript engines, it is more about adding a new feature to them. That greatly reduces the amount of work to implement WebAssembly and should help with getting the support of the web development community. \n \n Does the web finally have a universal bytecode?   # WebAssembly is not bytecode: Bytecode is linear and (usually) stack-, register- or  SSA-based , WebAssembly is a binary format for an abstract syntax tree (AST). Compared to bytecode, this has the following advantages: \n \n WebAssembly is relatively easy to add to all current JavaScript engines, because it is high-level and similar to parts of JavaScript. That is, it builds on the infrastructures of engines, instead of replacing them. Engines will continue to have different compilation strategies and/or bytecode, which is good for the web ecosystem, because the differences have fostered experimentation and innovation. \n \n \n WebAssembly is not versioned. It uses the same evolution strategy as JavaScript (feature detection and polyfills). \n \n On the other hand, WebAssembly   like bytecode in two ways: \n \n WebAssembly will eventually lead to a “universal” virtual machine (VM). It will probably gain features that JavaScript/asm.js will never have and therefore better accommodate languages that currently don’t compile well to JavaScript. Note, though, that asm.js was the beginning of that universal VM – you don’t need a binary format for that. \n \n \n WebAssembly eliminates the parser as a bottleneck. \n \n Isn’t WebAssembly like Flash?   # Everything mentioned in the previous question applies here, too: Flash is based on bytecode, but WebAssembly is not bytecode and does not have some of its disadvantages. Additionally, WebAssembly is much better integrated into the web platform, its code lives in the universe of JavaScript. So far, the power consumption story of the web platform also seems to be better than Flash’s, but there is still a lot of room for improvement. Will WebAssembly make JavaScript faster?   # Short answer: yes (load time) and no (execution time). 70% of the speed native C/C++ means that WebAssembly is fast where C/C++ is fast (static code) and slow where C/C++ is slow (e.g. dynamic OOP features). It does not currently make sense to compile JavaScript to WebAssembly, because it lacks JavaScript-specific features such as objects and arrays (for C++, one manually manages a heap in a typed array). Once WebAssembly gains those features, JavaScript can be compiled to it, but it will use the same techniques as current engines. Therefore, only the load time of applications will improve, because parsing is much faster. The reduction of the size of executables will be less dramatic. One can already save a lot of space via minification and compression. First experiments ( see below ) resulted in gzipped asm.js being 1.4 times bigger than gzipped WebAssembly. How do I create WebAssembly code?   # The main three options are: \n Write the code manually and use the textual representation. \n Produce binary output programmatically. \n Use a compiler to compile an LLVM-based language (initially mainly C/C++) to WebAssembly. The official FAQ “ What compilers can I use to build WebAssembly programs? ” has more information. \n First experiences in practice   # For the Unity Game Engine, first tests were made with WebAssembly. Quoting “ WebGL: WebAssembly and Feature Roadmap ” by Jonas Echterhoff for the Unity Blog: Experimenting with a prototype WebAssembly format on a build of our AngryBots demo, we saw the size of the generated JavaScript code go from 19.0 MB of asm.js code (gzip-compressed to 4.1 MB) down to 6.3 MB of WebAssembly code (gzip-compressed to 3.0 MB). This means that the amount of data the browser needs to process gets reduced by 3.0x, and the compressed download size gets reduced by 1.4x. Actual results may change based on the project used, but we expect to see very relevant improvements to anyone caring about WebGL deployment in Unity. Further reading   # Especially informative is Eric Elliott’s interview with Brendan Eich: “ Why we Need WebAssembly ”. References: asm.js: closing the gap between JavaScript and native   ↩︎ \n “ Introduction to JavaScript Source Maps ” by Ryan Seddon on HTML5 Rocks  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/07/favorite-es6-features.html", "title": "What are your favorite JavaScript ES6 features?", "content": "What are your favorite JavaScript ES6 features? esnext dev javascript I’ve created a survey to find out what ES6 (a.k.a. ECMAScript 2015) features people like most: \n Submit your answer via a form \n Summary of responses \n I previously  asked the same question on Twitter  and one feature stood out:  Classes  were the only feature that some people disliked, but they were also liked by a few people ( I cover their pros and cons in “Exploring ES6” ). On Twitter, the top 10 most liked features were: Arrow functions Modules Destructuring Generators Promises Template literals Spread operator New object literal features (including method definitions)  and  Rest parameters comments powered by Disqus."},
{"url": "https://2ality.com/2012/09/javascript-quotes.html", "title": "JavaScript: single quotes or double quotes?", "content": "JavaScript: single quotes or double quotes? dev javascript jslang jsstyle asked \n     “Is this a ploy to get lots of @-replies?” –  @tobie \n     “Using single quotes saves bandwidth because you don’t have to send the extra pixels. #performance #truestory” –  @mathias \n Examining the pros and cons In favor of single quotes \n     Less visual clutter. \n     Generating HTML: HTML attributes are usually delimited by double quotes.\n \n        However, single quotes are just as legal in HTML. \n \n        Furthermore, inline HTML is normally an anti-pattern. Prefer templates.\n     \n     Generating JSON: Only double quotes are allowed in JSON.\n \n        Again, you shouldn’t have to construct JSON this way.   is often enough. If not, use templates.\n     \n In favor of double quotes \n     “Doubles are easier to spot if you don't have color coding. Like in a console log or some kind of view-source setup.” –  @wiredearp \n     Similarity to other languages: In shell programming (Bash etc.), single-quoted string literals exist, but escapes are not interpreted inside them. C and Java use double quotes for strings and single quotes for characters.\n     \n     If you want code to be valid  JSON , you need to use double quotes.\n     \n In favor of both @medikoo In favor of neither What do JavaScript engines prefer? comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/future-of-markdown.html", "title": "The future of Markdown", "content": "The future of Markdown markdown publishing computers Markdown \nHowever, Markdown is poorly specified and there are many slightly incompatible dialects. The blog post “ The Future of Markdown ” (by Jeff Atwood for Coding Horror) mentions a proposal by David Greenspan:\n \n    I want this new language – working name \"Rockdown\" – to be seen as Markdown with a spec, and therefore only deviate from Markdown's behavior in unobtrusive ways. It should basically be a replacement that paves over the problems and ambiguities in Markdown.\n the post \nTwo relevant technologies:\n \n     AsciiDoc  is similar to Markdown, but better suited for books. It is internally based on DocBook. O’Reilly uses it for many of its books.\n     \n     MultiMarkdown  improves on Markdown in two major ways:\n         \n             More output formats (not just HTML): PDF (via LaTeX), OPML, OpenDocument (which can be converted to RTF and Microsoft Word). \n             More syntax features: tables, footnotes, citations and more.\n             \n         \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/river-trail-firefox.html", "title": "JavaScript: parallel programming via River Trail coming to Firefox", "content": "JavaScript: parallel programming via River Trail coming to Firefox dev javascript blog post \nRiver Trail is a set of mechanisms that enable a new functional style of parallel programming in JavaScript. An initial prototype was developed by Intel. Recently,  work has started  to bring it to Firefox.\n\n \n\n Intel’s River Trail prototype The Past, Present, and Future of JavaScript \n River Trail  is an experiment by Intel Labs that adds data parallelism to JavaScript, but without having to explicitly control it, as with WebCL. It introduces the new type   with transformation methods that are parameterized via a function implementing the transformation (a so-called elemental function). Arrays have similar methods (e.g.  ), but  's methods execute their elemental functions several times in parallel.\nThe following code uses  :\n \nThe current River Trail prototype is an extension for Firefox. To distribute the work, it uses OpenCL, which must be installed on the operating system.\nConveniently, one has the option of using a sequential implementation of  , in pure JavaScript, if River Trail is not installed. More details Rivertrail \nParallel arrays have some key differences from JavaScript arrays:\n \n They are immutable \n They never have holes \n They can be multidimensional but always in a regular way (e.g., in a two-dimensional matrix, each row has the same number of columns) \n River Trail specification \n First, the function that is taken as argument is required to be a   [which can only change data that it has created (stored in local variables) – including objects]. \n Second, whenever possible, the JavaScript engine will execute the function in parallel. \n Modes of execution \n\t Sequentially: a shimmable  [1]  fallback. \n\t Multicore: one worker thread per core. \n\t Vectorized: is similar to multicore, but each worker thread will use  SSE instructions , allowing it to process more than one array element at a time.\n\t \n\t GPU: run vectorized code, but on the GPU instead of the CPU.\n\t \n River Trail in Firefox Reference What is the difference between a shim and a polyfill? comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/dunder.html", "title": "How to pronounce __proto__", "content": "How to pronounce __proto__ esnext dev javascript __proto__ jslang series \nBracketing variable names with double underscores is a tradition in Python that JavaScript has borrowed a few times, most prominently for the property    [1]  (which is currently non-standard, but will become part of ECMAScript 6). For Python, the following pronounciation has been  suggested  by Ned Batchelder:\n \n \n    My problem with the double underscore is that it's hard to say. How do you pronounce __init__? “underscore underscore init underscore underscore”? “under under init under under”? Just plain “init” seems to leave out something important.\n     \n    I have a solution: double underscore should be pronounced “dunder”. So __init__ is “dunder init dunder”, or just “dunder init”.\n Why the double underscore? [2] [3] Reactions \n     “du” (pronounced “dee yoo”), suggested by Mark McDonnell \n     “dubscore” \n     “scorescore” \n References JavaScript: __proto__ The pitfalls of using objects as maps in JavaScript Private data for objects in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/tc39-september.html", "title": "ECMAScript.next: TC39’s September 2012 meeting", "content": "ECMAScript.next: TC39’s September 2012 meeting esnext tc39 dev javascript Rick Waldron detailed account [1] September 18 notes \n     The final draft of the Internationalization API (ECMA-402) has been approved ( page with PDFs ,  HTML format ). It will be submitted to the Ecma General Assembly for ratification. This API exists separately from ECMAScript and will be available for ECMAScript 5 or later.\n     \n     TC39 discussed River Trail  [2] , JavaScript language extensions for parallel programming. River Trail won’t be in ECMAScript 6, but ECMAScript 7 or later is possible.\n     \n     \n        For a while, operators for batch-assignment and/or batch-definition were considered for inclusion in ECMAScript 6. The latest decision was to instead use a function and to specify the properties to be added via an object literal. This kind of merging of two objects is already popular in third-party libraries. For example, Underscore.js has  . ECMAScript 6 will have the function\n \n         Another blog post  explains how it works.\n     \n     Concise method definitions will be enumerable: ECMAScript.next offers a more compact way of defining methods in an object literal:\n \n        This is equivalent to:\n \n        This kind of   will be enumerable  [5]  in ECMAScript.next. Quoting David Herman: “Users expect that things they create to be enumerable and things that the platform provides to be non-enumerable.”\n     \n September 19 notes \n     More work on refining the proxy API. \n     Property name objects  [6]  are now called “symbols”. That’s a good choice. Now you can say: Each property has a name. Such a name is either a string or a symbol.\n     \n     Syntactic support for symbols: There are two main pitfalls with symbols. First, they introduce an indirection that is difficult for many people to grasp and leads to verbosity:\n \n        Instead, the following would be easier to understand:\n \n        Second, if a an object or a class has many private properties, there is much redundancy, because you always have to declare a symbol before you can use it. The discussion of how to best avoid this redundancy is ongoing.\n     \n September 20 notes \n     : is a mechanism to provide built-in support for data binding. Data binding is used in many user interface frameworks (two examples: qooxdoo, SproutCore): If one changes the value of a model object property then that change will be immediately reflected in the user interface.   will not become part of ECMAScript 6, but will probably appear in ECMAScript 7. A prototype for Chrome is currently being implemented.\n     \n\n     Thin arrow: Currently, only fat arrow ( ) functions  [7]  are to be included in ECMAScript 6. They provide a compact notation for non-method functions (with lexical  ). Some people have expressed a desire for thin arrow ( ) functions with dynamic  . However, consensus in TC39 was that the similar syntax would confuse users, they would have to decide which of the two arrows to use to achieve a given task. Traditional functions won’t go away and can be used instead of thin arrow functions. I welcome that decision, because users now have a clear and simple choice:\n         \n             Need a method? Use the compact method syntax in classes and object literals. \n             Need a non-method function? Use a (fat) arrow function. \n         \n        That means that in the long run, we probably won’t have non-method functions any more that have   as an implicit parameter (to be handed in by   or  ). An additional explicit parameter will have to be introduced in these cases.\n     \n\n     Existential operator: CoffeeScript allows you to chain property accesses and to finish early if an   or   appears anywhere in the chain:\n \n        TC39 recognizes that such a feature is useful, but it does not have a high enough priority at the moment. Thus, it seems unlikely that it will become part of ECMAScript 6.\n     \n     Time table: the ECMAScript 6 specification should be feature-complete in January 2013. \n References ECMAScript: ES.next versus ES 6 versus ES Harmony  [explains what TC39 is] JavaScript: parallel programming via River Trail coming to Firefox A closer look at super-references in JavaScript and ECMAScript.next Properties in JavaScript: definition versus assignment JavaScript properties: inheritance and enumerability Private data for objects in JavaScript ECMAScript.next: arrow functions and method definitions comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/javascript-properties.html", "title": "Object properties in JavaScript", "content": "Object properties in JavaScript dev javascript jslang Protecting objects in JavaScript \nProperties determine the state of an object in JavaScript. This blog post examines in detail how they work.\n\n \n\n Kinds of properties Named data properties (“properties”) Named accessor properties Internal properties \n     The internal property [[Prototype]] points to the prototype of an object. It can be read via  . Its value can only be set by creating a new object that has a given prototype, e.g. via   or    [1] .\n     \n     The internal property [[Extensible]] determines whether or not one can add properties to an object. It can be read via  . It can be set   via  . Once  , it cannot be become   again.\n     \n Property attributes \nThe following attributes are specific to named data properties:\n \n     [[Value]] hold the property’s value, its data.\n     \n     [[Writable]] holds a boolean indicating whether the value of a property can be changed.\n     \n \n     [[Get]] holds the  , a function that is called when a property is read. That function computes the result of the read access.\n     \n     [[Set]] holds the  , a function that is called when a property is set to a value. The function receives that value as a parameter.\n     \n \n     [[Enumerable]] holds a boolean. Making a property non-enumerable hides it from some operations (see below).\n     \n     [[Configurable]] holds a boolean. If false, you cannot delete a property, change any of its attributes (except [[Value]]) or convert between data property and accessor property.\n    In other words, [[Configurable]] controls the writability of a property’s meta-data.\n     \n Default values \n \nThese defaults are especially important for property descriptors (see below).\n\n\n Property descriptors Functions that use property descriptors \n     \n        Create or change a property on   whose name is   and whose attributes are specified via  . Return the modified object. Example:\n \n     \n     \n        The batch version of  . Each property of   holds a property descriptor. The names of the properties and their values tell   what properties to create or change on  .\n        Example:\n \n     \n     \n        First, create an object whose prototype is  . Then, if the optional parameter   has been specified, add properties to it – in the same manner as  . Finally, return the result.\n        For example, the following code snippet produces the same result as the previous snippet:\n \n     \n     \n        Returns the descriptor of the own (non-inherited) property of   whose name is  . If there is no such property,   is returned.\n \n     \n Enumerability [2] Operations affected by enumerability \nThe for-in loop iterates over the names of all enumerable properties, including inherited ones (note that none of the non-enumerable properties of   show up):\n \n  returns the names of all own (non-inherited) enumerable properties:\n Operations that ignore enumerability Best practices \nAs we have seen, non-enumerability mostly benefits for-in and ensures that legacy code using it won’t break. The non-enumerable properties create the illusion that for-in only iterates over the user-created own properties of an object. In your code, you should avoid for-in if you can  [3] .\n \nIf you use objects as maps from strings to values, you should only work with own properties and ignore enumerability. But there are more pitfalls for this use case  [4] .\n\n Conclusion \nFurther reading on 2ality:\n \n     Read “ JavaScript properties: inheritance and enumerability ” for more information on how inheritance and enumerability affect property-related operations. \n     Read “ JavaScript inheritance by example ” for an introduction to JavaScript inheritance. \n References JavaScript: __proto__ What object is not an instance of Object? Iterating over arrays and objects in JavaScript The pitfalls of using objects as maps in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/es6-scoping.html", "title": "Variables and scoping in ECMAScript 6", "content": "Variables and scoping in ECMAScript 6 esnext dev javascript  Chapter “ Variables and scoping ” in “Exploring ES6”. This blog post examines how variables and scoping are handled in ECMAScript 6  [1] . Block scoping via   and     # Both   and   create variables that are   – they only exist within the innermost block that surrounds them. The following code demonstrates that the  -declared variable   only exists inside the then-block of the   statement: In contrast,  -declared variables are function-scoped: Block scoping means that you can shadow variables within a function:  creates immutable variables   # Variables created by   are mutable: Variables created by  , constants, are immutable: Note that   does not affect whether the value of a constant itself is mutable or not: If a constant refers to an object, it will always refer to that object, but the object itself can still be changed (if it is mutable). If you wanted   to truly be a constant, you’d have to  freeze its value :  in loop bodies   # Once a   variable has been created, it can’t be changed. But that doesn’t mean that you can’t re-enter its scope and start fresh, with a new value. For example, via a loop: When should I use  , when  ?   # If you want to mutate a variable that holds a primitive value, you can’t use  : However, you can use a   variable to refer to something mutable: I’m still mulling over what the best style is, but I currently use   in situations like the previous example, because   refers to something mutable. I do use   to indicate that both variable and value are immutable: The temporal dead zone   # A variable declared by   or   has a so-called   (TDZ): When entering its scope, it can’t be accessed (got or set) until execution reaches the declaration. Let’s first examine the life cycle of   variables, which don’t have temporal dead zones: \n \n When the scope (its surrounding function) of a   variable is entered, storage space (a so-called  ) is created for it. The variable is immediately initialized, by setting it to  . \n \n \n When the execution within the scope reaches the declaration, the variable is set to the value specified by the   (an assignment) – if there is one. If there isn’t, the value value of the variable remains  . \n \n Variables declared via   have temporal dead zones, which means that their life cycles look like this: \n \n When the scope (its surrounding block) of a   variable is entered, storage space (a so-called  ) is created for it. The variable remains uninitialized. \n \n \n Getting or setting an uninitialized causes a ReferenceError. \n \n \n When the execution within the scope reaches the declaration, the variable is set to the value specified by the   (an assignment) – if there is one. If there isn’t, the value of the variable is set to  . \n \n  variables work similarly to   variables, but they must have an initializer (i.e., be set to a value immediately) and can’t be changed. Within a TDZ, an exception is thrown if a variable is got or set: The following example demonstrates that the dead zone is really   (based on time) and not spatial (based on location):  and the temporal dead zone   # A variable being unaccessible in the temporal dead zone means that you can’t even apply   to it: I don’t expect this to be a problem in practice, because you can’t conditionally add  -declared variables to a scope. In contrast, you can do so for  -declared variables; assigning to a property of   creates a global   variable:  in loop heads   # In loops, you get a fresh   for each iteration if you  -declare a variable. The loops that allow you to do so are:  ,   and  . This looks as follows: In contrast, a   declaration leads to a single binding for the whole loop (a   declaration works the same): Getting a fresh binding for each iteration may seem strange at first, but it is very useful whenever you use loops to create functions (e.g. callbacks for event handling) that refer to loop variables. Parameters   # Parameters versus local variables   # If you  -declare a variable that has the same name as a parameter, you get a static (load-time) error: Doing the same inside a block shadows the parameter: In contrast,  -declaring a variable that has the same name as a parameter does nothing, just like re-declaring a   variable within the same scope does nothing. Parameter default values and the temporal dead zone   # If parameters have default values  [2] , they are treated like a sequence of   statements and are subject to temporal dead zones: Parameter default values don’t see the scope of the body   # The scope of parameter default values is separate from the scope of the body (the former surrounds the latter). That means that methods or functions defined “inside” parameter default values don’t see the local variables of the body: The global object   # JavaScript’s  global object  (  in web browsers,   in Node.js) is more a bug than a feature, especially with regard to performance. That’s why it’s not surprising that ES6 introduces a distinction: \n All properties of the global object are global variables. In global scope, the following declarations create such properties:\n \n  declarations \n Function declarations \n \n \n But there are now also global variables that are not properties of the global object. In global scope, the following declarations create such variables:\n \n  declarations \n  declarations \n Class declarations \n \n \n Function declarations and class declarations   # Function declarations… \n are block-scoped, like  . \n create properties on the global object (while in global scope), like  . \n are  : independently of where a function declaration is mentioned in its scope, it is always created at the beginning of the scope. \n The following code demonstrates the hoisting of function declarations: Class declarations… \n are block-scoped. \n don’t create properties on the global object. \n are   hoisted. \n Classes not being hoisted may be surprising, because, under the hood, they create functions. The rationale for this behavior is that the values of their   clauses are defined via expressions and those expressions have to be executed at the appropriate times. Further reading   # Using ECMAScript 6 today  [an early draft of my book on ECMAScript 6]  ↩︎ \n Destructuring and parameter handling in ECMAScript 6   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/proto-breaks-webapps.html", "title": "The text “__proto__” can break a webapp", "content": "The text “__proto__” can break a webapp esnext dev javascript __proto__ jslang series \nThe text “__proto__” can still break webapps if it appears somewhere in the content, as I was reminded of today, via  Domenic Denicola  and  Peter van der Zee .\n\n \n\n The breakage \n      For a while, if you typed in “__proto__” at the beginning of a document in Google Docs then it would  hang . \n      If you click on @__proto__ in a tweet then the profile summary that comes up only has a title bar, but no content. You also get “slow script” dialogs in Firefox.\nYou can try it out in  this tweet . \n Why? [1] [2] \n  is only supported in  some browsers , things only break if it is supported. Thus, Firefox exhibits these problems, but Internet Explorer 9 does not. However,   will become part of ECMAScript 6  [1]  which means that all browsers will eventually support it.\n\n References JavaScript: __proto__ The pitfalls of using objects as maps in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/tablet-aspect-ratios.html", "title": "What is the best display aspect ratio for tablets?", "content": "What is the best display aspect ratio for tablets? mobile computers tablet The aspect ratios of current tablet displays \n \nThe last column shows the aspect ratio normalized to an area of 12288 (96 times 128). That is, all areas in that columns are the same, only the sides of the rectangles are different. The formula for the factor   with which the sides have to be multiplied is:\n \n \n \n \nThe rectangles look as follows.\n \n \n \n Is there a perfect aspect ratio? \n \n \n     Among the tablets covered here, the iPad works best in portrait orientation. Its display has the “widest” aspect ratio of all tablets. That aspect ratio is the same as those of  XGA  displays and TVs.\n        It is also close to Letter paper.\n        Note that the  Kindle Paperwhite  that is clearly optimized for being used in portrait orientation, has the same display aspect ratio as the iPad (768 × 1024 pixels).\n        Alas, the iPad works less well for movies where black bars mean that you lose quite a bit of display space.\n     \n     The Surface works best for watching movies. Its resolution (between 1365  × 768 and 1366 × 768.375) is almost 16:9, the aspect ratio of DVDs and many notebook screens.\n     \n     The Nexus is situated between the extremes iPad and Surface. It is less elongated than 16:9. \n Lichtenberg ratio comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/online-conferences.html", "title": "Online conferences", "content": "Online conferences life business JavaScript Summit 2012 How it works Benefits \n  One question is important: Why wouldn’t you simply watch free videos and save your money? There are two aspects of an online conference that elevate it above watching videos on your own:\n \n     You can interact with the speakers. \n     You can interact with other members of the audience. I’m not sure how useful that is and how well it scales up to large audiences, but it might contribute to the conference feeling like an event. \n Federated conferences \nHowever, one could have local sub-conferences – a federated conference, if you will. That is, people meet locally to watch talks together. For keynotes, this is already a reality: during the past year, I’ve attended local screenings of the Google I/O keynotes and the Microsoft BUILD keynote, in Munich. The nice thing is that one still doesn’t have to travel, but gets some of the social benefits of an offline conference. The JavaScript Summit supports the idea of federation via “Meeting Room Tickets”: An “Individual Ticket” only allows one person to attend virtually, the Meeting Room Ticket is for an arbitrary amount of people, in a single room. It is sold as “ideal for projecting the summit in an auditorium or meeting room”. The price for a Meeting Room Ticket is roughly three times the price of an Individual Ticket.\n\n Pricing dotJS Mix-IT BarCamps comments powered by Disqus."},
{"url": "https://2ality.com/2012/10/mac-gui-from-shell.html", "title": "Controlling the Mac user interface from the shell", "content": "Controlling the Mac user interface from the shell jsshell dev shell mac [1] open open and files \n     Open a folder in the Finder:\n \n     \n     Open a file in the application that has been associated with it (which can be overridden per file):\n \n     \n     Reveal a file in the Finder (instead of opening it):\n \n     \n     Open a file with a given application:\n \n     \n open and URLs \n     Open a URL:\n \n     \n     Open a   URL to generate an email:\n \n        Check  [2]  for details.\n     \n open and text editors answer \n  has the following options for working with text editors:\n \n     Open a file in TextEdit:\n \n     \n     Open a file with the default text editor:\n \n     \n     Read stdin, open the result in the default text editor. For example, the following command reads input from the keyboard and puts what you have typed in new window.\n \n        Another example: open the text “Hello World!” in a new window.\n \n        On my system,   always used TextEdit, so your mileage may vary.\n     \n [3] osascript [4] pbpaste and pbcopy \nExample – changing the clipboard (e.g. if the current content of the clipboard is the plain text \"Hello World\", then it becomes \"Hell- W-rld\").\n uglify.js References Write your shell scripts in JavaScript, via Node.js Generate emails via mailto URLs on Node.js openurl – a Node.js module for opening URLs Reload a web browser when a file changes (Node.js, Grunt, Mac) comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/soundscript.html", "title": "Google SoundScript: faster OOP for JavaScript", "content": "Google SoundScript: faster OOP for JavaScript esnext dev javascript typedjs  More information – “ Experimental New Directions for JavaScript ” by Andreas Rossberg (slides in English). Google is currently working on  , a way to speed up object-oriented programming in JavaScript. The content of this blog post is completely based on a recent talk  [1]  by Dmitry Lomov. That is, everything I have written here is inferred from those slides and may or may not be correct.  This blog post describes first ideas, avenues that Google is exploring for making JavaScript OOP faster. The final version of SoundScript may look and work completely different. Speeding up JavaScript   # JavaScript has already become quite fast. Additionally, Mozilla recently presented asm.js  [2]  as a way to compile static languages such as C++ to JavaScript. asm.js shares many traits with bytecode and achieves about 70% of native speed. asm.js is great for cross-compiling and for number crunching (e.g. a video codec), but it doesn’t help with more sophisticated JavaScript and lives in a relatively separate world (it does its own memory management in a heap stored in a typed array). SoundScript has been created by Google to fill that gap. Before we examine how it works, let’s first look at things that slow down JavaScript OOP in V8. Things that slow down OOP in V8   # Variables and properties can have values of any type   # The type of the value stored in a variable or a property can change at any time, which means that the storage space used for it cannot be optimized for a particular type. Therefore, V8 stores all values in single machine words: \n Objects are pointers into the heap. \n Numbers:\n \n Small integers are stored as 31-bit (plus the type tag 0 stored in the zero-th bit). \n Doubles are pointers into the heap. \n \n \n Strings are pointers into the heap. \n Etc. \n Pointers are bad for performance, especially those for doubles. Properties can be added to and removed from objects   # In V8, objects have so-called   – objects are internally assigned classes depending on the order in which properties are added to them. Such classes allow performance optimizations similar to those that are performed in more static languages. Dynamically adding and removing properties changes the hidden class of an object, which often prevents those optimizations. Parameter types can vary   # In V8, each formal parameter has an   in V8, a list of hidden classes that the value may be an instance of. This list is filled at runtime, by observing code execution. The inline cache speeds up accessing properties, because a hidden class maps property names to indices and lets the compiled code access properties by index (as opposed to by name, via a hashmap). The following code examples are taken from Mr. Lomov’s slides  [1:1] . If the list has a single entry, access is fast (a single machine instruction): If there are two entries, things are slower, because more checks are necessary. (Remember that the order in which properties are added matter for hidden classes.) The more entries there are, the poorer performance becomes: Arrays can have holes   # If arrays don’t have holes, their elements are stored as contiguous memory and accessed via indices: If arrays do have holes, a map from indices to elements has to be used: Arrays can have elements of any type   # If arrays don’t have holes and only contain small integers or doubles, their storage space is optimized: small integers don’t have type tags, doubles are stored as 64 bit values (not as pointers). SoundScript   # SoundScript (“sound” as in type systems not as in noise) comprises two modes that lead to object-oriented JavaScript becoming more efficient. Stricter mode   # SoundScript is enabled by a new “stricter” mode, which is switched on similarly to  strict mode , by putting the following line first in a file or in a function: Stricter mode limits JavaScript‘s dynamism in the following ways: \n Arrays are not allowed to have holes. \n Objects and the instances produced by ECMAScript 6 classes are  sealed  (you can’t add or remove properties or change the attributes of properties). \n And a few other minor restrictions (that are still work in progress). \n Take, for example, the following ECMAScript 6 class: \n  is sealed \n  is sealed \n  is sealed \n Typed stricter mode   # This mode leads to JavaScript being statically typed, via type annotations (whose syntax is compatible with TypeScript, Flow and AtScript  [3] ). This looks as follows. Typed stricter mode is fastest if everything is typed and no variable has the type  . If a variable has the type   it will be handled like a normal JavaScript variable (and be as slow). Typed stricter mode ensures that inline caches have single entries and that less checks for the hiddden classes of values are necessary. Conclusion   # The division of labor is clear: \n Use asm.js if you need to crunch numbers. \n Use SoundScript if you need fast OOP. Further optimizations for storing objects efficiently are being worked on (e.g.  Typed Objects ). \n Use JavaScript for everything else. Then you get maximum flexibility and static typing (should you desire it) is completely optional  [3:1] . \n SoundScript is still in its very early stages. What matters is that Google experiments with making JavaScript OOP faster.   SoundScript is integrated with JavaScript can still be tweaked later. Random idea of mine: Instead of marking code via   and  , it may be feasible to use ES6 modules in some way. Further reading   # “ Javascript at the speed of light ” by Dmitry Lomov (slides)  ↩︎   ↩︎ \n asm.js: closing the gap between JavaScript and native   ↩︎ \n Statically typed JavaScript via Microsoft TypeScript, Facebook Flow and Google AtScript   ↩︎   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/es6-book.html", "title": "First details of my upcoming book on ES6", "content": "First details of my upcoming book on ES6 esnext dev javascript I’m glad that I can finally announce the first details of my upcoming book: \n  Exploring ES6 – Upgrade to the next version of JavaScript \n   ExploringJS.com \n \n Go there to get more information and to subscribe to be notified when the book comes out. \n \n \n Thanks to everybody who helped me figure out the title! comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/flow-playground.html", "title": "Try out Facebook’s Flow typechecker online", "content": "Try out Facebook’s Flow typechecker online esnext dev javascript typedjs facebook flow typescript You can now try out Flow  [1] , Facebook’s typechecker for JavaScript, online, at  tryflow.org . The following example demonstrates Flow‘s power: The last line produces a static (“compile time”) error, because Flow infers the signature: In contrast, TypeScript infers the following signature (which you can check in the  TypeScript Playground ): Statically typed JavaScript via Microsoft TypeScript, Facebook Flow and Google AtScript   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/es6-classes-final.html", "title": "Classes in ECMAScript 6 (final semantics)", "content": "Classes in ECMAScript 6 (final semantics) esnext dev javascript chapter “Classes” Recently , TC39 decided on the final semantics of classes in ECMAScript 6  [1] . This blog post explains how their final incarnation works. The most significant recent changes were related to how subclassing is handled. Overview   # The essentials   # Base classes   # A class is defined like this in ECMAScript 6 (ES6): You use this class just like an ES5 constructor function: In fact, the result of a class definition is a function: However, you can only invoke a class via  , not via a function call ( Sect. 9.2.2  in the spec): # Function declarations are  : When entering a scope, the functions that are declared in it are immediately available – independently of where the declarations happen. That means that you can call a function that is declared later: In contrast, class declarations are not hoisted. Therefore, a class only exists after execution reached its definition and it was evaluated. Accessing it beforehand leads to a  : The reason for this limitation is that classes can have an   clause whose value is an arbitrary expression. That expression must be evaluated in the proper “location”, its evaluation can’t be hoisted. Not having hoisting is less limiting than you may think. For example, a function that comes before a class declaration can still refer to that class, but you have to wait until the class declaration has been evaluated before you can call the function. # Similarly to functions, there are two kinds of  , two ways to define a class:   and  . Also similarly to functions, the identifier of a class expression is only visible within the expression: Inside the body of a class definition   # A class body can only contain methods, but not data properties. Prototypes having data properties is generally considered an anti-pattern, so this just enforces a best practice. # Let’s examine three kinds of methods that you often find in class literals. The object diagram for this class declaration looks as follows. Tip for understanding it:   is an inheritance relationship between objects, while   is a normal property whose value is an object. The property   is only special because the   operator uses its value as the prototype for instances it creates.  This method is special, as it defines the function that represents the class: It is sometimes called a  . It has features that normal constructor functions don’t have (mainly the ability to constructor-call its super-constructor via  , which is explained later).    (or  ) are properties of   itself. If you prefix a method definition with  , you create a class method:  The   of   are the properties of  . They are usually methods and inherited by instances of  . # The syntax for getters and setters is just like  in ECMAScript 5 object literals : You use   as follows. # You can define the name of a method via an expression, if you put it in square brackets. For example, the following ways of defining   are all equivalent. Several special methods in ECMAScript 6 have keys that are symbols  [2] . Computed method names allow you to define such methods. For example, if an object has a method whose key is  , it is    [3] . That means that its contents can be iterated over by the   loop and other language mechanisms. # If you prefix a method definition with an asterisk ( ), it becomes a    [3:1] . Among other things, a generator is useful for defining the method whose key is  . The following code demonstrates how that works. Subclassing   # The   clause lets you create a subclass of an existing constructor (which may or may not have been defined via a class): Again, this class is used like you’d expect: There are two kinds of classes: \n  is a  , because it doesn’t have an   clause. \n  is a  . \n There are two ways of using  : \n A   (the pseudo-method   in a class literal) uses it like a function call ( ), in order to make a super-constructor call (line A). \n Method definitions (in object literals or classes, with or without  ) use it like property references ( ) or method calls ( ), in order to refer to super-properties (line B). \n # The prototype of a subclass is the superclass in ECMAScript 6: That means that static properties are inherited: You can even super-call static methods: # In a derived class, you must call   before you can use  : Implicitly leaving a derived constructor without calling   also causes an error: # Just like in ES5, you can override the result of a constructor by explicitly returning an object: If you do so, it doesn’t matter whether   has been initialized or not. In other words: you don’t have to call   in a derived constructor if you override the result in this manner. # If you don’t specify a   for a base class, the following definition is used: For derived classes, the following default constructor is used: # In ECMAScript 6, you can finally subclass all built-in constructors (there are  work-arounds for ES5 , but these have significant limitations). For example, you can now create your own exception classes (that will inherit the feature of having a stack trace in most engines): You can also create subclasses of   whose instances properly handle  : Note that subclassing built-in constructors is something that engines have to support natively, you won’t get this feature via transpilers. The details of classes   # What we have seen so far are the essentials of classes. You only need to read on if you are interested how things happen under the hood. Let’s start with the syntax of classes. The following is a slightly modified version of the syntax shown in  Sect. A.4 of the ECMAScript 6 specification . Two observations: \n \n The value to be extended can be produced by an arbitrary expression. Which means that you’ll be able to write code such as the following: \n \n \n \n Semicolons are allowed between methods. \n \n Various checks   # \n \n Error checks: the class name cannot be   or  ; duplicate class element names are not allowed; the name   can only be used for a normal method, not for a getter, a setter or a generator method. \n \n \n Classes can’t be function-called. They throw a   if they are. \n \n \n Prototype methods cannot be used as constructors: \n \n \n Attributes of properties   # Class declarations create (mutable) let bindings. For a given class  : \n Static methods   are writable and configurable, but not enumerable. Making them writable allows for dynamic patching. \n A constructor and the object in its property   have an immutable link:\n \n  is non-writeable, non-enumerable, non-configurable. \n  is non-writeable, non-enumerable, non-configurable. \n \n \n Prototype methods   are writable and configurable, but not enumerable. \n Note that method definitions in object literals produce enumerable properties. The details of subclassing   # In ECMAScript 6, subclassing looks as follows. This code produces the following objects. The next subsection examines the prototype chains (in the two columns), the subsection after that examines how   is allocated and initialized. Prototype chains   # In the diagram, you can see that there are two   (objects linked via the   relationship, which is an inheritance relationship): \n \n Left column: classes (functions). The prototype of a derived class is the class it extends. The prototype of a base class is  , which is also the prototype of functions: \n \n \n \n Right column: the prototype chain of the instance. The whole purpose of a class is to set up this prototype chain. The prototype chain ends with   (whose prototype is  ), which is also the prototype of objects created via object literals: \n \n \n The prototype chain in the left column leads to static properties being inherited. Allocating and initializing the instance object   # The data flow between class constructors is different from the canonical way of subclassing in ES5. Under the hood, it roughly looks as follows. The instance object is created in different locations in ES6 and ES5: \n In ES6, it is created in the base constructor, the last in a chain of constructor calls. \n In ES5, it is created in the operand of  , the first in a chain of constructor calls. \n The previous code uses two new ES6 features: \n \n  is an implicit parameter that all functions have. It is to constructor calls what   is to method calls. \n \n If a constructor has been directly invoked via  , its value is that constructor (line B). \n If a constructor was called via  , its value is the   of the constructor that made the call (line A). \n During a normal function call, it is  . That means that you can use   to determine whether a function was function-called or constructor-called (via  ). \n Inside an arrow function,   refers to the   of the surrounding non-arrow function. \n \n \n \n   [4]  lets you do a constructor call while specifying   via the last parameter. \n \n The advantage of this way of subclassing is that it enables normal code to subclass built-in constructors (such as   and  ). A later section explains why a different approach was necessary. # \n  originally being uninitialized in derived constructors means that an error is thrown if they access   in any way before they have called  . \n Once   is initialized, calling   produces a  . This protects you against calling   twice. \n If a constructor returns implicitly (without a   statement), the result is  . If   is uninitialized, a   is thrown. This protects you against forgetting to call  . \n If a constructor explicitly returns a non-object (including   and  ), the result is   (this behavior is required to remain compatible with ES5 and earlier). If   is uninitialized, a   is thrown. \n If a constructor explicitly returns an object, it is used as its result. Then it doesn’t matter whether   is initialized or not. \n # Let’s examine how the   clause influences how a class is set up ( Sect. 14.5.14 of the spec ). The value of an   clause must be “constructible” (invocable via  ).   is allowed, though. \n Constructor kind: base \n Prototype of  :   (like a normal function) \n Prototype of  :   (which is also the prototype of objects created via object literals) \n \n Constructor kind: derived \n Prototype of  :  \n Prototype of  :  \n \n Constructor kind: derived \n Prototype of  :  \n Prototype of  :  \n Note the following subtle difference with the first case: If there is no   clause, the class is a base class and allocates instances. If a class extends  , it is a derived class and   allocates the instances. The resulting instances (including their prototype chains) are the same, but you get there differently. \n Constructor kind: derived \n Prototype of  :  \n Prototype of  :  \n Such a class is not very useful:  -calling it leads to an error, because the default constructor makes a super-constructor call and   (the super-constructor) can’t be constructor-called. The only way to make the error go away is by adding a   that returns an object. Why can’t you subclass built-in constructors in ES5?   # In ECMAScript 5, most built-in constructors can’t be subclassed ( several work-arounds exist ). To understand why, let’s use the canonical ES5 pattern to subclass  . As we shall soon find out, this doesn’t work. Unfortunately, if we instantiate  , we find out that it doesn’t work properly: The instance property   does not change in reaction to us adding array elements: There are two obstracles that prevent   from being a proper array.  The   you hand to the constructor   (in line A) is completely ignored. That means you can’t use   to set up the instance that was created for  .  The instance objects created by   are   (a term used by the ECMAScript specification for objects that have features that normal objects don’t have): Their property   tracks and influences the management of array elements. In general, exotic objects can be created from scratch, but you can’t convert an existing normal object into an exotic one. Unfortunately, that is what   would have to do, when called in line A: It would have to turn the normal object created for   into an exotic array object. # In ECMAScript 6, subclassing   looks as follows: This works (but it’s not something that ES6 transpilers can support, it depends on whether a JavaScript engine supports it natively): We can now see how the ES6 approach to subclassing circumvents the obstacles: \n Allocation happens in the base constructor, which means that   can allocate an exotic object. While most of the new approach is due to how derived constructors behave, this step requires that a base constructor is aware of   and makes   the protoype of the allocated instance. \n Initialization also happens in the base constructor, a derived constructor receives an initialized object and works with that one instead of passing its own instance to the super-constructor and requiring it to set it up. \n Referring to super-properties in methods   # The following ES6 code makes a super-method call in line B. To understand how super-calls work, let’s look at the object diagram of  :  makes a super-call (line B) to the method (starting in line A) that it has overridden. Let’s call the object, in which a method is stored, the   of that method. For example,   is the home object of  . The super-call in line B involves three steps: \n Start your search in the prototype of the home object of the current method. \n \n Look for a method whose name is  . That method may be found in the object where the search started or later in the prototype chain. \n \n Call that method with the current  . The reason for doing so is: the super-called method must be able to access the same instance properties (in our example, the properties of  ). \n Note that even if you are only getting or setting a property (not calling a method), you still have to consider   in step #3, because the property may be implemented via a getter or a setter. Let’s express these steps in three different, but equivalent, ways: Variation 3 is how ECMAScript 6 handles super-calls. This approach is supported by  two internal   that the   of functions have (  provide storage space, so-called  , for the variables in a scope): \n : This internal binding also exists in ECMAScript 5 and stores the value of  . \n : Refers to the home object of the environment’s function. Filled in via an internal property   that all methods have that use  . Both the binding and the property are new in ECMAScript 6. \n A method definition in a class literal that uses   is now special: Its value is still a function, but it has the internal property  . That property is set up by the method definition and can’t be changed in JavaScript. Therefore, you can’t meaningfully move such a method to a different object. Using   to refer to a property is not allowed in function declarations, function expressions and generator functions. Referring to super-properties is handy whenever prototype chains are involved, which is why you can use it in method definitions inside object literals and class literals (the class can be derived or not, the method can be static or not). Constructor calls explained via JavaScript code   # The JavaScript code in this section is a much simplified version of how the specification describes constructor calls and super-constructor calls. It may be interesting to you if you prefer code to explanations in human language. Before we can delve into the actual functionality, we need to understand a few other mechanisms. Internal variables and properties   # The specification writes internal variables and properties in double brackets ( ). In the code, I use double underscores, instead ( ). Internal variables used in the code: \n : The operand of the   operator that triggered the current constructor call (passed on if   is called recursively via  ). \n : Stores the value of  . \n : Refers to the function that is currently executed. \n Internal properties used in the code: \n : All constructor functions (including those created by classes) have this own (non-inherited) method. It implements constructor calls and is invoked by  . \n : A property of constructor functions whose value is either   or  . \n Environments   #  provide storage space for variables, there is one environment per scope. Environments are managed as a stack. The environment on top of that stack is considered active. The following code is a sketch of how environments are handled. Constructor calls   # Let’s start with the default way ( ES6 spec Sect. 9.2.3 ) in which constructor calls are handled for functions: Super-constructor calls   # Super-constructor calls are handled as follows ( ES6 spec Sect. 12.3.5.1 ). The species pattern   # One more mechanism of built-in constructors has been made extensible in ECMAScript 6: If a method such as   returns a fresh instance, what constructor should it use to create that instance? The default is to use the same constructor that created  , but some subclasses may want it to remain a direct instance of  . ES6 lets subclasses override the default, via the so-called  : \n When creating a new instance of  , methods such as   use the constructor stored in  . \n If a sub-constructor of   does nothing, it inherits  . That property is a getter that returns  . \n You can override the default, via a static getter (line A): An alternative is to use   (you can’t use assignment, as that would trigger a setter, which doesn’t exist): The following getters all return  , which means that methods such as   use the constructor that created the current instance for their results. \n \n \n \n \n \n \n \n Conclusion   # The specialization of functions   # There is an interesting trend in ECMAScript 6: Previously, a single kind of function took on three roles: real function, method and constructor. In ES6, there is specialization: \n \n Arrow functions are specialized for non-method callbacks, where them picking up the   of their surrounding method or constructor is an advantage. Without  , they don’t make much sense as methods and they throw an exception when invoked via  . \n \n \n Method definitions enable the use of  , by setting up the property  . The functions they produce can’t be constructor-called. \n \n \n Class definitions are the only way to create derived constructors (enabling ES6-style subclassing that works for built-in constructors). Class definitions produce functions that can only be constructor-called. \n \n The future of classes   # The design maxim for classes was “maximally minimal”. Several advanced features were discussed, but ultimately discarded in order to get a design that would be unanimously accepted by TC39. Upcoming versions of ECMAScript can now extend this minimal design – classes will provide a foundation for features such as traits (or mixins), value objects (where different objects are equal if they have the same content) and const classes (that produce immutable instances). Does JavaScript need classes?   # Classes are controversial within the JavaScript community. On one hand, people coming from class-based languages are happy that they don’t have to deal with JavaScript’s unorthodox inheritance mechanisms, anymore. On the other hand, there are many JavaScript programmers who argue that what’s complicated about JavaScript is not prototypal inheritance, but constructors  [5] . ES6 classes provide a few clear benefits: \n \n They are backwards compatible with much of the current code. \n \n \n Compared to constructors and constructor inheritance, classes make it easier for beginners to get started. \n \n \n Subclassing is supported within the language. \n \n \n Built-in constructors are subclassable. \n \n \n No library for inheritance is needed, anymore; code will become more portable between frameworks. \n \n \n They provide a foundation for advanced features in the future (mixins and more). \n \n \n They help tools that statically analyze code (IDEs, type checkers, style checkers, etc.). \n \n I have made my peace with classes and am glad that they are in ES6. I would have preferred them to be prototypal (based on constructor objects  [5:1] , not constructor functions), but I also understand that backwards compatibility is important. Further reading   # Acknowledgement: #1 was an important source of this blog post. “ Exploring ES6: Upgrade to the next version of JavaScript ”, book by Axel  ↩︎ \n Symbols in ECMAScript 6   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎   ↩︎ \n Meta programming with ECMAScript 6 proxies   ↩︎ \n Prototypes as classes – an introduction to JavaScript inheritance   ↩︎   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/exploring-es6-cover.html", "title": "Vote for your favorite “Exploring ES6” cover!", "content": "Vote for your favorite “Exploring ES6” cover! esnext dev javascript exploring es6 There are two candidates for the cover of my upcoming book, “ Exploring ES6 ”. You can now  vote for your favorite . I’ll announce a winner in a week. comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/using-es6-today-minsk.html", "title": "A 90 minute overview of ECMAScript 6 (video)", "content": "A 90 minute overview of ECMAScript 6 (video) esnext dev javascript On February 1, 2015, I held the 90 minute talk “Using ECMAScript 6 today” at the  Rolling Scopes Conference  in Minsk. A video recording of that talk is online: \n Part 1  [40:44] \n Part 2  [53:04] \n Slides \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/02/es6-iteration.html", "title": "Iterables and iterators in ECMAScript 6", "content": "Iterables and iterators in ECMAScript 6 esnext dev javascript iteration  Please read chapter “ Iterables and iterators ” in “Exploring ES6”. This blog post is part of a series on iteration in ES6: Iterables and iterators in ECMAScript 6 ES6 generators in depth ECMAScript 6 introduces a new interface for iteration,  . This blog post explains how it works, which language constructs consume data via it (e.g., the new   loop) and which sources provide data via it (e.g., arrays). Iterability   # The idea of iterability is as follows. \n \n  JavaScript has language constructs that consume data. For example,   loops over values and the spread operator ( ) inserts values into arrays or function calls. \n \n \n  The data consumers could get their values from a variety of sources. For example, you may want to iterate over the elements of an array, the key-value entries in a map or the characters of a string. \n \n It’s not practical for every consumer to support all sources, especially because it should be possible to create new sources and consumers, e.g. via libraries with data structures or with new ways of processing data. Therefore, ES6 introduces the interface  . Data consumers use it, data sources implement it: Given that JavaScript does not have interfaces,   is more of a convention: \n \n  A value is considered   if it has a method whose key is the symbol  [1]    that returns a so-called  . The iterator is an object that returns values via its method  . We say: it  , one per method call. \n \n \n  Data consumers use the iterator to retrieve the values they are consuming. \n \n Let’s see what consumption looks like for an array  . First, you create an iterator via the method whose key is  : Then you call the iterator’s method   repeatedly to retrieve the items “inside” the array: As you can see,   returns each item wrapped in an object, as the value of the property  . The boolean property   indicates when the end of the sequence of items has been reached.  and iterators are part of a so-called   (methods plus rules for using them) for iteration. A key characteristic of this protocol is that it is sequential: the iterator returns values one at a time. That means that if an iterable data structure is non-linear (such as a tree), iteration will linearize it. Iterable data sources   # I’ll use the   loop (which is explained in more detail later) to iterate over various kinds of iterable data. Arrays   # Arrays (and typed arrays) are iterables over their elements: Strings   # Strings are iterable, but they enumerate Unicode code points, each of which may comprise one or two JavaScript “characters”: Note that you have just seen that primitive values can be iterable, too. A value doesn’t have to be an object in order to be iterable. Maps   # Maps  [2]  are iterables over their entries. Each entry is encoded as a   pair, an array with two elements. The entries are always enumerated deterministically, in the same order in which they were added to the map. Note that WeakMaps  [2:1]  are not iterable. Sets   # Sets  [2:2]  are iterables over their elements (which are enumerated in the same order in which they were added to the set). Note that WeakSets  [2:3]  are not iterable.    # Even though the special variable   is more or less obsolete in ECMAScript 6 (due to rest parameters), it is iterable: DOM data structures   # Most DOM data structures will eventually be iterable: Note that implementing this functionality is work in progress. But it is relatively easy to do so, because the symbol   can’t clash with existing property keys  [1:1] . Iterable computed data   # Not all iterable content does have to come from data structures, it could also be computed on the fly. For example, all major ES6 data structures (arrays, typed arrays, maps, sets) have three methods that return iterable objects: \n  returns an iterable over entries encoded as   arrays. For arrays, the values are the array elements and the keys are their indices. For sets, each key and value are the same – the set element. \n  returns an iterable over the keys of the entries. \n  returns an iterable over the values of the entries. \n Let’s see what that looks like.   gives you a nice way to get both array elements and their indices: Plain objects are not iterable   # Plain objects (as created by object literals) are not iterable: The reasoning is as follows. The following two activities are different: Examining the structure of a program (reflection) Iterating over data It is best to keep these two activities separate. #1 is relevant for all objects, #2 only for data structures. You could make most objects iterable by adding a method   to  , but they would lose this ability in two cases: \n If they are created via  . Then   is not in their prototype chain. \n If they are data structures. Then they need iterability for their data. Not only would you not be able to iterate over the properties of, say, arrays (which are also data structures). But you couldn’t ever later add iterability to an existing class, because that would break code that iterates over the properties of their instances. \n Therefore, the safest way to make properties iterable is via a tool function. For example, via  , whose implementation is shown later (future ECMAScript versions may have something similar built in): It is also important to remember that iterating over the properties of an object is mainly interesting if you use objects as maps  [3] . But we only do that in ES5 because we have no better alternative. In ECMAScript 6, we have  . Iterating language constructs   # This section lists all built-in ES6 programming constructs that make use of the iteration protocol. Destructuring via an array pattern   # Destructuring  [4]  via array patterns works for any iterable: The   loop   #  is a new loop in ECMAScript 6. One form of it looks like this: This loop iterates over  , assigns each of the enumerated items to the iteration variable   and lets you process it in the body. The scope of   is the loop, it doesn’t exist outside it. Note that the iterability of   is required, otherwise   can’t loop over a value. That means that non-iterable values must be converted to something iterable. For example, via  , which turns array-like values and iterables into arrays: I expect   to mostly replace  , because it is more versatile (  only works for array-like values) and will be faster long term (see FAQ at the end). # If you  -declare the iteration variable, a fresh binding (slot) will be created for each iteration. That can be seen in the following code snippet where we save the current binding of   for later, via an arrow function. Afterwards, you can see that the arrow functions don’t share the same binding for  , they each have a different one. It is instructive to see how things are different if you  -declare the iteration variable. Now all arrow functions refer to the same binding of  . Having one binding per iteration is very helpful whenever you create functions via a loop (e.g. to add event listeners). # Two more loops get one binding per iteration if you  -declare their iteration variables:   and  . Let’s look at   with a  -declared iteration variable  : If you  -declare  , you get the traditional behavior. Similarly,   with a  -declared iteration variable   leads to one binding per iteration: -declaring   produces a single binding: # So far, we have only seen   with a declared iteration variable. But there are several other forms. You can iterate with an existing variable: You can also iterate with an object property: And you can iterate with an array element: # Combining   with destructuring is especially useful for iterables over key-value pairs (encoded as arrays). That’s what maps are:  also returns an iterable over key-value pairs: Therefore,   gives you a way to treat enumerated items differently, depending on their position: This function is used as follows:    #   [5]  converts iterable and array-like values to arrays. It is also available for typed arrays.  works as expected for a subclass of   (which inherits this class method) – it converts iterables to instances of the subclass. Spread   # The spread operator  [4:1]  inserts the values of an iterable into an array: That means that it provides you with a compact way to convert any iterable to an array: The spread operator also turns an iterable into the arguments of a function, method or constructor call: Maps and sets   # The constructor of a map turns an iterable over   pairs into a map: The constructor of a set turns an iterable over elements into a set: The constructors of   and   work similarly. Furthermore, maps and sets are iterable themselves (WeakMaps and WeakSets aren’t), which means that you can use their constructors to clone them. Promises   #  and   accept iterables over promises  [6] :    #   [7]  yields all items enumerated by an iterable. The most important use case for   is to recursively call a generator  [7:1]  (which produces something iterable). Implementing iterables   # The iteration protocol looks as follows. An object becomes   (“implements” the interface  ) if it has a method (own or inherited) whose key is  . That method must return an  , an object that   the   “inside” the iterable via its method  . In TypeScript notation, the interfaces for iterables and iterators look as follows (based on  [8] ):  is an optional methods that we’ll get to later (so is  , but it is practically never used for iterators and therefore explained in  a follow-up blog post on generators ). Let’s first implement a dummy iterable to get a feeling for how iteration works. Let’s check that   is, in fact, iterable: The code executes three steps, with the counter   ensuring that everything happens in the right order. First we, return the value  , then the value   and then we indicate that the end of the enumerated items has been reached. Each item is wrapped in an object with the properties: \n  which holds the actual item and \n  which is a boolean flag that indicates whether the end has been reached, yet. \n You can omit   if it is   and   if it is  . That is, the   statement could be written as follows. As is explained in  the follow-up blog post on generators , there are cases where you want even the last item with   to have a  . Otherwise,   could be simpler and return items directly (without wrapping them in objects). The end of iteration would then be indicated via a special value (e.g., a symbol). Let’s look at one more implementation of an iterable. The function   returns an iterable over the arguments that are passed to it: Iterators that are iterable   # The previous function can be simplified if the iterable and the iterator are the same object: Even if the original iterable and the iterator are not the same object, it is still occasionally useful if an iterator has the following method (which also makes it an iterable): All built-in ES6 iterators follow this pattern (via a common prototype, see  follow-up blog post on generators ). For example, the default iterator for arrays: Why is it useful if an iterator is also an iterable?   only works for iterables, not for iterators. Because array iterators are iterable, you can continue an iteration in another loop: An alternative is to use a method that returns an iterable. For example, the result of   iterates the same way as the default iteration. Therefore, the previous code snippet is equivalent to: But with an iterable, you can’t be sure that it won’t restart iteration if   calls the method  . For example, instances of   are iterables that start at the beginning whenever you call this method. One use case for continuing an iteration is that you can remove initial items (e.g. a header) before processing the actual content via  . Optional iterator methods:   and     # Two iterator methods are optional: \n  gives an iterator the opportunity to clean up if an iteration ends prematurely. \n  is about forwarding a method call to a generator that is iterated over via  . It is explained in  the follow-up blog post on generators . \n # As mentioned before, the optional iterator method   is about letting an iterator clean up if it wasn’t iterated over until the end. It   an iterator. In   loops, premature (or  , in spec language) termination can be caused by: \n \n  (if you continue an outer loop,   acts like a  ) \n \n \n In each of these cases,   lets the iterator know that the loop won’t finish. Let’s look at an example, a function   that returns an iterable of text lines in a file and would like to close that file no matter what happens: Due to  , the file will be properly closed in the following loop: The   method must return an object. That is due to how generators handle the   statement and will be explained in  the follow-up blog post on generators . The following constructs close iterators that aren’t completely “drained”: \n \n \n Destructuring \n \n ,  ,  ,  \n ,  \n More examples of iterables   # In this section, we look at a few more examples of iterables. Most of these iterables are easier to implement via generators.  The follow-up blog post on generators  shows how. Tool functions that return iterables   # Tool functions and methods that return iterables are just as important as iterable data structures. The following is a tool function for iterating over the own properties of an object. Combinators for iterables   #   [9]  are functions that combine existing iterables to create new ones. Let’s start with the combinator function  , which returns an iterable over the first   items of  .  turns   iterables into an iterable of  -tuples (encoded as arrays of length  ). As you can see, the shortest iterable determines the length of the result: Infinite iterables   # Some iterable may never be  . With an infinite iterable, you must not iterate over “all” of it. For example, by breaking from a   loop: Or by only accessing the beginning of an infinite iterable: Or by using a combinator.   is one possibility: The “length” of the iterable returned by   is determined by its shortest input iterable. That means that   and   provide you with the means to number iterables of arbitrary (finite) length: Frequently asked question   # Isn’t the iteration protocol slow?   # You may be worried about the iteration protocol being slow, because a new object is created for each invocation of  . However, memory management for small objects is fast in modern engines and in the long run, engines can optimize iteration so that no intermediate objects need to be allocated. A  thread on es-discuss  has more information. Conclusion   # In this blog post we have seen that even with just the foundations of ES6 iteration, you can already do a lot. Generators  [7:2]  build on that foundation and help with, among other things, implementing iterators. The JavaScript runtime library is still missing tools for working with iterators. Python has the feature-rich module  , JavaScript will eventually get a similar module. Further reading   # Symbols in ECMAScript 6   ↩︎   ↩︎ \n ECMAScript 6: maps and sets   ↩︎   ↩︎   ↩︎   ↩︎ \n “ Pitfalls: Using an Object as a Map ” in “Speaking JavaScript”  ↩︎ \n Destructuring and parameter handling in ECMAScript 6  [includes an explanation of the spread operator ( )]  ↩︎   ↩︎ \n ECMAScript 6’s new array methods   ↩︎ \n ECMAScript 6 promises (2/2): the API   ↩︎ \n ES6 generators in depth   ↩︎   ↩︎   ↩︎ \n “ Closing iterators ”, slides by David Herman  ↩︎ \n “ Combinator ” in HaskellWiki  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/03/no-promises.html", "title": "No promises: asynchronous JavaScript with only generators", "content": "No promises: asynchronous JavaScript with only generators esnext dev javascript Two ECMAScript 6  [1]  features enable an intriguing new style of asynchronous JavaScript code: promises  [2]  and generators  [3] . This blog post explains this new style and presents a way of using it without promises. Overview   # Normally, you make a function calls like this: It would be great if this style of invocation also worked for functions that perform tasks (such as downloading a file) asynchronously. For that to work, execution of the previous code would have to pause until   returns with a result. Before ECMAScript 6, you couldn’t pause and resume the execution of code, but you could simulate it, by putting   into a callback, a so-called    [4] . The continuation is triggered by  , once it is done:   [2:1]  are basically a smarter way of managing callbacks: In ECMAScript 6, you can use generator functions  [3:1] , which can be paused and resumed.  With a library such as Q , a generator-based solution looks almost like our ideal code: Alas,   needs to be implemented using promises: However, with a small library shown later, you can run the initial code like with  , but implement   like this: Line A is how the library provides   with callbacks. The advantage compared to the previous code is that this function is again a generator and can make other asynchronous calls via  . Code   # I’ll first show two examples, before I present the code of the library. Example 1:     #  is an asynchronous function, implemented via a generator: In the following code,   is used three time, sequentially: The parallel version of this code looks as follows. As you can see, the library performs the asynchronous calls in parallel if you yield an array of generator invocations. This code takes about 1000 milliseconds. Example 2:     # The following code demonstrates how you can implement a function that gets a file via  : Let’s use   sequentially: Using   in parallel looks like this: The library   # The library profits from the fact that calling a generator function does not execute its body, but returns a generator object. Note that you only need use   and   in asynchronous functions that use callbacks. If an asynchronous function only calls other asynchronous functions (via  ) then you can simply explicitly   a value. One important feature is missing: support for calling async functions implemented via promises. It would be easy to add, though – by adding another case to  . Conclusion: asynchronous JavaScript via coroutines   #   [5]  are a single-threaded version of multi-tasking: Each coroutine is a thread, but all coroutines run in a single thread and they explicitly relinquish control via  . Due to the explicit yielding, this kind of multi-tasking is also called   (versus the usual  ). Generators are   co-routines  [6] : their execution state is only preserved   the generator function: It doesn’t extend further backwards than that and recursively called functions can’t yield. The code for asynchronous JavaScript without promises that you have seen in this blog post is purely a proof of concept. It is completely unoptimized and may have other flaws preventing it from being used in practice. But coroutines seem like the right mental model when thinking about asynchronous computation in JavaScript. They could be an interesting avenue to explore for ECMAScript 2016 (ES7) or later. As we have seen, not much would need to be added to generators to make this work: \n  is a kludge. \n Similarly, having to report results and errors via callbacks is unfortunate. It’d be nice if   and   could always be used, but they don’t work inside callbacks. \n What about streams?   # When it comes to asynchronous computation, there are two fundamentally different needs: The results of a single computation: One popular way of performing those are promises. A series of results: Asynchronous Generators  [7]  have been proposed for ECMAScript 2016 for this use case. For #1, coroutines are an interesting alternative. For #2, David Nolen has suggested  [8]  that CSP (Communicating Sequential Processes) work well. For binary data, WHATWG is working on Streams  [9] . Current practical solutions   # All current practical solutions are based on Promises: \n Q  is a promise library and polyfill that includes the aforementioned  , which is based on promises. \n co  brings just the   functionality and relies on an external Promise implementation. It is therefore a good fit for environments such as  Babel  that already have Promises. \n Babel  has a first implementation of async functions ( as proposed for ECMAScript 2016 ). Under the hood, they are translated to code that is similar to   and based on Promises. However, if you use this feature, you are leaving standard territory and your code won’t be portable to other ES6 environments. Async functions may still change considerably before they are standardized. \n Further reading   # “ Exploring ES6: Upgrade to the next version of JavaScript ”, book by Axel  ↩︎ \n ECMAScript 6 promises (2/2): the API   ↩︎   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎   ↩︎ \n Asynchronous programming and continuation-passing style in JavaScript   ↩︎ \n “ Coroutine ” on Wikipedia  ↩︎ \n “ Why coroutines won't work on the web ” by David Herman  ↩︎ \n “ Async Generator Proposal ” by Jafar Husain  ↩︎ \n “ ES6 Generators Deliver Go Style Concurrency ” by David Nolen  ↩︎ \n “ Streams: Living Standard ”, edited by Domenic Denicola and Takeshi Yoshino  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/03/destructuring-algorithm.html", "title": "The destructuring algorithm in ECMAScript 6", "content": "The destructuring algorithm in ECMAScript 6 esnext dev javascript  Please read Sect. “ The destructuring algorithm ” in “Exploring ES6”. This blog post looks at  destructuring  from a different angle: as a recursive matching algorithm. At the end, I’ll use this new knowledge to explain one especially tricky case of destructuring. Destructuring   # This section gives a brief overview of destructuring. For further details, consult the blog post “ Destructuring and parameter handling in ECMAScript 6 ”. The following code is an example of destructuring: In line (A) we destructure  : we extract data from it via a pattern on the left-hand side of the assignment operator ( ) and assign that data to the variables   and  . These variables are automatically declared beforehand, because the line starts with a  . You can destructure arrays, too: Destructuring can be used in the following locations: The algorithm   # The following is a destructuring assignment. We want to use   to extract data from  . In the following sections, I describe an algorithm for doing so. It is known in functional programming as  . The previous destructuring assignment is processed via That is, the operator   (“match against”)     against  . The algorithm is specified via recursive rules that take apart both operands of the   operator. The declarative notation may take some getting used to, but it makes the specification of the algorithm more concise. Each rule has two parts: \n The head specifies which operands are handled by the rule. \n The body specifies what to do next. \n I only show the algorithm for destructuring assignment. Destructuring variable declarations and destructuring parameter definitions work similarly. Patterns   # A pattern is either: \n A variable:  \n An object pattern:  \n An array pattern:  \n Each of the following sections covers one of these three cases. Variables   # \n \n (1)   (including   and  ) \n \n \n Object patterns   # \n \n (2a)  \n \n \n \n (2b)  \n \n \n \n (2c)  \n \n \n \n (2d)  \n \n \n \n (2e)   (done) \n \n Array patterns   # The sub-algorithm in this section starts with an array pattern and an iterable and continues with the elements of the pattern and an iterator (obtained from the iterable). The helper functions   and   are defined at the end of this section. \n \n (3a)  \n \n \n \n \n (3b)  \n \n \n \n \n (3c)  \n \n \n \n (3d)  \n \n \n \n (3e)   (hole, elision) \n \n \n \n (3f)   (always last part!) \n \n \n \n (3g)   (no elements left, nothing to do) \n \n The rules in this section use the following two helper functions: Using the algorithm   # The following function definition is used to make sure that both of the  named parameters    and   have default values and can be omitted. Additionally,   enables us to omit the object literal, too (see last function call below). But why would you define the parameters as in the previous code snippet? Why not as follows – which is also completely legal ECMAScript 6? To see why solution 1 is correct, let’s use both solutions for two examples. Using solution 2   # For function calls, formal parameters (inside function definitions) are matched against actual parameters (inside function calls). As an example, take the following function definition and the following function call. The parameters   and   are set up similarly to the following destructuring. Let’s examine how destructuring works for  .     leads to this destructuring: The only array element on the left-hand side does not have a match on the right-hand side, which is why the default value is used (rules 3b, 3d): The left-hand side contains  , it is an abbreviation for: This destructuring leads to the following two assignments (rule 2c, 1): However, this is the only case in which the default value is used.  Let’s examine the function call   which leads to the following destructuring: There is an array element at index 0 on the right-hand side. Therefore, the default value is ignored and the next step is (rule 3d): That leads to both   and   being set to  , which is not what we want. Using solution 1   # Let’s try solution 1.   We don’t have an array element at index 0 on the right-hand side and use the default value (rule 3d): The left-hand side contains property value shorthands, which means that this destructuring is equivalent to: Neither property   nor property   have a match on the right-hand side. Therefore, the default values are used and the following destructurings are performed next (rule 2d): That leads to the following assignments (rule 1):   The first element of the array pattern has a match on the right-hand side and that match is used to continue destructuring (rule 3d): Like in example 1, there are no properties   and   on the right-hand side and the default values are used: Conclusion   # The examples demonstrate that default values are a feature of pattern parts (object properties or array elements). If a part has no match or is matched against   then the default value is used. That is, the pattern is matched against the default value, instead. comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/var-statement-rules.html", "title": "Variable declarations: three rules you can break", "content": "Variable declarations: three rules you can break dev javascript jslang jsstyle \nFor this blog post, you should know how JavaScript’s function-scoped   declarations work. Consult  [1]  if you don’t.\n\n Three rules you can break Rule to break: Don’t put a var statement inside a block \n  From the perspective of JavaScript semantics, the existence of the variable   is not limited to the then-block. However, conceptually,     limited to that block: it isn’t used anywhere else and if one removes the block, it should be removed, too. Thus, the unconventional version expresses the author’s intention well. But you have to be careful to only use each pseudo-block-local variable once, because if you declare a variable a second time, it keeps its current value. Your code might assume that it is  , afterwards.\n \nConventional wisdom is right when it comes to long functions. Then you run the risk of losing track of variables. However, functions shouldn’t be longer than 5-10 lines, anyway. At that size, the increased conceptual clarity is usually worth the risks.\n\n Rule to break: Don’t put a var statement inside a loop jsPerf test Rule to break: Use a single var statement per function \nAvoiding the repetition of   has a negative effect: If you forget a comma, you can inadvertently create global variables. For example:\n [2] [3] \n     Forgetting punctuation is not an issue. This time, automatic semicolon insertion works for you, not against you.\n     \n     It is easier to rearrange and remove parts. \n     Everything is automatically indented correctly. \n ECMAScript 6 Conclusion References JavaScript variable scoping and its pitfalls Automatic semicolon insertion in JavaScript JavaScript’s strict mode: a summary comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/es6-talks.html", "title": "Four talks on ECMAScript 6/ECMAScript.next", "content": "Four talks on ECMAScript 6/ECMAScript.next esnext dev javascript \n     [2012-10-08] Brendan Eich:  Harmony of Dreams Come True  (blog post linking to video and slides) \n     [2012-10-13] Yehuda Katz:  ECMAScript 6  (video) \n     [2012-10-22] John K. Paul:  JavaScript: The Real Bad Parts  (slides) \n     [2012-10-22] Domenic Denicola:  ES6 is Nigh  (site linking to slides) \n the guide comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/canvas-in-workers.html", "title": "A proposal for using Canvas in web workers", "content": "A proposal for using Canvas in web workers dev html5 javascript clientjs \nIn the browser, all “normal” work happens in a single thread. That means that the user interface and computing tasks are competing for processor time. Thus, if you don’t want to block the user interface, you perform computationally intensive tasks in a background thread, via   (see  section below ). Creating bitmap graphics is a common activity on the web and a candidate for being done in the background.\nThe easiest solution would be to make Canvas (HTML element and bitmap API), available to workers. But that is not possible, because they don’t have access to the DOM and Canvas cannot exist independently of it. Quoting  Ian Hickson :\n \n     Option A: Provide an API for off-screen graphics in workers, requiring that every frame you package the whole thing up, send it over to the main thread, and blt it there.\n     \n     Option B: Provide a mechanism by which a worker can actually paint \ndirectly onto a main thread <canvas> element. \n \n     (A) when a rendering context is not bound to a specific canvas, it can be used as an off-screen drawing surface.\n     \n     (B) You can then bind such a rendering context to a canvas; when you do this, there is a commit() method that you can use which tells the user agent to push the bitmap drawn on the CanvasRenderingContext2D object to the canvas bitmap / screen.\n     \n Material on web workers \n     “ The Basics of Web Workers ” by Eric Bidelman at HTML5 Rocks.\n     \n     “ Using web workers ” at the Mozilla Developer Network \n     HTML specification:  web workers \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/property-assignment-prototype-chain.html", "title": "Property assignment and the prototype chain", "content": "Property assignment and the prototype chain dev javascript jslang Properties in JavaScript: definition versus assignment The prototype chain [1] [2] Assigning to properties Accessors and the prototype chain [3] [4] Read-only properties in the prototype chain [5] References JavaScript: __proto__ What object is not an instance of Object? Object properties in JavaScript JavaScript’s strict mode: a summary Properties in JavaScript: definition versus assignment comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/js-inheritance-beyond-basics.html", "title": "JavaScript inheritance: beyond the basics (video)", "content": "JavaScript inheritance: beyond the basics (video) dev javascript jslang video recording the slides \n     JavaScript inheritance basics \n     Object exemplars \n     ECMAScript 6 classes \n     Super-references \n     __proto__ \n Object properties in JavaScript \nYou can see that a lot of work went into making this video, it has been produced very professionally: the opening looks and sounds nice, the mic is great (and makes me look like a motivational speaker) and the slides have been inserted perfectly into the video.\nI’m really thankful that JSConf EU makes such professionally produced content available for free.\n comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/guide-esnext.html", "title": "A guide to 2ality’s posts on ECMAScript.next/ECMAScript 6", "content": "A guide to 2ality’s posts on ECMAScript.next/ECMAScript 6 esnext 2ality dev guide javascript esnext sitemap \nLast date covered by this guide: 2012-11-09.\n \n\nGeneral information on ECMAScript.next:\n \n     ECMAScript: ES.next versus ES 6 versus ES Harmony \n     Major and minor JavaScript pitfalls and ECMAScript 6 \n     The first ECMAScript.next features in Firefox and Chrome \n     es6-shim – ECMAScript 6 functionality on ECMAScript 5 \n     A first look at what might be in ECMAScript 7 and 8 \n \n     Quasi-literals: embedded DSLs in ECMAScript.next  [new name: template strings] \n     ECMAScript.next’s for-of loop \n     ECMAScript.next: arrow functions and method definitions \n     Keyword parameters in JavaScript and ECMAScript.next \n     Classes and object-orientation:\n         \n             ECMAScript.next: classes \n             Private data for objects in JavaScript \n             A closer look at super-references in JavaScript and ECMAScript.next \n         \n     \n     The special property  :\n         \n             JavaScript: __proto__ \n             How to pronounce __proto__ \n             The text “__proto__” can break a webapp \n         \n     \n \n     ECMAScript.next: Array.from() and Array.of() \n \n     Subtyping JavaScript built-ins \n     Make node.js code pretty via a generator-based library \n \n     ECMAScript.next: TC39’s September 2012 meeting \n     ECMAScript.next: TC39’s July 2012 meeting \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/jed-toolkit.html", "title": "Jed – a JavaScript internationalization toolkit", "content": "Jed – a JavaScript internationalization toolkit dev javascript clientjs The Jed internationalization toolkit describes Jed Toolkit Dojo Foundation libraries build tools for developers tools for translators Data formats for storing internationalized text \n     GNU gettext : is popular in the Unix world, but can only handle one translation dimension (such as  grammatical number , gender or other context) well. Even a simple example, such as a sentence containing two words with varying multiplicity, involves more than one dimension. Namely, twice the dimension “grammatical number”.\n     \n     ICU MessageFormat : handles multiple dimensions well. Quoting Sexton: “I really liked how ICU MessageFormat made a lot of decisions based on how translators think, instead of how programmers think.”.\n     \n More information Client Side Internationalization blog post \nRelated blog posts:\n \n     Crowdsourcing language translations \n     Duolingo: using free online language lessons to translate texts \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/arrays.html", "title": "Arrays in JavaScript", "content": "Arrays in JavaScript dev javascript jslang jsarrays \nThis blog post goes deeply into how arrays work in JavaScript: they are much more like objects than you might think.\n\n \n\n Overview Array indices: If a key is a string holding a non-negative integer below a certain maximum then it is treated as an array index.\n     : The value of this property is a non-negative integer holding the length of an array. That length is defined as the numerically largest array index, converted to integer, plus one. \n     Arrays with holes [2] The Array constructor : creates a new empty array. The empty array literal   is a more concise way of doing the same thing.\n     : creates an array with   holes. On  some JavaScript engines , this operation lets you pre-allocate arrays, giving you performance benefits for small arrays (not for large ones). In most cases, performance doesn’t matter and you can avoid the redundancy introduced by a preallocation.\n        If it fits the problem, an array literal initializing all elements at once is preferable.\n     : creates an array whose elements are  ,   etc. This variant of the constructor is never a good choice, because if you use it for a single element that is a number, the variant #2 is invoked. To avoid this bug, use the array literal   which does everything this constructor variant does.\n     \n(As an aside, because there are not many use cases for this: JavaScript therefore does not have a built-in function for reliably creating arrays from elements. ECMAScript 6 will have   which rectifies this situation.)\n\n Array indices , parsed as an unsigned 32 bit integer and converted to string is equal to  . , converted to integer, is smaller than 2 −1 (the maximum length). [1] length Tracking indices Decreasing the length Increasing the length Legal values for  Array instances define \n     Array indices: increase  , if necessary.\n     \n     : throw an error for illegal values, possibly remove elements if the new value is smaller than the previous one.\n     \n [[Put]] \nThe above means that it is impossible to create a subtype of   using standard ECMAScript 5. “ Subtyping JavaScript built-ins ” has details.\n\n Beyond the limits Recommendations \n     Pretend array indices are numbers. That’s what usually happens under the hood and the general direction in which ECMAScript is moving.\n     \n     Avoid the   constructor. \n     Use array literals whenever you can. \n     Don’t be clever with regard to arrays. If you follow standard patterns, engines usually figure out what you are trying to do and optimize accordingly. The article “ Performance Tips for JavaScript in V8 ” (by Chris Wilson) contains several interesting array-related suggestions.\n     \n Object properties in JavaScript Related blog posts Integers and shift operators in JavaScript JavaScript: sparse arrays vs. dense arrays comments powered by Disqus."},
{"url": "https://2ality.com/2012/11/coercing-objects.html", "title": "Coercing objects to primitives", "content": "Coercing objects to primitives dev javascript jslang Categorizing values in JavaScript following tweet Coercion \n     \n     \n \n     “Number”: you expect the value to be a number. \n     “String”: you expect the value to be a string. \n     “Default”: you don’t have any expectations for the value. \n \n\nLet’s try out coercion via the following object:\n Coercing to number Coercing to string Coercing to boolean \n     \n     \n     \n     ,  ,  \n     \n Understanding the initial result Recommendations \n     Stay away from instances of  ,   and  . You don’t normally need or encounter them in JavaScript.\n     \n     However, I do like using  ,   and   as functions, to coerce values. They are nicely descriptive when used in this manner.\n     \n     Obviously, all of the above ways of coercing to primitives work for any value, not just for objects:\n \n     \n     One does not often coerce objects to primitives. Doing so is, however, good for many WTFs  [1]  and hacks  [2] .\n     \n Further reading What is {} + {} in JavaScript?  [Describes the binary plus operator and the conversion to number and string in detail] Fake operator overloading in JavaScript  [a fun hack involving objects being coerced to numbers] JavaScript’s two zeros comments powered by Disqus."},
{"url": "https://2ality.com/2015/01/es6-maps-sets.html", "title": "ECMAScript 6: maps and sets", "content": "ECMAScript 6: maps and sets esnext dev javascript Exploring ES6  Updated version of this blog post: chapter “ Maps and Sets ”. Among others, the following four data structures are new in ECMAScript 6:  ,  ,   and  . This blog post explains how they work. Map   # JavaScript has always had a very spartan standard library. Sorely missing was a data structure for mapping values to values. The best you can get in ECMAScript 5 is a map from strings to arbitrary values, by abusing objects. Even then there are  several pitfalls  that can trip you up. The   data structure in ECMAScript 6 lets you use arbitrary values as keys and is highly welcome. Basic operations   # Working with single entries: Determining the size of a map and clearing it: Setting up a map   # You can set up a map via an iterable over key-value “pairs” (arrays with 2 elements). One possibility is to use an array (which is iterable): Alternatively, the   method is chainable: Keys   # Any value can be a key, even an object: # Most map operations need to check whether a value is equal to one of the keys. They do so via the internal operation  SameValueZero , which works like    [1] , but considers   to be equal to itself. Let’s first see how   handles  : Conversely, you can use   as a key in maps, just like any other value: Like  ,   and   are considered the same value (which is normally the best way to handle the two zeros  [2] ). Different objects are always considered different. That is something that can’t be configured (yet), as explained later, in the FAQ. Getting an unknown key produces  : Iterating   # Let’s set up a map to demonstrate how one can iterate over it. Maps record the order in which elements are inserted and honor that order when iterating over keys, values or entries. #  returns an iterable  [3]  over the keys in the map:  returns an iterable over the values in the map: #  returns the entries of the map as an iterable over [key,value] pairs (arrays). Destructuring enables you to access the keys and values directly: The default way of iterating over a map is  : Thus, you can make the previous code snippet even shorter: # The spread operator ( ) turns an iterable into the arguments of a function or parameter call. For example,   accepts a variable amount of parameters. With the spread operator, you can apply that method to iterables. Spread also turns an iterable into the elements of an array. That lets us convert the result of   (an iterable) into an array: Looping over entries   # The   method   has the following signature: The signature of the first parameter mirrors the signature of the callback of  , which is why the value comes first. Mapping and filtering   # You can   and   arrays, but there are no such operations for maps. The solution: Convert the map into an array of [key,value] pairs. Map or filter the array. Convert the result back to a map. That’s what happens in the following example: Step 1 is performed by the spread operator ( ) which I have explained previously. Map API   # \n \n \nReturns the   that   is mapped to in this map. If there is no key   in this map,   is returned. \n \n \n \nMaps the given key to the given value. If there is already an entry whose key is  , it is updated. Otherwise, a new entry is created. \n \n \n \nReturns whether the given key exists in this map. \n \n \n \nIf there is an entry whose key is  , it is removed and   is returned. Otherwise, nothing happens and   is returned. \n \n \n \n \nReturns how many entries there are in this map. \n \n \n \nRemoves all entries from this map. \n \n  happens in the order in which entries were added to a map. \n \n \nReturns an iterable with one [key,value] pair for each entry in this map. The pairs are arrays of length 2. \n \n \n \nThe first parameter is a callback that is invoked once for each entry in this map. If   is provided,   is set to it for each invocation. Otherwise,   is set to  . \n \n \n \nReturns an iterable over all keys in this map. \n \n \n \nReturns an iterable over all values in this map. \n \n \n \nThe default way of iterating over maps. Refers to  . \n \n WeakMap   # A   is a map that doesn’t prevent its keys from being garbage-collected. That means that you can associate data with objects without having to worry about memory leaks. A WeakMap is a data structure whose keys must be objects and whose values can be arbitrary values. It has the same API as  , with one significant difference: you can’t iterate over the contents – neither the keys, nor the values, nor the entries. You can’t clear a WeakMap, either. The rationales for these restrictions are: \n \n The volatility of WeakMaps makes iteration difficult. \n \n \n Not having   provides a security property. Quoting  Mark Miller : “The mapping from weakmap/key pair value can only be observed or affected by someone who has both the weakmap and the key. With  , someone with only the WeakMap would’ve been able to affect the WeakMap-and-key-to-value mapping.” \n \n Using WeakMaps for private data   # The following code uses the WeakMaps   and   to store private data. Let’s use  : Because   keeps instance-specific data elsewhere, its instance   has no own property keys: WeakMap API   # WeakMaps have only four methods, all of them work the same as the   methods. \n \n \n \n \n Set   # ECMAScript 5 doesn’t have a set data structure, either. There are two possible work-arounds: \n Use the keys of an object to store the elements of a set of strings. \n Store (arbitrary) set elements in an array: Check whether it contains an element via  , remove elements via  , etc. This is not a very fast solution, but it’s easy to implement. One issue to be aware of is that   can’t find the value  . \n ECMAScript 6 has the data structure   which works for arbitrary values, is fast and handles   correctly. Basic operations   # Managing single elements: Determining the size of a set and clearing it: Setting up a set   # You can set up a set via an iterable over the elements that make up the set. For example, via an array: Alternatively, the   method is chainable: Values   # Like maps, elements are compared similarly to  , with the exception of   being like any other value. Adding an element a second time has no effect: Similarly to  , two different objects are never considered equal (which can’t currently be customized, as explained in the FAQ, later): Iterating   # Sets are iterable and the   loop works as you’d expect: As you can see, sets preserve iteration order. That is, elements are always iterated over in the order in which they were inserted. The previously explained spread operator ( ) works with iterables and thus lets you convert a set to an array: We now have a concise way to convert an array to a set and back, which has the effect of eliminating duplicates from the array: Mapping and filtering   # In contrast to arrays, sets don’t have the methods   and  . A work-around is to convert them to arrays and back. Mapping: Filtering: API   # Single set elements: \n \n \nAdds   to this set. \n \n \n \nChecks whether   is in this set. \n \n \n \nRemoves   from this set. \n \n All set elements: \n \n \nReturns how many elements there are in this set. \n \n \n \nRemoves all elements from this set. \n \n \n \n \nReturns an iterable over all elements of this set. \n \n \n \nThe default way of iterating over sets. Points to  . \n \n \n \nLoops over the elements of this set and invokes the callback (first parameter) for each one.   and   are both set to the element, so that this method works similarly to  . If   is provided,   is set to it for each call. Otherwise,   is set to  . \n \n  The following two methods only exist so that the interface of sets is similar to the interface of maps. Each set element is handled as if it were a map entry whose key and value are the element. \n \n \n WeakSet   # A   is a set that doesn’t prevent its elements from being garbage-collected. Consult the section on   for an explanation of why WeakSets don’t allow iteration, looping and clearing. Given that you can’t iterate over their elements, there are not that many use cases for WeakSets. They enable you to mark objects, to associate them with boolean values. API   # WeakSets have only three methods, all of them work the same as the   methods. \n \n \n \n FAQ   # Why   and not  ?   #  Arrays have the property   to count the number of entries. Why do maps and set have a different property,  , for this purpose?    is for sequences, data structures that are indexable – like arrays.   is for collections that are primarily unordered – like maps and sets. Why can’t I configure how maps and sets compare keys and values?   #  It would be nice if there were a way to configure what map keys and what set elements are considered equal. Why isn’t there?  That feature has been postponed, as it is difficult to implement properly and efficiently. One option is to hand callbacks to collections that specify equality. Another option, available in Java, is to specify equality via a method that object implement (  in Java). However, this approach is problematic for mutable objects: In general, if an object changes, its “location” inside a collection has to change, as well. But that’s not what happens in Java. JavaScript will probably go the safer route of only enabling   for special immutable objects (so-called  ). Comparison by value means that two values are considered equal if their contents are equal. Primitive values are compared by value in JavaScript. References   # “ Equality Operators: === Versus == ” in “Speaking JavaScript”  ↩︎ \n “ Two Zeros ” in “Speaking JavaScript”  ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/12/es6-proxies.html", "title": "Meta programming with ECMAScript 6 proxies", "content": "Meta programming with ECMAScript 6 proxies esnext dev javascript js proxies  Please read chapter “ Metaprogramming with proxies ” in “Exploring ES6”. This blog post explains the ECMAScript 6 (ES6) feature  . Proxies enable you to intercept and customize operations performed on objects (such as getting properties). They are a meta programming feature. The code in this post occasionally uses other ES6 features. Consult “ Using ECMAScript 6 today ” for an overview of all of ES6. Before we can get into what proxies are and why they are useful, we first need to understand what   is. Programming versus meta programming   # In programming, there are levels: \n At the   (also called:  ), code processes user input. \n At the  , code processes base level code. \n Base and meta level can be diffent languages. In the following meta program, the meta programming language is JavaScript and the base programming language is Java. Meta programming can take different forms. In the previous example, we have printed Java code to the console. Let’s use JavaScript as both meta programming language and base programming language. The classic example for this is the   function , which lets you evaluate/compile JavaScript code on the fly. There are  very few actual use cases  for  . In the interaction below, we use it to evaluate the expression  . Other JavaScript operations may not look like meta programming, but actually are, if you look closer: The program is examining its own structure while running. This doesn’t look like meta programming, because the separation between programming constructs and data structures is fuzzy in JavaScript. All of the   methods  can be considered meta programming functionality. Kinds of meta programming   # Reflective meta programming means that a program processes itself.\nKiczales et al.  [1]  distinguish three kinds of reflective meta programming: \n  you have read-only access to the structure of a program. \n  you can change that structure. \n  you can redefine the semantics of some language operations. \n Let’s look at examples.    performs introspection (see previous example).  The following function   moves a property from a source to a target. It performs self-modification via the bracket operator for property access, the assignment operator and the   operator. (In production code, you’d probably use  property descriptors  for this task.) Using  : JavaScript doesn’t currently support intercession, proxies were created to fill that gap. An overview of proxies   # ECMAScript 6 proxies bring intercession to JavaScript. They work as follows. There are many operations that you can perform on an object  . For example: \n Getting a property   (via  ) \n Listing enumerable own properties (via  ) \n Proxies are special objects that allow you to provide custom implementations for some of these operations. A proxy is created with two parameters: \n : For each operation, there is a corresponding handler method that – if present – performs that operation. Such a method   the operation (on its way to the target) and is called a   (a term borrowed from the domain of operating systems). \n : If the handler doesn’t intercept an operation then it is performed on the target. That is, it acts as a fallback for the handler. In a way, the proxy wraps the target. \n In the following example, the handler intercepts the operation   (getting properties). When we get property  , the handler intercepts that operation: The handler doesn’t implement the trap   (setting properties). Therefore, setting   is forwarded to   and leads to   being set. Function-specific traps   # If the target is a function, two additional operations can be intercepted: \n : Making a function call, triggered via  ,  ,  . \n : Making a constructor call, triggered via  . \n The reason for only enabling these traps for function targets is simple: You wouldn’t be able to forward the operations   and  , otherwise. Revocable proxies   # ECMAScript 6 lets you create proxies that can be   (switched off): On the left hand side of the assignment operator ( ), we are using  destructuring  to access the properties   and   of the object returned by  . After you call the function   for the first time, any operation you apply to   causes a  . Subsequent calls of   have no further effect. Proxies as prototypes   # A proxy   can become the prototype of an object  . Some operations that begin in   may continue in  . One such operation is  . The property   can’t be found in  , which is why the search continues in   and the trap   is triggered there. There are more operations that affect prototypes, they are listed at the end of this post. Forwarding operations   # Operations whose traps the handler doesn’t implement are automatically forwarded to the target. Sometimes there is some task you want to perform in addition to forwarding the operation. For example, a handler that intercepts all operations and logs them, but doesn’t prevent them from reaching the target: For each trap, we first log the name of the operation and then forward it by performing it manually. ECMAScript 6 has the module-like object   that helps with forwarding: for each trap  has a method If we use  , the previous example looks as follows. Now what each of the traps does is so similar that we can implement the handler via a proxy: For each trap, the proxy asks for a handler method via the   operation and we give it one. That is, all of the handler methods can be implemented via the single meta method  . It was one of the goals for the proxy API to make this kind of virtualization simple. Let’s use this proxy-based handler: The following interaction confirms that the   operation was correctly forwarded to the target: Use cases for proxies   # This section demonstrates what proxies can be used for. That will also give you the opportunity to see the API in action. Implementing the DOM in JavaScript   # The browser Document Object Model (DOM) is usually implemented as a mix of JavaScript and C++. Implementing it in pure JavaScript is useful for: \n Emulating a browser environment, e.g. to manipulate HTML in Node.js.  jsdom  is one library that does that. \n Speeding the DOM up (switching between JavaScript and C++ costs time). \n Alas, the standard DOM can do things that are not easy to replicate in JavaScript. For example, most DOM collections are live views on the current state of the DOM that change dynamically whenever the DOM changes. As a result, pure JavaScript implementations of the DOM are not very efficient. One of the reasons for adding proxies to JavaScript was to help write more efficient DOM implementations. Accessing a restful web service   # A proxy can be used to create an object on which arbitrary methods can be invoked. In the following example, the function   creates one such object,  . Invoking a method on   retrieves the contents of the web service resource with the same name. Retrieval is handled via an  ECMAScript 6 promise . The following code is a quick and dirty implementation of   in ECMAScript 5. Because we don’t have proxies, we need to know beforehand what methods will be invoked on  . The parameter   provides us with that information, it holds an array with method names. The ECMAScript 6 implementation of   can use proxies and is simpler: Both implementations use the following function to make HTTP GET requests (how it works is explained in the  2ality blog post on promises ). Tracing property accesses   # The example in this section is inspired by Brendan Eich’s talk “ Proxies are Awesome ”: We want to trace when a given set of properties is read or changed. To demonstrate how that works, let’s create a class for points and trace accesses to the properties of an instance. Getting and setting properties of   now has the following effects: Intriguingly, tracing also works whenever   accesses the properties, because   now refers to the proxy, not to an instance of  . In ECMAScript 5, you’d implement   as follows. We replace each property with a getter and a setter that traces accesses. The setters and getters use an extra object,  , to store the data of the properties. Note that we are destructively changing the original implementation, which means that we are meta programming. In ECMAScript 6, we can use a simpler, proxy-based solution. We intercept property getting and setting and don’t have to change the implementation. Warning about unknown properties   # When it comes to accessing properties, JavaScript is very forgiving. For example, if you try to read a property and misspell its name, you don’t get an exception, you get the result  . You can use proxies to get an exception in such a case. This works as follows. We make the proxy a prototype of an object. If a property isn’t found in the object, the   trap of the proxy is triggered. If the property doesn’t even exist in the prototype chain after the proxy, it really is missing and we throw an exception. Otherwise, we return the value of the inherited property. We do so by forwarding the   operation to the target, whose prototype is the prototype of the proxy. Let’s use   for an object that we create: If we turn   into a constructor, we can use it for ECMAScript 6 classes via  : If you are worried about accidentally   properties, you have two options: You can either create a proxy that traps  . Or you can make an object   non-extensible via  , which means that JavaScript doesn’t let you add new (own) properties to  . Negative array indices   # Some array methods let you refer to the last element via  , to the second-to-last element via  , etc. For example: Alas, that doesn’t work when accessing elements via the bracket operator ( ). We can, however, use proxies to add that capability. The following function   creates arrays that support negative indices. It does so by wrapping proxies around array instances. The proxies intercept the   operation that is triggered by the bracket operator. Acknowledgement: The idea for this example comes from a  blog post  by hemanth.hm. Data binding   # Data binding is about syncing data between objects. One popular use case are widgets based on the MVC (Model View Controler) pattern: With data binding, the   (the widget) stays up-to-date if you change the   (the data visualized by the widget). To implement data binding, you have to observe and react to changes made to an object. In the following code snippet, I sketch how that could work for an array. Output: Data binding is a complex topic. Given its popularity and concerns over proxies not being performant enough, a dedicated mechanism has been created for data binding:  . It will probably be part of ECMAScript 7 and is already  supported  by Chrome. Consult Addy Osmani’s article “ Data-binding Revolutions with Object.observe() ” for more information on  . Revocable references   #  work as follows: A client is not allowed to access an important resource (an object) directly, only via a reference (an intermediate object, a wrapper around the resource). Normally, every operation applied to the reference is forwarded to the resource. After the client is done, the resource is protected by   the reference, by switching it off. Henceforth, applying operations to the reference throws exceptions and nothing is forwarded, anymore. In the following example, we create a revocable reference for a resource. We then read one of the resource’s properties via the reference. That works, because the reference grants us access. Next, we revoke the reference. Now the reference doesn’t let us read the property, anymore. Proxies are ideally suited for implementing revocable references, because they can intercept and forward operations. This is a simple proxy-based implementation of  : The code can be simplified via the proxy-as-handler technique from the previous section. This time, the handler basically is the   object. Thus, the   trap normally returns the appropriate   method. If the reference has been revoked, a   is thrown, instead. However, you don’t have to implement revocable references yourself, because ECMAScript 6 lets you create proxies that can be revoked. This time, the revoking happens in the proxy, not in the handler. All the handler has to do is forward every operation to the target. As we have seen that happens automatically if the handler doesn’t implement any traps. #  build on the idea of revocable references: Environments that are designed to run untrusted code wrap a membrane around that code to isolate it and keep the rest of the system safe. Objects pass the membrane in two directions: \n The code may receive objects from the outside. \n Or it may hand objects to the outside. \n In both cases, revocable references are wrapped around the objects. Objects returned by wrapped functions or methods are also wrapped. Once the untrusted code is done, all of those references are revoked. As a result, none of its code on the outside can be executed anymore and outside objects that it has cease to work, as well. The  Caja Compiler  is “a tool for making third party HTML, CSS and JavaScript safe to embed in your website”. It uses membranes to achieve this task. Other use cases   # There are more use cases for proxies. For example: \n Local placeholders that forward method invocations to remote objects. Similar: web service example. \n Data access objects for databases: reading and writing to the object reads and writes to the database. Similar: web service example. \n Profiling: Intercept method invocations to track how much time is spent in each method. Similar: tracing example. \n Type checking: Nicholas Zakas has used proxies to  type-check objects . \n The design of the proxy API   # In this section, we go deeper into how proxies work and why they work that way. Stratification: keeping base level and meta level separate   # Firefox has allowed you to do some interceptive meta programming for a while: If you define a method whose name is  , it is notified whenever a method is called that doesn’t exist. The following is an example of using  . Thus,   works similarly to a proxy trap. In contrast to proxies, the trap is an own or inherited method of the object whose operations we want to intercept. The problem with that approach is that base level and meta level are mixed. Base-level code may accidentally invoke or see a meta level method and there is the possibility of accidentally defining a meta level method. Even in standard ECMAScript 5, base level and meta level are sometimes mixed. For example, the following meta programming mechanisms can fail, because they exist at the base level: \n : This call can fail if a property in the prototype chain overrides the built-in implementation. For example, it fails if   is  . Safe ways to call this method are   and its abbreviated version  . \n ,  : For these two methods, problem and solution are the same as with  . \n : In most JavaScript engines,   is a special property that lets you get and set the prototype of  . Hence, when you use objects as dictionaries, you must be careful to  avoid   as a property key . \n By now, it should be obvious that making (base level) property keys special is problematic. Therefore, proxies are   – base level (the proxy object) and meta level (the handler object) are separate. Virtual objects versus wrappers   # Proxies are used in two roles: \n \n As  , they   their targets, they control access to them. Examples of wrappers are: revocable resources and tracing proxies. \n \n \n As  , they are simply objects with special behavior and their targets don’t matter. An example is a proxy that forwards method calls to a remote object. \n \n An earlier design of the proxy API conceived proxies as purely virtual objects. However, it turned out that even in that role, a target was useful, to enforce invariants (which is explained later) and as a fallback for traps that the handler doesn’t implement. Transparent virtualization and handler encapsulation   # Proxies are shielded in two ways: \n It is impossible to determine whether an object is a proxy or not ( ). \n You can’t access a handler via its proxy ( ). \n Both principles give proxies considerable power for impersonating other objects. One reason for enforcing   (as explained later) is to keep that power in check. If you do need a way to tell proxies apart from non-proxies, you have to implement it yourself. The following code is a module   that exports two functions: one of them creates proxies, the other one determines whether an object is one of those proxies. This module uses the ECMAScript 6 data structure   for keeping track of proxies.   is ideally suited for this purpose, because it doesn’t prevent its elements from being garbage-collected. The next example shows how   can be used. The meta object protocol and proxy traps   # This section examines how JavaScript is structured internally and how the set of proxy traps was chosen. The term   is highly overloaded in computer science. One definition is: A prototcol is about achieving tasks via an object, it comprises a set of methods plus a set of rules for using them. Note that this definition is different from viewing protocols as interfaces (as, for example, Objective C does), because it includes rules. The ECMAScript specification describes how to execute JavaScript code. It includes a  protocol for handling objects . This protocol operates at a meta level and is sometimes called the meta object protocol (MOP). The JavaScript MOP consists of own internal methods that all objects have. “Internal” means that they exist only in the specification (JavaScript engines may or may not have them) and are not accessible from JavaScript. The names of internal methods are written in double square brackets. The internal method for getting properties is called  . If we pretend that property names with square brackets are legal, this method would roughly be implemented as follows in JavaScript. The MOP methods called in this code are: \n  (trap  ) \n  (trap  ) \n  (trap  ) \n  (trap  ) \n In line (*) you can see why proxies in a prototype chain find out about   if a property isn’t found in an “earlier” object: If there is no own property whose key is  , the search continues in the prototype   of  .  You can see that   calls other MOP operations. Operations that do that are called  . Operations that don’t depend on other operations are called  . # The  meta object protocol of proxies  is different from that of normal objects. For normal objects, derived operations call other operations. For proxies, each operation is either intercepted by a handler method or forwarded to the target. What operations should be interceptable via proxies? One possibility is to only provide traps for fundamental operations. The alternative is to include some derived operations. The advantage of derived traps is that they increase performance and are more convenient: If there wasn’t a trap for  , you’d have to implement its functionality via  . One problem with derived traps is that they can lead to proxies behaving inconsistently. For example,   may return a value that is different from the value stored in the descriptor returned by  . # Intercession by proxies is  : you can’t intercept every language operation. Why were some operations excluded? Let’s look at two reasons. First, stable operations are not well suited for intercession. An operation is   if it always produces the same results for the same arguments. If a proxy can trap a stable operation, it can become unstable and thus unreliable.  Strict equality  ( ) is one such stable operation. It can’t be trapped and its result is computed by treating the proxy itself as just another object. Another way of maintaining stability is by applying an operation to the target instead of the proxy. As explained later, when we look at how invariants are enfored for proxies, this happens when   is applied to a proxy whose target is non-extensible. A second reason for not making more operations interceptable is that intercession means executing custom code in situations where that normally isn’t possible. The more this interleaving of code happens, the harder it is to understand and debug a program. # If you want to create virtual methods via ECMAScript 6 proxies, you have to return functions from a   trap. That raises the question: why not introduce an extra trap for method invocations (e.g.  )? That would enable us to distinguish between: \n Getting properties via   (trap  ) \n Invoking methods via   (trap  ) \n There are two reasons for not doing so. First, not all implementations distinguish between   and  . For example,  Apple’s JavaScriptCore doesn’t . Second, extracting a method and invoking it later via   or   should have the same effect as invoking the method via dispatch. In other words, the following two variants should work equivalently. If there was an extra trap   then that equivalence would be harder to maintain.  Some things can only be done if you are able to distinguish between   and  . Those things are therefore impossible with the current proxy API. Two examples are: auto-binding and intercepting missing methods. First, by making a proxy the prototype of an object  , you can automatically bind methods: \n Retrieving the value of a method   via   returns a function whose   is bound to  . \n  performs a method call. \n Auto-binding helps with using methods as callbacks. For example, variant 2 from the previous example becomes simpler: Second,   lets a proxy emulate the previously mentioned   mechanism that Firefox supports. The proxy would again become the prototype of an object  . It would react differently depending on how an unknown property   is accessed: \n If you read that property via  , no intercession happens and   is returned. \n If you make the method call   then the proxy intercepts and, e.g., notifies a callback. \n Enforcing invariants for proxies   # Before we look at what invariants are and how they are enforced for proxies, let’s review how objects can be protected via non-extensibility and non-configurability. # There are two ways of protecting objects: \n non-extensibility protects objects \n non-configurability protects properties (or rather, their attributes) \n  If an object is non-extensible, you can’t add properties and you can’t change its prototype:  All the data of a property is stored in  . A property is like a record and attributes are like the fields of that record. Examples of attributes: \n The attribute   holds the value of a property. \n The boolean attribute   controls whether a property’s value can be changed. \n The boolean attribute   controls whether a property’s attributes can be changed. \n Thus, if a property is both non-writable and non-configurable, it is read-only and remains that way: For more details on these topics (including how   works) consult the following sections in “Speaking JavaScript”: \n Property Attributes and Property Descriptors \n Protecting Objects \n # Traditionally, non-extensibility and non-configurability are: \n Universal: they work for all objects. \n Monotonic: once switched on, they can’t be switched off again. \n These and other characteristics that remain unchanged in the face of language operations are called  . With proxies, it is easy to violate invariants, as they are not intrinsically bound by non-extensibility etc. The proxy API prevents proxies from violating invariants by checking the parameters and results of handler methods. Non-extensibility and non-configurability are enforced by using the target object for bookkeeping. The following are a few examples of invariants (for an arbitrary object  ) and how they are enforced for proxies (an exhaustive list is given at the end of this post): \n Invariant:   must return a boolean.\n \n Enforced by coercing the value returned by the handler to a boolean. \n \n \n Invariant:   must return an object or  .\n \n Enforced by throwing a   if the handler doesn’t return an appropriate value. \n \n \n Invariant: If   returns   then all future calls must return   and   must now be non-extensible.\n \n Enforced by throwing a   if the handler returns  , but the target object is not extensible. \n \n \n Invariant: Once an object has been made non-extensible,   must always return  .\n \n Enforced by throwing a   if the result returned by the handler is not the same (after coercion) as  . \n \n \n Enforcing invariants has the following benefits: \n Proxies work like all other objects with regard to extensibility and configurability. Therefore, universality is maintained. This is achieved without preventing proxies from virtualizing (impersonating) protected objects. \n A protected object can’t be misrepresented by wrapping a proxy around it. Misrepresentation can be caused by bugs or by malicious code. \n The following sections give examples of invariants being enforced. # In response to the   trap, the proxy must return the target’s prototype if the target is non-extensible. To demonstrate this invariant, let’s create a handler that returns a prototype that is different from the target’s prototype: Faking the prototype works if the target is extensible: We do, however, get an error if we fake the prototype for a non-extensible object. # If the target has a non-writable non-configurable property then the handler must return that property’s value in response to a   trap. To demonstrate this invariant, let’s create a handler that always returns the same value for properties. Property   is not both non-writable and non-configurable, which means that the handler is allowed to pretend that it has a different value: However, property   is both non-writable and non-configurable. Therefore, we can’t fake its value: Reference: the proxy API   # This section serves as a quick reference for the proxy API: the global objects   and  . Creating proxies   # There are two ways to create proxies: \n \n \nCreates a new proxy object with the given target and the given handler. \n \n \n \nCreates a proxy that can be revoked via the function  .   can be called multiple times, but only the first call has an effect and switches   off. Afterwards, any operation performed on   leads to a   being thrown. \n \n Handler methods   # This subsection explains what traps can be implemented by handlers and what operations trigger them. Several traps return boolean values. For the traps   and  , the boolean is the result of the operation. For all other traps, the boolean indicates whether the operation succeeded or not. Traps for all objects: \n  →  \n \n \n \n \n  →  \n \n \n \n \n \n  →  \n \n \n \n \n  →  \n \n \n \n \n \n  →  \n \n \n \n \n  →  \n \n \n \n \n  →  \n \n \n \n \n  →  \n \n \n \n \n  →  \n \n  (only uses string-valued keys) \n  (only uses symbol-valued keys) \n  (only uses enumerable string-valued keys; enumerability is checked via  ) \n \n \n  →  \n \n \n \n \n  →  \n \n \n \n \n \n  →  \n \n \n \n \n Traps for functions (available if target is a function): \n  →  \n \n \n \n \n \n \n  →  \n \n \n \n \n # The following operations are  , they don’t use other operations to do their work:  ,  ,  ,  ,  ,  ,  ,  ,  All other operations are  , they can be implemented via fundamental operations. For example, for data properties,   can be implemented by iterating over the prototype chain via   and calling   for each chain member until either an own property is found or the chain ends. Invariants   # Invariants are safety constraints for handlers. This subsection documents what invariants are enforced by the proxy API and how. Whenever you read “the handler must do X” below, it means that a   is thrown if it doesn’t. Some invariants restrict return values, others restrict parameters. Ensuring the correct return value of a trap is ensured in two ways: Normally, an illegal value means that a   is thrown. But whenever a boolean is expected, coercion is used to convert non-booleans to legal values. This is the complete list of invariants that are enforced (source:  ECMAScript 6 specification ): \n \n \n No invariants are enforced. \n \n \n \n \n The result returned by the handler must be an object (not   or a primitive value). \n \n \n \n \n If the target is not extensible then   can’t create a property that the target doesn’t already have. \n If   sets the attribute   to   then the target must have a non-configurable own property whose key is  . \n If   was used to (re)define an own property for the target then that must not cause an exception. An exception is thrown if a change is forbidden by the attributes   and  . \n \n \n \n \n Non-configurable own properties of the target can’t be deleted. \n \n \n \n \n The handler must return an object. \n \n \n \n \n If the target has an own, non-writable, non-configurable data property whose key is   then the handler must return that property’s value. \n If the target has an own, non-configurable, getter-less accessor property then the handler must return  . \n \n \n \n \n The handler must return either an object or  . \n Non-configurable own properties of the target can’t be reported as non-existent by the handler. \n If the target is non-extensible then exactly the target’s own properties must be reported by the handler as existing (and none of them as missing). \n If the handler reports a property as non-configurable then that property must be a non-configurable own property of the target. \n If the result returned by the handler were used to (re)define an own property for the target then that must not cause an exception. An exception is thrown if the change is not allowed by the attributes   and  . Therefore, the handler can’t report a non-configurable property as configurable and it can’t report a different value for a non-configurable non-writable property. \n \n \n \n \n The result must be either an object or  . \n If the target object is not extensible then the handler must return the prototype of the target object. \n \n \n \n \n A handler must not hide (report as non-existent) a non-configurable own property of the target. \n If the target is non-extensible then no own property of the target may be hidden. \n \n \n \n \n The result returned by the handler is coerced to boolean. \n After coercion to boolean, the value returned by the handler must be the same as  . \n \n \n \n \n The handler must return an object, which treated as array-like and converted into an array. \n Each element of the result must be either a string or a symbol. \n The result must contain the keys of all non-configurable own properties of the target. \n If the target is not extensible then the result must contain exactly the keys of the own properties of the target (and no other values). \n \n \n \n \n The result returned by the handler is coerced to boolean. \n If the handler returns a truthy value (indicating a successful change) then   must be   afterwards. \n \n \n \n \n If the target has an own, non-writable, non-configurable data property whose key is   then   must be the same as the value of that property (i.e., the property can’t be changed). \n If the target has an own, non-configurable, setter-less accessor property then a   is thrown (i.e., such a property can’t be set). \n \n \n \n \n The result returned by the handler is coerced to boolean. \n If the target is not extensible, the prototype can’t be changed. This is enforced as follows: If the target is not extensible and the handler returns a truthy value (indicating a successful change) then   must be the same as the prototype of the target. Otherwise, a   is thrown. \n \n \n The prototype chain   # The following operations of normal objects perform operations on objects in the prototype chain (source:  ECMAScript 6 specification ). Therefore, if one of the objects in that chain is a proxy, its traps are triggered. The specification implements the operations as internal own methods (that are not visible to JavaScript code). But in this section, we pretend that they are normal methods that have the same names as the traps. The parameter   becomes the receiver of the method call. \n \nTraverses the prototype chain of   via  . Per object, it retrieves the keys via   and examines whether a property is enumerable via  . \n \nIf   has no own property with the given key,   is invoked on the prototype of  . \n \nSimilarly to  ,   is invoked on the prototype of   if   has no own property with the given key. \n \nSimilarly to  ,   is invoked on the prototype of   if   has no own property with the given key. \n All other operations only affect own properties, they have no effect on the prototype chain. Reflect   # The global object   implements all interceptable operations of the JavaScript meta object protocol as methods. The names of those methods are the same as those of the handler methods, which, as we have seen, helps with forwarding operations from the handler to the target. \n  →  \nBetter version of  . \n  →  \nThe   operator as a function. \n  →  \nSimilar to  . \n  →  \nThe   operator as a function. \n  →  \nReturns an iterater over all enumerable string property keys of  . In other words, the iterator returns all values that the   loop would iterate over. \n  →  \nA function that gets properties. \n  →  \nSame as  . \n  →  \nSame as  . \n  →  \nThe   operator as a function. \n  →  \nSame as  . \n  →  \nReturns all own property keys (strings and symbols!) in an array. \n  →  \nSimilar to  . \n  →  \nA function that sets properties. \n  →  \nThe new standard way of setting the prototype of an object. The current non-standard way that works in most engines is to set the special property  . \n Several methods have boolean results. For   and  , they are the results of the operation. For the remaining methods, they indicate whether the operation succeeded. Apart from forwarding operations, why is   useful  [2] ? \n Different return values:   duplicates the following methods of  , but its methods return booleans indicating whether the operation succeeded (where the   methods return the object that was modified).\n \n  →  \n  →  \n  →  \n \n \n Operators as functions: The following   methods implement functionality that is otherwise only available via operators:\n \n  →  \n  →  \n  →  \n  →  \n  →  \n \n \n The   loop as an iterator: This is rarely useful, but if you need it, you can get an iterator over all enumerable (own and inherited) string property keys of an object.\n \n  →  \n \n \n Shorter version of  : The only safe way to invoke the built-in function method   is via   (or similar).   is cleaner and shorter. \n State of implementations   # As usual,  Kangax’ ES6 compatibility table  is the best way of finding out how well engines support proxies. As of December 2014, Internet Explorer has the most complete support and Firefox supports some of the API (caveats:   doesn’t work properly,   is not supported yet and   is empty). No other browser or engine currently supports proxies. Conclusion   # This concludes our in-depth look at the proxy API. For each application, you have to take performance into consideration and – if necessary – measure. Proxies may not always be fast enough. On the other hand, performance is often not crucial and it is nice to have the meta programming power that proxies give us. As we have seen, there are numerous use cases they can help with. Acknowledgements   # Thanks go to Tom Van Cutsem: his paper  [3]  is the most important source of this blog post and he kindly answered questions about the proxy API that I had. \n Jaydson Gomes \n Raymond Camden \n Further reading   # “ The Art of the Metaobject Protocol ” by Gregor Kiczales, Jim des Rivieres and Daniel G. Bobrow. Book, 1991.  ↩︎ \n “ Harmony-reflect: Why should I use this library? ” by Tom Van Cutsem.  ↩︎ \n “ On the design of the ECMAScript Reflection API ” by Tom Van Cutsem and Mark Miller. Technical report, 2012.  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/12/es6-symbols.html", "title": "Symbols in ECMAScript 6", "content": "Symbols in ECMAScript 6 esnext dev javascript \n TODO: Mention early what their main purpose is, what they are good for. \n Symbols are a new primitive type in ECMAScript 6  [1] . This blog post explains how they work. A new primitive type   # ECMAScript 6 introduces a new primitive type: symbols. They are tokens that serve as unique IDs. You create symbols via the factory function   (which is loosely similar to   returning strings if called as a function):  has an optional string-valued parameter that lets you give the newly created symbol a description: Every symbol returned by   is unique, every symbol has its own identity: You can see that symbols are primitive if you apply the   operator to one of them – it will return a new symbol-specific result:  Two quick ideas of mine. If a symbol has no description, JavaScript engines could use the name of the variable (or property) that a symbol is assigned to. Minifiers could also help, by turning the original name of a variable into a parameter for  . Symbols as property keys   # Symbols can be used as property keys: Classes and object literals have a feature called    [2] : You can specify the key of a property via an expression, by putting it in square brackets. In the following object literal, we use a computed property key to make the value of   the key of a property. A method definition can also have a computed key: Enumerating own property keys   # Given that there is now a new kind of value that can become the key of a property, the following terminology is used for ECMAScript 6: \n  are either strings or symbols. \n  are strings. \n Let’s examine the API for enumerating own property keys by first creating an object.  ignores symbol-valued property keys:  ignores string-valued property keys:  considers all kinds of keys: The name of   doesn’t really work, anymore: it only considers enumerable property keys that are strings. Using symbols to represent concepts   # In ECMAScript 5, one often represents concepts (think enum constants) via strings. For example: However, strings are not as unique as we’d like them to be. To see why, let’s look at the following function. It is noteworthy that you can use arbitrary expressions as   cases, you are not limited in any way. For example: We use the flexibility that   offers us and refer to the colors via our constants (  etc.) instead of hard-coding them (  etc.). Interestingly, even though we do so, there can still be mix-ups. For example, someone may define a constant for a mood: Now the value of   is not unique anymore and   can be mistaken for it. If you use it as a parameter for  , it returns   where it should throw an exception. Let’s use symbols to fix this example. Now we can also use the ECMAScript 6 feature  , which lets us declare actual constants (you can’t change what value is bound to a constant, but the value itself may be mutable). Each value returned by   is unique, which is why no other value can be mistaken for  now. Intriguingly, the code of   doesn’t change at all if we use symbols instead of strings, which shows how similar they are. Symbols as keys of properties   # Being able to create properties whose keys never clash with other keys is useful in two situations: \n If several parties contribute internal properties to the same object, via mixins. \n To keep meta-level properties from clashing with base-level properties. \n Symbols as keys of internal properties   # Mixins are object fragments (sets of methods) that you can compose to augment the functionality of an object or a prototype. If their methods have symbols as keys, they can’t clash with other methods (of other mixins or of the object that they are added to), anymore. Public methods are seen by clients of the object a mixin is added to. For usability’s sake, you probably want those methods to have string keys. Internal methods are only known to the mixin or only needed to communicate with it. They profit from having symbols as keys. Symbols do not offer real privacy, because it is easy to find out the symbol-valued property keys of an object. But the guarantee that a property key can’t ever clash with any other property key is often enough. If you truly want to prevent the outside from accessing private data, you need to use WeakMaps or closures. For example: The instances of   are keys in the WeakMap  . The WeakMap does not prevent the instances from being garbage-collected. Entries whose keys are objects that don’t exist anymore are removed from WeakMaps. The same code looks as follows if you use a symbol key for the internal property. Symbols as keys of meta-level properties   # Symbols having unique identities makes them ideal as keys of public properties that exist on a different level than “normal” property keys, because meta-level keys and normal keys must not clash. One example of meta-level properties are methods that objects can implement to customize how they are treated by a library. Using symbol keys protect the library from mistaking normal methods as customization methods.   [3]  in ECMAScript 6 is one such customization. An object is   if it has a method whose key is the symbol (stored in)  . In the following code,   is iterable. The iterability of   enables you to use the   loop and similar JavaScript features: Crossing realms with symbols   # A   (short: realm) is a context in which pieces of code exist. It includes global variables, loaded modules and more. Even though code exists “inside” exactly one realm, it may have access to code in other realms. For example, each frame in a browser has its own realm. And execution can jump from one frame to another, as the following HTML demonstrates. The problem is that each realm has its own local copy of   and, because objects have individual identities, those local copies are considered different, even though they are essentially the same object. Similarly, libraries and user code a loaded once per realm and each realm has a different version of the same object. In contrast, members of the primitive types boolean, number and string don’t have individual identities and multiple copies of the same value are not a problem: The copies are compared “by value” (by looking at the content, not at the identity) and are considered equal. Symbols have individual identities and thus don’t travel across realms as smoothly as other primitive values. That is a problem for symbols such as   that should work across realms: If an object is iterable in one realm, it should be iterable in others, too. If a cross-realm symbol is provided by the JavaScript engine, the engine can make sure that the same value is used in each realm. For libraries, however, we need extra support, which comes in the form of the  : This registry is global to all realms and maps strings to symbols. For each symbol, libraries need to come up with a string that is as unique as possible. To create the symbol, they don’t use  , they ask the registry for the symbol that the string is mapped to. If the registry already has an entry for the string, the associated symbol is returned. Otherwise, entry and symbol are created first. You ask the registry for a symbol via   and retrieve the string associated with a symbol (its  ) via  : As expected, cross-realm symbols, such as  , that are provided by the JavaScript engine are not in the registry: Safety checks   # JavaScript warns you about two mistakes by throwing exceptions: Invoking   as a constructor and coercing symbols to string. Invoking Symbol as a constructor   # While all other primitive values have literals, you need to create symbols by function-calling  . Thus, it is relatively easy to accidentally invoke   as a constructor. That produces instances of   and is not very useful. Therefore, an exception is thrown when you try to do that: There is still a way to create wrapper objects, instances of  :  , called as a function, converts all values to objects, including symbols. Coercing a symbol to string   # Given that both strings and symbols can be property keys, you want to protect people from accidentally converting a symbol to a string. For example, like this: ECMAScript 6 throws an exception if one uses   conversion to string (handled internally via the  ToString operation ): However, you can still explicitly convert symbols to strings: Frequently asked questions   # Are symbols primitives or objects?   # In some ways, symbols are like primitive values, in other ways, they are like objects: \n Symbols are like strings (primitive values) w.r.t. what they are used for: as representations of concepts and as property keys. \n Symbols are like objects in that each symbol has its own identity. \n The latter point can be illustrated by using objects as colors instead of symbols: Optionally, you can make objects-as-symbols more minimal by freezing   instead of  . Note that, in contrast to strings, objects can’t become property keys. What are symbols then – primitive values or objects? In the end, they were turned into primitives, for two reasons. First, symbols are more like strings than like objects: They are a fundamental value of the language, they are immutable and they can be used as property keys. Symbols having unique identities doesn’t necessarily contradict them being like strings: UUID algorithms produce strings that are quasi-unique. Second, symbols are most often used as property keys, so it makes sense to optimize the JavaScript specification and the implementations for that use case. Then many abilities of objects are unnecessary: \n Objects can become prototypes of other objects. \n Wrapping an object with a proxy doesn’t change what it can be used for. \n Objects can be introspected: via  ,  , etc. \n Them not having these abilities makes life easier for the specification and the implementations. There are also reports from the V8 team that when handling property keys, it is simpler to treat a primitive type differently than objects. Aren’t strings enough?   # In contrast to strings, symbols are unique and prevent name clashes. That is nice to have for tokens such as colors, but it is essential for supporting meta-level methods such as the one whose key is  . Python uses the special name   to avoid clashes. You can reserve double underscore names for programming language mechanisms, but what is a library to do? With symbols, we have an extensibility mechanism that works for everyone. As you can see later, in the section on public symbols, JavaScript itself already makes ample use of this mechanism. There is one hypothetical alternative to symbols when it comes to clash-free property keys: use a naming convention. For example, strings with URLs (e.g.  ). But that would introduce a second category of property keys (versus “normal” property names that are usually valid identifiers and don’t contain colons, slashes, dots, etc.), which is basically what symbols are, anyway. Thus it is more elegant to explicitly turn those keys into a different kind of value. TODO: JSON?   # Only string-valued keys... TODO: Ruby’s symbols, Clojures keywords?   # No, Ruby’s symbols are like string literals in JavaScript. The symbol API   # This section gives an overview of the ECMAScript 6 API for symbols. The function     # \n  →  \nCreates a new symbol. The optional parameter   allows you to give the symbol a description, which is useful for debugging. \n  is not intended to be used as a constructor – an exception is thrown if you invoke it via  . Public symbols   # Several public symbols  can be accessed via properties of  . They are all used as property keys and enable you to customize how JavaScript handles an object. Customizing basic language operations: \n \n  (method) \nLets an object   customize the behavior of  . \n \n \n  (method) \nLets an object customize how it is converted to a primitive value. This is the first step whenever something is coerced to a primitive type (via operators etc.). \n \n \n  (string) \nCalled by   to compute the default string description of an object  : '[object '+obj[Symbol.toStringTag]+']'. \n \n [3:1] \n  (method) \nMakes an object iterable. Returns an iterator. \n  Four string methods are simply forwarded to their regular expression parameters. The methods that they are forwarded to have the following keys. \n  is used by  . \n  is used by  . \n  is used by  . \n  is used by  . \n \n \n  (Object) \nLets an object hide some properties from the   statement. \n \n \n  (method) \nHelps with cloning typed arrays and instances of  ,   and  . \n \n \n  (boolean)\nIndicates whether   should concatenate the elements of an object or the object as an element. \n \n Global symbol registry   # If you want a symbol to be the same in all realms, you need to create it via the global symbol registry. The following method lets you do that: \n  →  \nReturns the symbol whose key is the string   in the registry. If   isn’t in the registry yet, a new symbol is created and filed in the registry under the key  . \n Another method lets you make the reverse look up and found out under which key a string is stored in the registry. This is may be useful for serializing symbols. \n  →  \nreturns the string that is associated with the symbol   in the registry. If   isn’t in the registry, this method returns  . \n Further reading   # Using ECMAScript 6 today   ↩︎ \n ECMAScript 6: new OOP features besides classes   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/12/es6-oop.html", "title": "ECMAScript 6: new OOP features besides classes", "content": "ECMAScript 6: new OOP features besides classes esnext dev javascript  Please read chapter “ New OOP features besides classes ” in “Exploring ES6”. Classes  [1]  are   major new OOP feature in ECMAScript 6  [2] . However, it also includes new features for object literals and new utility methods in  . This blog post describes them. New features of object literals   # Method definitions   # In ECMAScript 5, methods are properties whose values are functions: In ECMAScript 6, methods are still function-valued properties, but there is now a more compact way of defining them: Getters and setters continue to work as they did in ECMAScript 5 (note how syntactically similar they are to method definitions): Let’s use  : There is also a way to concisely define properties whose values are generator functions  [3] : This code is equivalent to: Property value shorthands   # Property value shorthands let you abbreviate the definition of a property in an object literal: If the name of the variable that specifies the property value is also the property key then you can omit the key. This looks as follows. The last line is equivalent to: Property value shorthands work well together with destructuring  [4] : One use case for property value shorthands are multiple return values  [4:1] . Computed property keys   # Remember that there are two ways of specifying a key when you set a property. Via a fixed name:  Via an expression:  In object literals, you only have option #1 in ECMAScript 5. ECMAScript 6 additionally provides option #2: This new syntax can also be combined with a method definition: The main use case for computed property keys are symbols: you can define a public symbol and use it as a special property key that is always unique. One prominent example is the symbol stored in  . If on object has a method with that key, it becomes iterable  [3:1] . The method must return an iterator, which is used by constructs such as the   loop to iterate over the object. The following code demonstrates how that works. Line A starts a generator method definition with a computed key (the symbol stored in  ). New methods of Object   # Object.assign(target, source_1, source_2, ···)   # This method merges the sources into the target: It modifies  , first copies all enumerable own properties of   into it, then all own properties of  , etc. At the end, it returns the target. Let’s look more close at how   works: \n \n Both kinds of property keys:   supports both strings and symbols as property keys. \n \n \n Only enumerable own properties:   ignores inherited properties and properties that are not enumerable. \n \n \n Copying via assignment: Properties in the target object are created via assignment (internal operation [[Put]]). That means that if   has (own or inherited) setters, those will be invoked during copying. An alternative would have been to   new properties, an operation which always creates new own properties and never invokes setters. There originally was a proposal for a variant of   that uses definition instead of assignment. That proposal has been rejected for ECMAScript 6, but may be reconsidered for later editions. \n \n # Let’s look at a few use cases. You can use   to add properties to   in a constructor:  is also useful for filling in defaults for missing properties. In the following example, we have an object   with default values for properties and an object   with data. In line A, we created a fresh object, copied the defaults into it and then copied   into it, overriding the defaults.   returns the result of these operations, which we assign to  . Another use case is adding methods to objects: You could also assign functions, but then you don’t have the nice method definition syntax and need to mention   each time: One last use case for   is a quick way of cloning objects: This way of cloning is also somewhat dirty, because it doesn’t preserve the property attributes of  . If that is what you need, you have to use  property descriptors . If you want the clone to have the same prototype as the original, you can use   and  : Object.getOwnPropertySymbols(obj)   # In ECMAScript 6, the key of a property can be either a string or a symbol. There are now five tool methods that retrieve the property keys of an object  : \n \n  →  \nretrieves all string-valued keys of all enumerable own properties. \n \n \n  →  \nretrieves all string-valued keys of all own properties. \n \n \n  →  \nretrieves all symbol-valued keys of all own properties. \n \n \n  →  \nretrieves all keys of all own properties. \n \n \n  →  \nretrieves all string-values keys of all enumerable properties. \n \n Object.is(value1, value2)   # The strict equals operator ( ) treats two values differently than one might expect. First,   is not equal to itself. That is unfortunate, because it often prevents us from detecting  : Second, JavaScript has  two zeros , but strict equals treats them as if they were the same value: Doing this is normally a good thing.  provides a way of comparing values that is a bit more precise than  . It works as follows: Everything else is compared as with  . If we combine   with the new ECMAScript 6 array method    [5] , we can find   in arrays: Object.setPrototypeOf(obj, proto)   # This method sets the prototype of   to  . The non-standard way of doing so in ECMAScript 5, that is supported by many engines, is via assinging to the special property  . The recommended way of setting the prototype remains the same as in ECMAScript 5: during the creation of an object, via  . That will always be faster than first creating an object and then setting its prototype. Obviously, it doesn’t work if you want to change the prototype of an existing object. References   # ECMAScript 6: classes   ↩︎ \n Using ECMAScript 6 today   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎   ↩︎ \n Multiple return values in ECMAScript 6   ↩︎   ↩︎ \n ECMAScript 6’s new array methods   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/12/one-javascript.html", "title": "One JavaScript: avoiding versioning in ECMAScript 6", "content": "One JavaScript: avoiding versioning in ECMAScript 6 esnext dev javascript What is the best way to add new features to a language? This blog post describes the approach taken by ECMAScript 6  [1] , the next version of JavaScript. It is called  , because it avoids versioning. Versioning   # In principle, a new version of a language is a chance to clean it up, by removing outdated features or by changing how features work. That means that new code doesn’t work in older implementations of the language and that old code doesn’t work in a new implementation. Each piece of code is linked to a specific version of the language. Two approaches are common for dealing with versions being different. First, you can take an “all or nothing” approach and demand that, if a code base wants to use the new version, it must be upgraded completely. Python took that approach when upgrading from Python 2 to Python 3. A problem with it is that it may not be feasible to migrate all of an existing code base at once, especially if it is large. Furthermore, the approach is not an option for the web, where you’ll always have old code and where JavaScript engines are updated automatically. Second, you can permit a code base to contain code in multiple versions, by tagging code with versions. On the web, you could tag ECMAScript 6 code via a dedicated  Internet media type . Such a media type can be associated with a file via an HTTP header: It can also be associated via the   attribute of the   element (whose  default value  is  ): This specifies the version  , externally to the actual content. Another option is to specify the version inside the content ( ). For example, by starting a file with the following line: Both ways of tagging are problematic: out-of-band versions are brittle and can get lost, in-band versions add clutter to code. A more fundamental issue is that allowing multiple versions per code base effectively forks a language into sub-languages that have to be maintained in parallel. This causes problems: \n Engines become bloated, because they need to implement the semantics of all versions. The same applies to tools analyzing the language (e.g. style checkers such es JSLint). \n Programmers need to remember how the versions differ. \n Code becomes harder to refactor, because you need to take versions into consideration when you move pieces of code. \n Therefore, versioning is something to avoid, especially for JavaScript and the web. Evolution without versioning   # But how can we get rid of versioning? By always being backwards-compatible. That means we must give up some of our ambitions w.r.t. cleaning up JavaScript: \n We can’t introduce breaking changes: Being backwards-compatible means not removing features and not changing features. The slogan for this principle is: “don’t break the web”. \n We can, however, add new features and make existing features more powerful. \n As a consequence, no versions are needed for new engines, because they can still run all old code. David Herman calls this approach to avoiding versioning   (1JS)  [2] , because it avoids splitting up JavaScript into different versions or modes. As we shall see later, 1JS even undoes some of a split that already exists, due to strict mode. Supporting new code on old engines is more complicated. You have to detect in the engine what version of the language it supports. If it doesn’t support the latest version, you have to load different code: your new code compiled to an older version. That is how you can already use ECMAScript 6 in current engines: you compile it to ECMAScript 5  [1:1] . Apart from performing the compilation step ahead of time, you also have the option of compiling in the engine, at runtime. Detecting versions is difficult, because many engines support parts of versions before they support them completely. For example, this is how you’d check whether an engine supports ECMAScript 6’s   loop – but that may well be the only ES6 feature it supports: Mark Miller  describes  how the Caja library detects whether an engine supports ECMAScript 5. He expects detection of ECMAScript 6 to work similarly, eventually. One JavaScript does not mean that you have to completely give up on cleaning up the language. Instead of cleaning up existing features, you introduce new, clean, features. One example for that is  , which declares block-scoped variables and is an improved version of  . It does not, however, replace  , it exists alongside it, as the superior option. One day, it may even be possible to eliminate features that nobody uses, anymore. Some of the ES6 features were designed by surveying JavaScript code on the web. Two examples (that are explained in more detail later) are: \n  is available in non-strict mode, because   rarely appears on the web. \n Function declarations do occasionally appear in non-strict blocks, which is why the ES6 specification describes measures that web browsers can take to ensure that such code doesn’t break. \n Strict mode and ECMAScript 6   # Strict mode  was introduced in ECMAScript 5 to clean up the language. It is switched on by putting the following line first in a file or in a function: Strict mode introduces three kinds of breaking changes: \n Syntactic changes: some previously legal syntax is forbidden in strict mode. For example:\n \n The   statement is forbidden. It lets users add arbitrary objects to the chain of variable scopes, which slows down execution and makes it tricky to figure out what a variable refers to. \n Deleting an unqualified identifier (a variable, not a property) is forbidden. \n Functions can only be declared at the top level of a scope. \n More identifiers are  reserved :  \n \n \n More errors. For example:\n \n Assigning to an undeclared variable causes a  . In sloppy mode, a global variable is created in this case. \n Changing read-only properties (such as the length of a string) causes a  . In non-strict mode, it simply has no effect. \n \n \n Different semantics: Some constructs behave differently in strict mode. For example:\n \n  doesn’t track the current values of parameters, anymore. \n  is   in non-method functions. In sloppy mode, it refers to the global object ( ), which meant that global variables were created if you called a constructor without  . \n \n \n Strict mode is a good example of why versioning is tricky: Even though it enables a cleaner version of JavaScript, its adoption is still relatively low. The main reasons are that it breaks some existing code, can slow down execution and is a hassle to add to files (let alone interactive command lines). I love   of strict mode and don’t nearly use it often enough. Supporting sloppy mode   # One JavaScript means that we can’t give up on sloppy mode: it will continue to be around (e.g. in HTML attributes). Therefore, we can’t build ECMAScript 6 on top of strict mode, we must add its features to both strict mode and non-strict mode (a.k.a. sloppy mode). Otherwise, strict mode would be a different version of the language and we’d be back to versioning. Unfortunately, two ECMAScript 6 features are difficult to add to sloppy mode:   declarations and block-level function declarations. Let’s examine why that is and how to add them, anyway.  declarations in sloppy mode   #  enables you to declare block-scoped variables. It is difficult to add to sloppy mode, because   is only a reserved word in strict mode. That is, the following two statements are legal in ECMAScript 5 sloppy mode: In strict ECMAScript 6, you get an exception in line 1, because you are using the reserved word   as a variable name. And the statement in line 2 is interpreted as a   variable declaration. In sloppy ECMAScript 6, the first line does not cause an exception, but the second line is still interpreted as a   declaration. The pattern in that line is rare enough that ES6 can afford to make this interpretation. Other ways of writing   declarations can’t be mistaken for existing sloppy syntax: Block-level function declarations in sloppy mode   # ECMAScript 5 strict mode forbids function declarations in blocks. The specification allowed them in sloppy mode, but didn’t specify how they should behave. Hence, various implementations of JavaScript support them, but handle them differently. ECMAScript 6 wants a function declaration in a block to be local to that block. That is OK as an extension of ES5 strict mode, but breaks some sloppy code. Therefore, ES6 provides “ web legacy compatibility semantics ” for browsers that lets function declarations in blocks exist at function scope. Other keywords   # The identifiers   and   are only reserved in ES5 strict mode. ECMAScript 6 uses context-specific syntax rules to make them work in sloppy mode: \n In sloppy mode,   is only a reserved word inside a generator function. \n  is currently only used inside class literals, which are implicitly strict (see below). \n Implicit strict mode   # The bodies of modules and classes are implicitly in strict mode in ECMAScript 6 – there is no need for the   marker. Given that virtually all of our code will live in modules in the future, ECMAScript 6 effectively upgrades the whole language to strict mode. The bodies of other constructs (such as arrow functions and generator functions) could have been made implicitly strict, too. But given how small these constructs usually are, using them in sloppy mode would have resulted in code that is fragmented between the two modes. Classes and especially modules are large enough to make fragmentation less of an issue. It is interesting to note that, inside a   element, you can’t declaratively import modules via an   statement. Instead, there will be a new element, which may be called  , whose insides are much like a module  [3] : Modules can be imported asynchronously and code is implicitly strict and not in global scope (variables declared at the top level are not global). Another way of importing a module, that works inside both elements, is the programmatic   API that returns a module asynchronously, via a promise. Things that can’t be fixed   # The downside of One JavaScript is that you can’t fix existing quirks, especially the following two. First,   should return the string   and not  . But fixing that would break existing code. On the other hand, adding new results for new kinds of operands is OK, because current JavaScript engines already occasionally return custom values for host objects. One example are ECMAScript 6’s symbols: Second, the global object (  in browsers) shouldn’t be in the scope chain of variables. But it is also much too late to change that now. At least you won’t be in global scope in modules and within   elements. Conclusion   # One JavaScript means making ECMAScript 6 completely backwards compatible. It is great that that succeeded. Especially appreciated is that modules (and thus most of our code) are implicitly in strict mode. In the short term, adding ES6 constructs to both strict mode and sloppy mode is more work when it comes to writing the language specification and to implementing it in engines. In the long term, both the spec and engines profit from the language not being forked (less bloat etc.). Programmers profit immediately from One JavaScript, because it makes it easier to get started with ECMAScript 6. Further reading   # Using ECMAScript 6 today  (overview plus links to more in-depth material)  ↩︎   ↩︎ \n The original 1JS proposal (warning: out of date): “ ES6 doesn’t need opt-in ” by David Herman.  ↩︎ \n ECMAScript 6 modules in future browsers   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/retina-images.html", "title": "A new way of delivering Retina images on the web", "content": "A new way of delivering Retina images on the web dev html5 html webdev \nDaan Jobsis has found an interesting solution: Use a high-resolution JPEG image, but but with an extreme compression rate (e.g. 75%):\n \n Retina revolution comments powered by Disqus."},
{"url": "https://2ality.com/2015/01/aurelia.html", "title": "New frontend framework “Aurelia”: Web Components, 6to5, jspm, MVVM", "content": "New frontend framework “Aurelia”: Web Components, 6to5, jspm, MVVM esnext dev javascript webcomponents clientjs Aurelia  is a new framework by Durandal creator  Rob Eisenberg  (which helps credibility-wise). It uses an interesting combination of technologies/techniques: \n Web Components: as an infrastructure for widgets (polyfilled where necessary) \n 6to5 : to compile ECMAScript 6 to ECMAScript 5 \n jspm : for package management \n MVVM (as used by Knockout and the Knockout-inspired Durandal): as a UI pattern \n jspm is currently based on Traceur, support for 6to5 is  work in progress .  Quoting Eisenberg  on how Aurelia combines 6to5 and jspm: There is work on system.js currently to decouple it from traceur and allow the use of 6to5 instead. Note that it only loads traceur if you are feeding it actual es6 code that hasn’t been transpiled. Since aurelia is transpiled and the skeleton is set up to use 6to5…system.js actually never loads traceur and it never comes into play. I haven’t used Aurelia, yet. Opinions welcome. comments powered by Disqus."},
{"url": "https://2ality.com/2015/01/template-strings-html.html", "title": "HTML templating with ES6 template strings", "content": "HTML templating with ES6 template strings esnext dev template literals javascript Despite their name,   in ECMAScript 6 (ES6) are more like a different kind of function call than a mechanism for defining templates. This blog post explains how you can still use them for HTML templating. It is based on  an idea  by  Claus Reinke . If you are not familiar with ES6 template strings, you may want to consult  [1]  before reading on. Defining and using a template   # You define a template as follows. It relies on the     (a function that we’ll look at later). The trick is that the the inside of each substitution   can be an arbitrary expression. We use   to create an array of strings inside the first substitution (which   turns into the appropriate string). Thanks to arrow functions  [2] , the callback of   is nicely concise. Inside the callback, we are “invoking”   again. Therefore, calling the function   leads to several calls of the function  . The double dollar sign in   is not ES6 syntax, it is simply the normal text “ ” in front of the substitution  . But the template handler treats a substitution differently if it is preceded by a dollar sign – it HTML-escapes the string returned by it. The template is used like this: This code produces the following output: Note that the angle brackets around   and   are escaped, whereas   isn’t. The template handler   # The template handler is surprisingly simple: Each substitution is always surrounded by literal sections. If the template string ends with a substitution, the last literal section is an empty string. Accordingly, the following expression is always true: That’s why we need to append the last literal section in line (A). The following is a simple implementation of  . More ideas   # There are more things you can do with this approach to templating: \n \n This approach isn’t limited to HTML, it would work just as well for other kinds of text. Obviously, escaping would have to be adapted. \n \n \n if-then-else inside the template can be done via the ternary operator ( ) or via the logical Or operator ( ): \n \n \n \n Some of the leading whitespace in each line can be trimmed if the first non-whitespace character in the first line defines where the first column is. \n \n \n Destructuring  [3]  can be used: \n \n \n Should I use this in production code?   # Use this approach if you need something quick and dirty. It is not as readable as the template syntax supported by Handlebars.js and similar templating engines. On the other hand, it is lightweight and control flow mechanisms (loops and if-then-else) are easy to understand, because they are just JavaScript. Further reading   # Template strings: embedded DSLs in ECMAScript 6   ↩︎ \n ECMAScript 6: arrow functions and method definitions   ↩︎ \n Multiple return values in ECMAScript 6   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/01/es6-strings.html", "title": "New string features in ECMAScript 6", "content": "New string features in ECMAScript 6 esnext dev javascript The blog post covers new features of strings in ECMAScript 6 (ES6). Unicode code point escapes   # Unicode “characters” (code points) are 21 bit long  [1] . JavaScript strings are (roughly) sequences of 16 bit characters, encoded as UTF-16. Therefore, code points beyond the first 16 bits of the code point range (the  , BMP) are represented by two JavaScript characters. Until now, if you wanted to specify such code points via numbers, you needed two so-called  . As an example, the following statement prints a rocket (code point 0x1F680) to most consoles: In ECMAScript 6, there is a new kind of Unicode escape that lets you specify any code point: String interpolation, multi-line string literals and raw string literals   # Template strings  [2]  provide three interesting features. First, template strings support string interpolation: Second, template strings can contain multiple lines: Third, template strings are “raw” if you prefix them with the     – the backslash is not a special character and escapes such as   are not interpreted: Iterating over strings   # Strings are    [3] , which means that you can use   to iterate over their characters: And you can use the spread operator ( ) to turn strings into arrays: Handling Unicode code points   # The string iterator splits strings along code point boundaries, which means that the strings it returns comprise one or two characters: That gives you a quick way to count the Unicode code points in a string: It also helps with reversing strings that contain non-BMP code points: Numeric values of code points   # The new method   returns the numeric value of a code point at a given index in a string: This method works well when combined with iteration over strings: The opposite of   is  : Checking for containment and repeating strings   # Three new methods check whether a string exists within another string: Each of these methods has a position as an optional second parameter, which specifies where the string to be searched starts or ends: The   method repeats strings: All new methods   # Template strings: \n \nTemplate string tag for “raw” content (backslashes are not interpreted). \n Unicode and code points: \n \nTurns numbers denoting Unicode code points into a string. \n \nReturns the number of the code point starting at position   (comprising one or two JavaScript “characters”). \n \nDifferent combinations of code points may look the same.  Unicode normalization  changes them all to the same value(s), their so-called  . That helps with comparing and searching for strings. The   form is recommended for general text. \n Finding strings: \n \nDoes the receiver start with  ?   lets you specify where the string to be checked starts. \n \nDoes the receiver end with  ?   lets you specify where the string to be checked ends. \n \nDoes the receiver contain  ?   lets you specify where the string to be searched starts. \n Repeating strings: \n \nReturns the receiver, concatenated   times. \n Further reading   # Chapter 24, “ Unicode and JavaScript ” of “Speaking JavaScript”; includes an introduction to Unicode.  ↩︎ \n Template strings: embedded DSLs in ECMAScript 6   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2015/01/es6-set-operations.html", "title": "ECMAScript 6 sets: union, intersection, difference", "content": "ECMAScript 6 sets: union, intersection, difference esnext dev javascript section “Missing Set operations” A recent  question  by Dmitry Moskowski reminded me: ECMAScript 6 sets have no methods for computing the union (e.g.  ), intersection (e.g.  ) or difference (e.g.  ). This blog post explains how to work around that limitation. Union   # Union (  ∪  ): create a set that contains the elements of both set   and set  . The pattern is always the same: \n Convert one or both sets to arrays. \n Perform the operation. \n Convert the result back to a set. \n As explained in  [1] , the spread operator ( ) inserts the elements of something iterable (like a set) into an array. Therefore,   means that   and   are converted to arrays and concatenated. It is equivalent to  . Intersection   # Intersection (  ∩  ): create a set that contains those elements of set   that are also in set  . Steps: Convert   to an array, filter the elements, convert the result to a set. Difference   # Difference (  \\  ): create a set that contains those elements of set   that are not in set  . This operation is also sometimes called   ( ). Conclusion   # This blog post showed how you can implement union, intersection and different for sets. Long-term, I expect JavaScript to have built-in functionality for this, e.g. via functions that operate on iterables (similar to Python’s  itertools ). Further reading   # ECMAScript 6: maps and sets   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/javascript-puzzle-equal.html", "title": "JavaScript puzzle: equal, but not the same", "content": "JavaScript puzzle: equal, but not the same dev javascript puzzle jslang posted Show answer \n \n+0 and -0 are the only two values that are not the same, but are still considered strictly equal  [1] . They can only be distinguished indirectly, by applying a mathematical operation to them that produces distinguishable results. Dividing 1 by zero is one of several operations that does so:\n “ Stricter equality in JavaScript ” explores more consequences of strict equality’s special treatment of +0, -0 and  .\n     “ JavaScript’s two zeros ” provides more information on the two zeros. For example, other ways than the above for distinguishing them.\n     comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/template-strings-xregexp.html", "title": "Using ES6 template strings for regular expressions", "content": "Using ES6 template strings for regular expressions esnext dev template literals javascript [1] an example XRegExp \n(As an aside, XRegExp is highly recommended if you are working with regular expressions. You get many advanced features, but there is only a small performance penalty – once at creation time – because XRegExp compiles its input to native regular expressions.)\n \nWithout template strings, you write code such as the following:\n \n \n Template strings: embedded DSLs in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2015/01/es6-destructuring.html", "title": "Destructuring and parameter handling in ECMAScript 6", "content": "Destructuring and parameter handling in ECMAScript 6 esnext dev javascript chapter “Destructuring” section “Parameter handling” ECMAScript 6 (ES6) supports  , a convenient way to extract values from data stored in (possibly nested) objects and arrays. This blog post describes how it works and gives examples of its usefulness. Additionally, parameter handling receives a significant upgrade in ES6: it becomes similar to and supports destructuring, which is why it is explained here, too. Destructuring   # In locations that receive data (such as the left-hand side of an assignment), destructuring lets you use patterns to extract parts of that data. In the following example, we use destructuring in a variable declaration (line (A)). It declares the variables   and   and assigns them the values   and  . Destructuring can be used in the following locations. Each time,   is set to  . Constructing versus extracting   # To fully understand what destructuring is, let’s first examine its broader context. JavaScript has operations for constructing data: And it has operations for extracting data: Note that we are using the same syntax that we have used for constructing. There is nicer syntax for constructing – an  :  in ECMAScript 6 enables the same syntax for extracting data, where it is called an  : Just as the object literal lets us create multiple properties at the same time, the object pattern lets us extract multiple properties at the same time. You can also destructure arrays via patterns: We distinguish: \n  the data to be destructured. For example, the right-hand side of a destructuring assignment. \n  the pattern used for destructuring. For example, the left-hand side of a destructuring assignment. \n Being selective with parts   # If you destructure an object, you are free to mention only those properties that you are interested in: If you destructure an array, you can choose to only extract a prefix: If a part has no match   # Similarly to how JavaScript handles non-existent properties and array elements, destructuring silently fails if the target mentions a part that doesn’t exist in the source: the interior of the part is matched against  . If the interior is a variable that means that the variable is set to  : Nesting   # You can nest patterns arbitrarily deeply: How do patterns access the innards of values?   # In an assignment  , how does the   acess what’s inside  ? # The object pattern coerces destructuring sources to objects before accessing properties. That means that it works with primitive values: # The coercion to object is not performed via  , but via the internal operation  .   never fails:  throws a   if it encounters   or  . Therefore, the following destructurings fail, even before destructuring accesses any properties: As a consequence, you can use the empty object pattern   to check whether a value is coercible to an object. As we have seen, only   and   aren’t: The parentheses around the object patterns are necessary because statements must not begin with curly braces in JavaScript. # Array destructuring uses an iterator to get to the elements of a source. Therefore, you can array-destructure any value that is iterable. Let’s look at examples of iterable values. Strings are iterable: Don’t forget that the iterator over strings returns code points (“Unicode characters”, 21 bits), not code units (“JavaScript characters”, 16 bits). (For more information on Unicode, consult the chapter “ Chapter 24. Unicode and JavaScript ” in “Speaking JavaScript”.) For example: You can’t access the elements of a set  [1]  via indices, but you can do so via an iterator. Therefore, array destructuring works for sets: The   iterator always returns elements in the order in which they were inserted, which is why the result of the previous destructuring is always the same.  Destructuring also works for iterators over infinite sequences. The generator function   returns an iterator that yields 0, 1, 2, etc. The following destructuring extracts the first three elements of that infinite sequence. # A value is iterable if it has a method whose key is   that returns an object. Array-destructuring throws a   if the value to be destructured isn’t iterable: The   is thrown even before accessing elements of the iterable, which means that you can use the empty array pattern   to check whether a value is iterable: Default values   #  are a feature of patterns: \n Each part of a pattern can optionally specify a default value. \n If the part has no match in the source, destructuring continues with the default value (if one exists) or  . \n Let’s look at an example. In the following destructuring, the element at index 0 has no match on the right-hand side. Therefore, destructuring continues by matching   against 3, which leads to   being set to 3. You can also use default values in object patterns: Default values are also used if a part does have a match and that match is  : The rationale for this behavior is explained later, in the section on parameter default values. # The default values themselves are only computed when they are needed. That is, this destructuring: is equivalent to: You can observe that if you use  : In the second destructuring, the default value is not needed and   is not called. # A default value can refer to any variable, including another variable in the same pattern: However, order matters: the variables   and   are declared from left to right and produce a   if they are accessed before their declaration. # So far we have only seen default values for variables, but you can also associate them with patterns: What does this mean? Recall the rule for default values: If the part has no match in the source, destructuring continues with the default value […]. The element at index 0 has no match, which is why destructuring continues with: You can more easily see why things work this way if you replace the pattern   with the variable  :  Let’s further explore default values for patterns. In the following example, we assign a value to   via the default value  : Because the array element at index 0 has no match on the right-hand side, destructuring continues as follows and   is set to 123. However,   is not assigned a value in this manner if the right-hand side has an element at index 0, because then the default value isn’t triggered. In this case, destructuring continues with: Thus, if you want   to be 123 if either the object or the property is missing, you need to specify a default value for   itself: Here, destructuring continues as follows, independently of whether the right-hand side is   or  . More object destructuring features   # # Property value shorthands  [2]  are a feature of object literals: If the value of a property is provided via a variable whose name is the same as the key, you can omit the key. This works for destructuring, too: This declaration is equivalent to: You can also combine property value shorthands with default values: # Computed property keys  [2:1]  are another object literal feature that also works for destructuring: You can specify the key of a property via an expression, if you put it in square brackets: Computed property keys allow you to destructure properties whose keys are symbols  [3] : More array destructuring features   # # Elision lets you use the syntax of array “holes” to skip elements during destructuring: # The   ( ) lets you extract the remaining elements of an array into an array. You can only use the operator as the last part inside an array pattern: [Note: This operator extracts data. The same syntax ( ) is used by the  , which constructs and is explained later.] If the operator can’t find any elements, it matches its operand against the empty array. That is, it never produces   or  . For example: The operand of the rest operator doesn’t have to be a variable, you can use patterns, too: The rest operator triggers the following destructuring: You can assign to more than just variables   # If you assign via destructuring, each variable part can be everything that is allowed on the left-hand side of a normal assignment, including a reference to a property ( ) and a reference to an array element ( ). You can also assign to object properties and array elements via the rest operator ( ): If you   variables via destructuring then you must use simple identifiers, you can’t refer to object properties and array elements. Pitfalls of destructuring   # There are two things to be mindful of when using destructuring. # Because code blocks begin with a curly brace, statements must not begin with one. This is unfortunate when using object destructuring in an assignment: The work-around is to either put the pattern in parentheses or the complete expression: # Within a destructuring variable declaration, every variable in the source is declared. In the following example, we are trying to declare the variable   and refer to the existing variable  , which doesn’t work. The fix is to use a destructuring assignment and to declare   beforehand: Examples of destructuring   # Let’s start with a few smaller examples. The   loop  [4]  supports destructuring: You can use destructuring to swap values. That is something that engines could optimize, so that no array would be created. You can use destructuring to split an array: # Some built-in JavaScript operations return arrays. Destructuring helps with processing them:  returns   if the regular expression doesn’t match. Unfortunately, you can’t handle   via default values, which is why you must use the Or operator ( ) in this case: # To see the usefulness of multiple return values, let’s implement a function   that searches for the first element in the array   for which the function   returns  . The question is: what should that function return? Sometimes one is interested in the element itself, sometimes in its index, sometimes in both. The following implementation does both. In line (A), the array method   returns an iterable over   pairs. We destructure one pair per iteration. In line (B), we use property value shorthands to return the object  . In the following example, we use several ECMAScript features to write more concise code: An arrow functions helps us with defining the callback, destructuring and property value shorthands help us with handling the return value. Due to   and   also referring to property keys, the order in which we mention them doesn’t matter: We have successfully handled the case of needing both index and element. What if we are only interested in one of them? It turns out that, thanks to ECMAScript 6, our implementation can take care of that, too. And the syntactic overhead compared to functions that support only elements or only indices is minimal. Each time, we only extract the value of the one property that we need. Parameter handling   # Parameter handling has been significantly upgraded in ECMAScript 6. It now supports parameter default values, rest parameters (varags) and destructuring. The new way of handling parameters is equivalent to destructuring the actual parameters via the formal parameters. That is, the following function call: is equivalent to: Let’s look at specific features next. Parameter default values   # ECMAScript 6 lets you specify default values for parameters: Omitting the second parameter triggers the default value: Watch out –   triggers the default value, too: The default value is computed on demand, only when it is actually needed: # It isn’t immediately obvious why   should be interpreted as a missing parameter or a missing part of an object or array. The rationale for doing so is that it enables you to delegate the definition of default values. Let’s look at two examples. In the first example (source:  Rick Waldron’s TC39 meeting notes from 2012-07-24 ), we don’t have to define a default value in  , we can delegate that task to  . In the second example,   doesn’t have to define a default for  , it can delegate that task to  : Default values further entrench the role of   as indicating that something doesn’t exist, versus   indicating emptiness. # Within a parameter default value, you can refer to any variable, including other parameters: However, order matters: parameters are declared from left to right and within a default value, you get a   if you access a parameter that hasn’t been declared, yet. Default values exist in their own scope, which is between the “outer” scope surrounding the function and the “inner” scope of the function body. Therefore, you can’t access inner variables from the default values: If there were no outer   in the previous example, the default value   would produce a  . Rest parameters   # Putting the rest operator ( ) in front of the last formal parameter means that it will receive all remaining actual parameters in an array. If there are no remaining parameters, the rest parameter will be set to the empty array: # Rest parameters can completely replace JavaScript’s infamous special variable  . They have the advantage of always being arrays: One interesting feature of   is that you can have normal parameters and an array of all parameters at the same time: You can avoid   in such cases if you combine a rest parameter with array destructuring. The resulting code is longer, but more explicit: Note that   is iterable  [4:1]  in ECMAScript 6, which means that you can use   and the spread operator: Simulating named parameters   # When calling a function (or method) in a programming language, you must map the actual parameters (specified by the caller) to the formal parameters (of a function definition). There are two common ways to do so: \n \n  are mapped by position. The first actual parameter is mapped to the first formal parameter, the second actual to the second formal, and so on. \n \n \n  use   (labels) to perform the mapping. Names are associated with formal parameters in a function definition and label actual parameters in a function call. It does not matter in which order named parameters appear, as long as they are correctly labeled. \n \n Named parameters have two main benefits: they provide descriptions for arguments in function calls and they work well for optional parameters. I’ll first explain the benefits and then show you how to simulate named parameters in JavaScript via object literals. # As soon as a function has more than one parameter, you might get confused about what each parameter is used for. For example, let’s say you have a function,  , that returns entries from a database. Given the function call: what do these two numbers mean? Python supports named parameters, and they make it easy to figure out what is going on: # Optional positional parameters work well only if they are omitted at the end. Anywhere else, you have to insert placeholders such as   so that the remaining parameters have correct positions. With optional named parameters, that is not an issue. You can easily omit any of them. Here are some examples: # JavaScript does not have native support for named parameters like Python and many other languages. But there is a reasonably elegant simulation: name parameters via an object literal, passed as a single actual parameter. When you use this technique, an invocation of   looks like: The function receives an object with the properties  ,  , and  . You can omit any of them: In ECMAScript 5, you’d implement   as follows: In ECMAScript 6, you can use destructuring, which looks like this: If you call   with zero arguments, the destructuring fails, because you can’t match an object pattern against  . That can be fixed via a default value. In the following code, the object pattern is matched against   if there isn’t at least one argument. You can also combine positional parameters with named parameters. It is customary for the latter to come last: In principle, JavaScript engines could optimize this pattern so that no intermediate object is created, because both the object literals at the call sites and the object patterns in the function definitions are static.  In JavaScript, the pattern for named parameters shown here is sometimes called   or   (e.g., by the jQuery documentation). Pitfall: destructuring a single arrow function parameter   # Arrow functions have a special single-parameter version where no parentheses are needed: The single-parameter version does not support destructuring: Examples of parameter handling   # # You will probably mostly use the   loop in ECMAScript 6, but the array method   also profits from destructuring. Or rather, its callback does. First example: destructuring the arrays in an array. Second example: destructuring the objects in an array. # An ECMAScript 6 Map  [1:1]  doesn’t have a method   (like arrays). Therefore, one has to: Convert it to an array of   pairs.  the array. Convert the result back to a map. This looks as follows. # The tool method    [5]  works as follows: \n Input: an array of Promises. \n Output: a Promise that resolves to an array as soon as the last input Promise is resolved. The array contains the resolutions of the input Promises. \n Destructuring helps with handling the array that the result of   resolves to:  is a Promise-based version of  . It is  part of the Fetch standard . # In ECMAScript 5, you have a few options for ensuring that a required parameter has been provided, which are all quite clumsy: In ECMAScript 6, you can (ab)use default parameter values to achieve more concise code (credit: idea by Allen Wirfs-Brock): Interaction: # This section presents three approaches to enforcing a maximum arity. The running example is a function   whose maximum arity is 2 – if a caller provides more than 2 parameters, an error should be thrown. The first approach collects all actual parameters in the formal rest parameter   and checks its length. The second approach relies on unwanted actual parameters appearing in the formal rest parameter  . The third approach uses a sentinel value that is gone if there is a third parameter. One caveat is that the default value   is also triggered if there is a third parameter whose value is  . Sadly, each one of these approaches introduces significant visual and conceptual clutter. I’m tempted to recommend checking  , but I also want   to go away. The spread operator ( )   # The spread operator ( ) is the opposite of the rest operator: Where the rest operator extracts arrays, the spread operator turns the elements of an array into the arguments of a function call or into elements of another array. Spreading into function and method calls   #  is a good example for demonstrating how the spread operator works in method calls.   returns the argument whose value is greatest. It accepts an arbitrary number of arguments, but can’t be applied to arrays. The spread operator fixes that: In contrast to the rest operator, you can use the spread operator anywhere in a sequence of parts: Another example is JavaScript not having a way to destructively append the elements of one array to another one. However, arrays do have the method  , which appends all of its arguments to its receiver. The following code shows how you can use   to append the elements of   to  . Spreading into constructors   # In addition to function and method calls, the spread operator also works for constructor calls: That is something that is  difficult to achieve in ECMAScript 5 . Spreading into arrays   # The spread operator can also be used inside arrays: That gives you a convenient way to concatenate arrays: # The spread operator lets you convert any iterable object to an array: Let’s convert a set  [1:2]  to an array: Your own iterable objects  [4:2]  can be converted to arrays in the same manner: Note that, just like the   loop, the spread operator only works for iterable objects. Most important objects are iterable: arrays, maps, sets and  . Most DOM data structures will also eventually be iterable. Should you ever encounter something that is not iterable, but array-like (indexed elements plus a property  ), you can use    [6]  to convert it to an array: Further reading:   # ECMAScript 6: maps and sets   ↩︎   ↩︎   ↩︎ \n ECMAScript 6: new OOP features besides classes   ↩︎   ↩︎ \n Symbols in ECMAScript 6   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎   ↩︎   ↩︎ \n ECMAScript 6 promises (2/2): the API   ↩︎ \n ECMAScript 6’s new array methods   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/clear-array.html", "title": "Two ways of clearing an array in JavaScript", "content": "Two ways of clearing an array in JavaScript dev javascript jslang \nIn a  blog post , David Walsh mentions two approaches for emptying (clearing) an array. This blog post explains the pros and cons of both approaches. In order to understand them, we first need to know about  .\n \n\n Background: aliasing Clearing an array Replace an array with an empty array Set the array’s length to zero [1] performance test Reference Arrays in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/es6-workflow.html", "title": "The future of JavaScript: a CoffeeScript-like workflow", "content": "The future of JavaScript: a CoffeeScript-like workflow esnext dev javascript [1] Evolving a web programming language Applications are written in many different ECMAScript versions. Even a single application is likely to be a mix of several versions, considering that it often includes libraries and external code (e.g. for analytics).\n     Many different browser versions are in use, even quite old ones. In every browser, there is exactly one version of ECMAScript available. Users have little control over which version it is, because browsers often update themselves automatically (making new versions forced upgrades).\n     \nIt is interesting to compare that with how things work with traditional programming languages: You have much more control. End users decide when to upgrade engine and app versions. As an app developer, you can usually demand that a reasonably recent version of a language be installed and can target that version.\nBreaking changes to a language can be introduced by letting users install two versions in parallel (which is what Python did with version 3).\n\n Why not versioning? [2] Solution for app developers: a CoffeeScript-like workflow [3] [4] [5] \n     Different syntax: when CoffeeScript was created, giving it a different syntax made sense, because it wasn’t JavaScript and pretending so would have clashed with future versions of that language. However, now that CoffeeScript’s most important “fixes” are available in ECMAScript 6, we can go native again. This point is obviously controversial – people who like CoffeeScript often do so   of its different syntax, not despite it. I, however, agree with Nicholas Zakas’  assertion :\n         \n            [...] [I] want the web as a whole to continue to grow and get better, and that only happens when we have more competent developers entering the workforce.\n             \n            I see compile-to-JavaScript languages as a barrier to that goal. We should be convincing more people to learn JavaScript rather than giving them more options to not write JavaScript. I often wonder what would happen if all of the teams and companies who spent time, energy, personnel, and money to develop these alternatives instead used those resources on improving JavaScript and teaching it.\n         \n     \n     No compilation during development: Soon, you’ll be able to use an ECMAScript 6 capable browser during development and won’t have to compile. It’s a small thing, but still less complexity to worry about.\n     \n     New features: ECMAScript 6 can do things that CoffeeScript can’t. Two examples: modules and generators  [6] .\n     \n Compiling ECMAScript 6 to ECMAScript 3 \n     Traceur : compiles ECMAScript 6 to ECMAScript 3, on the fly. You can thus already play with ECMAScript 6 now. Dynamic compilation is an interesting alternative to compiling before deployment. Possible problems are performance and debugging.\n     \n     Harmonizr : statically compiles to ECMAScript 3. It supports ECMAScript 6 features such as modules, arrow functions and classes.\n     \n     TypeScript : statically compiles to ECMAScript 3 and has several advanced features, some of them borrowed from ECMAScript 6 (classes, modules). Interestingly, feedback from TypeScript now helps with evolving ECMAScript. Issues encountered here let us discover potential problems with ECMAScript 6 – before it exists. Note that TypeScript is not always completely compatible with ECMAScript 6 (especially w.r.t. how it handles private properties).\n     \n     Esprima: Ariya Hidayat has written articles on how to use his ECMAScript parser  Esprima  to compile ECMAScript 6  modules  and  classes  to earlier ECMAScript versions.\n     \n Compiling   declarations [7] The standard library [8] Using new language features directly Wait until ECMAScript 6 is the dominant version, switch to it completely. That will take a while.\n     Dynamically feature-detect what a browser supports and shim less functionality.\n     Determine what ECMAScript version a browser supports before delivering JavaScript source files from the server. If it supports ECMAScript 6, deliver the original source code. If it doesn’t, deliver the compiled source code.\n     Conclusion guide References ECMAScript: ES.next versus ES 6 versus ES Harmony JavaScript’s strict mode: a summary SourceMap on Firefox: source debugging for languages compiled to JavaScript [update: WebKit, too] ECMAScript.next: arrow functions and method definitions ECMAScript.next: classes ECMAScript.next’s for-of loop  [explains what generators are] JavaScript variable scoping and its pitfalls es6-shim – ECMAScript 6 functionality on ECMAScript 5 comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/comprehensions.html", "title": "ECMAScript.next: array comprehensions and generator comprehensions", "content": "ECMAScript.next: array comprehensions and generator comprehensions esnext dev javascript \nECMAScript.next will have two kinds of comprehensions: array comprehensions and generator comprehensions. They allow one to quickly assemble an array or a sequence of elements. Comprehensions exist in many programming languages, for example: CoffeeScript, Python, Haskell, Clojure.\n\n \n\n Array comprehensions [1] \n     \n     \n [2] Generator comprehensions [1] Syntax: left-to-right versus right-to-left David Herman Trying out comprehensions in Firefox \n     Array comprehensions \n     Generator expressions  (Firefox’s name for generator comprehensions) \n References ECMAScript.next: for-of, iterators, generators ECMAScript.next: arrow functions and method definitions comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/looking-back-on-2012.html", "title": "Looking back on 2012", "content": "Looking back on 2012 2ality \n     I talked at several great conferences:\n         \n             April,  Mix-IT , Lyon: “ An overview of JavaScript ” ( video ). I’m glad that people  liked it .\n             \n             May,  Fluent , San Francisco: “ Improving JavaScript ” ( video ). \n             October,  JSConf EU , Berlin: “ JavaScript inheritance: beyond the basics ” ( video ).\n             \n         \n        More speaking engagements of mine are coming up in 2013, follow me  on Twitter  to be notified.\n     \n     O’Reilly has published “ The Past, Present, and Future of JavaScript ”, as a free mini-ebook (registration required).\n     \n     Articles of mine have been published in the free digital magazine Appliness (“ A closer look at Underscore templates ”, among others) and on the Adobe Developer Connection (“ Categorizing values in JavaScript ”).\n     \n     I’ve become  the editor of the free email newsletter  JavaScript Weekly .\n     \n     The  JavaScript User Group Munich  that I organize is doing well: We regularly have over 80 attendees and were sponsored by Intel, Microsoft and Mozilla this year (Google sponsored us in 2011). Should you ever come to Munich, consider holding a talk!\n     \n     2ality began almost 8 years ago. I’m happy to report that it continues to thrive. Readership is steadily increasing. And people that I greatly respect have written  kind testimonials . I’m still trying to figure out how to make 2ality at least partially pay for itself: I made about 10 EUR per month with Google ads and decided to switch them off, because they simply were not worth the ugliness.\n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/brace-styles.html", "title": "Brace styles and JavaScript", "content": "Brace styles and JavaScript dev javascript jslang jsstyle brace styles Allman style [1] 1TBS (One True Brace Style) JavaScript [2] [1] \nThe   statement is one of the few cases where newline is significant in JavaScript: it works as a terminator for statements. In the future, newlines might become more significant in JavaScript  [3] .\n\n My preferences \n     1TBS \n     I omit braces in an if-statement if there is no else-case and the then-case has only one or two tokens. I write such if-statements in single lines. For example:\n \n     \n     I indent 4 spaces. I never use tabs for indentation, as they are displayed too differently on various systems. \n References Expressions versus statements in JavaScript Automatic semicolon insertion in JavaScript What JavaScript would be like with significant newlines comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/celsius-fahrenheit.html", "title": "What temperature has the same degrees in Celsius and Fahrenheit?", "content": "What temperature has the same degrees in Celsius and Fahrenheit? life scitech Converting from Fahrenheit to Celsius Converting from Celsius to Fahrenheit The same degrees in both systems? comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/two-prototypes.html", "title": "JavaScript terminology: the two prototypes", "content": "JavaScript terminology: the two prototypes dev javascript jslang Prototype 1: relationship between objects [1] [2] Prototype 2: property of constructors Resolving the name clash References JavaScript inheritance by example JavaScript: __proto__ comments powered by Disqus."},
{"url": "https://2ality.com/2012/12/blog-problem.html", "title": "The problem with blogs", "content": "The problem with blogs publishing computers RSS Atom The problem \nFurthermore, navigating blogs is often difficult, because there is little structure. If you are lucky, posts are well categorized, but even that falls short of proper instructions on where to start reading. Such instructions are especially important for people new to a blog, who want to catch up on existing content.\n\n A partial solution guides \nAdditionally, I think we need more content management systems that are a cross between a blog and a wiki – blikis. Martin Fowler describes blikis  as follows :\n comments powered by Disqus."},
{"url": "https://2ality.com/2014/08/formatting-generator-asterisk.html", "title": "How should I format the ECMAScript 6 generator asterisk?", "content": "How should I format the ECMAScript 6 generator asterisk? esnext dev javascript jslang  This blog post is now a section in “ ES6 generators in depth ”. The asterisk ( ) is used by ECMAScript 6 to mark generator-related constructs  [1] . In each case, you have considerable freedom w.r.t. adding or omitting whitespace before and after this character. This blog post explains how to best format the asterisk and why. The generator asterisk   # The generator asterisk appears in three locations in ECMAScript 6: \n Generator function declarations and expressions: \n \n Concise generator method definitions  [2] : \n \n The recursive   operator: \n \n Reasonable – and legal – variations of formatting the asterisk are: \n \n A space before and after it: \n \n \n \n A space before it: \n \n \n \n A space after it: \n \n \n \n No whitespace before and after it: \n \n \n Let’s figure out which of these variations make sense for which constructs and why. Generator function declarations and expressions   # Here, the star is only used because   (or something similar) isn’t available as a keyword. If it were, then a generator function declaration would look like this: Instead of  , ECMAScript 6 marks the   keyword with an asterisk. Thus,   can be seen as a synonym for  , which suggests writing generator function declarations as follows. Concise generator method definitions   # When writing a concise generator method definitions, I recommend to format the asterisk as follows. There are three arguments in favor of writing a space after the asterisk. First, the asterisk shouldn’t be part of the method name. On one hand, it isn’t part of the name of a generator function. On the other hand, the asterisk is only mentioned when defining a generator, not when using it. Second, a concise generator method definition is an abbreviation for the following syntax. (To make my point, I’m redundantly giving the function expression a name, too.) If concise method definitions are about omitting the   keyword then the asterisk should probably be followed by a space. Third, generator method definitions are syntactically similar to getters and setters (which are already available in ECMAScript 5): The keywords   and   can be seen as modifiers of a normal concise method definition. Arguably, an asterisk is also such a modifier. Recursive     # The following is an example of a generator function yielding its own yielded values recursively: The asterisk marks a different kind of   operator, which is why the above way of writing it makes sense. Documenting generator functions and methods   # Kyle Simpson (@getify) recently proposed something interesting: Given that we often append parentheses when we write about functions and methods such as  , wouldn’t it make sense to prepend an asterisk when writing about generator functions and methods? For example: should we write   to refer to the generator function in the previous subsection? I’d argue against that. When it comes to writing a function that returns an iterable, a generator is only one of the several options. I think it is better to not give away this implementation detail via marked function names. Furthermore, you don’t use the asterisk when calling a generator function, but you do use parentheses. Lastly, the asterisk doesn’t provide useful information –   can also be used with functions that return an iterable. But it may make sense to mark the names of functions and methods that return iterables (including generators). For example, via the suffix  . Further reading   # Iterators and generators in ECMAScript 6   ↩︎ \n Callable entities in ECMAScript 6   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/09/es6-function-signature-mismatch.html", "title": "Preventing function signature mismatch in ES5 and ES6", "content": "Preventing function signature mismatch in ES5 and ES6 esnext dev javascript jslang In some cases, using a function (or method) with a callback can lead to surprising results – if the  signature  of the latter does not match the expectations of the former. This blog post explains this phenomenon and suggests fixes. Function signature mismatch   # Let’s look at an example  [1] : Here,   expects the following signature: But   has the signature: It’s not a problem that  ’s arity is less than the 3 expected by  ; JavaScript does not complain if you ignore arguments. However,   and the optional   don’t match semantically. Whenever you are using a library function as a callback, you are taking a risk: its signature may not match semantically, it may even change later on. Preventing mismatch   # Prevention via arrow functions   # In ECMAScript 6, arrow functions  [2]  give you the means to be explicit about the signature of a callback, without too much verbosity: I like using arrow functions for this purpose: it’s compact and you immediately see how the code works. Prevention via a helper function   # Another option for preventing signature mismatch is to use a higher-order helper function, e.g.:  has the following signature: The indices indicate which of the input parameters   receives and in which order. The following is an implementation for ECMAScript 5. The following is an implementation for ECMAScript 6. Note how much simpler it is, due to rest parameters and arrow functions. References   # “ Pitfall: Unexpected Optional Parameters ” in Speaking JavaScript  ↩︎ \n ECMAScript 6: arrow functions and method definitions   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/08/javascript-coding-tips.html", "title": "Video: JavaScript coding tips", "content": "Video: JavaScript coding tips dev javascript jslang video The following video is a recording of the talk “ JavaScript coding tips ”, which I held 2014-05-16 at the  Sud Web Conference  in Toulouse, France. Bonus: \n See how I feel about comma first style (I was much meaner than I remember). I don’t personally like it, but I respect how creatively it solves a problem. \n Hear me speak French after the talk. \n Material: \n Slides \n “ Popular Coding Conventions on Github ” by  Outsider : what coding conventions do people use on GitHub and how frequently? \n “ A Meta Code Style Guide ”, chapter 26 of “ Speaking JavaScript ”, which covers some of the topics of this talk in more depth. \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/09/es6-modules-final.html", "title": "ECMAScript 6 modules: the final syntax", "content": "ECMAScript 6 modules: the final syntax esnext dev javascript jsmodules chapter “Modules” At the end of July 2014, TC39  [1]  had another  meeting , during which the last details of the ECMAScript 6 (ES6) module syntax were finalized. This blog post gives an overview of the complete ES6 module system. Module systems for current JavaScript   # JavaScript does not have built-in support for modules, but the community has created impressive work-arounds. The two most important (and unfortunately incompatible) standards are: \n  The dominant implementation of this standard is  in Node.js  (Node.js modules have a few features that go beyond CommonJS). Characteristics:\n \n Compact syntax \n Designed for synchronous loading \n Main use: server \n \n \n  The most popular implementation of this standard is  RequireJS . Characteristics:\n \n Slightly more complicated syntax, enabling AMD to work without eval() (or a compilation step). \n Designed for asynchronous loading \n Main use: browsers \n \n \n The above is but a grossly simplified explanation of the current state of affairs. If you want more in-depth material, take a look at “ Writing Modular JavaScript With AMD, CommonJS & ES Harmony ” by Addy Osmani. ECMAScript 6 modules   # The goal for ECMAScript 6 modules was to create a format that both users of CommonJS and of AMD are happy with: \n Similar to CommonJS, they have a compact syntax, a preference for single exports and support for cyclic dependencies. \n Similar to AMD, they have direct support for asynchronous loading and configurable module loading. \n Being built into the language allows ES6 modules to go beyond CommonJS and AMD (details are explained later): \n Their syntax is even more compact than CommonJS’s. \n Their structure can be statically analyzed (for static checking, optimization, etc.). \n Their support for cyclic dependencies is better than CommonJS’s. \n The ES6 module standard has two parts: \n Declarative syntax (for importing and exporting) \n Programmatic loader API: to configure how modules are loaded and to conditionally load modules \n An overview of the ES6 module syntax   # There are two kinds of exports: named exports (several per module) and default exports (one per module). Named exports (several per module)   # A module can export multiple things by prefixing their declarations with the keyword  . These exports are distinguished by their names and are called  . There are other ways to specify named exports (which are explained later), but I find this one quite convenient: simply write your code as if there were no outside world, then label everything that you want to export with a keyword. If you want to, you can also import the whole module and refer to its named exports via property notation:  For a while, I tried several clever strategies to be less redundant with my module exports in Node.js. Now I prefer the following simple but slightly verbose style that is reminiscent of the  revealing module pattern : Default exports (one per module)   # Modules that only export single values are very popular in the Node.js community. But they are also common in frontend development where you often have constructors/classes for models, with one model per module. An ECMAScript 6 module can pick a  , the most important exported value. Default exports are especially easy to import. The following ECMAScript 6 module “is” a single function: An ECMAScript 6 module whose default export is a class looks as follows: Note: The operand of the default export declaration is an  expression , it often does not have a name. Instead, it is to be identified via its module’s name. Having both named exports and a default export in a module   # The following pattern is surprisingly common in JavaScript: A library is a single function, but additional services are provided via properties of that function. Examples include jQuery and Underscore.js. The following is a sketch of Underscore as a CommonJS module: With ES6 glasses, the function   is the default export, while   and   are named exports. As it turns out, you can actually have named exports and a default export at the same time. As an example, the previous CommonJS module, rewritten as an ES6 module, looks like this: Note that the CommonJS version and the ECMAScript 6 version are only roughly similar. The latter has a flat structure, whereas the former is nested. Which style you prefer is a matter of taste, but the flat style has the advantage of being statically analyzable (why that is good is explained below). The CommonJS style seems partially motivated by the need for objects as namespaces, a need that can often be fulfilled via ES6 modules and named exports. # The default export is actually just a named export with the special name  . That is, the following two statements are equivalent: Similarly, the following two modules have the same default export: # You may be wondering – why do we need named exports if we could simply default-export objects (like CommonJS)? The answer is that you can’t enforce a static structure via objects and lose all of the associated advantages (described in the next section). Design goals   # If you want to make sense of ECMAScript 6 modules, it helps to understand what goals influenced their design. The major ones are: \n Default exports are favored \n Static module structure \n Support for both synchronous and asynchronous loading \n Support for cyclic dependencies between modules \n The following subsections explain these goals. Default exports are favored   # The module syntax suggesting that the default export “is” the module may seem a bit strange, but it makes sense if you consider that one major design goal was to make default exports as convenient as possible. Quoting  David Herman : ECMAScript 6 favors the single/default export style, and gives the sweetest syntax to importing the default. Importing named exports can and even should be slightly less concise. Static module structure   # In current JavaScript module systems, you have to execute the code in order to find out what the imports and exports are. That is the main reason why ECMAScript 6 breaks with those systems: by building the module system into the language, you can syntactically enforce a static module structure. Let’s first examine what that means and then what benefits it brings. A module’s structure being static means that you can determine imports and exports at compile time (statically) – you only have to look at the source code, you don’t have to execute it. The following are two examples of how CommonJS modules can make that impossible. In the first example, you have to run the code to find out what it imports: In the second example, you have to run the code to find out what it exports: ECMAScript 6 gives you less flexibility, it forces you to be static. As a result, you get several benefits  [2] , which are described next. # If you require a library in CommonJS, you get back an object: Thus, accessing a named export via   means you have to do a property lookup, which is slow, because it is dynamic. In contrast, if you import a library in ES6, you statically know its contents and can optimize accesses: # With a static module structure, you always statically know which variables are visible at any location inside the module: \n Global variables: increasingly, the only completely global variables will come from the language proper. Everything else will come from modules (including functionality from the standard library and the browser). That is, you statically know all global variables. \n Module imports: You statically know those, too. \n Module-local variables: can be determined by statically examining the module. \n This helps tremendously with checking whether a given identifier has been spelled properly. This kind of check is a popular feature of linters such as JSLint and JSHint; in ECMAScript 6, most of it can be performed by JavaScript engines. Additionally, any access of named imports (such as  ) can also be checked statically. # Macros are still on the roadmap for JavaScript’s future. If a JavaScript engine supports macros, you can add new syntax to it via a library.  Sweet.js  is an experimental macro system for JavaScript. The following is an example from the Sweet.js website: a macro for classes. For macros, a JavaScript engine performs a preprocessing step before compilation: If a sequence of tokens in the token stream produced by the parser matches the pattern part of the macro, it is replaced by tokens generated via the body of macro. The preprocessing step only works if you are able to statically find macro definitions. Therefore, if you want to import macros via modules then they must have a static structure. # Static type checking imposes constraints similar to macros: it can only be done if type definitions can be found statically. Again, types can only be imported from modules if they have a static structure. Types are appealing because they enable statically typed fast dialects of JavaScript in which performance-critical code can be written. One such dialect is  Low-Level JavaScript  (LLJS). It currently compiles to  asm.js . # If you want to support compiling languages with macros and static types to JavaScript then JavaScript’s modules should have a static structure, for the reasons mentioned in the previous two sections. Support for both synchronous and asynchronous loading   # ECMAScript 6 modules must work independently of whether the engine loads modules synchronously (e.g. on servers) or asynchronously (e.g. in browsers). Its syntax is well suited for synchronous loading, asynchronous loading is enabled by its static structure: Because you can statically determine all imports, you can load them before evaluating the body of the module (in a manner reminiscent of AMD modules). Support for cyclic dependencies between modules   # Two modules A and B are  cyclically dependent  on each other if both A (possibly indirectly/transitively) imports B and B imports A. If possible, cyclic dependencies should be avoided, they lead to A and B being   – they can only be used and evolved together. # Cyclic dependencies are not inherently evil. Especially for objects, you sometimes even want this kind of dependency. For example, in some trees (such as DOM documents), parents refer to children and children refer back to parents. In libraries, you can usually avoid cyclic dependencies via careful design. In a large system, though, they can happen, especially during refactoring. Then it is very useful if a module system supports them, because then the system doesn’t break while you are refactoring. The Node.js documentation acknowledges the importance of cyclic dependencies  [3]  and Rob Sayre provides additional  evidence : Data point: I once implemented a system like [ECMAScript 6 modules] for Firefox. I got  asked  for cyclic dependency support 3 weeks after shipping. That system that Alex Fritze invented and I worked on is not perfect, and the syntax isn't very pretty. But  it's still getting used  7 years later, so it must have gotten something right. Let’s see how CommonJS and ECMAScript 6 handle cyclic dependencies. # In CommonJS, if a module B requires a module A whose body is currently being evaluated, it gets back A’s exports object in its current state (line #1 in the following example). That enables B to refer to properties of that object inside its exports (line #2). The properties are filled in after B’s evaluation is finished, at which point B’s exports work properly. As a general rule, keep in mind that with cyclic dependencies, you can’t access imports in the body of the module. That is inherent to the phenomenon and doesn’t change with ECMAScript 6 modules. The limitations of the CommonJS approach are: \n \n Node.js-style single-value exports don’t work. In Node.js, you can export single values instead of objects, like this: \n \nIf you did that in module A, you wouldn’t be able to use the exported function in module B, because B’s variable   would still refer to A’s original exports object. \n \n \n You can’t use named exports directly. That is, module B can’t import   like this: \n \n  would simply be  . In other words, you have no choice but to refer to   via the exports object  . \n \n CommonJS has one unique feature: you can export before importing. Such exports are guaranteed to be accessible in the bodies of importing modules. That is, if A did that, they could be accessed in B’s body. However, exporting before importing is rarely useful. # In order to eliminate the aforementioned two limitations, ECMAScript 6 modules export bindings, not values. That is, the connection to variables declared inside the module body remains live. This is demonstrated by the following code. Thus, in the face of cyclic dependencies, it doesn’t matter whether you access a named export directly or via its module: There is an indirection involved in either case and it always works. More on importing and exporting   # Importing   # ECMAScript 6 provides the following ways of importing  [4] : Exporting   # There are two ways in which you can export things that are inside the current module  [5] . On one hand, you can mark declarations with the keyword  . The “operand” of a default export is an expression (including function expressions and class expressions). Examples: On the other hand, you can list everything you want to export at the end of the module (which is once again similar in style to the revealing module pattern). You can also export things under different names: Note that you can’t use  reserved words  (such as   and  ) as variable names, but you can use them as names for exports (you can also use them as property names in ECMAScript 5). If you want to directly import such named exports, you have to rename them to proper variables names. Re-exporting   # Re-exporting means adding another module’s exports to those of the current module. You can either add all of the other module’s exports: Or you can be more selective (optionally while renaming): eval() and modules   #  does not support module syntax. It parses its argument according to the Script grammar rule and scripts don’t support module syntax (why is explained later). If you want to evaluate module code, you can use the module loader API (described next). The ECMAScript 6 module loader API   # In addition to the declarative syntax for working with modules, there is also a  programmatic API . It allows you to: \n Programmatically work with modules and scripts \n Configure module loading \n Loaders handle resolving   (the string IDs at the end of  ), loading modules, etc. Their constructor is  . Each platform keeps a customized instance in the global variable   (the  ), which implements its specific style of module loading. Importing modules and loading scripts   # You can programmatically import a module, via an API based on  ES6 promises :  enables you to: \n Use modules inside   elements (where module syntax is not supported, consult Sect. “ Further information ” for details). \n Load modules conditionally. \n  retrieves a single module, you can use   to import several modules: More loader methods: \n  evaluates the JavaScript code in   to a module (which is delivered asynchronously via a promise). \n  is for registering a module (e.g. one you have created via  ). \n  both evaluates the module code in   and registers the result. \n Configuring module loading   # The module loader API has various hooks for configuration. It is still work in progress. A first system loader for browsers is currently being implemented and tested. The goal is to figure out how to best make module loading configurable. The loader API will permit many customizations of the loading process. For example: Lint modules on import (e.g. via JSLint or JSHint). Automatically translate modules on import (they could contain CoffeeScript or TypeScript code). Use legacy modules (AMD, Node.js). Configurable module loading is an area where Node.js and CommonJS are limited. Further information   # The following content answers two important questions related to ECMAScript 6 modules: How do I use them today? How do I embed them in HTML? \n \n Using ECMAScript 6 today  gives an overview of ECMAScript 6 and explains how to compile it to ECMAScript 5. If you are interested in the latter, start reading in  Sect. 2 . One intriguing minimal solution is the  ES6 Module Transpiler  which only adds ES6 module syntax to ES5 and compiles it to either AMD or CommonJS. \n \n \n  The code inside   elements does not support module syntax, because the element’s synchronous nature is incompatible with the asynchronicity of modules. Instead, you need to use the new   element. The blog post “ ECMAScript 6 modules in future browsers ” explains how   works. It has several significant advantages over   and can be polyfilled in its alternative version  . \n \n \n  “ JavaScript Modules ” (by  Yehuda Katz ) is a quick intro to ECMAScript 6 modules. Especially interesting is a  second page  where CommonJS modules are shown side by side with their ECMAScript 6 versions. \n \n Benefits of ECMAScript 6 modules   # At first glance, having modules built into ECMAScript 6 may seem like a boring feature – after all, we already have several good module systems. But ECMAScript 6 modules have features that you can’t add via a library, such as a very compact syntax and a static module structure (which helps with optimizations, static checking and more). They will also – hopefully – end the fragmentation between the currently dominant standards CommonJS and AMD. Having a single, native standard for modules means: \n No more UMD ( Universal Module Definition ): UMD is a name for patterns that enable the same file to be used by several module systems (e.g. both CommonJS and AMD). Once ES6 is the only module standard, UMD becomes obsolete. \n New browser APIs become modules instead of global variables or properties of  . \n No more objects-as-namespaces: Objects such as   and   serve as namespaces for functions in ECMAScript 5. In the future, such functionality can be provided via modules. \n  Thanks to Domenic Denicola for  confirming  the final module syntax. Thanks for corrections of this blog post go to: Guy Bedford, John K. Paul, Mathias Bynens, Michael Ficarra. References   # A JavaScript glossary: ECMAScript, TC39, etc.   ↩︎ \n “ Static module resolution ” by David Herman  ↩︎ \n “ Modules: Cycles ” in the Node.js API documentation  ↩︎ \n “ Imports ” (ECMAScript 6 specification)  ↩︎ \n “ Exports ” (ECMAScript 6 specification)  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/08/es6-today.html", "title": "Using ECMAScript 6 today", "content": "Using ECMAScript 6 today esnext dev javascript jslang Read my book, instead (free online!): “ Exploring ES6 ” ECMAScript 6 (ES6) still sounds like something from the future. After all, it will only  become a standard  by mid 2015. However, its features are continually appearing in browsers and there are compilers that translate ES6 code to ES5 code. The latter is already a compelling solution, because the ECMAScript 6 feature set is already frozen. This blog post gives a brief overview of ECMAScript 6 features and describes tools that enable you to use them today. Terminology   # \n TC39 (Ecma Technical Committee 39): the committee evolving JavaScript.\n \n Members: companies (all major browser vendors etc.). \n Meetings: attended by employees and invited experts. \n \n \n ECMAScript: the official name of the language\n \n Versions: ECMAScript 5 is short for “ECMAScript Language Specification, Edition 5” \n \n \n JavaScript:\n \n colloquially: the language \n formally: one implementation of ECMAScript \n \n \n ECMAScript Harmony: improvements after ECMAScript 5 (ECMAScript 6 and 7) \n ECMAScript.next: code name for ECMAScript 6 (until version number and feature set was clearer) \n More information: \n A JavaScript glossary: ECMAScript, TC39, etc. \n ECMAScript 6 highlights   # This section gives an overview of most ES6 features. New syntax   # # Property value shorthands  (used for destructuring in later examples): Method definitions : Computed property keys : This new syntax can also be combined with a method definition: The main use case for computed property keys is to make it easy to use symbols as property keys. # Classes : Subclassing built-ins  such as   and  : # Arrow functions : # Modules : # Block-scoped variables via   (writable) and   (read-only): Spread operator : Destructuring : Default parameter values: Rest parameters : Named parameters via destructuring : #  loop  (works for all objects that implement the ES6 iteration protocol): Iterators and generators  (  are a protocol for retrieving the contents of a collection which is supported by the   loop;   are “pausable functions” that help with implementing iterators and more): # Template strings  let you interpolate arbitrary expressions into a string: A template string can span multiple lines: If a template string is prefixed with an identifier (a  ), it becomes a function call: The function referred to by the identifier (the  ) is called with the static pieces between the   and the results of the expressions inside them. A tag handler can decide whether to accept the static pieces verbatim (“raw”) or with escapes such as   interpreted (“cooked”). That lets you implement small domain-specific languages. For example, the tag   is a hypothetical nicer interface to the  XRegExp regular expression library : Two features stand out: \n The content inside the backticks spans multiple lines. \n The backslash at the beginning of the last line ( ) is a regular expression backslash. Inside a string literal, it would have to be written as  . \n #  are a new primitive type in JavaScript. They mainly serve as unique (clash-free) names for properties. For example, an object is marked as iterable via a method whose key is (the symbol stored in)  . This key cannot accidentally clash with any other property key: The iterability of   enables you to use the   loop and similar JavaScript features: # Proxies  enable you to intercept and customize operations performed on objects (such as getting properties). They are a meta programming feature. In the following example, the handler intercepts the operation   (getting properties). When we get the property  , the handler intercepts that operation: New functionality in the standard library   # # ECMAScript 6 has several new utility methods. This section demonstrates a few of them. : : : New string methods: # The keys of a   can be arbitrary values: A   is a collection of unique elements: More collections: \n A   is a map that doesn’t prevent its keys from being garbage-collected. That means that you can associate data with objects without having to worry about memory leaks. \n A   is a set that doesn’t prevent its elements from being garbage-collected. \n # Promises: an API that helps with asynchronous programming. Quoting “ JavaScript Promises: There and back again ” by Jake Archibald: all new DOM APIs with async success/failure methods will use promises. This is happening already with Quota Management, Font Load Events, ServiceWorker, Web MIDI, Streams, and more. The following is an example of using promises: a function   that retrieves a resource via HTTP GET (the current way of doing this is via  ): This asynchronous function could be implemented like this: Promises are explained in two blog posts: \n ECMAScript 6 promises (1/2): foundations \n ECMAScript 6 promises (2/2): the API \n More Material on ECMAScript 6   # \n “ ECMAScript 6: what’s next for JavaScript? ” (by me): 60 minute video ( slides ) \n “ es6features ” (by Luke Hoban): Overview of ECMAScript 6 features \n “ paws-on-es6 ” (by Hemanth.HM): Minimalist examples of ES6 functionalities (code files) \n ” Understanding ECMAScript 6 ” by Nicholas C. Zakas: book, work in progress \n “ You Don't Know JS: ES6 & Beyond ” by Kyle Simpson: book, work in progress \n Deploying ES6   # How to use ES6 today is described in the blog post “ Deploying ECMAScript 6 ”. ECMAScript 7 and later   # Starting with ECMAScript 7, TC39 will time-box releases. The plan is to release a new version of ECMAScript every year, with whatever features are ready at that time. That will result in much smaller releases. Work on ECMAScript 7+ has already begun: \n Proposals are listed  on GitHub . \n A document  describes the process that is used by TC39, starting with ES7, to create new ECMAScript versions. \n Additionally, Microsoft, Facebook and Google are exploring optional static typing for JavaScript. Their approaches are lightweight and similar mechanisms may eventually become part of the language: \n Statically typed JavaScript via Microsoft TypeScript, Facebook Flow and Google AtScript \n FAQ   # How can ECMAScript 5 and ECMAScript 6 exist side by side?   # ECMAScript 6 is completely backwards compatible, it is a superset of ECMAScript 5. Details of how the new ES6 features were added to both strict mode and non-strict mode are explained in the blog post “ One JavaScript: avoiding versioning in ECMAScript 6 ”. Does it still make sense to learn ECMAScript 5?   # As we have seen, you can already exclusively write code in ECMAScript 6 and avoid older versions of JavaScript. Does that mean that you shouldn’t learn ECMAScript 5, anymore? Alas, it doesn’t, for several reasons: \n \n ECMAScript 6 is a superset of ECMAScript 5 – new JavaScript versions must never break existing code. Thus, nothing you learn about ECMAScript 5 is learned in vain. \n \n \n There are several ECMAScript 6 features that kind of replace ECMAScript 5 features, but still use them as their foundation. Two examples: classes are internally translated to constructors and methods are still functions (as they have always been). \n \n \n As long as ECMAScript 6 is compiled to ECMAScript 5, it is useful to understand the output of the compilation process. And you’ll have to compile to ES5 for a while (probably years), until you can rely on ES6 being available in all relevant browsers, in the same manner in that you can usually rely on ES5 now. \n \n \n It’s important to be able to understand legacy code. \n \n Will JavaScript ever be statically typed?   # Maybe. Three experiments with statically typing JavaScript are explained in the blog post “ Statically typed JavaScript via Microsoft TypeScript, Facebook Flow and Google AtScript ”. comments powered by Disqus."},
{"url": "https://2ality.com/2014/09/standard-markdown.html", "title": "Standardizing (a flavor of) Markdown", "content": "Standardizing (a flavor of) Markdown markdown publishing computers  Jeff Atwood renames “Standard Markdown” to “Common Markdown” and apologizes to John Gruber. Details: “ Standard Markdown is now Common Markdown ”. On September 3, Jeff Atwood  announced  a new standardization effort for John Gruber’s  Markdown :  Standard Markdown . It is amazing how ubiquitous Markdown has become and it’s great that there is now a standard for it. Highlights: \n The working group comprises representatives from: GitHub, Reddit, Stack Exchange, the open source community. \n There is a proper specification that also describes a parsing strategy. This should help tremendously with writing a parser that can handle all content that complies with the standard. Given all the incompatible Markdown dialects in existence, that is currently a very difficult task. \n There are  reference implementations  in JavaScript and C and a validation test suite.\n \n You can  try out  the reference implementation online. \n \n \n Background: \n The whole effort more or less started with a  blog post  by Jeff Atwood on 12 Oct 2012. \n John Gruber is not part of the standardization effort. Which is sad, but understandable, given how Atwood approached him. More information:\n \n “ Open Source Obligations ” by Daniel Jalkut. \n “ Atwood: Learn The First Thing About Open Source ” by Giles Bowkett. \n \n \n A few more thoughts: \n The use case “publishing” is currently a bit underrepresented in the working group. Members of the Ghost blogging platform and of Leanpub would be great additions. \n Mid-term to long-term, I’d like a more extensive standard to build on this one: It should comprise the Asciidoc features that are currently missing from Markdown (but maybe in more of a formal syntax instead of something ASCII art-ish). Rationale: better support Markdown for publishing, especially books. \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/09/es6-promises-foundations.html", "title": "ECMAScript 6 promises (1/2): foundations", "content": "ECMAScript 6 promises (1/2): foundations esnext async dev javascript promises jslang  Please read chapter “ Asynchronous programming (background) ” in “Exploring ES6”. This blog post explains foundations of asynchronous programming in JavaScript. It is first in a series of two posts and prepares you for  part two , which covers promises and the ECMAScript 6 promise API. The JavaScript call stack   # When a function   calls a function  ,   needs to know where to return to (inside  ) after it is done. This information is usually managed with a stack, the  . Let’s look at an example. Initially, when the program above is started, the call stack is empty. After the function call   in line (D), the stack has one entry: \n Location in global scope \n After the function call   in line (C), the stack has two entries: \n Location in  \n Location in global scope \n After the function call   in line (B), the stack has three entries: \n Location in  \n Location in  \n Location in global scope \n The stack trace printed in line (A) shows you what the call stack looks like: Next, each of the functions terminates and each time the top entry is removed from the stack. After function   is done, we are back in global scope and the call stack is empty. In line (E) we return and the stack is empty, which means that the program terminates. The browser event loop   # Simplifyingly, each browser tab runs (in) a single process: the  . This loop executes browser-related things (so-called  ) that it is fed via a  . Examples of tasks are: Parsing HTML Executing JavaScript code in script elements Reacting to user input (mouse clicks, key presses, etc.) Processing the result of an asynchronous network request Items 2–4 are tasks that run JavaScript code, via the engine built into the browser. They terminate when the code terminates. Then the next task from the queue can be executed. The following diagram (inspired by a slide by Philip Roberts  [1] ) gives an overview of how all these mechanisms are connected. The event loop is surrounded by other processes running in parallel to it (timers, input handling, etc.). These processes communicate with it by adding tasks to its queue. Timers   # Browsers have  timers .   creates a timer, waits until it fires and then adds a task to the queue. It has the signature: After   milliseconds,   is added to the task queue. It is important to note that   only specifies when the callback is  , not when it actually executed. That may happen much later, especially if the event loop is blocked (as demonstrated later in this post).  with   set to zero is a commonly used work-around to add something to the task queue right away. However, some browsers do not allow   to be below a minimum (4 ms in Firefox); they set it   that minimum if it is. Displaying DOM changes   # For most DOM changes (especially those involving a re-layout), the display isn’t updated right away. “Layout happens off a refresh tick every 16ms” ( @bz_moz ) and must be given a chance to run via the event loop. There are ways to coordinate frequent DOM updates with the browser, to avoid clashing with its layout rhythm. Consult the  documentation  on   for details. Run-to-completion semantics   # JavaScript has so-called run-to-completion semantics: The current task is always finished before the next task is executed. That means that each task has complete control over all current state and doesn’t have to worry about concurrent modification. Let’s look at an example: The function starting in line (A) is added to the task queue immediately, but only executed after the current piece of code is done (in particular line (B)!). That means that this code’s output will always be: Blocking the event loop   # As we have seen, each tab (in some browers, the complete browser) is managed by a single process – both the user interface and all other computations. That means that you can freeze the user interface by performing a long-running computation in that process. The following code demonstrates that. You can try it out  online . Whenever the link at the beginning is clicked, the function   is triggered. It uses the – synchronous –   function to block the event loop for five seconds. During those seconds, the user interface doesn’t work. For example, you can’t click the “Simple button”. Avoiding blocking   # You avoid blocking the event loop in two ways: First, you don’t perform long-running computations in the main process, you move them to a different process. This can be achieved via the  Worker API . Second, you don’t (synchronously) wait for the results of a long-running computation (your own algorithm in a Worker process, a network request, etc.), you carry on with the event loop and let the computation notify you when it is finished. In fact, you usually don’t even have a choice in browsers and have to do things this way. For example, there is no built-in way to sleep synchronously (like the previously implemented  ). Instead,   lets you sleep asynchronously. The next section explains techniques for waiting asynchronously for results. Receiving results asynchronously   # Two common patterns for receiving results asynchronously are: events and callbacks. Asynchronous results via events   # In this pattern for asynchronously receiving results, you create an object for each request and register event handlers with it: one for a successful computation, another one for handling errors. The following code shows how that works with the   API: Note that the last line doesn’t actually perform the request, it adds it to the task queue. Therefore, you could also call that method right after  , before setting up   and  . Things would work the same, due to JavaScript’s run-to-completion semantics. If you are used to multi-threaded programming languages, IndexedDB requests look like they might be prone to race conditions. However, run to completion makes the following code safe in JavaScript:  does not immediately open the database, it adds a task to the queue, which is executed after the current task is finished. That is why you can (and in fact must) register event handlers   calling  . Asynchronous results via callbacks   # If you handle asynchronous results via callbacks, you pass callback functions as trailing parameters to asynchronous function or method calls. The following is an example in Node.js. We read the contents of a text file via an asynchronous call to  : If   is successful, the callback in line (A) receives a result via the parameter  . If it isn’t, the callback gets an error (often an instance of   or a sub-constructor) via its first parameter. The same code in classic functional programming style would look like this: Continuation-passing style   # The programming style of using callbacks (especially in the functional manner shown previously) is also called   (CPS), because the next step (the  ) is explicitly passed as a parameter. This gives an invoked function more control over what happens next and when. The following code illustrates CPS: For each step, the control flow of the program continues inside the callback. This leads to nested functions, which are sometimes referred to as  . However, you can often avoid nesting, because JavaScript’s function declarations are   (their definitions are evaluated at the beginning of their scope). That means that you can call ahead and invoke functions defined later in the program. The following code uses hoisting to flatten the previous example. [2]  contains more information on CPS. Composing code in CPS   # In normal JavaScript style, you compose pieces of code via: Putting them one after another. This is blindingly obvious, but it’s good to remind ourselves that concatenating code in normal style is sequential composition. Array methods such as  ,   and  Loops such as   and  The library  Async.js  provides combinators to let you do similar things in CPS, with Node.js-style callbacks. It is used in the following example to load the contents of three files, whose names are stored in an array. Pros and cons of callbacks   # Using callbacks results in a radically different programming style, CPS. The main advantage of CPS is that its basic mechanisms are easy to understand. However, it has disadvantages: \n \n Error handling becomes more complicated: There are now two ways in which errors are reported – via callbacks and via exceptions. You have to be careful to combine both properly. \n \n \n Less elegant signatures: In synchronous functions, there is a clear separation of concerns between input (parameters) and output (function result). In asynchronous functions that use callbacks, these concerns are mixed: the function result doesn’t matter and some parameters are used for input, others for output. \n \n \n Composition is more complicated: Because the concern “output” shows up in the parameters, it is more complicated to compose code via combinators. \n \n Callbacks in Node.js style have three disadvantages (compared to those in a functional style): \n The   statement for error handling adds verbosity. \n Reusing error handlers is harder. \n Providing a default error handler is also harder. A default error handler is useful if you make a function call and don’t want to write your own handler. It could also be used by a function if a caller doesn’t specify a handler. \n Looking ahead   # The  second part  of this series covers promises and the ECMAScript 6 promise API. Promises are more complicated under the hood than callbacks. In exchange, they bring several significant advantages. Further reading   # Reviewers   # I’d like to thank the following people for reviewing this post. \n Andrea Giammarchi \n Philip Roberts \n “ Help, I'm stuck in an event-loop ” by Philip Roberts (video).  ↩︎ \n Asynchronous programming and continuation-passing style in JavaScript   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/web-design-adaptive-responsive.html", "title": "Responsive web design versus adaptive web design", "content": "Responsive web design versus adaptive web design dev web design webdev Progressive enhancement invented Responsive web design blog post UX Munich website \nResponsive web design has become very popular on the web. Marcotte has followed up his blog post with a  book . A simple web search will also turn up many resources.\n\n Adaptive web design definition comments powered by Disqus."},
{"url": "https://2ality.com/2014/10/typed-javascript.html", "title": "Statically typed JavaScript via Microsoft TypeScript, Facebook Flow and Google AtScript", "content": "Statically typed JavaScript via Microsoft TypeScript, Facebook Flow and Google AtScript atscript esnext dev javascript typedjs facebook flow typescript  Facebook Flow has been released as open source. Its website is  flowtype.org . The site mentions  plans for Flow’s future . This blog post looks at three initiatives for adding static typing to JavaScript: Microsoft’s TypeScript, Facebook’s Flow and Google’s AtScript. Typing   # Let’s first clarify some terminology related to typing (excerpted from “ Speaking JavaScript ”). Static versus dynamic   # In the context of language semantics and type systems,   usually means “at compile time” or “without running a program,” while   means “at runtime.” Static typing versus dynamic typing   # In a statically typed language, variables, parameters, and members of objects (JavaScript calls them properties) have types that the compiler knows at compile time. The compiler can use that information to perform type checks and to optimize the compiled code. Even in statically typed languages, a variable also has a dynamic type, the type of the variable’s value at a given point at runtime. The dynamic type can differ from the static type. For example (Java): The static type of foo is  ; its dynamic type is  . Normal JavaScript is dynamically typed; types of variables are generally not known at compile time. Benefits of static typing   # Does JavaScript really need static typing? Aren’t unit tests enough? Static typing isn’t magic: it does add complexity and visual clutter. This is especially true if you need to manually specify a type for everything (like in most of Java). Thankfully, neither of the three variants of typed JavaScript mentioned in this post force you to do so: if you don’t explicitly type an entity, they try to   its type, by how the entity is used. Three examples: \n If a variable is initialized with a value then the variable’s type is probably the same as the value’s type. \n A number being passed as an argument leads to the initial assumption that the corresponding formal parameter has the type  . \n The multiplication operator being applied to a parameter means that the parameter’s type is probably  . \n Static typing offers the following benefits: \n You get more errors at compile time. Early errors are good. This is usually faster than running unit tests and tends to catch a different category of errors. \n It helps IDEs with auto-completion. Years ago, I used GWT (Java, compiled to JavaScript on the front end). Its statically typed DOM made it easy to explore that API. \n Type annotations are useful for documenting parts of an API. I occasionally mention types in my  JSDoc  comments. If that information helps a static type checker then that is a nice side effect. \n Checking and documenting types helps large teams collaborate, because it gives you an additional way of specifying what you require from or provide for your collaborators. \n One more advantage is political: static typing (complemented by classes and modules) makes JavaScript more palatable for programmers coming from static languages such as Java and C# (i.e., many enterprise programmers). There is a danger of those programmers missing some of the subtleties of JavaScript, because it looks too familiar. However, more people liking a language that is still very recognizably JavaScript is a win, in my opinion. Microsoft TypeScript   # TypeScript  [1]  is a subset of ECMAScript 6  [2]  plus optional static typing. There are several ECMAScript 6 (ES6) features it doesn’t support yet (e.g.  , destructuring, string templates, promises, iterators and   loops) and it still uses an older version of the ES6 module syntax  [3] . Both divergences from ES6 will disappear by version 2.0  [4] , meaning that TypeScript will be a strict superset of ES6 (give or take ES6 features that are difficult to compile to ES5, such as generators and proxies). As mentioned, static typing is optional in TypeScript and supported via: \n \n Type annotations: You can annotate parameters, function results and properties to declare their types. \n \n \n Generics : TypeScript supports generic type variables, generic types, generic classes and generic constraints. \n \n \n Interfaces : enable you to describe the structure of a value. Interfaces match structurally (“duck typing”). Therefore, you can introduce interfaces for “existing” values – externally and without changing how those values are created (no need to “implement” like in Java or C#). \n \n \n Visibility modifiers  for instance properties declared in classes. If a property is marked private, it can only be accessed from “within” a class, external accesses produce compiler errors. \n \n Let’s look at examples.  In the following code, the parameters   and   and the function results are declared to have the type  . Thus, the compiler shows an error for the function call in the last line. TypeScript compiles the function to the following ECMAScript 5 code. That is, all type information is gone at runtime, the end result is normal JavaScript.  In the following code, we demand that objects passed via the parameter   must have the  -valued property  .  In the following code,   and   are private properties of   instances. They can be accessed by the method  , but not from outside. The class   is translated to this ECMAScript 5 code.  files   # TypeScript allows you to provide static type information for existing (untyped) code via external files, which have the file name extension  . The website  DefinitelyTyped  provides such files for many libraries. For example: jQuery, Backbone.js, Esprima, Express, gulp and Jasmine. That means that working with those libraries becomes more convenient if an IDE supports TypeScript. IDEs that do so are: Visual Studio, WebStorm, Eclipse (via  TypEcs ) and others. As an example (one of several in the  TypeScript manual ) let’s assume that this is how the   API is used: The   file for this API would be: Facebook Flow   # Flow  [5]  is a type checker for ECMAScript 6 that is based on flow analysis. As such, it only adds optional type annotations to the language and infers and checks types. It does not help with compiling ECMAScript 6 to ECMAScript 5. Flow is already in use at Facebook and will be open-sourced “later this year”. React lets you use Flow’s annotations by removing them while compiling its JavaScript dialect to plain JavaScript. Quoting the  React Blog : And lastly, on the heels of announcing Flow at @Scale yesterday, we're adding the ability to strip TypeScript-like type annotations as part of the   transform. To use, simply use the   flag on the command line, or set   in the options object when calling the API. The Flow type system has support for extensible objects, open methods, prototypes, tuples, enums, generics, nullable types, union types, intersection types and more. All of these features are motivated by staying true to JavaScript’s nature, by the desire to capture how current JavaScript code is (implicitly) typed. Nullable types help prevent type errors caused by accessing properties if a value is   or  . You explicity specify whether, for example, a given parameter can be   (or  ) or not. In the former case, the compiler forces you to check for   every time you access the parameter. In the latter case, the compiler warns you if you pass   or a nullable value.  Flow’s type annotation syntax being compatible with TypeScript’s makes you wonder why Facebook doesn’t use TypeScript. Avik Chaudhuri mentioned  [5:1]  the following reasons: \n Flow currently scales better than TypeScript. That is, it is faster for large programs. \n Flow can infer more types, which means that it is more useful as a consistency checker for existing (completely unannotated) code bases. \n Flow’s type system is richer. For example, TypeScript does not have non-nullable types. \n Controlling the type checker enables Facebook to support their own technologies (e.g. React and its custom JSX syntax). \n In order to scale, Flow runs as a server in the background and keeps itself up to date. Tools query the server. Flow’s type analysis is incremental, meaning that it can check modules in isolation. It supports many ECMAScript 6 features such as arrows, destructuring, optional parameters, promises, etc. Facebook is committed to track JavaScript standards as they evolve. Google AtScript   # The preferred way to code AngularJS 2.0 will be AtScript  [6] . It is compiled to ECMAScript 5 (for now) and all of the AngularJS 2 features will be accessible from ES5 code. AtScript is ECMAScript 6 plus the following extensions: \n Type annotations for variables, parameters and properties (with TypeScript-compatible syntax). \n Meta-data annotations (which are called “annotations” in Java and “decorators” in Python). \n In contrast to TypeScript and Flow, both data is available at runtime. Runtime type checks   # You can turn type annotations into runtime type checks  [6:1] : The following is AtScript code. The above code is equivalent to this ECMAScript 6 code: The idea is to use runtime type checks during development, because they help catch errors when you are working with untyped code. For deployment, you wouldn’t insert them into the code. Runtime type information   # Meta-data annotations mean that data is attached to annotated entities. For example, the following code uses two annotations,   and  . It is translated to: AngularJS uses the runtime type information for dependency injection and to configure constructs such as directives. For example  [7] : Thus, while TypeScript and Flow throw type data away after compilation, AtScript keeps it around. This is the only way to make it available to runtime mechanisms such as dependency injection. It also enables you to type-check JSON you load at runtime. Compiling to ECMAScript 5 and Dart   # What surprised me is that AtScript (  files) can be compiled to two target languages: \n ECMAScript 5 (  files), via Traceur  [2:1] , which supports AtScript’s language extensions \n Dart (  files) \n Given that AngularJS 2.0 is written completely in AtScript that means that there will be a single code base for both JavaScript and Dart. A common standard?   # The teams of TypeScript, Flow and AtScript seem eager to collaborate. Avik Chaudhuri says so in his talk  [5:2]  and the TypeScript team mentions it on their blog  [4:1] : The TypeScript team is working with both the Flow and AtScript teams to help ensure that resources that have already been created by the JavaScript typing community can be used across these tools. [...]  In the long term, we will also be working to fold the best features of these tools into ECMAScript, the standard behind JavaScript. Furthermore, the following timeline is given  [7:1]  for AtScript’s features (without mentioning specific dates for each step): Runtime type checking: compile AtScript to   and  Static type checking: IDE support Align with TypeScript ECMAScript proposal Browser support ECMAScript standard Obviously, steps 5 and 6 are somewhat beyond the control of the AtScript team and depend on how things develop in the future. Further reading   # “ Welcome to TypeScript ”, the official TypeScript homepage  ↩︎ \n Using ECMAScript 6 today   ↩︎   ↩︎ \n ECMAScript 6 modules: the final syntax   ↩︎ \n “ TypeScript and the Road to 2.0 ” by Jonathan Turner for the TypeScript Blog  ↩︎   ↩︎ \n Video: “ JavaScript Testing and Static Type Systems at Scale ” by Avik Chaudhuri and Jeff Morrison  ↩︎   ↩︎   ↩︎ \n “ AtScript Primer ” by Miško Hevery  ↩︎   ↩︎ \n Slides: “ Keynote: AtScript ” from the ng-europe conference  ↩︎   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/11/mobile-friendly-web-pages.html", "title": "Mobile-friendly web pages", "content": "Mobile-friendly web pages mobile dev google webdev Google has announced that they are marking web pages as “mobile-friendly” in their search results . I was initially worried about this, because many websites have mobile-specific versions that are worse than their desktop versions on mobile devices. I also don’t like being auto-forwarded to mobile locations (e.g. from   to  ), because it prevents URLs from being universal. However, Google’s criteria for mobile-friendliness are reasonable: Pages must… \n Avoid software that is not common on mobile devices, like Flash \n Use text that is readable without zooming \n Size content to the screen so users don't have to scroll horizontally or zoom \n Place links far enough apart so that the correct one can be easily tapped \n Google’s blog post gives tips for ensuring that your page is recognized as mobile-friendly. It seems like a similar approach could be used for checking whether pages are accessible. comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/facebook-graph-search.html", "title": "Graph search: Facebook as a database", "content": "Graph search: Facebook as a database semantic web social computers facebook graph search liveblog The three pillars of Facebook \n     News feed: what's going on with people around me? \n     Timeline: tell me something about this person \n     Graph search: letting people examine any aspect of the data stored in Facebook that they want. \n Graph search \n “Music liked by people who like Obama” \n “Friends of friends who are single men in San Francisco” \n “Languages my friends speak” \n “TV shows liked by doctors” \n “Movies my friends like” \n “Photos of my friends taken in Paris” \n “Bars in Dublin liked by people who live in Dublin” \n “Restaurants in San Francisco liked by Culinary Institute of America graduates” \n “People who have been product managers and who have been founders” \n \nThe user interface works as follows: Simply by giving a special kind of page a title similar to the examples above, you fill it with appropriate content. While typing in your question, you’ll be supported by a graphical user interface (with filters etc.), to get an impression of what is possible.\n \nGraph-based search lets you be quite clever with questions and produces precise answers, but the amount of data that is searched is much more limited than during a Google search. Facebook initially searches people, photos, places and interests. They will later add the content of posts and all relationships in the  Open Graph  standard. First, you’ll only be able to use English to perform queries. Other languages will be supported over time.\nIf Facebook doesn’t find anything in its graph, it calls on Microsoft’s Bing search engine to produce traditional results. For example, if you ask for the weather in California, you get an answer from Bing, not from Facebook.\n \n Wolfram Alpha  is another search engine that in many ways works similarly to Facebook’s graph search. Try it out if you want to see how a search engine works that doesn’t rely on full-text search (such as most of Google).\n\n Challenges \nPrivacy is another challenge. With graph search, you can only search what is already accessible to you. Zuckerberg mentioned that handling privacy currently takes up 10% of the CPU capacity of all of their data centers.\n\n Next steps Conclusion \nFacebook’s graph search is a real-world application of many of the ideas of the Semantic Web. The Semantic Web is, roughly, a graph search where the whole web is the graph (not just what’s stored in Facebook). One of the challenges of the Semantic Web is to get people to contribute data to it. Facebook has that problem mostly covered, as most of its data is already in graph form (as opposed to all the text documents on the open web).\n comments powered by Disqus."},
{"url": "https://2ality.com/2014/10/es6-promises-api.html", "title": "ECMAScript 6 promises (2/2): the API", "content": "ECMAScript 6 promises (2/2): the API esnext async dev javascript promises jslang  Please read chapter “ Promises for asynchronous programming ” in “Exploring ES6”. This blog post is an introduction to asynchronous programming via promises in general and the ECMAScript 6 (ES6) promise API in particular. It is second in a series of two posts –  part one  explains foundations of asynchronous programming (which you may need to learn in order to fully understand this post). Given that the ECMAScript 6 promise API is easy to polyfill for ECMAScript 5, I’m mainly using function expressions and not ECMAScript 6  arrow functions , even though the latter are much less verbose. Promises   # Promises are a pattern that helps with one particular kind of asynchronous programming: functions (or methods) that return their results asynchronously. To implement such a function, you return a  , an object that is a placeholder for the result. The caller of the function registers callbacks with the promise to be notified once the result has been computed. The function sends the result via the promise. The de-facto standard for JavaScript promises is called Promises/A+  [1] . The ECMAScript 6 promise API follows that standard. A first example   # Let’s look at a first example, to give you a taste of what working with promises is like. With Node.js-style callbacks, reading a file asynchronously looks like this: With promises, the same functionality is implemented like this: There are still callbacks, but they are provided via methods that are invoked on the result (  and  ). The error callback in line (B) is convenient in two ways: First, it’s a single style of handling errors. Second, you can handle the errors of both   and the callback from line (A). Creating and using promises   # Let’s look at how promises are operated from the producer and the consumer side. Producing a promise   # As a producer, you create a promise and send a result via it: A promise is always in either one of three (mutually exclusive) states: \n Pending: the result hasn’t been computed, yet \n Fulfilled: the result was computed successfully \n Rejected: a failure occurred during computation \n A promise is   (the computation it represents has finished) if it is either fulfilled or rejected. A promise can only be settled once and then stays settled. Subsequent attempts to settle it have no effect. The parameter of   (starting in line (A)) is called an  : \n If the computation went well, the executor sends the result via  . That usually fulfills the promise (it may not, if you resolve with a promise, as explained later). \n If an error happened, the executor notifies the promise consumer via  . That always rejects the promise. \n Consuming a promise   # As a consumer of  , you are notified of a fulfillment or a rejection via   – callbacks that you register with the method  : What makes promises so useful for asynchronous functions (with one-off results) is that once a promise is settled, it doesn’t change anymore. Furthermore, there are never any race conditions, because it doesn’t matter whether you invoke   before or after a promise is settled: \n In the former case, the appropriate reaction is called as soon as the promise is settled. \n In the latter case, the promise result (fulfillment value or rejection value) is cached and handed to the appropriate reaction “immediately” (queued as a task). \n Only handling fulfillments or rejections   # If you are only interested in fulfillments, you can omit the second parameter of  : If you are only interested in rejections, you can omit the first parameter. The method   is a more compact way of doing the same thing. It is recommended to use   exclusively for fulfillments and   for errors, because it nicely labels callbacks and because you can handle the rejections of multiple promises at the same time (how is explained later). Examples   # Let’s use these basic building blocks in a few examples. Example: promisifying XMLHttpRequest   # The following is a promise-based function that performs an HTTP GET via the event-based  XMLHttpRequest  API: This is how you use  : Example: delaying an activity   # Let’s implement   as the promise-based function   (similar to  ). Note that in line (A), we are calling   with zero parameters, which is the same as calling  . We don’t need the fulfillment value in line (B), either and simply ignore it. Just being notified is enough here. Example: timing out a promise   # Note that the rejection after the timeout (in line (A)) does not cancel the request, but it does prevent the promise being fulfilled with its result. Using   looks like this: Chaining     # The result of a method call is a new promise Q. That means that you can keep the promised-based control flow going by invoking   on Q: \n Q is resolved with what is returned by either   or  . \n Q is rejected if either   or   throw an exception. \n Resolving with normal values   # If you resolve the promise Q returned by   with a normal value, you can pick up that value via a subsequent  : Resolving with thenables   # You can also resolve the promise Q returned by   with a   R. A thenable is any object that has a promise-style method  . Thus, promises are thenable. Resolving with R (e.g. by returning it from  ) means that it is inserted “after” Q: R’s settlement is forwarded to Q’s   and   callbacks. In a way, Q becomes R. The main use for this mechanism is to flatten nested   calls, like in the following example: The flat version looks like this: Error handling   # As mentioned previously, whatever you return in an error handler becomes a fulfillment value (not rejection value!). That allows you to specify default values that are used in case of failure: Catching exceptions   # Exceptions in the executor are passed on to the next error handler. As are exceptions that are thrown in either one of  ’s parameters: Chaining errors   # There can be one or more   method calls that don’t provide an error handler. Then the error is passed on until there is an error handler. Composition   # This section describes how you can compose existing promises to create new ones. We have already encountered one way of composing promises: sequential chaining via  .   and   provide additional ways of composing.  via     # One nice thing about promises is that many synchronous tools still work, because promise-based functions return results. For example, you can use the array method  :  is an array of promises.   takes an array of promises (thenables and other values are converted to promises via  ) and, once all of them are fulfilled, it fulfills with an array of their values: Timing out via     #  takes an array of promises (thenables and other values are converted to promises via  ) and returns a promise P. The first of the input promises that is settled passes its settlement on to the output promise. As an example, let’s use   to implement a timeout: Promises are always async   # A promise library has complete control over whether results are delivered to promise reactions synchronously (right away) or asynchronously (after the current continuation, the current piece of code, is finished). However, the Promises/A+ specification demands that the latter mode of execution be always used. It states so via the following  requirement  (2.2.4) for the   method:  or   must not be called until the execution context stack contains only platform code. That means that you code can rely on run-to-completion semantics (as explained in part 1) and that chaining promises won’t starve other tasks of processing time. Cheat sheet: the ECMAScript 6 promise API   # This section gives an overview of the ECMAScript 6 promise API, as described in the  specification . Glossary   # The promise API is about delivering results asynchronously. A   (short: promise) is a stand-in for the result, which is delivered via that object. States: \n A promise is always in either one of three mutually exclusive states:\n \n Before the result is ready, the promise is  . \n If a result is available, the promise is  . \n If an error happened, the promise is  . \n \n \n A promise is   if “things are done” (if it is either fulfilled or rejected). \n A promise is settled exactly once and then remains unchanged. \n Reacting to state changes: \n \n  are callbacks that you register with the promise method  , to be notified of a fulfillment or a rejection. \n \n \n A   is an object that has a promise-style   method. Whenever the API is only interested in being notified of settlements, it only demands thenables. \n \n Changing states: There are two operations for changing the state of a promise. After you have invoked either one of them once, further invocations have no effect. \n  a promise means that the promise becomes rejected. \n  a promise has different effects, depending on what value you are resolving with:\n \n Resolving with a normal (non-thenable) value fulfills the promise. \n Resolving a promise P with a thenable T means that P can’t be resolved anymore and will now follow T’s state, including its fulfillment or rejection value. The appropriate P reactions will get called once T settles (or are called if T is already settled). \n \n \n Constructor   # The constructor for promises has the following signature: It creates a promise whose behavior is determined by the callback  . It can use its parameters to resolve or reject  : \n  resolves   with  :\n \n If   is thenable, its settlement is forwarded to   (which includes triggering reactions registered via  ). \n Otherwise,   is fulfilled with  . \n \n \n  rejects   with the value   (often an instance of  ). \n Static methods   # All static methods of   support subclassing: they create new instances via their receiver (think:  ) and also access other static methods via it (  versus  ). # The following two methods create new instances of their receiver (their  ). \n \n : \n \n If   is thenable, it is converted to a promise (an instance of the receiver). \n If   is a promise, it is returned unchanged. \n Otherwise, return a new instance of the receiver that is fulfilled with  . \n \n \n \n : creates a new promise that is rejected with the value  . \n \n # Intuitively, the static methods   and   compose iterables of promises to a single promise. That is: \n They take an iterable. The elements of the iterable are converted to promises via  . \n They return a new promise. That promise is a fresh instance of the receiver. \n The methods are: \n \n : returns a promise that… \n \n is fulfilled if all elements in   are fulfilled. \nFulfillment value: array with fulfillment values. \n is rejected if any of the elements are rejected. \nRejection value: first rejection value. \n \n \n \n : the first element of   that is settled is used to settle the returned promise. \n \n Instance prototype methods   # : \n The callbacks   and   are called  . \n  is called immediately if the promise is already fulfilled or as soon as it becomes fulfilled. Similarly,   is informed of rejections. \n  returns a new promise Q (created via the constructor of the receiver):\n \n If either of the reactions returns a value, Q is resolved with it. \n If either of the reactions throws an exception, Q is rejected with it. \n \n \n Omitted reactions:\n \n If   has been omitted, a fulfillment of the receiver is forwarded to the result of  . \n If   has been omitted, a rejection of the receiver is forwarded to the result of  . \n \n \n Default values for omitted reactions could be implemented like this: : \n Same as  . \n Pros and cons of promises   # The pros   # # One important advantage of promises is that they will increasingly be used by asnychronous browser APIs and unify currently diverse and incompatible patterns and conventions. Let’s look at two upcoming promise-based APIs. The fetch API is a promise-based alternative to XMLHttpRequest:  returns a promise for the actual request,   returns a promise for the content as a string. The  ECMAScript 6 API  for programmatically importing modules is based on promises, too: # Compared to events, promises are better for handling one-off results. It doesn’t matter whether you register for a result before or after it has been computed, you will get it. This advantage of promises is fundamental in nature. On the flip side, you can’t use them for handling recurring events. Chaining is another advantage of promises, but one that could be added to event handling. # Compared to callbacks, promises have cleaner function (or method) signatures. With callbacks, parameters are used for input and output: With promises, all parameters are used for input: Additional promise advantages include better error handling (which integrates exceptions) and easier composition (because you can reuse some synchronous tools such as  ). The cons   # Promises work well for for single asynchronous results. They are not suited for: \n Recurring events: If you are interested in those, take a look at  reactive programming , which add a clever way of chaining to normal event handling. \n Streams of data: A  standard  for supporting those is currently in development. \n ECMAScript 6 promises lack two features that are sometimes useful: \n You can’t cancel them. \n You can’t query them for how far along they are (e.g. to display a progress bar in a client-side user interface). \n The Q promise library has  support  for the latter and there are  plans  to add both capabilities to Promises/A+. Promises and generators   # With the help of a utility function such as  , you can use promise-based functions inside shallow coroutines, implemented via generators. This has the important advantage that the code looks synchronous and that you can use synchronous mechanisms such a  : The parameter of   is a generator function  [2] . If the   operator is used, the following things happen: Execution of the function is paused. The operand of   is “returned” by the function. (It’s not exactly a “return”, but ignore that for now.) Later, the function can be resumed with a value or an exception. In the former case, execution continues where it was previously paused and   returns the value. In the latter case, an exception is thrown inside the function, as if it were thrown “inside”  ’s operand. Thus, it’s clear what   has to do: When the generator function yields a promise,   registers reactions and waits for a settlement. If the promise is fulfilled, the generator is resumed with the result. If the promise is rejected, an exception is thrown inside the generator. There is  a proposal  to add support for spawning to JavaScript, via the new syntactic construct “async functions”. The previous example as an async function looks as follows. Under the hood, there is not much of a difference – async functions are based on generators. Debugging promises   # The main challenge with debugging asynchronous code is that it contains asynchronous function and method calls. Asynchronous calls originate in one task and are carried out in a new task. If something goes wrong in the new task, a stack trace will only cover that task and not contain information about previous tasks. Thus, you have to make do with much less debugging information in asynchronous programming. Google Chrome recently got the ability to debug asynchronous code  [3] . It doesn’t completely support promises, yet, but it’s impressive how well it handles normal asynchronous calls. For example, in the following code,   asynchronously calls   which in turn calls  . As you can see in the screen shot, the debugger shows a stack trace that contains all three functions. It even includes the anonymous functions in line (A) and (B). The internals of promises   # In this section, we will approach promises from a different angle: Instead of learning how to use the API, we will look at a simple implementation of it. This different angle helped me greatly with making sense of promises. The promise implementation is called DemoPromise and available  on GitHub . In order to be easier to understand, it doesn’t completely match the API. But it is close enough to still give you much insight into the challenges that actual implementations are facing.  is a constructor with three instance prototype methods: \n \n \n \n That is,   and   are methods (versus functions handed to a callback parameter of the constructor). A stand-alone promise   # Our first implementation is a stand-alone promise with minimal functionality: \n You can create a promise. \n You can resolve or reject a promise and you can only do it once. \n You can register   (callbacks) via  . The method does not support chaining, yet – it does not return anything. It must work independently of whether the promise has already been settled or not. \n This is how this first implementation is used: The following diagram illustrates how our first   works: Let’s examine   first. It has to handle two cases: \n If the promise is still pending, it queues invocations of   and  , to be used when the promise is settled. \n If the promise is already fulfilled or rejected,   or   can be invoked right away. \n  works as follows: If the promise is already settled, it does nothing (ensuring that a promise can only be settled once). Otherwise, the state of the promise changes to   and the result is cached in  . All fulfillment reactions that have been enqueued so far must be triggered now.  is similar to  . Chaining   # The next feature we implement is chaining: \n  returns a promise that is resolved with what either   or   return. \n If   or   are missing, whatever they would have received is passed on to the promise returned by  . \n Obviously, only   changes:  creates and returns a new promise (lines (A) and (F)). Additionally,   and   are set up differently: After a settlement... \n \n The result of   is used to resolve   (line (B). \n \n If   is missing, we use the fulfillment value to resolve   (line (C)). \n \n \n \n The result of   is used to resolve (not reject!)   (line (D)). \n \n If   is missing, we use the rejection value to reject   (line (E)). \n \n \n Flattening   # Flattening is mostly about making chaining more convenient: Normally, returning a value from a reaction passes it on to the next  . If we return a promise, it would be nice if it could be “unwrapped” for us, like in the following example: We returned a promise in line (A) and didn’t have to nest a call to   inside the current method, we could invoke   on the method’s result. Thus: no nested  , everything remains flat. We implement this by letting the   method do the flattening: \n Resolving a promise P with a promise Q means that Q’s settlement is forwarded to P’s reactions. \n P becomes “locked in” on Q: it can’t be resolved (incl. rejected), anymore. And its state and result are always the same as Q’s. \n We can make flattening more generic if we allow Q to be a thenable (instead of only a promise). To implement locking-in, we introduce a new boolean flag  . Once it is true,   is locked and can’t be resolved anymore. Note that   may still be pending, because its state is now the same as the promise it is locked in on. The actual resolution now happens in the private method  : The flattening is performed in line (A): If   is fulfilled, we want   to be fulfilled and if   is rejected, we want   to be rejected. The forwarding happens via the private methods   and  , to get around the protection via  . Promise states in more detail   # With chaining, the states of promises become more complex (as covered by  Sect. 25.4  of the ECMAScript 6 specification): If you are only   promises, you can normally adopt a simplified worldview and ignore locking-in. The most important state-related concept remains “settledness”: a promise is settled if it is either fulfilled or rejected. After a promise is settled, it doesn’t change, anymore (state and fulfillment or rejection value). If you want to   promises then “resolving” matters, too and is now harder to understand: \n Intuitively, “resolved” means “can’t be (directly) resolved anymore”. A promise is resolved if it is either settled or locked in. Quoting the spec: “An unresolved promise is always in the pending state. A resolved promise may be pending, fulfilled or rejected.” \n Resolving does not necessarily lead to settling: you can resolve a promise with another one that is always pending. \n Resolving now includes rejecting (i.e., it is more general): you can reject a promise by resolving it with a rejected promise. \n Exceptions   # As our final feature, we’d like our promises to handle exceptions in user code as rejections. For now, “user code” means the two callback parameters of  . The following excerpt shows how we turn exceptions inside   into rejections – by wrapping a   around its invocation in line (A). Revealing constructor pattern   # If we wanted to turn   into an actual promise implementation, we’d still need to implement the revealing constructor pattern  [4] : ES6 promises are not resolved and rejected via methods, but via functions that are handed to the  , the callback parameter of the constructor. If the executor throws an exception then “its” promise must be rejected. Two useful additional promise methods   # This section describes two useful methods that are easy to add to ES6 promises. Many of the more comprehensive promise libraries have them.    # When you chain several promise method calls, you risk silently discarding errors. For example: If   in line (A) produces a rejection, it will never be handled anywhere. The promise library Q provides a method  , to be used as the last element in a chain of method calls. It either replaces the last   (and has one to two arguments): Or it is inserted after the last   (and has zero arguments): Quoting the  Q documentation : The Golden Rule of   vs.   usage is: either return your promise to someone else, or if the chain ends with you, call   to terminate it. Terminating with   is not sufficient because the catch handler may itself throw an error. This is how you would implement   in ECMAScript 6: While  ’s functionality is clearly useful, it has not been added to ECMAScript 6, because this kind of check can be performed automatically by debuggers in the future (a  thread  on es-discuss provides further background).    # Sometimes you want to perform an action independently of whether an error happened or not. For example, to clean up after you are done with a resource. That’s what the promise method   is for, which works much like the   clause in exception handling. Its callback receives no arguments, but is notified of either a resolution or a rejection. This is how    proposes  to implement  : The callback determines how the settlement of the receiver ( ) is handled: \n If the callback throws an exception or returns a rejected promise then that becomes/contributes the rejection value. \n Otherwise, the settlement of the receiver becomes the settlement of the promise returned by  . In a way, we take   out of the chain of methods. \n  (by  Jake Archibald ): using   to hide a spinner. Simplified version:  (by  Kris Kowal ): using   to tear down a test. ES6-compatible promise libraries   # There are many promise libraries out there. The following ones conform to the ECMAScript 6 API, which means that you can use them now and easily migrate to native ES6 later. \n “ RSVP.js ” by Stefan Penner is a superset of the ES6 promise API.\n \n “ ES6-Promises ” by Jake Archibald extracts just the ES6 API out of RSVP.js. \n \n \n “ Native Promise Only (NPO) ” by Kyle Simpson is “a polyfill for native ES6 promises, as close as possible (no extensions) to the strict spec definitions”. \n “ Lie ” by Calvin Metcalf is “a small, performant, promise library implementing the Promises/A+ spec”. \n  by Kris Kowal implements the ES6 API. \n Lastly, the “ ES6 Shim ” by Paul Millr includes  . \n Interfacing with legacy asynchronous code   # When you are using a promise library, you sometimes need to use non-promise-based asynchronous code. This section explains how to do that for Node.js-style asynchronous functions and jQuery deferreds. Interfacing with Node.js   # The promise library Q has  several tool functions  for converting functions that use Node.js-style   callbacks to ones that return a promise (there are even functions that do the opposite – convert promise-based functions to ones that accept callbacks). For example: denodify  is a micro-library that only provides the “nodification” functionality and complies with the ECMAScript 6 promise API. Interfacing with jQuery   # jQuery has  deferreds  which are similar to promises, but have  several differences  that prevent compatibility. Their method   is almost like that of ES6 promises (main difference: it doesn’t catch errors in reactions). Thus, we can convert a jQuery deferred to an ES6 promise via  : Further reading   # “ Promises/A+ ”, edited by Brian Cavalier and Domenic Denicola (the de-facto standard for JavaScript promises)  ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎ \n “ Debugging Asynchronous JavaScript with Chrome DevTools ” by Pearl Chen  ↩︎ \n “ The Revealing Constructor Pattern ” by Domenic Denicola (this pattern is used by the   constructor)  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/categorizing-values.html", "title": "Categorizing values in JavaScript", "content": "Categorizing values in JavaScript dev javascript advancedjs jslang \n[This post is a copy of my  Adobe Developer Connection article , I’m publishing it here for archival purposes.]\n\n Required knowledge Primitives versus objects \n \nThe following values are primitive:\n \n     \n     \n     Booleans \n     Numbers \n     Strings \n \n\n  All non-primitive values are objects.\nObjects are mutable:\n Internal properties Internal properties Terminology: prototypes versus prototype objects On one hand, there is the prototype-of relationship between objects. Each object has a hidden property [[Prototype]] that either points to its   or is  . The prototype is a continuation of the object.\nIf a property is accessed and it can’t be found in the latter, the search continues in the former. Several objects can have the same prototype.\n     On the other hand, if a type is implemented by a constructor   then that constructor has a property   that holds the type’s  .\n     \n      returns the prototype of  :\n \n     \n      creates an empty object whose prototype is  .\n \n          can do  more , but that is beyond the scope of this post.\n     \n      returns   if   is a prototype of   (or a prototype of a prototype, etc.).\n \n     \n The property “constructor” Categorizing values \n     [[Class]] is an internal property with a string that classifies an object \n      is an operator that categorizes primitives and helps distinguish them from objects \n      is an operator that categorizes objects \n      is a function that determines whether a value is an array \n [[Class]] generic \n      if   is  ,\n     \n      if   is  ,\n     \n      if   is an object  . \n     A primitive is converted to an object and then handled like in the previous rule. \n typeof \n \n  returning   for   is a bug. It can’t be fixed, because that would break existing code. Note that a function is also an object, but   makes a distinction. Arrays, on the other hand, are considered objects by it.\n\n instanceof Array.isArray() Built-in prototype objects Object.prototype \n  [[Class]],   and   agree on most other objects:\n Function.prototype Array.prototype RegExp.prototype Date.prototype ECMAScript 5.1 specification \nTime is measured in ECMAScript in milliseconds since 01 January, 1970 UTC.\n Number.prototype String.prototype Boolean.prototype Recommendations Treating prototype objects as primal members of their types analogs to classes Which categorization mechanisms to use \n \nFor normal code, use   and   and forget about   and  .\nYou have to be aware of  ’s quirks: That   is considered an   and that there are two non-primitive categories:   and  . For example, a function for determining whether a value   is an object would be implemented as follows.\n \n \nIf you expect to receive values from other frames then   is not reliable, any more. You have to consider [[Class]] and  . An alternative is to work with the name of an object’s constructor but that is a brittle solution: not all objects record their constructor, not all constructors have a name and there is the risk of name clashes. The following function shows how to retrieve the name of the constructor of an object.\n What to read next \nAs a next step, you can learn more about JavaScript inheritance. The following four blog posts will get you started:\n \n     Prototypes as classes – an introduction to JavaScript inheritance \n     JavaScript inheritance by example \n     Exemplar patterns in JavaScript \n     Private data for objects in JavaScript \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/tc39-november.html", "title": "ECMAScript.next: TC39’s November 2012 meeting", "content": "ECMAScript.next: TC39’s November 2012 meeting esnext tc39 dev javascript [1] [1] excellent notes a list November 27 \n     TC39 approved the final draft of the Internationalization API (ECMA-402). Since then, on December 12, the Ecma General Assembly unanimously approved ECMA-402, making it  a standard . The API exists separately from ECMAScript and can be used under ECMAScript 5 or later. Plans for version 2.0 are currently being made. High-priority functionality includes case conversion and message formatting that can handle things such as gender and grammatical number. Alex Slexton has experience with message formatting  [2]  and will be consulted.\n     \n     : Sometimes several Unicode code points represent the same character. Normalization ensures that for each such character, the same character is used everywhere. That helps with comparing strings and with searching for text.\n     \n     Generator functions  [3]  will get their own prototype  , a sub-prototype of  . That object is not global, though, it must be imported from a module. The following three expressions all test whether   is a generator function.\n \n     \n November 28 Symbols [4] [5] Modules \nDefining a nested module:\n November 29 Chaining calls to collections \n     Map.prototype.set \n     WeakMap.prototype.set \n     Set.prototype.add \n Iterating over objects [3] \n      converts iterable and Array-like objects to arrays. If the iteration protocol is supported, it uses it. Otherwise, the object is considered Array-like and converted accordingly.\n     \n     for-of loop  [3] : only supports iteration protocol.\n     \n     Spread ( ) operator: only supports iteration protocol. This operator allows one to insert the elements of an array into a function call or an array literal. Examples:\n \n        Among other things, spread can often be used instead of  .\n     \n Collection APIs \n     : returns an iterable of the keys of the collection. \n     : returns an iterable of the values of the collection. \n     : returns an iterable of two-element   arrays. \n let declarations in non-strict code 7.6.1.2 Array comprehensions and generator comprehensions: two new clauses [6] References ECMAScript: ES.next versus ES 6 versus ES Harmony  [also explains what TC39 is] Jed – a JavaScript internationalization toolkit ECMAScript.next: for-of, iterators, generators Private data for objects in JavaScript ECMAScript.next: classes ECMAScript.next: array comprehensions and generator comprehensions comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/learn-javascript.html", "title": "Learning JavaScript via other languages", "content": "Learning JavaScript via other languages dev javascript jslang \n      In my first semester of Informatics, I had the great fortune of being taught Scheme via the classic “ Structure and Interpretation of Computer Programs ” (free online). Due to Scheme, JavaScript has closures  [1] . Furthermore, Racket (a Scheme dialect)  inspired  ECMAScript 6’s approach to privacy, private symbols  [2] .\n     \n      Later, I took a cursory look at prototype-based object-oriented languages. One paper was especially insightful: “ Organizing Programs Without Classes ”. Class-based languages have two relationships: instance-of (between objects and classes) and subclass-of (between classes). Prototype-based languages manage with just one relationship: has-prototype (between objects). How you organize things is still very similar in both kinds of languages, as the very readable paper explains, via the programming language Self (another one of JavaScript’s original influences).\n     \n      Java holds three leassons for JavaScript.\n        First, it helps with most of its syntax – the original mandate for JavaScript was that its syntax had to look like Java’s  [1] .\n        Second, it helps with object-oriented programming, even though it sometimes feels a bit rigid. The book “ Effective Java ” (affiliate link) is a great primer on Java issues, many of which are relevant for other OOP languages.\n        Third, you get an idea of what good IDEs can do. JavaScript still has some catching up to do in this area.\n     \n References JavaScript: how it all began Private data for objects in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/fallgruben.html", "title": "JavaScripts 12 größte Fallgruben", "content": "JavaScripts 12 größte Fallgruben dev javascript deutsch jslang CHIP Web Design 2013 \nJavaScript ist eigentlich eine recht kompakte Sprache. Wenn es nur nicht all diese Fallgruben gäbe...\nDieser Artikel erklärt die 12 größten und wie man am besten mit ihnen umgeht. Zur Lektüre werden grundlegende JavaScript-Kenntnisse vorausgesetzt. Wir halten uns an die aktuelle Version von JavaScript, ECMAScript 5.\n\n \n\n \n \nDie folgenden Abschnitte behandeln je eine Fallgrube.\nAm Ende wird ein Ausblick auf ECMAScript 6 gegeben, das viele der Fallgruben eliminiert.\n\n \n Fallgrube: implizite Umwandlungen von Werten \nDas automatische Umwandeln nach Boolean ist meistens eher praktisch, wir befassen uns aber damit, weil es Wissensgrundlage für spätere Themen ist. Eine echte Fallgrube ist hingegen, wie Werte von String-Werte umgewandelt.\n\n Implizite Umwandlung nach Boolean: „truthy“ und „falsy“ Werte \n     ,   (siehe auch Fallgrube 2) \n     Boolean:  \n     Number:  ,  ,  \n     String:  \n Implizite Umwandlung von Strings Implizite Umwandlung von Objekten Rufe die Methode   auf. Ist das Ergebnis primitiv (kein Objekt), verwende es und wandle es in eine Zahl um. Rufe andernfalls die Methode   auf. Ist das Ergebnis primitiv, verwende es und wandle es in eine Zahl um. Wirf andernfalls einen  . Fallgrube: zwei „Nicht-Werte“   und  \n  wird von der Sprache selbst zugewiesen. Variablen, die noch nicht initialisiert wurden, haben diesen Wert.\n \n  wird wenn, dann von Programmierern verwendet, z.B. um anzugeben, dass ein Wert fehlt.\n\n Check: hat eine Variable einen Wert? Fallgrube: die normale Gleicheit ( ) \nDer normale Gleichheitsoperator ( ) hat viele Macken. Er ist zwar tolerant, aber es gelten nicht die üblichen Regeln für truthy und falsy:\n 2ality.com/2011/06/javascript-equality.html \nBei der strengen Gleichheit ( ) können Werte unterschiedlichen Typs nie gleich sein, weshalb keines der oben genannten Probleme auftritt.\n\n \n Fallgrube: unbekannte Variablennamen erschaffen globale Variablen Fallgrube: Parameterbehandlung \n  Einer Funktion können beim Aufruf beliebig viele Argumente übergeben werden, egal wie viele Parameter in der Funktionsdefinition stehen. Jedem fehlenden Parameter wird der Wert   gegeben. Argumente, die zu viel sind, werden ignoriert.\nLassen Sie uns beispielsweise von folgender Funktion ausgehen:\n \n\n  Alle übergebenen Parameter sind über die Array-ähnliche Variable   zugänglich. Mit folgender Funktion können wir uns ansehen, wie sie funktioniert.\n Wurde ein Parameter übergeben? Standardwerte für Parameter Eine variable Anzahl von Parametern Eine bestimmte Anzahl von Parametern erzwingen arguments ist kein Array Fallgrube: der Geltungsbereich von Variablen Fallgrube: Closures und freie (externe) Variablen Die Fallgrube Fallgrube: Array-ähnliche Objekte \n     haben: indizierten Zugriff auf Elemente und das Property  , das angibt, wie viele Elemente das Objekt enthält.\n     \n     haben nicht: Array-Methoden wie  ,   und  .\n     \n Generische Methoden Fallgrube: Vererbung zwischen Konstruktoren Die zwei Prototypen \n \nAuf der einen Seite gibt es die Prototypbeziehung zwischen Objekten, durch die ein Objekt alle Propertys seines Prototyps erbt. Intern wird diese Beziehung hergestellt, indem ein Objekt über das interne Property [[Prototype]] auf sein Prototyp-Objekt verweist. Extern kann man dieses Property nicht sehen, aber man kann per   ein Objekt herstellen, das einen gegebenen Prototyp hat:\n \n \nAuf der anderen Seite gibt es das Property  , das Konstruktoren haben. Dieses hat als Wert ein Objekt, das zum Prototyp aller Instanzen des Konstruktors wird.\n Alleinstehende Konstruktoren Sub-Konstruktoren Der Sub-Konstruktor muss den Super-Konstruktor aufrufen, damit dieser seine Instanzdaten hinzufügen kann. Das geschieht per  -Methode, da der Super-Konstruktor das aktuelle   verwenden muss und kein eigenes Instanzobjekt erzeugen soll.\n     Der Sub-Prototyp muss vom Super-Prototypen erben, da er auf diesem Weg die Super-Methoden erhält.\n     Durch Schritt 2 haben wir das Objekt weggeworfen, in dem   richtig gesetzt ist. Hier müssen wir nachbessern.\n     Aufrufe von überschriebenen Methoden (Super-Methoden) sind leider kompliziert. Wir greifen direkt auf die Super-Methode   zu und geben ihr per   das aktuelle   mit.\n     Eine Hilfsfunktion für Konstruktor-Vererbung 2ality.com/2012/10/javascript-properties.html Lesen und Schreiben von Propertys Lesen von unbekannten Propertys Zuweisen zu unbekannten Propertys \nDiese Art der Zuweisung schützt also Prototyp-Propertys davor, verändert zu werden. Dennoch wird davon abgeraten, Standardwerte dort abzulegen, denn wenn man in Objekte hineingreift, wirkt der Schutz nicht:\n Fallgrube:   in echten Funktionen Fallgrube: this in echten Funktionen in einer Methode Fallgrube: this in extrahierten Methoden Fallgrube: this und falsch aufgerufene Konstruktoren Fallgrube: die for-in-Schleife Iterieren über Objekte 2ality.com/2012/10/javascript-properties.html \nUm zu sehen, warum das problematisch sein kann, erstellen wir einen Konstruktor   für Objekte wie das oben erwähnte  .\n Iterieren über Arrays Alternativen zu for-in Fazit und Ausblick ECMAScript 5 und ältere Browser \n     Sie können die ECMAScript-5-Funktionalität per Bibliothek nachrüsten. \n         github.com/kriskowal/es5-shim \n     \n     Sie können Underscore.js verwenden. Diese Bibliothek enthält vieles der ECMAScript-5-Funktionalität. Kann ein Browser ECMAScript 5, so reicht Underscore die Aufrufe zur Standardbibliothek durch. \n         underscorejs.org \n     \n ECMAScript 6 Implizite Umwandlungen von Werten Zwei „Nicht-Werte“   und  Die normale Gleicheit ( ) Unbekannte Variablennamen erschaffen globale Variablen Parameterbehandlung Der Geltungsbereich von Variablen Closures und freie (externe) Variablen Array-ähnliche Objekte Vererbung zwischen Konstruktoren Lesen und Schreiben von Propertys  in echten Funktionen Die for-in-Schleife \n     Mächtige Parameterbehandlung (Fallgrube 5 und teilweise 8, da man   nicht mehr benötigen wird).\n     \n     -Deklarationen für Variablen mit Block-Gültigkeitsbereich (Fallgrube 6).\n     \n     Eine vielseitige for-of-Schleife (Fallgrube 12).\n     \n     Wenn man   in einer der drei for-Schleifen (for, for-in, for-of) verwendet, so wird bei jedem Schleifendurchlauf eine neue Bindung der Schleifenvariable angelegt (Fallgrube 7).\n     \n     Klassen, die – trotz ihres Namens – nur eine angenehmere Syntax für Konstruktoren sind (Fallgrube 9).\n     \n     Das Schlüsselwort  , um Super-Methoden aufzurufen (teilweise Fallgrube 9).\n     \n     Arrow Functions, echte Funktionen ohne eigenes   (teilweise Fallgrube 11). \n Danksagungen comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/interview-functionn.html", "title": "Web development: 2012 and forward", "content": "Web development: 2012 and forward dev html5 webdev Functionn an interview Tell us a little bit about yourself. How has 2012 been to you? What have you been working on lately? Now that 2012 is over, what do you think were some of the most exciting developments in the world of web development this year? What web development tool/library/framework/mindset shift has impressed you most in 2012? (You can talk about as many as you wish here). Which single tool/library/framework/mindset shift would you recommend other developers to use/put to work? What most excites, scares and disappoints you about the web today? One word to describe the web as it is today? How do you see the web change in 2013 and beyond? What do you look forward to in 2013? If you had the superpower to change something in the world, what would you change? :-) Looking back on 2012 comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/isinstance.html", "title": "JavaScript: fixing categorization", "content": "JavaScript: fixing categorization dev javascript jslang [1] Problems Three different mechanisms for basic tasks \n     Distinguishing primitives from each other and from objects: use    [1] .\n     \n     Determining which constructor an object is an instance of: use    [1] .\n     \n     Finding out whether a value is an array, even if it comes from another frame: use    [1] .\n     \n Objects that are not instances of   is quirky \n      is  .\n     \n     The type of objects is  , except for functions, whose type is  .\n     \n The future: more value objects more kinds of value objects One possible solution gist Step 1: an extensible protocol Step 2: more types Examples Open issues ECMAScript 6 current draft Reference Categorizing values in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/01/parseint.html", "title": "parseInt() doesn’t always correctly convert to integer", "content": "parseInt() doesn’t always correctly convert to integer numbers dev javascript jsint jslang How parseInt() works The radix ECMAScript specification Examples [1] [2] Alternatives to parseInt() Integers and shift operators in JavaScript \nAnother good option is the following function, an implementation of the ToInteger() operation from the ECMAScript specification:\n Further reading series on numbers Displaying numbers in JavaScript How numbers are encoded in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/xregexp.html", "title": "JavaScript’s regular expressions are more fun with XRegExp", "content": "JavaScript’s regular expressions are more fun with XRegExp dev javascript jslib jslang XRegExp Highlights: insignificant whitespace, inline comments, named groups Highlight: subpatterns ECMAScript 6 and XRegExp template strings even more pleasant to use comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/installable-web-apps.html", "title": "Installing web apps natively", "content": "Installing web apps natively dev javascript clientjs Web apps have been around for a while, but the ability to install them as if they were native apps is relatively new. This blog post takes a look at what’s currently possible. Delivering and publishing installable web apps   # Web apps are called   if they can be installed natively. Such apps are currently delivered in either one of two formats: \n  the app is delivered as a collection of assets (HTML, CSS, JavaScript, etc.), hosted individually on a web server. Two associated files provide important meta-data:\n \n App manifest: specifies information such as: the app’s name; links to icons; the path of the HTML file that is the entry into the app; etc. \n Cache manifest: enumerates the assets of an app, enabling engines to download all of them and run the app offline. \n \n \n  the app is delivered as an archive that contains all of its assets. The archive still contains an app manifest, but doesn’t need a cache manifest. \n In order to   a web app, to put it online, two options are common: \n  (sometimes also called “app marketplace”): You submit your hosted or packaged app to a central authority which makes the app available to the public. This service may be contingent on the app passing a review process. \n  you publish the app yourself, via a server that you have access to. \n Signing packaged apps   # The main reason for the existence of packaged apps is that it is easy to   them via  public-key cryptography : Each app developer gets a public and a private encryption key. Their   is a hash of the package contents, encrypted via the private key. The signature proves who created the package and is validated by decrypting it with the public key and checking that the resulting hash is correct. The hash also ensures that no one has tampered with the archive. The kind of signing that I have just described tracks developers, not apps. As a benefit, developers can sign and publish their apps themselves; there is no need to submit them to an app store. But this approach still enables several security measures: \n If an app does something evil, browsers can blacklist and prevent the execution of all of its developer’s apps. That is, developers can be held accountable for their creations. \n Signed apps are more trusted and get access to some security-critical APIs that unsigned apps are not allowed to use. \n A web app’s data on a server can be encrypted via a developer’s private key, meaning that it doesn’t exist in the clear and is a bit safer from attackers. \n Obviously, for maximum security and less technically savvy users, this approach can still be complemented by a curated app store where each app has been reviewed. The state of the art   # Apache Cordova (on which PhoneGap is based) is the classic solution for turning web apps into native apps. Alas, it requires intermediate steps: building the native app and – often – submitting it to a proprietary app store. On the other hand, you do get comprehensive access to native APIs. The platforms supported by Cordova are: Amazon Fire OS, Android, Firefox OS, iOS, Ubuntu, Windows Phone, Windows, and  others . The following subsections cover additional solutions, which often do not require intermediate steps to go from web app to native installation. Windows, OS X, Linux   # \n \n  can create native apps from running web apps. \n \n Both hosted and packaged apps can be either self-published or submitted to the Firefox Marketplace. It is also possible to run one’s own marketplace. \n More information: “ Quickstart – App Center ” by Mozilla. \n Trying it out: run the quickstart’s  demo app  in Firefox and push its install button to create and install a native app. \n Current limitations: First, there can be at most one app per origin (domain plus port). Fixing this is  in progress . Second, the only way to install an app is by running installation code from it (e.g. after a button has been clicked). In other words, there is no way to declaratively associate a manifest via a   element and let Firefox trigger the installation. Third, on OS X, you must use the context menu to open a native app for the first time (i.e., it is not natively signed and Gatekeeper initially prevents it from running). \n Bonus feature: Firefox for Android can  generate  native Android apps. \n Under consideration: there is an  open ticket  for supporting Safari-style meta-tags. \n \n \n \n  So-called “ Chrome Apps ” can be hosted or packaged, but they can only be installed via the Chrome Web Store. Thus, self-publishing is not possible on Chrome. \n \n Bonus feature: There are  tools  for turning a Chrome App into a native iOS or Android app. \n \n \n \n  allows you to write native apps  in JavaScript , but many of the non-UI APIs are proprietary. \n \n Bonus feature: web apps can  customize  their tiles. \n \n \n \n  lets you write native apps  in HTML5 . \n \n Other operating systems   # \n  Users can add web pages as icons to the Home screen. In the app switcher, they appear as separate apps with custom icons.\n \n More information: “ Safari Web Content Guide: Configuring Web Applications ” \n Limitations: First, configuration is a bit cumbersome and performed via a set of   and   elements. Second, the app has to be open long enough for it to be cached if it is to work offline ( source ). \n \n \n  Starting with Android 4.0, Chrome contributes a powerful “Add to Homescreen” to the platform. It lets you install web apps so that they look and feel like native apps. (The corresponding feature of the stock Android browser is much less powerful and more like bookmarking.)\n \n More information: “ Add to Homescreen - Google Chrome ” \n Bonus: Configuration compatible with Safari on iOS (and just as cumbersome). \n \n \n  You can add web apps to your collection or pin them to your start screen. But they appear as Internet Explorer during app switching and offline operation doesn’t always seem to work reliably.\n \n Limitation: Configuration similarly cumbersome to Safari on iOS (but incompatible with it). \n \n \n  Firefox-style web apps   the native apps. \n  Chrome apps   the native apps. Again: apps can only be installed if they are in the Chrome Web Store. \n A standard manifest format for web apps   # Currently, the manifest files used by Mozilla and Google are different. However, both companies recently agreed on a  common standard . The following are two examples from the specification.  a typical manifest.  linking to the manifest. The future of packaged apps   # Apart from signing apps, packages could serve two more use cases: \n They speed up downloading, because you need less HTTP round-trips to download the contents (as opposed to downloading files individually). A package format could replace current improvised techniques. Longer-term, SPDY and HTTP/2 will solve this problem, too. \n They would also be useful for bundling content. HTML content usually comprises multiple files, which impairs portability. For example, to email such content, people often ZIP it and send it. Then the recipient has to unpack the ZIP file in order to access the content. \n Alas, packaged apps as supported by Mozilla and Google currently have two problems: \n There is no standard format for them. \n You can’t access their content without unpacking them. Ideally, web browsers would handle them as if they were unpacked directories. \n To fix these problems, Mozilla’s Jonas Sicking recently proposed four measures: Standardizing a package format that supports streaming and per-file meta-data. Introducing a Content Security Policy mechanism similar to “self”, but meaning “in the same package” instead of “from the same origin”. Enabling URL syntax for referring to files inside a package. This could look as follows:   (  would separate the path   the package from the path   the package). Standardizing the signing of packages. Source of this section: “ Future of packaged apps ” by Jonas Sicking. \n TJ VanToll \n Jonathan Sampson \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/logitech-presenter-r700-mac.html", "title": "Using the Logitech Presenter R700 with a Mac", "content": "Using the Logitech Presenter R700 with a Mac hardware presenting computers mac Recently, I was shopping for a   (a remote control for PowerPoint, Keynote, etc.) and liked the  Logitech Presenter R700  (a newer European-only version of the R800) best, due to its design and its integrated display with a countdown. Alas, Macs are not officially supported for this device. Thankfully, they can be made to work together, as explained in this blog post. I also mention how my configuration file can be adapted to an R800. Installation   # If you press keys on the R700, wireless signals are sent to the R700’s USB stick, which appears to OS X as a USB keyoard. The key presses that OS X receives work for PowerPoint, but not for other apps. Thankfully, a tool called  KeyRemap4MacBook  lets you remap the keys per app and only for the R700 – without affecting other devices (including the actual keyboard). Based on Andrew Ferrier’s  work , I wrote a configuration file that makes the R700 work with Keynote, DVD Player and VLC. Installation: \n Install  KeyRemap4MacBook \n Copy the file   from my  GitHub repo  to this location: \n \n In KeyRemap4MacBook’s preferences, click the button ReloadXML and check the new “R700” items. \n Done. \n If you want   to work with an R800, you need to change the product ID. You can look up the correct one via the EventViewer, which is launched from KeyRemap4MacBook’s menu. The key mappings   # The R700’s default key mappings: \n Left: page up \n Right: page down \n Play: alternates between F5 and Esc \n Blank screen: . (dot) \n Keynote’s key mappings: \n Left: page up (unchanged) \n Right: page down (unchanged) \n Play: ⌥⌘P (always) \n Blank screen: B \n DVD Player’s key mappings: \n Left: ⌘↓ (turn volume  ) \n Right: ⌘↑ (turn volume  ) \n Play: FSpace (always) \n Blank screen: ⌘F (equivalent to ^⌘F) \n VLC’s key mappings: same as DVD Player. comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/jsx-template-strings.html", "title": "React JSX via ECMAScript 6 template strings", "content": "React JSX via ECMAScript 6 template strings esnext dev template literals javascript Facebook’s React has an optional language extension that enables you to embed HTML inside JavaScript. This extension can make your code more concise, but it also breaks compatibility with the rest of the JavaScript ecosystem. ECMAScript 6 will have    [1] , which enable you to implement JSX (or something close to it) inside the language. Jonathan Raphaelson has done so and the result looks as follows. More information: \n You can check out the full example and the implementation of the      on GitHub .\n [1:1]  explains what a template handler is and how you can write one yourself. \n Template strings: embedded DSLs in ECMAScript 6   ↩︎   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/unconnected-computing.html", "title": "Ideas for fixing unconnected computing", "content": "Ideas for fixing unconnected computing mobile computers I traveled quite a bit recently and got exposed to a negative aspect of current technology: Things work well if you have a solid internet connection with no traffic limits and are plugged into a power outlet. Otherwise, things do not work well at all. This blog post describes the problems that arise and suggests solutions. Managing data traffic   # Cell phones are quite good at conserving traffic, laptops much less so. This becomes a problem when your laptop has a mobile connection (e.g., via tethering or in a hotel with data caps). I once accidentally started iTunes in such a situation and immediately used up my daily allowance of traffic. Similarly, mobile email is frugal with traffic (only the current folder is updated, attachments are only downloaded on demand, etc.), desktop email is usually not. How can this be handled better? I’d like to see three traffic modes for all operating systems: “full”, “restricted”, “minimal”: \n In  , all data transfers are allowed and happen immediately and automatically. \n In  , you are asked to confirm data transfers beyond a given limit (e.g. a few hundred KB). Apps also try to consume less data (e.g. they don’t periodically access servers, anymore; only when the user asks for it). \n In  , as little as possible would be downloaded. For example, web browsers would never download high-resolution images or custom fonts. These are reductions that hurt, but still give you bare minimum services. \n The currently active mode can be chosen automatically, in most cases (but manual override must be possible). Location seems an interesting criterion: \n At home, I have broadband and can use full traffic mode. \n Abroad, I’m roaming and every byte counts. I need minimal traffic mode. \n At a hotel, I have daily data caps and restricted traffic mode is appropriate. \n Note that being connected via Wi-Fi does not necessarily mean that traffic is unlimited. Which mode to use could also be configured per network (cellular per carrier, Wi-Fi per WLAN). Lastly, the same file is often downloaded multiple times. For example, the same image by several web browsers and by a Twitter client. Several apps could share a cache and traffic could be saved. Syncing while offline   # Automatically syncing one’s data via the internet has made operating multiple devices much easier. A few examples: \n With the IMAP procotol, one’s emails stay on the server and you have the same data on every device. \n With Dropbox and similar technologies, folders with files are synced across devices. \n Most browsers sync bookmarks, these days. \n Syncing photos makes cell phones even more convenient as cameras. \n Alas, syncing doesn’t work if one is not connected. It would be nice if we could have peer syncing: create a WLAN and let the devices sync with each other, instead of with a server on the internet. Even in a broadband setting, it would help if one could peer-sync large downloads such as apps, OS upgrades, etc. Handling intermittent connectivity   # It is interesting to see how much apps and protocols are designed around continuous connectivity: Usually a task is aborted if there is a time-out. If connectivity is intermittent, one has to start from scratch every time one is connected. Therefore, the task will never finish if one cannot transmit all of the data in a single session, even if it could be done in multiple sessions. Additionally, you often have to re-try manually. Again, some kind of queue seems useful: tasks requiring connectivity would be added to it and worked on incrementally, whenever there is a connection. Additionally, I’d love to have a way to tell my device that I’m about to go offline for a longer time. It could then immediately download emails, web pages in reading lists, contacts, events, files, etc., without waiting for an app to start or a periodic timer to go off. Managing power consumption   # Operating systems (Windows 8, OS X, Android) are becoming increasingly adept at saving battery power: network requests are batched, apps put to sleep in the background, etc. On desktop operating systems, I feel that I should get a warning if an app uses an exceptional amount of processing time. This is bad if you are running on battery power. But even if you are plugged in, you want such a warning, because processing-intensive apps can run for a long time without being noticed, while consuming considerable amounts of power. When it comes to tethering, I like a feature that Apple has added to the upcoming OS X Yosemite: In your laptop’s Wi-Fi menu, you can see your tethered iPhone’s battery life and signal strength. Thus, there is no need to take one’s phone out of one’s pocket to check those stats. A few tips for mobile computing   # These are a few random things that I find useful when I’m mobile: \n Dropbox: My battery lasts longer if Dropbox doesn’t run. I then start it periodically, whenever I want to sync. \n git  is excellent for working offline, because you can sync selectively and get unlimited undo. \n If I need complete control over mobile traffic, I only use my phone and don’t tether. That means that I won’t have the surprise downloads that can happen on desktop operating systems. \n BitTorrent Sync  looks like a way to sync data between peers, but I haven’t tested it, yet. I’m curious to know whether it works even if you are completely offline. \n Conclusion   # Whenever I am mulling over the problem of unconnected computing, I keep coming back to the aforementioned task queue – an operating system service similar to a printer queue, to which apps post tasks that depend on being connected to the internet. Such a queue would have several advantages: \n Optimized operation under intermittent connectivity: The queue helps with finishing tasks in small steps, whenever there is connectivity and however long it lasts. \n Asynchronous workflow: You can always start a task, independently of whether you are currently online or not. If you are offline, finishing the task is simply delayed until you are online again. \n Activities that are currently hidden inside apps become visible and can be controlled. You can reorder and cancel them and you can request to be notified when one of them is finished. \n Controlling traffic via the previously mentioned modes would work well together with the queue: If a task is too expensive for the current mode, you can pause it temporarily, until conditions become more favorable.  The website of the “ Offline First! ” project (by the team behind  Hoodie ) describes many interesting ideas for improving the offline operation of apps (especially of web-based apps, but also of native apps). comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/simple-http-server.html", "title": "SimpleHTTPServer: a quick way to serve a directory", "content": "SimpleHTTPServer: a quick way to serve a directory dev webdev Python’s SimpleHTTPServer is the classic quick solution for serving the files in a directory via HTTP (often, you’ll access them locally, via  ). This is useful, because there are some things that don’t work with   URLs in web browsers. Using SimpleHTTPServer   # SimpleHTTPServer is invoked like this (the parameter   is optional): (On OS X, Python is pre-installed and this command works out of the box.) Let’s look at an example of using SimpleHTTPServer: During the following Unix shell interaction, I first list the files in the current directory and then start SimpleHTTPServer to serve it. Afterwards, I can access the following URLs: \n  lists the files in the current directory (namely, just  ). If there were a file  , it would be displayed, instead. \n  displays the file   in the current directory. \n Customizing SimpleHTTPServer   # The following Unix shell script demonstrates how to customize SimpleHTTPServer so that it serves files that have a given file name extension with a given media type. One case where that matters is Firefox being picky about the media type of the  . comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/googleio-polymer.html", "title": "Three Google I/O videos about Web Components and Polymer", "content": "Three Google I/O videos about Web Components and Polymer dev javascript webcomponents polymer googleio clientjs video The  videos  of the Google I/O 2014 talks have been online for a while now. Three of them are about Web Components and Polymer. This blog post briefly describes what they are about and mentions a few highlights, which may help you to decide which videos you want to watch. The three talks are: “ Polymer and the Web Components revolution ” by Matt McNulty (38:47) “ Polymer and Web Components change everything you know about Web development ” by Eric Bidelman (36:13) “ Unlock the next era of UI development with Polymer ” by Rob Dodson (41:30) If you need a quick primer to Web Components, you can look at slide 35ff of the slides for my talk “ Six technologies that will change the web platform ”. Polymer and the Web Components revolution   # Matt McNulty gives a broad overview of Web Components and Polymer, setting the stage for the remaining two talks. McNulty explains why Web Components are important, then describes  , which is a Web Components polyfill plus a convenience layer on top. The nice thing about Polymer’s new “ Paper Elements ” (UI components following Google’s new   design language) is that they are custom elements. That means that they can be used with any HTML framework. They will work even better in the next versions of AngularJS and Ember.js, which explicitly support Web Components. I found it interesting to hear that Polymer co-evolves with the Chrome platform: if Polymer encounters problems (e.g. jank), they are fixed in Chrome. Similar to Mozilla’s  X-Tag , Polymer’s Web Component polyfill enables us to field-test web platform APIs before they are standardized. Polymer and Web Components change everything you know about Web development   # Eric Bidelman’s talk is mainly about the current state of Web Components. Polymer is mentioned occasionally, though. Highlights: \n Web Components state of the union:\n \n Chrome supports all Web Component APIs natively, Firefox isn’t far behind. \n Webkit: All Shadow DOM code was recently removed, but: “ Web Components development will continue in a branch in near future ” \n Internet Explorer: Web Component APIs are “ under consideration ”. Eric mentions that they are asking hard questions, meaning that they are taking Web Components seriously. \n Web Components in use:  experimental implementation  of  WinJS  components on top of Polymer, GitHub displays timestamps via a   custom element, the Chrome OS keyboard and media player are Web Components. \n \n \n Problems solved by custom elements:\n \n Cleaner DOM (markup encapsulated in custom elements) \n Common widgets across frameworks \n Better support for widgets in the platform and in dev tools \n And more \n \n \n Example that profits from HTML imports: Twitter Bootstrap. Two   elements for CSS and four   elements for JavaScript versus a single HTML import (of an HTML file packaging these elements). \n Unlock the next era of UI development with Polymer   # Rob Dodson goes deeply into the new Paper UI components and shows off some interesting UI-related functionality provided by Polymer. A few notes: \n Goal: support multiple devices and app-like user interface. That’s not what HTML was originally built for. \n Overview of Polymer’s Paper elements: Layout, Material, Theming, Transitions. \n The   CSS pseudo-element and   CSS combinator enable you to reach inside shadow DOMs and style custom elements. \n In Polymer, the   element can be used to share style information between elements, which helps with theming. \n Polymer gives you declarative support for Flexbox, via HTML attributes. I really like like the design of the Paper elements. You can see that a lot of thought has gone into making them work with both touch and pointer devices. comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/stages-of-js.html", "title": "The five stages of coming to terms with JavaScript", "content": "The five stages of coming to terms with JavaScript dev javascript humor The  five stages  of coming to terms with JavaScript are: Denial: “I won’t need this language.” Anger: “Why does the web have to be so popular?” Bargaining: “OK, at least let me compile a reasonable language to JavaScript.” Depression: “Programming is not for me, I’ll pursue a career in masonry, like I always wanted.” Acceptance: “I can’t fight it, I may as well prepare for it.” comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/javascript-survival-guide.html", "title": "A JavaScript survival guide", "content": "A JavaScript survival guide dev javascript Are you a programmer who is considering learning JavaScript, but unsure whether it is worth the pain? Then this blog post is for you: I argue that it   worth it and give tips for surviving the language. Why learn JavaScript?   # The present   # The main reason for choosing JavaScript is the breadth of its ecosystem: the web platform, Node.js, JSON, NoSQL databases, Cordova/PhoneGap, automating PhotoShop and many other apps, etc. Compared to Java, I like the interactivity of JavaScript and the web platform. It is easy to quickly try out things and to inspect what is currently going on. I also like the flexibility of the language. It means that where you have deep inheritance hierarchies and other relatively complex patterns in more static languages, you can often get by with more lightweight solutions in JavaScript. The future   # ECMAScript 6  [1] , the upcoming version of JavaScript fixes many of JavaScript’s problems: not enough data structures, limited built-in support for inheritance, no built-in support for modules, shadowing  , functions playing too many roles, … (As an aside: many of JavaScript’s deficiencies can be fixed via libraries and tools, but built-in classes and modules will make JavaScript code more portable and – hopefully – reduce the fragmentation of the community.) Additionally, there is much innovation and experimentation around: \n Language: near-native performance via asm.js  [2] , easy parallelization via ParallelJS  [3] , macros via  Sweet.js , … \n Web platform: Web Components  [2:1] , … \n Take your time to get to know JavaScript   # An important insight for learning JavaScript (paraphrasing Golo Roden): JavaScript may look familiar, but it really isn’t. Take your time to get to know it. The learning curve for JavaScript is due to: Power: it’s a very flexible and powerful language. Quirkiness: it’s also a spartan and quirky language. People who hate JavaScript tend to think that JavaScript is all #2 and no #1, but if you learn it properly, you’ll appreciate #1 and get relatively simple rules and techniques for working around #2. JavaScript’s power   # JavaScript is an interesting mix of object-oriented programming (OOP) and functional programming (FP). JavaScript creator Brendan Eich’s favorite parts of JavaScript are: \n First-class functions (FP) \n Closures (FP) \n Prototypes (prototypal OOP) \n Object literals (prototypal OOP) \n Array literals (FP) \n JavaScript is one of the few languages that allow you to directly create objects, which is nice for prototyping and incremental development. Testament to the power of aforementioned parts is how many missing features were added using them: \n A better   loop (the array method  ) \n Inheritance libraries (classes, mixins, etc.) \n Module systems \n JSON , a JavaScript-native data storage format could also be mentioned in this list. How to survive JavaScript?   # If JavaScript has become inevitable for you and you still find its shortcomings hard to accept, what can you do to minimize the pain? This section gives a few tips. Learn as much as you can   # These are a few things that helped me with learning the language: \n “ JSbooks ” is a list of free online books on JavaScript. \n Stick to the good parts: pick a safe subset of JavaScript and use it exclusively. That doesn’t mean you can afford to completely ignore the rest of the language, but you don’t have to burden your brain with all of its details. \n Read JavaScript style guides: You probably won’t agree with everything they say, but they will give you ideas what to look out for. Three good style guides (among many):\n \n Idiomatic.js: Principles of Writing Consistent, Idiomatic JavaScript \n Google JavaScript Style Guide \n Airbnb JavaScript Style Guide \n \n \n Get in contact with the community: the diversity of the web means that the JavaScript community is also diverse, which makes them inspiring and instructive to hang out with. There are many opportunities to do so:\n \n Twitter: is a great way to stay up to date on web development topics and to find out what the community is talking about. \n User groups: many of the larger cities have JavaScript user groups.  CommunityJS.org  is directory of them. \n Conferences: JavaScript has arrived in the enterprise, which means there are now more JavaScript conferences than ever, for all tastes and wallet sizes. Lanyrd has  a list . \n \n \n More safety   # There are several ways in which you can make the language safer: \n Strict mode : you’ll get more errors and a slightly cleaner language. \n Linters (style checkers): analyze JavaScript source code and detect problems and anti-patterns. As a consequence, they offset some of the disadvantages of the language’s dynamic nature and teach good style. Three well-know linters are:\n \n JSLint : the classic, the first JavaScript linter, by Douglas Crockford \n JSHint : currently the most popular linter \n ESLint : key strength – easily extensible \n \n \n Testing: is an important weapon for making dynamic languages safer to work with. You’ll usually write more tests than in a static language. On the other hand, it’s relatively pleasant to write tests in JavaScript. \n Libraries and frameworks: shield you from some of the quirks of the language and browsers.\n \n Examples: Underscore.js, jQuery, AngularJS, Ember.js, … \n \n \n More comfort   # JavaScript is a relatively spartan language. Thus, it’s good that IDEs (such as Microsoft’s Visual Studio and JetBrain’s WebStorm) are constantly improving and make dealing with it simpler. Additionally, even though ECMAScript 6, the next version of JavaScript, hasn’t even been formally standardized, yet, you can already use it, by compiling it to ECMAScript 5  [4] . That means that you get to work with a much more full-featured language. Further reading: “Speaking JavaScript”   # Especially initially, I wrote the book “Speaking JavaScript” ( free online ) for myself, to document my exploration of the JavaScript ecosystem. I also wanted to create the book that I wish I had had when I started learning the language: providing comprehensive understanding, while assuming that you already know how to program. The following chapters are useful for getting started: \n “ Why JavaScript? ” (sales pitch) \n “ Basic JavaScript ” (quick start in less than 30 pages) \n “ A Meta Code Style Guide ” (complements the existing JavaScript style guides) \n “ What to Do Next ” (JavaScript learning resources) \n References   #  This blog post is based on a discussion I had with my colleague Béla Varga. ECMAScript 6: what’s next for JavaScript?   ↩︎ \n asm.js: closing the gap between JavaScript and native   ↩︎   ↩︎ \n ParallelJS: data parallelism for JavaScript   ↩︎ \n “ ECMAScript 6 tools ” by Addy Osmani.  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/angularjs-vs-polymer.html", "title": "The roles of AngularJS and Polymer", "content": "The roles of AngularJS and Polymer dev javascript webcomponents angularjs polymer clientjs A key feature of AngularJS 2.0 is its support for Web Components  [1] . Google’s Polymer is a Web Component polyfill (enabling them on all current browsers) and a framework on top of Web Components. This blog post describes how the Angular team sees the roles of AngularJS and Polymer. The roles, according to the AngularJS team   # AngularJS 2.0 team member Rob Eisenberg recently  explained  the relationship between AngularJS and Polymer: \n “Angular is really designed around optimizing   development (including DI, routing, templating and decorator directives, more advanced databinding)” \n “while Polymer is really optimized around   development. So, it has basic templating and binding and a strong component model.” \n Therefore, Eisenberg expects people to implement cross-framework UI components either as pure Web Components or via Polymer. He thinks apps and app-specific components are more likely to be built in Angular. Are Polymer and AngularJS competing? Yes and no   # At Google I/O 2014, Google presented  , custom elements following the new Material Design. These elements are Web Components, implemented via Polymer. They are very useful for Angular, especially version 2.0 and don’t compete with it. That is, Polymer as a Web Component polyfill and platform for widgets benefits Angular. However, Polymer as a framework does compete with it in some ways. It’ll be interesting to see how that plays out in the future. Further reading   # Plans for supporting Web Components in AngularJS and Ember.js   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/07/method-calls.html", "title": "Dispatched and direct method calls in ECMAScript 5 and 6", "content": "Dispatched and direct method calls in ECMAScript 5 and 6 esnext dev javascript jslang There are two ways to call methods in JavaScript: \n via dispatch, e.g.  \n directly, e.g.  \n This blog post explains how these two work and why you will rarely call methods directly in ECMAScript 6. Dispatched method calls versus direct method calls   # Background: prototype chains   # Remember that each object in JavaScript is actually a chain of one or more objects ( [1]  is a quick refresher of JavaScript OOP). The first object inherits properties from the later objects. For example, the prototype chain of an array   looks as follows: The instance, holding the elements   and  , the properties provided by the   constructor , the properties provided by the   constructor  (the end of the chain, so not really a member of it) You can examine the chain via  : Properties in “earlier” objects override properties in “later” objects. For example,   provides an array-specific version of the   method, overriding  . Dispatched method calls   # If you look at the method call   you can see that it actually performs two steps Dispatch: In the prototype chain of  , retrieve the value of the first property whose name is  . Call: Call the value and set the implicit parameter   to the     of the method invocation. You can make the two steps explicit by using the   method of functions: Direct method calls   # There are two ways to make direct method calls in JavaScript: \n \n \n Both method   and method   are invoked on functions. They are different from normal function calls in that you specify a value for  .   provides the arguments of the method call via individual parameters,   provides them via an array. One problem of invoking a method via dynamic dispatch is that the method needs to be in the prototype chain of an object.   enables you to call a method directly while specifying the receiver. That means that you can borrow a method from an object that is not in the current prototype chain. For example, you can borrow   and thus apply the original, un-overridden implementation of   to  : Methods that work with a variety of objects (not just with instances of “their” constructor) are called  .   has  a list  of all methods that are generic. The list includes most array methods and all methods of   (which have to work with all objects and are thus implicitly generic). Use cases for direct method calls   # Provide parameters to a method via an array   # Some functions accept multiple values, but only one value per parameter. What if you want to pass the values via an array? For example,   lets you destructively append several values to an array: But you can’t destructively append a whole array. You can work around that limitation by using  : Similarly,   and   only work for single values: With  , you can use them for arrays: Convert an array-like object to an array   # Some objects in JavaScript are  , they are almost arrays, but don’t have any of the array methods. Let’s look at two examples. First, the special variable   of functions is array-like. It has a   and indexed access to elements. But   isn’t an instance of   and does not have the method  . Second, the DOM method   returns an instance of  . Thus, for many complex operations, you need to convert array-like objects to arrays first. That is achieved via  . This method copies the elements of its receiver into a new array: If you call   directly, you can convert a   to an array: And you can convert   to an array: Use   safely   #  tells you whether   has the   (non-inherited) property  . However, calling   via dispatch can cease to work properly if   is overridden.  may also be unavailable via dispatch if   is not in the prototype chain of an object. In both cases, the solution is to make a direct call to  : Avoiding intermediate objects   # Applying an array method such as   to a string normally involves two steps: Strings are array-like and can become the   value of generic array methods. Therefore, a direct call lets you avoid step 1: Similarly, you can apply   to a string either after you split it or via a direct method call: Note that the direct calls may be more efficient, but they are also much less elegant. Be sure that they are really worth it! Abbreviations for   and     # You can access the methods of   via an empty object literal (whose prototype is  ). For example, the following two direct method calls are equivalent: The same trick works for  : This pattern has become quite popular. It does not reflect the intention of the author as clearly as the longer version, but it’s much less verbose.  Speed-wise , there isn’t much of a difference between the two versions. Alternatives to direct method calls in ECMAScript 6   # Thanks to new features in ECMAScript 6, you’ll rarely need direct method calls. The spread operator ( ) mostly replaces     # Making a direct method call via   only because you want to turn an array into arguments is clumsy, which is why ECMAScript 6 has the spread operator ( ) for this. It provides this functionality even in dipatched method calls. Another example: As a bonus, spread also works with the   operator: Note that   can’t be used with   – the above feat can only be achieved via a complicated work-around  [2]  in ECMAScript 5. Array-like objects are less burdensome in ECMAScript 6   # On one hand, ECMAScript 6 has  , a simpler way of converting array-like objects to arrays: On the other hand, you won’t need the array-like  , because ECMAScript 6 has   (declared via a triple dot):    #  is mostly used to implement maps via objects. Thankfully, ECMAScript 6 has a built-in   data structure, which means that you’ll need   less. Avoiding intermediate objects   #  can convert and map in a single step, if you provide it with a callback as the second argument. As a reminder, the two step solution is: Further reading   # Understanding the four layers of JavaScript OOP   ↩︎ \n “ apply() for Constructors ” (Speaking JavaScript)  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/foreach-es6.html", "title": "ECMAScript 6’s parameter destructuring and forEach()", "content": "ECMAScript 6’s parameter destructuring and forEach() esnext dev javascript Destructuring [1] Destructuring and forEach() [2] [3] References Keyword parameters in JavaScript and ECMAScript.next ECMAScript.next: arrow functions and method definitions ECMAScript.next: for-of, iterators, generators comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/web-platform.html", "title": "Will the term “web platform” replace “HTML5”?", "content": "Will the term “web platform” replace “HTML5”? dev html5 webdev [1] Why “web platform” is a good choice \nAccordingly, when the web community got together to better document web development, the name “web platform” was chosen for what was to be documented. Thanks to  that effort , the web platform also has a logo:\n\n The increasing importance of the web platform \n     Desktop operating systems: Chrome OS  [2] , Windows 8  [3] ,  Ubuntu \n     \n     Mobile operating systems:  Firefox OS ,  Tizen ,  Ubuntu Phone \n     \n packaged apps Chrome app launcher Desktop WebRT Related blog posts Branding web technologies and the new HTML5 logo A few thoughts on Chromebooks and Chrome OS A Windows 8 keynote review by a JavaScript programmer and Apple user comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/try-finally.html", "title": "JavaScript: try-finally", "content": "JavaScript: try-finally dev javascript jslang \nQuestion: what is the output the following code?\n \n     The   clause is always executed, no matter what happens inside the   clause (return, exception, break, normal exit). \n     However, it is executed   the return statement. \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/edge-2013-videos.html", "title": "The Edge 2013 videos are online", "content": "The Edge 2013 videos are online dev webdev video Edge 2013 the website \n    Each themed session is an hour long, and starts with a maximum 10 minute talk by an expert in that topic, outlining the current state of the platform in that area. [...] The remainder of the session will be given over to an open but structured discussion, with a professional moderator and a panel of seasoned developers who have in-depth knowledge of the subject. [...]\n     \n    Session participants will include [...] a notetaker to record the discussion so we can share it on the web later.\n \n        Keywords:\n         App Cache ,\n         Web Storage ,\n         Quota API ,\n         Filesystem API \n     \n        Keywords:\n         Net-info API ,\n         Websockets ,\n         Navigation timing ,\n         Closure compiler ,\n         UglifyJS ,\n        Build tools\n     \n        Keywords:\n         Web workers ,\n         Performance timeline ,\n         Memory management ,\n         TreeWalker ,\n         NodeIterator ,\n         insertAdjacentHTML ,\n         createContextualFragment ,\n         MutationObservers ,\n        H/W acceleration,\n        DOM avoidance,\n        Caching patterns,\n        Perception\n     \n        Keywords:\n         Seamless IFRAMEs ,\n         CSS regions ,\n         CSS3 fonts ,\n         CSS3 transforms ,\n         CSS filters ,\n         FT columnflow ,\n         Web components ,\n         Flexbox ,\n         Media queries \n     \n        Keywords:\n         FT Fastclick ,\n         pointer.js ,\n         Pointer events ,\n         Speech input API ,\n         Console browsers ,\n         Leap motion ,\n         Kinect hacks \n     \n        Keywords:\n         Chrome packaged apps ,\n         Phonegap ,\n         W3C Widgets ,\n         Device API access control \n     \n        Keywords:\n         Chrome DevTools ,\n         Adobe Edge ,\n         Jenkins ,\n         Selenium ,\n         Eggplant ,\n         Webdriver \n     comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/asm-js.html", "title": "asm.js: closing the gap between JavaScript and native", "content": "asm.js: closing the gap between JavaScript and native jsfuture dev javascript \n     New feature  32 bit floats  pushes asm.js  performance  to 70% of native. \n     More JavaScript engines  support asm.js . \n     The  conclusion  mentions LLJS as another asm.js source language. \n specification Things that slow down JavaScript \n      Floating point numbers (including integers stored as floating point numbers) are  , they have wrappers that allow them to co-exist with other values such as objects.\n     \n      Most JavaScript engines compile code in two stages. Initially, a format is used that can be compiled to quickly, but that runs slowly (e.g. interpreted bytecode). The execution of that format is observed. If it runs more often, assumptions can be made about the types of its parameters etc. and it can be compiled to a format that runs faster. If one of the assumptions turns out to be wrong, the faster format can’t be used any more and the engine has to go back to the slower format. The faster format is always slowed down by checking whether the assumptions still hold.\n     \n      which can be slow.\n     \n      JavaScript’s data structures are very flexible, but they also make memory management slower.\n     \n David Herman How asm.js works \n     Ahead of time (AOT) compilation: a complete fast executable can be produced when the code is loaded (compare: JITs only produce a slow version at load time).\n     \n     Linking: The asm.js module function is invoked and linked to its external dependencies   and   (see below).\n     \n \n     : a standard library object, providing access to (a subset of) the standard library.\n     \n     : a foreign function interface (FFI) providing access to arbitrary external JavaScript functions.\n     \n     : a heap buffer, an instance of   that acts as the asm.js heap.\n     \n \n \nLet’s look at a concrete example:\n Standard library \n     Global double values:  ,  \n     \n     Double functions (arity 1):  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  \n     \n     Double functions (arity 2):  ,  \n     \n     Integer or double function (arity 1):  \n     \n     Integer function (arity 2, proposed for ECMAScript 6):   (integer multiplication)\n     \n     Double values:  ,  ,  ,  ,  ,  ,  ,  \n     \n Static typing Supported types \n     64 bit double-precision floating point numbers. Type annotation:  \n     \n     32 bit integers (ignoring several types that are needed so that all asm.js-supported JavaScript operations can be typed correctly). Type annotation:  \n     \n     32 bit floats. Type annotation:  \n     \n [1] \n \nReference types are only allowed for variable declarations at the top level of a module. All other variables and parameters must have value types. The following reference types are available:\n \n      types:  ,  ,  ,  ,  ,  ,  ,  . These types are used for accessing the asm.js heap.\n     \n     Functions \n     Function tables: an array of functions that all have the same type \n     References to foreign functions \n \n  Two ECMAScript 6 features were added specifically to better support asm.js and similar approaches.\n \n       \n        performs fast multiplication of 32 bit integers.\n     \n       \n        rounds the 64 bit double   to a 32 bit float.\n     \n Checking for asm.js conformance \n\n \nWhen you invoke an asm.js module, the following dynamic checks are performed. If one of them fails, the AOT-compiled code can’t be linked and the engine must fall back to normal JavaScript.\n \n     No exception must be thrown until the   statement is reached. \n     The   object (if provided) must be an instance of  . Its   must be a multiple of 8. \n     All view objects must be true instances of their respective typed array types. \n     All properties of the   object must implement the semantics as specified by the ECMAScript standard. In practice, that means that they must have the same values as the properties of the global object that have the same names.\n     \n Advantages of asm.js \n     Relatively easy to implement on top of existing JavaScript engines.  Quoting  David Herman:\n         \n     \n     Interacts well with JavaScript. It is a subset of JavaScript, after all.\n     \n     Backward compatible with all existing JavaScript engines: if an engine isn’t aware of asm.js then the code simply runs as normal JavaScript.\n     \n Emscripten and the performance Emscripten \nEmscripten already produces surprisingly fast code. In fact, its way of code generation has been the inspiration for asm.js and its creator Alon Zakai is part of the asm.js team. A modified version of Emscripten now targets asm.js, which results in considerable performance increases on engines with the necessary support.\n \nInitially, C code compiled to asm.js ran at 50% of native speed.\nSupport for 32 bit floats pushed performance to approximately  70% of native .\n\n\n The future \n     Modules: ECMAScript 6 will have modules, then asm.js code can be packaged more conveniently.\n     \n     Type guards: Versions after ECMAScript 6  [2]  might have type guards, obviating the need for the current, slightly hacky, type annotations.\n     \n     Better parallel programming: better support for data parallelism could come via either ParallelJS  [3]  or SIMD  [4] .\n     \n     More value objects are also planned for ECMAScript, with 64 bit integers having priority. Once JavaScript has them, they are also available to asm.js.\n     \n asm.js FAQ Support in JavaScript engines \n     Firefox: optimized for asm.js since version 22 \n     Chrome and Opera : are optimizing for asm.js without requiring the directive  \n Conclusion: the best of both worlds \n      use asm.js for computationally intensive tasks and as a target language for compilers. The latter is the dominant asm.js use case. That is, it is not meant to be written by hand, but to be generated via tools such as  Emscripten  (source languages: C, C++) and  LLJS  (source language: static dialect of JavaScript).\n     \n      use all of JavaScript for maximum flexibility.\n     \n \n \nJavaScript source code becomes a format for delivering programs that abstracts over the different compilation strategies of JavaScript engines  [5]  and over the difference between asm.js and JavaScript. Delivering source code is not an approach that opposes a particular compilation strategy (bytecode etc.), you simply postpone deciding on one, giving engines the freedom to make their own choice. Additionally, this approach allows you to compile asm.js code in the browser: simply assemble a text string with the code and use   or (better)   to compile it.\n \nJavaScript engines are optimized for higher-level code in a manner that can’t be replicated by less specialized engines. Thus, there will always be a schism between low-level and high-level engines; asm.js manages to make that schism as small as possible.\n\n More material \n     Website  asmjs.org :\n         \n             Specification \n             FAQ \n         \n     \n     Talk: “ Big Web App? Compile It! ” by Alon Zakai [video and slides]\n     \n References Integers and shift operators in JavaScript A first look at what might be in ECMAScript 7 and 8 ParallelJS: data parallelism for JavaScript JavaScript gains support for SIMD JavaScript myth: JavaScript needs a standard bytecode comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/link-friendly-content.html", "title": "Link-friendly content", "content": "Link-friendly content blogging publishing computers JavaScript Weekly Cosmetic tips \n      Make sure your spelling is OK. Alas, the “.js” suffix is used in many variations. When in doubt, look up the name you are referring to. Names that are very often spelled wrong:\n         \n             JavaScript (not Javascript) \n             Ajax (not AJAX): it’s not a real acronym, see the  post  where the term was invented \n             Node.js or Node (not NodeJS): this one is more tricky, as there are many variations. Starting with a capital N and ending with “.js” seems the most common way to spell it.\n             \n         \n     \n      Don’t use URL shorteners. They don’t let you see where they are pointing, undoing the self-descriptiveness of good URLs (see below); they stop working if the shortening server is down; and they are both easier to break (e.g. by losing one character) and much harder to fix.\n         \n        On Twitter, not using a shortener means using Twitter’s built-in   service for which the original URL is stored with each tweet. Observe which tweets use t.co (you can see the original URL in the tweet) and which don’t – the former group is more informative. Alas, Twitter doesn’t give you access to the statistics collected by its   server. They really should.\n     \n      Not a big deal, but you can pay attention to the following typographical details. \n         \n             Curly quotes: “hello” (not: \"hello\") \n             Curly apostrophes: it’s (not: it's) \n             Proper dashes : nice – I like it (not: nice - I like it): Double hyphens (--) are often used as a work-around, but with widespread Unicode support, there is no need to do so these days.\n             \n         \n     \n Tips for blog posts \n      I’ve come across pages where it was virtually impossible to find out who had written them. Demo pages are especially notorious. Thus: Let us know who the author is, how they can be contacted and what the current page is about.\n     \n      Creating nice URLs is an art form. If you succeed, people will look at your URL and immediately have a rough idea what it points to. \n        Useful elements:\n         \n             Year of publication and month of publication. This automatically dates your content and gives important context.\n             \n             Stable file name. You will often change your mind with regard to the title of a post. The file name should be something that you are absolutely sure about, as it can’t be changed later on.\n             \n         \n        An example:   \n     \n      There should be a clearly visible date of publication. This is necessary, but has the disadvantage of making content seem dated that is still current  [1] .\n     \n      You should be obsessing over this one. This is what people tweet, it has to both describe what the page is about and make people curious (hopefully, those are not mutually exclusive goals).\n     \n      The beginning of a post is what people read after the headline has reeled them in. They have to decide whether the content is really for them. Thus, give a brief summary, let people know what to expect. You can also mention what is unique about a post, what makes it stand apart from the crowd. Good abstracts are used as link descriptions by many link blogs and email newsletters.\n     \n      Excerpt and link to the complete code elsewhere (e.g. on GitHub). If you feel that people have to see all of the code then break it up into smaller pieces.\n     \n      Have a clear starting destination that includes a table of contents. Make sure that that starting destination is easy to reach from each part of the series. It is what people will often link to.\n     \n      This tip is probably controversial, because it is subjective: Google+ is very convenient for blogging and much good content is published on it. However, I dislike it for four reasons:\n        First, Google+ URLs are less pretty than typical blog URLs. Compare:\n \n        Second, Google+ pages are more heavyweight than blog pages, they put a strain on your browser. Third, blogs usually look better than Google+. Fourth, blog content is easier to navigate (archived by year and month, etc.). The last three points are unavoidable: Blogs can be optimized for blog content in a manner that Google+ can’t.\n     \n Tips for GitHub projects \n      Fill it out, it is the closest thing to a title that a project has.\n     \n      Is there more project-related content elsewhere? In addition to the description, you can also specify a website for a project.\n        Decide: Do you really need a separate website? What is its relationship with the GitHub project page? Note that you can also host web pages on GitHub  [2] .\n     \n      You can choose between several formats: plain text, HTML, Markdown, AsciiDoc. Such a  readme is essentially a blog post introducing your project, thus all of the above tips for blogging apply. For a readme, the title is especially important, because, visually, it becomes the title of the project page. Additionally, the project’s “spec sheet” should be mentioned early: what are the requirements, what technologies is it based on, etc.     \n     \n The dilemma of curating news References The problem with blogs GitHub: serve files to the web, with a single branch comments powered by Disqus."},
{"url": "https://2ality.com/2013/02/javascript-influences.html", "title": "Perl and Python influences in JavaScript", "content": "Perl and Python influences in JavaScript esnext dev javascript jslang code base blog post Perl influences in ECMAScript 5 \n     \n     \n     \n     \n \n     \n     \n     \n     \n     \n     \n     \n     \n Python influences in ECMAScript 5 \n     \n     \n     \n \n     \n     \n ECMAScript 6 \n     Arrow functions  [1]  and classes  [2]  were inspired by CoffeeScript. \n     Generators  [3]  were inspired by Python. \n References ECMAScript 6: arrow functions and method definitions ECMAScript 6: classes Iterators and generators in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/subclassing-builtins-es6.html", "title": "Subclassing builtins in ECMAScript 6", "content": "Subclassing builtins in ECMAScript 6 esnext dev javascript Classes in ECMAScript 6 (final semantics) \nIn JavaScript, it is difficult to create sub-constructors of built-in constructors such as  . This blog post explains the problem and possible solutions – including one that will probably be chosen by ECMAScript 6. The post is based on Allen Wirfs-Brock’s  slides  from a presentation he held on January 29, during a TC39 meeting.\n\n \n\n The problem [1] Trying to subclass Array [[Construct]] method Allocation: create an instance  , an object whose prototype is   (if that value is not an object, use  ).\n     Initialization: Initialize   via  . If the result of that call is an object, return it. Otherwise, return  .\n     Allocation obstacle: MyArray allocates the wrong kind of object Initialization obstacle: MyArray can’t use Array for initialization Solutions Solution: __proto__ [2] \nThis is the only solution that works in current browsers (that support  ).\n\n Non-solution: constructors make objects exotic ECMAScript 6 solution: decouple allocation and initialization \n  In a subclass of  , we’d like to reuse method   of  . In ECMAScript 5, we can’t, because the prototype of a constructor is always   and never its super-constructor. That is, it doesn’t inherit   from its super-constructor. However, in ECMAScript 6, constructor inheritance is the default.\n \nAdditionally, Wirfs-Brock proposes to handle allocation in a separate, publicly accessible method whose key is the well-known symbol   (that can be imported from some module).   would only override that method and default   would look like this for all constructors:\n [3] \n  Sub-constructors need to be able to use   for initialization. Thus, it needs to distinguish two different kinds of invocation:\n \n     Used as a function: create a new instance.\n     \n     Used for initialization (via   or via a super-call): set up  .\n     \n \nThis solution will probably be adopted by ECMAScript 6. Its complexity will be largely hidden: You can either use the canonical way of subclassing shown above or you can use a class definition  [4] :\n When   does not initialize Factory constructors \n  You need to distinguish whether you are called directly via   or via a sub-constructor. It is conceivable to add language support for this. An alternative is to have a parameter   whose default value is  . Sub-constructor set it to  . If it is  , you initialize. Otherwise, you return the result of a sub-constructor.\n\n Cached instances Returning an argument A few observations The constructor as a method JavaScript becomes less prototypal A method for post-initialization? freeze non-extensible How about ECMAScript 5? [5] Acknowledgement References What’s up with the “constructor” property in JavaScript? JavaScript: __proto__ Categorizing values in JavaScript ECMAScript 6: classes Subclassing builtins in ECMAScript 5 comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/tc39-january.html", "title": "ECMAScript 6: TC39’s January 2013 meeting", "content": "ECMAScript 6: TC39’s January 2013 meeting esnext tc39 dev javascript [1] notes blog posts \n(Note: a blog post on the  March TC39 meeting  will be posted at some time in the future.)\n\n \n\n January 29 \n      strict equality ( ) is safer than sloppy equality ( ). But it still has the quirk of   not being equal to itself  [2] . The original plan for ECMAScript 6 was to introduce an   operator that fixes this quirk, but those plans have been abandoned. Instead, you can use   if you need “stricter” equality  [2] .   also distinguishes positive and negative zero  [3]  (which isn’t always desirable).\n     \n      Chrome 24 shipped with an (unprefixed) implementation of the first edition of ECMA-402. Thanks to the API, the methods  ,   get meaningful implementations (until now, they didn’t do anything locale-specific on most JavaScript engines). Work to specify the second edition of ECMA-402 continues.\n     \n January 30 Static methods static methods An   that doesn’t return an array [4] Destructuring is refutable by default proposal Property   of functions property  TypedArray becomes part of ECMAScript January 31 Refining the semantics of classes Map/Set comparator [6] [2] [3] Simplified syntax for array comprehensions and generator comprehensions [7] gist References ECMAScript: ES.next versus ES 6 versus ES Harmony Stricter equality in JavaScript JavaScript’s two zeros ECMAScript.next: Array.from() and Array.of() ECMAScript 6’s parameter destructuring and forEach() Equality in JavaScript: === versus == ECMAScript.next: array comprehensions and generator comprehensions comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/permutations.html", "title": "Encoding permutations as integers via the Lehmer code (JavaScript)", "content": "Encoding permutations as integers via the Lehmer code (JavaScript) dev javascript jslang Permutations Computing a permutation: a naive solution \n     Compute a random number  , 0 ≤   < 3.   is the first element of the permutation. Remove element   from  .\n     \n     Compute a random number  , 0 ≤   < 2.   is the second element of the permutation. Remove element   from  .\n     \n     The remaining element of   is the last element of the permutation.\n     \n Encoding permutations as integers The naive algorithm in two steps Compute the indices for the (continually shrinking) array  .\n     Turn the indices into a permutation.\n     Lehmer code Mapping integers to Lehmer codes positional system \n decimal system \nFor example, if each digit is in the range 0–9 then we can use the fixed radix 10 and the decimal system. That is, each digit has the same radix. “Radix” is just another way of saying “upper bound of a digit”. The following table reminds us of the decimal system.\n \n \nThe value of a position is the value of the digit multiplied by the multiplier. The value of a complete decimal number is the sum of the values of the positions.\n \nNote that each multiplier is one plus the sum of all previous highest digits multiplied by their multipliers. For example:\n \n factoradic system \nEncoding the digits of a Lehmer code into an integer is more complex, because each digit has a different radix. We want the mapping to be bijective (a one-to-one mapping without “holes”). The factoradic system is what we need, as explained via the following table. The digit ranges reflect the rules of the Lehmer code.\n \n \nThe last digit is always zero and often omitted.\nAgain, a multiplier is one plus the highest value that you can achive via previous positions. For example:\n \n  uses the following function to compute the factorial of a number:\n Putting everything together Practically useful? \n     Computing a random permutation: the  Fisher–Yates shuffle \n     Enumerating all permutations: the  Steinhaus–Johnson–Trotter algorithm \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/es6-array-methods.html", "title": "ECMAScript 6’s new array methods", "content": "ECMAScript 6’s new array methods esnext dev javascript Exploring ES6  Updated version of this blog post: chapter “ New Array features ”. This blog post explains what new array methods ECMAScript 6 will bring and how to use them in current browsers. Note: I’m using the terms   and    interchangeably. Class methods   #  has gained methods of its own. Array.from(arrayLike, mapFunc?, thisArg?)   # ’s basic functionality is to convert two kinds of objects to arrays: \n Array-like objects , which have a property   and indexed elements. Examples include the results of DOM operations such as  . \n Iterable objects , whose contents can be retrieved one element at a time. Arrays are iterable, as are ECMAScript’s new data structures   and  . \n The following code is an example of converting an array-like object to an array: The result of   is not an array and does not have a   method, which is why we need to convert it to an array before we can use that method. #  is also a convenient alternative to using    generically : The second parameter of both methods is an  arrow function . In this example, the result of   is again an array-like object, not an array, which is why we couldn’t invoke   on it. Previously, we converted the array-like object to an array in order to call  . Here, we skipped that intermediate step via a generic method call and via the two-parameter version of  . #  ignores holes  [1]  in arrays, it treats them as if they were   elements: That means that you can use   to create and fill an array: If you want to fill an array with a fixed value (first one of the previous two examples) then   (see below) is a better choice. # Another use case for   is to convert an array-like or iterable object to an instance of a subclass of  . For example, if you create a subclass   of   (subclassing arrays is explained in  [2] ) and want to convert such an object to an instance of  , you simply use  . The reason that that works is because constructors inherit from each other in ECMAScript 6 (a super-constructor is the prototype of its sub-constructors). You can also combine this functionality with mapping, to get a map operation where you control the result’s constructor: Array.of(...items)   # If you want to turn several values into an array, you should always use an array literal, especially since the array constructor doesn’t work properly if there is a single value that is a number ( more information  on this quirk): But how are you supposed to turn values into an instance of a sub-constructor of   then? This is where   helps (remember that sub-constructors of   inherit all of  ’s methods, including  ).  is also handy as a function that doesn’t have  ’s quirk related to wrapping values in arrays. However, be careful about an   pecularity that can trip you up here: As you can see above,   passes three parameters to its callback, the last two are simply often ignored ( details ). Prototype methods   # Several new methods are available for array instances. Iterating over arrays   # The following methods help with iterating over arrays: \n \n \n \n The result of each of the aforementioned methods is a sequence of values, but they are not returned as an array; they are revealed one by one, via an iterator. Let’s look at an example (I’m using   to put the iterators’ contents into arrays): You can combine   with ECMAScript 6’s   loop  [3]  and destructuring to conveniently iterate over (index, element) pairs: Note: this code already works in the current Firefox. Searching for array elements   # \nreturns the first array element for which the callback   returns  . If there is no such element, it returns  . Example: \nreturns the index of the first element for which the callback   returns  . If there is no such element, it returns  . Example: Both   methods ignore holes  [1:1] . The full signature of the callback   is: # A well-known  limitation  of   is that it can’t find  , because it searches for elements via  : With  , you can use    [4]  and will have no such problem: You can also adopt a more general approach, by creating a helper function  : Array.prototype.fill(value, start?, end?)   # Fills an array with the given  : Holes  [1:2]  get no special treatment: Optionally, you can restrict where the filling starts and ends: When can I use the new array methods?   # \n Some of them are already available in browsers. As usual, check kangax’s  ECMAScript 6 compatibility table . \n Paul Miller’s  es6-shim  library has backported them to ECMAScript 5. \n References   # “ Holes in Arrays ” (Speaking JavaScript)  ↩︎   ↩︎   ↩︎ \n Subclassing builtins in ECMAScript 6   ↩︎ \n Iterators and generators in ECMAScript 6   ↩︎ \n Stricter equality in JavaScript   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/wrong-syntax-highlighting.html", "title": "We’re doing syntax highlighting wrong", "content": "We’re doing syntax highlighting wrong clip programming dev James Fisher  mentions  two things that are often syntax-highlit wrong: \n \n  “The comment is washed out. While the rest of the text exists in black, boldface, and bright colors, the comments fade into the background. […] The implication is obvious: we have collectively decided that the comment is less important than the code.” \n \n \n  “[…] a red line is one that was deleted, and a green line is one that was added. […] Our diff viewer, then, tells us that deletions are bad, dangerous, and possibly an error, while insertions are good, safe, and successful.” \n \n Consult the  blog post  for the rationales and several instructive illustrations. comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/oop-layers.html", "title": "Understanding the four layers of JavaScript OOP", "content": "Understanding the four layers of JavaScript OOP dev javascript jslang video JavaScript OOP is baffling: on one hand, there is a simple core, on the other hand, there are some really weird things going on. I’ve been pondering for a long time how to explain it well and I think the best way to do so is via four layers: single objects, prototype chains, constructors, constructor inheritance. The first two layers are JavaScript’s simple OOP core, layers 3 and 4 are where the complications start. I’ve explained the four OOP layers in an O’Reilly webcast: \n Video on YouTube  (starts later to avoid duplicated content at the beginning) \n Slides \n Full webcast  (requires Flash, but the audience’s comments in the chat are interesting) \n Additional material: \n “ In defense of JavaScript’s constructors ” explains my – conservative – recommendation of constructors \n “ JavaScript’s ‘this’: how it works, where it can trip you up ” \n Chapter “ Objects and Inheritance ” in the online version of “Speaking JavaScript” \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/webcomponents-org.html", "title": "Meet the site of the Web Components community", "content": "Meet the site of the Web Components community dev html5 javascript clientjs \nThe Web Components community has a new site:  WebComponents.org . Quoting  Addy Osmani :\n \nThe site had previously been soft-launched at  webcomponents.github.io  and is now online at the final URL. It’s good to have a single site with a simple URL where one can look up information related to this  important  technology. The site’s twitter account is  @Web_Components .\n \n \nWebComponents.org features icons for the Web Components sub-standards (Shadow DOM etc.), which can be downloaded in various formats at a  repository  on GitHub.\n \nPreviously, the best location with Web Components resources was a  page  by Eric Bidelman. I’m hoping that this page will be merged into WebComponents.org.\n comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/electrolysis-resumed.html", "title": "Firefox Electrolysis (one process per tab) is back", "content": "Firefox Electrolysis (one process per tab) is back browser dev firefox Electrolysis (e10s)  [1]  is a project to add a one-process-per-tab architecture (similar to Google Chrome’s) to Firefox. It was put on hold  [2]  in early 2012 and is now being resumed. Quoting  a post  on the mozilla.dev.platform Google Group: e10s is a priority for Mozilla’s engineering management and they are dedicating more help to make it happen. We’ve picked up some Firefox Metro engineers looking for new homes, new engineering manager, a Google Summer of Code student, and a gfx contractor. So expect to see more progress and more review requests. You can check out recent improvements in Firefox Nightly: You can test e10s in its own window, like Private Browsing, using the Nightly channel’s \"File > New e10s Window\" menu item. Electrolysis - MozillaWiki   ↩︎ \n Firefox Electrolysis project put on hold   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/es6-schedule.html", "title": "The ECMAScript 6 schedule changes", "content": "The ECMAScript 6 schedule changes esnext dev javascript Allen Wirfs-Brock, editor of the ECMAScript 6 specification, recently mentioned on Twitter that the schedule for ECMAScript 6 has changed slightly. The changes   # This is the content of Wirfs-Brock’s  tweets : \n TC39 has decided to move the formal publication date of the ECMAScript 6 standard to June 2015. \n Work for ECMAScript 7 continues on schedule. \n The extra time is for more implementation feedback and more ECMAScript 6 specification review, bug fixes, and test development. \n The ECMAScript 6 feature set will remain frozen during this extended validation period. \n What does this mean?   # ECMAScript 6 is basically done: its feature set  [1]  is frozen, it is mostly being refined now. You can already program in it and compile it to current JavaScript  [2] . The JavaScript frameworks  AngularJS  and  Ember.js  will even be based on it (with ways to opt out). Again, via cross-compilation. Furthermore, ECMAScript 6 features are appearing in modern browsers at a steady pace  [3] . The previous schedule looked as follows: \n November 2013: final review of draft \n July 2014: editorially complete \n December 2014: Ecma approval (formal publication date) \n According to  Wirfs-Brock, ECMAScript 6 will be finished (with the exception of fixing last bugs) by the end of 2014. The publication process starts in March 2015 (and is finished in June 2015). In other words: ECMAScript 6 implementation and adoption is progressing nicely, but standardization takes more time. The specification is a huge document and getting all the details right is an enormous task. References   # 2ality blog posts  on ECMAScript 6.  ↩︎ \n “ ECMAScript 6 Tools ” by Addy Osmani: to be used to compile ECMAScript 6 to ECMAScript 5 or 3 (so that it runs on current engines).  ↩︎ \n “ ECMAScript 6 compatibility table ” by kangax.  ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/raffle.html", "title": "Implementing a raffle in JavaScript", "content": "Implementing a raffle in JavaScript example dev javascript At two recent occasions, there were copies of “Speaking JavaScript” to be raffled off. This blog post describes two ways of drawing winners via JavaScript. There is a list of the attendees’ names   # If there is a list of the attendees’ names, drawing a winner is relatively easy. In my case, it was a MunichJS meetup and a list of names was online, as a  web page . In a browser console, I accessed the DOM to make a random pick: At (1) I invoke    generically , because the result of    is not an array and does not have that method. At (2), I use   and   to compute an integer in the range [0,  ). You don’t know the attendees’ names   # If you don’t have a list of the attendees’ names then you need figure out a way to pick a place. For many seating arrangements, there is an aisle in the middle. In such a case, I find a triple easy to understand as a coordinate: Row number (starting at zero) Column number (starting at zero, relative to left/right side of auditorium)  or  #2 and #3 mean that you stand in the aisle and start counting chairs either to your left or to your right, once you are at the right row. The following function computes a random coordinate, if you provide it with the number of rows and the number of columns (in each side of the auditorium). Using the function looks like this: comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/curbing-online-abuse.html", "title": "Curbing Online Abuse", "content": "Curbing Online Abuse social computers “ Curbing Online Abuse Isn’t Impossible. Here’s Where We Start ” by Laura Hudson describes how online abuse was curbed in the battle-arena game  , published by  . The following insight is interesting: “Riot found that persistently negative players were only responsible for roughly 13 percent of the game’s bad behavior. The other 87 percent was coming from players whose presence, most of the time, seemed to be generally inoffensive or even positive. […] Banning the worst trolls wouldn’t be enough to clean up  , Riot’s player behavior team realized. Nothing less than community-wide reforms could succeed. It’s great that Riot’s measures often succeeded in educating offenders and changing their behavior. comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/parallel-js.html", "title": "Parallel JS (River Trail): soon in Firefox", "content": "Parallel JS (River Trail): soon in Firefox dev javascript blog post \nParallel JS will soon be included in Firefox Nightly builds. This project was initially called River Trail  [1] . It automatically parallelizes code that uses the   type and its array-like methods (  etc.). [Source of this post: “ Parallel JS lands ” by Nicholas D. Matsakis.]\n \n \nTime table:\n \n      Only a limited subset of JavaScript is supported and you don’t get good feedback as to whether your code could be parallelized and if not, why not.\n     \n      All   (that don’t mutate shared state, only data that they create and store in local variables) will be parallelizable; better diagnostics when parallelization is not possible.\n     \n      Make parallelization as wide-spread in JavaScript as possible and evolve the API. One  possible improvement  is to bring parallelization to normal arrays. Currently,   pulls double duty, it is both a lightweight array that can be manipulated in parallel and a capable multi-dimensional matrix. Matsakis proposes adding parallelizing methods to arrays (e.g.  ), so that   can focus on the latter duty.\n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/06/es6-multiple-return-values.html", "title": "Multiple return values in ECMAScript 6", "content": "Multiple return values in ECMAScript 6 esnext dev javascript If you combine the features “property value shorthand” and “destructuring”, ECMAScript 6 gives you an elegant way to handle multiple return values. This blog post explains why that is useful and how it works. Destructuring   # Destructuring is an ECMAScript 6 feature which lets you use patterns to extract values from an object: Destructuring also works for arrays: That is, object literals and array literals enable us to construct compound values and destructuring enables us to take them apart. It can be used in the following locations: Multiple return values   # To see the usefulness of multiple return values, let’s implement a function   that searches for the first element in the array   for which the function   returns  . The question is: what should that function return? Sometimes one is interested in the element itself, sometimes in its index, sometimes in both. The following is an implementation of the last use case. I’ve decided in favor of returning the element and the index via an object and against returning them via an array, because the labeling of the values in an object makes things more self-descriptive. Let’s rewrite the function and use some ECMAScript 6 features: In line (1), we have used: \n the new   loop  [1] \n a block-scoped   variable declaration \n the method   which returns a sequence of [index, element] pairs \n array destructuring to conveniently access the components of those pairs \n In line (2), we have used so-called  . The following two expressions are equivalent. Now it is time to use the function. In ECMAScript 5,  finding the first even number in an array looks as follows. In ECMAScript 6, less code is needed: We use property value shorthands and object destructuring to assign values to   and  . Additionally, the predicate is less verbosely specified via an arrow function  [2] . Due to   and   also referring to property keys, the order in which we mention them doesn’t matter: We have successfully handled the case of needing both index and element. What if we are only interested in one of them? It turns out that, thanks to ECMAScript 6, our implementation can take care of that, too, with minimal syntactic overhead: Each time, we only extract the value of the one property that we need. References   # Iterators and generators in ECMAScript 6   ↩︎ \n ECMAScript.next: arrow functions and method definitions   ↩︎ \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/is-integer.html", "title": "Checking whether a value is an integer in JavaScript", "content": "Checking whether a value is an integer in JavaScript dev javascript jslang Integers lead an odd life in JavaScript. In the ECMAScript specification, they only exist conceptually: All numbers are always floating point and integers are ranges of numbers without decimal fractions (for details, consult “ Integers in JavaScript ” in “Speaking JavaScript”). In this blog post, I explain how to check whether a value is an integer. ECMAScript 5   # There are many ways in which you could implement this check. At this moment, you may want to take a break and try to write your own solution: a function   that returns   if   is an integer and  , otherwise. Let’s look at a few examples. Checking via the remainder operator   # One can use the remainder operator ( ) to express the fact that a number is an integer if the remainder of dividing it by 1 is 0. I like this solution, because it is quite self-descriptive. It usually works as expected: You have to be careful with the remainder operator, because the first operand determines the sign of the result: if it is positive, the result is positive, if it is negative, the result is negative. However, we are checking for zero, so that’s not an issue here. One problem remains: this function can return   for non-numbers, because   coerces its operands to numbers: That can be easily fixed by adding a type check: Checking via     # A number is an integer if it remains the same after being rounded to the “closest” integer. Implemented as a check in JavaScript, via  : This function works as it should: It also handles non-numbers correctly, because   always returns numbers and   only returns   if both operands have the same type. If you wanted to make the code more explicit, you could add a type check (like we did in the previous solution). Furthermore,   and   work just as well as  . Checking via bitwise operators   # Bitwise operators provide another way of converting a number to a “close” integer: This solution (along with other solutions based on bitwise operators) has one disadvantage: it can’t handle numbers beyond 32 bits. Checking via     #  also converts numbers to integers and can be used similarly to  . Let’s find out whether that is a good idea. Like the   solution, this implementation handles non-numbers well, but it does not correctly identify all numbers as integers: Why?   coerces its first parameter to string before parsing digits. It is not a good choice for converting numbers to integers. Above,   stops parsing   before the first non-digit,  , which is why it returns  . Other solutions   # I received a few more interesting solutions via Twitter,  check them out . ECMAScript 6   # Complementing   et al., ECMAScript 6 provides an additional way of converting numbers to integers:  . That function removes a number’s decimal fraction: Furthermore, ECMAScript 6 makes the task of checking for integers trivial, because it comes with a built-in function  . Further reading   # \n “ Converting to Integer ” (in “Speaking JavaScript”) covers the most common ways of converting numbers to integers. \n “ Safe Integers ” (in “Speaking JavaScript”) explains what range of integers can be safely used in JavaScript and what “safely used” means. \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/nodejs-harmony.html", "title": "ECMAScript Harmony features in Node.js", "content": "ECMAScript Harmony features in Node.js esnext dev nodejs javascript David Klassen [1] \n \nNote: “harmony semantics for  ” is something that (unfortunately) had to be rejected for Harmony. It would have consisted of   returning  , but that change would break too much existing code.\n \n \n ECMAScript: ES.next versus ES 6 versus ES Harmony comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/quirk-undefined.html", "title": "JavaScript quirk 2: two “non-values” – undefined and null", "content": "JavaScript quirk 2: two “non-values” – undefined and null dev twelvequirks javascript jslang series \nMost programming languages have only one value for “no value” or “empty reference”. For example, that value is   in Java. JavaScript has two of those special values:   and  . They are basically the same (something that will change with ECMAScript 6, as will be explained in the last post of this series), but they are used slightly differently.\n\n \n\n \n  is assigned via the language itself. Variables that have not been initialized yet have this value:\n Check: does a variable have a value? truthy \nSome people advocate lenient non-equality ( ) to check that   is neither   nor  :\n Performance-wise comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/quirk-implicit-conversion.html", "title": "JavaScript quirk 1: implicit conversion of values", "content": "JavaScript quirk 1: implicit conversion of values dev twelvequirks javascript jslang series \nJavaScript is very tolerant when it comes to accepting values. For example, everywhere it expects a number, it does not reject values from other types, but tries to convert them:\n Implicit conversion to boolean: “truthy” and “falsy” values \n     ,  \n     Boolean:  \n     Number:  ,  ,  \n     String:  \n Implicit conversion of strings Implicit conversion of objects Call  . If the result is primitive (not an object) then use it and convert it to a number.\n     Otherwise, call  . If the result is primitive, use it and convert it to a number.\n     Otherwise, throw a  . Best practice: explicit conversion [1] Reference NaN and Infinity in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/enforcing-tostring.html", "title": "Enforcing toString()", "content": "Enforcing toString() dev javascript jslang @puffnfresh suggests [1] \n     Call method  . If it returns a primitive, we are done.\n     \n     Otherwise, call method  . If it returns a primitive, we are done.\n     \n     Otherwise, throw an error. \n [2] \nWithout the code snippet at the beginning of this post,   returns   (an object) and is inherited by all objects that don’t override this method:\n References Coercing objects to primitives What is {} + {} in JavaScript? comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/check-undefined.html", "title": "Checking for undefined: === versus typeof versus falsiness", "content": "Checking for undefined: === versus typeof versus falsiness dev javascript jslang Checking via === [1] Changing undefined property of the global object \nBecause you could globally change the value of   under ECMAScript 3, two techniques were often used to ensure that it had the correct value. If you are targeting older browsers, these techniques are still relevant.\n \n  shadow   yourself.\n \n  compare with  . The   operator  [2]  evaluates its operand, ignores the result and returns  . That means that   will always evaluate to  .\n Checking via typeof [3] Checking for falsiness [4] Conclusion References Equality in JavaScript: === versus == The void operator in JavaScript Categorizing values in JavaScript JavaScript quirk 1: implicit conversion of values comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/blink.html", "title": "Google’s Blink: a few interesting facts", "content": "Google’s Blink: a few interesting facts browser dev blink webkit google webdev chrome Blink How much did each company contribute to WebKit? Reviewers and companies in the WebKit project Why didn’t WebKit2 adopt Chrome’s multiprocess architecture? explanation How will WebKit change without Chrome support? simpler since 2008 Conclusion issue [1] \nAll things considered, forking WebKit seems the best solution for everyone involved, as far as the browser implementation side is concerned. Web developers will have to wait and see, but there are   many subtle differences between the variants of WebKit.\n\n Reference asm.js: closing the gap between JavaScript and native comments powered by Disqus."},
{"url": "https://2ality.com/2013/03/ecma.html", "title": "Ecma wasn’t always Ecma", "content": "Ecma wasn’t always Ecma dev javascript jslang jshistory [1] Ecma International [1] \nThis little bit of history also explains why it’s spelled ECMAScript and not EcmaScript: That’s a remnant from when Ecma was still ECMA.\n \n \n ECMAScript: ES.next versus ES 6 versus ES Harmony comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/12quirks.html", "title": "12 JavaScript quirks", "content": "12 JavaScript quirks dev twelvequirks javascript jslang Implicit conversion of values Two “non-values” –   and  Normal equality ( ) Unknown variable names create global variables Parameter handling The scope of variables Inadvertent sharing of variables via closures Array-like objects Subtyping constructors Reading and writing of properties  in real functions The for-in loop [1] \nThe series will provide a good overview of JavaScript. It is a translation of a  previous blog post  in German.\nECMAScript 5 will be used and a basic knowledge of JavaScript is required, but much will be explained. I will post one quirk per week.\n \n \n ECMAScript: ES.next versus ES 6 versus ES Harmony comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/quirk-equality.html", "title": "JavaScript quirk 3: normal equality (==)", "content": "JavaScript quirk 3: normal equality (==) dev twelvequirks javascript jslang series \nLet’s start with a simple rule: the normal equality operators   and   are so problematic that you should always use strict equality (  and  ). Some people say that there are exceptions to this rule, I disagree  [2] . Keeping this rule in mind, we can now take a look at what is strange about  , without burdening our minds unnecessarily.\n\n \n\n \nThe “normal” equality operator ( ) has many quirks. While it is forgiving, it does not adhere to the typical rules of truthy and falsy (see  quirk 1 ):\n \nIf you are still interested in finding out how exactly   works, you can read up on it here:  [1] .\nWith strict equality ( ), values of different types are never equal  [1] , which means that all of the above problems go away.\n \n \n Equality in JavaScript: === versus == When is it OK to use == in JavaScript? comments powered by Disqus."},
{"url": "https://2ality.com/2014/02/time-values.html", "title": "JavaScript time values: dates as milliseconds since 1970-01-01", "content": "JavaScript time values: dates as milliseconds since 1970-01-01 dev javascript jslang \nWhat the date API calls   is called a   by the ECMAScript specification. It is a primitive number that encodes a date as milliseconds since 1 January 1970 00:00:00 UTC. Each date object stores its state as a time value, in the internal property   (the same property that instances of the wrapper constructors  ,  , and   use to store their wrapped primitive values).\n \n  Leap seconds are ignored in time values.\n \nThe following methods work with time values:\n \n  uses a time value to create a date. \n  parses a string with a date time string and returns a time value. \n  returns the current date time as a time value. \n  interprets the parameters relative to UTC and returns a time value. \n  returns the time value stored in the receiver. \n  changes the date as specified via a time value. \n  returns the time value stored in the receiver. This method determines how dates are converted to primitives, as explained in the next subsection. \n [1] \nA few examples of converting dates to time values:\n\n Converting a Date to a Number [2] Reference What are integers in JavaScript? Coercing objects to primitives comments powered by Disqus."},
{"url": "https://2ality.com/2014/04/slides.html", "title": "In search of the perfect technology for slides", "content": "In search of the perfect technology for slides presenting computers \nThere are a variety of software technologies out there for helping you with creating slides. Following are ones that I find intriguing:\n\n \n\n \n      somewhat surprisingly, I still find PDF the best format for slides (I would have expected it to be HTML by now). Why? You get a single, easily portable and printable file that scales well to various screen sizes and resolutions. Furthermore, all modern web browsers have excellent PDF support, which means that you don’t even have to “leave the web” if you want to check out a PDF file. Lastly,  Speakerdeck  is a convenient way of putting PDF slides online. As examples, you can check out  my slides .\n     \n\n      works remarkably well for slides, via the built-in Beamer package. Things I love about this technology:\n         \n             You can directly produce PDF and use PDF images. \n             The file with the slide data is plain text, which means you can easily version-control it. Additionally LaTeX lets you include external text content and you can generate some of your own content via scripts. \n             SyncTeX  allows you to jump from a PDF to a text editor and vice versa. That is, you get both the advantages of WYSIWYG and rendered content. \n             Many features: tables, sophisticated math, “pauses” to reveal content incrementally, automatic syntax highlighting etc.\n             \n             No need to tweak: Well, actually, this is both an advantage and a disadvantage. I love that you simply author the content and LaTeX places everything automatically. Unfortunately, creating your own theme takes work.\n             \n         \n     \n      One benefit of these apps is that they work well on tablets.\n     \n     Deckset  is a new app for OS X. It has many of the advantages of LaTeX, because you author your slides in Markdown and display them via the Deckset app. That app also exports PDF. However, it does not yet offer as many features as LaTeX (tables, math, pauses) and doesn’t have something similar to SyncTeX.\n     \n      I recently asked on Twitter and got a few great  recommendations . Most frequently mentioned were:\n         \n             reveal.js by Hakim El Hattab \n             Shower by Vadim Makeev \n         \n        Both allow you to export to PDF.\n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/04/required-parameters-es6.html", "title": "Handling required parameters in ECMAScript 6", "content": "Handling required parameters in ECMAScript 6 esnext dev javascript \n     Keyword parameters in JavaScript and ECMAScript.next \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/04/call-stack-size.html", "title": "The maximum call stack size", "content": "The maximum call stack size esnext dev javascript How many recursive calls? gist \n     Node.js: 11034 \n     Firefox: 50994 \n     Chrome: 10402 \n Tail call optimization in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2014/02/break.html", "title": "Taking a break", "content": "Taking a break 2ality comments powered by Disqus."},
{"url": "https://2ality.com/2014/03/reduce-index.html", "title": "reduce() and array indices", "content": "reduce() and array indices dev javascript jslang What indices does the callback receive? pointed out reduce() and empty arrays More information on  \n     The section “ Reduction Methods ” of Speaking JavaScript explains  in detail.\n     \n     A blog post by Ariya Hidayat covers “ Searching using Array.prototype.reduce ”.\n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/04/html-label.html", "title": "Making checkbox labels clickable via <label>", "content": "Making checkbox labels clickable via <label> dev html \nWithout  , you need to click directly on a checkbox in order to toggle it:\n\n \n \n \n \n on MDN comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/beyond-always-on.html", "title": "Beyond “always on”", "content": "Beyond “always on” mobile scitech Always on Facebook Home Google Glass Beyond “always on” \n     very sporadic and asynchronous (letters) \n     sporadic and synchronous (traditional phones) \n     sporadic and asynchronous (non-mobile email) \n     continuous and synchronous (mobile dumbphones) \n     continuous and asynchronous, with the occasional synchronous communication (mobile smartphones) \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/04/polymer-x-tag-interoperable.html", "title": "The interoperability of Web Component polyfills", "content": "The interoperability of Web Component polyfills dev html5 javascript webcomponents webdev Web Components \n     Polymer  by Google \n     X-Tag  by Mozilla \n Custom Element Interoperability \n   @b_lionel  told me about  Bosonic , which is partially based on Polymer and also  interoperable .\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/quirk-parameters.html", "title": "JavaScript quirk 5: parameter handling", "content": "JavaScript quirk 5: parameter handling dev twelvequirks javascript jslang series \nThe basics of parameter handling in JavaScript are simple, advanced tasks require manual work. This blog post first looks at the basics and then covers advanced topics.\n\n \n\n The basics of parameter handling Fact: you can always pass an arbitrary amount of parameters Fact: all passed parameters are stored in  Has a parameter been passed? [1] Default values for parameters An arbitrary number of parameters Enforcing a certain number of parameters  is not an array Reference JavaScript quirk 1: implicit conversion of values  [explains “truthy” and “falsy”] comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/current-script.html", "title": "Identifying the current  script  element", "content": "Identifying the current   element guest rodney dev javascript clientjs Rodney Rehm You may find yourself in a situation requiring you to know the DOM context of the JavaScript that is currently executing. The DOM context of a running JavaScript is the   element that caused the JavaScript to be executed in the first place. With HTML5 the WhatWG introduced  , which this article will use to explain simple techniques to make use of DOM context. What do I need the   context for?   # The script you’re running may be in need of parameterization. It requires some sort of configuration, some data so it can do its job properly. Developers who’ve used  RequireJS  haven seen this before: That’s a shorthand way of doing the following in JavaScript: We can see here that first the script   is downloaded and evaluated, then it is initialized with some basic configuration. The first example pulled some configuration data out of the attribute   of the   element the JavaScript was loaded in. It used the   element to configure and initialize itself. No other script was required to achieve this. Another example where DOM context can come in handy is when you need to know the containing DOM element: The script   needs to know its parent element in order to initialize itself. Again, we could have achieved the same thing with the following, more verbose JavaScript: We can take things further by using the   of a remote   resource for configuration, in case a data-attribute is insufficient: If you think that the above is an error, you’re probably remembering the old rule to never put code inside an external script. After all,   says that »script elements with a   attribute specified should not have a script embedded within its tags« – but what exactly is \"not a script\"? HTML5 mandates the text content of a   element that has a   attribute to either be empty – which is what we’re used to – or contain only  script documentation . In other words, if you put something in there, make sure it’s a valid script comment. So you either have to make sure all lines are preceded by   to make them line-comments, or you wrap the content in   and   to make the entire content a block-comment. Et voila, we have content that is \"not a script\". In reality no browser (Blink, Gecko, Trident, WebKit) cares about this rule – at least not in a way that would prevent you from reading the script element’s  . Of course you also need to make sure that the character sequences   and   don’t show up in your content, as the general [restrictions for contents of script elements]( script content restrictions ) still applies. Summing things up, DOM context can be a powerful tool for configuring JavaScript. Obtaining the   DOM context?   # The  WhatWG HTML5 Specification  defines the property  . It contains a reference to the  currently executed script . The good news is that Gecko (Firefox) and Blink (Chrome, Opera) support this property already. The bad news is, WebKit (Safari, Safari iOS, Android Stock Browser) and Trident (Internet Explorer) don’t yet know  . At first glance it looks as if   could fill the gap. And it does, unless you’re planning on working with   inside an  . While Internet Explorer lists   within inline   in  , every other browser does not.   does not show that limitation and returns   within   just fine. We can reliably access the current script’s DOM element with the following snippet: There are two situations where this snippet will fail, though. When a script is loaded asynchronously using  , the order of script execution is uncertain. Therefore the   trick will not work, as it relies on the currently executed script being the last of that collection. The same holds true for  s that are not appended to the end of the document. In the future this might become less of a problem, as   properly resolves async scripts. With   we don’t see this limitation. While async scripts can be executed whenever they become ready, deferred scripts are collected and executed right after the browser finished parsing the document. That’s why it can keep track of the   element reference even through  . If a script is made selectable, by adding an id attribute, a certain class or, say, a data attribute, one could query the DOM with the appropriate selector instead. That’s the route  RequireJS 2.1.11 currentScript detection  went. This will work fine in any situation, except for when the given selector is used multiple times. Conclusion   # Knowing which   the currently executed JavaScript belongs to can help simplify configuration. Modern browsers support  , others can be helped along with   – but watch out for   and  . @rachelnabors @derSchepp  is a web developer, enjoying to create tools that not just work, but work well. He currently works for Deutsche Telekom on JavaScript applications of their Connected Home Platform  Qivicon . Rod started out working the full web stack as a freelancer over a decade ago. In recent years he focused on the front end, particularly on JavaScript. With utilities like  URI.js , articles like  Designing Better JavaScript APIs  and testing  CSS Transitions  he’s trying to make the web a better place. comments powered by Disqus."},
{"url": "https://2ality.com/2014/05/this.html", "title": "JavaScript’s this: how it works, where it can trip you up", "content": "JavaScript’s this: how it works, where it can trip you up dev javascript jslang A different way of understanding `this` in JavaScript \n \nIn JavaScript, the special variable   is relatively complicated, because it is available everywhere, not just in object-oriented settings. This blog post explains how   works and where it can cause problems, concluding with best practices.\n \n \nTo understand  , it is best to partition the locations where it can be used into three categories:\n \n        is an extra, often implicit, parameter.\n     \n        refers to the global object in browsers and to a module’s exports in Node.js.\n     \n        either picks up the current value of   or sets it to the global object, depending on whether it is called directly or indirectly.\n     \n  in functions \n     Real functions (  is the global object in sloppy mode,   in strict mode) \n     Constructors (  refers to the newly created instance) \n     Methods (  refers to the receiver of the method call) \n  in real functions mode \n     Sloppy mode:   refers to the  global object  (  in browsers).\n \n     \n     Strict mode:   has the value  .\n \n     \n  in constructors slightly more complex  in methods  in the top-level scope global object  in  here \nIf   is called indirectly,   refers to the  global object :\n -related pitfalls strict mode Pitfall: forgetting  Pitfall: extracting methods improperly global object Pitfall: shadowing  \n   . Assign   to a variable that isn’t shadowed (another popular name is  ) and use that one.\n \n   . Use   to create a function whose   always has the correct value (the method’s   in the following example).\n \n   ’s second parameter. This method has a second parameter whose value is passed to the callback as  .\n Best practices comments powered by Disqus."},
{"url": "https://2ality.com/2013/04/quirk-automatic-globals.html", "title": "JavaScript quirk 4: unknown variable names create global variables", "content": "JavaScript quirk 4: unknown variable names create global variables dev twelvequirks javascript jslang series \nNormally, JavaScript automatically creates a global variable if you use an unknown variable name:\n [1] JavaScript’s strict mode: a summary comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/history-undefined.html", "title": "JavaScript history: undefined", "content": "JavaScript history: undefined dev javascript jslang jshistory [1] \nThe first version of JavaScript did not have exception handling, which is why JavaScript so often converts automatically  [2]  and/or fails silently ( tweet ).\n \nJavaScript copied Java’s approach of partitioning values into primitives and objects  [3] .   is the value for “not an object”. The precedent from C (but not from Java) is to convert   to 0 (C has pointers, not references and lets you perform  arithmetic  with pointers).\n \nRemaining problem: In JavaScript, each variable can hold both primitives and objects. In Java, a variable’s static type limits it to either kind of value. We therefore need a value for “neither a primitive nor an object”. That value could be  , but at the time, Eich wanted something that wasn’t “reference-y” (associated with objects) and did not convert to 0 ( tweet ). Now you know why   and   are converted to different numbers:\n \n \n JavaScript quirk 2: two “non-values” – undefined and null JavaScript quirk 1: implicit conversion of values Categorizing values in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/web-components-angular-ember.html", "title": "Plans for supporting Web Components in AngularJS and Ember.js", "content": "Plans for supporting Web Components in AngularJS and Ember.js emberjs dev html5 javascript webcomponents angularjs polymer webdev [1] \nBelow, you’ll see mentions of Google’s new framework, Polymer  [1] . It is built directly on top of Web Components. One of Polymer’s goals is to help refine and fully figure out that standard.\n\n AngularJS entry \n Angular will use the underlying web platform features available to it (e.g. Node.bind, template integration, Custom Elements, etc...) \n Web Components (Polymer, Ember, or any other framework/library) will work seamlessly within Angular apps and directives. \n Components written in Angular will export to Web Components (to be used by Polymer, Ember, or any other framework/library). \n Ember.js Ember and Web Components HTMLBars \nIt builds on the work of Rafael Weinstein and the Polymer team, and attempts to harmonize that work with Ember's architecture.\n \nEmber's scope is much wider than components, and is mostly focused on application architecture and URL-driven design. Today, we need a system to manage the lifecycle of data-binding and custom views, so we include such a system alongside our architectural tools.\n \nOnce the web provides its own tools for managing components, and eventually data bindings, Ember will embrace them and transition away from our Ember-specific solution. This document is how we get from here to there, continuing to build ambitious and stable applications in the meantime.\n \n[...]\n Reference Google’s Polymer and the future of web UI frameworks \n        [describes both Web Components and Polymer]\n     comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/quirk-array-like-objects.html", "title": "JavaScript quirk 8: array-like objects", "content": "JavaScript quirk 8: array-like objects dev twelvequirks javascript jslang series \nSome objects in JavaScript look like arrays, but aren’t. They are called  . This blog post looks at what exactly that means and how to best work with those objects.\n\n Array-like objects \n\t has: indexed access to elements and the property   that tells us how many elements the object has.\n\t \n\t does not have: array methods such as  ,   and  .\n\t \n [1] Generic methods Examples Converting an array-like object to an array Reference JavaScript quirk 5: parameter handling comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/google-polymer.html", "title": "Google’s Polymer and the future of web UI frameworks", "content": "Google’s Polymer and the future of web UI frameworks dev html5 javascript webcomponents google polymer webdev \n     [2013-07-16]  Hello Polymer: Q&A with Google’s Polymer team  [more information on Polymer]\n     \n     [2013-05-23]  Plans for supporting Web Components in AngularJS and Ember.js \n     \n Polymer Polymer \n     Foundation (platform.js): Foundational building blocks. Most, if not all, of these APIs will eventually become native browser APIs.\n     \n     Core (polymer.js): Helpers complementing Foundation.\n     \n     Elements: UI and non-UI components built on Core.\n     \n The Foundation layer (platform.js) DOM Mutation Oberservers  and  Object.observe()  (probably ECMAScript 7): for observing changes to DOM elements and plain JavaScript objects.\n     Pointer Events : handle mouse and touch in the same manner, on all platforms.\n     Shadow DOM : encapsulate structure and style inside elements (e.g. custom ones).\n     Custom Elements : define your own HTML5 elements. The names of custom elements must contain a dash, which is a simple way of namespacing them and distinguishes them from standard elements.\n     HTML Imports : package custom elements. Such packages include HTML, CSS and JavaScript.\n     Model-Driven Views (MDV) : Does data-binding directly in HTML. Not yet in the process of being standardized.\n     Web Animations : API unifying several of the web’s animation approaches.\n     Web Components \nplatform.js shims these APIs on browsers where they are not (yet) available. It is only 31KB (if minified and gzipped). One of the declared goals of Polymer is to field-test HTML5 UI APIs before standardizing them.\n\n Layers: Core and Elements Interoperability X-Tag When can I use it? its code Polymer versus other frameworks tweet What does it all mean? \n     A rich set of widgets. In my opinion, this is the biggest deal about Web Components (and, to a lesser degree, about Polymer). We finally get a large set of widgets that we can use anywhere.\n     \n     User interface layout. I have high hopes for  CSS Grid Layout  here. Grid Layout is native HTML, so it complements Web Components quite naturally.\n     \n     “Glue” to combine widgets (e.g. data binding).\n     \n classes Resources \n     Talks at Google I/O 2013:\n         \n             “ Web Components: A Tectonic Shift for Web Development ” by Eric Bidelman\n             \n             “ Web Components in Action ” by Matthew McNulty, Alex Komoroske [builds on the previous talk, covers Polymer]\n             \n         \n     \n     HTML5 Rocks : articles on Web Components.\n     \n     Polymer homepage:  polymer-project.org \n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/beginning-infinity.html", "title": "The beginning of infinity in JavaScript", "content": "The beginning of infinity in JavaScript numbers dev javascript jslang \nAll numbers in JavaScript are floating point numbers and (roughly) encoded internally  [1]  as\n \nThe mantissa is a binary 1, followed by a binary dot, followed by a 52 bit fraction  . The 11 bit exponent   has to be in the range\n \nConsult  [1]  if you want to know more about how numbers are encoded in JavaScript.\n\n Reference How numbers are encoded in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/quirk-closures.html", "title": "JavaScript quirk 7: inadvertent sharing of variables via closures", "content": "JavaScript quirk 7: inadvertent sharing of variables via closures dev twelvequirks javascript jslang series \nClosures are a powerful JavaScript feature: If a function leaves the place where it was created, it still has access to all variables that existed at that place. This blog post explains how closures work and why one has to be careful w.r.t. inadvertent sharing of variables.\n\n \n\n Closures \nWhen a function   is invoked, a new environment is created for its parameters and local variables. There is always a chain of environments:\n \n     ’s environment \n     ’s outer environment \n     The outer environment of  ’s outer environment \n     ... \n     The environment for global variables (the  ) \n The quirk: inadvertent sharing \nOne possible fix is to copy the current value of   via an IIFE  [1] :\n A practical example Connect Four \nThe last post in this series will explain how ECMAScript 6 helps with the problem of inadvertent sharing.\n\n Reference JavaScript quirk 6: the scope of variables comments powered by Disqus."},
{"url": "https://2ality.com/2013/05/quirk-variable-scope.html", "title": "JavaScript quirk 6: the scope of variables", "content": "JavaScript quirk 6: the scope of variables dev twelvequirks javascript jslang series \nIn most programming languages, variables only exist within the block in which they have been declared. In JavaScript, they exist in the complete (innermost) surrounding function:\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/12/printing-github-markdown.html", "title": "Printing Markdown files on GitHub", "content": "Printing Markdown files on GitHub bookmarklet dev hack javascript clientjs \nThis blog post explains three ways of printing Markdown files that are hosted on GitHub:\n \n \n     Markdown tools: such as  kramdown  can be used to turn Markdown files into HTML files that can be printed.\n     \n     Safari’s Reader mode  [1] : With many pages, Safari displays a “Reader” button in the address bar. Clicking it usually removes all clutter around content. You can print a page in Reader mode. Disadvantage of this solution (especially compared to the next one): You lose most of the syntax highlighting of source code.\n     \n     Bookmarklet  [2] : Create a bookmark with the following URL, click it and everything around the content is removed.\n         \n     \n ServiceWorkers Explained \n \n Tip: clutter-free web content via Safari Reader Implementing bookmarklets in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/web-platform-2014.html", "title": "Web platform: five technologies to look forward to in 2014", "content": "Web platform: five technologies to look forward to in 2014 dev webdev javascript webcomponents clientjs jslang asm.js: near-native performance on the web ParallelJS: parallelized JavaScript code ECMAScript 6 (ES6): evolving the language, uniting the community Web Components: a standard infrastructure for widgets CSS Grid Layout: native-like GUI layout asm.js: near-native performance on the web \n \n \n     Near-native speed in web browsers. \n     Tightly integrated with JavaScript. \n     Already compatible with all existing JavaScript engines. An engine optimizing asm.js code takes more work, but can be implemented incrementally. \n asm.js: closing the gap between JavaScript and native ParallelJS: parallelized JavaScript code \n  You get parallelism without any pitfalls. Plans for the future are impressive, too – ParallelJS may eventually produce code for GPUs.\n \n  “ ParallelJS: data parallelism for JavaScript ”\n\n\n ECMAScript 6 (ES6): evolving the language, uniting the community already available \n  ECMAScript 6 brings many new features, but I expect the following two to have the biggest impact. And it’s not because they bring something to JavaScript that wasn’t there, before – the inheritance APIs and module systems that we currently have work really well. It is because they unity the community.\n \n      Currently, almost every framework has its own inheritance API, hindering code portability. With ECMAScript 6 classes, there is hope that everybody will eventually use the same mechanism.\n     \n      Roughly, the world of JavaScript modules is divided into Node.js modules and AMD modules. It looks like ES6 modules will change that.\n     \n \n \n \n     The slides of my talk “ ECMAScript 6: what’s next for JavaScript? ” are online. An older version of this talk is available  on video . \n     I’ve written  many blog posts  on ECMAScript 6, if you want to delve into details.\n     \n     The draft ECMAScript 6 specification is available as  PDF  and  HTML , if you are feeling hard core.\n     \n     “ JavaScript Promises: There and back again ” (by Jake Archibald) explains promises and how to use them with generators.\n     \n     “ Tracking ECMAScript 6 Support [in current JavaScript engines] ” by Addy Osmani \n Web Components: a standard infrastructure for widgets Shadow DOM \n  Web Components will enable a common ecosystem for web widgets. In the present, you may come across an exciting widget on the web, only to find out that it doesn’t work with your framework of choice. In the future, that problem will hopefully go away, because all widgets will be Web Components and all frameworks will support Web Components. Then frameworks can focus on new ideas and don’t have to reinvent the foundational infrastructure wheel.\n \nGoogle’s  Polymer Project  polyfills Web Components for current browsers. That means that the APIs can be polished via experience gained from real-world projects before becoming part of HTML5.\n \n \n \n     “ Web Components Resources ” by Eric Bidelman \n     Google’s Polymer and the future of web UI frameworks \n CSS Grid Layout: native-like GUI layout \n  Desktop and mobile UI frameworks such as Android, iOS (Cocoa) and Java SWT are still ahead of the web when it comes to layouting graphical user interfaces. CSS Grid Layout will eliminate that gap. How about  support  in browsers? Internet Explorer already supports it, implementations in  Firefox  and  Chrome  are in progress. Here is hoping that it will be available on the latter two browsers in 2014. If you look at the editors of the spec, below, the signs are good.\n \n   Flexbox  is another CSS layouting mechanism, with broad  support  across browsers. It is great for fluid rows of HTML elements. When it comes to grids, it gets you quite far, because you can nest vertical and horizontal flexboxes. However, you have to decide on a dominant dimension (horizontal or vertical), making dynamic relationships in both dimensions impossible. In other words: true grids (as used for desktop-style graphical user interfaces) are easier in CSS Grid Layout.\n \n \n \n     “ CSS Grid Layout Module Level 1 ” by  Tab Atkins Jr.  (Google),  fantasai  (Mozilla), Rossen Atanassov (Microsoft)\n     \n     “ Understanding the Difference between CSS3 Flexbox & Grid Layout ” by Kyle Keeling ( @kyle_keeling ) \n     “ [Where] can I use CSS Grid Layout? ” by Alexis Deveria ( @Fyrd )\n     \n Conclusion comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/eval.html", "title": "Evaluating JavaScript code via eval() and new Function()", "content": "Evaluating JavaScript code via eval() and new Function() dev javascript jslang \n\n [1]  in strict mode [2] Indirect   evaluates in global scope \n     Directly : via a direct call to a function whose name is “eval”.\n     \n     Indirectly: in some other way (via  , as a method of  , by storing it under a different name and calling it there, etc.).\n     \n \n      points to the data structure in which the variable’s value is stored \n      is the name of the variable \n \n  That is a consequence of the code being evaluated independently of its current surroundings.\n  versus  Best practices \nOften, there are better alternatives. For example, Brendan Eich recently  tweeted  an anti-pattern used by programmers who wanted to access a property whose name was stored in a variable  :\n [3] \n \nThere are a few legitimate, albeit advanced, use cases for   and  : configuration data with functions (which JSON does not allow), template libraries, interpreters, command lines and module systems.\n\n Conclusion Global eval. What are the options? \n \nMariusz Nowak (@medikoo) told me that code evaluated by Function is sloppy by default, everywhere.\n\n References Expressions versus statements in JavaScript JavaScript’s strict mode: a summary JavaScript’s JSON API comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/efficient-string-repeat.html", "title": "Repeating strings efficiently", "content": "Repeating strings efficiently bitwise_ops dev javascript jslang pointed me efficient algorithm \nThe algorithm makes use of the fact that natural numbers (non-negative integers) can be represented as sums of powers of two.\n\n Natural numbers as sums of powers of two The algorithm implemented [1] [2] \nWhere a naive algorithm takes   steps to produce a result, this algorithm takes log ( ) steps. As an aside, concatenating strings via the plus operator ( ) has become fast on modern JavaScript engines  [3] .\n\n ECMAScript 6’s String.prototype.repeat() polyfill References Binary bitwise operators in JavaScript Integers and shift operators in JavaScript String concatenation in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/new-operator.html", "title": "The new operator implemented in JavaScript", "content": "The new operator implemented in JavaScript dev javascript jslang  operator \n     Line 1: The prototype of a new instance of a constructor   is    [4] \n     \n     Line 2: The implementor of a constructor can override that the   operators returns  , by returning an object. This is useful when a constructor should return an instance of a sub-constructor. The blog post  [3]  gives an  example .\n     \n JavaScript inheritance by example In defense of JavaScript’s constructors  [Why I recommend constructors, even though they are far from perfect] Exemplar patterns in JavaScript  [alternatives to constructors as factories for objects] JavaScript terminology: the two prototypes comments powered by Disqus."},
{"url": "https://2ality.com/2014/02/video-fake-operator-overloading.html", "title": "Video: Fake operator overloading", "content": "Video: Fake operator overloading dev javascript jslang video Fluent Conference publicly available \n \n \nThe actual beginning of the talk (a few seconds where I say the talk’s title) is missing. But my mic test is there! ;-)\n \n \nThis presentation explains how to achieve a limited form of operator overloading in JavaScript. You’ll learn tricks that allow you to write code like this:\n \n     Slides \n     The  blog post  that the talk is based on \n comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/tc39-march-november-2013.html", "title": "ECMAScript 6: TC39 meetings, March–November 2013", "content": "ECMAScript 6: TC39 meetings, March–November 2013 esnext tc39 dev javascript [1] blog posts \nThis post is made possible by Rick Waldron’s excellent  notes  of the meetings.\n\n \n\n \n March \n     Adobe joins TC39 ( announcement ). \n     Iterator protocol: TC39 decided on an iteration protocol for ECMAScript 6, which is described in  [2] .\n     \n      creates a clone of  . \n     Two new array methods  proposed by Rick Waldron:\n         \n             \n             \n             \n             \n         \n     \n May July \n     Maps can optionally be initialized via an iterable  [2]  of   pairs.\n     \n     Two new array methods that help WebGL:\n         \n             \n             \n         \n     \n     The  maximum length  of arrays has been expanded to 2 −1.\n     \n     Support for safe integers  [3]  via\n         \n             \n             \n             \n         \n     \n      counts the leading zero bits of an unsigned 32 bit integer  [4] . Useful, e.g., for audio decoding.\n     \n     Calling constructors as functions (omitting  ) is deprecated. If a constructor creates new instances even if it is called as a function then that can break subclassing, if sub-constructors can’t use it for setting up instance properties (longer explanation:  [5] ).\n        Therefore: classes throw when called as functions, as do the built-in constructors  ,  ,  ,  . Note that the   method still works, as it is needed for subclassing.\n     \n     Value objects: An ECMAScript edition after ECMAScript 6 will probably enable user-defined “value objects”, which are compared by value (comparing the contents, as is done for primitives) and not by reference (comparing identities, as is done for objects). That means that we will effectively be able to create new primitive types, including custom literals and dynamically dispatched polymorphic operators. Possibly even more important than that is that JavaScript will come with several built-in value object constructors. A few candidates:\n         \n              (literals: 123L) for usigned 64 bit integers \n              (literals: 1.23f) for 32 bit floating point numbers \n              for SIMD  [6] \n              (literals: 1.23n) for arbitrary precision floating point numbers \n         \n        Details: “ JS Responsibilities ” (slide 5+) by Brendan Eich.\n     \n September \n     @@unscopables : This special property allows one to hide own properties from the   statement. This mechanism became necessary, because old code with   statements broke when TC39 tried to add methods to  . So see why this happened, look at the following code:\n \n        If you add a method   to   then the above code breaks, because   in line (2) does not refer to   in line (1), anymore. Hence, all new array methods are hidden from   in ECMAScript 6, via:\n \n     \n      converts a 64 bit double to a 32 bit float and enables floats in asm.js  [7] .\n     \n     Line terminators in template strings: CR, LF, and CRLF are normalized to LF, which should help with cross-platform code.\n     \n     Tail call optimization: is something that most functional languages do; the last function call in a function whose return value isn’t used is executed as a jump. That means that many kinds of recursion don’t grow the stack anymore and become viable ways of implementing loops. ECMAScript 6 will perform tail call optimization, but only in strict mode (which doesn’t have  ).\n     \n     Symbols : are a new type for unique IDs in ECMAScript 6. Characteristics:\n         \n             A new primitive type with the usual wrapper objects. \n             \n              creates a symbol,   throws an exception (to avoid confusion).\n             \n             Implicit conversion to string throws an exception. Rationale: you want to use symbols as unique property keys and implicit conversion to string would be a major source of bugs. \n              throws an exception. That prevents people from accidentally using wrapper objects (which have no use other than as a provider of methods).\n             \n             You can retrieve the symbols that are keys of own properties via  .   only returns string-valued property keys.\n             \n               [8]  copies all enumerable own properties, independently of whether their keys are symbols or strings.\n             \n             A cross-realm registry for symbols means that they can be used across all frames etc. of an engine (see November meeting for details).\n             \n         \n        Originally, there were plans for providing private properties via symbols, but those plans were canceled, at least for ECMAScript 6. That is, properties whose keys are symbols are always public.\n     \n     The current specification process has several problems:\n         \n             Large editions drive the schedule. That means that once it has been decided that an edition comprises a given set of features then mature features may be unnecessarily delayed in order for other features to be finished. On the other hand, less mature features are under pressure to finalize.\n             \n             Informal process for accepting features. Acceptance of a feature for an edition occurs before details are sorted out and there is no formal way of tracking the maturity of a feature. That makes scheduling unpredictable.\n             \n             The burden of spec writing is on the editor of an edition (a constrained resource).\n             \n         \n        Solution:\n         \n             Release a revision every two years. That is, the schedule is now driven by dates instead of by editions. \n             The formal stage of maturity (explained below) at a cut-off date determines whether or not a feature is included in an edition.\n             \n             The maturity stages of a feature are:\n                 \n                 Proposal: describe problem and solution \n                 Working Draft: detailed solution, initial spec \n                 Candidate Draft: must be validated by implementations \n                 Last Call Draft: final spec (written by the designer of a feature) \n                 \n             \n         \n        More information: “ TC-39 Process Proposal ” by Rafael Weinstein and Dmitry Lomov.\n     \n     Destructuring: does not throw an exception if an expected property is missing, but still throws if a sub-pattern does not match.\n \n     \n     Promises : will be part of ECMAScript 6. They are already used in several browser APIs. Three examples:  ServiceWorker ,  Streams  and  Web MIDI .\n     \n     Object.observe() : Work on this feature is ongoing, it will probably be part of ECMAScript 7 (which will be released much more quickly than ECMAScript 6).\n     \n     Data parallelism (originally River Trail, now ParallelJS  [9] ): Ongoing work, making steady progress.\n     \n November \n     ES6 status: Cut from ES6 are\n         \n             refutable matching. Matching is mostly irrefutable (does not throw an exception if a property is missing), as demonstrated above. \n             binary data \n             regular expression lookbehind \n              (   [8]  is in) \n         \n        Will be in ES6: promises, tail call optimization.\n     \n     Cross-realm registry for symbols: A “meta-global” registry will allow symbols to cross realms. That means that you can use a symbol from the current frame to retrieve a property value of an object from a different frame. The registry API looks as follows.\n         \n              returns a symbol from the registry if an entry for   already exists, creates a new symbol and adds it to the registry if there is no such entry.\n             \n              returns the key under which a symbol is registered. Useful for tasks such as serialization.\n             \n         \n     \n     \n        transfers a method to a different object. This functionality is necessary because with super-references  [10] , a method is tied relatively closely to the object that owns it (its  ). A method’s home object is stored in a property of that method. Therefore,   creates a new function object whose internal property [[Code]] has the same value as in  , but whose properties [[HomeObject]] and, possibly, [[MethodName]] have different values.\n     \n     Custom comparators for   keys and   elements have been deferred. They determine what keys or elements are considered equal and have been deferred, because ensuring that they are efficient enough is difficult.\n     \n     Modules are mostly done now, consult  [11]  for details. \n References A JavaScript glossary: ECMAScript, TC39, etc. Iterators and generators in ECMAScript 6 Safe integers in JavaScript Integers and shift operators in JavaScript Subclassing builtins in ECMAScript 6 JavaScript gains support for SIMD asm.js: closing the gap between JavaScript and native ECMAScript 6: merging objects via Object.assign() ParallelJS: data parallelism for JavaScript A closer look at super-references in JavaScript and ECMAScript 6 ECMAScript 6 modules: the future is now comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/object-assign.html", "title": "ECMAScript 6: merging objects via Object.assign()", "content": "ECMAScript 6: merging objects via Object.assign() esnext dev javascript ECMAScript 6: new OOP features besides classes \nCopying all properties of one object to another one is a common operation in JavaScript. This blog post explains ECMAScript 6’s implementation of it, which is called  .\n\n \n \nThis merging operation has a name in the JavaScript ecosystem that is only used there (and, unfortunately, clashes with classic OOP terminology): “extend”. Two examples of “extend” being provided by libraries:\n \n     Prototype:  \n        Prototype first used the name “extend” for this operation.\n     \n     Underscore.js:  \n     \n Object.assign() [1] Property keys: either strings or symbols symbols Copying versus assignment [1] [2] Use cases for Object.assign() Setting up instance properties Adding a method to an object [3] Cloning an object References Object properties in JavaScript Properties in JavaScript: definition versus assignment Callable entities in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2014/01/binary-bitwise-operators.html", "title": "Binary bitwise operators in JavaScript", "content": "Binary bitwise operators in JavaScript bitwise_ops numbers dev javascript jsint jslang \nThese operators work with 32-bit integers. That is, they convert their operands to 32-bit integers and produce a result that is a 32-bit integer (encoded as a floating point number, at least externally).\n\n Inputting and outputting binary numbers \n  parses a string   in binary notation (base 2). For example:\n Binary bitwise operators \n  one boolean operation per bit. In the formulas below,   means bit   of number   interpreted as a boolean (0 is  , 1 is  ). For example,   is  ,   is  .\n\n \n     And:  \n     \n     Or:  \n     \n     Xor:  \n     \n \n  changing bits of   via  .\n \n     And: keeps only those bits of   that are set in  . This operation is also called masking, with   being the mask. \n     Or: sets all bits of   that are set in   and keeps all other bits unchanged. \n     Xor: inverts all bits of   that are set in   and keeps all other bits unchanged. \n Further reading Integers and shift operators in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/video-es6.html", "title": "Video: An overview of ECMAScript 6", "content": "Video: An overview of ECMAScript 6 esnext dev javascript video publicly available \n \n \nYou can download the slides on the  official page  of the talk.\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/freezing-instances.html", "title": "Freezing instances and the first invoked constructor", "content": "Freezing instances and the first invoked constructor dev javascript jslang The problem [1] The solution Am I the first invoked constructor? [2] A helper method for post-processing an instance Not hardcoding the reference to the constructor [3] Another way of checking for the first invoked constructor [4] References JavaScript inheritance by example What’s up with the “constructor” property in JavaScript? Expressions versus statements in JavaScript JavaScript terminology: the two prototypes comments powered by Disqus."},
{"url": "https://2ality.com/2014/02/javascript-integers.html", "title": "What are integers in JavaScript?", "content": "What are integers in JavaScript? numbers dev javascript jsint jslang What are integers? \nSecond, the ECMAScript specification has integer operators: namely, all of the bitwise operators. Those operators convert their operands to 32-bit integers and return 32-bit integers. For the specification,   only means that the numbers don’t have a decimal fraction, and   means that they are within a certain range. For engines,   means that an actual integer (non-floating-point) representation can usually be introduced or maintained.\n\n Ranges of integers \n     \n        Safe integers  [1] , the largest practically usable range of integers that JavaScript supports:\n         \n             53 bits plus a sign, range (−2 , 2 ) \n         \n     \n     Array indices  [2] :\n         \n             32 bits, unsigned \n             Maximum length: 2 −1 \n             Range of indices: [0, 2 −1) (excluding the maximum length!) \n         \n     \n     \n        Bitwise operands  [3] :\n         \n             Unsigned right shift operator ( ): 32 bits, unsigned, range [0, 2 ) \n             All other bitwise operators: 32 bits, including a sign, range [−2 , 2 ) \n         \n     \n     \n        “Char codes”, UTF-16 code units as numbers:\n         \n             Accepted by  \n             Returned by  \n             16 bit, unsigned \n         \n     \n More blog posts on integers \n     Converting to integer via shift operators: “ Integers and shift operators in JavaScript ” \n     Converting to integer via  : “ parseInt() doesn’t always correctly convert to integer ” \n References Safe integers in JavaScript Arrays in JavaScript Label  : blog posts on bitwise operators comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/triggering-events.html", "title": "Triggering events in vanilla JavaScript", "content": "Triggering events in vanilla JavaScript dom dev javascript clientjs \nThe running example is about sending a   event to a form. I needed to do that for a demo of user interface testing via  CasperJS . And, unfortunately, the   method does not send that event on most web engines.\n\n \n\n The recipe Look up the constructor of the event, via a  table on MDN  that maps event names to event constructors.\n         \n          submit events are created via the   constructor.\n     Look up the arguments of the event constructor, via the drafts of the specifications for\n         DOM4  and\n         UI Events .\n         \n          The constructor for  interface Event  has the following Interface Definition Language (IDL) signature:\n \n        Optionally,   can be passed in as an object and configures whether an event bubbles or is cancelable. It is defined in IDL as:\n \n     Dispatch the event. All event targets have a method  , whose only parameter is the event to dispatch.\n         \n          The following code triggers a submit event:\n \n        Line (*) is equivalent to:\n \n     web page A table \nOn browsers that don’t support event constructors, you have to resort to the legacy  .\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/pnacl-vs-asmjs.html", "title": "Running code fast in web browsers: PNaCl versus asm.js", "content": "Running code fast in web browsers: PNaCl versus asm.js asmjs dev javascript pnacl webdev Thoughts on asm.js vs PNaCl Comparing PNaCl and asm.js [1] [2] \nasm.js is a minimal solution. It being based on JavaScript give it three advantages:\n \n     asm.js code already runs in all current JavaScript engines, albeit much slower than in an asm.js-optimized engine.\n     \n     Easy to standardize: asm.js semantics is derived from JavaScript and thus very easy to define, because it can be based on the ECMAScript specification.\n     \n     Easy to port: an asm.js implementation is based on a JavaScript engine, meaning comparatively little work is required to create one. As an aside, standardization is a requirement for portability, because it enables interoperability between ports.\n     \n \nThat doesn’t mean that asm.js is perfect: It can certainly benefit from further performance optimizations and while the size of a file with gzipped asm.js code seems to be acceptable, processing such a file will always incur a performance penalty (gzipped or not). But asm.js is good enough for many applications: For example, Mozilla has  ported  the game engine Unreal Engine 3 (= lots of C++ code) to it.\n \nIt’ll be interesting to see how much PNaCl and asm.js will become cross-browser. For PNaCl, things don’t look good: no one has indicated an interest in a port. For asm.js, Google sounded like they would support it (at Google I/O). Support from other vendors is less certain.\n\n References Introduction to Portable Native Client asm.js: closing the gap between JavaScript and native comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/with-array.html", "title": "with makes it harder to evolve JavaScript", "content": "with makes it harder to evolve JavaScript dev javascript jslang [1] \nTo see why, let’s look at the following function:\n \nHow? By adding a property to  . For example:\n \nThis is not just a thought experiment, an array method   was recently added to Firefox and broke the TYPO3 content management system. Brandon Benvie ( comment 13 ) figured out what went wrong.\n \n \n JavaScript’s with statement and why it’s deprecated comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/auto-binding.html", "title": "ECMAScript 6: automatically binding extracted methods", "content": "ECMAScript 6: automatically binding extracted methods esnext dev javascript The problem with extracting methods Adding and removing event listeners Binding automatically [1] \nThanks to a  recent decision  by TC39, ECMAScript 6 proxies allow us to fix the problem. We control access to methods via a proxy: If a method is called, the proxy is notified via   and ignores the notification (meaning that the method call will progress normally). If, however, the method’s property is read, the proxy intercepts and binds the method. The following function wraps a proxy around an object.\n \nTo reduce memory consumption, it is best to wrap the proxy around the instance prototype  [2]  of a constructor.\nFor example:\n Sub-constructors Caching bound methods Auto-binding in use Auto-binding and classes A better solution suggested [3] Conclusion \nAs an aside, Python always auto-binds methods. Maybe JavaScript can provide built-in support for it in the future.\n\n References ECMAScript.next: classes JavaScript terminology: the two prototypes Subtyping JavaScript builtins in ECMAScript 5 comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/feeds.html", "title": "Feeds (RSS, Atom) in the time of social media", "content": "Feeds (RSS, Atom) in the time of social media social blogging computers Social media versus feeds The strengths of social media \n     High-volume streams of information. In this setting, you don’t care about missing an item.\n     \n     Spreading news items. If you see an item in one of the streams you are following, Twitter et al. make it simple to share it with your followers: you can insert a reference to it into your own stream. That means that news items spread globally, if enough people find them interesting.  \n     \n     Communication. I especially find Twitter useful for publicly discussing topics, or for finding out what people think about a given topic.\n     \n The stengths of feeds \n     Events (e.g.: “When is the next meeting of user group X?”)\n     \n     Blogs: especially when you don’t want to miss a single blog post. Which is more likely if a blog is low-volume.\n     \n     Podcasts\n     \n     YouTube channels \n \nAs a result of the openness of the standards RSS and Atom, you also get broad support for developers via libraries for parsing, generation, etc. And for users via apps and web services.\n \nLastly, feeds also allow you to take content offline. However, not many feeds have stand-alone items; usually you get a brief summary with a link to the actual content. Hence, I’m usually reading my feeds while I’m online so that I can follow links.\n \nFeeds are less ideal for high-volume channels, where you don’t need to read each item. But maybe those could be supported by limiting how many items are kept (say, a maximum of 100 items) and by not including them in the count of unread items.\n\n \n  Some people want their feed reader application to present them with an automatically generated newspaper, laying out items in a grid, interspersed with images, etc. For tracking things, however, I love the classic email user interface: Three vertical panes, one for folders/tags, one for items, one for the currently selected item. Alas, not many apps have this kind of user interface. For example, as far as I know, the only iOS app that does is  Byline . Alas, it only supports Feedly at the moment.\n\n Life without Google Reader announced Feedbin Alternatives Yoleo \nToday, Google Reader stopped working, it is still possible to download a list with one’s subscriptions until July 15. Let’s take a minute and mourn a great product.\n \n Conclusion Feedbin blog \nTo conclude, the future of feeds looks bright. They complement, rather than compete with, social media. I expect people to come up with new ideas and apps based on feeds.\n\n Related reading The problem with blogs comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/iterators-generators.html", "title": "Iterators and generators in ECMAScript 6", "content": "Iterators and generators in ECMAScript 6 esnext dev javascript Iterables and iterators in ECMAScript 6 \nThe  iterator pattern  enables unified and simple access to the elements stored in data structures.\nGenerators are  . Think: functions that can be suspended and resumed. Among other things, they help with implementing iterators.\n \nThis blog post explains how iterators and generators work in ECMAScript 6. The iterator protocol has  recently  changed, this post explains the new protocol.\n\n \n\n Iterators explicit lazy programming \nSecond, many algorithms (map, filter, etc.) can based on iterators and are decoupled from how data structures store elements.\n\n Iterator protocols \n     Java : iterators have two methods.\n         \n              returns the next element. \n              returns   if there are no more elements. \n         \n     \n     C# : iterators have\n         \n             a property   that returns the current element. \n             a method   that advances the iterator and returns   if iteration has progressed beyond the last element. \n         \n     \n     Python : has a single method.\n         \n             : returns the next element or raises a   exception if there are no further elements. \n         \n        That means that you invoke   until an exception is thrown.\n     \n Returning an element:  After the last element:  Sect. 3.2 Implementing an iterator Iterables The for-of loop Generators \nThe following is a generator function (short: generator). It is written like a normal JavaScript function declaration, but with the keyword   instead of  .\n Using generators for iteration Using generators as lightweight threads task.js task.js When can I use these things? tweet from V8 \nFirefox has had  iterators and generators  for a long time, but they still work slightly differently from the ECMAScript 6 standard.\n \nAdditionally, you can keep an eye on the  ECMAScript 6 compatibility table  to find out how much various engines support.\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/basic-javascript.html", "title": "Basic JavaScript for the impatient programmer", "content": "Basic JavaScript for the impatient programmer dev javascript jslang Speaking JavaScript Basic JavaScript \n Kind words jQuery Enlightenment JavaScript Enlightenment DOM Enlightenment \nThis blog post enables you to   – if you already know how to program.\nIt describes the smallest subset of the language that allows you to be productive. I call that subset “Basic JavaScript” and recommend to program in it for a while, before moving on to more details and advanced topics. Learning everything at once is too confusing. The post concludes with tips for what to  learn next .\n\n \n \nWarning: Below, I’m describing rules of thumbs and best practices. I favor clarity over precision (e.g., whenever you see the word “roughly”). The rules are safe, but – unavoidably – a matter of taste.\n\n Table of contents Conventions used in this blog post The nature of the language Syntax Variables and assignment Values Booleans Numbers Strings Statements Functions Exception handling Strict mode Variable scoping and closures Objects and inheritance Arrays Regular expressions Math Other functionality of the standard library What to learn next? Conventions used in this blog post Command line interaction Finding documentation Mozilla Developer Network mdn array push The nature of the language JavaScript versus ECMAScript being developed Influences very quickly \n     Java is the cause of JavaScript’s syntax and of how it  partitions values  into primitives and objects.\n     \n     Scheme and AWK inspired JavaScript’s handling of functions – they are first-class and used frequently in the language.  Closures  make them a powerful tool.\n     \n     Self is responsible for JavaScript’s unique style of object-oriented programming (OOP). Its  core  (which we can’t go into here) is elegant, some of the things built on top of that core are less so. But a  simple pattern  (shown later) takes care of most use cases. A killer feature of JavaScript OOP is that you can create objects, directly. There is no need to create a class or something similar first.\n     \n     Perl and Python  influenced  JavaScript’s handling of strings, arrays and regular expressions.\n     \n \nOn one hand, JavaScript has quirks and is missing quite a bit of functionality (block-scoped variables, modules, support for subtyping, etc.). On the other hand, it has several powerful features that allow you to work around these problems. In other languages, you learn language features. In JavaScript, you often learn patterns, instead.\n\n Further reading \n     JavaScript: how it all began \n     JavaScript: the glass is half full  [what makes JavaScript appealing?] \n     ECMAScript: ES.next versus ES 6 versus ES Harmony  [includes a brief history of ECMAScript versions] \n     Perl and Python influences in JavaScript \n Syntax Statements versus expressions \n     Statements “do things”. A program is a sequence of statements. Example of a statement, which declares (creates) a variable  :\n \n     \n     Expressions produce values. They are the right-hand side of an assignment, function arguments, etc. Example of an expression:\n \n     \n Control flow statements and blocks Semicolons optional \nAs you can see above, semicolons terminate statements, but not blocks. There is one case where you will see a semicolon after a block: A function expression is an expression that ends with a block. If such an expression comes last in a statement, it is followed by a semicolon:\n Comments Further reading \n     Expressions versus statements in JavaScript \n     Automatic semicolon insertion in JavaScript \n Variables and assignment Assignment Compound assignment operators Identifiers and variable names \nRoughly, the first character of an identifier can be any Unicode letter, a dollar sign ( ) or an underscore ( ). Later characters can additionally be any Unicode digit. Thus, the following are all legal identifiers:\n Further reading \n     Valid JavaScript variable names  [by Mathias Bynens] \n Values Primitive values versus objects \n     The   are: booleans, numbers, strings,  ,  .\n     \n     All other values are  . That is actually how objects are defined – all values that are not primitive.\n     \n Primitive values \n     Booleans :  ,  \n     \n     Numbers :  ,  \n     \n     Strings :  ,  \n     Two “ non-values ”:  ,  \n     \n \n      the “content” is compared.\n \n     \n      the values of properties can’t be changed, no properties can be added or removed.\n \n        (Reading an unknown property always returns  .)\n     \n      you can’t define your own primitives.\n     \n Objects \n     Plain objects  (type  ) can be created by  :\n \n        The above object has two properties: The value of property   is  , the value of property   is  .\n     \n     Arrays  (type  ) can be created by  :\n \n        The above array has three elements that can be accessed via numeric indices. For example, the index of   is 0.\n     \n     Regular expressions  (type  ) can be created by  :\n \n     \n \n      identities are compared, every value has its own identity.\n \n     \n     \n \n     \n      you can define new object types, via  constructors .\n     \n arrays regular expressions undefined and null \n      means “no value”. Uninitialized variables are  :\n \n        If you read a non-existant property, you also get  :\n \n        Missing parameters are  , too:\n \n     \n      means “no object”. It is used as a non-value when an object is expected (parameters, last in a chain of objects, etc.).\n     \n considered  Wrapper types \n     The wrapper type of booleans is  . Booleans get their methods from  :\n \n        Note that the name of the wrapper type starts with a capital  . If the type of booleans was accessible in JavaScript, it would likely be called  .\n     \n     The wrapper type of numbers is  . \n     The wrapper type of strings is  . \n Categorizing values via typeof and instanceof \n  looks like this:\n \nThe following table lists all results of  .\n \n \nTwo things contradict what we have said about primitives versus objects:\n \n     The type of a function is   and not  . Given that   (the type of functions) is a subtype of   (the type of objects), this isn’t wrong.\n     \n     The type of   is  . This is a bug, but one that can’t be fixed, because it would break existing code.\n     \n \n  looks like this:\n Further reading \n     Categorizing values in JavaScript \n     Improving the JavaScript typeof operator \n Booleans \n     Binary logical operators:   (And),   (Or).\n     \n     Prefix logical operator:   (Not)\n     \n     Equality operators:  \n     \n     Ordering operators (for strings and numbers):  \n     \n Truthy and falsy \n     ,  \n     Boolean:  \n     Number:  ,  \n     \n     String:  \n Binary logical operators \n     And: If the first operand is falsy, return it. Otherwise, return the second operand.\n \n     \n     Or: If the first operand is truthy, return it. Otherwise, return the second operand.\n \n     \n Equality operators Further reading \n     Equality in JavaScript: === versus == \n     When is it OK to use == in JavaScript? \n Numbers \n      (“not a number”): an error value.\n \n     \n     : also mostly an error value.\n \n          is sometimes useful, because it is larger than any other number. Similarly,   is smaller than any other number.\n     \n     : JavaScript has  two zeros ,   and  . It normally does not let you see that and displays both as simply  :\n \n        Therefore, it is best to pretend that there is only a single zero (as we have done when we looked at falsy values: both   and   are falsy).\n     \n Operators arithmetic operators \n     Addition:  \n     Subtraction:  \n     Multiplication:  \n     Division:  \n     Remainder:  \n     Increment:  ,  \n     Decrement:  ,  \n     Negate:  \n     Convert to number:  \n \nJavaScript also has operators for  bitwise operations  (e.g. bitwise And).\n\n Further reading series \n     How numbers are encoded in JavaScript \n     JavaScript’s two zeros \n     Integers and shift operators in JavaScript \n     NaN and Infinity in JavaScript \n     Working with large integers in JavaScript \n Strings String operators String methods methods \n Further reading \n     String concatenation in JavaScript \n     JavaScript: single quotes or double quotes? \n Statements Conditionals Loops \n      leaves the loop. \n      starts a new loop iteration. \n Functions \nAnother way of defining   is via a  :\n Function declarations are hoisted hoisted The special variable  Too many or too few arguments later Optional parameters Enforcing an arity Converting   to an array Further reading \n     JavaScript quirk 5: parameter handling \n Exception handling exception handling Further reading \n     Subtyping JavaScript builtins in ECMAScript 5  [especially relevant for errors] \n Strict mode Strict mode Explicit errors  in non-method functions No auto-created global variables Further reading \n     JavaScript’s strict mode: a summary \n Variable scoping and closures recommend Variables are function-scoped Variables are hoisted Closures IIFE: Simulating block scoping Immediately Invoked Function Expression Inadvertent sharing via closures \nClosures keep their connections to outer variables, which is sometimes not what you want:\n Further reading \n     Variable declarations: three rules you can break \n     JavaScript quirk 6: the scope of variables \n     JavaScript quirk 7: inadvertent sharing of variables via closures \n Objects and inheritance all values identifiers Single objects Arbitrary property keys identifiers Extracting methods Functions inside a method Constructors: factories for objects JavaScript inheritance by example \nIn addition to being “real” functions and methods, functions play a third role in JavaScript: They become  , factories for objects, if invoked via the   operator. Constructors are thus a rough analog to classes in other languages.\nBy convention, the names of constructors start with capital letters.\nExample:\n \nTo use  , we invoke it via the   operator:\n Further reading \n     The pitfalls of using objects as maps in JavaScript  [important, read soon] \n     JavaScript inheritance by example \n     Object properties in JavaScript  [advanced: each property has attributes that determine whether it is writable, etc.] \n     Private data for objects in JavaScript \n Arrays Array literals \nProperty   always indicates how many elements an array has.\n Array methods methods Iterating over arrays \n  iterates over an array and hands the current element and its index to a function:\n \n  creates a new array, by applying a function to each element of an existing array.\n Further reading \n     Arrays in JavaScript \n     JavaScript quirk 8: array-like objects \n Regular expressions Method test(): is there a match? Method exec(): match and capture groups a way Method replace(): search and replace a way Further reading \n     JavaScript: an overview of the regular expression API \n     JavaScript Regular Expression Enlightenment  [by Cody Lindley] \n Math Other functionality of the standard library \n     :\n        a constructor for dates whose main functionality is parsing and creating date strings and accessing the components of a date (year, hour, etc.).\n     \n     :\n        an object with functions for parsing and generating JSON data.\n     \n      methods: these browser-specific methods are not part of the language proper, but some of them also work  on Node.js .\n     \n What to learn next? \n     Style guides: I have written a  guide to style guides .\n     \n     Underscore.js : a library that complements JavaScript’s minimalistic standard functionality.\n     \n     JSbooks – free JavaScript books \n     Frontend rescue: how to keep up to date on frontend technologies \n     \n Feedback welcome comments powered by Disqus."},
{"url": "https://2ality.com/2013/11/immediately-invoked.html", "title": "Immediately invoked constructors and object literals", "content": "Immediately invoked constructors and object literals dev javascript jslang [1] Immediately invoked constructors reminded \nObviously, an IIFE is always an alternative to an immediately invoked constructor. It has two advantages: The code should look more familiar and you can use an object literal.\n Immediately invoked object literals [2] \nDepending on your taste, you may prefer an IIFE:\n References JavaScript variable scoping and its pitfalls Expressions versus statements in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/10/dict-pattern.html", "title": "The dict pattern: objects without prototypes are better maps", "content": "The dict pattern: objects without prototypes are better maps dev javascript jslang The pitfalls Inherited properties prevent you from directly using the   operator for checking for a key and brackets for reading a value:\n \n     Map entries override methods, meaning that you can’t directly invoke methods on an object-as-map.\n     You need to escape the key  , because it triggers special behavior in many JavaScript engines.\n     The pitfalls of using objects as maps in JavaScript The dict pattern Normal objects Prototype-less objects are better maps \n     Inherited properties (pitfall #1) are not an issue, any more, simply because there are none. Therefore, you can now freely use the   operator to detect whether a property exists and brackets to read properties.\n     \n     Soon:   is disabled. In ECMAScript 6, the special property   will be disabled if Object.prototype is not in the prototype chain of an object. You can expect JavaScript engines to slowly migrate to this behavior, but it is not yet very common.\n     \n Best practice: use a library [1] Reference The pitfalls of using objects as maps in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/06/chrome-omnibox-search.html", "title": "Searching websites and evaluating JavaScript via Chrome’s omnibox", "content": "Searching websites and evaluating JavaScript via Chrome’s omnibox browser computers chrome Managing search engines \nNext to the drop-down list with the defaults, there is the button “Manage search engines...”, which is where things get interesting. First there is a list with “default search engines” (the ones in the drop-down list), then there is a list with “other search engines”. You can add new search engines to the latter and then move them to the former by clicking the “Make default” button that appears when you hover over an appropriate item.\n \nA search engine entry has three fields: A name, a keyword and a URL. The keyword is an abbreviation for the URL, the URL can contain the placeholder string “ ” where Chrome fills in what you have typed in order to perform a query. Lets try this out and add the following search engine to “other search engines”:\n \n     Name: Vimeo \n     Keyword: vi \n     URL: http://vimeo.com/search?q=%s \n \n \nThen Chrome tells us to hit Tab, after which we can enter a query:\n \n \nChrome also recognizes when you are typing the beginning of a keyword, so you can choose a longer one, if you want to (caveat: not always reliable when several keywords start with the same characters). Google’s  documentation  says that normal URLs work, too, but that wasn’t the case for my Chrome.\n \nNote that Firefox has had this feature for a long time  [1] . You can turn any bookmark into a search engine by assigning it a keyword. This has the added advantage that you can organize your keyword bookmarks in folders.\n\n Automatically adding a web site to Chrome’s search engines OpenSearch \nYou can go to   to see a real-world example. After you have visited that web site, there is an entry for it in your “other search engines”.\n\n Evaluate JavaScript via a keyword [2] \n     Name: Evaluate \n     Keyword: eval \n     URL:  \n References Browser keywords: using the address bar as a command line Tip: use JavaScript as a calculator in Firefox and Chrome comments powered by Disqus."},
{"url": "https://2ality.com/2013/10/typeof-null.html", "title": "The history of “typeof null”", "content": "The history of “typeof null” dev javascript jslang jshistory \nIn JavaScript,   is  , which incorrectly suggests that   is an object (it isn’t, it’s a primitive value, consult my blog post on  categorizing values  for details). This is a bug and one that unfortunately can’t be fixed, because it would break existing code. Let’s explore the history of this bug.\n\n \n\n \n\nThe “typeof null” bug is a remnant from the first version of JavaScript. In this version, values were stored in 32 bit units, which consisted of a small type tag (1–3 bits) and the actual data of the value. The type tags were stored in the lower bits of the units. There were five of them:\n \n     000: object. The data is a reference to an object.\n     \n     1: int. The data is a 31 bit signed integer.\n     \n     010: double. The data is a reference to a double floating point number.\n     \n     100: string. The data is a reference to a string.\n     \n     110: boolean. The data is a boolean.\n     \n \nTwo values were special:\n \n      ( ) was the integer −2  (a number outside the integer range).\n     \n      ( ) was the machine code NULL pointer. Or: an object type tag plus a reference that is zero.\n     \n \n     At (1), the engine first checks whether the value   is   ( ). This check is performed by comparing the value via equals:\n \n     \n     The next check (2) is whether the value has an object tag. If it additionally is either callable (3) or its internal property [[Class]] marks it as a function (4) then   is a function. Otherwise, it is an object. This is the result that is produced by  .\n     \n     The subsequent checks are for number, string and boolean. There is not even an explicit check for  , which could be performed by the following C macro.\n \n     \n \n  Thanks to Tom Schuster ( @evilpies ) for  pointing  me to the classic JavaScript  source code .\n\n\n \n\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/11/es6-modules-browsers.html", "title": "ECMAScript 6 modules in future browsers", "content": "ECMAScript 6 modules in future browsers esnext dev javascript jsmodules clientjs Status Report: ES6 Modules \n [1]  is an introduction to ECMAScript 6 modules and how they can be used in current browsers. In contrast, this blog post explains how future browsers will support them natively. As part of that support, we will get the   tag, a better version of the   tag.\n\n \n\n Browsers: asynchronous modules, synchronous scripts Load modules synchronously, while the body is executed. That is what Node.js does.\n     Load all modules asynchronously, before the body is executed. That is how AMD modules are handled. It is the only option for browsers, because modules are loaded over the internet. Otherwise, execution would pause for too long. As an added benefit, this approach allows one to load multiple modules in parallel.\n     \n  Scripts are normally loaded or executed synchronously. The JavaScript thread stops until the code has been loaded or executed.\n\n ECMAScript 6 modules in browsers \nGiven the synchronicity of scripts, it is obvious that you can’t simply add import and export capability and turn them into modules. There must be a way to handle module code differently. Therefore, there will be a new tag   for modules that replaces the   tag and is completely asynchronous:\n\n [2] \nSimilar to  ,   can also be used to load external modules. For example, the following tag starts a web application via a   module (the attribute name   is my invention, it isn’t yet clear what name will be used).\n [3] Bundling \nOne candidate for the separator is  . With this separator, a URL that refers to a file   inside a package looks like this:\n \n     Old browsers send separate requests for each file in a package.\n     \n     New browsers download the package once and afterwards extract files as necessary.\n     \n     Old servers store both separate files and the package and serve either one, depending on what browsers request.\n     \n     New servers could create the package on demand.\n     \n \nIntriguingly, packages could become a cross-browser format for archiving web pages (including images, CSS, etc.).\n \nHow to best set up modules to be loaded from a package is still being worked out. At the very least you can plug into the  module loader API  and set it up manually.\n\n Conclusion \nIn its inline version, the   tag nicely cleans up the problematic   tag:\n \n      Strict mode is on by default, avoiding the visual clutter of  \n     The code runs asynchronously.\n     \n     The code runs in its own scope, there is no danger of polluting the global scope.\n     \n Sources of this post \n     “ Modules: Status Update ”, slides by David Herman.\n     \n     “ Modules vs Scripts ”, an email by David Herman.\n     \n     “ Packages ”, a Gist by Yehuda Katz.\n     \n References ECMAScript 6 modules: the future is now JavaScript’s strict mode: a summary What is the difference between a shim and a polyfill? comments powered by Disqus."},
{"url": "https://2ality.com/2013/11/initializing-arrays.html", "title": "Initializing an array with values", "content": "Initializing an array with values dev javascript jslang jsarrays [1] \nLet us start with something simple: producing an array of length   whose first element is 0, second element is 1, etc.\n\n Array.prototype.map() [2] Filling an array via apply() [3] _.range() Underscore.js Setting up multi-dimensional arrays \nLet’s use   to set up a matrix for Tic-tac-toe. We initialize all arrays correctly:\n References Arrays in JavaScript Array iteration and holes in JavaScript Apply and arrays: three tricks comments powered by Disqus."},
{"url": "https://2ality.com/2013/12/strict-mode-in-node-repl.html", "title": "Using strict mode in the Node.js REPL", "content": "Using strict mode in the Node.js REPL dev nodejs javascript [1] Node.js REPL \n  Start the REPL as usual, wrap your code in an IIFE  [2] :\n \n  Use the Node.js command line option  :\n \n \n JavaScript’s strict mode: a summary JavaScript variable scoping and its pitfalls comments powered by Disqus."},
{"url": "https://2ality.com/2013/12/paralleljs.html", "title": "ParallelJS: data parallelism for JavaScript", "content": "ParallelJS: data parallelism for JavaScript jsfuture dev javascript concurrency \n     [2015-01-05]  . It apparently wasn’t powerful enough.  Its experimental implementation will be removed  from SpiderMonkey (Firefox’s JavaScript engine).\n     \n     [2013-12-28] A low-level  JavaScript API for SIMD  is another avenue for parallelization (within a single processer core).\n     \n Background Concurrency versus parallelism \n      more than one task is executed at the same time. That means that the tasks run on different processors or processor cores.\n     \n      more than one task makes progress at the same time. Often, tasks depend on each other. Concurrent tasks may run in parallel, but they can also be run via time slicing (virtual parallelism, if you will).\n     \n Kinds of parallelism \n      The same piece of code is executed several times in parallel. The instances operate on different elements of the same dataset. For example: MapReduce is a data-parallel programming model.\n     \n      Different pieces of code are executed in parallel. Examples:  Web Workers  and the Unix model of spawning processes.\n     \n ParallelJS (PJS) River Trail \nParallelJS brings the RiverTrail idea to normal arrays and has recently  been included  in Firefox Nightly. It adds three methods to arrays (binary data will eventually get those methods, too):\n \n     \n     \n     \n \n     It must not mutate shared data. It can freely change data that it has created, but can only read data from the outside world.\n     \n     Many host (or “native”) objects can’t be used. That includes the DOM, which may never be supported and regular expressions for which short- to mid-term support is likely. All vanilla JavaScript objects are fine, though.\n     \n \nThe rules for when PJS code can be run concurrently will probably never be standardized, because a PJS standard needs to accomodate a variety of implementation approaches (see below). There will, however, be guidelines and recommendations for what works for most implementations.\n \nGiven how difficult it is to predict whether your code can be run concurrently or not, an important part of PJS will be diagnostic tools. They will let you find out when and why code is not parallelizable.\n \nParallelJS is currently tentatively scheduled for ECMAScript 8. If you are worried that that’s too far into the future: ECMAScript 7 and ECMAScript 8 will be smaller and developed more quickly than ECMAScript 6.\n\n Modes of execution Sequentially: a shim can make the PJS array methods available on older engines\n     Concurrently: run multiple instances of the callback concurrently. The operating system can distribute those instances across cores.\n     SIMD: use SIMD processor instructions (such as Intel’s  SSE ) for faster processing.\n     GPU: run vectorized code, but on the GPU instead of the CPU.\n     Task parallelism task parallelism Sources \n     ParallelJS status quo and future: “ PJS Roadmap ”\n     \n     What ParallelJS code can be parallelized: “ Parallelizable JavaScript Subset ”\n     \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/12/dom-arrays.html", "title": "Why are there so many array-like objects in the DOM?", "content": "Why are there so many array-like objects in the DOM? dev javascript clientjs jshistory Tweet \n     ECMAScript 1 does have arrays, but it corresponds to JavaScript 1.3.\n        JavaScript version numbers apply to the JavaScript engines implemented by Netscape/Mozilla. The cross-engine way of referring to the capabilities of the language are thus ECMAScript versions.\n     \n     Arrays were indeed added after JavaScript 1, as  this page  shows, which lists the additions for version 1.1.\n     \n \n     JavaScript quirk 8: array-like objects \n     Arrays in JavaScript \n comments powered by Disqus."},
{"url": "https://2ality.com/2013/12/array-prototype-find.html", "title": "ECMAScript 6: the new array methods find() and findIndex()", "content": "ECMAScript 6: the new array methods find() and findIndex() esnext dev javascript ECMAScript 6’s new array methods \nTwo new Array methods (proposed by Rick Waldron) are in the latest ECMAScript 6 specification draft:\n \n     \n     \n Array.prototype.find(predicate, thisValue?) \nThis method could be implemented as follows.\n Array.prototype.findIndex(predicate, thisValue?) Finding NaN via findIndex() [1] [2] Availability ECMAScript 6 compatibility table \nFurthermore, Paul Millr’s  es6-shim  has backported the methods to ECMAScript 5.\n\n References NaN and Infinity in JavaScript Stricter equality in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/12/simd-js.html", "title": "JavaScript gains support for SIMD", "content": "JavaScript gains support for SIMD jsfuture asmjs dev javascript concurrency a proposal for SIMD.js \n\n Recently , a new JavaScript feature has  landed  for the next Firefox Nightly: an API for   (Single Instruction, Multiple Data). This blog post explains how the API works and how it fits into the JavaScript landscape.\n\n \n\n What is SIMD? \nJohn McCutchan (Google) and Peter Jensen (Intel) have proposed a JavaScript API for SIMD. That API initially grew out of the  SIMD support  in Dart, because Dart SIMD code needed to be compiled to JavaScript.\n \nAt the moment, the API provides two data types:\n \n      (C type: __m128): four 32 bit floating point numbers. \n      (C type: __m128i): four 32 bit unsigned integers. \n \n \nApart from the aforementioned native implementation in Firefox, the API has also  been implemented  in vanilla JavaScript, based on  typed arrays . The source of the latter is well documented, so you can use it look up all operators that the API supports.\n\n How does the SIMD API fit into the JavaScript landscape?  for hand-optimized code and for compiling to JavaScript.\n      that works across a wide variety of processor architectures.\n     [1] following goal supported [2] \nWhat about the second use case? Here, ParallelJS  [3]  shines. It isn’t tied to specific vector sizes or vector element sizes. And it will probably eventually even be able to produce GPU code.\n \nLastly, I find it interesting how strongly Intel is interested in adding SIMD support to JavaScript. They helped Mozilla’s Niko Matsakis with implementing SIMD for Firefox and they are  reportedly  doing the same for Google’s V8 JavaScript engine. One reason is probably that they want JavaScript to run well on their mobile operating system  Tizen .\n \nThe SIMD API won’t be in ECMAScript 6, but will probably be included in either ECMAScript 7 or ECMAScript 8.\n\n Further reading \n     “ Optimizing SIMD [on Firefox] ” by Niko Matsakis (there is also a  follow-up post ). \n References A JavaScript glossary: ECMAScript, TC39, etc. asm.js: closing the gap between JavaScript and native ParallelJS: data parallelism for JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/for-loop-performance.html", "title": "Performance optimizations and for loops", "content": "Performance optimizations and for loops dev javascript jslang Performance optimizations? measure \n     The canonical way performs roughly as well as the optimized versions, with a few notable exceptions. \n     Caching the length while counting up is never slower than not caching it. \n     Counting down behaves unpredicatably: It can be faster or slower than counting up. \n     As expected,   is much slower than a   loop. \n Array.prototype.forEach [1] ECMAScript 6 [2] [2] Recommendations \nSimilarly, don’t be needlessly clever with your code. Usually, it’s more important that your code is easy to understand and correct than that it is fast.\nJavaScript engines automatically optimize more and more of the established patterns, which means that you have to have a good reason for veering off the established path.\n \nI find   loops easier to understand than   loops. I suspect that JavaScript engines can and will optimize their execution even further in the future.\n \nTo me, it is important to keep code as local as possible. Hence, I like to declare variables inside a loop that are only used there. This is a bit more controversial, but it does not normally incur a performance penality  [3] .\n\n References JavaScript quirk 7: inadvertent sharing of variables via closures Iterators and generators in ECMAScript 6 Variable declarations: three rules you can break comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/hello-polymer.html", "title": "Hello Polymer: Q&A with Google’s Polymer team", "content": "Hello Polymer: Q&A with Google’s Polymer team dev html5 javascript webcomponents google polymer webdev online event \nThe actual video of the event starts at  2:40 .\n\n Goals and nature of the project [1] \nThe following diagram describes the architecture of Polymer:\n \n \n \n     : The red parts are shims  [2]  for upcoming APIs. These shims will be used by most frameworks in the future and eventually be replaced by native APIs.\n     \n     : The yellow parts express a taste in frameworks – how the foundational APIs should be combined. It is but one of many ways of doing so.\n     \n     The green parts are Polymer elements, web components built on top of  . Not all elements display something on screen. For example, the element  . The  Polymer documentation  lists all elements that are currently available. The plan for Polymer UI elements is to make Google’s design skills (as, e.g., demonstrated by the Maps app on Android and iOS) readily available on the web.\n     \n Polymer’s philosophy \n     Embrace HTML. Everything is a custom element (even non-visual components). \n     Leverage the evolving web platform: get smaller and better over time. \n     Minimize boilerplate code:\n         \n             Remove the tediousness of building web apps (natively). \n             Provide a feedback to to web platform standards. \n         \n     \n     “Salt to taste”: Polymer is designed to be à la carte. Every framework can pick and choose what it needs. Web components will provide a thriving ecosystem for everyone. That’s why the Polymer stack is layered.\n     \n Demo 15:07 \n     Create a custom element in a text editor. \n     Look at the element in the (still very basic) GUI editor “Pica”. \n     Use data binding (  is a YouTube component):\n \n     \n Questions and answers 21:45 \n     \n         \n        It’s main goal is to bootstrap an ecosystem around web components. Everyone will profit from the powerful widgets created as part of the project. Framework authors can use what they want from Polymer and ignore the rest.\n         \n        Additionally, the Polymer team wants to figure out how to best use the new APIs and to help people with them. Polymer is work in progress. While there are people on the team that have much experience with various frameworks, the setting of Polymer is completely new. All of a sudden the DOM is the framework. As a consequence, if something doesn’t work like it should, the team gives feedback to standards bodies and tries to fix it. The mission of Polymer could be described as “help build the web of tomorrow”.\n     \n     \n         \n        Polymer is still pre-alpha! But there is much interest from within Google and from framework authors.\n     \n     \n         \n        Polymer works on the latest versions of all browsers (Chrome, Firefox, Internet Explorer, etc.). Older browsers are ignored. Polyfilling on them is simply too difficult and Polymer needs to look ahead in order to make progress. Some things can’t be polyfilled perfectly on all browsers yet (e.g. the encapsulation provided by the Shadow DOM), which means that Polymer has to compromise and/or wait for browsers to catch up.\n     \n     \n         \n        Yes you can. Polymer [as opposed to  ] is a very thin layer that will get even thinner over time.\n     \n     \n         \n        You don’t want to break existing content if you add new tags to HTML. Thus, the names of the latter tags will never have dashes in them. The original rules for the names of custom elements were more complicated (a prefix   was required), but the Polymer team figured out a simpler way and gave feedback to standards bodies.\n     \n     \n         \n        It has nothing to do with AngularJS (and  ), it’s simply an example of a custom tag.\n     \n     \n         \n        AngularJS taught people how to think declaratively. Web components are framework-independent. The only thing that is tricky is to combine Polymer with another framework   a web component.\n         \n        [Additionally, AngularJS and Ember.js have announced their migration strategies towards web components  [3] .]\n     \n     \n         \n        It’s still too early, but first experiments have started.\n     \n References Google’s Polymer and the future of web UI frameworks What is the difference between a shim and a polyfill? Plans for supporting Web Components in AngularJS and Ember.js comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/trailing-commas.html", "title": "Trailing commas in object literals and array literals", "content": "Trailing commas in object literals and array literals dev javascript jslang Trailing commas in object literals Trailing commas in array literals [1] Trailing commas in JSON [2] What browsers support object literals with trailing commas? compatibility table References Arrays in JavaScript JavaScript’s JSON API comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/meta-style-guide.html", "title": "A meta style guide for JavaScript", "content": "A meta style guide for JavaScript dev javascript jslang Existing style guides \n     Idiomatic.js: Principles of Writing Consistent, Idiomatic JavaScript \n     Google JavaScript Style Guide \n \n   Popular Conventions on GitHub : analyzes GitHub code to find out which coding conventions are most frequently used.\n   \n   JavaScript, the winning style : examines what the majority of several popular style guides is recommending.\n   \n General tips Code should be consistent \n     How much whitespace (after parentheses, between statements etc.) \n     Indentation (e.g.: how many spaces per level of indentation) \n     How and where to write   statements \n Code should be easy to understand \n \nSometimes writing   means that things are actually faster to read. Two examples: First, familiar things are easier to understand. That can mean that using familiar, slightly more verbose, constructs can be preferable. Second, humans read tokens, not characters. Therefore,   is easier to read than  .\n \n  Most code bases are filled with new ideas and concepts. That means that if you want to work with a code base, you need to learn those ideas and concepts. In contrast with textbooks, the added challenge with code is that people will not read it linearly. They will jump in anywhere and should be able to roughly understand what is going on.\nThree parts of a code base help:\n \n     Code: should explain   is happening, it should be self-explanatory. To write such code, use descriptive identifiers and break up long functions (or methods) into smaller sub-functions. If those functions are small enough and have meaningful names, you can often avoid comments.\n     \n     Comments: should explain   things are happening. If you need to know a concept to understand the code, you can either include the name of the concept in an identifier or mention it in a comment. Someone reading the code can then turn to the documentation to find out more about the concept.\n     \n     Documentation: should fill in the blanks left by the code and the comments. It should tell you how to get started with the code base and provide you with the big picture. It should also contain a glossary for all important concepts.\n     \n \n  There is a lot of clever code out there that uses in-depth knowledge of the language to achieve impressive terseness. Such code is usually like a puzzle and difficult to figure out. One does encounter the opinion that if people don’t understand such code, maybe they should really learn JavaScript first. But that’s not what this is about. No matter how clever you are, entering other people’s mental universes is always challenging. So simple code is not “stupid code”, it’s code where most of the effort went into making everything easy to understand. Note that “other people” includes your past selves. I often find that clever thoughts I had in the past don’t make sense to my present self.\n \n  Much cleverness is directed at these optimizations. However, you normally don’t need them. On one hand, JavaScript engines are becoming increasingly smart and automatically optimize the speed of code that follows established patterns. On the other hand, minification tools rewrite your code so that it is as small as possible. In both cases, tools are clever for you, so that you don’t have to be.\n \nSometimes you have no choice but to optimize the performance of your code. If you do, be sure to measure and optimize the right pieces. In browsers, the problems are often related to DOM and HTML and not the language proper.\n\n Commonly accepted best practices \n     Use strict mode  [1] . It prevents several problems.\n     \n     Always use semicolons. Avoid the pitfalls of automatic semicolon insertion  [2] . \n     Always use strict equality ( ) and strict inequality ( ). I recommend to always obey this rule  [3] . I even prefer the first of the following two conditions, even though they are equivalent:\n \n     \n     Always use braces (  statements and loops). If an   statement doesn’t have an   clause and can be written in a single line, I omit the braces.\n     \n     Use the One True Bace Style  [4]  (the opening brace starts in the same line as the statement it belongs to).\n     \n     Indentation: either use only spaces or only tabs for indentation, but don’t mix them.\n     \n     Quoting strings  [5] : You can write string literals with either single quotes or double quotes in JavaScript. Single quotes are slightly more common. They make it easier to work with HTML code (which normally has attribute values in double quotes). On the other hand, several other languages (C, Java, etc.) only have double-quoted strings (meaning that they look more familiar in JavaScript code). Furthermore, with the JSON format, you don’t have a choice, you have to double-quote strings.\n     \n Prefer literals to constructors [6] Don’t be clever \n  Don’t nest the conditional operator.\n \n  If possible, use the increment operator ( ) and the decrement operator ( ) as statements, don’t use them as expressions. In the latter case, they return a value and while there is a mnemonic (if the operand comes first, its value is returned before incrementing/decrementing it), you still need to think to figure out what is going on:\n Acceptable cleverness \n  Using the Or ( ) operator to assign default values to parameters is a common practice:\n [7] Controversial rules Syntax \n  Most code I am seeing uses spaces for indentation, because tabs are displayed so differently between applications and operating systems. I prefer 4 spaces per level of indentation, because that makes the indentation more visible.\n \n  I don’t declare multiple variables with a single declaration.\n [8] \n  If your function isn’t too long (which it shouldn’t be, anyway) then you can afford to be less careful w.r.t. hoisting and pretend that   declarations are block-scoped.\nThat is, you can declare a variable in the context in which it is used (inside a loop  [8] , inside a then-block or an else-block, etc.). This kind of local encapsulation makes a code fragment easier to understand in isolation. Is is also easier to remove the code fragment or to move it somewhere else.\n \n  This helps with reading, because it is easier to make out the scopes of the operators. Two examples:\n Object-orientation [9] \n     always use constructors \n     always use   when creating an instance \n \n     Your code better fits into the JavaScript mainstream and is more likely to be portable between frameworks.\n     \n     Speed advantages. In modern engines, using instances of constructors is very fast (e.g. via  hidden classes ).\n     \n     Classes, the default inheritance construct in ECMAScript 6 (see below), will be based on constructors.\n     \n \n  If you want an object’s private data to be completely safe, you have to use closures. Otherwise, you can use normal properties  [10] . One common practice is to prefix the names of private properties with underscores. The problem with closures is that code becomes more complicated (unless you put all methods in the instance, which is unidiomatic and slow) and slower (accessing data in closures is currently slower than accessing properties).\n \n  I find that such a constructor invocation looks cleaner with parentheses.\n Miscellaneous \n    should only refer to the receiver of the current method invocation, it should not be abused as an implicit parameter. Rationale: such functions are easier to call and you can later switch to ECMAScript 6’s arrow functions  [11] . More abstractly, I like to keep object-oriented and functional mechanisms separate.\n \n  This is more self-explanatory and safer than comparing with   or checking for truthiness.\n \n \n \n  If you can, it’s best to fail fast and to not fail silently. JavaScript is only so forgiving (division by zero etc.), because the first version of ECMAScript did not have exceptions. For example: don’t coerce values, throw an exception. However, you have to find a way to recover gracefully from failure when your code is in production.\n\n Conclusion References JavaScript’s strict mode: a summary Automatic semicolon insertion in JavaScript When is it OK to use == in JavaScript? Brace styles and JavaScript JavaScript: single quotes or double quotes? Arrays in JavaScript  [explains that the array constructor is only safe if you call it with a single argument – a non-negative integer] Trailing commas in object literals and array literals Variable declarations: three rules you can break In defense of JavaScript’s constructors Private data for objects in JavaScript ECMAScript.next: arrow functions and method definitions comments powered by Disqus."},
{"url": "https://2ality.com/2013/08/javascript-resource-directories.html", "title": "Directories for JavaScript resources", "content": "Directories for JavaScript resources dev javascript jslib asked \nI was only aware of the following two directories:\n \n     “ JSDB : a collection of the best JavaScript libraries”\n     \n     “ Microjs : fantastic micro-frameworks and micro-libraries for fun and profit”\n     \n \n     “ JavaScriptOO : every JavaScript project you should be looking into” (via @getify).\n     \n     “ JSter : a catalog of JavaScript libraries and tools for web development” (via @check_ca) \n     “ Unheap : a tidy repository of jQuery plugins” (via @fredrik_sogaard)\n     \n     “ Master List of HTML5, JavaScript, and CSS Resources ” by Gene Loparco\n     \n \n     npm (Node Packaged Modules) \n     Bower \n [1] \n     jsDelivr : free CDNs for JavaScript libraries, jQuery plugins, CSS frameworks, fonts and more \n     “ cdnjs : the missing CDN” [hosts less popular libraries]\n     \n \n     “ The Toolbox : a directory of the best time-saving apps and tools” (via @elijahmanor) \n \n \n Let a big company host your JavaScript libraries comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/defending-constructors.html", "title": "In defense of JavaScript’s constructors", "content": "In defense of JavaScript’s constructors dev javascript jslang doesn’t like them Kyle Simpson Eric Elliott \nIn this blog post, I explain that not all of the constructors’ flaws are real. But even with those that are real, I still recommend to use them. I’ll tell you why and what the future holds for constructors.\n\n \n\n Recommendations \n     always use constructors \n     always use   when creating an instance \n \n     Your code better fits into the JavaScript mainstream and is more likely to be portable between frameworks.\n     \n     Speed advantages. In modern engines, using instances of constructors is very fast (e.g. via  hidden classes ).\n     \n     Classes, the default inheritance construct in ECMAScript 6 (see below), will be based on constructors.\n     \n Why not make   optional? But built-in constructors allow me to omit  But I want to spread [1] Protecting against accidentally omitting  Protection via strict mode [2] Protection via lint tools But constructors can only produce direct instances factory constructors [3] Can‘t we do better than constructors? Proto.js \n \nSo far, the JavaScript community has not agreed on a common inheritance library (which would help tooling and code portability) and it is doubtful that that will ever happen.\nThat means, we’re stuck with constructors under ECMAScript 5.\n\n Is there no way to at least ease some of the constructor pain? \nThe most pressing constructor pain point is subclassing. Node.js has the utility function   that only tackles subclassing, nothing else (e.g., it does not help with defining constructors).\nI’d love this function to be ported to browsers (preferably via a  UMD module ) and gain widespread use everywhere.\n\n ECMAScript 6: the future of constructors [4] \nES6 classes internally desugar to constructors. This is not optimal, because the sugared version looks quite different from the desugared version. That is bound to surprise people in the future when they are trying to find out how classes actually work. In contrast, prototypal inheritance is a much better match for the structure of classes. Hence, desugaring them to something prototypal would have been cleaner.\n \nOn the other hand, backward compatibility is a strong reason in favor of constructors. And one of the main goals for classes was to make them as lightweight as possible.\nTherefore, even though I’m not completely happy with classes, I think they are the best currently possible solution and an important part of ES6 that deserves everyone’s support.\n\n Don’t ES6 classes prevent multiple inheritance? Conclusion \nUnder ECMAScript 6, using classes  [4]  is the obvious choice. They help with subclassing, let you subclass built-in constructors  [5]  and more.\n \nBoth solutions are compromises, but especially classes will make JavaScript a friendlier language and unify a currently very divided inheritance landscape. Many custom inheritance APIs have been created to help with data binding. ECMAScript 7 will remove this last reason for custom APIs via built-in support for data binding, via  .\n\n References Spreading arrays into arguments in JavaScript JavaScript’s strict mode: a summary Exemplar patterns in JavaScript ECMAScript.next: classes Subclassing builtins in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/es6-modules.html", "title": "ECMAScript 6 modules: the future is now", "content": "ECMAScript 6 modules: the future is now esnext dev javascript jsmodules ECMAScript 6 modules: the final syntax \nThis blog post first explains how modules work in ECMAScript 6, the next version of JavaScript. It then describes tools that allow you to already use them now.\n\n \n\n \n Module systems for current JavaScript \n     CommonJS Modules (CJS): The dominant incarnation of this standard is  Node.js modules  (Node.js modules have a few features that go beyond CJS). Characteristics:\n         \n             Compact syntax \n             Designed for synchronous loading \n             Main use: server \n         \n     \n     Asynchronous Module Definition (AMD): The most popular implementation of this standard is  RequireJS . Characteristics:\n         \n             Slightly more complicated syntax, enabling AMD to work without   (or a compilation step).\n             \n             Designed for asynchronous loading \n             Main use: browsers \n         \n     \n Writing Modular JavaScript With AMD, CommonJS & ES Harmony ECMAScript 6 modules ECMAScript 6 (ES6) modules \n     You get compile time errors if you try to import something that has not been exported. \n     You can easily load ES6 modules asynchronously. \n \n     Declarative syntax (for importing and exporting).\n     \n     Programmatic loader API: to configure how modules are loaded and to conditionally load modules.\n     \n ECMAScript 6 module syntax Exporting [1] \nNote that this syntax is quite convenient. In Node.js modules (AMD is similar), you have two options. Option 1: be redundant.\n An alternative to inlined exports Importing Re-exporting Default exports ECMAScript 6 module loader API programmatic API Importing modules and loading scripts \n  works similarly to  , but loads script files instead of importing modules.\n\n Configuring module loading \n     Customize how module IDs are mapped to module files.\n     \n     Lint modules on import (e.g. via JSLint or JSHint).\n     \n     Automatically translate modules on import (they could contain CoffeeScript or TypeScript code).\n     \n     Use legacy modules (AMD, Node.js).\n     \n Using ECMAScript 6 modules today \n     ES6 Module Transpiler : write your modules using a subset of ECMAScript 6 (roughly: ECMAScript 5 +   +  ), compile them to AMD or CommonJS modules. A  blog post  by Ryan Florence explains this approach in detail.\n     \n     ES6 Module Loader : polyfills the ECMAScript 6 module loader API on current browsers. To enter the world of modules, you use the API:\n \n        In actual modules, you use ECMAScript 5 +   +  . For example:\n \n        The project  jspm loader  builds on the ES6 Module Loader and enables you to load AMD modules and CJS modules in addition to ES6 modules.\n     \n \n     require-hm : a plugin for RequireJS allowing it to load ECMAScript 6 modules (only ECMAScript 5 plus importing and exporting is supported). A  blog post  by Caolan McMahon explains how it works. Warning: uses an older module syntax.\n     \n     Traceur  (an ECMAScript 6 to ECMAScript 5 compiler): has partial support for modules and may eventually support them fully.\n     \n     TypeScript  (roughly: ECMAScript 6 plus optional static typing): compiles modules in external files (which can use most of ECMAScript 6) to AMD or CommonJS.\n     \n Further reading \n     The specification of ECMAScript 6 modules: Modules are not yet in the  draft ECMAScript 6 specification . Until they are, consult the  Harmony wiki  for details.\n     \n     “ ES6 Modules ” by Yehuda Katz: a discussion of common use cases and interoperability with existing module systems.\n     \n References ECMAScript.next: classes JavaScript quirk 6: the scope of variables comments powered by Disqus."},
{"url": "https://2ality.com/2013/07/array-iteration-holes.html", "title": "Array iteration and holes in JavaScript", "content": "Array iteration and holes in JavaScript dev javascript jslang jsarrays [1] Running example Preliminaries Trailing holes Copying arrays Array methods Other array methods Loops Function.prototype.apply() [1] Conclusion and recommendation Further reading “ JavaScript: sparse arrays vs. dense arrays ”\n         \n        What are holes and how do they differ from elements that are  ?\n     “ Iterating over arrays and objects in JavaScript ”\n         \n        General information on iterating over arrays.\n     comments powered by Disqus."},
{"url": "https://2ality.com/2013/08/protecting-objects.html", "title": "Protecting objects in JavaScript", "content": "Protecting objects in JavaScript dev javascript jslang Preventing extensions is the weakest level, sealing is stronger, freezing is strongest. Preventing extension Object.preventExtensions(obj) [1] [2] Checking whether an object is extensible Object.isExtensible(obj) Sealing Object.seal(obj) [3] \n(As an aside, JavaScript does allow you to change an unconfigurable property from writable to read-only, due to  historical reasons .)\n \nThe following example demonstrates that sealing makes all properties unconfigurable.\n Checking whether an object is sealed Object.isSealed(obj) Freezing Object.freeze(obj) Checking whether an object is frozen Object.isFrozen(obj) References JavaScript’s strict mode: a summary JavaScript variable scoping and its pitfalls Object properties in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/09/types.html", "title": "JavaScript’s type system", "content": "JavaScript’s type system dev javascript jslang JavaScript’s types Chap. 8 \n         Undefined, \n         Null, \n         Boolean, \n         String, \n         Number, and \n         Object. \n     Static versus dynamic Static typing versus dynamic typing \nEven in statically typed languages, a variable (etc.) also has a dynamic type, the type of the variable’s value at a given time at runtime. The dynamic type can differ from the static type. For example (Java):\n \nJavaScript is dynamically typed, types of variables are generally not known at compile time.\n\n Static type checking versus dynamic type checking \nJavaScript performs a very limited kind of dynamic type checking,\n Coercion [1] Don’t use: strongly typed, weakly typed generally useful definitions Reference Categorizing values in JavaScript comments powered by Disqus."},
{"url": "https://2ality.com/2013/08/regexp-g.html", "title": "The flag /g of JavaScript’s regular expressions", "content": "The flag /g of JavaScript’s regular expressions dev javascript jslang regexp [1] The flag   of regular expressions RegExp.prototype.test(): determining whether there is a match String.prototype.search(): finding the index of a match RegExp.prototype.exec(): capturing groups, optionally repeatedly [1] String.prototype.match():  replace(): search and replace The problem with the   flag \n     \n     \n \n     You can’t inline the regular expression when you call those methods. For example:\n \n        The above loop is infinite, because a new regular expression is created for each loop iteration, which restarts the iteration over the results. Therefore, the above code must be rewritten:\n \n        Note: it’s a best practice not to inline, anyway, but you have to be aware that you can’t do it, not even in quick hacks.\n     \n     Code that wants to invoke   and   multiple times must be careful with regular expressions handed to it as a parameter. Their flag   must be set and it must reset their  .\n     \n Example: counting occurrences Using match() to count occurrences Performance considerations Juan Ignacio Dopazo compared Acknowledgements Mathias Bynens Juan Ignacio Dopazo Šime Vidas Reference JavaScript: an overview of the regular expression API comments powered by Disqus."},
{"url": "https://2ality.com/2013/09/osx-kill-chrome-tabs.html", "title": "OS X: kill all Google Chrome tabs from the shell", "content": "OS X: kill all Google Chrome tabs from the shell browser chrome mac Sindre Sorhus \nI’d love Chrome to have a mode where all background tabs are stopped completely and only the frontmost tab is active. Kind of like processes are managed on iOS.\n comments powered by Disqus."},
{"url": "https://2ality.com/2013/09/ecmascript-i18n-api.html", "title": "The ECMAScript Internationalization API", "content": "The ECMAScript Internationalization API dev javascript jslang The ECMAScript Internationalization API, edition 1 \n      supports two scenarios: sorting a set of strings and searching within a set of strings. Collation is parameterized by locale and aware of Unicode.\n     \n      Parameters include:\n         \n             Style of formatting: decimal, currency (which one and how to refer to it, is determined by other parameters), percent.\n             \n             Locale (directly specified or best fit, searched for via a matcher object)\n             \n             Numbering system (Western digits, Arabic digits, Thai digits, etc.)\n             \n             Precision: number of integer digits, fraction digits, significant digits\n             \n             Grouping separators on or off\n             \n         \n     \n      Parameters include:\n         \n             what information to format and in which style (short, long, numeric, etc.)\n             \n             a locale\n             \n             a time zone\n             \n         \n     \n \n     \n     \n     \n     \n     \n What kind of standard is it? [1] \nA set of conformance tests complements the standard and ensures that the various implementations of the API are compatible (ECMA-262 has a similar test suite).\n\n When can I use it? compatibility table Upcoming: edition 2 Internationalization API wiki wiki page \n     Message formatting: format a string with placeholders, including plural and gender support.\n     \n     Parsing numbers.\n     \n     Text segmentation: break text into grapheme clusters, words, lines, and sentences.\n     \n Further reading specification \n     “ The ECMAScript Internationalization API ” by Norbert Lindenberg \n     “ ECMAScript Internationalization API ” by David Storey \n     “ Using the JavaScript Internationalization API ” by Marcos Caceres \n Reference A JavaScript glossary: ECMAScript, TC39, etc. comments powered by Disqus."},
{"url": "https://2ality.com/2013/08/es6-callables.html", "title": "Callable entities in ECMAScript 6", "content": "Callable entities in ECMAScript 6 esnext dev javascript details \nIn ECMAScript 5, one creates all callable entities via functions. ECMAScript 6 has more constructs for doing so. This blog post describes them.\n\n \n\n The status quo: ECMAScript 5 \n     As normal functions: you can directly call functions. \n     As methods: you can assign a function to the property of an object and call it as a method, via that object. \n     As constructors: you can invoke functions as constructors, via the   operator. \n It confuses people. You can use a function the wrong way, e.g. call a constructor or a method as a normal function.\n     Functions used as normal functions shadow the   of surrounding constructors or methods  [1] . That’s because   is always   (provided by each function call), but should be   in this case, like normal variables that are resolved via surrounding scopes if they are not declared within a function.\n     ECMAScript 6’s callable entities [3] Function expression → arrow function [2] Function declaration → const + arrow function \nBut they also have two advantages: First, a function object created by a function declaration always gets a meaningful name, which is useful for debugging. However, ECMAScript 6 engines will probably also assign names to arrow functions, at least in standard scenarios such as the one above.\n \nSecond, function declarations are   (moved to the beginning of the current scope). That allows you to call them before they appear in the source code. Here, more discipline is required in ECMAScript 6 and source code will sometimes not look as nice (depending on your taste). However, one important case of calling methods and normal functions that appear later does not change: calling them from other methods and functions (after the callees have been evaluated!).\n \nIronically, not using function declarations may make things less confusing for newcomers, because they won’t need to understand the difference between function expressions and function declarations  [3] . In ECMAScript 5, I’m often seeing code like this, using a function expression instead of a function declaration (even though the latter is considered best practice):\n IIFE → block + let [1] Function in object literal → concise method syntax Constructor → class [4] New in ECMAScript 6: generator functions and generator methods [5] \nIn my opinion, a better choice would be to replace generator function declarations with generator arrow functions. Or at least to additionally introduce the latter, with an asterisk somewhere. For example:\n rejected Avoiding function expressions Functions with   as an implicit parameter Adding methods to an object Conclusion The clear separation of concerns makes things less confusing, especially for newcomers: classes replace constructors, blocks replace IIFEs, the keyword   does not appear when you define a method, etc.\n     ECMAScript 6 prevents some incorrect uses of functions, but not many: you will get an exception if you invoke a class as a function. Calling extracted methods as functions remains a problem.\n     Arrow functions eliminate the pitfall of inadvertently shadowing  .\n     References JavaScript variable scoping and its pitfalls ECMAScript.next: arrow functions and method definitions Expressions versus statements in JavaScript ECMAScript.next: classes Iterators and generators in ECMAScript 6 comments powered by Disqus."},
{"url": "https://2ality.com/2013/09/data-in-prototypes.html", "title": "Data in prototype properties", "content": "Data in prototype properties dev javascript jslang \nThis blog post explains when you should and should not put data in prototype properties.\n\n \n\n Avoid: prototype properties with initial values for instance properties \nA constructor usually sets instance properties to initial values. If one such value is a default then you don’t need to create an instance property. You only need a prototype property with the same name whose value is the default. For example:\n \nThis approach mostly works: You can create an instance   of  . Getting   reads  . Setting   creates a new own property in   and preserves the shared default value in the prototype.\nWe only have a problem if we change the default value (instead of replacing it with a new value):\n Best practice: don’t share default values [1] [2] \nECMAScript 6 will make this even more of a best practice, because constructor parameters can have default values and you can define prototype methods in class bodies, but not prototype properties with data.\n\n Creating instance properties on demand [3] [4] \nObviously, that is quite a bit of work, so you have to be sure it is worth it.\n\n Avoid non-polymorphic prototype properties \nExample: You can store a constant in a prototype property and access it via  .\n [5] \nMutable prototype properties are difficult to manage. If they are non-polymorphic then you can at least replace them with variables.\n\n Polymorphic prototype properties [6] References Categorizing values in JavaScript JavaScript inheritance by example Properties in JavaScript: definition versus assignment What’s up with the “constructor” property in JavaScript? JavaScript variable scoping and its pitfalls Categorizing values in JavaScript  [Sect. 2.4 explains that   doesn’t work if objects cross frames] comments powered by Disqus."},
{"url": "https://2ality.com/2013/08/objects-truthy.html", "title": "Why all objects are truthy in JavaScript", "content": "Why all objects are truthy in JavaScript dev javascript jslang jshistory [1] [2] Why converting to boolean is different \nAs an example, let’s assume that   coerces to   and use it in an expression:\n The exception to the rule References JavaScript quirk 1: implicit conversion of values What is {} + {} in JavaScript? comments powered by Disqus."},
{"url": "https://2ality.com/2013/10/safe-integers.html", "title": "Safe integers in JavaScript", "content": "Safe integers in JavaScript numbers dev javascript jsint jslang What are integers in JavaScript? \nJavaScript can only safely represent integers   in the range −2  <   < 2 . This blog post examines why that is and what “safely represent” means. It is based on an  email  by Mark S. Miller to the es-discuss mailing list. \n\n \n\n Safe integers \nIn the range (−2 , 2 ) (excluding the lower and upper bounds), JavaScript integers are  : there is a one-to-one mapping between mathematical integers and their representations in JavaScript.\n \nBeyond this range, JavaScript integers are  : two or more mathematical integers are represented as the same JavaScript integer. For example, starting at 2 , JavaScript can only represent every second mathematical integer.\n [1] \nSimilarly, starting at 2 , JavaScript can only represent every fourth mathematical integer (and so on).\n Definitions in ECMAScript 6 Safe results of arithmetic computations Recommended reading How numbers are encoded in JavaScript series comments powered by Disqus."},
{"url": "https://2ality.com/2013/09/javascript-unicode.html", "title": "Unicode and JavaScript", "content": "Unicode and JavaScript dev javascript unicode jslang \nThis blog post is a brief introduction to Unicode and how it is handled in JavaScript.\n\n \n\n Unicode History \nThe first Unicode draft proposal was published in 1988. Work continued afterwards and the working group expanded. The   was incorporated on January 3, 1991:\n Important Unicode concepts \n      Both terms mean something quite similar. Characters are are digital entities, graphemes are atomic units of written languages (alphabetic letters, typographic ligatures, etc.). Sometimes, several characters are used to display a single grapheme.\n     \n      A concrete way of writing a grapheme. Sometimes the same grapheme is written differently, depending on its context or other factors. For example, the graphemes f and i can be displayed as a glyph f and a glyph i, connected by a ligature glyph. Or without a ligature.\n     \n      Unicode maps the characters it supports to numbers called  .\n     \n      To store or transmit code points, they are encoded as  , pieces of data with a fixed length. The length is measured in bits and determined by an encoding scheme, of which Unicode has several ones: UTF-8, UTF-16, etc. The number in the name indicates the length of the code units, in bits.\n    If a code point is too large to fit into a single code unit, it must be broken up into multiple units. That is, the number of code units needed to represent a single code point can vary.\n     \n      If a code unit is larger than a single byte, byte ordering matters. The BOM is a single pseudo-character (possibly encoded as multiple code units) at the beginning of a text that indicates whether the code units are big endian (most significant bytes come first) or little endian (least significant bytes come first). The default, for texts without a BOM, is big endian.\n        The BOM also indicates the encoding that is used, it is different for UTF-8, UTF-16, etc. It also serves as a marker for Unicode, if web browsers have no other information w.r.t. the encoding of a text. However, the BOM is not used very often, for several reasons:\n         \n             UTF-8 is by far the most popular Unicode encoding and does not need a BOM, because there is only one way of ordering bytes.\n             \n             Several character encodings include byte ordering. Then a BOM must not be used. Examples: UTF-16BE (UTF-16 big endian), UTF-16LE, UTF-32BE, UTF-32LE. This is a safer way of handling byte ordering, because there is no danger of mixing up meta-data and data.\n             \n         \n     \n      Sometimes the same grapheme can be represented in several ways. For example, the grapheme “ö” can be represented as a single code point or as an “o” followed by a combining character “¨” (diaeresis, double dot). Normalization is about translating a text to a canonical representation; equivalent code points and sequences of code points are all translated to the same code point (or sequence of code points). That is useful for text processing, e.g. to search for text. Unicode specifies several normalizations.\n     \n      Each Unicode character is assigned several properties by the specification:\n         \n             Name: an English name, composed of uppercase letters A-Z, digits 0-9, hypen - and <space>. Two examples:\n                 \n                     “λ” has the name “GREEK SMALL LETTER LAMDA” \n                     “!” has the name “EXCLAMATION MARK” \n                 \n             \n             General category : Partitions characters into categories such as letter, uppercase letter, number, punctuation, etc.\n             \n             Age: With what version of Unicode was the character introduced (1.0, 1.1., 2.0, etc.)?\n             \n             Deprecated: Is the use of the character discouraged?\n             \n             And many more.\n             \n         \n     \n Code points \n     Plane 0: Basic Multilingual Plane (BMP): 0x0000–​0xFFFF\n     \n     Plane 1: Supplementary Multilingual Plane (SMP): 0x10000–​0x1FFFF\n     \n     Plane 2: Supplementary Ideographic Plane (SIP): 0x20000–​0x2FFFF\n     \n     Planes 3–13: Unassigned\n     \n     Plane 14: Supplement­ary Special-Purpose Plane (SSP: 0xE0000–​0xEFFFF\n     \n     Planes 15–16: Supplement­ary Private Use Area (S PUA A/B): 0x0F0000–0x10FFFF\n     \n Unicode encodings \n  is a format with 16 bit code units that needs one to two units to represent a code point. BMP code points can be represented by single code units. Higher code points are 20 bit, after subtracting 0x10000 (the range of the BMP). These bits are encoded as two code units:\n \n     Lead surrogate – most significant 10 bits: stored in the range 0xD800–0xDBFF (four times 8 bits = 4 × two hexadecimal digits). \n     Tail surrogate – least significant 10 bits: stored in the range  0xDC00–0xDFFF (four times 8 bits = 4 × two hexadecimal digits). \n \n , a deprecated format, uses 16 bit code units to represent (only!) the code points of the BMP. When the range of Unicode code points expanded beyond 16 bits, UTF-16 replaced UCS-2.\n \n \nUTF-8 has 8 bit code units. It builds a bridge between the legacy ASCII encoding and Unicode. ASCII only has 128 characters, whose numbers are the same as the first 128 Unicode code points. UTF-8 is backwards compatible, because all ASCII characters are valid code units. In other words, a single code unit in the range 0–127 encodes a single code point in the same range. Such code units are marked by their highest bit being zero. If, on the other hand, the highest bit is one then more units will follow, to provide the additional bits for the higher code points. That leads to the following encoding scheme:\n \n     0000–007F: 0xxxxxxx (7 bits, stored in 1 byte)\n     \n     0080–07FF: 110xxxxx, 10xxxxxx (5+6 bits = 11 bits, stored in 2 bytes)\n     \n     0800–FFFF: 1110xxxx, 10xxxxxx, 10xxxxxx (4+6+6 bits = 16 bits, stored in 3 bytes)\n     \n     10000–1FFFFF: 11110xxx, 10xxxxxx, 10xxxxxx, 10xxxxxx (3+6+6+6 bits = 21 bits, stored in 4 bytes)  \n        (The highest code point is 10FFFF, so UTF-8 has some extra room.)\n     \n \nUTF-8 has become the most popular Unicode format. Initially, due to its backwards compatibility with ASCII. Later, due to its broad support across operating systems, programming environments and applications.\n\n JavaScript source code and Unicode Source code internally Sect. 6 \nIn string literals, an additional kind of escape is available:   with two-digit hexadecimal numbers that represent code units in the range 0x00–0xFF. For example:\n Source code externally as follows \n     If there is a BOM, the encoding is a UTF variant, depending on what BOM is used.\n     \n     Otherwise, if the source code is loaded via HTTP(S) then the Content-Type header can specify an encoding, via the   parameter. For example:\n \n        Note: the correct   (formerly known as  ) for JavaScript files is  . However, older browsers (e.g. Internet Explorer 8 and earlier) work most reliably with  . Unfortunately, the  default value  for the attribute   of   tags is  . At least, you can omit that attribute for JavaScript; there is no benefit in including it.\n     \n     Otherwise, if the script tag has the attribute   then that encoding is used. Even though the attribute   holds a valid media type, that type must not have the parameter   (like in the Content-Type header, above).\n     \n     Otherwise, the encoding of the document is used, in which the script tag resides. For example, this is the beginning of an HTML5 document, where a   tag declares that the document is encoded as UTF-8.\n \n        It is highly recommended to always specify an encoding. If you don’t, a locale-specific  default encoding  is used. That is, people will see the file differently in different countries. Only the lowest 7 bit are relatively stable across locales.\n     \n \n     For your own application, you can use Unicode. But you must specify the encoding of the app’s HTML page as UTF-8.\n     \n     For libraries, it’s safest to release code that is ASCII (7 bit).\n     \n UglifyJS error JavaScript strings and Unicode Sect. 8.4 \n  There are many nice Unicode symbol tables on the web. Take a look at Tim Whitlock’s “ Emoji Unicode Tables ” and be amazed by how many symbols there are in modern Unicode fonts. None of the symbols in the table are images, they are all font glyphs. Let’s assume you want to display a character via JavaScript that is in an astral plane. For example, a cow (code point 0x1F404):\n \n     “ UTF Converter ” \n     “ JavaScript escapes ” by Mathias Bynens \n \n  If a string contains a surrogate pair (two code units encoding a single code point) then the   property doesn’t count characters, any more. It counts code units:\n Punycode.js \n  If you want to search in strings or compare them then you need to normalize, e.g. via the library  unorm  (by Bjarke Walling).\n\n JavaScript regular expressions and Unicode [1] \nLine terminators influence matching and do have a  Unicode definition . A line terminator is either one of four characters:\n \n \nThe following regular expression constructs support Unicode:\n \n     Whitespace ( ) and non-whitespace ( ) have Unicode-based definitions:\n \n     \n     The dot ( ) matches all code points (not code units!) except line terminators. See below how to match any code unit.\n     \n     In multiline mode, the assertion   matches at the beginning of the input and after line terminators, the assertion   matches before line terminators and at the end of the input. Otherwise, they only match at the beginning or end of the input, respectively.\n     \n \n      matches digits,   matches non-digits, where a digit is equivalent to  \n     \n      matches word characters,   matches non-word characters, where a word character is equivalent to  \n     \n      matches at word breaks,   matches inside words, where words are sequences of word characters ( ). Example: In the string  , the character class escape   sees the character “b” as starting a word.\n \n     \n Matching any code unit [1] Libraries \n  is a regular expression library that has an  official addon  for matching Unicode categories, scripts, blocks and properties via one of the following three constructs:\n The future of handling Unicode in JavaScript \n     The ECMAScript Internationalization API  [2] : offers Unicode-based collation (sorting and searching) and more.\n     \n     ECMAScript 6: The next version of JavaScript will have several Unicode-related features, such as escapes for arbitrary code points and a method for accessing code points in a string (as opposed to code units). The blog post “ Supplementary Characters for ECMAScript ” by Norbert Lindenberg explains the plans for Unicode support in ECMAScript 6.\n     \n Recommended reading and sources of this post \n     Wikipedia has several good entries on  Unicode  and its terminology.\n     \n     Unicode.org , the official website of the Unicode Consortium and its  FAQ  is also really good.\n     \n     Introductory article by Joel Spolsky: “ The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) ” \n \n     “ JavaScript’s internal character encoding: UCS-2 or UTF-16? ” by Mathias Bynens \n     ” JavaScript, Regex, and Unicode “ by Steven Levithan \n Acknowledgements @mathias @annevk @CWMma References JavaScript: an overview of the regular expression API The ECMAScript Internationalization API comments powered by Disqus."},
{"url": "https://2ality.com/2013/10/console-api.html", "title": "The JavaScript console API", "content": "The JavaScript console API dev nodejs javascript clientjs \nThis blog post gives an overview of the methods of  .\n\n \n\n How standardized is the console API across browsers? documentation specification \n     Chrome:  developers.google.com/chrome-developer-tools/docs/console-api/ \n     Firebug:  getfirebug.com/wiki/index.php/Console_API \n     Firefox:  developer.mozilla.org/en-US/docs/Web/API/console \n     Internet Explorer:  msdn.microsoft.com/en-us/library/ie/hh772183.aspx \n     Node.js:  nodejs.org/api/stdio.html \n     Safari:  developer.apple.com/library/safari/documentation/AppleApplications/Conceptual/Safari_Developer_Guide/Console/Console.html \n Simple logging \n \n    Clear the console.\n \n \n    Prefer  , which does the same as this method.\n \n \n    Log the parameters to the console. In browers, the logged content may be marked by an “error” icon and/or include a stack trace or a link to the code.\n \n  [Firebug-only] \n    Log   etc. and show an interactive stack trace.\n \n \n    Log the parameters to the console. In browers, the logged content may be marked by an “error” icon and/or include a stack trace or a link to the code.\n \n \n    Log the parameters to the console. If the first parameter is a printf-style format string, use it to print the remaining parameters. Example (Node.js REPL)\n \n    The only dependable cross-platform formatting directive is  . Node.js supports   to format data as JSON, browsers tend to support directives that log something interactive to the console.\n \n \n    Logs a stack trace (which is interactive in browsers).\n \n \n    Log the parameters to the console. In browers, the logged content may be marked by an “warning” icon and/or include a stack trace or a link to the code.\n \n \n \n  has been typeset in italics, because it is only supported on a single platform.\n\n Checking and counting \n \n    If   is  , log   to the console and throw an exception. If it is  , do nothing.\n \n \n    Count how many times the line with this statement is executed with this label. \n \n \n Formatted logging \n \n    Print a representation of the object to the console. In browsers that representation can be explored interactively (in Node.js, it can’t).\n \n \n    Print the XML source tree of an HTML or XML element.\n \n \n    Log the objects to the console and open a nested block that contains all future logged content. The block is closed by calling  . The block is initially expanded, but can be collapsed.\n \n \n    Works like  , but the block is initially collapsed.\n \n \n    Close a group that has been opened by   or  .\n \n \n    Print an array as a table, one element per row. The optional parameter   specifies which properties/array indices are shown in the columns. If that parameter is missing, all property keys are used as table columns. Missing properties and array elements show up as   in columns.\n \n    The resulting table is:\n     \n     \n \n \n Profiling and timing \n  [Safari-only] \n    The same as  .\n \n \n    Turn on profiling. The optional parameter   is used for the profile report.\n \n \n    Stop profiling and print the profile report.\n \n \n    Start a timer whose label is  .\n \n \n    Stop the timer whose label is   and print the time that has elapsed since starting it.\n \n \n    Log a time stamp with the given  . May be logged to the console or a timeline.\n \n \n \n  has been typeset in italics, because it is only supported on a single platform. (devtools) means that the developer tools must be open in order for the method to work.\n\n Acknowledgements comments powered by Disqus."},
{"url": "https://2ality.com/2013/09/window.html", "title": "Tips for using window in JavaScript", "content": "Tips for using window in JavaScript dev javascript jslang The global object and  \nJavaScript creator Brendan Eich considers the global object one of his “ biggest regrets ”.\n\n Cross-platform considerations [1] Use cases for window Marking global variables \n  I prefer not to refer to built-in global variables via  . They are well-known names, so you gain little from an indicator that they are global. And the prefixed   adds clutter:\n \n  When working with a style checking tool such as JSLint and JSHint, using   means that you don’t get an error when referring to a global variable that is not declared in the current file. However, both tools provide ways for telling them about such variables and preventing such errors (search for “global variable” in their documentation).\n\n Checking whether a global variable exists Creating things in global scope \n  Don’t create a global variable by assigning to it without declaring it:\n The future of global variables [2] Conclusion \nThe idea for this blog post came from the answers of a  tweet , where I asked why and how people use  .\n\n\n References JavaScript variable scoping and its pitfalls What is the difference between a shim and a polyfill? JavaScript’s strict mode: a summary comments powered by Disqus."}
]