[
{"url": "https://alistapart.com/article/breaking-out-of-the-box/", "title": "Breaking Out of the Box", "content": "CSS is about styling boxes. In fact, the whole web is made of boxes, from the browser viewport to elements on a page. But every once in a while a new feature comes along that makes us rethink our design approach. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. , for example, make it fun to play with circular clip areas.   and   offer challenges to best organize content that stays clear of them. And   make us rethink how to best use available space in a number of different  . These recent evolutions of the web platform made it both more challenging and more interesting to design products. They’re great opportunities for us to break out of our rectangular boxes. I’d like to talk about a new feature similar to the above: the Window Controls Overlay for Progressive Web Apps (PWAs).  are blurring the lines between apps and websites. They combine the best of both worlds. On one hand, they’re stable, linkable, searchable, and responsive just like websites. On the other hand, they provide additional powerful capabilities, work offline, and read files just like native apps. As a design surface, PWAs are really interesting because they challenge us to think about what mixing web and device-native user interfaces can be. On desktop devices in particular, we have more than   telling us what applications should look like, and it can be hard to break out of this mental model. At the end of the day though, PWAs on desktop are constrained to the window they appear in: a rectangle with a title bar at the top. Here’s what a typical desktop PWA app looks like: Sure, as the author of a PWA, you get to choose the color of the title bar (using the Web Application Manifest   property), but that’s about it. What if we could think outside this box, and reclaim the real estate of the app’s entire window? Doing so would give us a chance to make our apps more beautiful and feel more integrated in the operating system. This is exactly what the   offers. This new PWA functionality makes it possible to take advantage of the full surface area of the app, including where the title bar normally appears. About the title bar and window controls Let’s start with an explanation of what the title bar and window controls are. The   is the area displayed at the top of an app window, which usually contains the app’s name.   are the affordances, or buttons, that make it possible to minimize, maximize, or close the app’s window, and are also displayed at the top. Window Controls Overlay removes the physical constraint of the title bar and window controls areas. It frees up the full height of the app window, enabling the title bar and window control buttons to be overlaid on top of the application’s web content.  If you are reading this article on a desktop computer, take a quick look at other apps. Chances are they’re already doing something similar to this. In fact, the very web browser you are using to read this uses the top area to display tabs. Spotify displays album artwork all the way to the top edge of the application window. Microsoft Word uses the available title bar space to display the auto-save and search functionalities, and more. The whole point of this feature is to allow you to make use of this space with your own content while providing a way to account for the window control buttons. And it enables you to offer this modified experience on a range of platforms while not adversely affecting the experience on browsers or devices that don’t support Window Controls Overlay. After all, PWAs are all about  , so this feature is a chance to enhance your app to use this extra space when it’s available. Let’s use the feature For the rest of this article, we’ll be working on a demo app to learn more about using the feature. The demo app is called  . It’s a simple CSS playground where users can create designs using CSS and a single HTML element. The app has two pages. The first lists the existing CSS designs you’ve created: The second page enables you to create and edit CSS designs: Since I’ve added a simple web manifest and service worker, we can install the app as a PWA on desktop. Here is what it looks like on macOS: And on Windows: Our app is looking good, but the white title bar in the first page is wasted space. In the second page, it would be really nice if the design area went all the way to the top of the app window. Let’s use the Window Controls Overlay feature to improve this. Enabling Window Controls Overlay The feature is still experimental at the moment. To try it, you need to enable it in one of the supported browsers. As of now, it has been implemented in Chromium, as a collaboration between Microsoft and Google. We can therefore use it in Chrome or Edge by going to the internal   page, and enabling the   flag. Using Window Controls Overlay To use the feature, we need to add the following   member to our web app’s manifest file: On the surface, the feature is really simple to use. This manifest change is the only thing we need to make the title bar disappear and turn the window controls into an overlay. However, to provide a great experience for all users regardless of what device or browser they use, and to make the most of the title bar area in our design, we’ll need a bit of CSS and JavaScript code. Here is what the app looks like now: The title bar is gone, which is what we wanted, but our logo, search field, and   button are partially covered by the window controls because now our layout starts at the top of the window. It’s similar on Windows, with the difference that the close, maximize, and minimize buttons appear on the right side, grouped together with the PWA control buttons: Using CSS to keep clear of the window controls Along with the feature, new CSS environment variables have been introduced: You use these variables with the CSS   function to position your content where the title bar would have been while ensuring it won’t overlap with the window controls. In our case, we’ll use two of the variables to position our header, which contains the logo, search bar, and   button.  The  variable gives us the distance from the left of the viewport to where the title bar would appear, and   is its width. (Remember, this is not equivalent to the width of the entire viewport, just the title bar portion, which as noted earlier, doesn’t include the window controls.) By doing this, we make sure our content remains fully visible. We’re also defining fallback values (the second parameter in the   function) for when the variables are not defined (such as on non-supporting browsers, or when the Windows Control Overlay feature is disabled). Now our header adapts to its surroundings, and it doesn’t feel like the window control buttons have been added as an afterthought. The app looks a lot more like a native app. Changing the window controls background color so it blends in Now let’s take a closer look at our second page: the CSS playground editor. Not great. Our CSS demo area does go all the way to the top, which is what we wanted, but the way the window controls appear as white rectangles on top of it is quite jarring. We can fix this by changing the app’s theme color. There are a couple of ways to define it: PWAs can define a theme color in the web app manifest file using the   manifest member. This color is then used by the OS in different ways. On desktop platforms, it is used to provide a background color to the title bar and window controls. Websites can use the   as well. It’s used by browsers to customize the color of the UI around the web page. For PWAs, this color can override the manifest  . In our case, we can set the manifest   to white to provide the right default color for our app. The OS will read this color value when the app is installed and use it to make the window controls background color white. This color works great for our main page with the list of demos. The   meta tag can be changed at runtime, using JavaScript. So we can do that to override the white with the right demo background color when one is opened. Here is the function we’ll use: With this in place, we can imagine how using color and CSS transitions can produce a smooth change from the list page to the demo page, and enable the window control buttons to blend in with the rest of the app’s interface. Dragging the window Now, getting rid of the title bar entirely does have an important accessibility consequence: it’s much more difficult to move the application window around. The title bar provides a sizable area for users to click and drag, but by using the Window Controls Overlay feature, this area becomes limited to where the control buttons are, and users have to very precisely aim between these buttons to move the window. Fortunately, this can be fixed using CSS with the   property. This property is, for now, only supported in Chromium-based browsers and needs the   vendor prefix.  To make any element of the app become a dragging target for the window, we can use the following:  It is also possible to explicitly make an element non-draggable:  These options can be useful for us. We can make the entire header a dragging target, but make the search field and   button within it non-draggable so they can still be used as normal. However, because the editor page doesn’t display the header, users wouldn’t be able to drag the window while editing code. So let’s use a different approach. We’ll create another element before our header, also absolutely positioned, and dedicated to dragging the window. With the above code, we’re making the draggable area span the entire viewport width, and using the   variable to make it as tall as what the title bar would have been. This way, our draggable area is aligned with the window control buttons as shown below. And, now, to make sure our search field and button remain usable: With the above code, users can click and drag where the title bar used to be. It is an area that users expect to be able to use to move windows on desktop, and we’re not breaking this expectation, which is good. Adapting to window resize It may be useful for an app to know both whether the window controls overlay is visible and when its size changes. In our case, if the user made the window very narrow, there wouldn’t be enough space for the search field, logo, and button to fit, so we’d want to push them down a bit. The Window Controls Overlay feature comes with a JavaScript API we can use to do this:  . The API provides three interesting things:  lets us know whether the overlay is visible.  lets us know the position and size of the title bar area.  lets us know when the size or visibility changes. Let’s use this to be aware of the size of the title bar area and move the header down if it’s too narrow. In the example above, we set the   class on the   of the app if the title bar area is narrower than 250px. We could do something similar with a media query, but using the   API has two advantages for our use case: It’s only fired when the feature is supported and used; we don’t want to adapt the design otherwise. We get the size of the title bar area across operating systems, which is great because the size of the window controls is different on Mac and Windows. Using a media query wouldn’t make it possible for us to know exactly how much space remains. Using the above CSS code, we can move our header down to stay clear of the window control buttons when the window is too narrow, and move the thumbnails down accordingly. Thirty pixels of exciting design opportunities Using the Window Controls Overlay feature, we were able to take our simple demo app and turn it into something that feels so much more integrated on desktop devices. Something that reaches out of the usual window constraints and provides a custom experience for its users. In reality, this feature only gives us about 30 pixels of extra room and comes with challenges on how to deal with the window controls. And yet, this extra room and those challenges can be turned into exciting design opportunities. More devices of all shapes and forms get invented all the time, and the web keeps on evolving to adapt to them. New features get added to the web platform to allow us, web authors, to integrate more and more deeply with those devices. From watches or foldable devices to desktop computers, we need to evolve our design approach for the web. Building for the web now lets us think outside the rectangular box. So let’s embrace this. Let’s use the standard technologies already at our disposal, and experiment with new ideas to provide tailored experiences for all devices, all from a single codebase! If you get a chance to try the Window Controls Overlay feature and have feedback about it, you can  . It’s still early in the development of this feature, and you can help make it even better. Or, you can take a look at the  , or this   and its  .  Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/redefine-success-first/", "title": "Designers, (Re)define Success First", "content": "About two and a half years ago, I introduced the idea of  . It was born out of my frustration with the many obstacles to achieving design that’s usable and equitable; protects people’s privacy, agency, and focus; benefits society; and restores nature. I argued that we need to overcome the inconveniences that prevent us from acting ethically and that we need to elevate design ethics to a more practical level by structurally integrating it into our daily work, processes, and tools. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Unfortunately, we’re still very far from this ideal.  At the time, I didn’t know yet   to structurally integrate ethics. Yes, I had found some tools that had worked for me in previous projects, such as using checklists, assumption tracking, and “dark reality” sessions, but I didn’t manage to apply those in   project. I was still struggling for time and support, and at best I had only partially achieved a higher (moral) quality of design—which is far from my definition of  . I decided to dig deeper for the root causes in business that prevent us from practicing daily ethical design. Now, after much research and experimentation, I believe that I’ve found the key that will let us structurally integrate ethics. And it’s surprisingly simple! But first we need to zoom out to get a better understanding of what we’re up against. Influence the system Sadly, we’re trapped in a capitalistic system that reinforces   and  , and it’s obsessed with the  . Sea levels, temperatures, and our demand for energy continue to rise unchallenged, while the gap between rich and poor continues to widen. Shareholders expect ever-higher returns on their investments, and companies feel forced to set short-term objectives that reflect this. Over the last decades, those objectives have   that promotes ever-higher levels of consumption. When we’re working for an organization that pursues “double-digit growth” or “aggressive sales targets” (which is 99 percent of us), that’s very hard to resist while remaining human  . Even with our best intentions, and even though we like to say that we create solutions for people, we’re a part of the problem. What can we do to change this? We can start by acting on the right level of the system. Donella H. Meadows, a system thinker, once listed   in order of effectiveness. When you apply these to design, you get: At the lowest level of effectiveness, you can affect   such as usability scores or the number of design critiques. But none of that will change the direction of a company. Similarly, affecting  (such as team budgets),   (such as the number of designers),   (such as the number of new hires), and   (such as the time that it takes to hear about the effect of design) won’t significantly affect a company. Focusing instead on   such as management control, employee recognition, or design-system investments can help a company become better at achieving its objectives. But that doesn’t change the objectives themselves, which means that the organization will still work against your ethical-design ideals. The next level,  , is what most ethical-design initiatives focus on now: the exchange of ethical methods, toolkits, articles, conferences, workshops, and so on. This is also where ethical design has remained mostly  . We’ve been focusing on the wrong level of the system all this time. Take   for example—they beat knowledge every time. There can be widely accepted rules, such as how finance works, or a scrum team’s definition of done. But ethical design can also be smothered by unofficial rules meant to maintain profits, often revealed through comments such as “the client didn’t ask for it” or “don’t make it too big.” Changing the rules without holding official power is very hard. That’s why the next level is so influential:  . Experimentation, bottom-up initiatives, passion projects, self-steering teams—all of these are examples of self-organization that improve the resilience and creativity of a company. It’s exactly this diversity of viewpoints that’s needed to structurally tackle big systemic issues like consumerism, wealth inequality, and climate change. Yet even stronger than self-organization are   and  . Our companies want to make more money, which means that everything and everyone in the company does their best to… make the company more money. And once I realized that profit is nothing more than a measurement, I understood how crucial a very specific, defined metric can be toward pushing a company in a certain direction. The takeaway? If we truly want to incorporate ethics into our daily design practice, we must first change the measurable objectives of the company we work for, from the bottom up. Redefine success Traditionally,  . You tend to see these represented as equals; if you type the three words in a search engine, you’ll find diagrams of three equally sized, evenly arranged circles. But in our hearts, we all know that the three dimensions aren’t equally weighted: it’s viability that ultimately controls whether a product will go live. So a more realistic representation might look like this: Desirability and feasibility are the  ; viability is the  . Companies—outside of nonprofits and charities—exist to make money. A genuinely purpose-driven company would try to reverse this dynamic: it would recognize finance for what it was intended for: a  . So both feasibility and viability are means to achieve what the company set out to achieve. It makes intuitive sense: to achieve most anything, you need resources, people, and money. (Fun fact: the Italian language knows no difference between feasibility and viability; both are simply  .) But simply swapping   for   isn’t enough to achieve an ethical outcome. Desirability is still linked to consumerism because the associated activities aim to identify what people want— . Desirability objectives, such as user satisfaction or conversion, don’t consider whether a product is healthy for people. They don’t prevent us from creating products that distract or manipulate people or stop us from contributing to society’s wealth inequality. They’re unsuitable for establishing a healthy balance with nature. There’s a fourth dimension of success that’s missing: our designs also need to be   in the effect that they have on the world. This is hardly a new idea. Many similar models exist, some calling the fourth dimension  ,  , or  . What I’ve never seen before, however, is the necessary step that comes after: to influence the system as designers and to make ethical design more practical, we must create objectives for ethical design that are achievable and inspirational. There’s no one way to do this because it highly depends on your culture, values, and industry. But I’ll give you the version that I developed with a group of colleagues at a design agency. Consider it a template to get started. Pursue well-being, equity, and sustainability We created objectives that address design’s effect on three levels: individual, societal, and global. An objective on the individual level tells us what success is beyond the typical focus of usability and satisfaction—instead considering matters such as how much time and attention is required from users. We pursued  : We create products and services that allow for people’s health and happiness. Our solutions are calm, transparent, nonaddictive, and nonmisleading. We respect our users’ time, attention, and privacy, and help them make healthy and respectful choices. An objective on the societal level forces us to consider our impact beyond just the user, widening our attention to the economy, communities, and other indirect stakeholders. We called this objective  : We create products and services that have a positive social impact. We consider economic equality, racial justice, and the inclusivity and diversity of people as teams, users, and customer segments. We listen to local culture, communities, and those we affect. Finally, the objective on the global level aims to ensure that we remain in balance with the only home we have as humanity. Referring to it simply as  , our definition was: We create products and services that reward sufficiency and reusability. Our solutions support the circular economy: we create value from waste, repurpose products, and prioritize sustainable choices. We deliver functionality instead of ownership, and we limit energy use. In short, ethical design (to us) meant achieving wellbeing for each user and an equitable value distribution within society through a design that can be sustained by our living planet. When we introduced these objectives in the company, for many colleagues,   and   suddenly became tangible and achievable through practical—and even familiar—actions. Measure impact  But defining these objectives still isn’t enough. What truly caught the attention of senior management was the fact that we created a way to   every design project’s well-being, equity, and sustainability. This overview lists example metrics that you can use as you pursue well-being, equity, and sustainability: There’s a lot of power in measurement. As the saying goes, what gets measured gets done.   once shared this example: “If the desired system state is national security, and that is defined as the amount of money spent on the military, the system will produce military spending. It may or may not produce national security.” This phenomenon explains why   is a poor indicator of success: it’s typically  , and so on. But none of these metrics increase the health of people, communities, or ecosystems. What if instead we measured success through metrics for (digital) well-being, such as (reduced)   or software energy consumption? There’s another important message here. Even if we set an objective to build a calm interface, if we were to choose the wrong metric for calmness—say, the number of interface elements—we could still end up with a screen that induces anxiety. Choosing the wrong metric can completely undo good intentions.  Additionally, choosing the right metric is enormously helpful in   the design team. Once you go through the exercise of  , you’re forced to consider what success looks like   and how you can prove that you’ve reached your ethical objectives. It also forces you to consider what we as designers have   over: what can I include in my design or change in my process that will lead to the right type of success? The answer to this question brings a lot of clarity and focus. And finally, it’s good to remember that traditional businesses run on measurements, and managers love to spend much time discussing charts (ideally hockey-stick shaped)—especially if they concern profit, the one-above-all of metrics. For good or ill, to improve the system, to have a serious discussion about ethical design with managers, we’ll need to speak that business language. Practice daily ethical design Once you’ve defined your objectives and you have a reasonable idea of the potential metrics for your design project,   then do you have a chance to structurally practice ethical design. It “simply” becomes a matter of using your creativity and choosing from all the knowledge and toolkits already available to you. I think this is quite exciting! It opens a whole new set of challenges and considerations for the design process. Should you go with that energy-consuming video or would a simple illustration be enough? Which typeface is the most calm and inclusive? Which new tools and methods do you use? When is the website’s end of life? How can you provide the same service while requiring less attention from users? How do you make sure that those who are affected by decisions are there when those decisions are made? How can you measure our effects? The redefinition of success will completely change what it means to do good design. There is, however, a final piece of the puzzle that’s missing: convincing your client, product owner, or manager to be mindful of well-being, equity, and sustainability. For this, it’s essential to engage stakeholders in a dedicated kickoff session. Kick it off or fall back to status quo The kickoff is the most important meeting that can be so easy to forget to include. It consists of two major phases: 1) the alignment of  , and 2) the definition of  . In the first phase, the entire (design) team goes over the project brief and meets with all the relevant stakeholders. Everyone gets to know one another and express their expectations on the outcome and their contributions to achieving it. Assumptions are raised and discussed. The aim is to get on the same level of understanding and to in turn avoid preventable miscommunications and surprises later in the project. For example, for a recent freelance project that aimed to design a digital platform that facilitates US student advisors’ documentation and communication, we conducted an online kickoff with the client, a subject-matter expert, and two other designers. We used a combination of canvases on Miro: one with questions from “ ” (to get to know each other), a   (to express expectations), and a version of the   to align on scope, timeline, and other practical matters. The above is the traditional purpose of a kickoff. But just as important as expressing expectations is agreeing on what   means for the project—in terms of desirability, viability, feasibility, and ethics. What are the objectives in each dimension? Agreement on what success means at such an early stage is crucial because you can rely on it for the remainder of the project. If, for example, the design team wants to build an inclusive app for a diverse user group, they can raise diversity as a specific success criterion during the kickoff. If the client agrees, the team can refer back to that promise throughout the project. “As we agreed in our first meeting, having a diverse user group that includes A and B is necessary to build a successful product. So we do activity X and follow research process Y.” Compare those odds to a situation in which the team didn’t agree to that beforehand and had to ask for permission halfway through the project. The client might argue that that came   of the agreed scope—and she’d be right. In the case of this freelance project, to define success I prepared a round canvas that I call the  . It consists of an inner ring, meant to capture ideas for objectives, and a set of outer rings, meant to capture ideas on how to measure those objectives. The rings are divided into five dimensions of successful design: healthy, equitable, sustainable, desirable, feasible, and viable. We went through each dimension, writing down ideas on digital sticky notes. Then we discussed our ideas and verbally agreed on the most important ones. For example, our client agreed that sustainability and progressive enhancement are important success criteria for the platform. And the subject-matter expert emphasized the importance of including students from low-income and disadvantaged groups in the design process. After the kickoff, we summarized our ideas and shared understanding in a project brief that captured these aspects: the project’s origin and purpose:  the problem definition:  the concrete goals and metrics for each success dimension:  the scope, process, and role descriptions:  With such a brief in place, you can use the agreed-upon objectives and concrete metrics as a checklist of success, and your design team will be ready to pursue the right objective—using the tools, methods, and metrics at their disposal to achieve ethical outcomes. Conclusion Over the past year, quite a few colleagues have asked me, “Where do I start with ethical design?” My answer has always been the same: organize a session with your stakeholders to (re)define success. Even though you might not always be 100 percent successful in agreeing on goals that cover all responsibility objectives, that beats the alternative (the status quo) every time. If you want to be an ethical, responsible designer, there’s no skipping this step. To be even more specific: if you consider yourself a  , your challenge is to define ethical objectives, set the right metrics, and conduct those kick-off sessions. If you consider yourself a  , your starting point is to understand how your industry contributes to consumerism and inequality, understand how finance drives business, and brainstorm which levers are available to influence the system on the highest level. Then redefine success to create the space to exercise those levers. And for those who consider themselves service designers or UX designers or UI designers: if you truly want to have a positive, meaningful impact, stay away from the toolkits and meetups and conferences for a while. Instead, gather your colleagues and define goals for well-being, equity, and sustainability through design. Engage your stakeholders in a workshop and challenge them to think of ways to achieve and measure those ethical goals. Take their input, make it concrete and visible, ask for their agreement, and hold them to it. Otherwise, I’m genuinely sorry to say, you’re wasting your precious time and creative energy. Of course, engaging your stakeholders in this way can be uncomfortable. Many of my colleagues expressed doubts such as “What will the client think of this?,” “Will they take me seriously?,” and “Can’t we just do it within the design team instead?” In fact, a product manager once asked me why ethics couldn’t just be a structured part of the design  —to just do it without spending the effort to define ethical objectives. It’s a tempting idea, right? We wouldn’t have to have difficult discussions with stakeholders about what values or which key-performance indicators to pursue. It would let us focus on what we like and do best: designing. But as systems theory tells us, that’s not enough. For those of us who aren’t from marginalized groups and have the privilege to be able to speak up and be heard, that uncomfortable space is exactly where we need to be if we truly want to make a difference. We can’t remain within the design-for-designers bubble, enjoying our privileged working-from-home situation, disconnected from the real world out there. For those of us who have the possibility to speak up and be heard: if we solely keep   about ethical design and it remains at the level of articles and toolkits—we’re not designing ethically. It’s just theory. We need to actively engage our colleagues and clients by challenging them to redefine success in business. With a bit of courage, determination, and focus, we can break out of this cage that finance and business-as-usual have built around us and become facilitators of a new type of business that can see beyond financial value. We just need to agree on the right objectives at the start of each design project, find the right metrics, and realize that we already have everything that we need to get started. That’s what it means to do daily ethical design. Like this: \n\t\t\t\t\t\t\tRecently by Lennart Overkamp\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/mobile-first-css-is-it-time-for-a-rethink/", "title": "Mobile-First CSS: Is It Time for a Rethink?", "content": "The mobile-first design methodology is great—it focuses on what really matters to the user, it’s well-practiced, and it’s been a common design pattern for years. So developing your CSS mobile-first should also be great, too…right?  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Well, not necessarily. Classic mobile-first CSS development is based on the principle of overwriting style declarations: you begin your CSS with default style declarations, and overwrite and/or add new styles as you add breakpoints with   media queries for larger viewports (for a good overview see “ ”). But all those exceptions create complexity and inefficiency, which in turn can lead to an increased testing effort and a code base that’s harder to maintain. Admit it—how many of us willingly want that? On your own projects, mobile-first CSS may yet be the best tool for the job, but first you need to evaluate just how appropriate it is in light of the visual design and user interactions you’re working on. To help you get started, here’s how I go about tackling the factors you need to watch for, and I’ll discuss some alternate solutions if mobile-first doesn’t seem to suit your project. Advantages of mobile-first Some of the things to like with mobile-first CSS development—and why it’s been the de facto development methodology for so long—make a lot of sense: One thing you undoubtedly get from mobile-first is a nice development hierarchy—you just focus on the mobile view and get developing.  It’s a tried and tested methodology that’s worked for years for a reason: it solves a problem really well. . The mobile view is the simplest and arguably the most important, as it  , and often accounts for a   (depending on the project).  As development is done using desktop computers, it can be tempting to initially focus on the desktop view. But thinking about mobile from the start prevents us from getting stuck later on; no one wants to spend their time retrofitting a desktop-centric site to work on mobile devices! Disadvantages of mobile-first Setting style declarations and then overwriting them at higher breakpoints can lead to undesirable ramifications: The farther up the breakpoint hierarchy you go, the more unnecessary code you inherit from lower breakpoints.  Styles that have been reverted to their browser default value in a class name declaration now have a higher specificity. This can be a headache on large projects when you want to keep the CSS selectors as simple as possible. Changes to the CSS at a lower view (like adding a new style) requires all higher breakpoints to be regression tested. At wider breakpoints, classic mobile-first   media queries don’t leverage the browser’s capability to download CSS files in priority order. The problem of property value overrides There is nothing inherently wrong with overwriting values; CSS was designed to do just that. Still, inheriting incorrect values is unhelpful and can be burdensome and inefficient. It can also lead to increased style specificity when you have to overwrite styles to reset them back to their defaults, something that may cause issues later on, especially if you are using a combination of bespoke CSS and utility classes. We won’t be able to use a utility class for a style that has been reset with a higher specificity. With this in mind, I’m developing CSS with a focus on the default values much more these days. Since there’s no specific order, and no chains of specific values to keep track of, this frees me to develop breakpoints  . I concentrate on finding common styles and isolating the specific exceptions in closed media query ranges (that is, any range with a   set).  This approach opens up some opportunities, as you can look at each breakpoint as a clean slate. If a component’s layout looks like it should be based on Flexbox at all breakpoints, it’s fine and can be coded in the default style sheet. But if it looks like Grid would be much better for large screens and Flexbox for mobile, these can both be done entirely independently when the CSS is put into closed media query ranges. Also, developing simultaneously requires you to have a good understanding of any given component in all breakpoints up front. This can help surface issues in the design earlier in the development process. We don’t want to get stuck down a rabbit hole building a complex component for mobile, and then get the designs for desktop and find they are equally complex and incompatible with the HTML we created for the mobile view!  Though this approach isn’t going to suit everyone, I encourage you to give it a try. There are plenty of tools out there to help with concurrent development, such as  ,  , and many others.  Having said that, I don’t feel the order itself is particularly relevant. If you are comfortable with focusing on the mobile view, have a good understanding of the requirements for other breakpoints, and prefer to work on one device at a time, then by all means stick with the classic development order. The important thing is to identify common styles and exceptions so you can put them in the relevant stylesheet—a sort of manual tree-shaking process! Personally, I find this a little easier when working on a component across breakpoints, but that’s by no means a requirement. Closed media query ranges in practice  In classic mobile-first CSS we overwrite the styles, but we can avoid this by using media query ranges. To illustrate the difference (I’m using SCSS for brevity), let’s assume there are three visual designs:  smaller than 768 from 768 to below 1024 1024 and anything larger  Take a simple example where a block-level element has a default   of “20px,” which is overwritten at tablet to be “40px” and set back to “20px” on desktop. Classic   mobile-first Closed media query range The subtle difference is that the mobile-first example sets the default   to “20px” and then overwrites it at each breakpoint, setting it three times in total. In contrast, the second example sets the default   to “20px” and only overrides it at the relevant breakpoint where it isn’t the default value (in this instance, tablet is the exception). The goal is to:  Only set styles when needed.  Not set them with the   of overwriting them later on, again and again.  To this end, closed media query ranges are our best friend. If we need to make a change to any given view, we make it in the CSS media query range that applies to the specific breakpoint. We’ll be much less likely to introduce unwanted alterations, and our regression testing only needs to focus on the breakpoint we have actually edited.  Taking the above example, if we find that   spacing on desktop is already accounted for by the margin at that breakpoint, and since we want to remove the padding altogether, we could do this by setting the mobile   in a closed media query range. The browser default   for our block is “0,” so instead of adding a desktop media query and using   or “0” for the   value (which we would need with mobile-first), we can wrap the mobile   in a closed media query (since it is now also an exception) so it won’t get picked up at wider breakpoints. At the desktop breakpoint, we won’t need to set any   style, as we want the browser default value. Bundling versus separating the CSS Back in the day, keeping the number of requests to a minimum was very important due to the browser’s limit of concurrent requests (typically around six). As a consequence, the use of image sprites and CSS bundling was the norm, with all the CSS being downloaded in one go, as one stylesheet with highest priority.  With HTTP/2 and HTTP/3 now on the scene, the number of requests is no longer the big deal it used to be. This allows us to separate the CSS into multiple files by media query. The clear benefit of this is the browser can now request the CSS it currently needs with a higher priority than the CSS it doesn’t. This is more performant and can reduce the overall time  . Which HTTP version are you using? To determine which version of HTTP you’re using, go to your website and open your browser’s dev tools. Next, select the   tab and make sure the   column is visible. If “h2” is listed under  , it means HTTP/2 is being used.  Also, if your site is still using HTTP/1...WHY?!! What are you waiting for? There is  . Splitting the CSS Separating the CSS into individual files is a worthwhile task. Linking the separate CSS files using the relevant   attribute allows the browser to identify which files are needed immediately (because they’re render-blocking) and which can be deferred. Based on this, it allocates each file an appropriate priority. In the following example of a website visited on a mobile breakpoint, we can see the mobile and default CSS are loaded with “Highest” priority, as they are currently needed to render the page. The remaining CSS files (print, tablet, and desktop) are still downloaded in case they’ll be needed later, but with “Lowest” priority.  With , the browser will have to download the CSS file and parse it before rendering can start. While, as noted, with the   linked and marked up with the relevant   attribute, the browser can prioritize the files it currently needs. Using closed media query ranges allows the browser to do this at all widths, as opposed to classic mobile-first   queries, where the desktop browser would have to download all the CSS with Highest priority. We can’t assume that desktop users always have a fast connection. For instance, in many rural areas, internet connection speeds are still slow.  The media queries and number of separate CSS files will vary from project to project based on project requirements, but might look similar to the example below. Bundled CSS This single file contains all the CSS, including all media queries, and it will be downloaded with Highest priority. Separated CSS Separating the CSS and specifying a   attribute value on each   tag allows the browser to prioritize what it currently needs. Out of the five files listed above, two will be downloaded with Highest priority: the default file, and the file that matches the current media query. The others will be downloaded with Lowest priority. Depending on the project’s deployment strategy, a change to one file ( , for example) would only require the QA team to regression test on devices in that specific media query range. Compare that to the prospect of deploying the single bundled   file, an approach that would normally trigger a full regression test. Moving on The uptake of mobile-first CSS was a really important milestone in web development; it has helped front-end developers focus on mobile web applications, rather than developing sites on desktop and then attempting to retrofit them to work on other devices. I don’t think anyone wants to return to that development model again, but it’s important we don’t lose sight of the issue it highlighted: that things can easily get convoluted and less efficient if we prioritize one particular device—any device—over others. For this reason, focusing on the CSS in its own right, always mindful of what is the default setting and what’s an exception, seems like the natural next step. I’ve started noticing small simplifications in my own CSS, as well as other developers’, and that testing and maintenance work is also a bit more simplified and productive.  In general, simplifying CSS rule creation whenever we can is ultimately a cleaner approach than going around in circles of overrides. But whichever methodology you choose, it needs to suit the project. Mobile-first may—or may not—turn out to be the best choice for what’s involved, but first you need to solidly understand the trade-offs you’re stepping into. Like this: \n\t\t\t\t\t\t\tRecently by Patrick Clancey\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/personalization-pyramid/", "title": "Personalization Pyramid: A Framework for Designing with User Data", "content": "As a UX professional in today’s data-driven landscape, it’s increasingly likely that you’ve been asked to design a personalized digital experience, whether it’s a public website, user portal, or native application. Yet while there continues to be no shortage of marketing hype around personalization platforms, we still have very few standardized approaches for implementing personalized UX. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. That’s where we come in. After completing dozens of personalization projects over the past few years, we gave ourselves a goal: could you create a holistic personalization framework specifically for UX practitioners? The   is a designer-centric model for standing up human-centered personalization programs, spanning data, segmentation, content delivery, and overall goals. By using this approach, you will be able to understand the core components of a contemporary, UX-driven personalization program (or at the very least know enough to get started).   According to a Dynamic Yield survey, 39% of respondents felt support is available on-demand when a business case is made for it (up 15% from 2020). For the sake of this article, we’ll assume you’re already familiar with the basics of digital personalization. A good overview can be found here:  . While UX projects in this area can take on many different forms, they often stem from similar starting points.       Your organization or client purchased a content management system (CMS) or marketing automation platform (MAP) or related technology that supports personalization The CMO, CDO, or CIO has identified personalization as a goal Customer data is disjointed or ambiguous You are running some isolated targeting campaigns or A/B testing Stakeholders disagree on personalization approach Mandate of customer privacy rules (e.g. GDPR) requires revisiting existing user targeting practices Regardless of where you begin, a successful personalization program will require the same core building blocks. We’ve captured these as the “levels” on the pyramid. Whether you are a UX designer, researcher, or strategist, understanding the core components can help make your contribution successful.   From top to bottom, the levels include: We’ll go through each of these levels in turn. To help make this actionable, we created an accompanying   to illustrate specific examples from each level. We’ve found them helpful in personalization brainstorming sessions, and will include examples for you here. The components of the pyramid are as follows: North Star A north star is what you are aiming for overall with your personalization program (big or small). The North Star defines the (one) overall mission of the personalization program. What do you wish to accomplish? North Stars cast a shadow. The bigger the star, the bigger the shadow. Example of North Starts might include:  Goals As in any good UX design, personalization can help accelerate   are the tactical and measurable metrics that will prove the overall program is successful. A good place to start is with your current analytics and measurement program and metrics you can benchmark against. In some cases, new goals may be appropriate. The key thing to remember is that  , rather it is a means to an end. Common goals include: Conversion Time on task Net promoter score (NPS) Customer satisfaction  Touchpoints Touchpoints are where the personalization happens. As a UX designer, this will be one of your largest areas of responsibility. The touchpoints available to you will depend on how your personalization and associated technology capabilities are instrumented, and should be rooted in improving a user’s experience at a particular point in the journey. Touchpoints can be multi-device (mobile, in-store, website) but also more granular (web banner, web pop-up etc.). Here are some examples: Touchpoints Email: Role Email: Time of open In-store display (JSON endpoint) Native app Search Touchpoints Web overlay Web alert bar Web banner Web content block Web menu If you’re designing for web interfaces, for example, you will likely need to include personalized “zones” in your wireframes. The content for these can be presented programmatically in touchpoints based on our next step, contexts and campaigns. Contexts and Campaigns Once you’ve outlined some touchpoints, you can consider the actual personalized content a user will receive. Many personalization tools will refer to these as “campaigns” (so, for example, a campaign on a web banner for new visitors to the website). These will programmatically be shown at certain touchpoints to certain user segments, as defined by user data. At this stage, we find it helpful to consider two separate models: a   and a  . The context helps you consider the level of engagement of the user at the personalization moment, for example a user casually browsing information vs. doing a deep-dive. Think of it in terms of information retrieval behaviors. The content model can then help you determine what type of personalization to serve based on the context (for example, an “Enrich” campaign that shows related articles may be a suitable supplement to extant content). Personalization   Model: Personalization   Model: We’ve written extensively about each of these models elsewhere, so if you’d like to read more you can check out Colin’s   and Jeff’s  .  User Segments User segments can be created prescriptively or adaptively, based on user research (e.g. via rules and logic tied to set user behaviors or via A/B testing). At a minimum you will likely need to consider how to treat the   or first-time visitor, the   or returning visitor for whom you may have a stateful cookie (or equivalent post-cookie identifier), or the   visitor who is logged in. Here are some examples from the personalization pyramid: Unknown Guest Authenticated Default Referred Role Cohort Unique ID Actionable Data Every organization with any digital presence has data. It’s a matter of asking what data you can ethically collect on users, its inherent reliability and value, as to how can you use it (sometimes known as “data activation.”) Fortunately, the tide is turning to first-party data: a recent study by Twilio estimates some   to personalize the customer experience.  First-party data represents multiple advantages on the UX front, including being relatively simple to collect, more likely to be accurate, and less susceptible to the “creep factor” of third-party data. So a key part of your UX strategy should be to determine what the best form of data collection is on your audiences. Here are some examples: There is a progression of profiling when it comes to recognizing and making decisioning about different audiences and their signals. It tends to move towards more granular constructs about smaller and smaller cohorts of users as time and confidence and data volume grow. While some combination of     is generally a prerequisite for any implementation (more commonly referred to as first party and third-party data)   are typically not cost-effective directly out of the box. This is because a strong data backbone and content repository is a prerequisite for optimization. But these approaches should be considered as part of the larger roadmap and may indeed help accelerate the organization’s overall progress. Typically at this point you will partner with key stakeholders and product owners to design a  . The profiling model includes defining approach to configuring profiles, profile keys, profile cards and pattern cards. A multi-faceted approach to profiling which makes it scalable. Pulling it Together While the cards comprise the starting point to an inventory of sorts (we provide blanks for you to tailor your own), a set of potential levers and motivations for the style of personalization activities you aspire to deliver, they are more valuable when thought of in a grouping.  In assembling a card “hand”, one can begin to trace the entire trajectory from leadership focus down through a strategic and tactical execution. It is also at the heart of the way both co-authors have conducted workshops in assembling a program backlog—which is a fine subject for another article. In the meantime, what is important to note is that each colored class of card is helpful to survey in understanding the range of choices potentially at your disposal, it is threading through and making concrete decisions about for whom this decisioning will be made: where, when, and how. Lay Down Your Cards Any sustainable personalization strategy must consider near, mid and long-term goals. Even with the leading CMS platforms like Sitecore and Adobe or the most exciting composable CMS DXP out there, there is simply no “easy button” wherein a personalization program can be stood up and immediately view meaningful results. That said, there is a common grammar to all personalization activities, just like every sentence has nouns and verbs. These cards attempt to map that territory. Like this: \n\t\t\t\t\t\t\tRecently by Colin Eagan\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/humility-an-essential-value/", "title": "Humility: An Essential Value", "content": "Humility, a designer’s essential value—that has a nice ring to it. What about humility, an office manager’s essential value? Or a dentist’s? Or a librarian’s? They all sound great. When humility is our guiding light, the path is always open for fulfillment, evolution, connection, and engagement. In this chapter, we’re going to talk about why. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. That said, this is a book for designers, and to that end, I’d like to start with a story—well, a journey, really. It’s a personal one, and I’m going to make myself a bit vulnerable along the way. I call it: When I was coming out of art school, a long-haired, goateed neophyte, print was a known quantity to me; design on the web, however, was rife with complexities to navigate and discover, a problem to be solved. Though I had been formally trained in graphic design, typography, and layout, what fascinated me was how these traditional skills might be applied to a fledgling digital landscape. This theme would ultimately shape the rest of my career. So rather than graduate and go into print like many of my friends, I devoured HTML and JavaScript books into the wee hours of the morning and taught myself how to code during my senior year. I wanted—nay, needed—to better understand the underlying implications of what my design decisions would mean once rendered in a browser. The late ’90s and early 2000s were the so-called “Wild West” of web design. Designers at the time were all figuring out how to apply design and visual communication to the digital landscape. What were the rules? How could we break them and still engage, entertain, and convey information? At a more macro level, how could my values, inclusive of humility, respect, and connection, align in tandem with that? I was hungry to find out. Though I’m talking about a different era, those are timeless considerations between non-career interactions and the world of design. What are your core passions, or values, that transcend medium? It’s essentially the same concept we discussed earlier on the direct parallels between what fulfills you, agnostic of the tangible or digital realms; the core themes are all the same. First within tables, animated GIFs, Flash, then with Web Standards,  s, and CSS, there was personality, raw unbridled creativity, and unique means of presentment that often defied any semblance of a visible grid. Splash screens and “browser requirement” pages aplenty. Usability and accessibility were typically victims of such a creation, but such paramount facets of any digital design were largely (and, in hindsight, unfairly) disregarded at the expense of experimentation. For example, this iteration of my personal portfolio site (“the pseudoroom”) from that era was experimental, if not a bit heavy- handed, in the visual communication of the concept of a living sketchbook. Very skeuomorphic. I collaborated with fellow designer and dear friend Marc Clancy (now a co-founder of the creative project organizing app Milanote) on this one, where we’d first sketch and then pass a Photoshop file back and forth to trick things out and play with varied user interactions. Then, I’d break it down and code it into a digital layout. Along with design folio pieces, the site also offered free downloads for Mac OS customizations: desktop wallpapers that were effectively design experimentation, custom-designed typefaces, and desktop icons. From around the same time, GUI Galaxy was a design, pixel art, and Mac-centric news portal some graphic designer friends and I conceived, designed, developed, and deployed. Design news portals were incredibly popular during this period, featuring (what would now be considered) Tweet-size, small-format snippets of pertinent news from the categories I previously mentioned. If you took Twitter, curated it to a few categories, and wrapped it in a custom-branded experience, you’d have a design news portal from the late 90s / early 2000s. We as designers had evolved and created a bandwidth-sensitive, web standards award-winning, much more accessibility-conscious website. Still ripe with experimentation, yet more mindful of equitable engagement. You can see a couple of content panes here, noting general news (tech, design) and Mac-centric news below. We also offered many of the custom downloads I cited before as present on my folio site but branded and themed to GUI Galaxy. The site’s backbone was a homegrown CMS, with the presentation layer consisting of global design + illustration + news author collaboration. And the collaboration effort here, in addition to experimentation on a ‘brand’ and content delivery, was hitting my core. We were designing something bigger than any single one of us and connecting with a global audience. Collaboration and connection transcend medium in their impact, immensely fulfilling me as a designer. Now, why am I taking you down this trip of design memory lane? Two reasons. First, there’s a reason for the nostalgia for that design era (the “Wild West” era, as I called it earlier): the inherent exploration, personality, and creativity that saturated many design portals and personal portfolio sites. Ultra-finely detailed pixel art UI, custom illustration, bespoke vector graphics, all underpinned by a strong design community. Today’s web design has been in a period of stagnation. I suspect there’s a strong chance you’ve seen a site whose structure looks something like this: a hero image / banner with text overlaid, perhaps with a lovely rotating carousel of images (laying the snark on heavy there), a call to action, and three columns of sub-content directly beneath. Maybe an icon library is employed with selections that vaguely relate to their respective content. Design, as it’s applied to the digital landscape, is in dire need of thoughtful layout, typography, and visual engagement that goes hand-in-hand with all the modern considerations we now know are paramount: usability. Accessibility. Load times and bandwidth- sensitive content delivery. A responsive presentation that meets human beings wherever they’re engaging from. We must be mindful of, and respectful toward, those concerns—but not at the expense of creativity of visual communication or via replicating cookie-cutter layouts. Pixel Problems Websites during this period were often designed and built on Macs whose OS and desktops looked something like this. This is Mac OS 7.5, but 8 and 9 weren’t that different. Desktop icons fascinated me: how could any single one, at any given point, stand out to get my attention? In this example, the user’s desktop is tidy, but think of a more realistic example with icon pandemonium. Or, say an icon was part of a larger system grouping (fonts, extensions, control panels)—how did it also maintain cohesion amongst a group? These were 32 x 32 pixel creations, utilizing a 256-color palette, designed pixel-by-pixel as mini mosaics. To me, this was the embodiment of digital visual communication under such ridiculous constraints. And often, ridiculous restrictions can yield the purification of concept and theme. So I began to research and do my homework. I was a student of this new medium, hungry to dissect, process, discover, and make it my own. Expanding upon the notion of exploration, I wanted to see how I could push the limits of a 32×32 pixel grid with that 256-color palette. Those ridiculous constraints forced a clarity of concept and presentation that I found incredibly appealing. The digital gauntlet had been tossed, and that challenge fueled me. And so, in my dorm room into the wee hours of the morning, I toiled away, bringing conceptual sketches into mini mosaic fruition. These are some of my creations, utilizing the only tool available at the time to create icons called ResEdit. ResEdit was a clunky, built-in Mac OS utility not really made for exactly what we were using it for. At the core of all of this work: Research. Challenge. Problem- solving. Again, these core connection-based values are agnostic of medium. There’s one more design portal I want to talk about, which also serves as the second reason for my story to bring this all together. This is K10k, short for Kaliber 1000. K10k was founded in 1998 by Michael Schmidt and Toke Nygaard, and was  design news portal on the web during this period. With its pixel art-fueled presentation, ultra-focused care given to every facet and detail, and with many of the more influential designers of the time who were invited to be news authors on the site, well… it was the place to be, my friend. With respect where respect is due, GUI Galaxy’s concept was inspired by what these folks were doing. For my part, the combination of my web design work and pixel art exploration began to get me some notoriety in the design scene. Eventually, K10k noticed and added me as one of their very select group of news authors to contribute content to the site. Amongst my personal work and side projects—and now with this inclusion—in the design community, this put me on the map. My design work also began to be published in various printed collections, in magazines domestically and overseas, and featured on other design news portals. With that degree of success while in my early twenties, something else happened: I evolved—devolved, really—into a colossal asshole (and in just about a year out of art school, no less). The press and the praise became what fulfilled me, and they went straight to my head. They inflated my ego. I actually felt somewhat superior to my fellow designers. The casualties? My design stagnated. Its evolution—my evolution— stagnated. I felt so supremely confident in my abilities that I effectively stopped researching and discovering. When previously sketching concepts or iterating ideas in lead was my automatic step one, I instead leaped right into Photoshop. I drew my inspiration from the smallest of sources (and with blinders on). Any critique of my work from my peers was often vehemently dismissed. The most tragic loss: I had lost touch with my values. My ego almost cost me some of my friendships and burgeoning professional relationships. I was toxic in talking about design and in collaboration. But thankfully, those same friends gave me a priceless gift: candor. They called me out on my unhealthy behavior. Admittedly, it was a gift I initially did not accept but ultimately was able to deeply reflect upon. I was soon able to accept, and process, and course correct. The realization laid me low, but the re-awakening was essential. I let go of the “reward” of adulation and re-centered upon what stoked the fire for me in art school. Most importantly: I got back to my core values. Always Students Following that short-term regression, I was able to push forward in my personal design and career. And I could self-reflect as I got older to facilitate further growth and course correction as needed. As an example, let’s talk about the Large Hadron Collider. The LHC was designed  Thanks, Wikipedia. Around fifteen years ago, in one of my earlier professional roles, I designed the interface for the application that generated the LHC’s particle collision diagrams. These diagrams are the rendering of what’s actually happening inside the Collider during any given particle collision event and are often considered works of art unto themselves. Designing the interface for this application was a fascinating process for me, in that I worked with Fermilab physicists to understand what the application was trying to achieve, but also how the physicists themselves would be using it. To that end, in this role, I cut my teeth on usability testing, working with the Fermilab team to iterate and improve the interface. How they spoke and what they spoke about was like an alien language to me. And by making myself humble and working under the mindset that I was but a student, I made myself available to be a part of their world to generate that vital connection. I also had my first ethnographic observation experience: going to the Fermilab location and observing how the physicists used the tool in their actual environment, on their actual terminals. For example, one takeaway was that due to the level of ambient light-driven contrast within the facility, the data columns ended up using white text on a dark gray background instead of black text-on-white. This enabled them to pore over reams of data during the day and ease their eye strain. And Fermilab and CERN are government entities with rigorous accessibility standards, so my knowledge in that realm also grew. The barrier-free design was another essential form of connection. So to those core drivers of my visual problem-solving soul and ultimate fulfillment: discovery, exposure to new media, observation, human connection, and evolution. What opened the door for those values was me checking my ego before I walked through it. An evergreen willingness to listen, learn, understand, grow, evolve, and connect yields our best work. In particular, I want to focus on the words ‘grow’ and ‘evolve’ in that statement. If we are always students of our craft, we are also continually making ourselves available to evolve. Yes, we have years of applicable design study under our belt. Or the focused lab sessions from a UX bootcamp. Or the monogrammed portfolio of our work. Or, ultimately, decades of a career behind us. But all that said: experience does not equal “expert.” As soon as we close our minds via an inner monologue of ‘knowing it all’ or branding ourselves a “#thoughtleader” on social media, the designer we  is our final form. The designer we  will never exist. Like this: \n\t\t\t\t\t\t\tRecently by Justin Dauer\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/i-am-a-creative/", "title": "I am a creative.", "content": "I am a creative. What I do is alchemy. It is a mystery. I do not so much do it, as let it be done through me. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I am a creative. Not all creative people like this label. Not all see themselves this way. Some creative people see science in what they do. That is their truth, and I respect it. Maybe I even envy them, a little. But my process is different—my being is different. Apologizing and qualifying in advance is a distraction. That’s what my brain does to sabotage me. I set it aside for now. I can come back later to apologize and qualify. After I’ve said what I came to say. Which is hard enough.  Sometimes it   come that way. Sometimes what I need to create comes in an instant. I have learned not to say it at that moment, because if you admit that sometimes the idea just comes and it is the best idea and you know it is the best idea, they think you don’t work hard enough. Sometimes I work and work and work until the idea comes. Sometimes it comes instantly and I don’t tell anyone for three days. Sometimes I’m so excited by the idea that came instantly that I blurt it out, can’t help myself. Like a boy who found a prize in his Cracker Jacks. Sometimes I get away with this. Sometimes other people agree: yes, that   the best idea. Most times they don’t and I regret having  given way to enthusiasm.  Enthusiasm is best saved for the meeting where it will make a difference. Not the casual get-together that precedes that meeting by two other meetings. Nobody knows why we have all these meetings. We keep saying we’re doing away with them, but then just finding other ways to have them. Sometimes they are even good. But other times they are a distraction from the actual work. The proportion between when meetings are useful, and when they are a pitiful distraction, varies, depending on what you do and where you do it. And who you are and how you do it. Again I digress. I am a creative.   is the theme. Sometimes many hours of hard and patient work produce something that is barely serviceable. Sometimes I have to accept that and move on to the next project. Don’t ask about process. I am a creative.  I am a creative. I don’t control my dreams. And I don’t control my best ideas.  I can hammer away, surround myself with facts or images, and sometimes that works. I can go for a walk, and sometimes that works. I can be making dinner and there’s a Eureka having nothing to do with sizzling oil and bubbling pots. Often I know what to do the instant I wake up. And then, almost as often, as I become conscious and part of the world again, the idea that would have saved me turns to vanishing dust in a mindless wind of oblivion. For creativity, I believe, comes from that other world. The one we enter in dreams, and perhaps, before birth and after death. But that’s for poets to wonder, and I am not a poet. I am a creative. And it’s for theologians to mass armies about in their creative world that they insist is real. But that is another digression. And a depressing one. Maybe on a much more important topic than whether I am a creative or not. But still a digression from what I came here to say. Sometimes the process is avoidance. And agony. You know the cliché about the tortured artist? It’s true, even when the artist (and let’s put that noun in quotes) is trying to write a soft drink jingle, a callback in a tired sitcom, a budget request. Some people who hate being called creative may be closeted creatives, but that’s between them and their gods. No offense meant. Your truth is true, too. But mine is for me.  Creatives recognize creatives. Creatives recognize creatives like queers recognize queers, like real rappers recognize real rappers, like cons know cons. Creatives feel massive respect for creatives. We love, honor, emulate, and practically deify the great ones. To deify any human is, of course, a tragic mistake. We have been warned. We know better. We know people are just people. They squabble, they are lonely, they regret their most important decisions, they are poor and hungry, they can be cruel, they can be just as stupid as we can, because, like us, they are clay. But. But. But they make this amazing thing. They birth something that did not exist before them, and could not exist without them. They are the mothers of ideas. And I suppose, since it’s just lying there, I have to add that they are the mothers of invention.  OK, that’s done. Continue.  Creatives belittle our own small achievements, because we compare them to those of the great ones. Beautiful animation! Well, I’m no Miyazaki. Now THAT is greatness. That is greatness straight from the mind of God. This half-starved little thing that   made? It more or less fell off the back of the turnip truck. And the turnips weren’t even fresh. Creatives knows that, at best, they are  . Even the creatives who are Mozart believe that.  I am a creative. I haven’t worked in advertising in 30 years, but in my nightmares, it’s my former creative directors who judge me. And they are right to do so. I am too lazy, too facile, and when it really counts, my mind goes blank. There is no pill for creative dysfunction. I am a creative. Every deadline I make is an adventure that makes Indiana Jones look like a pensioner snoring in a deck chair. The longer I remain a creative, the faster I am when I do my work and the longer I brood and walk in circles and stare blankly before I do that work.  I am still 10 times faster than people who are not creative, or people who have only been creative a short while, or people who have only been professionally creative a short while. It’s just that, before I work 10 times as fast as they do, I spend twice as long as they do putting the work off. I am that confident in my ability to do a great job when I put my mind to it. I am that addicted to the adrenaline rush of postponement. I am still that afraid of the jump. I am not an artist. I am a creative. Not an artist. Though I dreamed, as a lad, of someday being that. Some of us belittle our gifts and dislike ourselves because we are not Michelangelos and Warhols. That is narcissism—but at least we aren’t in politics. I am a creative. Though I believe in reason and science, I decide by intuition and impulse. And live with what follows—the catastrophes as well as the triumphs.  I am a creative. Every word I’ve said here will annoy other creatives, who see things differently. Ask two creatives a question, get three opinions. Our disagreement, our passion about it, and our commitment to our own truth are, at least to me, the proofs that we are creatives, no matter how we may feel about it. I am a creative. I lament my lack of taste in the areas about which I know very little, which is to say almost all areas of human knowledge. And I trust my taste above all other things in the areas closest to my heart, or perhaps, more accurately, to my obsessions. Without my obsessions, I would probably have to spend my time looking life in the eye, and almost none of us can do that for long. Not honestly. Not really. Because much in life, if you really look at it, is unbearable. I am a creative. I believe, as a parent believes, that when I am gone, some small good part of me will carry on in the mind of at least one other person. Working saves me from worrying about work. I am a creative. I live in dread of my small gift suddenly going away. I am a creative. I am too busy making the next thing to spend too much time deeply considering that almost nothing I make will come anywhere near the greatness I comically aspire to. I am a creative. I believe in the ultimate mystery of process. I believe in it so much, I am even fool enough to publish an essay I dictated into a tiny machine and didn’t take time to review or revise. I won’t do this often, I promise. But I did it just now, because, as afraid as I might be of your seeing through my pitiful gestures toward the beautiful, I was even more afraid of forgetting what I came to say.  There. I think I’ve said it.  Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/opportunities-for-ai-in-accessibility/", "title": "Opportunities for AI in Accessibility", "content": "In reading  , I absolutely appreciated the skepticism that he has for AI in general as well as for the ways that many have been using it. In fact, I’m very skeptical of AI myself, despite my role at Microsoft as an accessibility innovation strategist who helps run the AI for Accessibility grant program. As with any tool, AI can be used in very constructive, inclusive, and accessible ways; and it can also be used in destructive, exclusive, and harmful ones. And there are a ton of uses somewhere in the mediocre middle as well. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I’d like you to consider this a “yes… and” piece to complement Joe’s post. I’m not trying to refute any of what he’s saying but rather provide some visibility to projects and opportunities where AI can make meaningful differences for people with disabilities. To be clear, I’m not saying that there aren’t real risks or pressing issues with AI that need to be addressed—there are, and we’ve needed to address them, like, yesterday—but I want to take a little time to talk about what’s possible in hopes that we’ll get there one day. Joe’s piece spends a lot of time talking about computer-vision models generating alternative text. He highlights a ton of valid issues with the current state of things. And while computer-vision models continue to improve in the quality and richness of detail in their descriptions, their results aren’t great. As he rightly points out, the current state of image analysis is pretty poor—especially for certain image types—in large part because current AI systems examine images in isolation rather than within the contexts that they’re in (which is a consequence of having separate “foundation” models for text analysis and image analysis). Today’s models aren’t trained to distinguish between images that are contextually relevant (that should probably have descriptions) and those that are purely decorative (which might not need a description) either. Still, I still think there’s potential in this space. As Joe mentions, human-in-the-loop authoring of alt text should absolutely be a thing. And if AI can pop in to offer a starting point for alt text—even if that starting point might be a prompt saying  —I think that’s a win. Taking things a step further, if we can specifically train a model to analyze image usage in context, it could help us more quickly identify which images are likely to be decorative and which ones likely require a description. That will help reinforce which contexts call for image descriptions   it’ll improve authors’ efficiency toward making their pages more accessible. While complex images—like graphs and charts—are challenging to describe in any sort of succinct way (even for humans),   points to an interesting opportunity as well. Let’s suppose that you came across a chart whose description was simply the title of the chart and the kind of visualization it was, such as:   (That would be a pretty awful alt text for a chart since that would tend to leave many questions about the data unanswered, but then again, let’s suppose that that was the description that was in place.) If your browser knew that that image was a pie chart (because an onboard model concluded this), imagine a world where users could ask questions like these about the graphic: Setting aside the realities of  —where a model just makes up plausible-sounding “facts”—for a moment, the opportunity to learn more about images and data in this way could be revolutionary for blind and low-vision folks as well as for people with various forms of color blindness, cognitive disabilities, and so on. It could also be useful in educational contexts to help people who   see these charts, as is, to understand the data in the charts. Taking things a step further: What if you could ask your browser to simplify a complex chart? What if you could ask it to isolate a single line on a line graph? What if you could ask your browser to transpose the colors of the different lines to work better for form of color blindness you have? What if you could ask it to swap colors for patterns? Given these tools’ chat-based interfaces and our existing ability to manipulate images in today’s AI tools, that seems like a possibility. Now imagine a purpose-built model that could extract the information from that chart and convert it to another format. For example, perhaps it could turn that pie chart (or better yet, a series of pie charts) into more accessible (and useful) formats, like spreadsheets. That would be amazing! Safiya Umoja Noble absolutely hit the nail on the head when she titled her book  . While her book was focused on the ways that search engines reinforce racism, I think that it’s equally true that all computer models have the potential to amplify conflict, bias, and intolerance. Whether it’s Twitter always showing you the latest tweet from a bored billionaire, YouTube sending us into a Q-hole, or Instagram warping our ideas of what natural bodies look like, we know that poorly authored and maintained algorithms are incredibly harmful. A lot of this stems from a lack of diversity among the people who shape and build them. When these platforms are built with inclusively baked in, however, there’s real potential for algorithm development to help people with disabilities. Take  , for example. They are an employment network for neurodivergent people. They use an algorithm to match job seekers with potential employers based on over 75 data points. On the job-seeker side of things, it considers each candidate’s strengths, their necessary and preferred workplace accommodations, environmental sensitivities, and so on. On the employer side, it considers each work environment, communication factors related to each job, and the like. As a company run by neurodivergent folks, Mentra made the decision to flip the script when it came to typical employment sites. They use their algorithm to propose available candidates to companies, who can then connect with job seekers that they are interested in; reducing the emotional and physical labor on the job-seeker side of things. When more people with disabilities are involved in the creation of algorithms, that can reduce the chances that these algorithms will inflict harm on their communities. That’s why diverse teams are so important. Imagine that a social media company’s recommendation engine was tuned to analyze who you’re following and if it was tuned to prioritize follow recommendations for people who talked about similar things but who were different in some key ways from your existing sphere of influence. For example, if you were to follow a bunch of nondisabled white male academics who talk about AI, it could suggest that you follow academics who are disabled or aren’t white or aren’t male who also talk about AI. If you took its recommendations, perhaps you’d get a more holistic and nuanced understanding of what’s happening in the AI field. These same systems should also use their understanding of biases about particular communities—including, for instance, the disability community—to make sure that they aren’t recommending any of their users follow accounts that perpetuate biases against (or, worse, spewing hate toward) those groups. If I weren’t trying to put this together between other tasks, I’m sure that I could go on and on, providing all kinds of examples of how AI could be used to help people with disabilities, but I’m going to make this last section into a bit of a lightning round. In no particular order: Voice preservation. You may have seen   or   or you may be familiar with the voice-preservation offerings from  ,  , or others. It’s possible to train an AI model to replicate your voice, which can be a tremendous boon for people who have ALS (Lou Gehrig’s disease) or motor-neuron disease or other medical conditions that can lead to an inability to talk. This is, of course, the same tech that can also be used to create audio deepfakes, so it’s something that we need to approach  , but the tech has truly transformative potential. Voice recognition. Researchers like those in the   are paying people with disabilities for their help in collecting recordings of people with atypical speech. As I type, they are actively recruiting people with Parkinson’s and related conditions, and they have plans to expand this to other conditions as the project progresses. This research will result in more inclusive data sets that will let more people with disabilities use voice assistants, dictation software, and voice-response services as well as control their computers and other devices more easily, using only their voice. Text transformation. The current generation of LLMs is quite capable of adjusting existing text content without injecting hallucinations. This is hugely empowering for people with cognitive disabilities who may benefit from text summaries or simplified versions of text or even text that’s prepped for  . We need to recognize that our differences matter. Our lived experiences are influenced by the intersections of the identities that we exist in. These lived experiences—with all their complexities (and joys and pain)—are valuable inputs to the software, services, and societies that we shape. Our differences need to be represented in the data that we use to train new models, and the folks who contribute that valuable information need to be compensated for sharing it with us. Inclusive data sets yield more robust models that foster more equitable outcomes. Want a model that doesn’t demean or patronize or objectify people with disabilities? Make sure that you have content about disabilities that’s authored by people with a range of disabilities, and make sure that that’s well represented in the training data. Want a model that doesn’t use ableist language? You may be able to use   to build a filter that can intercept and remediate ableist language before it reaches readers. That being said, when it comes to sensitivity reading, AI models won’t be replacing human copy editors anytime soon.  Want a coding copilot that gives you accessible recommendations from the jump? Train it on code that you know to be accessible. I have no doubt that AI can and will harm people… today, tomorrow, and well into the future. But I also believe that we can acknowledge that and, with an eye towards accessibility (and, more broadly, inclusion), make thoughtful, considerate, and intentional changes in our approaches to AI that will reduce harm over time as well. Today, tomorrow, and well into the future. Many thanks to Kartik Sawhney for helping me with the development of this piece, Ashley Bischoff for her invaluable editorial assistance, and, of course, Joe Dolson for the prompt. Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-wax-and-the-wane-of-the-web/", "title": "The Wax and the Wane of the Web", "content": "I offer a single bit of advice to friends and family when they become new parents:   Just as you start to get the hang of feedings, diapers, and regular naps, it’s time for solid food, potty training, and overnight sleeping. When you figure those out, it’s time for preschool and rare naps. The cycle goes on and on. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The same applies for those of us working in design and development these days. Having worked on the web for almost three decades at this point, I’ve seen the regular wax and wane of ideas, techniques, and technologies. Each time that we as developers and designers get into a regular rhythm, some new idea or technology comes along to shake things up and remake our world. I built my first website in the mid-’90s. Design and development on the web back then was a free-for-all, with few established norms. For any layout aside from a single column, we used   elements, often with empty cells containing a single pixel spacer GIF to add empty space. We styled text with numerous   tags, nesting the tags every time we wanted to vary the font style. And we had only three or four typefaces to choose from: Arial, Courier, or Times New Roman. When Verdana and Georgia came out in 1996, we rejoiced because our options had nearly doubled. The only safe colors to choose from were the 216 “web safe” colors known to work across platforms. The few interactive elements (like contact forms, guest books, and counters) were mostly powered by CGI scripts (predominantly written in Perl at the time). Achieving any kind of unique look involved a pile of hacks all the way down. Interaction was often limited to specific pages in a site. At the turn of the century, a new cycle started. Crufty code littered with   layouts and   tags waned, and a push for web standards waxed.   got more widespread adoption by browsers makers, developers, and designers. This shift toward standards didn’t happen accidentally or overnight. It took active engagement between the   and browser vendors and heavy evangelism from folks like the  to build standards.   and books like   by Jeffrey Zeldman played key roles in teaching developers and designers why standards are important, how to implement them, and how to sell them to their organizations. And approaches like   introduced the idea that content should be available for all browsers—with additional enhancements available for more advanced browsers. Meanwhile, sites like the   showcased just how powerful and versatile CSS can be when combined with a solid semantic HTML structure. Server-side languages like PHP, Java, and .NET overtook Perl as the predominant back-end processors, and the cgi-bin was tossed in the trash bin. With these better server-side tools came the first era of web applications, starting with content-management systems (particularly in the blogging space with tools like  ,  ,  , and  ). In the mid-2000s,   opened doors for asynchronous interaction between the front end and back end. Suddenly, pages could update their content without needing to reload. A crop of JavaScript frameworks like  ,  , and   arose to help developers build more reliable client-side interaction across browsers that had wildly varying levels of standards support. Techniques like   let crafty designers and developers display fonts of their choosing. And technologies like Flash made it possible to add animations, games, and even more interactivity. These new technologies, standards, and techniques reinvigorated the industry in many ways. Web design flourished as designers and developers explored more diverse styles and layouts. But we still relied on tons of hacks. Early CSS was a huge improvement over table-based layouts when it came to basic layout and text styling, but its limitations at the time meant that designers and developers still relied heavily on images for   and tiled backgrounds for   (among other hacks). Complicated layouts required all manner of nested floats or absolute positioning (or both). Flash and image replacement for custom fonts was a great start toward varying the typefaces from the big five, but both hacks introduced accessibility and performance problems. And JavaScript libraries made it easy for anyone to add a dash of interaction to pages, although at the cost of doubling or even quadrupling the download size of simple websites. The symbiosis between the front end and back end continued to improve, and that led to the current era of modern web applications. Between expanded server-side programming languages (which kept growing to include Ruby, Python, Go, and others) and newer front-end tools like React, Vue, and Angular, we could build fully capable software on the web. Alongside these tools came others, including collaborative version control, build automation, and shared package libraries. What was once primarily an environment for linked documents became a realm of infinite possibilities. At the same time, mobile devices became more capable, and they gave us internet access in our pockets.   and   opened up opportunities for new interactions anywhere and any time. This combination of capable mobile devices and powerful development tools contributed to the waxing of social media and other centralized tools for people to connect and consume. As it became easier and more common to connect with others directly on Twitter, Facebook, and even Slack, the desire for hosted personal sites waned. Social media offered connections on a global scale, with both the good and bad that that entails. Want a much more extensive history of how we got here, with some other takes on ways that we can improve? Jeremy Keith wrote “ .” Or check out the “ ” at the  . Neal Agarwal also has a fun tour through “ .” In the last couple of years, it’s felt like we’ve begun to reach another major inflection point. As   and wane, there’s been a   again. There are many different ways to make a website, from the tried-and-true classic of hosting plain HTML files to   to content management systems of all flavors. The fracturing of social media also comes with a cost: we lose crucial infrastructure for discovery and connection.  ,  ,  , and other tools of the   can help with this, but they’re still relatively underimplemented and  . We can build amazing personal websites and add to them regularly, but without discovery and connection, it can sometimes feel like we may as well be shouting into the void. Browser support for CSS, JavaScript, and other standards like web components has accelerated, especially through efforts like  . New technologies gain support across the board in a fraction of the time that they used to. I often learn about a new feature and   only to find that its coverage is already above 80 percent. Nowadays, the barrier to using newer techniques often isn’t browser support but simply the limits of how quickly designers and developers can learn what’s available and how to adopt it. Today, with  , we can prototype almost any idea. All the tools that we now have available make it easier than ever to start something new. But the upfront cost that these frameworks may save in initial delivery eventually comes due as upgrading and maintaining them becomes a part of our technical debt. If we rely on third-party frameworks, adopting new standards can sometimes take longer since we may have to wait for those frameworks to adopt those standards. These frameworks—which used to let us adopt new techniques sooner—have now become hindrances instead. These same frameworks often come with   too, forcing users to wait for scripts to load before they can read or interact with pages. And when   (whether through poor code, network issues, or other environmental factors), there’s often no alternative, leaving users with blank or broken pages. Today’s hacks help to shape tomorrow’s standards. And there’s nothing inherently wrong with embracing hacks—for now—to move the present forward. Problems only arise when we’re unwilling to admit that they’re hacks or we hesitate to replace them. So what can we do to create the future we want for the web?  Optimize for performance, for accessibility, and for the user. Weigh the costs of those developer-friendly tools. They may make your job a little easier today, but how do they affect everything else? What’s the cost to users? To future developers? To standards adoption? Sometimes the convenience may be worth it. Sometimes it’s just a hack that you’ve grown accustomed to. And sometimes it’s holding you back from even better options.  Standards continue to evolve over time, but browsers have done a remarkably good job of continuing to support older standards. The same isn’t always true of third-party frameworks. Sites built with even the hackiest of HTML from the ’90s still   today. The same can’t always be said of sites built with frameworks even after just a couple years.  Whether your craft is code, pixels, or processes, consider the impacts of each decision. The convenience of many a modern tool comes at the cost of not always understanding the underlying decisions that have led to its design and not always considering the impact that those decisions can have. Rather than rushing headlong to “move fast and break things,” use the time saved by modern tools to consider more carefully and design with deliberation.  If you’re always learning, you’re also growing. Sometimes it may be hard to pinpoint what’s worth learning and what’s just today’s hack. You might end up focusing on something that won’t matter next year, even if you were to focus solely on learning standards. ( ) But constant learning opens up new connections in your brain, and the hacks that you learn one day may help to inform different experiments another day.  This web that we’ve built is the ultimate experiment. It’s the single largest human endeavor in history, and yet each of us can create our own pocket within it.  . Build a   for ideas. Make   in your own mad    . Start your own  . There has never been a more empowering place to be creative, take risks, and explore what we’re capable of.  As you experiment, play, and learn, share what’s worked for you. Write on your own website, post on whichever social media site you prefer, or shout it from a TikTok.  ! But take the time to   too: find new voices, learn from them, and share what they’ve taught you. As designers and developers for the web (and beyond), we’re responsible for building the future every day, whether that may take the shape of personal websites, social media tools used by billions, or anything in between. Let’s imbue our values into the things that we create, and let’s make the web a better place for everyone. Create that thing that only you are uniquely qualified to make. Then share it, make it better, make it again, or make something new. Learn. Make. Share. Grow. Rinse and repeat. Every time you think that you’ve mastered the web, everything will change. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/prepersonalization-workshop/", "title": "To Ignite a Personalization Practice, Run this Prepersonalization Workshop", "content": "Picture this. You’ve joined a squad at your company that’s designing new product features with an emphasis on automation or AI. Or your company has just implemented a  . Either way, you’re designing with data. Now what? When it comes to  , there are many cautionary tales, no overnight successes, and few guides for the perplexed.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Between the fantasy of getting it right and the fear of it going wrong—like when we encounter “ ” in the vein of a company  —the personalization gap is real. It’s an especially confounding place to be a digital professional without a map, a compass, or a plan. For those of you venturing into personalization, there’s no   and few tour guides because effective personalization is so specific to each organization’s talent, technology, and market position.  But you can ensure that your team has packed its bags sensibly. There’s a DIY formula to increase your chances for success. At minimum, you’ll defuse your boss’s irrational exuberance. Before the party you’ll need to effectively prepare. We call it  . Consider Spotify’s DJ feature, which debuted this past year. We’re used to seeing the polished final result of a personalization feature. Before  , the  , or the behind-the-scenes  , a personalized feature had to be conceived, budgeted, and prioritized. Before any personalization feature goes live in your product or service, it lives amid a backlog of worthy ideas for expressing customer experiences more dynamically. So how do you know where to place your personalization bets? How do you design consistent interactions that won’t trip up users or—worse—breed mistrust? We’ve found that for many budgeted programs to justify their ongoing investments, they first needed one or more workshops to convene key stakeholders and internal customers of the technology. Make yours count. ​From   to fledgling startups, we’ve seen the same evolution up close with our clients. In our experiences with working on small and large personalization efforts, a program’s ultimate track record—and its ability to weather tough questions, work steadily toward shared answers, and organize its design and technology efforts—turns on how effectively these prepersonalization activities play out. Time and again, we’ve seen effective workshops separate future success stories from unsuccessful efforts, saving countless time, resources, and collective well-being in the process. A personalization practice involves a multiyear effort of testing and feature development. It’s not a switch-flip moment in your tech stack. It’s best managed as a backlog that often evolves through three steps:  This is why we created our progressive personalization framework and why we’re field-testing an accompanying  : we believe that  . You won’t need these cards. But we strongly recommend that you create something similar, whether that might be digital or physical. Set your kitchen timer How long does it take to cook up a prepersonalization workshop? The surrounding assessment activities that we recommend including can (and often do) span weeks. For the core workshop, we recommend aiming for two to three days. Here’s a summary of our broader approach along with details on the essential first-day activities. The full arc of the wider workshop is threefold: Give yourself at least a day, split into two large time blocks, to power through a concentrated version of those first two phases. Kickstart: Whet your appetite We call the first lesson the “landscape of connected experience.” It explores the personalization possibilities in your organization. A  , in our parlance, is   on the backend. This could be a content-management system combined with a marketing-automation platform. It could be a digital-asset manager combined with a customer-data platform. Spark conversation by naming consumer examples and business-to-business examples of connected experience interactions that you admire, find familiar, or even dislike. This should cover a representative range of personalization patterns, including automated app-based interactions (such as onboarding sequences or wizards), notifications, and recommenders. We have a catalog of these in the cards. Here’s a list of   to jog your thinking. This is all about setting the table. What are the possible paths for the practice in your organization? If you want a broader view, here’s a   and a  . Assess each example that you discuss for its complexity and the level of effort that you estimate that it would take for your team to deliver that feature (or something similar). In our cards, we divide connected experiences into five levels: functions, features, experiences, complete products, and portfolios. Size your own build here. This will help to focus the conversation on the merits of ongoing investment as well as the gap between what you deliver today and what you want to deliver in the future. Next, have your team plot each idea on the following 2×2 grid, which lays out the   for a personalized experience. This is critical because it emphasizes how personalization can not only help your external customers but also affect your own ways of working. It’s also a reminder (which is why we used the word   earlier) of the broader effort beyond these tactical interventions. Each team member should vote on where they see your product or service putting its emphasis. Naturally, you can’t prioritize all of them. The intention here is to flesh out how different departments may view their own upsides to the effort, which can vary from one to the next. Documenting your desired outcomes lets you know how the team internally aligns across representatives from different departments or functional areas. The third and final kickstart activity is about naming your  . Is your customer journey well documented? Will data and privacy compliance be too big of a challenge? Do you have   that you have to address? (We’re pretty sure that you do: it’s just a matter of recognizing the relative size of that need and its remedy.) In our cards, we’ve noted a number of program risks, including common team dispositions. Our Detractor card, for example, lists six stakeholder behaviors that hinder progress. Effectively collaborating and managing expectations is critical to your success. Consider the potential barriers to your future progress. Press the participants to name specific steps to overcome or mitigate those barriers in your organization. As studies have shown, personalization efforts face many common barriers. At this point, you’ve hopefully discussed sample interactions, emphasized a key area of benefit, and flagged key gaps? Good—you’re ready to continue. Hit that test kitchen Next, let’s look at what you’ll need to bring your personalization recipes to life. Personalization engines, which are robust software suites for automating and expressing dynamic content, can intimidate new customers. Their capabilities are sweeping and powerful, and they present broad options for how your organization can conduct its activities. This presents the question: Where do you begin when you’re configuring a connected experience? What’s important here is to avoid treating the installed software like it were a dream kitchen from some fantasy remodeling project (as one of our client executives memorably put it). These software engines are more like   where your team can begin devising, tasting, and refining the snacks and meals that will become a part of your personalization program’s regularly evolving menu. The ultimate menu of the prioritized backlog will come together over the course of the workshop. And creating “dishes” is the way that you’ll have individual team stakeholders construct personalized interactions that serve their needs or the needs of others. The dishes will come from recipes, and those recipes have set ingredients. Verify your ingredients Like a good product manager, you’ll make sure—andyou’ll validate with the right stakeholders present—that you have all the ingredients on hand to cook up your desired interaction (or that you can work out what needs to be added to your pantry). These ingredients include the audience that you’re targeting, content and design elements, the context for the interaction, and your measure for how it’ll come together.  This isn’t just about discovering requirements. Documenting your personalizations as a series of if-then statements lets the team:  This helps you streamline your designs and your technical efforts while you deliver a shared palette of core motifs of your personalized or automated experience. Compose your recipe What ingredients are important to you? Think of a who-what-when-why  :  Who are your key audience segments or groups? What kind of content will you give them, in what design elements, and under what circumstances? And for which business and user benefits? We first developed these   five years ago. We regularly play-test their fit with conference audiences and clients. And we still encounter new possibilities. But they all follow an underlying who-what-when-why logic. Here are three examples for a subscription-based reading app, which you can generally follow along with right to left in the cards in the accompanying photo below.  A useful preworkshop activity may be to think through a first draft of what these cards might be for your organization, although we’ve also found that this process sometimes flows best through cocreating the recipes themselves. Start with a set of blank cards, and begin labeling and grouping them through the design process, eventually distilling them to a refined subset of highly useful candidate cards. You can think of the later stages of the workshop as   in focus—like a more nuanced customer-journey mapping. Individual “cooks” will pitch their recipes to the team, using a common   format so that measurability and results are baked in, and from there, the resulting collection will be prioritized for finished design and delivery to production. Better kitchens require better architecture Simplifying a customer experience is a complicated effort for those who are inside delivering it. Beware anyone who says otherwise. With that being said,  “Complicated problems can be hard to solve, but  .” When personalization becomes a laugh line, it’s because a team is  : they aren’t designing with their best data. Like a sparse pantry, every organization has metadata debt to go along with its technical debt, and this creates a drag on personalization effectiveness. Your AI’s output quality, for example, is indeed limited by your  . Spotify’s poster-child prowess today was unfathomable before they   a seemingly modest   that now   its underlying information architecture. You can definitely stand the heat… Personalization technology opens a doorway into a confounding ocean of possible designs. Only a disciplined and highly collaborative approach will bring about the necessary focus and intention to succeed. So banish the dream kitchen. Instead, hit the test kitchen to save time, preserve job satisfaction and security, and safely dispense with the fanciful ideas that originate upstairs of the doers in your organization. There are meals to serve and mouths to feed. This workshop framework gives you a fighting shot at lasting success as well as sound beginnings. Wiring up your information layer isn’t an overnight affair. But if you use the same cookbook and shared recipes, you’ll have solid footing for success. We designed these activities to make your organization’s needs concrete and clear, long before the hazards pile up. While there are associated costs toward investing in this kind of technology and product design, your ability to size up and confront your unique situation and your digital capabilities is time well spent. Don’t squander it. The proof, as they say, is in the pudding. Like this: \n\t\t\t\t\t\t\tRecently by Colin Eagan\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/user-research-is-storytelling/", "title": "User Research Is Storytelling", "content": "Ever since I was a boy, I’ve been fascinated with movies. I loved the characters and the excitement—but most of all the stories. I wanted to be an actor. And I believed that I’d get to do the things that Indiana Jones did and go on exciting adventures. I even dreamed up ideas for movies that my friends and I could make and star in. But they never went any further. I did, however, end up working in user experience (UX). Now, I realize that there’s an element of theater to UX—I hadn’t really considered it before, but user research is storytelling. And to get the most out of user research, you need to tell a good story where you bring stakeholders—the product team and decision makers—along and get them interested in learning more. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Think of your favorite movie. More than likely it follows a   that’s commonly seen in storytelling: the setup, the conflict, and the resolution. The first act shows what exists today, and it helps you get to know the characters and the challenges and problems that they face. Act two introduces the conflict, where the action is. Here, problems grow or get worse. And the third and final act is the resolution. This is where the issues are resolved and the characters learn and change. I believe that this structure is also a great way to think about user research, and I think that it can be especially helpful in explaining user research to others. It’s sad to say, but many have come to see research as being expendable. If budgets or timelines are tight, research tends to be one of the first things to go. Instead of investing in research, some product managers rely on designers or—worse—their own opinion to make the “right” choices for users based on their experience or accepted best practices. That may get teams some of the way, but that approach can so easily miss out on solving users’ real problems. To remain user-centered, this is something we should avoid. User research elevates design. It keeps it on track, pointing to problems and opportunities. Being aware of the issues with your product and reacting to them can help you stay ahead of your competitors. In the three-act structure, each act corresponds to a part of the process, and each part is critical to telling the whole story. Let’s look at the different acts and how they align with user research. Act one: setup The setup is all about understanding the background, and that’s where foundational research comes in.   (also called  ,  , or   research) helps you understand users and identify their problems. You’re learning about what exists today, the challenges users have, and how the challenges affect them—just like in the movies. To do foundational research, you can conduct   or  (or both!), which can help you start to identify problems as well as opportunities. It doesn’t need to be a huge investment in time or money. Erika Hall writes about , which can be as simple as spending 15 minutes with a user and asking them one thing: “‘Walk me through your day yesterday.’ That’s it. Present that one request. Shut up and listen to them for 15 minutes. Do your damndest to keep yourself and your interests out of it. Bam, you’re doing ethnography.” According to Hall,  [This] will probably prove quite illuminating. In the highly unlikely case that you didn’t learn anything new or useful, carry on with enhanced confidence in your direction.”   This makes total sense to me. And I love that this makes user research so accessible. You don’t need to prepare a lot of documentation; you can just recruit participants and do it! This can yield a wealth of information about your users, and it’ll help you better understand them and what’s going on in their lives. That’s really what act one is all about: understanding where users are coming from.   and how it should form the bulk of your research. If you can draw from any additional user data that you can get your hands on, such as surveys or analytics, that can supplement what you’ve heard in the foundational studies or even point to areas that need further investigation. Together, all this data paints a clearer picture of the state of things and all its shortcomings. And that’s the beginning of a compelling story. It’s the point in the plot where you realize that the main characters—or the users in this case—are facing challenges that they need to overcome. Like in the movies, this is where you start to build empathy for the characters and root for them to succeed. And hopefully stakeholders are now doing the same. Their sympathy may be with their business, which could be losing money because users can’t complete certain tasks. Or maybe they do empathize with users’ struggles. Either way, act one is your initial hook to get the stakeholders interested and invested. Once stakeholders begin to understand the value of foundational research, that can open doors to more opportunities that involve users in the decision-making process. And that can guide product teams toward being more user-centered. This benefits everyone—users, the product, and stakeholders. It’s like winning an Oscar in movie terms—it often leads to your product being well received and successful. And this can be an incentive for stakeholders to repeat this process with other products. Storytelling is the key to this process, and knowing how to tell a good story is the only way to get stakeholders to really care about doing more research.  This brings us to act two, where you iteratively evaluate a design or concept to see whether it addresses the issues. Act two: conflict Act two is all about digging deeper into the problems that you identified in act one. This usually involves  , such as usability tests, where you assess a potential solution (such as a design) to see whether it addresses the issues that you found. The issues could include unmet needs or problems with a flow or process that’s tripping users up. Like act two in a movie, more issues will crop up along the way. It’s here that you learn more about the characters as they grow and develop through this act.  Usability tests   according to Jakob Nielsen, who found that that number of users can usually identify most of the problems: “As you add more and more users, you learn less and less because you will keep seeing the same things again and again… After the fifth user, you are wasting your time by observing the same findings repeatedly but not learning much new.”  There are parallels with storytelling here too; if you try to tell a story with too many characters, the plot may get lost. Having fewer participants means that each user’s struggles will be more memorable and easier to relay to other stakeholders when talking about the research. This can help convey the issues that need to be addressed while also highlighting the value of doing the research in the first place. Researchers have run usability tests in person for decades, but you can also   using tools like Microsoft Teams, Zoom, or other teleconferencing software. This approach has become increasingly popular since the beginning of the pandemic, and it works well. You can think of in-person usability tests like going to a play and remote sessions as more like watching a movie. There are advantages and disadvantages to each. In-person usability research is a much richer experience. Stakeholders can experience the sessions with other stakeholders. You also get real-time reactions—including surprise, agreement, disagreement, and discussions about what they’re seeing. Much like going to a play, where audiences get to take in the stage, the costumes, the lighting, and the actors’ interactions, in-person research lets you see users up close, including their body language, how they interact with the moderator, and how the scene is set up. If in-person usability testing is like watching a play—staged and controlled—then conducting usability testing in the field is like   where any two sessions might be very different from one another. You can take usability testing into the field by   with the product and then conduct your research there. Or you can go out to meet users at their location to do your research. With either option, you get to see how things work in context, things come up that wouldn’t have in a lab environment—and conversion can shift in entirely different directions. As researchers, you have less control over how these sessions go, but this can sometimes help you understand users even better. Meeting users where they are can provide clues to the external forces that could be affecting how they use your product. In-person usability tests provide another level of detail that’s often missing from remote usability tests.  That’s not to say that the “movies”—remote sessions—aren’t a good option. Remote sessions can reach a wider audience. They allow a lot more stakeholders to be involved in the research and to see what’s going on. And they open the doors to a much wider geographical pool of users. But with any remote session there is the potential of time wasted if participants can’t log in or get their microphone working.  The benefit of  , is that you get to see real users interact with the designs in real time, and you can ask them questions to understand their thought processes and grasp of the solution. This can help you not only identify problems but also glean why they’re problems in the first place. Furthermore, you can test hypotheses and gauge whether your thinking is correct. By the end of the sessions, you’ll have a much clearer picture of how usable the designs are and whether they work for their intended purposes. Act two is the heart of the story—where the excitement is—but there can be surprises too. This is equally true of usability tests.  , which change the way that you look at things—and these twists in the story can move things in new directions.  Unfortunately, user research is sometimes seen as expendable. And too often usability testing is the only research process that some stakeholders think that they ever need. In fact, if the designs that you’re evaluating in the usability test aren’t grounded in a solid understanding of your users (foundational research), there’s not much to be gained by doing usability testing in the first place. That’s because you’re narrowing the focus of what you’re getting feedback on, without understanding the users’ needs. As a result, there’s no way of knowing whether the designs might solve a problem that users have. It’s only feedback on a particular design in the context of a usability test.   On the other hand, if you only do foundational research, while you might have set out to solve the right problem, you won’t know whether the thing that you’re building will actually solve that. This illustrates the importance of doing both foundational and directional research.  In act two, stakeholders will—hopefully—get to watch the story unfold in the user sessions, which creates the conflict and tension in the current design by surfacing their highs and lows. And in turn, this can help motivate stakeholders to address the issues that come up. Act three: resolution While the first two acts are about understanding the background and the tensions that can propel stakeholders into action, the third part is about resolving the problems from the first two acts. While it’s important to have an audience for the first two acts, it’s crucial that they stick around for the final act. That means the whole product team, including developers, UX practitioners, business analysts, delivery managers, product managers, and any other stakeholders that have a say in the next steps. It allows the whole team to hear users’ feedback together, ask questions, and discuss what’s possible within the project’s constraints. And it lets the UX research and design teams clarify, suggest alternatives, or give more context behind their decisions. So you can get everyone on the same page and get agreement on the way forward. This act is mostly told in voiceover with some audience participation. The researcher is the narrator, who paints a picture of the issues and what the future of the product could look like given the things that the team has learned. They give the stakeholders their recommendations and their guidance on creating this vision. Nancy Duarte in the   offers an approach to  . “The  use the same techniques as great storytellers: By reminding people of the status quo and then revealing the path to a better way, they set up a conflict that needs to be resolved,” writes Duarte. “That tension helps them persuade the audience to adopt a new mindset or behave differently.” This type of structure aligns well with research results, and particularly results from usability tests. It provides evidence for “what is”—the problems that you’ve identified. And “what could be”—your recommendations on how to address them. And so on and so forth. You can reinforce your recommendations with examples of things that competitors are doing that could address these issues or with examples where competitors are gaining an edge. Or they can be visual, like quick mockups of how a new design could look that solves a problem. These can help generate conversation and momentum. And this continues until the end of the session when you’ve wrapped everything up in the conclusion by summarizing the main issues and suggesting a way forward. This is the part where you reiterate the main themes or problems and what they mean for the product—the denouement of the story. This stage gives stakeholders the next steps and hopefully the momentum to take those steps! While we are nearly at the end of this story, let’s reflect on the idea that user research is storytelling. All the elements of a good story are there in the three-act structure of user research:  : You meet the protagonists (the users) and the antagonists (the problems affecting users). This is the beginning of the plot. In act one, researchers might use methods including contextual inquiry, ethnography, diary studies, surveys, and analytics. The output of these methods can include personas, empathy maps, user journeys, and analytics dashboards. : Next, there’s character development. There’s conflict and tension as the protagonists encounter problems and challenges, which they must overcome. In act two, researchers might use methods including usability testing, competitive benchmarking, and heuristics evaluation. The output of these can include usability findings reports, UX strategy documents, usability guidelines, and best practices. : The protagonists triumph and you see what a better future looks like. In act three, researchers may use methods including presentation decks, storytelling, and digital media. The output of these can be: presentation decks, video clips, audio clips, and pictures.  The researcher has multiple roles: they’re the storyteller, the director, and the producer. The participants have a small role, but they are significant characters (in the research). And the stakeholders are the audience. But the most important thing is to get the story right and to use storytelling to tell users’ stories through research. By the end, the stakeholders should walk away with a purpose and an eagerness to resolve the product’s ills.  So the next time that you’re planning research with clients or you’re speaking to stakeholders about research that you’ve done, think about how you can weave in some storytelling. Ultimately, user research is a win-win for everyone, and you just need to get stakeholders interested in how the story ends. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/beware-the-cut-n-paste-persona/", "title": "Beware the Cut ‘n’ Paste Persona", "content": " is a website that generates human faces with a machine learning algorithm. It takes real portraits and recombines them into fake human faces. We recently scrolled past a LinkedIn post stating that this website could be useful “if you are developing a persona and looking for a photo.”  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. We agree: the computer-generated faces could be a great match for personas—but not for the reason you might think. Ironically, the website highlights the core issue of this very common design method:  . Like the pictures, personas are artificially made. Information is taken out of natural context and recombined into an isolated snapshot that’s detached from reality.  But strangely enough, designers use personas to inspire their design for the real world.  Personas: A step back Most designers have created, used, or come across personas at least once in their career. In their article “ ,” the Interaction Design Foundation defines personas as “fictional characters, which you create based upon your research in order to represent the different user types that might use your service, product, site, or brand.” In their most complete expression, personas typically consist of a name, profile picture, quotes, demographics, goals, needs, behavior in relation to a certain service/product, emotions, and motivations (for example, see Creative Companion’s  ). The purpose of personas, as   design agency Designit, is “to make the research relatable, [and] easy to communicate, digest, reference, and apply to product and service development.” The decontextualization of personas Personas are popular because they make “dry” research data more relatable, more human. However, this method constrains the researcher’s data analysis in such a way that the investigated users are removed from their unique contexts. As a result, personas don’t portray key factors that make you understand their decision-making process or allow you to relate to users’ thoughts and behavior; they lack  . You understand   the persona did, but you don’t have the background to understand  . You end up with representations of users that are actually   human. This “decontextualization” we see in personas happens in four ways, which we’ll explain below.  Personas assume people are static  Although many companies still try to box in their employees and customers with outdated personality tests (referring to you, Myers-Briggs), here’s a painfully obvious truth: people are not a fixed set of features. You act, think, and feel differently according to the situations you experience. You appear different to different people; you might act friendly to some, rough to others. And you change your mind all the time about decisions you’ve taken.   that while people generally behave according to certain patterns, it’s actually a combination of background and environment that determines how people act and take decisions. The context—the environment, the influence of other people, your mood, the entire history that led up to a situation—determines the kind of person you are in each specific moment.  In their attempt to simplify reality, personas do not take this variability into account; they present a user as a fixed set of features. Like personality tests, personas snatch people away from real life. Even worse, people are reduced to a label and categorized as “that kind of person” with no means to exercise their innate flexibility. This practice reinforces stereotypes, lowers diversity, and doesn’t reflect reality.  Personas focus on individuals, not the environment In the real world, you’re designing for a context, not for an individual. Each person lives in a family, a community, an ecosystem, where there are environmental, political, and social factors you need to consider. A design is never meant for a single user. Rather, you design for one or more particular contexts in which many people might use that product. Personas, however, show the user   rather than describe how the user relates to the environment.  Would you always make the same decision over and over again? Maybe you’re a committed vegan but still decide to buy some meat when your relatives are coming over. As they depend on different situations and variables, your decisions—and behavior, opinions, and statements—are not absolute but highly contextual. The persona that “represents” you wouldn’t take into account this dependency, because it doesn’t specify the premises of your decisions. It doesn’t provide a justification of why you act the way you do. Personas enact the well-known bias called  : explaining others’ behavior too much by their personality and too little by the situation. As mentioned by the Interaction Design Foundation, personas are usually placed in a scenario that’s a “specific context with a problem they want to or have to solve”—does that mean context actually   considered? Unfortunately, what often happens is that you take a fictional character and based on that fiction determine how this character might deal with a certain situation. This is made worse by the fact that you haven’t even fully investigated and understood the   context of the people your persona seeks to represent; so how could you possibly understand how they would act in   situations?  Personas are meaningless averages As mentioned in Shlomo Goltz’s   on  , “a persona is depicted as a specific person but is not a real individual; rather, it is synthesized from observations of many people.” A well-known critique to this aspect of personas is that  , as per the   of the USA Air Force designing planes based on the average of 140 of their pilots’ physical dimensions and not a single pilot actually fitting within that average seat.  The same limitation applies to mental aspects of people. Have you ever heard a famous person say, “They took what I said out of context! They used my words, but I didn’t mean it like that.” The celebrity’s statement was reported literally, but the reporter failed to explain the context around the statement and didn’t describe the non-verbal expressions. As a result, the intended meaning was lost. You do the same when you create personas: you collect somebody’s statement (or goal, or need, or emotion), of which the meaning can only be understood if you provide its own specific context, yet report it as an isolated finding.  But personas go a step further, extracting a decontextualized finding and joining it with   decontextualized finding from somebody else. The resulting set of findings often does not make sense: it’s unclear, or even contrasting, because it lacks the underlying reasons on why and how that finding has arisen. It lacks  . And the persona doesn’t give you the full background of the person(s) to uncover this meaning: you would need to dive into the raw data for each single persona item to find it. What, then, is the usefulness of the persona? The relatability of personas is deceiving To a certain extent, designers realize that a persona is a lifeless average. To overcome this, designers invent and add “relatable” details to personas to make them resemble real individuals. Nothing captures the absurdity of this better than a sentence by the Interaction Design Foundation: “Add a few fictional personal details to make the persona a realistic character.” In other words, you add non-realism in an attempt to create more realism. You deliberately obscure the fact that “John Doe” is an abstract representation of research findings; but wouldn’t it be much more responsible to   that John is only an abstraction? If something is artificial, let’s present it as such. It’s the finishing touch of a persona’s decontextualization: after having assumed that people’s personalities are fixed, dismissed the importance of their environment, and hidden meaning by joining isolated, non-generalizable findings, designers   new context to create (their own) meaning. In doing so, as with everything they create, they introduce a host of biases. As phrased by Designit, as designers we can “contextualize [the persona] based on our reality and experience. We create connections that are familiar to  .” This practice reinforces stereotypes, doesn’t reflect real-world diversity, and gets further away from people’s actual reality with every detail added.  To do good design research, we should report the reality “as-is” and make it relatable for our audience, so everyone can use their own empathy and develop their own interpretation and emotional response. Dynamic Selves: The alternative to personas If we shouldn’t use personas, what should we do instead?  Designit has proposed using   instead of personas. Each Mindset is a “spectrum of attitudes and emotional responses that different people have within the same context or life experience.” It challenges designers to not get fixated on a single user’s way of being. Unfortunately, while being a step in the right direction, this proposal doesn’t take into account that people are part of an environment that determines their personality, their behavior, and, yes, their mindset. Therefore, Mindsets are also not absolute but change in regard to the situation. The question remains, what determines a certain Mindset? Another alternative comes from Margaret P., author of the article “ ,” who has argued for replacing personas with   that consist of a   of user abilities. For example, a visual impairment could be permanent (blindness), temporary (recovery from eye surgery), or situational (screen glare). Persona spectrums are highly useful for more inclusive and   design, as they’re based on the understanding that the context is the pattern, not the personality. Their limitation, however, is that they have a very   take on users that misses the relatability of a real person taken from within a spectrum.  In developing an alternative to personas, we aim to transform the standard design process to be context-based. Contexts are generalizable and have patterns that we can identify, just like we tried to do previously with people. So how do we identify these patterns? How do we ensure truly context-based design?  Understand real individuals in multiple contexts Nothing is more relatable and inspiring than reality. Therefore, we have to understand real individuals in their multi-faceted contexts, and use this understanding to fuel our design. We refer to this approach as  . Let’s take a look at what the approach looks like, based on an example of how one of us applied it in a recent project that researched habits of Italians around energy consumption. We drafted a design research plan aimed at investigating people’s attitudes toward energy consumption and sustainable behavior, with a focus on smart thermostats.  When we argue against personas, we’re often challenged with   such as “Where are you going to find a single person that encapsulates all the information from one of these advanced personas[?]” The answer is simple:  . You don’t need to have information about many people for your insights to be deep and meaningful.  In qualitative research, validity does not derive from quantity but from accurate sampling. You select the people that best represent the “population” you’re designing for. If this sample is chosen well, and you have understood the sampled people in sufficient depth, you’re able to infer how the rest of the population thinks and behaves. There’s no need to study seven Susans and five Yuriys; one of each will do.  Similarly, you don’t need to understand Susan in fifteen different contexts. Once you’ve seen her in a couple of diverse situations, you’ve understood the scheme of Susan’s response to different contexts. Not Susan as an atomic being but Susan in relation to the surrounding environment: how she might act, feel, and think in different situations.  Given that each person is representative of a part of the total population you’re researching, it becomes clear why each should be represented as an individual, as each already is an abstraction of a larger group of individuals in similar contexts. You don’t want abstractions of abstractions! These selected people need to be understood and shown in their full expression, remaining in their microcosmos—and if you want to identify patterns you can focus on identifying patterns in contexts. Yet the question remains: how do you select a representative sample? First of all, you have to consider what’s the target audience of the product or service you are designing: it might be useful to look at the company’s goals and strategy, the current customer base, and/or a possible future target audience.  In our example project, we were designing an application for those who own a smart thermostat. In the future, everyone could have a smart thermostat in their house. Right now, though, only early adopters own one. To build a significant sample, we needed to understand the reason why these early adopters became such. We therefore recruited by asking people why they had a smart thermostat and how they got it. There were those who had   to buy it, those who had been   by others to buy it, and those who had   it in their house. So we selected representatives of these three situations, from different age groups and geographical locations, with an equal balance of tech savvy and non-tech savvy participants.  After having chosen and recruited your sample, conduct your research using ethnographic methodologies. This will make your qualitative data rich with anecdotes and examples. In our example project, given COVID-19 restrictions, we converted an in-house ethnographic research effort into remote family interviews, conducted from home and accompanied by diary studies. To gain an in-depth understanding of attitudes and decision-making trade-offs, the research focus was not limited to the interviewee alone but deliberately included the whole family. Each interviewee would tell a story that would then become much more lively and precise with the corrections or additional details coming from wives, husbands, children, or sometimes even pets. We also focused on the relationships with other meaningful people (such as colleagues or distant family) and all the behaviors that resulted from those relationships. This wide research focus allowed us to shape a vivid mental image of dynamic situations with multiple actors.  It’s essential that the scope of the research remains broad enough to be able to include all possible actors. Therefore, it normally works best to define broad research areas with macro questions. Interviews are best set up in a semi-structured way, where follow-up questions will dive into topics mentioned spontaneously by the interviewee. This open-minded “plan to be surprised” will yield the most insightful findings. When we asked one of our participants how his family regulated the house temperature, he replied, “My wife has not installed the thermostat’s app—she uses WhatsApp instead. If she wants to turn on the heater and she is not home, she will text me.  During the research analysis, you start representing each individual with   Dynamic Selves, each “Self” representing one of the contexts you have investigated. The core of each Dynamic Self is a quote, which comes supported by a photo and a few relevant demographics that illustrate the wider context. The research findings themselves will show which demographics are relevant to show. In our case, as our research focused on families and their lifestyle to understand their needs for thermal regulation, the important demographics were family type, number and nature of houses owned, economic status, and technological maturity. (We also included the individual’s name and age, but they’re optional—we included them to ease the stakeholders’ transition from personas and be able to connect multiple actions and contexts to the same person). To capture exact quotes, interviews need to be video-recorded and notes need to be taken  as much as possible. This is essential to the truthfulness of the several Selves of each participant. In the case of real-life ethnographic research, photos of the context and anonymized actors are essential to build realistic Selves. Ideally, these photos should come directly from field research, but an evocative and representative image will work, too, as long as it’s realistic and depicts meaningful actions that you associate with your participants. For example, one of our interviewees told us about his mountain home where he used to spend every weekend with his family. Therefore, we portrayed him hiking with his little daughter.  At the end of the research analysis, we displayed all of the Selves’ “cards” on a single canvas, categorized by activities. Each card displayed a situation, represented by a quote and a unique photo. All participants had multiple cards about themselves. Once you have collected all main quotes from the interview transcripts and diaries, and laid them all down as Self cards, you will see patterns emerge. These patterns will highlight the   for new product creation, new functionalities, and new services—for new design.  In our example project, there was a particularly interesting insight around the concept of humidity. We realized that people don’t know what humidity is and why it is important to monitor it for health: an environment that’s too dry or too wet can cause respiratory problems or worsen existing ones. This highlighted a big opportunity for our client to educate users on this concept and become a health advisor. Benefits of Dynamic Selves When you use the Dynamic Selves approach in your research, you start to notice unique social relations, peculiar situations real people face and the actions that follow, and that people are surrounded by changing environments. In our thermostat project, we have come to know one of the participants, Davide, as a boyfriend, dog-lover, and tech enthusiast.  Davide is an individual we might have once reduced to a persona called “tech enthusiast.” But we can have tech enthusiasts who have families or are single, who are rich or poor. Their motivations and priorities when deciding to purchase a new thermostat can be opposite according to these different frames.  Once you have understood Davide in multiple situations, and for each situation have understood in sufficient depth the underlying reasons for his behavior, you’re able to generalize how he would act in another situation. You can use your understanding of him to infer what he would think and do in the contexts (or scenarios) that you design for. The Dynamic Selves approach aims to dismiss the conflicted dual purpose of personas—to summarize and empathize at the same time—by separating your research summary from the people you’re seeking to empathize with. This is important because our empathy for people is  : the bigger the group, the harder it is to feel empathy for others. We feel the strongest empathy for individuals we can personally relate to.   If you take a   person as inspiration for your design, you no longer need to create an artificial character. No more inventing details to make the character more “realistic,” no more unnecessary additional bias. It’s simply how this person is in real life. In fact, in our experience, personas quickly become nothing more than a name in our   and prototype screens, as we all know that these characters don’t really exist.  Another powerful benefit of the Dynamic Selves approach is that it raises the stakes of your work: if you mess up your design, someone real, a person you and the team know and have met, is going to feel the consequences. It might stop you from taking shortcuts and will remind you to conduct   checks on your designs. And finally, real people in their specific contexts are a better basis for anecdotal storytelling and therefore are more effective in persuasion. Documentation of real research is essential in achieving this result. It adds weight and urgency behind your design arguments: “When I met Alessandra, the conditions of her workplace struck me. Noise, bad ergonomics, lack of light, you name it. If we go for this functionality, I’m afraid we’re going to add complexity to her life.” Conclusion Designit mentioned in their article on Mindsets that “design thinking tools offer a shortcut to deal with reality’s complexities, but this process of simplification can sometimes flatten out people’s lives into a few general characteristics.” Unfortunately, personas have been culprits in a crime of oversimplification. They are unsuited to represent the complex nature of our users’ decision-making processes and don’t account for the fact that humans are immersed in contexts.  Design needs simplification but not generalization. You have to look at the research elements that stand out: the sentences that captured your attention, the images that struck you, the sounds that linger. Portray those, use them to describe the person in their multiple contexts. Both insights and people come with a context; they cannot be cut from that context because it would remove meaning.  It’s high time for design to move away from fiction, and embrace reality—in its messy, surprising, and unquantifiable beauty—as our guide and inspiration. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/thats-not-my-burnout/", "title": "That’s Not My Burnout", "content": "Are you like me, reading about people fading away as they burn out, and feeling unable to relate? Do you feel like your feelings are invisible to the world because you’re experiencing burnout differently? When burnout starts to push down on us, our core comes through more. Beautiful, peaceful souls get quieter and fade into that distant and distracted burnout we’ve all read about. But some of us, those with fires always burning on the edges of our core, get hotter. In my heart I am fire. When I face burnout I double down, triple down, burning hotter and hotter to try to best the challenge. I don’t fade—I am engulfed in a  .  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. So what on earth is a zealous burnout? Imagine a woman determined to do it all. She has two amazing children whom she, along with her husband who is also working remotely, is homeschooling during a pandemic. She has a demanding client load at work—all of whom she loves. She gets up early to get some movement in (or often catch up on work), does dinner prep as the kids are eating breakfast, and gets to work while positioning herself near “fourth grade” to listen in as she juggles clients, tasks, and budgets. Sound like a lot? Even with a supportive team both at home and at work, it is.  Sounds like this woman has too much on her plate and needs self-care. But no, she doesn’t have time for that. In fact, she starts to feel like she’s dropping balls. Not accomplishing enough. There’s not enough of her to be here and there; she is trying to divide her mind in two all the time, all day, every day. She starts to doubt herself. And as those feelings creep in more and more, her internal narrative becomes more and more critical. Suddenly she KNOWS what she needs to do! She should DO MORE.  This is a hard and dangerous cycle. Know why? Because once she doesn’t finish that new goal, that narrative will get worse. Suddenly she’s failing. She isn’t doing enough. SHE is  . She might fail, she might fail her family…so she’ll find more she should do. She doesn’t sleep as much, move as much, all in the efforts to do more. Caught in this cycle of trying to prove herself to herself, never reaching any goal. Never feeling “enough.”  So, yeah, that’s what zealous burnout looks like for me. It doesn’t happen overnight in some grand gesture but instead slowly builds over weeks and months. My burning out process looks like speeding up, not a person losing focus. I speed up and up and up…and then I just stop. I am the one who could It’s funny the things that shape us. Through the lens of childhood, I viewed the fears, struggles, and sacrifices of someone who had to make it all work without having enough. I was lucky that my mother was so resourceful and my father supportive; I never went without and even got an extra here or there.  Growing up, I did not feel shame when my mother paid with food stamps; in fact, I’d have likely taken on any debate on the topic, verbally eviscerating anyone who dared to criticize the disabled woman trying to make sure all our needs were met with so little. As a child, I watched the way the fear of not making those ends meet impacted people I love. As the non-disabled person in my home, I would take on many of the physical tasks because I was “the one who could” make our lives a little easier. I learned early to associate fears or uncertainty with putting more of myself into it—I am the one who can. I learned early that when something frightens me, I can double down and work harder to make it better. I can own the challenge. When people have seen this in me as an adult, I’ve been told I seem fearless, but make no mistake, I’m not. If I seem fearless, it’s because this behavior was forged from other people’s fears.  And here I am, more than 30 years later still feeling the urge to mindlessly push myself forward when faced with overwhelming tasks ahead of me, assuming that I am the one who can and therefore should. I find myself driven to prove that I can make things happen if I work longer hours, take on more responsibility, and do  .  I do not see people who struggle financially as failures, because I have seen how strong that tide can be—it pulls you along the way. I truly get that I have been privileged to be able to avoid many of the challenges that were present in my youth. That said, I am still “the one who can” who feels she should, so if I were faced with not having enough to make ends meet for my own family, I would see myself as having failed. Though I am supported and educated, most of this is due to good fortune. I will, however, allow myself the arrogance of saying I have been careful with my choices to have encouraged that luck. My identity stems from the idea that I am “the one who can” so therefore feel obligated to do the most. I can choose to stop, and with some quite literal cold water splashed in my face, I’ve made the choice to before. But that choosing to stop is not my go-to; I move forward, driven by a fear that is so a part of me that I barely notice it’s there until I’m feeling utterly worn away. So why all the history? You see, burnout is a fickle thing. I have heard and read a lot about burnout over the years. Burnout is real. Especially now, with COVID, many of us are balancing more than we ever have before—all at once! It’s hard, and the procrastinating, the avoidance, the shutting down impacts so many amazing professionals. There are important articles that relate to what I imagine must be the majority of people out there, but not me. That’s not what my burnout looks like. The dangerous invisibility of zealous burnout A lot of work environments see the extra hours, extra effort, and overall focused commitment as an asset (and sometimes that’s all it is). They see someone trying to rise to challenges, not someone stuck in their fear. Many well-meaning organizations have safeguards in place to protect their teams from burnout. But in cases like this, those alarms are not always tripped, and then when the inevitable stop comes, some members of the organization feel surprised and disappointed. And sometimes maybe even betrayed.  Parents—more so mothers, statistically speaking—are praised as being so on top of it all when they can work, be involved in the after-school activities, practice self-care in the form of diet and exercise, and still meet friends for coffee or wine. During COVID many of us have binged countless streaming episodes showing how it’s so hard for the female protagonist, but she is strong and funny and can do it. It’s a “very special episode” when she breaks down, cries in the bathroom, woefully admits she needs help, and just stops for a bit. Truth is, countless people are hiding their tears or are doom-scrolling to escape. We know that the media is a lie to amuse us, but often the perception that it’s what we should strive for has penetrated much of society. Women and burnout I love men. And though I don’t love every man (heads up, I don’t love every woman or nonbinary person either), I think there is a beautiful spectrum of individuals who represent that particular binary gender.  That said, women are still more often at risk of burnout than their male counterparts, especially in these COVID stressed times. Mothers in the workplace feel the pressure to do all the “mom” things while giving 110%. Mothers not in the workplace feel they need to do more to “justify” their lack of traditional employment. Women who are not mothers often feel the need to do even more because they don’t have that extra pressure at home. It’s vicious and systemic and so a part of our culture that we’re often not even aware of the enormity of the pressures we put on ourselves and each other.  And there are prices beyond happiness too.   a decade ago that “uncovered strong links between women’s job stress and cardiovascular disease.”   “Heart disease is the leading cause of death for women in the United States, killing 299,578 women in 2017—or about 1 in every 5 female deaths.”  This relationship between work stress and health, from what I have read, is more dangerous for women than it is for their non-female counterparts. But what if your burnout isn’t like that either? That might not be you either. After all, each of us is so different and how we respond to stressors is too. It’s part of what makes us human.  ,  Here are a few questions I sometimes ask friends if I am concerned about them.  This simple question should be the first thing you ask yourself. Chances are, even if you’re burning out doing all the things you love, as you approach burnout you’ll just stop taking as much joy from it all.  I have observed in myself and others that when someone is burning out, they no longer feel they can say no to things. Even those who don’t “speed up” feel pressure to say yes to not disappoint the people around them.  Another observance is that we all tend to stop doing things for ourselves. Anything from skipping showers and eating poorly to avoiding talking to friends. These can be red flags.   Many of us try to disregard feelings of burnout. Over and over I have heard, “It’s just crunch time,” “As soon as I do this one thing, it will all be better,” and “Well I should be able to handle this, so I’ll figure it out.” And it  really be crunch time, a single goal, and/or a skill set you need to learn. That happens—life happens. BUT if this doesn’t stop, be honest with yourself. If you’ve worked more 50-hour weeks since January than not, maybe it’s not crunch time—maybe it’s a bad situation that you’re burning out from.  If something is truly temporary and you do need to just push through, then it has an exit route with a defined end. Take the time to listen to yourself as you would a friend. Be honest, allow yourself to be uncomfortable, and break the thought cycles that prevent you from healing.  So now what? What I just described is a different path to burnout, but it’s still burnout. There are well-established approaches to working through burnout: Get enough sleep. Eat healthy. Work out. Get outside. Take a break. Overall, practice self-care. Those are hard for me because they feel like more tasks. If I’m in the burnout cycle, doing any of the above  feels like a waste. The narrative is that if I’m already failing, why would I take care of myself when I’m dropping all those other balls? People need me, right?  If you’re deep in the cycle, your inner voice might be pretty awful by now. If you need to, tell yourself you need to take care of the person your people depend on. If your roles are pushing you toward burnout, use them to help make healing easier by justifying the time spent working on you.  To help remind myself of the airline attendant message about putting the mask on yourself first, I have come up with a few things that I do when I start feeling myself going into a zealous burnout. Cook an elaborate meal for someone!  OK, I am a “food-focused” individual so cooking for someone is always my go-to. There are countless tales in my home of someone walking into the kitchen and turning right around and walking out when they noticed I was “chopping angrily.” But it’s more than that, and you should give it a try. Seriously. It’s the perfect go-to if you don’t feel worthy of taking time for yourself—do it for someone else. Most of us work in a digital world, so cooking can fill all of your senses and force you to be in the moment with all the ways you perceive the world. It can break you out of your head and help you gain a better perspective. In my house, I’ve been known to pick a place on the map and cook food that comes from wherever that is (thank you, Pinterest). I love cooking Indian food, as the smells are warm, the bread needs just enough kneading to keep my hands busy, and the process takes real attention for me because it’s not what I was brought up making. And in the end, we all win! Vent like a foul-mouthed fool I have been making an effort to practice more gratitude over the past few years, and I recognize the true benefits of that. That said, sometimes you just gotta let it all out—even the ugly. Hell, I’m a big fan of not sugarcoating our lives, and that sometimes means that to get past the big pile of poop, you’re gonna wanna complain about it a bit.  When that is what’s needed, turn to a trusted friend and allow yourself some pure verbal diarrhea, saying all the things that are bothering you. You need to trust this friend not to judge, to see your pain, and, most importantly, to tell you to remove your cranium from your own rectal cavity. Seriously, it’s about getting a reality check here! One of the things I admire the most about my husband (though often after the fact) is his ability to break things down to their simplest. “We’re spending our lives together, of course you’re going to disappoint me from time to time, so get over it” has been his way of speaking his dedication, love, and acceptance of me—and I could not be more grateful. It also, of course, has meant that I needed to remove my head from that rectal cavity. So, again, usually those moments are appreciated in hindsight. Pick up a book!  There are many books out there that aren’t so much self-help as they are people just like you sharing their stories and how they’ve come to find greater balance. Maybe you’ll find something that speaks to you. Titles that have stood out to me include:  by Arianna Huffington  by Tim Ferriss  by Rachel Hollis  by Brené Brown Or, another tactic I love to employ is to read or listen to a book that has NOTHING to do with my work-life balance. I’ve read the following books and found they helped balance me out because my mind was pondering their interesting topics instead of running in circles:  by Amy Stewart  by Darin Olien  by Adam Rutherford  by Toby Hemenway  If you’re not into reading, pick up a topic on YouTube or choose a podcast to subscribe to. I’ve watched countless permaculture and gardening topics in addition to how to raise chickens and ducks. For the record, I do not have a particularly large food garden, nor do I own livestock of any kind…yet. I just find the topic interesting, and it has nothing to do with any aspect of my life that   anything from me. Forgive yourself You are never going to be perfect—hell, it would be boring if you were. It’s OK to be broken and flawed. It’s human to be tired and sad and worried. It’s OK to not do it all. It’s scary to be imperfect, but you cannot be brave if nothing were scary. This last one is the most important:  You never promised to be everything to everyone at all times. We are more powerful than the fears that drive us.  This is hard. It is hard for me. It’s what’s driven me to write this—that it’s OK to stop. It’s OK that your unhealthy habit that might even benefit those around you needs to end. You can still be successful in life. I recently read that we are all writing our eulogy in how we live. Knowing that your professional accomplishments won’t be mentioned in that speech, what will yours say? What do you want it to say?  Look, I get that none of these ideas will “fix it,” and that’s not their purpose. None of us are in control of our surroundings, only how we respond to them. These suggestions are to help stop the spiral effect so that you are empowered to address the underlying issues and choose your response. They are things that work for me most of the time. Maybe they’ll work for you. Does this sound familiar?  If this sounds familiar, it’s not just you. Don’t let your negative self-talk tell you that you “even burn out wrong.” It’s not wrong. Even if rooted in fear like my own drivers, I believe that this need to do more comes from a place of love, determination, motivation, and other wonderful attributes that make you the amazing person you are. We’re going to be OK, ya know. The lives that unfold before us might never look like that story in our head—that idea of “perfect” or “done” we’re looking for, but that’s OK. Really, when we stop and look around, usually the only eyes that judge us are in the mirror.  Do you remember that Winnie the Pooh sketch that had Pooh eat so much at Rabbit’s house that his buttocks couldn’t fit through the door? Well, I already associate a lot with Rabbit, so it came as no surprise when he abruptly declared that this was unacceptable. But do you recall what happened next? He put a shelf across poor Pooh’s ankles and decorations on his back, and made the best of the big butt in his kitchen.  At the end of the day we are resourceful and know that we are able to push ourselves if we need to—even when we are tired to our core or have a big butt of fluff ‘n’ stuff in our room. None of us has to be afraid, as we can manage any obstacle put in front of us. And maybe that means we will need to redefine success to allow space for being uncomfortably human, but that doesn’t really sound so bad either.  So, wherever you are right now, please breathe. Do what you need to do to get out of your head. Forgive and take care. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/async-design-critique-giving-feedback/", "title": "Asynchronous Design Critique: Giving Feedback", "content": "Feedback, in whichever form it takes, and whatever it may be called, is one of the most effective soft skills that we have at our disposal to collaboratively get our designs to a better place while growing our own skills and perspectives. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Feedback is also one of the most underestimated tools, and often by assuming that we’re already good at it, we settle, forgetting that it’s a skill that can be trained, grown, and improved. Poor feedback can create confusion in projects, bring down morale, and affect trust and team collaboration over the long term. Quality feedback can be a transformative force.  Practicing our skills is surely a good way to improve, but the learning gets even faster when it’s paired with a good foundation that channels and focuses the practice. What are some foundational aspects of giving good feedback? And how can feedback be adjusted for remote and distributed work environments?  On the web, we can identify a long tradition of asynchronous feedback: from the early days of open source, code was shared and discussed on mailing lists. Today, developers engage on pull requests, designers comment in their favorite design tools, project managers and scrum masters exchange ideas on tickets, and so on.  is often the name used for a type of feedback that’s provided to make our work better, collaboratively. So it shares a lot of the principles with feedback in general, but it also has some differences. The content The foundation of every good critique is the feedback’s content, so that’s where we need to start. There are many models that you can use to shape your content. The one that I personally like best—because it’s clear and actionable—is this one from  . While this equation is generally used to give feedback to people, it also fits really well in a design critique because it ultimately answers some of the core questions that we work on: What? Where? Why? How? Imagine that you’re giving some feedback about some design work that spans multiple screens, like an onboarding flow: there are some pages shown, a flow blueprint, and an outline of the decisions made. You spot something that could be improved. If you keep the three elements of the equation in mind, you’ll have a mental model that can help you be more precise and effective. Here is a comment that could be given as a part of some feedback, and it might look reasonable at a first glance: it seems to superficially fulfill the elements in the equation. But does it? Not sure about the buttons’ styles and hierarchy—it feels off. Can you change them?  for design feedback doesn’t just mean pointing out which part of the interface your feedback refers to, but it also refers to offering a perspective that’s as specific as possible. Are you providing the user’s perspective? Your expert perspective? A business perspective? The project manager’s perspective? A first-time user’s perspective? When I see these two buttons, I expect one to go forward and one to go back.  is about the  . Just pointing out a UI element might sometimes be enough if the issue may be obvious, but more often than not, you should add an explanation of what you’re pointing out. When I see these two buttons, I expect one to go forward and one to go back. But this is the only screen where this happens, as before we just used a single button and an “×” to close. This seems to be breaking the consistency in the flow. The   approach is meant to provide open guidance by eliciting the critical thinking in the designer receiving the feedback. Notably, in Lara’s equation she provides a second approach:  , which instead provides guidance toward a specific solution. While that’s a viable option for feedback in general, for design critiques, in my experience, defaulting to the   approach usually reaches the best solutions because designers are generally more comfortable in being given an open space to explore. The difference between the two can be exemplified with, for the  approach: When I see these two buttons, I expect one to go forward and one to go back. But this is the only screen where this happens, as before we just used a single button and an “×” to close. This seems to be breaking the consistency in the flow. Would it make sense to unify them? Or, for the  approach: When I see these two buttons, I expect one to go forward and one to go back. But this is the only screen where this happens, as before we just used a single button and an “×” to close. This seems to be breaking the consistency in the flow. Let’s make sure that all screens have the same pair of forward and back buttons. At this point in some situations, it might be useful to integrate with an extra  : why you consider the given suggestion to be better. When I see these two buttons, I expect one to go forward and one to go back. But this is the only screen where this happens, as before we just used a single button and an “×” to close. This seems to be breaking the consistency in the flow. Let’s make sure that all screens have the same two forward and back buttons so that users don’t get confused. Choosing the   approach or the   approach can also at times be a matter of personal preference. A while ago, I was putting a lot of effort into improving my feedback: I did rounds of anonymous feedback, and I reviewed feedback with other people. After a few rounds of this work and a year later, I got a positive response: my feedback came across as effective and grounded. Until I changed teams. To my shock, my next round of feedback from one specific person wasn’t that great. The reason is that I had previously tried not to be prescriptive in my advice—because the people who I was previously working with preferred the open-ended   format over the   style of suggestions. But now in this other team, there was one person who instead preferred specific guidance. So I adapted my feedback for them to include requests. One comment that I heard come up a few times is that this kind of feedback is quite long, and it doesn’t seem very efficient. No… but also yes. Let’s explore both sides. No, this style of feedback is actually   because the length here is a byproduct of clarity, and spending time giving this kind of feedback can provide exactly enough information for a good fix. Also if we zoom out, it can reduce future back-and-forth conversations and misunderstandings, improving the overall efficiency and effectiveness of collaboration beyond the single comment. Imagine that in the example above the feedback were instead just, “Let’s make sure that all screens have the same two forward and back buttons.” The designer receiving this feedback wouldn’t have much to go by, so they might just apply the change. In later iterations, the interface might change or they might introduce new features—and maybe that change might not make sense anymore. Without the  , the designer might imagine that the change is about consistency… but what if it wasn’t? So there could now be an underlying concern that changing the buttons would be perceived as a regression. Yes, this style of feedback is   because the points in some comments don’t always need to be exhaustive, sometimes because certain changes may be obvious (“The font used doesn’t follow our guidelines”) and sometimes because the team may have a lot of internal knowledge such that some of the   may be implied. So the equation above isn’t meant to suggest a strict template for feedback but a mnemonic to reflect and improve the practice. Even after years of active work on my critiques, I still from time to time go back to this formula and reflect on whether what I just wrote is effective. The tone Well-grounded content is the foundation of feedback, but that’s not really enough. The soft skills of the person who’s providing the critique can multiply the likelihood that the feedback will be well received and understood. Tone alone can make the difference between content that’s rejected or welcomed, and it’s been demonstrated that   in people. Since our goal is to be understood and to have a positive working environment, tone is essential to work on. Over the years, I’ve tried to summarize the required soft skills in a formula that mirrors the one for content: the  . Respectful feedback comes across as grounded, solid, and constructive. It’s the kind of feedback that, whether it’s positive or negative, is perceived as useful and fair.  refers to when the feedback happens. To-the-point feedback doesn’t have much hope of being well received if it’s given at the wrong time. Questioning the entire high-level information architecture of a new feature when it’s about to ship might still be relevant if that questioning highlights a major blocker that nobody saw, but it’s way more likely that those concerns will have to wait for a later rework. So in general, attune your feedback to the stage of the project. Early iteration? Late iteration? Polishing work in progress? These all have different needs. The right timing will make it more likely that your feedback will be well received.  is the equivalent of intent, and in the context of person-to-person feedback, it can be referred to as  . That means checking before we write to see whether what we have in mind will truly help the person and make the project better overall. This might be a hard reflection at times because maybe we don’t want to admit that we don’t really appreciate that person. Hopefully that’s not the case, but that can happen, and that’s okay. Acknowledging and owning that can help you make up for that: how would I write if I really cared about them? How can I avoid being passive aggressive? How can I be more constructive?  is relevant especially in a diverse and cross-cultural work environments because having great content, perfect timing, and the right attitude might not come across if the way that we write creates misunderstandings. There might be many reasons for this: sometimes certain words might trigger specific reactions; sometimes nonnative speakers might not understand all the nuances of some sentences; sometimes our brains might just be different and we might perceive the world differently—neurodiversity must be taken into consideration. Whatever the reason, it’s important to review not just what we write but how. A few years back, I was asking for some feedback on how I give feedback. I received some good advice but also a comment that surprised me. They pointed out that when I wrote “Oh, […],” I made them feel stupid. That wasn’t my intent! I felt really bad, and I just realized that I provided feedback to them for months, and every time I might have made them feel stupid. I was horrified… but also thankful. I made a quick fix: I added “oh” in my list of replaced words (your choice between: macOS’s text replacement, aText, TextExpander, or others) so that when I typed “oh,” it was instantly deleted.  Something to highlight because it’s quite frequent—especially in teams that have a strong group spirit—is that people tend to beat around the bush. It’s important to remember here that  —it just means that even when you provide hard, difficult, or challenging feedback, you do so in a way that’s respectful and constructive. The nicest thing that you can do for someone is to help them grow. We have a great advantage in giving feedback in written form: it can be   who isn’t directly involved, which can help to reduce or remove any bias that might be there. I found that the best, most insightful moments for me have happened when I’ve shared a comment and I’ve asked someone who I highly trusted, “How does this sound?,” “How can I do it better,” and even “How would you have written it?”—and I’ve learned a lot by seeing the two versions side by side. The format Asynchronous feedback also has a major inherent advantage: we can take more time to refine what we’ve written to make sure that it fulfills two main goals: the   of communication and the   of the suggestions. Let’s imagine that someone shared a design iteration for a project. You are reviewing it and leaving a comment. There are many ways to do this, and of course context matters, but let’s try to think about some elements that may be useful to consider. In terms of  , start by grounding the critique that you’re about to give by providing  . Specifically, this means describing where you’re coming from: do you have a deep knowledge of the project, or is this the first time that you’re seeing it? Are you coming from a high-level perspective, or are you figuring out the details? Are there regressions? Which user’s perspective are you taking when providing your feedback? Is the design iteration at a point where it would be okay to ship this, or are there major things that need to be addressed first? Providing context is helpful even if you’re sharing feedback within a team that already has some information on the project. And context is absolutely essential when giving cross-team feedback. If I were to review a design that might be indirectly related to my work, and if I had no knowledge about how the project arrived at that point, I would say so, highlighting my take as external. We often focus on the negatives, trying to outline all the things that could be done better. That’s of course important, but it’s just as important—if not more—to focus on the  , especially if you saw progress from the previous iteration. This might seem superfluous, but it’s important to keep in mind that design is a discipline where there are hundreds of possible solutions for every problem. So pointing out that the design solution that was chosen is good and explaining why it’s good has two major benefits: it confirms that the approach taken was solid, and it helps to ground your negative feedback. In the longer term, sharing positive feedback can help prevent regressions on things that are going well because those things will have been highlighted as important. As a bonus, positive feedback can also help reduce impostor syndrome. There’s one powerful approach that combines both   and  :   (compared to a previous iteration, competitors, or benchmarks) and why, and then on that foundation, you can add what could be improved. This is powerful because there’s a big difference between a critique that’s for a design that’s already in good shape and a critique that’s for a design that isn’t quite there yet. Another way that you can improve your feedback is to  : the comments should always be about the work, never about the person who made it. It’s “This button isn’t well aligned” versus “You haven’t aligned this button well.” This is very easy to change in your writing by reviewing it just before sending. In terms of  , one of the best approaches to help the designer who’s reading through your feedback is to   it into bullet points or paragraphs, which are easier to review and analyze one by one. For longer pieces of feedback, you might also consider splitting it into sections or even across multiple comments. Of course, adding screenshots or signifying markers of the specific part of the interface you’re referring to can also be especially useful. One approach that I’ve personally used effectively in some contexts is to enhance the bullet points with four markers using emojis. So a red square 🟥 means that it’s something that I consider blocking; a yellow diamond 🔶 is something that I can be convinced otherwise, but it seems to me that it should be changed; and a green circle 🟢 is a detailed, positive confirmation. I also use a blue spiral 🌀 for either something that I’m not sure about, an exploration, an open alternative, or just a note. But I’d use this approach only on teams where I’ve already established a good level of trust because if it happens that I have to deliver a lot of red squares, the impact could be quite demoralizing, and I’d reframe how I’d communicate that a bit. Let’s see how this would work by reusing the example that we used earlier as the first bullet point in this list: 🔶 Navigation—When I see these two buttons, I expect one to go forward and one to go back. But this is the only screen where this happens, as before we just used a single button and an “×” to close. This seems to be breaking the consistency in the flow. Let’s make sure that all screens have the same two forward and back buttons so that users don’t get confused. 🟢 Overall—I think the page is solid, and this is good enough to be our release candidate for a version 1.0. 🟢 Metrics—Good improvement in the buttons on the metrics area; the improved contrast and new focus style make them more accessible.  🟥  Button Style—Using the green accent in this context creates the impression that it’s a positive action because green is usually perceived as a confirmation color. Do we need to explore a different color? 🔶Tiles—Given the number of items on the page, and the overall page hierarchy, it seems to me that the tiles shouldn’t be using the Subtitle 1 style but the Subtitle 2 style. This will keep the visual hierarchy more consistent. 🌀 Background—Using a light texture works well, but I wonder whether it adds too much noise in this kind of page. What is the thinking in using that? What about giving feedback directly in   or another design tool that allows in-place feedback? In general, I find these difficult to use because they hide discussions and they’re harder to track, but in the right context, they can be very effective. Just make sure that each of the comments is separate so that it’s easier to match each discussion to a single task, similar to the idea of splitting mentioned above. One final note:  . Sometimes we might feel that something is obviously good or obviously wrong, and so we don’t say it. Or sometimes we might have a doubt that we don’t express because the question might sound stupid. Say it—that’s okay. You might have to reword it a little bit to make the reader feel more comfortable, but don’t hold it back. Good feedback is transparent, even when it may be obvious. There’s another advantage of asynchronous feedback:  . Especially in large projects, “Why did we do this?” could be a question that pops up from time to time, and there’s nothing better than open, transparent discussions that can be reviewed at any time. For this reason, I recommend using software that saves these discussions, without hiding them once they are resolved.  Content, tone, and format. Each one of these subjects provides a useful model, but working to improve eight areas— —is a lot of work to put in all at once. One effective approach is to take them one by one: first identify the area that you lack the most (either from your perspective or from feedback from others) and start there. Then the second, then the third, and so on. At first you’ll have to put in extra time for every piece of feedback that you give, but after a while, it’ll become second nature, and your impact on the work will multiply. Like this: \n\t\t\t\t\t\t\tRecently by Erin Casali\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/asynchronous-design-critique-giving-feedback-part2/", "title": "Asynchronous Design Critique: Getting Feedback", "content": "“Any comment?” is probably one of the worst ways to ask for feedback. It’s vague and open ended, and it doesn’t provide any indication of what we’re looking for. Getting good feedback starts earlier than we might expect: it starts with the request.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. It might seem counterintuitive to start the process of receiving feedback with a  , but that makes sense if we realize that getting feedback can be thought of as a form of design research. In the same way that we wouldn’t do any research without the right questions to get the insights that we need, the best way to ask for feedback is also to craft sharp questions. Design critique is not a one-shot process. Sure, any good feedback workflow continues until the project is finished, but this is particularly true for design because design work continues   after iteration, from a high level to the finest details. Each level needs its own set of questions. And finally, as with any good research, we need to   what we got back, get to the core of its insights, and take action.  ,  , and  . Let’s look at each of those. The question Being open to feedback is essential, but we need to be precise about what we’re looking for. Just saying “Any comment?”, “What do you think?”, or “I’d love to get your opinion” at the end of a presentation—whether it’s in person, over video, or through a written post—is likely to get a number of varied opinions or, even worse, get everyone to follow the direction of the first person who speaks up. And then… we get frustrated because vague questions like those can turn a high-level flows review into people instead commenting on the borders of buttons. Which might be a hearty topic, so it might be hard at that point to redirect the team to the subject that you had wanted to focus on. But how do we get into this situation? It’s a mix of factors. One is that we don’t usually consider   as a part of the feedback process. Another is how natural it is to just leave the question implied, expecting the others to be on the same page. Another is that in nonprofessional discussions, there’s often no need to be that precise. In short, we tend to underestimate the importance of the questions, so we don’t work on improving them. . It’s also a form of consent: it makes it clear that you’re open to comments and what kind of comments you’d like to get. It puts people in the right mental state, especially in situations when they weren’t expecting to give feedback. There isn’t a single best way to ask for feedback. It just needs to be , and specificity can take many shapes. A model for design critique that I’ve found particularly useful in my coaching is the one of  . “ ” refers to each of the steps of the process—in our case, the design process. In progressing from user research to the final design, the kind of feedback evolves. But within a single step, one might still review whether some assumptions are correct and whether there’s been a proper translation of the amassed feedback into updated designs as the project has evolved. A starting point for potential questions could derive from the  . What do you want to know: Project objectives? User needs? Functionality? Content? Interaction design? Information architecture? UI design? Navigation design? Visual design? Branding? Here’re a few example questions that are precise and to the point that refer to different layers: Functionality: Is automating account creation desirable? Interaction design: Take a look through the updated flow and let me know whether you see any steps or error states that I might’ve missed. Information architecture: We have two competing bits of information on this page. Is the structure effective in communicating them both? UI design: What are your thoughts on the error counter at the top of the page that makes sure that you see the next error, even if the error is out of the viewport?  Navigation design: From research, we identified these second-level navigation items, but once you’re on the page, the list feels too long and hard to navigate. Are there any suggestions to address this? Visual design: Are the sticky notifications in the bottom-right corner visible enough? The other axis of specificity is about how   you’d like to go on what’s being presented. For example, we might have introduced a new end-to-end flow, but there was a specific view that you found particularly challenging and you’d like a detailed review of that. This can be especially useful from one iteration to the next where it’s important to  . There are other things that we can consider when we want to achieve more specific—and more effective—questions. A simple trick is to remove   from your questions like “good,” “well,” “nice,” “bad,” “okay,” and “cool.” For example, asking, “When the block opens and the buttons appear, is this interaction good?” might look specific, but you can spot the “good” qualifier, and convert it to an even better question: “When the block opens and the buttons appear, is it clear what the next action is?” Sometimes  . That’s rare, but it can happen. In that sense, you might still make it explicit that you’re looking for a wide range of opinions, whether at a high level or with details. Or maybe just say, “At first glance, what do you think?” so that it’s clear that what you’re asking is open ended but focused on someone’s impression after their first five seconds of looking at it. Sometimes the  , and some areas may have already been explored in detail. In these situations, it might be useful to explicitly say that some parts are already locked in and aren’t open to feedback. It’s not something that I’d recommend in general, but I’ve found it useful to avoid falling again into rabbit holes of the sort that might lead to further refinement but aren’t what’s most important right now. Asking specific questions can completely change the quality of the feedback that you receive. People with less refined critique skills will now be able to offer more actionable feedback, and even expert designers will welcome the clarity and efficiency that comes from focusing only on what’s needed. It can save a lot of time and frustration. The iteration Design iterations are probably the most visible part of the design work, and they provide a natural checkpoint for feedback. Yet a lot of design tools with inline commenting tend to show changes as a single fluid stream in the same file, and those types of design tools make conversations disappear once they’re resolved, update shared UI components automatically, and compel designs to always show the latest version—unless these would-be helpful features were to be manually turned off. The implied goal that these design tools seem to have is to arrive at just one final copy with all discussions closed, probably because they inherited patterns from how written documents are collaboratively edited. That’s probably not the best way to approach design critiques, but even if I don’t want to be too prescriptive here: that could work for some teams. The asynchronous design-critique approach that I find most effective is to create explicit checkpoints for discussion. I’m going to use the term   for this. It refers to a   of the design iteration followed by a   of some kind. Any platform that can accommodate this structure can use this. By the way, when I refer to a “write-up or presentation,” I’m including video recordings or other media too: as long as it’s asynchronous, it works. Using iteration posts has many advantages: It creates a   in the design work so that the designer can review feedback from each iteration and prepare for the next. It makes   for future review, and conversations are likewise always available. It creates a   of how the design changed over time. Depending on the tool, it might also make it easier to collect feedback and   on it. These posts of course don’t mean that no other feedback approach should be used, just that iteration posts could be the primary rhythm for a remote design team to use. And other feedback approaches (such as live critique, pair designing, or inline comments) can build from there. I don’t think there’s a standard format for iteration posts. But there are a few high-level elements that make sense to include as a baseline: Each project is likely to have a  , and hopefully it’s something that’s already been summarized in a single sentence somewhere else, such as the client brief, the product manager’s outline, or the project owner’s request. So this is something that I’d repeat in every iteration post—literally copy and pasting it. The idea is to provide context and to repeat what’s essential to make each iteration post   so that there’s no need to find information spread across multiple posts. If I want to know about the latest design, the latest iteration post will have all that I need. This copy-and-paste part introduces another relevant concept:  . So having posts that repeat information is actually very effective toward making sure that everyone is on the same page. The   is then the actual series of information-architecture outlines, diagrams, flows, maps, wireframes, screens, visuals, and any other kind of design work that’s been done. In short, it’s any design artifact. For the final stages of work, I prefer the term   to emphasize that I’ll be showing full flows instead of individual screens to make it easier to understand the bigger picture.  It can also be useful to label the artifacts with clear   because that can make it easier to refer to them. Write the post in a way that helps people understand the work. It’s not too different from organizing a good live presentation.  For an efficient discussion, you should also include a bullet list of the  from the previous iteration to let people focus on what’s new, which can be especially useful for larger pieces of work where keeping track, iteration after iteration, could become a challenge. And finally, as noted earlier, it’s essential that you include a list of the   to drive the design critique in the direction you want. Doing this as a numbered list can also help make it easier to refer to each question by its number. Not all iterations are the same.  —they can be more exploratory and experimental, maybe even breaking some of the design-language guidelines to see what’s possible. Then later, the iterations start settling on a solution and refining it until the design process reaches its end and the feature ships. I want to highlight that even if these iteration posts are written and conceived as checkpoints,  . A post might be a draft—just a concept to get a conversation going—or it could be a cumulative list of each feature that was added over the course of each iteration until the full picture is done. Over time, I also started using  , and so on. This might look like a minor labelling tip, but it can help in multiple ways: Unique—It’s a clear unique marker. Within each project, one can easily say, “This was discussed in i4,” and everyone knows where they can go to review things. Unassuming—It works like versions (such as v1, v2, and v3) but in contrast, versions create the impression of something that’s big, exhaustive, and complete. Iterations must be able to be exploratory, incomplete, partial. Future proof—It resolves the “final” naming problem that you can run into with versions. No more files named “final final complete no-really-its-done.” Within each project, the largest number always represents the latest iteration. To mark when a design is complete enough to be worked on, even if there might be some bits still in need of attention and in turn more iterations needed, the wording   (RC) could be used to describe it: “with i8, we reached RC” or “i12 is an RC.” The review What usually happens during a design critique is an open  , with a back and forth between people that can be very productive. This approach is particularly effective during live, synchronous feedback. But when we work asynchronously, it’s more effective to use a different approach:  . Written feedback from teammates, stakeholders, or others can be treated as if it were the result of user interviews and surveys, and we can analyze it accordingly. This shift has some major benefits that make asynchronous feedback particularly effective, especially around these friction points: The first friction point is feeling a   to every single comment. Sometimes we write the iteration post, and we get replies from our team. It’s just a few of them, it’s easy, and it doesn’t feel like a problem. But other times, some solutions might require more in-depth discussions, and the amount of replies can quickly increase, which can create a tension between trying to be a good team player by replying to everyone and doing the next design iteration. This might be especially true if the person who’s replying is a stakeholder or someone directly involved in the project who we feel that we need to listen to. We need to accept that this pressure is absolutely normal, and it’s human nature to try to accommodate people who we care about. Sometimes replying to all comments can be effective, but if we treat a design critique more like user research, we realize that we don’t have to reply to every comment, and in asynchronous spaces, there are alternatives: One is to  . When the design evolves and we post a follow-up iteration, that’s the reply. You might tag all the people who were involved in the previous discussion, but even that’s a choice, not a requirement.  Another is to   to acknowledge each comment, such as “Understood. Thank you,” “Good points—I’ll review,” or “Thanks. I’ll include these in the next iteration.” In some cases, this could also be just a single top-level comment along the lines of “Thanks for all the feedback everyone—the next iteration is coming soon!” Another is to provide a   of the comments before moving on. Depending on your workflow, this can be particularly useful as it can provide a simplified checklist that you can then use for the next iteration. The second friction point is the  , which is the kind of feedback that comes from someone outside the project or team who might not be aware of the context, restrictions, decisions, or requirements—or of the previous iterations’ discussions. On their side, there’s something that one can hope that they might learn: they could start to acknowledge that they’re doing this and they could be more conscious in outlining where they’re coming from. Swoop-by comments often trigger the simple thought “We’ve already discussed this…”, and it can be frustrating to have to repeat the same reply over and over. Let’s begin by acknowledging again that there’s no need to reply to every comment. If, however, replying to a previously litigated point might be useful, a   to the previous discussion for extra details is usually enough. Remember,  , so it’s okay to repeat things sometimes! Swoop-by commenting can still be useful for two reasons: they might point out something that still isn’t clear, and they also have the potential to stand in for the point of view of a user who’s seeing the design for the first time. Sure, you’ll still be frustrated, but that might at least help in dealing with it. The third friction point is the   we could have with the design, which could make us feel defensive if the   were to feel more like a  . Treating feedback as user research helps us create a healthy distance between the people giving us feedback and our ego (because yes, even if we don’t want to admit it, it’s there). And ultimately, treating everything in aggregated form allows us to better prioritize our work. Always remember that while you need to listen to stakeholders, project owners, and specific advice, you don’t have to accept every piece of feedback. You have to analyze it and make a decision that you can justify, but sometimes “no” is the right answer.  As the designer leading the project, you’re in charge of that decision. Ultimately, everyone has their specialty, and as the designer, you’re the one who has the most knowledge and the most context to make the right decision. And  . Like this: \n\t\t\t\t\t\t\tRecently by Erin Casali\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-for-the-unexpected/", "title": "Designing for the Unexpected", "content": "I’m not sure when I first heard this quote, but it’s something that has stayed with me over the years. How do you create services for situations you can’t imagine? Or design products that work on devices yet to be invented? Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Flash, Photoshop, and responsive design When I first started designing websites, my go-to software was Photoshop. I created a 960px canvas and set about creating a layout that I would later drop content in. The development phase was about attaining pixel-perfect accuracy using fixed widths, fixed heights, and absolute positioning. Ethan Marcotte’s talk at An Event Apart and subsequent article “ ” in  in 2010 changed all this. I was sold on responsive design as soon as I heard about it, but I was also terrified. The pixel-perfect designs full of magic numbers that I had previously prided myself on producing were no longer good enough. The fear wasn’t helped by my first experience with responsive design. My first project was to take an existing fixed-width website and make it responsive. What I learned the hard way was that you can’t just add responsiveness at the end of a project. To create fluid layouts, you need to plan throughout the design phase. A new way to design Designing responsive or fluid sites has always been about removing limitations, producing content that can be viewed on any device. It relies on the use of percentage-based layouts, which I initially achieved with native CSS and utility classes: Then with Sass so I could take advantage of @includes to re-use repeated blocks of code and move back to more semantic markup: Media queries The second ingredient for responsive design is media queries. Without them, content would shrink to fit the available space regardless of whether that content remained readable (The exact opposite problem occurred with the introduction of a mobile-first approach). Media queries prevented this by allowing us to add breakpoints where the design could adapt. Like most people, I started out with three breakpoints: one for desktop, one for tablets, and one for mobile. Over the years, I added more and more for phablets, wide screens, and so on.  For years, I happily worked this way and improved both my design and front-end skills in the process. The only problem I encountered was making changes to content, since with our Sass grid system in place, there was no way for the site owners to add content without amending the markup—something a small business owner might struggle with. This is because each row in the grid was defined using a   as a container. Adding content meant creating new row markup, which requires a level of HTML knowledge. Row markup was a staple of early responsive design, present in all the widely used frameworks like Bootstrap and Skeleton. Another problem arose as I moved from a design agency building websites for small- to medium-sized businesses, to larger in-house teams where I worked across a suite of related sites. In those roles I started to work much more with reusable components.  Our reliance on media queries resulted in components that were tied to common viewport sizes. If the goal of component libraries is reuse, then this is a real problem because you can only use these components if the devices you’re designing for correspond to the viewport sizes used in the pattern library—in the process not really hitting that “devices that don’t yet exist” goal. Then there’s the problem of space. Media queries allow components to adapt based on the viewport size, but what if I put a component into a sidebar, like in the figure below? Container queries: our savior or a false dawn? Container queries have long been touted as an improvement upon media queries, but at the time of writing are unsupported in most browsers. There are JavaScript workarounds, but they can create dependency and compatibility issues. The basic theory underlying container queries is that elements should change based on the size of their parent container and not the viewport width, as seen in the following illustrations. One of the biggest arguments in favor of container queries is that they help us create components or design patterns that are truly reusable because they can be picked up and placed anywhere in a layout. This is an important step in moving toward a form of component-based design that works at any size on any device. In other words, responsive components to replace responsive layouts. Container queries will help us move from designing pages that respond to the browser or device size to designing components that can be placed in a sidebar or in the main content, and respond accordingly. My concern is that we are still using layout to determine when a design needs to adapt. This approach will always be restrictive, as we will still need pre-defined breakpoints. For this reason, my main question with container queries is, How would we decide when to change the CSS used by a component?  A component library removed from context and real content is probably not the best place for that decision.  As the diagrams below illustrate, we can use container queries to create designs for specific container widths, but what if I want to change the design based on the image size or ratio? In this example, the dimensions of the container are not what should dictate the design; rather, the image is. It’s hard to say for sure whether container queries will be a success story until we have solid cross-browser support for them. Responsive component libraries would definitely evolve how we design and would improve the possibilities for reuse and design at scale. But maybe we will always need to adjust these components to suit our content. CSS is changing Whilst the container query debate rumbles on, there have been numerous advances in CSS that change the way we think about design. The days of fixed-width elements measured in pixels and floated   elements used to cobble layouts together are long gone, consigned to history along with table layouts. Flexbox and CSS Grid have revolutionized layouts for the web. We can now create elements that wrap onto new rows when they run out of space, not when the device changes. The   function paired with   or   allows us to specify how much space each column should use while leaving it up to the browser to decide when to spill the columns onto a new line. Similar things can be achieved with Flexbox, as elements can wrap over multiple rows and “flex” to fill available space.  The biggest benefit of all this is you don’t need to wrap elements in container rows. Without rows, content isn’t tied to page markup in quite the same way, allowing for removals or additions of content without additional development. This is a big step forward when it comes to creating designs that allow for evolving content, but the real game changer for flexible designs is CSS Subgrid.  Remember the days of crafting perfectly aligned interfaces, only for the customer to add an unbelievably long header almost as soon as they’re given CMS access, like the illustration below? Subgrid allows elements to respond to adjustments in their own content and in the content of sibling elements, helping us create designs more resilient to change. CSS Grid allows us to separate layout and content, thereby enabling flexible designs. Meanwhile, Subgrid allows us to create designs that can adapt in order to suit morphing content. Subgrid at the time of writing is only supported in Firefox but the above code can be implemented behind an @supports feature query.  Intrinsic layouts  I’d be remiss not to mention  , the term created by Jen Simmons to describe a mixture of new and old CSS features used to create layouts that respond to available space.  Responsive layouts have flexible columns using percentages. Intrinsic layouts, on the other hand, use the   unit to create flexible columns that won’t ever shrink so much that they render the content illegible. Intrinsic layouts can also utilize a mixture of fixed and flexible units, allowing the content to dictate the space it takes up. What makes intrinsic design stand out is that it not only creates designs that can withstand future devices but also helps scale design without losing flexibility. Components and patterns can be lifted and reused without the prerequisite of having the same breakpoints or the same amount of content as in the previous implementation.  We can now create designs that adapt to the space they have, the content within them, and the content around them. With an intrinsic approach, we can construct responsive components without depending on container queries. Another 2010 moment? This intrinsic approach should in my view be every bit as groundbreaking as responsive web design was ten years ago. For me, it’s another “everything changed” moment.  But it doesn’t seem to be moving quite as fast; I haven’t yet had that same career-changing moment I had with responsive design, despite   that brought it to my attention.  One reason for that could be that I now work in a large organization, which is quite different from the design agency role I had in 2010. In my agency days, every new project was a clean slate, a chance to try something new. Nowadays, projects use existing tools and frameworks and are often improvements to existing websites with an existing codebase.  Another could be that I feel more prepared for change now. In 2010 I was new to design in general; the shift was frightening and required a lot of learning. Also, an intrinsic approach isn’t exactly all-new; it’s about using existing skills and existing CSS knowledge in a different way.  You can’t framework your way out of a content problem Another reason for the slightly slower adoption of intrinsic design could be the lack of quick-fix framework solutions available to kick-start the change.  Responsive grid systems were all over the place ten years ago. With a framework like Bootstrap or Skeleton, you had a responsive design template at your fingertips. Intrinsic design and frameworks do not go hand in hand quite so well because the benefit of having a selection of units is a hindrance when it comes to creating layout templates. The beauty of intrinsic design is combining different units and experimenting with techniques to get the best for your content. And then there are design tools. We probably all, at some point in our careers, used Photoshop templates for desktop, tablet, and mobile devices to drop designs in and show how the site would look at all three stages. How do you do that now, with each component responding to content and layouts flexing as and when they need to? This type of design must happen in the browser, which personally I’m a big fan of.  The debate about “whether designers should code” is another that has rumbled on for years. When designing a digital product, we should, at the very least, design for a best- and worst-case scenario when it comes to content. To do this in a graphics-based software package is far from ideal. In code, we can add longer sentences, more radio buttons, and extra tabs, and watch in real time as the design adapts. Does it still work? Is the design too reliant on the current content? Personally, I look forward to the day intrinsic design is the standard for design, when a design component can be truly flexible and adapt to both its space and content with no reliance on device or container dimensions. Content first  Content is not constant. After all, to design for the unknown or unexpected we need to account for content changes like our earlier Subgrid card example that allowed the cards to respond to adjustments to their own content and the content of sibling elements. Thankfully, there’s more to CSS than layout, and plenty of properties and values can help us put content first. Subgrid and pseudo-elements like   and   help to separate design from markup so we can create designs that allow for changes. Instead of old markup hacks like this— —we can target content based on where it appears. Much bigger additions to CSS include l change the way we construct designs using logical dimensions (start and end) instead of physical ones (left and right), something CSS Grid also does with functions like  ,   and  . This flexibility allows for directional changes according to content, a common requirement when we need to present content in multiple languages. In the past, this was often achieved with Sass mixins but was often limited to switching from left-to-right to right-to-left orientation. In the Sass version, directional variables need to be set. These variables can be used as values— —or as properties. However, now we have native logical properties, removing the reliance on both Sass (or a similar tool) and pre-planning that necessitated using variables throughout a codebase. These properties also start to break apart the tight coupling between a design and strict physical dimensions, creating more flexibility for changes in language and in direction. There are also native start and end values for properties like  , which means we can replace   with  . Like the earlier examples, these properties help to build out designs that aren’t constrained to one language; the design will reflect the content’s needs. Fixed and fluid  We briefly covered the power of combining fixed widths with fluid widths with intrinsic layouts. The   and   functions are a similar concept, allowing you to specify a fixed value with a flexible alternative.  For   this means setting a fluid minimum value and a maximum fixed value. The element in the figure above will be 50% of its container as long as the element’s width doesn’t exceed 300px. For   we can set a flexible max value and a minimum fixed value. Now the element will be 50% of its container as long as the element’s width is at least 300px. This means we can set limits but allow content to react to the available space.  The   function builds on this by allowing us to set a preferred value with a third parameter. Now we can allow the element to shrink or grow if it needs to without getting to a point where it becomes unusable. This time, the element’s width will be 50% (the preferred value) of its container but never less than 300px and never more than 600px. With these techniques, we have a content-first approach to responsive design. We can separate content from markup, meaning the changes users make will not affect the design. We can start to future-proof designs by planning for unexpected changes in language or direction. And we can increase flexibility by setting desired dimensions alongside flexible alternatives, allowing for more or less content to be displayed correctly. Situation first Thanks to what we’ve discussed so far, we can cover device flexibility by changing our approach, designing around content and space instead of catering to devices. But what about that last bit of Jeffrey Zeldman’s quote, “…situations you haven’t imagined”? It’s a very different thing to design for someone seated at a desktop computer as opposed to someone using a mobile phone and moving through a crowded street in glaring sunshine. Situations and environments are hard to plan for or predict because they change as people react to their own unique challenges and tasks. This is why choice is so important. One size never fits all, so we need to design for multiple scenarios to create equal experiences for all our users. Thankfully, there is a lot we can do to provide choice. Responsible design  “There are parts of the world where mobile data is prohibitively expensive, and where there is little or no broadband infrastructure.” “ ” Chris Ashton One of the biggest assumptions we make is that people interacting with our designs have a good wifi connection and a wide screen monitor. But in the real world, our users may be commuters traveling on trains or other forms of transport using smaller mobile devices that can experience drops in connectivity. There is nothing more frustrating than a web page that won’t load, but there are ways we can help users use less data or deal with sporadic connectivity. The   attribute allows the browser to decide which image to serve. This means we can create smaller ‘cropped’ images to display on mobile devices in turn using less bandwidth and less data. The   attribute can also help us to think about how and when media is downloaded. It can be used to tell a browser about any critical assets that need to be downloaded with high priority, improving perceived performance and the user experience.  There’s also native  , which indicates assets that should only be downloaded when they are needed. With  ,  , and lazy loading, we can start to tailor a user’s experience based on the situation they find themselves in. What none of this does, however, is allow the user themselves to decide what they want downloaded, as the decision is usually the browser’s to make.  So how can we put users in control? The return of media queries  Media queries have always been about much more than device sizes. They allow content to adapt to different situations, with screen size being just one of them. We’ve long been able to check for media types like print and speech and features such as hover, resolution, and color. These checks allow us to provide options that suit more than one scenario; it’s less about one-size-fits-all and more about serving adaptable content.  As of this writing, the   is still under development. It introduces some really exciting queries that in the future will help us design for multiple other unexpected situations. For example, there’s a light-level feature that allows you to modify styles if a user is in sunlight or darkness. Paired with  , these features allow us to quickly create designs or themes for specific environments. Another key feature of the   spec is personalization. Instead of creating designs that are the same for everyone, users can choose what works for them. This is achieved by using features like  ,  , and  , the latter two of which already enjoy broad browser support. These features tap into preferences set via the operating system or browser so people don’t have to spend time making each site they visit more usable.  Media queries like this go beyond choices made by a browser to grant more control to the user. Expect the unexpected In the end, the one thing we should always expect is for things to change. Devices in particular change faster than we can keep up, with foldable screens already on the market. We can’t design the same way we have for this ever-changing landscape, but we can design for content. By putting content first and allowing that content to adapt to whatever space surrounds it, we can create more robust, flexible designs that increase the longevity of our products.  A lot of the CSS discussed here is about moving away from layouts and putting content at the heart of design. From responsive components to fixed and fluid units, there is so much more we can do to take a more intrinsic approach. Even better, we can test these techniques during the design phase by designing in-browser and watching how our designs adapt in real-time. When it comes to unexpected situations, we need to make sure our products are usable when people need them, whenever and wherever that might be. We can move closer to achieving this by involving users in our design decisions, by creating choice via browsers, and by giving control to our users with user-preference-based media queries.  Good design for the unexpected should allow for change, provide choice, and give control to those we serve: our users themselves. Like this: \n\t\t\t\t\t\t\tRecently by Cathy Dutton\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/voice-content-and-usability/", "title": "Voice Content and Usability", "content": "We’ve been having conversations for thousands of years. Whether to convey information, conduct transactions, or simply to check in on one another, people have yammered away, chattering and gesticulating, through spoken conversation for countless generations. Only in the last few millennia have we begun to commit our conversations to writing, and only in the last few decades have we begun to outsource them to the computer, a machine that shows much more affinity for written correspondence than for the slangy vagaries of spoken language. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Computers have trouble because between spoken and written language, speech is more primordial. To have successful conversations with us, machines must grapple with the messiness of human speech: the disfluencies and pauses, the gestures and body language, and the variations in word choice and spoken dialect that can stymie even the most carefully crafted human-computer interaction. In the human-to-human scenario, spoken language also has the privilege of face-to-face contact, where we can readily interpret nonverbal social cues. In contrast, written language immediately concretizes as we commit it to record and retains usages long after they become obsolete in spoken communication (the salutation “To whom it may concern,” for example), generating its own fossil record of outdated terms and phrases. Because it tends to be more consistent, polished, and formal, written text is fundamentally much easier for machines to parse and understand. Spoken language has no such luxury. Besides the nonverbal cues that decorate conversations with emphasis and emotional context, there are also verbal cues and vocal behaviors that modulate conversation in nuanced ways:   something is said, not  . Whether rapid-fire, low-pitched, or high-decibel, whether sarcastic, stilted, or sighing, our spoken language conveys much more than the written word could ever muster. So when it comes to voice interfaces—the machines we conduct spoken conversations with—we face exciting challenges as designers and content strategists. Voice Interactions We interact with voice interfaces for a variety of reasons, but according to Michael McTear, Zoraida Callejas, and David Griol in  , those motivations by and large mirror the reasons we initiate conversations with other people, too ( ). Generally, we start up a conversation because: we need something done (such as a transaction), we want to know something (information of some sort), or we are social beings and want someone to talk to (conversation for conversation’s sake). These three categories—which I call  ,  , and  —also characterize essentially every  : a single conversation from beginning to end that realizes some outcome for the user, starting with the voice interface’s first greeting and ending with the user exiting the interface. Note here that a   in our human sense—a chat between people that leads to some result and lasts an arbitrary length of time—could encompass multiple transactional, informational, and prosocial voice interactions in succession. In other words, a voice interaction is a conversation, but a conversation is not necessarily a single voice interaction. Purely   conversations are more gimmicky than captivating in most voice interfaces, because machines don’t yet have the capacity to   want to know how we’re doing and to do the sort of glad-handing humans crave. There’s also ongoing debate as to whether users actually prefer the sort of organic human conversation that begins with a prosocial voice interaction and shifts seamlessly into other types. In fact, in  , Michael Cohen, James Giangola, and Jennifer Balogh recommend sticking to users’ expectations by mimicking how they interact with other voice interfaces rather than trying too hard to be human—potentially alienating them in the process ( ). That leaves two genres of conversations we can have with one another that a voice interface can easily have with us, too: a   voice interaction realizing some outcome (“buy iced tea”) and an   voice interaction teaching us something new (“discuss a musical”). Transactional voice interactions Unless you’re tapping buttons on a food delivery app, you’re generally having a conversation—and therefore a voice interaction—when you order a Hawaiian pizza with extra pineapple. Even when we walk up to the counter and place an order, the conversation quickly pivots from an initial smattering of neighborly small talk to the real mission at hand: ordering a pizza (generously topped with pineapple, as it should be). Alison: Hey, how’s it going? Burhan: Hi, welcome to Crust Deluxe! It’s cold out there. How can I help you? Alison: Can I get a Hawaiian pizza with extra pineapple? Burhan: Sure, what size? Alison: Large. Burhan: Anything else? Alison: No thanks, that’s it. Burhan: Something to drink? Alison: I’ll have a bottle of Coke. Burhan: You got it. That’ll be $13.55 and about fifteen minutes. Each progressive disclosure in this   conversation reveals more and more of the desired outcome of the transaction: a service rendered or a product delivered. Transactional conversations have certain key traits: they’re direct, to the point, and economical. They quickly dispense with pleasantries. Informational voice interactions Meanwhile, some conversations are primarily about obtaining information. Though Alison might visit Crust Deluxe with the sole purpose of placing an order, she might not actually want to walk out with a pizza at all. She might be just as interested in whether they serve halal or kosher dishes, gluten-free options, or something else. Here, though we again have a prosocial mini-conversation at the beginning to establish politeness, we’re after much more. Alison: Hey, how’s it going? Burhan: Hi, welcome to Crust Deluxe! It’s cold out there. How can I help you? Alison: Can I ask a few questions? Burhan: Of course! Go right ahead. Alison: Do you have any halal options on the menu? Burhan: Absolutely! We can make any pie halal by request. We also have lots of vegetarian, ovo-lacto, and vegan options. Are you thinking about any other dietary restrictions? Alison: What about gluten-free pizzas? Burhan: We can definitely do a gluten-free crust for you, no problem, for both our deep-dish and thin-crust pizzas. Anything else I can answer for you? Alison: That’s it for now. Good to know. Thanks! Burhan: Anytime, come back soon! This is a very different dialogue. Here, the goal is to get a certain set of facts.   conversations are investigative quests for the truth—research expeditions to gather data, news, or facts. Voice interactions that are informational might be more long-winded than transactional conversations by necessity. Responses tend to be lengthier, more informative, and carefully communicated so the customer understands the key takeaways. Voice Interfaces At their core,   employ speech to support users in reaching their goals. But simply because an interface has a voice component doesn’t mean that every user interaction with it is mediated through voice. Because multimodal voice interfaces can lean on visual components like screens as crutches, we’re most concerned in this book with  , which depend entirely on spoken conversation, lack any visual component whatsoever, and are therefore much more nuanced and challenging to tackle. Though voice interfaces have long been integral to the imagined future of humanity in science fiction, only recently have those lofty visions become fully realized in genuine voice interfaces. Interactive voice response (IVR) systems Though written conversational interfaces have been fixtures of computing for many decades, voice interfaces first emerged in the early 1990s with text-to-speech (TTS) dictation programs that recited written text aloud, as well as speech-enabled in-car systems that gave directions to a user-provided address. With the advent of   (IVR) systems, intended as an alternative to overburdened customer service representatives, we became acquainted with the first true voice interfaces that engaged in authentic conversation. IVR systems allowed organizations to reduce their reliance on call centers but soon became notorious for their clunkiness. Commonplace in the corporate world, these systems were primarily designed as metaphorical switchboards to guide customers to a real phone agent (“Say   to book a flight or check an itinerary”); chances are you will enter a conversation with one when you call an airline or hotel conglomerate. Despite their functional issues and users’ frustration with their inability to speak to an actual human right away, IVR systems proliferated in the early 1990s across a variety of industries ( , PDF). While IVR systems are great for highly repetitive, monotonous conversations that generally don’t veer from a single format, they have a reputation for less scintillating conversation than we’re used to in real life (or even in science fiction). Screen readers Parallel to the evolution of IVR systems was the invention of the  , a tool that transcribes visual content into synthesized speech. For Blind or visually impaired website users, it’s the predominant method of interacting with text, multimedia, or form elements. Screen readers represent perhaps the closest equivalent we have today to an out-of-the-box implementation of content delivered through voice. Among the first screen readers known by that moniker was the Screen Reader for the BBC Micro and NEEC Portable developed by the Research Centre for the Education of the Visually Handicapped (RCEVH) at the University of Birmingham in 1986 ( ). That same year, Jim Thatcher created the first IBM Screen Reader for text-based computers, later recreated for computers with graphical user interfaces (GUIs) ( ). With the rapid growth of the web in the 1990s, the demand for accessible tools for websites exploded. Thanks to the introduction of semantic HTML and especially ARIA roles beginning in 2008, screen readers started facilitating speedy interactions with web pages that ostensibly allow disabled users to traverse the page as an aural and temporal space rather than a visual and physical one. In other words, screen readers for the web “provide mechanisms that translate visual design constructs—proximity, proportion, etc.—into useful information,” writes Aaron Gustafson in  . “At least they do when documents are authored thoughtfully” ( ). Though deeply instructive for voice interface designers, there’s one significant problem with screen readers: they’re difficult to use and unremittingly verbose. The visual structures of websites and web navigation don’t translate well to screen readers, sometimes resulting in unwieldy pronouncements that name every manipulable HTML element and announce every formatting change. For many screen reader users, working with web-based interfaces exacts a cognitive toll. In  , accessibility advocate and voice engineer Chris Maury considers why the screen reader experience is ill-suited to users relying on voice: From the beginning, I hated the way that Screen Readers work. Why are they designed the way they are? It makes no sense to present information visually and then, and only then, translate that into audio. All of the time and energy that goes into creating the perfect user experience for an app is wasted, or even worse, adversely impacting the experience for blind users. ( ) In many cases, well-designed voice interfaces can speed users to their destination better than long-winded screen reader monologues. After all, visual interface users have the benefit of darting around the viewport freely to find information, ignoring areas irrelevant to them. Blind users, meanwhile, are obligated to listen to every utterance synthesized into speech and therefore prize brevity and efficiency. Disabled users who have long had no choice but to employ clunky screen readers may find that voice interfaces, particularly more modern voice assistants, offer a more streamlined experience. Voice assistants When we think of   (the subset of voice interfaces now commonplace in living rooms, smart homes, and offices), many of us immediately picture HAL from   or hear Majel Barrett’s voice as the omniscient computer in  . Voice assistants are akin to personal concierges that can answer questions, schedule appointments, conduct searches, and perform other common day-to-day tasks. And they’re rapidly gaining more attention from accessibility advocates for their assistive potential. Before the earliest IVR systems found success in the enterprise, Apple published a demonstration video in 1987 depicting the Knowledge Navigator, a voice assistant that could transcribe spoken words and recognize human speech to a great degree of accuracy. Then, in 2001, Tim Berners-Lee and others formulated their vision for a Semantic Web “agent” that would perform typical errands like “checking calendars, making appointments, and finding locations” ( , behind paywall). It wasn’t until 2011 that Apple’s Siri finally entered the picture, making voice assistants a tangible reality for consumers. Thanks to the plethora of voice assistants available today, there is considerable variation in how programmable and customizable certain voice assistants are over others ( ). At one extreme, everything except vendor-provided features is locked down; for example, at the time of their release, the core functionality of Apple’s Siri and Microsoft’s Cortana couldn’t be extended beyond their existing capabilities. Even today, it isn’t possible to program Siri to perform arbitrary functions, because there’s no means by which developers can interact with Siri at a low level, apart from predefined categories of tasks like sending messages, hailing rideshares, making restaurant reservations, and certain others. At the opposite end of the spectrum, voice assistants like Amazon Alexa and Google Home offer a core foundation on which developers can build custom voice interfaces. For this reason, programmable voice assistants that lend themselves to customization and extensibility are becoming increasingly popular for developers who feel stifled by the limitations of Siri and Cortana. Amazon offers the Alexa Skills Kit, a developer framework for building custom voice interfaces for Amazon Alexa, while Google Home offers the ability to program arbitrary Google Assistant skills. Today, users can choose from among thousands of custom-built skills within both the Amazon Alexa and Google Assistant ecosystems. As corporations like Amazon, Apple, Microsoft, and Google continue to stake their territory, they’re also selling and open-sourcing an unprecedented array of tools and frameworks for designers and developers that aim to make building voice interfaces as easy as possible, even without code. Often by necessity, voice assistants like Amazon Alexa tend to be  —they’re tightly coupled to a device and can’t be accessed on a computer or smartphone instead. By contrast, many development platforms like Google’s Dialogflow have introduced   capabilities so users can build a single conversational interface that then manifests as a voice interface, textual chatbot, and IVR system upon deployment. I don’t prescribe any specific implementation approaches in this design-focused book, but in Chapter 4 we’ll get into some of the implications these variables might have on the way you build out your design artifacts. Voice Content Simply put,   is content delivered through voice. To preserve what makes human conversation so compelling in the first place, voice content needs to be free-flowing and organic, contextless and concise—everything written content isn’t. Our world is replete with voice content in various forms: screen readers reciting website content, voice assistants rattling off a weather forecast, and automated phone hotline responses governed by IVR systems. In this book, we’re most concerned with content delivered auditorily—not as an option, but as a necessity. For many of us, our first foray into informational voice interfaces will be to deliver content to users. There’s only one problem: any content we already have isn’t in any way ready for this new habitat. So how do we make the content trapped on our websites more conversational? And how do we write new copy that lends itself to voice interactions? Lately, we’ve begun slicing and dicing our content in unprecedented ways. Websites are, in many respects, colossal vaults of what I call  : lengthy prose that can extend for infinitely scrollable miles in a browser window, like microfilm viewers of newspaper archives. Back in 2002, well before the present-day ubiquity of voice assistants, technologist Anil Dash defined   as permalinked pieces of content that stay legible regardless of environment, such as email or text messages: A day’s weather forcast [ ], the arrival and departure times for an airplane flight, an abstract from a long publication, or a single instant message can all be examples of microcontent. ( ) I’d update Dash’s definition of microcontent to include all examples of bite-sized content that go well beyond written communiqués. After all, today we encounter microcontent in interfaces where a small snippet of copy is displayed alone, unmoored from the browser, like a textbot confirmation of a restaurant reservation. Microcontent offers the best opportunity to gauge how your content can be stretched to the very edges of its capabilities, informing delivery channels both established and novel. As microcontent, voice content is unique because it’s an example of how content is experienced in   rather than in  . We can glance at a digital sign underground for an instant and know when the next train is arriving, but voice interfaces hold our attention captive for periods of time that we can’t easily escape or skip, something screen reader users are all too familiar with. Because microcontent is fundamentally made up of isolated blobs with no relation to the channels where they’ll eventually end up, we need to ensure that our microcontent truly performs well as voice content—and that means focusing on the two most important traits of robust voice content:  and  . Fundamentally, the legibility and discoverability of our voice content both have to do with how voice content manifests in perceived time and space. Like this: \n\t\t\t\t\t\t\tRecently by Preston So\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/sustainable-web-design-excerpt/", "title": "Sustainable Web Design, An Excerpt", "content": "In the 1950s, many in the elite running community had begun to believe it wasn’t possible to run a mile in less than four minutes. Runners had been attempting it since the late 19th century and were beginning to draw the conclusion that the human body simply wasn’t built for the task.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But on May 6, 1956, Roger Bannister took everyone by surprise. It was a cold, wet day in Oxford, England—conditions no one expected to lend themselves to record-setting—and yet Bannister did just that, running a mile in 3:59.4 and becoming the first person in the record books to run a mile in under four minutes.  This shift in the benchmark had profound effects; the world now knew that the four-minute mile was possible. Bannister’s record lasted only forty-six days, when it was snatched away by Australian runner John Landy. Then a year later, three runners all beat the four-minute barrier together in the same race. Since then, over 1,400 runners have officially  ; the current record is 3:43.13, held by Moroccan athlete Hicham El Guerrouj. We achieve far more when we believe that something is possible, and we will believe it’s possible only when we see someone else has already done it—and as with human running speed, so it is with what we believe are the hard limits for how a website needs to perform. Establishing standards for a sustainable web In most major industries, the key metrics of environmental performance are fairly well established, such as miles per gallon for cars or energy per square meter for homes. The tools and methods for calculating those metrics are standardized as well, which keeps everyone on the same page when doing environmental assessments. In the world of websites and apps, however, we aren’t held to any particular environmental standards, and only recently have gained the tools and methods we need to even make an environmental assessment. The primary goal in sustainable web design is to reduce  . However, it’s almost impossible to actually measure the amount of CO  produced by a web product. We can’t measure the fumes coming out of the exhaust pipes on our laptops. The emissions of our websites are far away, out of sight and out of mind, coming out of power stations burning coal and gas. We have no way to trace the electrons from a website or app back to the power station where the electricity is being generated and actually know the exact amount of greenhouse gas produced. So what do we do?  If we can’t measure the actual carbon emissions, then we need to find what we   measure. The primary factors that could be used as indicators of carbon emissions are: Let’s take a look at how we can use these metrics to quantify the energy consumption, and in turn the carbon footprint, of the websites and web apps we create. Data transfer Most researchers use kilowatt-hours per gigabyte (kWh/GB) as a metric of energy efficiency when measuring the amount of data transferred over the internet when a website or application is used. This provides a great reference point for energy consumption and carbon emissions. As a rule of thumb, the more data transferred, the more energy used in the data center, telecoms networks, and end user devices. For web pages, data transfer for a single visit can be most easily estimated by measuring the  meaning the transfer size of the page in kilobytes the first time someone visits the page. It’s fairly easy to measure using the developer tools in any modern web browser. Often your web hosting account will include statistics for the total data transfer of any web application ( ). The nice thing about page weight as a metric is that it allows us to compare the efficiency of web pages on a level playing field without confusing the issue with constantly changing traffic volumes.  Reducing page weight requires a large scope. By early 2020, the median page weight was 1.97 MB for setups the HTTP Archive classifies as “desktop” and 1.77 MB for “mobile,” with desktop increasing 36 percent since January 2016 and mobile page weights nearly   ( ). Roughly half of this data transfer is image files, making images the single biggest source of carbon emissions on the average website.  History clearly shows us that our web pages   be smaller, if only we set our minds to it. While most technologies become ever more energy efficient, including the underlying technology of the web such as data centers and transmission networks, websites themselves are a technology that becomes less efficient as time goes on. You might be familiar with the concept of performance budgeting as a way of focusing a project team on creating faster user experiences. For example, we might specify that the website must load in a maximum of one second on a broadband connection and three seconds on a 3G connection. Much like speed limits while driving, performance budgets are upper limits rather than vague suggestions, so the goal should always be to come in under budget. Designing for fast performance does often lead to reduced data transfer and emissions, but it isn’t always the case. Web performance is often more about the subjective perception of load times than it is about the true efficiency of the underlying system, whereas page weight and transfer size are more objective measures and more reliable benchmarks for sustainable web design.  We can set a page weight budget in reference to a benchmark of industry averages, using data from sources like HTTP Archive. We can also benchmark page weight against competitors or the old version of the website we’re replacing. For example, we might set a maximum page weight budget as equal to our most efficient competitor, or we could set the benchmark lower to guarantee we are best in class.  If we want to take it to the next level, then we could also start looking at the transfer size of our web pages for repeat visitors. Although page weight for the first time someone visits is the easiest thing to measure, and easy to compare on a like-for-like basis, we can learn even more if we start looking at transfer size in other scenarios too. For example, visitors who load the same page multiple times will likely have a high percentage of the files cached in their browser, meaning they don’t need to transfer all of the files on subsequent visits. Likewise, a visitor who navigates to new pages on the same website will likely not need to load the full page each time, as some global assets from areas like the header and footer may already be cached in their browser. Measuring transfer size at this next level of detail can help us learn even more about how we can optimize efficiency for users who regularly visit our pages, and enable us to set page weight budgets for additional scenarios beyond the first visit. Page weight budgets are easy to track throughout a design and development process. Although they don’t actually tell us carbon emission and energy consumption analytics directly, they give us a clear indication of efficiency relative to other websites. And as transfer size is an effective analog for energy consumption, we can actually use it to estimate energy consumption too. In summary, reduced data transfer translates to energy efficiency, a key factor to reducing carbon emissions of web products. The more efficient our products, the less electricity they use, and the less fossil fuels need to be burned to produce the electricity to power them. But as we’ll see next, since all web products demand   power, it’s important to consider the source of that electricity, too. Carbon intensity of electricity Regardless of energy efficiency, the level of pollution caused by digital products depends on the   of the energy being used to power them. Carbon intensity is a term used to define the grams of CO  produced for every kilowatt-hour of electricity (gCO /kWh). This varies widely, with renewable energy sources and nuclear having   of less than 10 gCO /kWh (even when factoring in their construction); whereas fossil fuels have   of approximately 200–400 gCO /kWh.  Most electricity comes from national or state grids, where energy from a variety of different sources is mixed together with varying levels of carbon intensity. The distributed nature of the internet means that a single user of a website or app might be using energy from multiple different grids simultaneously; a website user in Paris uses electricity from the French national grid to power their home internet and devices, but the website’s data center could be in Dallas, USA, pulling electricity from the Texas grid, while the telecoms networks use energy from everywhere between Dallas and Paris. We don’t have control over the full energy supply of web services, but we do have some control over where we host our projects. With a data center using a significant proportion of the energy of any website, locating the data center in an area with low carbon energy will tangibly reduce its carbon emissions. Danish startup Tomorrow reports and  , and a glance at their map shows how, for example, choosing a data center in France will have significantly lower carbon emissions than a data center in the Netherlands ( ). That said, we don’t want to locate our servers too far away from our users; it takes energy to transmit data through the telecom’s networks, and the further the data travels, the more energy is consumed. Just like food miles, we can think of the distance from the data center to the website’s core user base as “megabyte miles”—and we want it to be as small as possible. Using the distance itself as a benchmark, we can use website analytics to identify the country, state, or even city where our core user group is located and measure the distance from that location to the data center used by our hosting company. This will be a somewhat fuzzy metric as we don’t know the precise center of mass of our users or the exact location of a data center, but we can at least get a rough idea.  For example, if a website is hosted in London but the primary user base is on the West Coast of the USA, then we could look up the distance from London to San Francisco, which is 5,300 miles. That’s a long way! We can see that hosting it somewhere in North America, ideally on the West Coast, would significantly reduce the distance and thus the energy used to transmit the data. In addition, locating our servers closer to our visitors helps reduce latency and delivers better user experience, so it’s a win-win. If we combine carbon intensity with a calculation for energy consumption, we can calculate the carbon emissions of our websites and apps. A tool my team created does this by measuring the data transfer over the wire when loading a web page, calculating the amount of electricity associated, and then converting that into a figure for CO  ( ). It also factors in whether or not the web hosting is powered by renewable energy. If you want to take it to the next level and tailor the data more accurately to the unique aspects of your project, the   accompanying this book shows you how. With the ability to calculate carbon emissions for our projects, we could actually take a page weight budget one step further and set carbon budgets as well. CO  is not a metric commonly used in web projects; we’re more familiar with kilobytes and megabytes, and can fairly easily look at design options and files to assess how big they are. Translating that into carbon adds a layer of abstraction that isn’t as intuitive—but carbon budgets do focus our minds on the primary thing we’re trying to reduce, and support the core objective of sustainable web design: reducing carbon emissions. Browser Energy Data transfer might be the simplest and most complete analog for energy consumption in our digital projects, but by giving us one number to represent the energy used in the data center, the telecoms networks, and the end user’s devices, it can’t offer us insights into the efficiency in any specific part of the system. One part of the system we can look at in more detail is the energy used by end users’ devices. As front-end web technologies become more advanced, the computational load is increasingly moving from the data center to users’ devices, whether they be phones, tablets, laptops, desktops, or even smart TVs. Modern web browsers allow us to implement more complex styling and animation on the fly using CSS and JavaScript. Furthermore, JavaScript libraries such as Angular and React allow us to create applications where the “thinking” work is done partly or entirely in the browser.  All of these advances are exciting and open up new possibilities for what the web can do to serve society and create positive experiences. However, more computation in the user’s web browser means more energy used by their devices. This has implications not just environmentally, but also for user experience and inclusivity. Applications that put a heavy processing load on the user’s device can inadvertently exclude users with older, slower devices and cause batteries on phones and laptops to drain faster. Furthermore, if we build web applications that require the user to have up-to-date, powerful devices, people throw away old devices much more frequently. This isn’t just bad for the environment, but it puts a disproportionate financial burden on the poorest in society. In part because the tools are limited, and partly because there are so many different models of devices, it’s difficult to measure website energy consumption on end users’ devices. One tool we do currently have is the Energy Impact monitor inside the developer console of the Safari browser ( ). You know when you load a website and your computer’s cooling fans start spinning so frantically you think it might actually take off? That’s essentially what this tool is measuring.  It shows us the percentage of CPU used and the duration of CPU usage when loading the web page, and uses these figures to generate an energy impact rating. It doesn’t give us precise data for the amount of electricity used in kilowatts, but the information it does provide can be used to benchmark how efficiently your websites use energy and set targets for improvement. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/design-for-safety-excerpt/", "title": "Design for Safety, An Excerpt", "content": "Antiracist economist Kim Crayton says that “intention without strategy is chaos.” We’ve discussed how our biases, assumptions, and inattention toward marginalized and vulnerable groups lead to dangerous and unethical tech—but what,  , do we need to do to fix it? The intention to make our tech safer is not enough; we need a strategy. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. This chapter will equip you with that plan of action. It covers how to integrate safety principles into your design work in order to create tech that’s safe, how to convince your stakeholders that this work is necessary, and how to respond to the critique that what we   need is more diversity. (Spoiler: we do, but diversity alone is not the antidote to fixing unethical, unsafe tech.) When you are designing for safety, your goals are to: identify ways your product can be used for abuse, design ways to prevent the abuse, and provide support for vulnerable users to reclaim power and control. The Process for Inclusive Safety is a tool to help you reach those goals ( ). It’s a methodology I created in 2018 to capture the various techniques I was using when designing products with safety in mind. Whether you are creating an entirely new product or adding to an existing feature, the Process can help you make your product safe and inclusive. The Process includes five general areas of action: Conducting research Creating archetypes Brainstorming problems Designing solutions Testing for safety The Process is meant to be flexible—it won’t make sense for teams to implement every step in some situations. Use the parts that are relevant to your unique work and context; this is meant to be something you can insert into your existing design practice. And once you use it, if you have an idea for making it better or simply want to provide context of how it helped your team, please get in touch with me. It’s a living document that I hope will continue to be a useful and realistic tool that technologists can use in their day-to-day work. If you’re working on a product specifically for a vulnerable group or survivors of some form of trauma, such as an app for survivors of domestic violence, sexual assault, or drug addiction, be sure to read Chapter 7, which covers that situation explicitly and should be handled a bit differently. The guidelines here are for prioritizing safety when designing a more general product that will have a wide user base (which, we already know from statistics, will include certain groups that should be protected from harm). Chapter 7 is focused on products that are   vulnerable groups and people who have experienced trauma. Step 1: Conduct research Design research should include a broad analysis of how your tech might be weaponized for abuse as well as specific insights into the experiences of survivors and perpetrators of that type of abuse. At this stage, you and your team will investigate issues of interpersonal harm and abuse, and explore any other safety, security, or inclusivity issues that might be a concern for your product or service, like data security, racist algorithms, and harassment. Your project should begin with broad, general research into similar products and issues around safety and ethical concerns that have already been reported. For example, a team building a smart home device would do well to understand the multitude of ways that existing smart home devices have been used as tools of abuse. If your product will involve AI, seek to understand the potentials for racism and other issues that have been reported in existing AI products. Nearly all types of technology have some kind of potential or actual harm that’s been reported on in the news or written about by academics.   is a useful tool for finding these studies. When possible and appropriate, include direct research (surveys and interviews) with people who are experts in the forms of harm you have uncovered. Ideally, you’ll want to interview advocates working in the space of your research first so that you have a more solid understanding of the topic and are better equipped to not retraumatize survivors. If you’ve uncovered possible domestic violence issues, for example, the experts you’ll want to speak with are survivors themselves, as well as workers at domestic violence hotlines, shelters, other related nonprofits, and lawyers. Especially when interviewing survivors of any kind of trauma, it is important to pay people for their knowledge and lived experiences. Don’t ask survivors to share their trauma for free, as this is exploitative. While some survivors may not want to be paid, you should always make the offer in the initial ask. An alternative to payment is to donate to an organization working against the type of violence that the interviewee experienced. We’ll talk more about how to appropriately interview survivors in Chapter 6. It’s unlikely that teams aiming to design for safety will be able to interview self-proclaimed abusers or people who have broken laws around things like hacking. Don’t make this a goal; rather, try to get at this angle in your general research. Aim to understand how abusers or bad actors weaponize technology to use against others, how they cover their tracks, and how they explain or rationalize the abuse. Step 2: Create archetypes Once you’ve finished conducting your research, use your insights to create abuser and survivor archetypes. Archetypes are not personas, as they’re not based on real people that you interviewed and surveyed. Instead, they’re based on your research into likely safety issues, much like when we design for accessibility: we don’t need to have found a group of blind or low-vision users in our interview pool to create a design that’s inclusive of them. Instead, we base those designs on existing research into what this group needs. Personas typically represent real users and include many details, while archetypes are broader and can be more generalized. The abuser archetype is someone who will look at the product as a tool to perform harm ( ). They may be trying to harm someone they don’t know through surveillance or anonymous harassment, or they may be trying to control, monitor, abuse, or torment someone they know personally. The survivor archetype is someone who is being abused with the product. There are various situations to consider in terms of the archetype’s understanding of the abuse and how to put an end to it: Do they need proof of abuse they already suspect is happening, or are they unaware they’ve been targeted in the first place and need to be alerted ( )? You may want to make multiple survivor archetypes to capture a range of different experiences. They may know that the abuse is happening but not be able to stop it, like when an abuser locks them out of IoT devices; or they know it’s happening but don’t know how, such as when a stalker keeps figuring out their location ( ). Include as many of these scenarios as you need to in your survivor archetype. You’ll use these later on when you design solutions to help your survivor archetypes achieve their goals of preventing and ending abuse. It may be useful for you to create persona-like artifacts for your archetypes, such as the three examples shown. Instead of focusing on the demographic information we often see in personas, focus on their goals. The goals of the abuser will be to carry out the specific abuse you’ve identified, while the goals of the survivor will be to prevent abuse, understand that abuse is happening, make ongoing abuse stop, or regain control over the technology that’s being used for abuse. Later, you’ll brainstorm how to prevent the abuser’s goals and assist the survivor’s goals. And while the “abuser/survivor” model fits most cases, it doesn’t fit all, so modify it as you need to. For example, if you uncovered an issue with security, such as the ability for someone to hack into a home camera system and talk to children, the malicious hacker would get the abuser archetype and the child’s parents would get survivor archetype. Step 3: Brainstorm problems After creating archetypes, brainstorm novel abuse cases and safety issues. “Novel” means things not found in your research; you’re trying to identify completely   safety issues that are unique to your product or service. The goal with this step is to exhaust every effort of identifying harms your product could cause. You aren’t worrying about how to prevent the harm yet—that comes in the next step. How could your product be used for any kind of abuse, outside of what you’ve already identified in your research? I recommend setting aside at least a few hours with your team for this process. If you’re looking for somewhere to start, try doing a Black Mirror brainstorm. This exercise is based on the show  , which features stories about the dark possibilities of technology. Try to figure out how your product would be used in an episode of the show—the most wild, awful, out-of-control ways it could be used for harm. When I’ve led Black Mirror brainstorms, participants usually end up having a good deal of fun (which I think is great—it’s okay to have fun when designing for safety!). I recommend time-boxing a Black Mirror brainstorm to half an hour, and then dialing it back and using the rest of the time thinking of more realistic forms of harm. After you’ve identified as many opportunities for abuse as possible, you may still not feel confident that you’ve uncovered every potential form of harm. A healthy amount of anxiety is normal when you’re doing this kind of work. It’s common for teams designing for safety to worry, “Have we really identified every possible harm? What if we’ve missed something?” If you’ve spent at least four hours coming up with ways your product could be used for harm and have run out of ideas, go to the next step. It’s impossible to guarantee you’ve thought of everything; instead of aiming for 100 percent assurance, recognize that you’ve taken this time and have done the best you can, and commit to continuing to prioritize safety in the future. Once your product is released, your users may identify new issues that you missed; aim to receive that feedback graciously and course-correct quickly. Step 4: Design solutions At this point, you should have a list of ways your product can be used for harm as well as survivor and abuser archetypes describing opposing user goals. The next step is to identify ways to design against the identified abuser’s goals and to support the survivor’s goals. This step is a good one to insert alongside existing parts of your design process where you’re proposing solutions for the various problems your research uncovered. Some questions to ask yourself to help prevent harm and support your archetypes include: Can you design your product in such a way that the identified harm cannot happen in the first place? If not, what roadblocks can you put up to prevent the harm from happening? How can you make the victim aware that abuse is happening through your product? How can you help the victim understand what they need to do to make the problem stop? Can you identify any types of user activity that would indicate some form of harm or abuse? Could your product help the user access support? In some products, it’s possible to proactively recognize that harm is happening. For example, a pregnancy app might be modified to allow the user to report that they were the victim of an assault, which could trigger an offer to receive resources for local and national organizations. This sort of proactiveness is not always possible, but it’s worth taking a half hour to discuss if any type of user activity would indicate some form of harm or abuse, and how your product could assist the user in receiving help in a safe manner. That said, use caution: you don’t want to do anything that could put a user in harm’s way if their devices are being monitored. If you do offer some kind of proactive help, always make it voluntary, and think through other safety issues, such as the need to keep the user in-app in case an abuser is checking their search history. We’ll walk through a good example of this in the next chapter. Step 5: Test for safety The final step is to test your prototypes from the point of view of your archetypes: the person who wants to weaponize the product for harm and the victim of the harm who needs to regain control over the technology. Just like any other kind of product testing, at this point you’ll aim to rigorously test out your safety solutions so that you can identify gaps and correct them, validate that your designs will help keep your users safe, and feel more confident releasing your product into the world. Ideally, safety testing happens along with usability testing. If you’re at a company that doesn’t do usability testing, you might be able to use safety testing to cleverly perform both; a user who goes through your design attempting to weaponize the product against someone else can also be encouraged to point out interactions or other elements of the design that don’t make sense to them. You’ll want to conduct safety testing on either your final prototype or the actual product if it’s already been released. There’s nothing wrong with testing an existing product that wasn’t designed with safety goals in mind from the onset—“retrofitting” it for safety is a good thing to do. Remember that testing for safety involves testing from the perspective of both an abuser and a survivor, though it may not make sense for you to do both. Alternatively, if you made multiple survivor archetypes to capture multiple scenarios, you’ll want to test from the perspective of each one. As with other sorts of usability testing, you as the designer are most likely too close to the product and its design by this point to be a valuable tester; you know the product too well. Instead of doing it yourself, set up testing as you would with other usability testing: find someone who is not familiar with the product and its design, set the scene, give them a task, encourage them to think out loud, and observe how they attempt to complete it. The goal of this testing is to understand how easy it is for someone to weaponize your product for harm. Unlike with usability testing, you   to make it impossible, or at least difficult, for them to achieve their goal. Reference the goals in the abuser archetype you created earlier, and use your product in an attempt to achieve them. For example, for a fitness app with GPS-enabled location features, we can imagine that the abuser archetype would have the goal of figuring out where his ex-girlfriend now lives. With this goal in mind, you’d try everything possible to figure out the location of another user who has their privacy settings enabled. You might try to see her running routes, view any available information on her profile, view anything available about her location (which she has set to private), and investigate the profiles of any other users somehow connected with her account, such as her followers. If by the end of this you’ve managed to uncover some of her location data, despite her having set her profile to private, you know now that your product enables stalking. Your next step is to go back to step 4 and figure out how to prevent this from happening. You may need to repeat the process of designing solutions and testing them more than once. Survivor testing involves identifying how to give information and power to the survivor. It might not always make sense based on the product or context. Thwarting the attempt of an abuser archetype to stalk someone also satisfies the goal of the survivor archetype to not be stalked, so separate testing wouldn’t be needed from the survivor’s perspective. However, there are cases where it makes sense. For example, for a smart thermostat, a survivor archetype’s goals would be to understand who or what is making the temperature change when they aren’t doing it themselves. You could test this by looking for the thermostat’s history log and checking for usernames, actions, and times; if you couldn’t find that information, you would have more work to do in step 4. Another goal might be regaining control of the thermostat once the survivor realizes the abuser is remotely changing its settings. Your test would involve attempting to figure out how to do this: are there instructions that explain how to remove another user and change the password, and are they easy to find? This might again reveal that more work is needed to make it clear to the user how they can regain control of the device or account. To make your product more inclusive and compassionate, consider adding stress testing. This concept comes from   by Eric Meyer and Sara Wachter-Boettcher. The authors pointed out that personas typically center people who are having a good day—but real users are often anxious, stressed out, having a bad day, or even experiencing tragedy. These are called “stress cases,” and testing your products for users in stress-case situations can help you identify places where your design lacks compassion.   has more details about what it looks like to incorporate stress cases into your design as well as many other great tactics for compassionate design. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/a-content-model-is-not-a-design-system/", "title": "A Content Model Is Not a Design System", "content": "Do you remember when having a great website was enough? Now, people are getting answers from Siri, Google search snippets, and mobile apps, not just our websites. Forward-thinking organizations have adopted an  , whose mission is to reach audiences across multiple digital channels and platforms. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But how do you set up a content management system (CMS) to reach your audience now and in the future? I learned the hard way that creating a  —a definition of content types, attributes, and relationships that let people and systems understand content—with my more familiar design-system thinking would capsize my customer’s omnichannel content strategy. You can avoid that outcome by creating content models that are semantic and that also connect related content.  I recently had the opportunity to lead the CMS implementation for a Fortune 500 company. The client was excited by the benefits of an omnichannel content strategy, including content reuse, multichannel  , and  —designing content to be intelligible to bots, Google knowledge panels, snippets, and voice user interfaces.  A content model is a critical foundation for an omnichannel content strategy, and for our content to be understood by multiple systems, the model needed   types—types named according to their meaning instead of their presentation. Our goal was to let authors create content and reuse it wherever it was relevant. But as the project proceeded, I realized that supporting content reuse at the scale that my customer needed required the whole team to recognize a new pattern. Despite our best intentions, we kept drawing from what we were more familiar with:  . Unlike web-focused content strategies, an omnichannel content strategy can’t rely on WYSIWYG tools for design and layout. Our tendency to approach the content model with our familiar design-system thinking constantly led us to veer away from one of the primary purposes of a content model: delivering content to audiences on multiple marketing channels. Two essential principles for an effective content model We needed to help our designers, developers, and stakeholders understand that we were doing something very different from their prior web projects, where it was natural for everyone to think about content as visual building blocks fitting into layouts. The previous approach was not only more familiar but also more intuitive—at least at first—because it made the designs feel more tangible. We discovered two principles that helped the team understand how a content model differs from the design systems that we were used to: Semantic content models A   uses type and attribute names that reflect the meaning of the content, not how it will be displayed. For example, in a nonsemantic model, teams might create types like  ,  , and  . Although these types might make it easy to lay out content, they don’t help delivery channels understand the content’s meaning, which in turn would have opened the door to the content being presented in each marketing channel. In contrast, a semantic content model uses type names like  ,  , and   so that each delivery channel can understand the content and use it as it sees fit.  When you’re creating a semantic content model, a great place to start is to look over the types and properties defined by  , a community-driven resource for type definitions that are intelligible to platforms like Google search. A semantic content model has several benefits: Even if your team doesn’t care about omnichannel content, a semantic content model   so that teams can evolve the website’s design without needing to refactor its content. In this way, content can withstand disruptive website redesigns.  A semantic content model also provides a competitive edge. By adding  based on Schema.org’s types and properties, a website can provide hints to help Google understand the content, display it in search snippets or knowledge panels, and use it to answer voice-interface user questions. Potential visitors could discover your content without ever setting foot in your website. Beyond those practical benefits, you’ll also need a semantic content model if you want to deliver omnichannel content. To use the same content in multiple marketing channels,  . For example, if your content model were to provide a list of questions and answers, it could easily be rendered on a frequently asked questions (FAQ) page, but it could also be used in a   or by a bot that answers  . For example, using a semantic content model for articles, events, people, and locations lets   provide cleanly structured data for search engines so that users can read the content on the website, in Google knowledge panels, and even with hypothetical voice interfaces in the future. Content models that connect After struggling to describe what makes a good content model, I’ve come to realize that the best models are those that are semantic and that also connect related content components (such as a FAQ item’s question and answer pair), instead of slicing up related content across disparate content components. A good content model connects content that should remain together so that multiple delivery channels can use it without needing to first put those pieces back together. Think about writing an article or essay. An article’s meaning and usefulness depends upon its parts being kept together. Would one of the headings or paragraphs be meaningful on their own without the context of the full article? On our project, our familiar design-system thinking often led us to want to create content models that would slice content into disparate chunks to fit the web-centric layout. This had a similar impact to an article that were to have been separated from its headline. Because we were slicing content into standalone pieces based on layout, content that belonged together became difficult to manage and nearly impossible for multiple delivery channels to understand. To illustrate, let’s look at how connecting related content applies in a real-world scenario. The design team for our customer presented a complex layout for a software product page that included multiple tabs and sections. Our instincts were to follow suit with the content model. Shouldn’t we make it as easy and as flexible as possible to add any number of tabs in the future? Because our design-system instincts were so familiar, it felt like we had needed a content type called “tab section” so that multiple tab sections could be added to a page. Each tab section would display various types of content. One tab might provide the software’s overview or its specifications. Another tab might provide a list of resources.  Our inclination to break down the content model into “tab section” pieces would have led to an unnecessarily complex model and a cumbersome editing experience, and it would have also created content that couldn’t have been understood by additional delivery channels. For example, how would another system have been able to tell which “tab section” referred to a product’s specifications or its resource list—would that other system have to have resorted to counting tab sections and content blocks? This would have prevented the tabs from ever being reordered, and it would have required adding logic in every other delivery channel to interpret the design system’s layout. Furthermore, if the customer were to have no longer wanted to display this content in a tab layout, it would have been tedious to migrate to a new content model to reflect the new page redesign. We had a breakthrough when we discovered that our customer had a specific purpose in mind for each tab: it would reveal specific information such as the software product’s overview, specifications, related resources, and pricing. Once implementation began, our inclination to focus on what’s visual and familiar had obscured the intent of the designs. With a little digging, it didn’t take long to realize that the concept of tabs wasn’t relevant to the content model. The meaning of the content that they were planning to display in the tabs was what mattered. In fact, the customer could have decided to display this content in a different way—without tabs—somewhere else. This realization prompted us to define content types for the software product based on the meaningful attributes that the customer had wanted to render on the web. There were obvious semantic attributes like   and   as well as rich attributes like  ,  , and  . The software’s product information stayed together because it wasn’t sliced across separate components like “tab sections” that were derived from the content’s presentation. Any delivery channel—including future ones—could understand and present this content. Conclusion In this omnichannel marketing project, we discovered that the best way to keep our content model on track was to ensure that it was   (with type and attribute names that reflected the meaning of the content) and that it   (instead of fragmenting it). These two concepts curtailed our temptation to shape the content model based on the design. So if you’re working on a content model to support an omnichannel content strategy—or even if you just want to make sure that Google and other interfaces understand your content—remember: A design system isn’t a content model. Team members may be tempted to conflate them and to make your content model mirror your design system, so you should protect the semantic value and contextual structure of the content strategy during the entire implementation process. This will let every delivery channel consume the content without needing a magic decoder ring. If your team is struggling to make this transition, you can still reap some of the benefits by using Schema.org–based structured data in your website. Even if additional delivery channels aren’t on the immediate horizon, the benefit to search engine optimization is a compelling reason on its own. Additionally, remind the team that decoupling the content model from the design will let them update the designs more easily because they won’t be held back by the cost of content migrations. They’ll be able to create new designs without the obstacle of compatibility between the design and the content, and ​they’ll be ready for the next big thing.  By rigorously advocating for these principles, you’ll help your team treat content the way that it deserves—as the most critical asset in your user experience and the best way to connect with your audience. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/how-to-sell-ux-research/", "title": "How to Sell UX Research with Two Simple Questions", "content": "Do you find yourself designing screens with only a vague idea of how the things on the screen relate to the things elsewhere in the system? Do you leave stakeholder meetings with unclear directives that often seem to contradict previous conversations? You   a better understanding of user needs would help the team get clear on what you are actually trying to accomplish, but time and budget for research is tight. When it comes to asking for more direct contact with your users, you might feel like poor Oliver Twist, timidly asking, “Please, sir, I want some more.”  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Here’s the trick. You need to get stakeholders   to identify high-risk assumptions and hidden complexity, so that they become just as motivated as you to get answers from users. Basically, you need to make them think it’s their idea.  In this article, I’ll show you how to collaboratively expose misalignment and gaps in the team’s shared understanding by bringing the team together around two simple questions: A gauntlet between research and screen design These two questions align to the first two steps of the ORCA process, which might become your new best friend when it comes to reducing guesswork. Wait, what’s ORCA?! Glad you asked. ORCA stands for Objects, Relationships, CTAs, and Attributes, and it outlines a process for creating solid object-oriented user experiences.   is my design philosophy. ORCA is an iterative methodology for synthesizing user research into an elegant structural foundation to support screen and interaction design.   and ORCA have made my work as a UX designer more collaborative, effective, efficient, fun, strategic, and meaningful. The ORCA process has four iterative rounds and a whopping fifteen steps. In each round we get more clarity on our Os, Rs, Cs, and As. I sometimes say that ORCA is a “garbage in, garbage out” process. To ensure that the testable prototype produced in the final round actually tests  , the process needs to be fed by   research. But if you don’t have a ton of research, the beginning of the ORCA process serves another purpose: it helps you sell the   for research. In other words, the ORCA process serves as a gauntlet between research and design. With good research, you can gracefully ride the killer whale from research into design. But without good research, the process effectively spits you back into research and with a cache of   open questions. Getting in the same curiosity-boat What gets us into trouble is not what we don’t know. It’s what we know for sure that just ain’t so. The first two steps of the ORCA process—Object Discovery and Relationship Discovery—shine a spotlight on the dark, dusty corners of your team’s misalignments and any inherent complexity that’s been swept under the rug. It begins to expose what this classic comic so beautifully illustrates: This is one reason why so many UX designers are frustrated in their job and why many projects fail. And this is also why we often can’t sell research: every decision-maker is confident in their own mental picture.  Once we expose hidden fuzzy patches in each picture and the differences between them all, the case for user research makes itself. But how we do this is important. However much we might want to, we can’t just tell everyone, “YOU ARE WRONG!” Instead, we need to facilitate and guide our team members to self-identify holes in their picture. When stakeholders take ownership of assumptions and gaps in understanding, BAM! Suddenly, UX research is not such a hard sell, and everyone is aboard the same curiosity-boat. Say your users are doctors. And you have no idea how doctors use the system you are tasked with redesigning. You might try to sell research by honestly saying: “We need to understand doctors better! What are their pain points? How do they use the current app?” But here’s the problem with that. Those questions are vague, and the answers to them don’t feel acutely actionable. Instead, you want your stakeholders themselves to ask super-specific questions. This is more like the kind of conversation you need to facilitate. Let’s listen in: Now we are getting somewhere. Do you see how powerful it can be getting stakeholders to debate these questions themselves? The diabolical goal here is to shake their confidence—gently and diplomatically. When these kinds of questions bubble up collaboratively and come directly from the mouths of your stakeholders and decision-makers, suddenly, designing screens   knowing the answers to these questions seems incredibly risky, even silly. If we create software without understanding the real-world information environment of our users, we will likely create software that does not   to the real-world information environment of our users. And this will, hands down, result in a more confusing, more complex, and less intuitive software product. The two questions But how do we get to these kinds of meaty questions diplomatically, efficiently, collaboratively, and  ?  We can do this by starting with those two big questions that align to the first two steps of the ORCA process: In practice, getting to these answers is easier said than done. I’m going to show you how these two simple questions can provide the outline for an Object Definition Workshop. During this workshop, these “seed” questions will blossom into dozens of specific questions and shine a spotlight on the need for more user research. Prep work: Noun foraging In the next section, I’ll show you how to run an Object Definition Workshop with your stakeholders (and entire cross-functional team, hopefully). But first, you need to do some prep work. Basically, look for nouns that are particular to the business or industry of your project, and do it across at least a few sources. I call this  . Here are just a few great noun foraging sources: the product’s marketing site the product’s competitors’ marketing sites (competitive analysis, anyone?) the existing product (look at labels!) user interview transcripts notes from stakeholder interviews or vision docs from stakeholders Put your detective hat on, my dear Watson. Get resourceful and leverage what you have. If all you have is a marketing website, some screenshots of the existing legacy system, and access to customer service chat logs, then use those. As you peruse these sources, watch for the nouns that are used over and over again, and start listing them (preferably on blue sticky notes if you’ll be creating an object map later!). You’ll want to focus on nouns that   represent objects in your system. If you are having trouble determining if a noun might be object-worthy, remember the acronym SIP and test for: Think of a library app, for example. Is “book” an object? Structure: can you think of a few attributes for this potential object?   Yep, it has structure. Check! Instance: what are some examples of this potential “book” object? Can you name a few?    ,  … OK, check! Purpose: why is this object important to the users and business?  … Check, check, check! As you are noun foraging, focus on capturing the nouns that have SIP. Avoid capturing   like dropdowns, checkboxes, and calendar pickers— ! Components are just the packaging for objects—they are a means to an end. No one is coming to your digital place to play with your dropdown! They are coming for the VALUABLE THINGS and what they can do with them. Those things, or objects, are what we are trying to identify. Let’s say we work for a startup disrupting the email experience. This is how I’d start my noun foraging. First I’d look at my own email client, which happens to be Gmail. I’d then look at Outlook and the new HEY email. I’d look at Yahoo, Hotmail…I’d even look at Slack and Basecamp and other so-called “email replacers.” I’d read some articles, reviews, and forum threads where people are complaining about email. While doing all this, I would look for and write down the nouns. (Before moving on, feel free to go noun foraging for this hypothetical product, too, and then scroll down to see how much our lists match up. Just don’t get lost in your own emails! Come back to me!) Drumroll, please… Here are a few nouns I came up with during my noun foraging: email message thread contact client rule/automation email address that is not a contact? contact groups attachment Google doc file / other integrated file newsletter? (HEY treats this differently) saved responses and templates Scan your list of nouns and pick out words that you are completely clueless about. In our email example, it might be   or  . Do as much homework as you can before your session with stakeholders: google what’s googleable. But other terms might be so specific to the product or domain that you need to have a conversation about them. This is really all you need to prepare for the workshop session: a list of nouns that represent potential objects and a short list of nouns that need to be defined further. Facilitate an Object Definition Workshop You could actually start your workshop with noun foraging—this activity   be done collaboratively. If you have five people in the room, pick five sources, assign one to every person, and give everyone ten minutes to find the objects within their source. When the time’s up, come together and find the overlap. Affinity mapping is your friend here! If your team is short on time and might be reluctant to do this kind of grunt work (which is usually the case) do your own noun foraging beforehand, but be prepared to show your work. I love presenting screenshots of documents and screens with all the nouns already highlighted. Bring the artifacts of your process, and start the workshop with a five-minute overview of your noun foraging journey. HOT TIP: before jumping into the workshop, frame the conversation as a requirements-gathering session to help   better understand the scope and details of the system. You don’t need to let them know that you’re looking for gaps in the team’s understanding so that you can prove the need for more user research—that will be our little secret. Instead, go into the session optimistically, as if your knowledgeable stakeholders and PMs and biz folks already have all the answers.  Then, let the question whack-a-mole commence. 1. What is this thing? Want to have some   fun? At the beginning of your session, ask stakeholders to privately write definitions for the handful of obscure nouns you might be uncertain about. Then, have everyone show their cards at the same time and see if you get different definitions (you will). This is   for exposing misalignment and starting great conversations. As your discussion unfolds, capture any agreed-upon definitions. And when uncertainty emerges, quietly (but visibly) start an “open questions” parking lot. 😉 After definitions solidify, here’s a great follow-up: 2. Do our users know what these things are? What do users call this thing?  They probably call email clients “apps.” But I’m not sure.  Automations are often called “workflows,” I think. Or, maybe users think workflows are something different. If a more user-friendly term emerges, ask the group if they can agree to use only that term moving forward. This way, the team can better align to the users’ language and mindset. OK, moving on.  If you have two or more objects that seem to overlap in purpose, ask one of these questions: 3. Are these the same thing? Or are these different? If they are not the same, how are they different?  Is a saved response the same as a template?  Yes! Definitely.  I don’t think so… A saved response is text with links and variables, but a template is more about the look and feel, like default fonts, colors, and placeholder images.  Continue to build out your growing glossary of objects. And continue to capture areas of uncertainty in your “open questions” parking lot. If you successfully determine that two similar things are, in fact, different, here’s your next follow-up question: 4. What’s the relationship between these objects?  Are saved responses and templates related in any way?   Yeah, a template can be applied to a saved response.  When is the template applied to a saved response? Does that happen when the user is constructing the saved response? Or when they apply the saved response to an email? How does that actually work? Listen. Capture uncertainty. Once the list of “open questions” grows to a critical mass, pause to start assigning questions to groups or individuals. Some questions might be for the dev team (hopefully at least one developer is in the room with you). One question might be specifically for someone who couldn’t make it to the workshop. And many questions will need to be labeled “user.”  Do you see how we are building up to our UXR sales pitch? Your next question narrows the team’s focus toward what’s most important to your users. You can simply ask, “Are saved responses in scope for our first release?,” but I’ve got a better, more devious strategy. By now, you should have a list of clearly defined objects. Ask participants to sort these objects from most to least important, either in small breakout groups or individually. Then, like you did with the definitions, have everyone reveal their sort order at once. Surprisingly—or not so surprisingly—it’s not unusual for the VP to rank something like “saved responses” as #2 while everyone else puts it at the bottom of the list. Try not to look too smug as you inevitably expose more misalignment. I did this for a startup a few years ago. We posted the three groups’ wildly different sort orders on the whiteboard. The CEO stood back, looked at it, and said, “This is why we haven’t been able to move forward in two years.” Admittedly, it’s tragic to hear that, but as a professional, it feels pretty awesome to be the one who facilitated a watershed realization. Once you have a good idea of in-scope, clearly defined things, this is when you move on to doing more relationship mapping. 6. Create a visual representation of the objects’ relationships We’ve already done a bit of this while trying to determine if two things are different, but this time, ask the team about   potential relationship. For each object, ask how it relates to all the other objects. In what ways are the objects connected? To visualize all the connections, pull out your trusty boxes-and-arrows technique. Here, we are connecting our objects with verbs. I like to keep my verbs to simple “has a” and “has many” statements. This system modeling activity brings up all sorts of new questions: Can a saved response have attachments? Can a saved response use a template? If so, if an email uses a saved response with a template, can the user override that template? Do users want to see all the emails they sent that included a particular attachment? For example, “show me all the emails I sent with   attached. I’ve changed my professional photo and I want to alert everyone to update it.”  Solid answers might emerge directly from the workshop participants. Great! Capture that new shared understanding. But when uncertainty surfaces, continue to add questions to your growing parking lot. Light the fuse You’ve positioned the explosives all along the floodgates. Now you simply have to light the fuse and BOOM. Watch the buy-in for user research flooooow. Before your workshop wraps up, have the group reflect on the list of open questions. Make plans for getting answers internally, then focus on the questions that need to be brought before users. Here’s your final step. Take those questions you’ve compiled for user research and discuss the level of risk associated with NOT answering them. Ask, “if we design without an answer to this question, if we make up our own answer and we are wrong, how bad might that turn out?”  With this methodology, we are cornering our decision-makers into advocating for user research as they themselves label questions as high-risk. Sorry, not sorry.   is your moment of truth. With everyone in the room, ask for a reasonable budget of time and money to conduct 6–8 user interviews focused   on these questions.  HOT TIP: if you are new to UX research, please note that you’ll likely need to rephrase the questions that came up during the workshop before you present them to users. Make sure your questions are open-ended and don’t lead the user into any default answers. Final words: Hold the screen design! Seriously, if at all possible, do not ever design screens again without first answering these fundamental questions: what are the objects and how do they relate? I promise you this: if you can secure a shared understanding between the business, design, and development teams   you start designing screens, you will have less heartache and save more time and money, and (it almost feels like a bonus at this point!) users will be more receptive to what you put out into the world.  I sincerely hope this helps you win time and budget to go talk to your users and gain clarity on what you are designing before you start building screens. If you find success using noun foraging and the Object Definition Workshop, there’s more where that came from in the rest of the ORCA process, which will help prevent even more late-in-the-game scope tugs-of-war and strategy pivots.  All the best of luck! Now go sell research! Like this: \n\t\t\t\t\t\t\tRecently by Sophia V. Prater\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/navigating-the-awkward/", "title": "Navigating the Awkward: A Framework for Design Conversations", "content": "We’ve all been there. A client or coworker shows us this amazing thing they (and maybe their entire team) have worked on for hours or weeks. They are so proud of it. It’s new or maybe it just looks new. They may or may not ask you what you think—but you’re there to experience it. And your brain quietly screams. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As an experienced designer, you often have an intuitive reaction and can quickly spot bad designs; they may be visually incongruent, poorly structured, confusing, lack social awareness, or look like they are trying too hard. If your initial response is so negative that it slips through into your expression or voice or body language, it can completely sabotage any possibility of buy-in. And, far more seriously, it can ruin the relationship of trust and collaboration you’re building with that person.  Reflecting on my own successes and failures—and the experiences of others—I’ve put together a conversational framework for navigating these all-too-frequent design interactions, whether you’re an in-house designer, a consultant, or an agency employee.  Be a relationship steward “Getting things done” is often accomplished at the expense of relationships and sustainable design solutions. As in, the “We need to manage this situation” approach (emphasis on the “manage”) quite often looks more immediately effective on paper than the “We need to be productive while stewarding this project for this partner” mindset.   The thing is, a design stewardship mindset to working with clients/partners is a better bet; thinking beyond buy-in or proving your point or getting your own way pays off in both an immediate situation, and long-term, for both sides. I’ve had plenty of those “design conversations gone wrong” over the years, and have noticed a common set of whys and hows behind the scenes. To help me consciously factor them in and stay focused, I’ve developed this simple conversational framework:  Move from selling to helping.  Question your triggers and explore the problem.  Map the problem to the client’s values.  Formulate questions for the client based on values.  Listen and be prepared to challenge your assumptions.  Reflect back on the problem and share recommendations with the client. We’re going to explore all that below, but here’s a   you can look at as we go. Healthy self-talk When confronted with a bad design, there are some common reactions a designer might have—what we often catch ourselves saying in our head (hopefully!) or directly to our clients. (I need to preface by saying I borrowed some of these from a viral “Hi, I’m a …you might know me from my greatest hits…” on Twitter.) You are not your users! Blindly following another organization’s best practices is not going to guarantee successful conversion for your business. Have they ever heard there’s such a thing as Calls to Action? Really, you couldn’t have bothered to tell the user ahead of time how many steps this process involves? No, a chatbot won’t magically fix your horrible content! Is this clipart?!! Don’t use your org chart for navigation…not even on your intranet. You can’t mix apples and oranges. Views do not equal engagement metrics! Stop celebrating outputs instead of outcomes! Diversity is more than just white women. You’re talking about implementation details, but I still don’t even know what problem we’re trying to solve. Not another FAQ! Does accessibility mean anything to these folks? We don’t need 15 unique designs for this button. There is a style guide for that! Good luck with your SEO efforts; keyword stuffing won’t get you ranking! Can we start designing experiences instead of pages and features? I am sure you can relate. While there’s nothing inherently wrong about these statements—and there are times when it is worth being upfront and saying them as-is—we also know they might be ineffective, or worse yet, perceived as confrontational.  Someone worked hard on this. They put a lot of thought into it. They love it. They want this to be the solution.  So, how can we avoid defensiveness? How do we engage the other person in a meaningful conversation that comes from a place of empathy instead of arrogant expertise?  In describing “ ,” Keith Yamashita points out that “each of us comes into the world curious, open, wanting to bond and wanting to have great connections with other people,” yet “our training, societal norms, school, and early jobs beat all of that out of us.” Self-awareness and inner reflection are essential to helping us reconnect with other humans.   is a great way to develop and enhance these skills. It’s not me, it’s you (Element 1) First step to getting your message across is shifting your position from “How do I share   perspective” to “How can I help my (clients/partners/coworkers) improve their current product?”  Make room for the needs of others and create some distance from your ego and. In particular, try to refrain from saying what you find so intuitive, as well as delay providing your opinion.  Blair Enns, who writes about the  , says it beautifully (emphasis is mine): You can be slick or the client can be slick. It’s better if it’s the client. You can fumble and be awkward in the conversation or the client can fumble and be awkward. It’s better you are the awkward one. You can have all the answers to the client’s questions or the client can have all the answers to your questions.   (Nobody has all the answers.) Those who are not trained in selling often think of the cliches and think they must be seen to be in control, to have the answers, to have the polish. The opposite however is better.   You don’t need to manufacture answers you do not have. It’s okay to say “let me think about that.” Allowing others to be in the spotlight may take some practice and requires you to  . When you find yourself triggered and itching to comment or to disagree with something, try the following exercise: The more you practice this kind of self-awareness, the more you’ll notice your triggers and change how you respond to them. This quick mental exercise gives you the space to make an intentional choice. For similar practical strategies, take a look at “ .” Winning the moment isn’t a win (Element 2) One potential trigger may be rooted in your mindset: are you more focused on trying to get “buy-in,” or on building positive, lasting relationships to support ongoing collaboration and stewardship? To do this, you need to first ask yourself some questions to get to the bottom of what your impulse is trying to communicate. You then need to   and identify a question that will engage your partner in a conversation. Here’s a hypothetical situation to explore what this might look like. You’re shown a very clunky, centralized system designed so users can register for recreational activities around the city. The client wants your team to create a chatbot to support it.  “Instead of pages and features, can we start designing experiences?” When we focus on pages and features like chatbot solutions, we typically aren’t seeing the whole picture. Organizations can get distracted by a shiny opportunity or single perceived problem in a product, but these can frequently overshadow where real impact can be made.  The   has a strong pull for many organizations. Organizations want solutions that take minimal perceived time and effort. Organizations want to save money/go with the cheaper option.  As a result, organizations risk prioritizing what seems to be the easy thing at the expense of other, more user-friendly and profitable solutions.  This example is simplistic, but notice that by asking a few sets of questions, we were able to move from a reactive statement to a reason why something may not be working—a reason that’s a lot less emotional and more factual. You could use a modified   like this, or some other questioning method that suits the situation.  If you dissect our example more closely, you’ll see that unlike the initial reaction, which speaks more to design elements like pages and features, we are now talking about more broadly relatable topics across business lines, such as cost savings or risk assessment. Structuring your conversation around topics most familiar to the other person and reflecting their core values can help us be more successful in improving their product. Ask with values in mind, close with opportunities (Element 3) I recently attended an excellent event on “Speaking Truth to Power,” presented by the Canada School of Public Service. The keynote speaker,  , shared his strategies for how to be an effective expert and advisor, such as: Be credible and build trust Have humility and empathy Make sure that the person you are advising understands that the advice they do not want to hear is for their benefit. He also broke down a few concepts that could be a barrier to implementing this advice. If we see ourselves as “speaking truth to power” we are likely making a values judgement. We believe and project to others that  , while the person on the other end  . It’s an arrogant position that weakens our ability to make any productive progress. Framing our interactions as a battle will likely result in a lose-lose situation.   Sarantakis then presents an example conversation that is rooted in credibility and humility, and comes from a place of care. He underscores that any advice you choose to share has to absolutely come from a place of concern for the person making a final decision, and not from a desire to show off and say so on record. It roughly looks like this: Here is what you need to know… You know X, but you may not know Y and Z. I know this is something you may not want to hear, but I need to say it because . As part of the panel discussion that followed the keynote,  , who has lots of experience advising senior leaders, reinforced Sarantakis points by stating that valuing truth, knowledge, and accuracy over relationship-building can be detrimental. Thinking back on my personal experiences, I fully agree.  So how do we build trust, credibility, and share from a place of care? Steve Bryant, Head of Content at  , has some thought-provoking words on this in his article “ ”: Translating core values into specific needs (Element 4) Going back to the exercises we just explored and what we think could be the source of the problem, it’s time to start moving backward from the core values to specific design characteristics that need to be addressed.   You have to always start the conversation as a set of questions. Beginning with questions allows you to set aside the expert hat,  , and let the client share their experiences. It shows them you care and are there to  .  Build rapport, be present, and be there to listen (Element 5) Erika Hall offers timeless advice about the need to build rapport and understand our partners in her article “ ”: And as social science shows, trying to bridge the gap with facts will never change anyone’s mind. The key is to value — truly value — and reflect the perspective of the people you want to influence. […] Attention is a gift beyond measure. A great bit of advice on “being present” rather than “presenting” on a topic is offered by Blair Enns (author of  ) in the episode “ .” Being present also means being vulnerable and open to discovering something new that might change your initial reaction.  And then be prepared to truly listen, not convince. Sarah Richards points out how important it is to   and work together to form new ones to accomplish common goals: How many times have you said you are going to talk to someone who is blocking you? Now count how many times have you said you are going to listen to someone who is blocking you? When we have someone in our organisation who disagrees with us, we go to see if we can convince someone that our way of thinking, our way of doing things, is the best way of doing it. Here is what a conversation relating to “Can we start designing experiences instead of pages and features?” might look like, if we follow this approach:  We want people to get answers to their questions as quickly as possible, so they can register and pay for local recreation activities of their choice faster. We live in a beautiful city and it’s a pity when residents and visitors can’t take advantage of everything it has to offer.     They complain that they can’t easily find activities in community centers closest to them or that there is no way for them to see all current and upcoming classes around the city at a glance, or that additional information about different activities is not provided within the system and they often have to look up events or class instructors separately to find more information on other websites. They also are not able to browse all activities by type of recreation, like “nature” activities, which might include hiking, city tours, birdwatching, garden events, and festivals. They often do not know what terminology to use to search for events and activities, so they say it is difficult to find things they already do not know about.    They say this frustrates them, as information on other websites might differ from the information in our system and they end up wasting their time guessing which one is correct and up-to-date. They then end up having to call the community center or organization providing an event for more information, to figure out if it is a good fit, before registering and paying; which significantly delays the process.  I think you see where this is going.  Here are a few more follow-up questions: Have you tried registering for an activity using the system? How did you feel/what did you experience?  What would you like people using your system to feel/experience? You’ve mentioned a number of barriers that people experience. How well do you think a chatbot will be able to remove these barriers now? What are some of the risks you foresee in trying to solve these problems? At this point, if you hear something that makes you pause and question your assumptions, ask further questions and consider going back to the drawing board. Maybe you need to ask yourself:  Respond with care and invite collaboration (Element 6) If what you’ve heard confirms your assumptions, you could offer a few concise, summative statements and a recommendation. Whatever you say needs to integrate the vocabulary used by the client (mirroring), to show them that you were listening and critically reflecting on the situation.  Let’s see how that might look: “Based on what you’ve shared, it seems that you want to make it quick and easy for anyone in the city to discover, decide on, and pay for a local recreation activity. The experience of the people using the system is very important to you, as you want them to enjoy the city they live in, as well as support the vibrancy of the city economically by registering and paying for local activities. If we want to help people enjoy and experience the city through events and activities, we need to make it simple and frictionless for them. The barriers they experience cannot be solved with a chatbot solution because the information people are looking for is often missing and not integrated into the current system in a meaningful way. So the chatbot would not give them the answers they need, creating further frustration.  Adding a chatbot also creates an extra layer of complexity. It does not solve the underlying cause of frustration stemming from lack of relevant and integrated information. Instead, it leaves the current experience broken and creates yet another place people need to go to for possible answers. It would also be a huge risk and time investment to design a chatbot, as your current content is not structured in a way that would allow us to have useful information extracted. Given your time and resource constraints, I would suggest we explore some other solutions together.”  Framing and reinforcing the conversation To recap, here are the six essential elements of the conversational framework:  Mentally move from how you can share and sell your perspective to how you can help your partner.  Ask yourself probing questions to better understand your reaction to the “bad design” trigger and what is at the core of the problem.  Map the core of the problem to value(s) you can use to begin the conversation with a partner.  Use value(s) identified to formulate and ask questions.  Get ready to truly listen to your partner and be prepared to challenge your assumptions.  Review your responses to probing questions and identify recommendations you can share back with the partner. This conversational framework starts with us as individuals, forces us to critically deconstruct our own reactions, then asks us to reframe what we find from a perspective of what matters and is known to our clients. It reminds us that we should learn something in the process by having intentional yet open conversations. Future of design leadership is stewardship The work we do in the web industry touches people—so we need to be people. We need to be human,  , and sustain relationships with our clients and partners. If we aren’t doing a good job there, can we really claim it’s not impinging on our designs and end users? Our growth as web professionals can’t be limited to technical expertise; design leadership is stewardship. It’s rooted in listen, then respond, in learning how to pause, create space, and get to the root of the problem in a productive and respectful way. We need to learn how to intercept our reactions, so that we can shift how we approach triggering situations, stay still and listen, and open up conversations rife with  . Guide clients toward better design choices by meeting them in the moment and partnering with them. In design work, being a steward does not mean that you should push to get your way. Neither does it mean you should indulge clients and create broken or unethical products. Rather, it proposes an attuned way of approaching potentially contentious conversations to arrive at a solid, ethical design. It is about framing the conversation positively and ushering it as a steward, rather than stalling discussion by being the gatekeeper.  Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/selling-design-systems/", "title": "The Never-Ending Job of Selling Design Systems", "content": "I’m willing to bet that you probably didn’t start your web career because you wanted to be a politician or a salesperson. But here’s the cold, hard truth, friend: if you want to work on design systems, you don’t have a choice. Someone has to pay for your time, and that means someone has to sell what you do to an audience that speaks value in an entirely different language.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. It’s not exactly easy to connect the benefits of a design system directly to revenue. With an ecomm site, you can add a feature and measure the impact. With other conversion-based digital experiences, if your work is good, your customers will convert more. But because a design system is (usually) an internal tool, it’s just harder to connect those dots.  This article boils down the methods I’ve put into practice convincing executives not just to fund the initial push of design system work, but to  . I’ll share how I’ve adjusted the language I use to describe common design system benefits, allowing me to more clearly communicate with decision makers. Know your audience In my experience, design systems can be owned by information technology teams, marketing and communications departments, or (best case scenario) cross-disciplinary teams that bring many specialists together. The first thing you need to do is determine where the system lives, as in which department owns and cares for it.  If it’s part of IT, for example, you need to think like a CIO or an IT Director and speak to their objectives and values. These leaders are typically more   focused; they’ll filter the value of the design system in terms of the employees of the company. In contrast, if the system belongs to Marketing, put on your CMO or Marketing Director hat. Marketing teams are often   focused; they think in terms of B2B audiences and end users.  The way organizations structure the ownership of a design system can be more complex, but let’s use these two paths (internal vs external) as frameworks for building a persuasive case for those owners. Internal-orientation motivators , there are three very specific internal motivators for having a design system: Efficiency Onboarding Scale. Efficiency benefit Design systems allow for the rapid prototyping of new ideas using existing, production-ready components. They allow teams to reuse design and code, and they allow individuals to focus their creative energy on new problems instead of wasting it on old ones. Executives and decision-makers may abstractly understand all that, but you need to be able to tell them what it will take to realize the efficiency benefit.  There’s a theoretical maximum to how productive a team can be. When you talk about a design system creating more efficiency in your processes, you’re really talking about raising the ceiling on that max. As happens with so many things in life, though, that comes with a trade-off. Early on, while a team is actually building the system, they won’t be as productive on the rest of their work. The efficiency curve looks like this: If you’re talking to an executive, it’s important to acknowledge this dip in productivity.  Spend some time working out these specific calculations for your organization. For example, you might need four team members for three months to reach a point where the system will save everyone on the team approximately two hours per week. You’re candidly acknowledging the necessary investment while demonstrating the eventual benefits. And make sure to mention that the productivity benefits will continue indefinitely! The math will almost always end up on your side.  Another critical point to raise is that simply having a design system has a cumulative effect on the efficiency of your teams. Since the system is an internal tool that can be used 1) across multiple products or experiences, 2) by many teams throughout the organization, and 3) in many phases of the product design and development process, you are gaining efficiencies on many levels.  The team working on in-store kiosks can build their interface with a well-tested set of components. Your UX people can use the system to prototype and test with production-ready code. The people responsible for grooming the backlog know there is a stable pattern library upon which they are building new features or fixing old ones. Anyone looking for answers to what, why, or how your organization designs and builds products will find those answers in the living system. The efficiency at each of these (and many other) decision points is how we can raise the ceiling on our   possible efficiency. How this plays out is very different in each organization. I’m here to tell you that part of the work is thinking about how a design system will impact   part of your process—not just design or development. If you aren’t already, start measuring how productive your team is now. The easiest way to do this is to break your team’s work down into measurable cycles. Once you have a rough idea of how much you can get done in a cycle of work, you’ll be able to compare your efficiency before the system was in place with your efficiency after. This kind of measurable benefit will speak volumes to your executive team. Onboarding benefits Growth is expensive. When you hire a new team member, you don’t just supply a salary and benefits. You need a computer, a desk, a chair, accounts to all the software/services…the list goes on. And all these expenses hit before your new employee is a fully contributing member of the team. You won’t start to recoup your investment for a few months, at least.  Design systems can reduce the time it takes your new hire to become a productive contributor. Once you have a healthy design system in place, you’re able to provide an employee with a clearly-defined and effective toolset that is well-documented and can be applied across multiple initiatives. More specifically, assigning new hires to start out working on the design system team will allow them to quickly learn how your organization designs and builds digital products. On the left in  , you have a pool of potential employees. As you hire individuals, you can bring them into the design system team, where they’ll gain a deep understanding of how your organization builds digital products. Once they’re up to speed, you can seamlessly move them to another product, discipline, or feature-based team where they’ll take this knowledge and hit the ground running. Additionally, your organization can benefit from having all team members (even those who have been around for a while) periodically work a rotation with the design system team. This continuously spreads the design system expertise around the organization and makes it part of the fabric of how you work. And don’t think this approach is only valuable for designers or developers. A healthy design system team comprises people from many disciplines. In addition to team member rotation, building in time to mentor folks from many different disciplines can prove tremendously valuable in the long run. A highly functional design system team can serve as an ideal model of workflow and can educate many team members dispersed throughout the organization about how to approach their work. Believe me, executives’ eyes will light up when you share how a design system can ensure high productivity in record time. As a caution, though, rotating people in and out of any team   often can leave them feeling exhausted and can make it hard for them to be productive. Remember, you have the flexibility to scale this to a level that makes sense for your team. Be smart and use this approach as it works in your context. As new people are added, a team typically returns to the “forming” stage of  . This is part of the reason that growth is expensive. But with a design system in place and a healthy culture, you can reduce the time it takes the team to get back to “performing.” Scale benefits Traditionally, you have to hire more people to scale productivity. A design system enables a team to accomplish more with less.   teams choose to work in a more systematic way. Small teams with an effective system can design, build, and maintain hundreds of sites each year. They’d never come close without a design system to work with.  UX Pin has a   that starts by acknowledging something that most of us ignore. Scaling design through hiring, without putting standards in place, is a myth. With every new hire, new ideas for color palettes, typography and patterns appear in the product, growing the inconsistency and increasing the maintenance cost. Every new hire increases the design entropy A well-executed system allows a team to scale while keeping design entropy at bay. Adding people to a team doesn’t necessarily mean they’ll get more work done faster. This is well-documented in historical software books like Fred Brooks’  . Eventually, you will have to investigate changing other factors (besides just adding more people) to increase productivity. A good design system can be one of these factors that increases the productivity of the team members you already have. It’s this change in productivity over scale that you need to measure and compare in order to prove value for this benefit. External-orientation motivators Let’s shift to thinking about the benefits that a design system offers to end-users. The four primary external motivators are: Consistency Trust Accessibility Usability. Consistency and Trust benefits Consistency is widely assumed to be the primary benefit of a design system. We identify dozens of button designs, color variations, and inconsistent typefaces in hopes of convincing higher-ups to allow us to build a system to bring it all in line. After working on design systems for the last five or six years, I can say with confidence that a design system will not make your product more consistent.  You see, us web designers and developers are very scrappy. We can create the most inconsistent experiences within even the most rigid systems. It’s not the system itself that creates consistency, it’s the culture of an organization. It’s all of the unspoken expectations—the filters through which we make decisions—that give us the confidence to pause and ask if the work we’re doing fits   with the product we’re building. A good CMO knows this, and they won’t buy the oversimplified idea that a design system will solve the rampant inconsistencies in our work.  Because of this, these executives often have a different (and easier to measure) question: “Does it convert?” This perspective and line of conversation is not an ideal approach. Believe me, we can create experiences that convert but are not good for our users or our brands. Given this, a conversation with your CMO might go better if you   instead. With inconsistent experiences, your   in your brand. They’ve been conditioned to expect a certain kind of user experience, and that’s what they should be given, even across multiple websites or products. Vanessa Mitchell wrote about   than it’s ever been: “Brand trust as an ‘“insurance policy”’ against future issues is not a new concept. Most organizations know trust bestowed by the consumer can not only make or break a business, it can also ensure you survive a problem in the future. But few achieve brand trust adequately, preferring to pay lip service rather than delve into what it really means: Authentically caring about customers and their needs.” When your customer is using your product to accomplish a very specific task,   Creating a consistent experience that works for everyone and allows them to accomplish their goals   building trust. CMOs need to understand how design systems empower trusted relationships so those relationships contribute to your bottom line. Customer engagement can be measured with web analytics platforms. What you’re looking for will vary depending on the context for your organization, but trends in things like time on site, visit frequency, subscription rates, and bounce rates will give you meaningful data to work with. It’s also very common to track customer engagement with metrics like   (NPS) by asking simple questions of customers repeatedly over time. There are so many ways to structure tests of the usability of your work, so I’d encourage you to loop in the UX team to help you find tests that will demonstrate the user engagement success of the design system effort. Accessibility benefits Accessibility can be a tremendous benefit of a design system. Do the work properly the first time, then allow that beautifully accessible component to serve your customers each time it is used. Certainly, it’s not a fail-safe measure—there is still integration-level testing to ensure component accessibility translates to the larger experience—but ensuring the accessibility of individual components will result in more accessible experiences. And integrating good accessibility practices into your system means more folks within your organization are aligned with this important work.  You might find at first that marketers aren’t all that interested in accessibility, but they should be. Did you know that there were 814   (just in the US!) in 2017? Did you know that there were almost 2,300 in 2018? That’s a  .  . First, because it’s the right thing to do. Second, because it’s important to the sustainability of the business. A design system can help you address this issue,   it can help you maintain compliance as you grow. This is the kind of message that resonates with leadership. Many organizations have a regular cadence of accessibility audits across their digital properties. While some of this can be automated, there’s always a manual aspect needed to truly evaluate the accessibility of a site or application. Tracking how often regressions occur in the properties served by your design system can be a great way to demonstrate the value that system is bringing to the organization. Usability benefits As with so many aspects of a design system, usability benefits come from repetition. Design system pros often hope to focus energy on solving a usability challenge   before moving on to the next problem. This absolutely is a benefit of a well-constructed system. It’s also very true that “familiarity breeds usability.” Your customers will learn to use your products and begin to subconsciously rely on that familiarity with the experience to lower their cognitive load. This should be just as important to our executive leadership as it is to those of us who are practitioners.  You can also reframe this benefit in the context of conversion. Helping our users accomplish their goals is helping them convert. They are there to use your product. So make it easy to do, and they’ll do it more. This is what businesses need and what executives want to see—improving the business by helping customers. As mentioned above, we want to make sure we’re doing this in healthy ways for both our users and our brands. Running usability studies will help to validate and measure the success of your work with the system, which many organizations are already doing. Your goal should be to validate that components are usable, which will allow you to build a culture of user-centered design. Setting the bar for what it takes to evolve the system—such as requiring that changes are tested with real users—introduces this idea into the core of all your processes, where it should be. Sell investment, not cost Knowing how and which internal and external motivators to touch on during conversations is significant, but there’s one last thing I’d like to mention, and it has to do with your way of thinking. A major factor in many of these conversations lies simply in how we frame things: move the conversation about the cost of building a design system into a conversation about the present and residual benefits of the investment you’re making. It’s easy to view the time and effort required to build a system as an investment in ultimately delivering high-quality digital products. But leadership will be more willing to consider realistic budgets and timelines if you talk about it like a long-term investment that has benefits on multiple levels throughout the business. This also leaves you with the ability to regularly remind them that this product will never be done—it will require ongoing funding and support. A design system project will not succeed if you don’t convince others that it’s the right thing to do. Successful, sustainable design systems start with the people, so you have to begin by building consensus. Building a design system means you’re asking everyone to change how they work—everyone has to be on board. This concept of collaboration is so core to the work of design systems that it led all of us here at Sparkbox to look for opportunities to better understand how teams around the world are designing, building, and using a more systematic approach to digital product design. For the last three years, we’ve been gathering and sharing data in the form of the   and the  . If you are considering a design system for your organization, or if you work with a design system team, the survey and calendar may be helpful in your quest to build better products. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-inclusive-content-models/", "title": "Designing Inclusive Content Models", "content": "In the 1920s, Robert Moses designed a system of parkways surrounding New York City. His designs, which included overpasses too low for public buses, have become an often-cited example of exclusionary design and are argued by biographer Robert A. Caro to represent a purposeful barrier between the city’s Black and Puerto Rican residents and nearby beaches.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. , it’s a particularly memorable reminder of the political power of design and the ways that choices can exclude various groups based on abilities and resources. The growing interest in   highlights questions of who can participate, and in relation to the web, this has often meant a focus on accessibility and user experience, as well as on questions related to team diversity and governance.  But principles of inclusive design should also play a role early in the design and development process, during content modeling. Modeling defines what content objects consist of and, by extension, who will be able to create them. So if web professionals are interested in inclusion, we need to go beyond asking who can access content and also think about how the design of content can install barriers that make it difficult for some people to participate in creation.  Currently, content models are primarily seen as mirrors that reflect inherent structures in the world. But if the world is biased or exclusionary, this means our content models will be too. Instead, we need to approach content modeling as an opportunity to filter out harmful structures and create systems in which more people can participate in making the web. Content models designed for inclusivity welcome a variety of voices and can ultimately increase products’ diversity and reach. Content models as mirrors Content models are tools for describing the objects that will make up a project, their attributes, and the possible relations between them. A content model for an art museum, for example, would typically describe, among other things, artists (including attributes such as name, nationality, and perhaps styles or schools), and artists could then be associated with artworks, exhibitions, etc. (The content model would also likely include objects like blog posts, but in this article we’re interested in how we model and represent objects that are “out there” in the real world, rather than content objects like articles and quizzes that live natively on websites and in apps.) The common wisdom when designing content models is to go out and research the project’s subject domain by talking with subject matter experts and project stakeholders. As Mike Atherton and Carrie Hane describe the process in  , talking with the people who know the most about a subject domain (like art in the museum example above) helps to reveal an “inherent” structure, and discovering or revealing that structure ensures that your content is complete and comprehensible. Additional research might go on to investigate how a project’s end users understand a domain, but Atherton and Hane describe this stage as mostly about terminology and level of detail. End users might use a different word than experts do or care less about the nuanced distinctions between Fauvism and neo-Expressionism, but ultimately, everybody is talking about the same thing. A good content model is just a mirror that reflects the structure you find.   Cracks in the mirrors The mirror approach works well in many cases, but there are times when the structures that subject matter experts perceive as inherent are actually the products of biased systems that quietly exclude. Like machine learning algorithms trained on   or  , existing structures tend to work for some people and harm others. Rather than recreating these structures, content modelers should consider ways to improve them.  A basic example is LinkedIn’s choice to require users to specify a company when creating a new work experience. Modeling experience in this way is obvious to HR managers, recruiters, and most people who participate in conventional career paths, but it assumes that valuable experience is only obtained through companies, and could potentially discourage people from entering other types of experiences that would allow them to represent alternative career paths and shape their own stories. These kinds of mismatches between required content attributes and people’s experiences either create explicit barriers (“I can’t participate because I don’t know how to fill in this field”) or increase the labor required to participate (“It’s not obvious what I should put here, so I’ll have to spend time thinking of a workaround”).  Setting as optional fields that might not apply to everyone is one inclusive solution, as is increasing the available options for responses requiring a selection. However, while gender-inclusive choices provide  , it’s also worth considering when business objectives would be met just as well by providing open text inputs that allow users to describe themselves in their own terms.  Instead of LinkedIn’s highly prescribed content, for example, Twitter bios’ lack of structure lets people describe themselves in more inclusive ways. Some people use the space to list formal credentials, while others provide alternate forms of identification (e.g., mother, cyclist, or coffee enthusiast) or jokes. Because the content is unstructured, there are fewer expectations about its use, taking pressure off those who don’t have formal credentials and giving more flexibility to those who do.  Browsing the Twitter bios of designers, for example, reveals a range of identification strategies, from listing credentials and affiliations to providing broad descriptions.  In addition to considering where structured content might exclude, content modelers should also consider how length guidelines can implicitly create barriers for content creators. In the following section, we look at a project in which we chose to reduce the length of contributor bios as a way to ensure that our content model didn’t leave anyone out.  Live in America Live in America is a performing arts festival scheduled to take place in October 2021 in Bentonville, Arkansas. The goal of the project is to survey the diversity of live performance from across the United States, its territories, and Mexico, and bring together groups of artists that represent distinct local traditions. Groups of performers will come from Alabama, Las Vegas, Detroit, and the border city of El Paso Juárez. Indigineous performers from Albuquerque are scheduled to put on a queer powwow. Performers from Puerto Rico will organize a cabaret.  An important part of the festival’s mission is that many of the performers involved aren’t integrated into the world of large art institutions, with their substantial fiscal resources and social connections. Indeed, the project’s purpose is to locate and showcase examples of live performance that fly under curators’ radars and that, as a result of their lack of exposure, reveal what makes different communities truly unique.  As we began to think about content modeling for the festival’s website, these goals had two immediate consequences: First, the idea of exploring the subject domain of live performance doesn’t exactly work for this project because the experts we might have approached would have told us about a version of the performing arts world that festival organizers were specifically trying to avoid. Experts’ mental models of performers, for example, might include attributes like residencies, fellowships and grants, curricula vitae and awards, artist statements and long, detailed bios. All of these attributes might be perceived as inherent or natural within one, homogenous community—but outside that community they’re not only a sign of misalignment, they represent barriers to participation. Second, the purposeful diversity of festival participants meant that locating a shared mental model wasn’t the goal. Festival organizers want to preserve the diversity of the communities involved, not bring them all together or show how they’re the same. It’s important that people in Las Vegas think about performance differently than people in Alabama and that they structure their projects and working relationships in distinct ways.  Content modeling for Live in America involved defining what a community is, what a project is, and how these are related. But one of the most interesting challenges we faced was how to model a person—what attributes would stand in for the people that would make the event possible.  It was important that we model participants in a way that preserved and highlighted diversity and also in a way that included everyone—that let everyone take part in their own way and that didn’t overburden some people or ask them to experience undue anxiety or perform extra work to make themselves fit within a model of performance that didn’t match their own.  Designing an inclusive content model for Live in America meant thinking hard about what a bio would look like. Some participants come from the institutionalized art world, where bios are long and detailed and often engage in intricate and esoteric forms of credentialing. Other participants create art but don’t have the same resources. Others are just people who were chosen to speak for and about their communities: writers, chefs, teachers, and musicians.  The point of the project is to highlight both performance that has not been recognized and the people who have not been recognized for making it. Asking for a written form that has historically been built around institutional recognition would only highlight the hierarchies that festival organizers want to leave behind. The first time we brought up the idea of limiting bios to five words, our immediate response was, “Can we get away with that?” Would some artists balk at not being allowed the space to list their awards? It’s a ridiculously simple idea, but it also gets at the heart of content modeling: what are the things and how do we describe them? What are the formats and limitations that we put on the content that would be submitted to us? What are we asking of the people who will write the content? How can we configure the rules so that everyone can participate? Five-word bios place everyone on the same ground. They ask everyone to create something new but also manageable. They’re comparable. They set well-known artists next to small-town poets, and let them play together. They let in diverse languages, but keep out the historical structures that set people apart. They’re also fun: Byron F. Aspaas of Albuquerque is “Diné. Táchii’nii nishłį́ Tódichii’nii bashishchiin.” Danny R.W. Baskin of Northwest Arkansas is “Baroque AF but eating well.” Brandi Dobney of New Orleans is “Small boobs, big dreams.” Imani Mixon of Detroit is “best dresser, dream catcher, storyteller.” Erika P. Rodríguez of Puerto Rico is “Anti-Colonialist Photographer. Caribeña. ♡ Ice Cream.” David Dorado Romo of El Paso Juárez is “Fonterizo historian wordsmith saxophonist glossolalian.” Mikayla Whitmore of Las Vegas is “hold the mayo, thank you.” Mary Zeno of Alabama is “a down home folk poet.” Modeling for inclusion We tend to think of inclusive design in terms of removing barriers to access, but content modeling also has an important role to play in ensuring that the web is a place where there are fewer barriers to creating content, especially for people with diverse and underrepresented backgrounds. This might involve rethinking the use of structured content or asking how length guidelines might create burdens for some people. But regardless of the tactics, designing inclusive content models begins by acknowledging the political work that these models perform and asking whom they include or exclude from participation.  All modeling is, after all, the creation of a world. Modelers establish what things exist and how they relate to each other. They make some things impossible and others so difficult that they might as well be. They let some people in and keep others out. Like overpasses that prevent public buses from reaching the beach, exclusionary models can quietly shape the landscape of the web, exacerbating the existing lack of diversity and making it harder for those who are already underrepresented to gain entry. As discussions of inclusive design continue to gain momentum, content modeling should play a role precisely because of the world-building that is core to the process. If we’re building worlds, we should build worlds that let in as many people as possible. To do this, our discussions of content modeling need to include an expanded range of metaphors that go beyond just mirroring what we find in the world. We should also, when needed, filter out structures that are harmful or exclusionary. We should create spaces that ask the same of everyone and that use the generativity of everyone’s responses to create web products that emerge out of more diverse voices. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-future-of-web-software-is-html-over-websockets/", "title": "The Future of Web Software Is HTML-over-WebSockets", "content": "The future of web-based software architectures is already taking form, and this time it’s server-rendered (again). Papa’s got a brand new bag: HTML-over-WebSockets and broadcast everything all the time. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The dual approach of marrying a Single Page App with an API service has left many dev teams mired in endless JSON wrangling and state discrepancy bugs across two layers. This costs dev time, slows release cycles, and saps the bandwidth for innovation. But a new WebSockets-driven approach is catching web developers’ attention. One that reaffirms the promises of classic server-rendered frameworks: fast prototyping, server-side state management, solid rendering performance, rapid feature development, and straightforward SEO. One that enables multi-user collaboration and reactive, responsive designs  . The end result is a single-repo application that feels to users just as responsive as a client-side all-JavaScript affair, but with straightforward templating and far fewer loading spinners, and no state misalignments, since state only lives in one place. All of this sets us up for a considerably easier (and faster!) development path.  Reclaiming all of that time spent addressing architecture difficulties grants you a pool of surplus hours that you can use to do awesome. Spend your dev budget, and your company’s salary budget, happily building full-stack features yourself, and innovating on things that benefit your company and customers.  And in my opinion, there’s no better app framework for reclaiming tedious development time than Ruby on Rails. Take another look at the underappreciated Stimulus. Beef up the View in your MVC with ViewComponents. Add in the   and   libraries for that Reactive Rails (as it has been dubbed) new car smell, and you’re off to the races. But we’ll get back to Rails in a bit… This all started with web frameworks… Web frameworks burst onto the scene around 2005 amidst a sea of mostly figure-it-out-for-yourself scripting language libraries glued together and thrown onto hand-maintained Apache servers. This new architecture promised developers a more holistic approach that wrapped up all the fiddly stuff in no-touch conventions, freeing developers to focus on programming ergonomics, code readability, and fast-to-market features. All a developer had to do was learn the framework’s core language, get up to speed on the framework itself and its conventions, and then start churning out sophisticated web apps while their friends were still writing XML configuration files for all those   approaches. Despite the early criticisms that always plague new approaches, these server-rendered frameworks became tools of choice, especially for fast-moving startups—strapped for resources—that needed an attractive, feature-rich app up  . But then the   notion took hold… As the web development world pushed deeper into the 2010s, the tides began to turn, and server-rendered frameworks took something of a backseat to the Single Page Application, wholly built in JavaScript and run entirely on the client’s computer. At many companies, the “server” became relegated to hosting an API data service only, with most of the business logic and all of the HTML rendering happening on the client, courtesy of the big ’ol package of JavaScript that visitors were forced to download when they first hit the site.  This is where things started to get ugly. Fast-forward to 2020 and the  , as we were promised it would with SPAs. Shoving megabytes of JavaScript down an iPhone 4’s throat doesn’t make for a great user experience. And if you thought building a professional web app took serious resources, what about building a web app   an API service   a communication layer between them? Do we really believe that every one of our users is going to have a device capable of digesting 100 kB of JSON and rendering a complicated HTML table   than a server-side app could on even a mid-grade server? Developing and hosting these JavaScript-forward apps didn’t get any cheaper either. In many cases we’re now doing twice the work, and maybe even paying twice the developers, to achieve the same results we had before with server-side app development. In 2005, app frameworks blew everyone’s minds with “build a blog app in 15 minutes” videos. Fifteen years  , doing the same thing with an SPA approach can require two codebases, a JSON serialization layer, and dozens of spinners all over the place so we can still claim a 50ms First Contentful Paint. Meanwhile, the user watches some blank gray boxes, hoping for HTML to finally render from all the JSON their browser is requesting and digesting.  How did we get here? This is not my beautiful house! Were we smart in giving up all of that server-rendered   and doubling down on staff and the time to implement in order to chase the promise of providing our users some fancier user interfaces? Well. Yes. Sort of. We’re not building web software for  . We’re building it for  . The users of our software have expectations of how it’s going to work for  . We have to meet them where they are. Our users are no longer excited about full-page refreshes and ugly Rube Goldberg-ian multi-form workflows. The SPA approach was the next logical leap from piles of unorganized spaghetti JavaScript living on the server. The problem, though: it was a 5% improvement, not a 500% improvement.  Is 5% better worth twice the work? What about the developer cost? Bedazzling the web app certainly makes things   from the user’s perspective. Done well, it can make the app feel slicker and more interactive, and it opens up a wealth of new non-native interaction elements. Canonizing those elements as   was the next natural evolution. Gone are the days of thinking through how an entire HTML document could be mutated to give the   of the user interacting with an atomic widget on the page—now, that can be implemented directly, and we can think about our UX in terms of component breakdowns. But, alas, the costs begin to bite us almost immediately. Go ahead, write that slick little rating stars component. Add some cool animations, make the mouseover and click area feel good, give some endorphin-generating feedback when a selection is made. But now what? In a real app, we need to   that change, right? The database has to be changed to reflect this new state, and the app in front of the user’s eyes needs to reflect that new reality too.  In the old days, we’d give the user a couple star GIFs, each a link that hit the same server endpoint with a different param value. Server-side, we’d save that change to the database, then send back a whole new HTML page for their browser to re-render; maybe we’d even get fancy and use AJAX to do it  , obviating the need for the full HTML and render. Let’s say the former costs   in developer time and salary (and we won’t even talk about lost opportunity cost for features rolled out too late for the market). In that case, the fancy AJAX-based approach costs   +  , but the cost of lots and lots of   grows as our app becomes more and more of a JavaScript spaghetti sprinkles mess. Over in the SPA world, we’re now writing JavaScript in the client-side app and using JSX or Handlebars templates to render the component, then code to persist that change to the front-end data store, then a PUT request to the API, where we’re also writing an API endpoint to handle the request, a JSON serializer (probably with its own pseudo-template) to package up our successful response, and then front-end code to ensure we re-render the component (and some branching logic to maybe rollback and re-render the client-side state change if the backend failed on us). This costs a lot more than even  in developer time and salary. And if you’ve split your team into “front-end” and “back-end” people, you might as well go ahead and double   cost (both time and money) for many non-trivial components where you need two different people to finish the implementation. Sure, the SPA mitigates some of the ever-growing spaghetti problem, but at what cost for a business racing to be relevant in the market or get something important out to the people who need it? One of the other arguments we hear in support of the SPA is the reduction in cost of cyber infrastructure. As if pushing that hosting burden onto the client (without their consent, for the most part, but that’s another topic) is somehow saving us on our cloud bills. But that’s ridiculous. For any non-trivial application, you’re still paying for a server to host the API and maybe another for the database, not to mention load balancers, DNS, etc. And here’s the thing:   Seriously, think about it. I’ve yet to work at any business where our technical infrastructure was anything more than a fraction of our salary overhead. And good developers expect raises. Cloud servers generally just get   over time. If you want to be efficient with your money—especially as a cash-strapped startup—you don’t need to cheap out on cloud servers; you need to get  . In the old, old days, before the web frameworks, you’d pay a developer for six weeks to finally unveil…the log-in page. Cue the sad trombone. Then frameworks made that log-in page an hour of work, total, and people were launching web startups overnight. The trumpets sound! Now, with our SPA approach, we’re back to a bunch of extra work.  . There’s that trombone again… We’re paying a lot of money for that 5% user experience improvement. But what if we could take the best client-side JavaScript ideas and libraries from that 5% improvement and reconnect them with the developer ergonomics and salary savings of a single codebase? What if components and organized JavaScript could all live in one rock-solid app framework optimized for server-side rendering? What if there   a path to a 500% jump? Sound impossible? It’s not. I’ve seen it, like C-beams glittering in the dark near the Tannhäuser Gate. I’ve built that 500% app, in my free time, with my kids running around behind me barking like dogs. Push broadcasts to logged-in users. Instant updates to the client-side DOM in milliseconds. JavaScript-driven 3D animations that interact with real-time chat windows. All in a single codebase, running on the same server hardware I’d use for a “classic” server-rendered app (and maybe I can even scale that hardware down since I’m rendering HTML fragments more often than full-page documents). No separate front-end app. Clean, componentized JavaScript and server-side code, married like peanut butter and jelly. It’s real, I tell you! Socket to me! (Get it? Get it? Ah, nevermind…) Finalized in 2011, support for WebSockets in modern browsers ramped up throughout the 2010s and is now fully supported in all modern browsers. With the help of a small bit of client-side JavaScript, you get a   socket connection between browser and server. Data can pass both ways, and can be pushed from either side at any time, no user-initiated request needed. Like the game industry’s ever-expanding moves into cloud-based gaming, the future of web apps is not going to be about pushing even heavier obligations onto the user/client, but rather the opposite: let the client act as a thin terminal that renders the state of things for the human. WebSockets provide the communication layer, seamless and fast; a direct shot from the server to the human. But this wasn’t terribly easy for many developers to grok at first. I sure didn’t. And the benefits weren’t exactly clear either. After years (decades, even) of wrapping our heads around the HTTP request cycle, to which all server-handled features must conform, adopting this WebSocket tech layer required a lot of head scratching. As with many clever new technologies or protocols, we needed a higher-level abstraction that provided something really effective for getting a new feature in front of a user, fast. Enter HTML-over-WebSockets… Want a hyper-responsive datalist typeahead that is perfectly synced with the database? On every keystroke, send a query down the WebSocket and get back   the changed set of   tags, nothing more, nothing less. How about client-side validations? Easy. On every input change, round up the form values and send ’em down the WebSocket. Let your server framework validate and send back changes to the HTML of the form, including any errors that need to be rendered. No need for JSON or complicated error objects. User presence indicators? Dead simple. Just check who has an active socket connection. What about multi-user chat? Or document collaboration? In classic frameworks and SPAs, these are the features we put off because of their difficulty and the code acrobatics needed to keep everyone’s states aligned. With HTML-over-the-wire, we’re just pushing tiny bits of HTML based on one user’s changes to     currently subscribed to the channel. They’ll see   the same thing as if they hit refresh and asked the server for the entire HTML page anew. And you can get those bits to every user in under 30ms. We’re not throwing away the promise of components either. Where this WebSockets-based approach can be seen as a thick server/thin client, so too can our components. It’s fractal, baby! Make that component   delightful things for the user with smart JavaScript, and then just ask the server for updated HTML, and mutate the DOM. No need for a client-side data store to manage the component’s state since it’ll render itself to look  . The HTML comes from the server, so no need for JSX or Handlebars or <insert other JavaScript templating library here>. The server is always in control: rendering the initial component’s appearance   updating it in response to any state change, all through the socket.  And there’s nothing saying you have to use those socket channels to send   HTML. Send a tiny bit of text, and have the client do something smart. Send a chat message from one user to every other user, and have their individual clients render that message in whatever app theme they’re currently using. Imagine the possibilities! But it’s complex/expensive/requires a bunch of new infrastructure, right? Nope. Prominent open-source web servers support it natively, generally without needing any kind of extra configuration or setup. Many server-side frameworks will automatically ship the JS code to the client for native support in communicating over the socket. In Rails, for example, setting up your app to use WebSockets is as easy as configuring the built-in ActionCable and then deploying as usual on the same hardware you would have used otherwise. Anecdotally, the typical single Rails server process seems to be perfectly happy supporting nearly 4,000 active connections. And you can easily swap in the excellent   to bump that up to around 10,000+ connections per node by not relying on the built-in Ruby WebSocket server. Again, this is on the usual hardware you’d be running your web server on in the first place. You don’t need to set up any extra hardware or increase your cloud infrastructure. This new approach is quickly appearing as extensions, libraries, or alternative configurations in a variety of languages and web frameworks, from Django’s   to Phoenix’s   and beyond. Seriously, go dig around for WebSockets-based libraries for your favorite app framework and then step into a new way of thinking about your app architectures. Build something amazing and marvel at the glorious HTML bits zipping along on the socket, like jet fighters passing in the night. It’s more than a new technical approach; it’s a new mindset, and maybe even a new wellspring of key app features that will drive your startup success. But I’d be remiss if I didn’t highlight for the reader  contender for Best Framework in a Leading Role. Sure, any app framework can adopt this approach, but for my money, there’s a strong case to be made that the vanguard could be Ruby on Rails.  So we come back around to Rails, 15 years on from its launch… Set up a Rails 6 app with the latest versions of  ,  ,  ,  , and GitHub’s   gem, and you can be working with Reactive Rails in a way that simultaneously feels like building a classic Rails app  like building a modern, componentized SPA, in a single codebase, with all the benefits of server-side rendering, HTML fragment caching, easy SEO, rock-solid security, and the like. You’ll suddenly find your toolbelt bursting with straightforward tools to solve previously daunting challenges. Oh, and with Turbolinks, you also get wrappers allowing for hybrid native/HTML UIs in the same codebase. Use a quick deploy solution like Heroku or Hatchbox, and one developer can build a responsive, reactive, multi-platform app in their spare time. Just see   if you don’t believe me.  OK, that all sounds exciting, but why Rails specifically? Isn’t it old and boring? You already said any framework can benefit from this new WebSocket, DOM-morphing approach, right?  Sure. But where Rails has always shined is in its ability to make rapid prototyping, well… , and in its deep ecosystem of well-polished gems. Rails also hasn’t stopped pushing the envelope forward, with the latest version 6.1.3 of the framework boasting a ton of cool features.  If you’ve got a small, resource-strapped team, Rails (and Ruby outside of the framework) still serves as a potent force multiplier that lets you punch way above your weight, which probably explains the  . With this new approach, there’s a   more weight behind that punch. While your competitors are fiddling with their JSON serializers and struggling to optimize away all the loading spinners, you’re rolling out a new multi-user collaborative feature every week…or every  .  You win. Your fellow developers win. Your business wins. And, most importantly, your   win. That’s what Rails promised from the day it was released to the community. That’s why Rails spawned so many imitators in other languages, and why it saw such explosive growth in the startup world for years. And that same old rapid prototyping spirit, married to this new HTML-over-the-wire approach, positions Rails for a powerful resurgence.  Ruby luminary and   of  , Obie Fernandez,  . Heck, even  . And the good folks over at Basecamp (creators of Rails in the first place), dropped their own take on the concept,  , just in time for the 2020 holidays, so your options for tackling this new and exciting technique continue to expand. Don’t call it a comeback, because Rails has been here for years. With this new architectural approach, brimming with HTML-over-WebSockets and full-duplex JavaScript interactions, Rails becomes something new, something beautiful, something that demands attention (again).  Reactive Rails, with StimulusReflex and friends, is a must-look for anyone exhausted from toiling with JSON endpoints or JSX, and I’m super excited to see the new crop of apps that it enables. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/dysfunctional-teams-back-on-track/", "title": "How to Get a Dysfunctional Team Back on Track", "content": "Maybe you’ve been part of a team that you’ve seen slowly slide into a rut. You didn’t notice it happen, but you’re now not shipping anything, no one’s talking to each other, and the management’s Eye of Sauron has cast its gaze upon you. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Maybe you’ve just joined a team that’s in the doldrums. Maybe the people who used to oil the wheels that kept everyone together have moved on and you’re having to face facts—you all hate each other. However you’ve ended up in this situation, the fact is that you’re now here and it’s up to someone to do something about it. And that person might be you. The first thing to understand is that you’re not the only person to ever encounter problems. Things like this happen all the time at work, but there are simple steps you can take and habits you can form to ease the situation and even dig yourself (and your team) out of the hole. I’ll share some techniques that have helped me, and maybe they can work for you, too. So let me tell you a story about a hot mess I found myself in and how we turned it around. Names and details have been changed to protect the innocent. An engineer called Jen was working with me on a new feature on our product that lets people create new meal recipes themselves. I was the Project Manager. We were working in six-week cycles. She had to rely on an API that was managed by Tom (who was in another team) to allow her to get and set the new recipe information on a central database. Before we kicked off, everyone knew the overall objective and everyone was all smiles and ready to go. The system architecture was a legacy mishmash of different parts of local databases and API endpoints. And, no prizes for guessing what’s coming next, the API documentation was like Swiss cheese. Two weeks into a six-week cycle, Jen hit Tom up with a list of her dream API calls that she wanted to use to build her feature. She asked him to confirm or deny they would work—or even if they existed at all—because once she started digging into the docs, it wasn’t clear to her if the API could support her plans. However, Tom had form for sticking his head in the sand and not responding to requests he didn’t like. Tom went to ground and didn’t respond. Tom’s manager, Frankie, was stretched too thin, and hence wasn’t paying attention to this until I was persistently asking about it, in increasingly fraught tones. In the meantime, Jen tried to do as much as she could. Every day she built a bit more based on her as-yet unapproved design, hoping it would all work out. With two weeks left to go, Tom eventually responded with a short answer—which boiled down to “The API doesn’t support these calls and I don’t see why I should build something that does. Why don’t you get the data from the other part of the system? And by the way, if I’m forced to do this, it will take at least six weeks.” And as we know, six weeks into two weeks doesn’t go. Problem. How did we sort it? When things go south, what do you do? Accept it. Acknowledge whatever has happened to get you into this predicament. Take some notes about it to use in team appraisals and retrospectives. Take a long hard look at yourself, too. Write a concise, impersonal summary of where you are. Try not to write it from your point of view. Imagine that you’re in your boss’ seat and just give them the facts as they are. Don’t dress things up to make them sound better. Don’t over-exaggerate the bad. Leave the emotions to the side. When you can see your situation clearly, you’ll make better decisions. Now, pointing out the importance of taking some time to cool down and gather your thoughts seems obvious, but it’s based on the study of some of the most basic circuitry in our brains. Daniel Goleman’s 1995 book,  , introduces the concept of  ; the idea that the part of our brain that deals with emotion—the limbic system—can biologically interrupt rational thinking when it is overstimulated. For instance, experiments show that   at the casino. And another study found that people in a negative emotional state are  . To put it another way, if you’re pissed off, you can’t think straight. So when you are facing up to the facts, avoid the temptation to keep it off-the-record and only discuss it on the telephone or in person with your colleagues. There’s nothing to be scared of by writing it down. If it turns out that you’re wrong about something, you can always admit it and update your notes. If you don’t write it down, then there’s always scope for misunderstanding or misremembering in future. In our case, we summarized how we’d ended up at that juncture; the salient points were: I hadn’t checked to ensure we had scoped it properly before committing to the work. It wasn’t a surprise that the API coverage was patchy, but I turned a blind eye because we were excited about the new feature. Jen should have looked for the hard problem first rather than do a couple of weeks’ worth of nice, easy work around the edges. That’s why we lost two weeks off the top. Tom and Frankie’s communication was poor. The reasons for that don’t form part of this discussion, but something wasn’t right in that team. And that’s step one. Few people like to make mistakes, but everyone   make one at some point in their life. Big ones, small ones, important ones, silly ones—we all do it. Don’t beat yourself up. At the start of my career, I worked on a team whose manager had a very high opinion of himself. He was good, but what I learned from him was that he spread that confidence around the team. If something was looking shaky, he insisted that if we could “smell smoke,” that he had to be the first to know so he could do something about it. If we made a mistake, there was no hiding from it. We learned how to face up to it and accept responsibility, but what was more important was learning from him the feeling we were the best people to fix it. There was no holding of grudges. What was done, was done. It was all about putting it behind us. He would tell us that we were only in this team because he had handpicked us because we were the best and he only wanted the best around him. Now, that might all have been manipulative nonsense, but it worked. The only thing you can control is what you do now, so try not to fret about what happened in the past or get anxious about what might happen in the future. With that in mind, once you’ve written the summary of your sticky situation, set it aside! I’ll let you in on a secret. No one else is interested in how you got here. They might be asking you about it (probably because they are scared that someone will ask them), but they’re always going to be more interested in how you’re going to sort the problem out. So don’t waste time pointing fingers. Don’t prepare slide decks to throw someone under the bus. Tag that advice with a more general “don’t be an asshole” rule. If you’re getting consistent heat about the past, it’s because you’re not doing a good enough job filling the bandwidth with a solid, robust, and realistic plan for getting out of the mess. So focus on the future. Sometimes it’s not easy to do that, but remember that none of this is permanent. Trust in the fact that if you pull it together, you’ll be in a much more powerful position to decide what to do next. Maybe the team will hold together with a new culture or, if it is irretrievably broken, once you’re out of the hole then you can do something about it and switch teams or even switch jobs. But be the person who sorted it out, or at the very least, be part of the gang who sorted it out. That will be obvious to outsiders and makes for a much better interview question response. In our story with Jen, we had a short ten-minute call with everyone involved on the line. We read out the summary and asked if anyone had anything to add. Tom spoke up and said that he never gets time to update the API documentation because he always has to work on emergencies. We added that to our summary: Tom has an ongoing time management problem. He doesn’t have enough time allocated to maintain and improve the API documentation. After that was added, everyone agreed that the summary was accurate. I explained that the worst thing that could now happen was that we had to report back to the wider business that we’d messed up and couldn’t hit our deadline. If we did that, we’d lose face. There would be real financial consequences. It would show up on our appraisals. It wouldn’t be good. It wouldn’t be the end of the world, but it wasn’t something that we wanted. Everyone probably knew all that already, but there’s a power in saying it out loud. Suddenly, it doesn’t seem so scary. Jen spoke up to say that she was new here and really didn’t want to start out like this. There was some murmuring in general support. I wrapped up that part of the discussion. I purposefully didn’t enter into a discussion about the solution yet. We had all come together to admit the circumstances we were in. We’d done that. It was enough for now. Stepping back for a second, as the person who is going to lead the team out of the wilderness, you may want to start getting in everyone’s face. You’ll be tempted to rely on your unlimited reserves of personal charm or enthusiasm to vibe everyone up. Resist the urge! Don’t do it! Your job is to give people the space to let them do their best work. I learned this the hard way. I’m lucky enough that I can bounce back quickly, but when someone is under pressure, funnily enough, a super-positive person who wants to throw the curtains open and talk about what a wonderful day it is might not be the most motivational person to be around. I’ve unwittingly walked into some short-tempered conversations that way. Don’t micromanage. In fact, scrap all of your management tricks. Your job is to listen to what people are telling you—even if they’re telling you things by not talking. Reframe the current problem. Break it up into manageable chunks. The first task to add to your list of things to do is simply to “Decide what we’re going to do about [the thing].” It’s likely that there’s a nasty old JIRA ticket that everyone has been avoiding or has been bounced back and forth between different team members. Set that aside. There’s too much emotional content invested in that ticket now. Create a new task that’s entirely centered on making a decision. Now, break it down into subtasks for each member of the team, like “Submit a proposal for what to do next.” Put your own suggestions in the mix but do your best to dissociate yourself from them. Once you start getting some suggestions back and can tick those tasks off the list, you start to generate positive momentum. Nurture that. If a plan emerges, champion it. Be wary of naysayers. Challenge them respectfully with “How do you think we should…?” questions. If they have a better idea, champion that instead; if they don’t respond at all, then gently suggest “Maybe we should go with this if no one else has a better idea.” Avoid words like “need,” “just,” “one,” or “small.” Basically, anything that imposes a view of other people’s work. It seems trivial, but try to see it from the other side. Saying, “I just need you to change that one small thing” hits the morale-killing jackpot. It unthinkingly diminishes someone else’s efforts. An engineer or a designer could reasonably react by thinking “What do you know about how to do this?!” Your job is to help everyone drop their guard and feel safe enough to contribute. Instead, try “We’re all looking at you here because you’re good at this and this is a nasty problem. Maybe you know a way to make this part work?” More often than not,  . So I asked Jen, Tom, and Frankie to submit their proposals for a way through the mess. It wasn’t straightforward. Just because we’d all agreed how we got here didn’t just magically make all the problems disappear. Tom was still digging his heels in about not wanting to write more code, and kept pushing back on Jen. There was a certain amount of back and forth. Although, with some constant reminders that we should maybe focus on what will move us forward, we eventually settled on a plan. Like most compromises, it wasn’t pretty or simple. Jen was going to have to rely on using the local database for a certain amount of the lower-priority features. Tom was going to have to create some additional API functions and would end up with some unnecessary traffic that might create too much load on the API. And even with the compromise, Tom wouldn’t be finished in time. He’d need another couple of weeks. But it was a plan! Once you’ve got a plan, commit to it and tell everyone affected what’s going on. When communicating with people who are depending on you, take the last line of your email, which usually contains the summary or the “ask,” and put it at the top. When your recipient reads the message, the opener is the meat. Good news or bad news, that’s what they’re interested in. They’ll read on if they want more. If it’s bad news, set someone up for it with a simple “I’m sorry to say I’ve got bad news” before you break it to them. No matter who they are, kindly  . When discussing it with the team, put the plan somewhere everyone can see it. Transparency is key. Don’t pull any moves—like publishing deadline dates to the team that are two weeks earlier than the date you’ve told the business. Teams aren’t stupid. They’ll know that’s what you do. Publish the new deadlines in a place where everyone on the team can see them, and say we’re aiming for this date but we’re telling the business that we’ll definitely be done by that date. In our case, I posted an update to the rest of the business as part of our normal weekly reporting cycle to announce we’d hit a bump that was going to affect our end date. Here’s an extract: And so on… That post was available for everyone within the team to see. Everyone knew what was to be done and what the target was. I had to field some questions from above, but I was ready with my summary of what went wrong and what we’d all agreed to do as a course of action. All I had to do was refer to it. Then I could focus on sharing the plan. Now, I’d like to say that we then had tea and scones every day for the next month and it was all rather spiffing. But that would be a lie. There was some more wailing and gnashing of teeth, but we all got through it and—even though we tried to finish early but failed—we did manage to finish by the November 22 date. And then, after a bit of a tidy up, we all moved on to the next project, a bit older and a bit wiser. I hope that helps you if you’re in a similar scenario.   or email me at   with any questions or comments. I’d love to hear about your techniques and advice. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/keeping-a-fresh-design-mind/", "title": "Keeping Your Design Mind New and Fresh", "content": "Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Since March 2020, most of us have been working from home, and the days blend into each other and look the same. This is not the first time I have experienced this type of feeling.  My commute — New York to New Jersey — is what folks in my area call the reverse commute.While going to the office, my days began to look the same: riding the subway to a bus to a shuttle to get to my job. Have you ever arrived at a destination and not even realized how you got there? This is how I began to experience the world everyday. I stopped paying attention to my surroundings. Because I worked a lot, the only time I would take off was for the holidays. During this time, I was a consultant and was coming to the end of an existing contract. For six years straight, I did this, until I decided to take six weeks off work to travel to Europe and visit places I had not seen before. A family friend let me stay with her in Munich, Germany; I did not speak German, and so began my adventure. I was in a new place, where I did not know anyone, and I got lost every single day. My eyes were opened to the fact that every day is an opportunity. It just took me going on a trip and traveling halfway around the world to realize it. There are new things to experience each and every day. When I returned to the U.S. and went back to work, I made a conscious decision to make each day different. Sometimes I would walk a new route. Some days I would take another train. Each change meant I saw something new: new clothing, new buildings, and new faces. It really impacted the way I viewed myself in the world. But what do you do when you cannot travel? Seeing a situation with new eyes takes practice, and you can still create the opportunity to see something by not taking your surroundings for granted. How do we do this? For me, I adopted a new philosophy of being WOQE: watching, observing, questioning, and exploring. Watching Let go of assumptions to open up your mind. This takes looking at yourself and understanding your beliefs. When I am looking to design something, I always have to tell myself that I am not the user. I don’t know where they come from, and I don’t know their reason for making the decisions they do. I begin the work to understand where they are coming from. It all starts with why. Observing View the situation from different angles. Architects think about the details of a building and look at different viewpoints and perspectives (i.e., outside the building, different sides of the building, etc.) How can you apply this approach to your designs? Here’s an example. I sketched something once as part of an augmented reality experience. Using my mobile device, I was able to walk around the sketch and see it from all sides, including the top and bottom. As a UX Designer, I have had to view items from both a user’s perspective and the business’ perspective. If I am giving a talk at a conference, I look at the talk from an audience perspective and my own. Questioning Use the “5 Why Technique” to get to the root of the problem. This involves asking “why” 5 times. You know how kids keep asking “why” when you answer a question from them? This approach is how you can get to the root of problems. For example, a friend of mine who is blind expressed interest in playing a popular augmented reality game. This intrigued me and I used a whiteboard as I worked through the 5 Whys with my friend. Here is the process we took: This may not be a scientific way of approaching a problem, but it is a starting point. My friend could not play this augmented reality game because designers were not taught to make this game for someone who is blind. After this exercise, I was able to work with a group of students who worked with my friend to create an augmented reality concept and ultimately a game using audio and haptic feedback. It all started with why. Exploring Collaborate with others to learn from others and teach others what you know. Let your friends and colleagues know what you are working on, and perhaps talk it through with them. When I was a freelance designer, I worked on my own and found it challenging when I would get stuck on a design. I searched online and found a group of designers who would come and share their work with each other for feedback. Through this group, I was able to get some insightful comments on my designs and explain some of my decisions. I began to collaborate with the folks in the group and found it very helpful. When talking to clients, this made me feel more confident explaining my designs because I had already been through the process with my online group. With all of our days blending into each other in this pandemic, we as designers have an unprecedented opportunity to really shake things up. Furthermore, we are problem solvers. As you move forward with your design practice, consider being WOQE to design with a fresh mind. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/now-thats-what-i-call-service-worker/", "title": "Now THAT’S What I Call Service Worker!", "content": "The   API is the   of the web platform. It offers incredibly broad utility while also yielding resiliency and better performance. If you’ve not used Service Worker yet—and you couldn’t be blamed if so, as  —it goes something like this: Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What you decide to do with requests you intercept is a) your call and b) depends on your website. You can  ,   during install,  , and—as will be our eventual focus—  for repeat visitors. Getting out of the woods Weekly Timber is a client of mine that provides logging services in central Wisconsin. For them, a fast website is vital. Their business is located in  , and like many rural stretches in the United States,  . Wisconsin has farmland for  , but it also has plenty of forests. When you need a company that cuts logs, Google is probably your first stop. How fast a given logging company’s website is might be enough to get you looking elsewhere if you’re left waiting too long on a crappy network connection. I initially didn’t believe a Service Worker was necessary for Weekly Timber’s website. After all, if things were plenty fast to start with, why complicate things? On the other hand, knowing that my client services not just Waushara County, but much of central Wisconsin, even a barebones Service Worker could be the kind of progressive enhancement that adds resilience in the places it might be needed most. The first Service Worker I wrote for my client’s website—which I’ll refer to henceforth as the “standard” Service Worker—used three  : These are neither new nor special strategies, but they provide two benefits: Offline capability, which is handy when network conditions are spotty. A performance boost for loading static assets. That performance boost translated to a 42% and 48% decrease in the median time to   and  , respectively. Better yet, these insights are based on  . That means these gains aren’t just theoretical, but a real improvement for real people. This performance boost is from bypassing the network entirely for static assets already in  —particularly render-blocking stylesheets. A similar benefit is realized when we rely on the HTTP cache, only the FCP and LCP improvements I just described are in comparison to pages with a primed HTTP cache without an installed Service Worker. If you’re wondering why  , it’s because the HTTP cache—at least in  —may still involve a trip to the server to verify asset freshness.  , but   yet. A long max-age value works, too, but the combination of Service Worker API and   gives you a lot more flexibility. Details aside, the takeaway is that the simplest and most well-established Service Worker caching practices can improve performance. Potentially more than what well-configured   headers can provide. Even so, Service Worker is an incredible technology with far more possibilities. It’s possible to go farther, and I’ll show you how. A better, faster Service Worker The web   itself some “innovation,” which is a word we equally love to throw around. To me, true innovation isn’t when we create new frameworks or patterns solely for the benefit of developers, but whether those inventions benefit people who end up using whatever it is we slap up on the web.   is a thing we ought to respect. Users above all else, always. The Service Worker API’s innovation space is considerable. How you work within that space can have a big effect on how the web is experienced. Things like   and   have taken Service Worker from great to killer. We can do the following with these new capabilities, respectively: Reduce Service Worker latency by parallelizing Service Worker startup time and  . Stream content in from   and the network. Moreover, we’re going to combine these capabilities and pull out one more trick: precache header and footer partials, then combine them with content partials from the network. This not only reduces how much data we download from the network, but it also improves perceptual performance for repeat visits. That’s innovation that helps everyone. Grizzled, I turn to you and say  Laying the groundwork If the idea of combining precached header and footer partials with network content on the fly seems like a Single Page Application (SPA), you’re not far off. Like an SPA, you’ll need to apply the “app shell” model to your website. Only instead of a client-side router plowing content into one piece of minimal markup, you have to think of your website as three separate parts: The header. The content. The footer. For my client’s website, that looks like this: The thing to remember here is that the individual partials don’t have to be valid markup in the sense that all tags need to be closed within each partial. The only thing that counts in the final sense is that the combination of these partials must be valid markup. To start, you’ll need to precache separate header and footer partials when the Service Worker is installed. For my client’s website, these partials are served from the   and   pathnames: Every page must be fetchable as a content partial minus the header and footer, as well as a full page with the header and footer. This is key because the initial visit to a page won’t be controlled by a Service Worker. Once the Service Worker takes over, then you serve content partials and assemble them into complete responses with the header and footer partials from  . If your site is static, this means generating a whole other mess of markup partials that you can rewrite requests to in the Service Worker’s   event. If your website has a back end—as is the case with my client—you can use an HTTP request header to instruct the server to deliver full pages or content partials. The hard part is putting all the pieces together—but we’ll do just that. Putting it all together Writing even a basic Service Worker can be challenging, but things get real complicated real fast when assembling multiple responses into one. One reason for this is that in order to avoid the Service Worker startup penalty, we’ll need to set up navigation preload. Navigation preload addresses the problem of Service Worker startup time, which delays navigation requests to the network. The last thing you want to do with a Service Worker is hold up the show. Navigation preload must be explicitly enabled. Once enabled, the Service Worker won’t hold up navigation requests during startup. Navigation preload is enabled in the Service Worker’s   event: , we have to do the usual feature check, which we store in the above example in the   variable. Additionally, we need to use   to resolve multiple asynchronous operations before the Service Worker activates. This includes pruning those old caches, as well as waiting for both   (which tells the Service Worker to assert control immediately rather than waiting until the next navigation) and navigation preload to be enabled. A ternary operator is used to enable navigation preload in supporting browsers and avoid throwing errors in browsers that don’t. If   is  , we enable navigation preload. If it isn’t, we pass a Boolean that won’t affect how   resolves. With navigation preload enabled, we need to write code in our Service Worker’s   event handler to make use of the preloaded response: Though this isn’t the entirety of the Service Worker’s   event code, there’s a lot that needs explaining: How the content partial is retrieved is tricky. With navigation preload enabled, a special   header with a value of   is added to navigation requests. We then work with that header on the back end to ensure the response is a content partial rather than the full page markup. However, because navigation preload isn’t available in all browsers, we send a different header in those scenarios. In Weekly Timber’s case, we fall back to a custom   header. In my client’s PHP back end, I’ve created some handy constants: From there, the   constant is used to adapt the response: The thing to be hip to here is that you should specify   for HTML responses to take the   (and in this case, the   header) into account for HTTP caching purposes—assuming you’re caching HTML at all, which may not be the case for you. With our handling of navigation preloads complete, we can then move onto the work of streaming content partials from the network and stitching them together with the header and footer partials from   into a single response that the Service Worker will provide. While the header and footer partials will be available almost instantaneously because they’ve been in   since the Service Worker’s installation, it’s the content partial we retrieve from the network that will be the bottleneck. It’s therefore vital that we   so we can start pushing markup to the browser as quickly as possible.   can do this for us. This   business is a mind-bender. Anyone who tells you it’s “easy” is whispering sweet nothings to you. It’s  . After I wrote my own function to merge streamed responses and messed up a critical step—which ended up not improving page performance, mind you—I modified   to suit my needs: As usual, there’s a lot going on: This is   if you use  , but depending on when you read this, that may not be an option for every browser. For now, we’ll have to stick with this approach. Now let’s revisit the Service Worker’s   event from earlier, and apply the   function: At the end of the   event handler, we pass the header and footer partials from   to the   function, and pass the result to the   event’s  , which serves the merged response on behalf of the Service Worker. Are the results worth the hassle? This is a lot of stuff to do, and it’s complicated! You might mess something up, or maybe your website’s architecture isn’t well-suited to this exact approach. So it’s important to ask: are the performance benefits worth the work? In my view? Yes! The synthetic performance gains aren’t bad at all: Synthetic tests don’t measure performance for anything except the specific device and internet connection they’re performed on. Even so, these tests were conducted on a staging version of my client’s website with a low-end   on a throttled “Fast 3G” connection in Chrome’s developer tools. Each category was tested ten times on the homepage. The takeaways here are: No Service Worker at all is slightly faster than the “standard” Service Worker with simpler caching patterns than the streaming variant. Like, ever so slightly faster. This may be due to the delay introduced by Service Worker startup, however, the RUM data I’ll go over shows a different case. Both LCP and FCP are tightly coupled in scenarios where there’s no Service Worker or when the “standard” Service Worker is used. This is because the content of the page is pretty simple and the CSS is fairly small. The Largest Contentful Paint is usually the opening paragraph on a page. However, the streaming Service Worker decouples FCP and LCP because the header content partial streams in right away from  . Both FCP and LCP are lower in the streaming Service Worker than in other cases. The benefits of the streaming Service Worker for real users is pronounced. For FCP, we receive an 79% improvement over no Service Worker at all, and a 63% improvement over the “standard” Service Worker. The benefits for LCP are more subtle. Compared to no Service Worker at all, we realize a 41% improvement in LCP—which is incredible! However, compared to the “standard” Service Worker, LCP is a touch slower. Because   is important, let’s look at the 95th percentile of FCP and LCP performance: The 95th percentile of RUM data is a great place to assess the slowest experiences. In this case, we see that the streaming Service Worker confers a 40% and 51% improvement in FCP and LCP, respectively, over no Service Worker at all. Compared to the “standard” Service Worker, we see a reduction in FCP and LCP by 19% and 43%, respectively. If these results seem a bit squirrely compared to synthetic metrics, remember: that’s RUM data for you! You never know who’s going to visit your website on which device on what network. While both FCP and LCP are boosted by the myriad benefits of streaming, navigation preload (in Chrome’s case), and sending less markup by stitching together partials from both   and the network, FCP is the clear winner. Perceptually speaking, the benefit is pronounced, as this video would suggest: Now ask yourself this: If this is the kind of improvement we can expect on such a small and simple website, what might we expect on a website with larger header and footer markup payloads? Caveats and conclusions Are there trade-offs with this on the development side?   yeah. , a cached header partial means the document title must be updated in JavaScript on each navigation by changing the value of  . It also means you’ll need to update the navigation state in JavaScript to reflect the current page if that’s something you do on your website. Note that this shouldn’t cause indexing issues, as Googlebot crawls pages with an unprimed cache. There may also be some challenges on sites with authentication. For example, if your site’s header displays the current authenticated user on log in, you may have to update the header partial markup provided by   in JavaScript on each navigation to reflect who is authenticated. You may be able to do this by storing basic user data in   and updating the UI from there. There are certainly other challenges, but it’ll be up to you to weigh the user-facing benefits versus the development costs. In my opinion, this approach has broad applicability in applications such as blogs, marketing websites, news websites, ecommerce, and other typical use cases. All in all, though, it’s akin to the performance improvements and efficiency gains that you’d get from an SPA. Only the difference is that you’re not replacing time-tested navigation mechanisms and grappling with all the messiness that entails, but  them. That’s the part I think is really important to consider in a world where client-side routing is all the rage. “What about  ?,” you might ask—and you’d be right to. Workbox simplifies a lot when it comes to using the Service Worker API, and you’re not wrong to reach for it. Personally, I prefer to work as close to the metal as I can so I can gain a better understanding of what lies beneath abstractions like Workbox. Even so, Service Worker is hard. Use Workbox if it suits you. As far as frameworks go, its abstraction cost is very low. Regardless of this approach, I think there’s incredible utility and power in using the Service Worker API to reduce the amount of markup you send. It benefits my client and all the people that use their website. Because of Service Worker and the innovation around its use, my client’s website is faster in the far-flung parts of Wisconsin. That’s something I feel good about. Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/human-readable-javascript/", "title": "Human-Readable JavaScript: A Tale of Two Experts", "content": "Everyone wants to be an expert. But what does that even mean? Over the years I’ve seen two types of people who are referred to as “experts.” Expert 1 is someone who knows every tool in the language and makes sure to use every bit of it, whether it helps or not. Expert 2 also knows every piece of syntax, but they’re pickier about what they employ to solve problems, considering a number of factors, both code-related and not.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Can you take a guess at which expert we want working on our team? If you said Expert 2, you’d be right. They’re a developer focused on delivering readable code—lines of JavaScript others can understand and maintain. Someone who can make the complex simple. But “readable” is rarely definitive—in fact, it’s largely based on the eyes of the beholder. So where does that leave us? What should experts aim for when writing readable code? Are there clear right and wrong choices? The answer is, it depends. The obvious choice In order to improve developer experience, TC39 has been adding lots of new features to ECMAScript in recent years, including many proven patterns borrowed from other languages. One such addition, added in ES2019, is   It takes an argument of depth or  , and flattens an array. If no argument is given, the depth defaults to 1. Prior to this addition, we needed the following syntax to flatten an array to a single level. When we added  , that same functionality could be expressed using a single, descriptive function. Is the second line of code more readable? The answer is emphatically yes. In fact, both experts would agree. Not every developer is going to be aware that   exists. But they don’t need to because   is a descriptive verb that conveys the meaning of what is happening. It’s a lot more intuitive than  . This is the rare case where there is a definitive answer to the question of whether new syntax is better than old. Both experts, each of whom is familiar with the two syntax options, will choose the second. They’ll choose the shorter, clearer, more easily maintained line of code. But choices and trade-offs aren’t always so decisive. The gut check The wonder of JavaScript is that it’s incredibly versatile. There is a reason it’s all over the web. Whether you think that’s a good or   thing is another story. But with that versatility comes the paradox of choice. You can write the same code in many different ways. How do you determine which way is “right”? You can’t even begin to make a decision unless you understand the available options and their limitations. Let’s use functional programming with   as the example. I’ll walk through various iterations that all yield the same result. This is the tersest version of our   examples. It uses the fewest characters, all fit into one line. This is our baseline. This next example adds only two characters: parentheses. Is anything lost? How about gained? Does it make a difference that a function with more than one parameter will always need to use the parentheses? I’d argue that it does. There is little to no detriment  in adding them here, and it improves consistency when you inevitably write a function with multiple parameters. In fact, when I wrote this,   enforced that constraint; it didn’t want me to create an arrow function without the parentheses. Let’s take it a step further. We’ve added curly braces and a return. Now this is starting to look more like a traditional function definition. Right now, it may seem like overkill to have a keyword as long as the function logic. Yet, if the function is more than one line, this extra syntax is again required. Do we presume that we will not have any other functions that go beyond a single line? That seems dubious. Next we’ve removed the arrow function altogether. We’re using the same syntax as before, but we’ve swapped out for the   keyword. This is interesting because there is no scenario in which this syntax won’t work; no number of parameters or lines will cause problems, so consistency is on our side. It’s more verbose than our initial definition, but is that a bad thing? How does this hit a new coder, or someone who is well versed in something other than JavaScript? Is someone who knows JavaScript well going to be frustrated by this syntax in comparison? Finally we get to the last option: passing just the function. And   can be written using any syntax we like. Again, there is no scenario in which passing the function name causes a problem. But step back for a moment and think about whether or not this could be confusing. If you’re new to this codebase, is it clear that   is a function and not an object? Sure,   is there to give you a hint, but it’s not unreasonable to miss that detail. How about the location of where   is declared and initialized? Is it easy to find? Is it clear what it’s doing and how it’s affecting this result? All of these are important considerations. As you can see, there is no obvious answer here. But making the right choice for your codebase means understanding all the options and their limitations. And knowing that consistency requires parentheses and curly braces and   keywords. There are a number of questions you have to ask yourself when writing code. Questions of   are typically the most common. But when you’re looking at code that is functionally identical, your determination should be based on humans—how humans consume code. Maybe newer isn’t always better So far we’ve found a clear-cut example of where both experts would reach for the newest syntax, even if it’s not universally known. We’ve also looked at an example that poses a lot of questions but not as many answers. Now it’s time to dive into code that I’ve written before…and removed. This is code that made me the first expert, using a little-known piece of syntax to solve a problem to the detriment of my colleagues and the maintainability of our codebase.  lets you unpack values from objects (or arrays). It typically looks something like this. It initializes a variable and assigns it a value all in one line. But it doesn’t have to. The last line of code assigns a variable to a value using destructuring, but the variable declaration takes place one line before it. It’s not an uncommon thing to want to do, but many people don’t realize you can do it. But look at that code closely. It forces an awkward semicolon for code that doesn’t use semicolons to terminate lines. It wraps the command in parentheses and adds the curly braces; it’s entirely unclear what this is doing. It’s not easy to read, and, as an expert, it shouldn’t be in code that I write. This code solves the problem. It works, it’s clear what it does, and my colleagues will understand it without having to look it up. With the destructuring syntax, just because I   doesn’t mean I  . Code isn’t everything As we’ve seen, the Expert 2 solution is rarely obvious based on code alone; yet there are still clear distinctions between which code each expert would write. That’s because code is for machines to read and humans to interpret. So there are non-code factors to consider! The syntax choices you make for a team of JavaScript developers is different than those you should make for a team of polyglots who aren’t steeped in the minutiae.  Let’s take spread vs.   as an example. Spread was added to ECMAScript a few years ago, and it’s enjoyed wide adoption. It’s sort of a utility syntax in that it can do a lot of different things. One of them is concatenating a number of arrays. As powerful as spread is, it isn’t a very intuitive symbol. So unless you already know what it does, it’s not super helpful. While both experts   safely assume a team of JavaScript specialists are familiar with this syntax, Expert 2 will probably question whether that’s true of a team of polyglot programmers. Instead, Expert 2 may select the   method instead, as it’s a descriptive verb that you can probably understand from the context of the code. This code snippet gives us the same nums result as the spread example above. And that’s but one example of how human factors influence code choices. A codebase that’s touched by a lot of different teams, for example, may have to hold more stringent standards that don’t necessarily keep up with the latest and greatest syntax. Then you move beyond the main source code and consider other factors in your tooling chain that make life easier, or harder, for the humans who work on that code. There is code that can be structured in a way that’s  . There is code that backs you into a corner for  . There is code that’s  , doesn’t  , or  . All of these factor into the recommendations Expert 2 makes. Expert 2 also considers the impact of naming. But let’s be honest, even   can’t get that right most of the time. Conclusion Experts don’t prove themselves by using every piece of the spec; they prove themselves by knowing the spec well enough to deploy syntax judiciously and make well-reasoned decisions. This is how experts become multipliers—how they make new experts. So what does this mean for those of us who consider ourselves experts or aspiring experts? It means that writing code involves asking yourself a lot of questions. It means considering your developer audience in a real way. The best code you can write is code that accomplishes something complex, but is inherently understood by those who examine your codebase. And no, it’s not easy. And there often isn’t a clear-cut answer. But it’s something you should consider with every function you write. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/do-you-need-to-localize-your-website/", "title": "Do You Need to Localize Your Website?", "content": "Global markets give you access to new customers. All you need to do is inform potential buyers about your product or service.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Your website is a good place to introduce your product or service outside your locale. Localizing your web content sounds like the right way to reach out to the global market. Localization will bridge the language barriers, or the wider scope of differing cultures.  Before we move on further with the discussion, let’s focus on the definition of “localization.”  According to the Cambridge Dictionary,   (as a marketing term) is “the process of making a product or service more suitable for a particular country, area, etc.,” while   is “something that is translated, or the process of translating something, from one language to another.”  In practice,  . While it’s true that localization includes both language and non-language aspects, most cultural adjustments in the localization process are done through the language. Hence, the two terms are often interchangeable.  Good translators will   simply find an equivalent of a word in another language. They will  .  Depending on the situation, they may or may not   and date formats.  , but changing “ ” to “Celsius 233” would be simply awkward. A good translator will suggest what to change and what to leave as it is.  Some people call this conversion process “localization.” The truth is, unit conversions had become a part of translation, long before the word “localization” was used to describe the process.  When we talk about linguistic versus non-linguistic aspects of a medium, and view them as separate entities, localization and translation may look different. However, when we look at the whole process of translating the message, seeing both elements as translatable items, the terms are interchangeable.  In this article, the terms “localization” and “translation” will be used interchangeably. We are going to discuss how to use a website as a communication tool to gain a new market in different cultures.  A good localization is not cheap, so it would be wise to ask yourselves several questions beforehand:  Who is your audience? What kind of culture do they live in? What kind of problems may arise during the localization process?  I will explain the details below.  Knowing your target audience should be at the top of your business plan.  For some, localization is not needed because they live in the same region and speak the same language as their target market. For example, daycare services, local coffee shops, and restaurants.  In some cases,  . In a bilingual society, you may want to cater to speakers of both languages as a sign of respect. In a multilingual society, aim to translate to the lingua franca and/or the language used by the majority. It makes people feel seen and it can create a positive image to your brand.  Sometimes, website translation is required by law. In Quebec, for instance, where French is spoken as  , you’ll need to include a French version of your website. You may also want to check  .  If your target market lives across the sea and speaks a different language, you may not have any choice but to localize. However, if those people can speak your  language, consider other aspects (cultural and/or legal) to make an informed decision on whether to translate.   Although there are many benefits of website translation, you don’t always have to do it  . Especially when your budget is tight or you can spend it on something more urgent. It’s better to postpone than to have a badly translated website.  .   If you’re legally required to launch a bilingual website but you don’t have the budget, you may want to check if you can be exempted. If you are not exempted, hire volunteers or seek government support, if possible.  Unless required otherwise by law, there is nothing wrong with using your current language in your product or service. You can maintain the already-formed relationship by focusing on what you have in common: the same interest.  For example, you have a coding tutorial website. Your current audience is IT professionals—mostly college graduates. You see an opportunity to expand to India.  Localization is  , as most Indian engineers have a good grasp of English. So, instead of doing a web translation project, you can use your money to improve or develop a new product or service for your Indian audience. Maybe you want to set up a workshop or a meetup in India. Or a bootcamp retreat in the country.  You can achieve this by focusing on the similarities you have with your audience.  The same rule applies to other countries where English language is commonly used by IT professionals. In the developing world, where English is rarely used,  . You may wonder how,  , they can learn programming. There’s an explanation for it.  There are two types of language skills:  . Passive language skills are usually learned first. Active language skills are developed later. You learn to speak by listening, and learn to write by reading. You go through this process as a child and, again, when you learn a new language as an adult. (This is not to confuse  , but to note that the process is relatively the same.)  As most free IT course materials are available online in English, some programmers may have to adapt and  . They may not be considered “fluent” in a formal way, but it doesn’t mean they lack the ability to grasp the language. They may not be able to speak or write perfectly, but they can understand technical texts.  In short, passive and active language skills can grow at different speeds. This fact leads you to  : those who can understand English, but only passively.  If your product is in a text format, translation won’t be necessary for this type of audience. If it’s an audio or video format, you may need to add subtitles, since native English speakers speak in so many different accents and at various speeds. Captioning will also help the hard of hearing. It may be required by regional or national accessibility legislation too. And it’s the right thing to do. One might argue that if these people can understand English, they will understand the text better in their native tongue.  Well, if all the programs you’re using or referring to are available in their native language version, it may not be a problem. But in reality, this is often not the case.  Linguistic consistency helps programmers work faster. And this alone should trump the presumed ease that comes with translation.  I was once involved in a global internet company’s localization project in Indonesia.  Indonesian SMEs mostly speak Indonesian since they mainly serve the domestic market. So, it was the right decision to target Indonesian SMEs using Indonesian language.  The company had the budget to target Indonesia’s market of 58 million SMEs, and there weren’t too many competitors yet. I think the localization plan was justified. But even with this generally well-thought-out plan, there were some problems in its execution.  The materials were filled with jargon and annoying outlinks. You could not just read an instruction until it was completed, because after a few words, you would be confronted with a “smart term.” Now to understand this smart term, you would have to follow a link that would take you to a separate page that was supposed to explain everything, but in that page you would find more smart terms that you’d need to click. At this point, the scent of information would have grown cold, and you’d likely have forgotten what you were reading or why.  Small business owners are among the busiest folks you can find. They do almost everything by themselves. They would not waste their time trying to read pages of instructions that throw them right and left.  Language-wise, the instructions could have been simplified. Design-wise, a hover/focus pop-up containing a brief definition or description could have been used to explain special terms.  I agree pop-ups can be distracting, but in terms of ease, for this use case, they would have worked far better than outlinks. There are   to make them more readable.  However, if the content of those pop-ups (definition, description, etc.) cannot be brief, it is wiser to write it down as a separate paragraph.  In my client’s case, they could have started each instruction by describing the definitions of those special terms. Those definitions ought to be written in one page so as to reduce the amount of time spent on clicking and returning to the intended page. This solution can also be applied when a definition is too long to be put inside a hover/focus bubble.  The text problem, in my client’s case, came with the source language. It was later transferred to the target language thanks to localization. They could have solved the problem at the source language level, but I think it would have been too late at that point.  , i.e., “ ,” doesn’t solve a problem like this because the issue is more technical than linguistic. Translators would still have to adjust their work to the given environment. They’d still have to retain all the links and translate all jargon-laden content.  The company should have hired a local writer to rewrite the content in the target language. It would have worked better. They didn’t take this route for a reason: namely, those “smart terms” were used as keywords. So as much as we hated them, we had to keep them there.   Let’s say you have considered everything. You’ve learned about your target audience, how your product will solve their problem, and that you have the budget to reach out to them. Naturally, you want to reach them now before your competitors do.  Now you can proceed with your web localization project plan.  One thing I want to repeat is that localization will transfer any errors you have in your original content to the translated pages. So you’ll need to do some content pre-checks before starting a web translation project. It will be cheaper to fix the problems   the translation project commences.  Pre-localization checks should include assessing the text you intend to translate. Ask someone outside the team to read the text and ask them to give their feedback. It’s even better if that someone represents the target audience.  Then make corrections, if need be. Use as little jargon as possible. Let readers focus on one article with no interruption.  Some companies like to coin new terms to create keywords that will lead people to their sites. This can be a smart move, and it is arguably good for search engine optimization. But if you want to  , you must make your message clear and understandable. Clear communication, not the invention of new words, should be your priority.  Following this course of action might mean sacrificing keywords for clarity, but   since visitors will stay longer on your site. After all, people are more likely to read your writing to the end if they are not being frustrated by difficult terms. Once your text is ready, you can start your localization project. You can hire a language agency or build your own team.  If you have a lot of content, it may be wise to outsource your project to a language agency. Doing so can save you time and money. An outside specialist consultancy will have the technology and skills to work on various types of localization projects. They can also translate your website to different languages at once.  As an alternative, you might directly hire freelance editors and translators to work on your project. Depending on many factors, this might end up less or more expensive than hiring an agency.  Make sure that the translators you hire, whether directly or through an agency, have relevant experience. If your text is about marketing, for instance, the translators and editors must be experts in this field. This is to make sure they can get your message across.  Most translation tools used today can retain sentence formatting, links, and HTML code, so you don’t need to worry about these.  Focus on the message you want to carry to your target audience. Be sensitive about cultural remarks and be careful about any potential misunderstanding caused by your translation. Consult with your language team about certain phrases that may become problematic when translated. Pick your words carefully. Choose the right expressions.  If you localize a website, you must be sure to provide customer service support in target-friendly language. This allows you to reply to customers immediately, rather than having to wait for a translator to become involved.   In summary, don’t be hasty when doing a web localization/translation project. There are a lot of things to consider beforehand. A well prepared plan will yield a better result. A good quality translation will not only bridge the language gap but it can also build trust and solidify your brand image in the mind of your target audience. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/immersive-content-strategy/", "title": "Immersive Content Strategy", "content": "Beyond the severe toll of the coronavirus pandemic, perhaps no other disruption has transformed user experiences quite like how the tethers to our formerly web-biased era of content have frayed. We’re transitioning to a new world of remote work and digital content. We’re also experimenting with unprecedented content channels that, not too long ago, elicited chuckles at the watercooler, like voice interfaces, digital signage, augmented reality, and virtual reality. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Many factors are responsible. Perhaps it’s because we yearn for immersive spaces that temporarily resurrect the Before Times, or maybe it’s due to the boredom and tedium of our now-cemented stuck-at-home routines. But aural user experiences slinging  , and immersive user experiences unlocking new forms of interacting with formerly web-bound content, are no longer figments of science fiction. They’re fast becoming a reality in the here and now. The idea of   is all the rage these days, and content strategists and designers are now seriously examining this still-amorphous trend. Immersive experiences embrace concepts like geolocation, digital signage, and extended reality (XR). XR encompasses augmented reality (AR) and virtual reality (VR) as well as their fusion: mixed reality (MR). Sales of immersive equipment like gaming and VR headsets  , and content strategists are increasingly attuned to the kaleidoscope of devices and interfaces users now interact with on a daily basis to acquire information. Immersive user experiences are becoming commonplace, and, more importantly,   for designers and developers looking to get their hands dirty. But that doesn’t mean our content is ready for prime time in settings unbound from the web like physical spaces, digital signage, or extended reality. Recasting your fixed web content in more immersive ways will enable more than just newfangled user experiences; it’ll prepare you for flexibility in an unpredictable future as well. These days, we interact with content through a slew of devices. It’s no longer the case that we navigate information on a single desktop computer screen. In my upcoming book   (A Book Apart, coming June 2021), I draw a distinction between what I call  —the unwieldy long-form copy plastered across browser viewports—and  : the kind of brisk, contextless bursts of content that we find nowadays on Apple Watches, Samsung TVs, and Amazon Alexas. Today, content also has to be ready for contextless situations—not only in truncated form when we struggle to make out tiny text on our smartwatches or scroll through new television series on Roku but also in places it’s never ended up before. As the twenty-first century continues apace, our clients and our teams are beginning to come to terms with the fact that the way copy is consumed in just a few decades will bear no resemblance whatsoever to the prosaic browsers and even smartphones of today. What do we mean by immersive content?  are those that,  , blur “the boundaries between the human, digital, physical, and virtual realms” to facilitate smarter, more interactive user experiences. But what do we mean by immersive content? I define  as content that plays in the sandbox of physical and virtual space—copy and media that are situationally or locationally aware rather than rooted in a static, unmoving computer screen. Whether a space is real or virtual, immersive content (or  ) will be a key way in which our customers and users deal with information in the coming years. Unlike voice content, which deals with time and sound, immersive content works with space and sight. Immersive content operates not along the axis of links and page changes but rather along  , as the following figure illustrates. Acknowledging the actual or imagined surroundings of where we are as human beings will have vast implications for content strategy, omnichannel marketing, usability testing, and accessibility. Before we dig deeper, let’s define a few clear categories of immersive content:  Though it may seem a misnomer, digital signage is one of the most widespread examples of immersive content already in use today. For example, you may have seen it used to display a guide of stores at a mall or to aid wayfinding in an airport. While still largely bound to flat screens, it’s an example of  .  Locational content involves copy that is delivered to a user on a personal device based on their current location in the world or within an identified physical space. Most often mediated through Bluetooth low-energy (BLE) beacon technology or GPS location services, it’s an example of   Unlike locational content, which doesn’t usually adjust itself seamlessly based on how users move in real-world space, AR content is now common in museums and other environments—typically as overlays that are superimposed over actual physical surroundings and adjust dynamically according to the user’s position and perspective. It’s  .  Like AR content, VR content is dependent on its imagined surroundings in terms of how it displays, but it’s part of a nonexistent space that is fully immersive, an example of  .  Long a gimmicky playground for designers and developers interested in pushing the envelope, navigable content is copy that users can move across and sift through as if it were a physical space itself: true  . The following illustration depicts these types of immersive content in their typical habitats. Why auditing immersive content is important Alongside conversational and voice content, immersive content is a compelling example of   where it has long lived: the browser viewport, the computer screen, and the 8.5”x11” or broadsheet borders of print media. For centuries, our written copy has been affixed to the staid standards of whatever bookbinders, newspaper printing presses, and screen manufacturers decided. Today, however, for the first time, we’re surmounting those arbitrary barriers and situating content in contexts that challenge all the assumptions we’ve made since the era of Gutenberg—and, arguably, since clay tablets, papyrus manuscripts, and ancient scrolls. Today, it’s never been more pressing to implement an  that centers the reality our customers increasingly live in: a world in which information can end up on any device, even if it has no tether to a clickable or scrollable setting. One of the most important elements of such a future-proof content strategy is an   that evaluates your content from a variety of standpoints so you can manage and plan it effectively. These audits generally consist of several steps:  Each content item needs to be examined from the perspective of each channel through a series of channel-relevant questions, like whether content is   or   on every conduit through which it travels. No questionnaire is complete for a content audit without   that measure how the content performs and   that determine necessary steps to improve its efficacy.  At the end of any content audit, it’s important to leaf through the results and any recommendations in a frank discussion with stakeholders, including content strategists, editors, designers, and others. In  , I shared the work we did on  , the first (but now decommissioned)  . Such a content audit is just one facet of the multifaceted omnichannel content strategy along various dimensions you’ll need to consider. Nonetheless, there are a few things all content audits share in terms of foundational evaluation criteria across all content delivery channels:  Is the content readable or easily consumable from a variety of vantage points and perspectives? In the case of immersive content, this can include examining   (how long content can be before users zone out, a big factor in digital signage) and   (like links and calls to action that make sense on the web but not on a VR headset).  It’s no longer guaranteed in immersive content experiences that every piece of content can be accessed from other content items, and content loses almost all of its context when displayed unmoored from other content in digital signs or AR overlays. For discoverability’s sake, avoid relegating content to unreachable siloes, whether content is inaccessible due to physical conditions (like walls or other obstacles) or technical ones (like a finicky VR headset). Like voice content, immersive content requires ample attention to the ways in which users approach and interact with content in physical and virtual spaces. And as I write in  , it’s also the case that   can influence how we work with copy and media. After all, how often do subway and rail commuters glance up while scrolling through service advisories on their smartphones to consult a potentially more up-to-date alert on a digital sign? Signage has long been a fixture of how we find our way through physical spaces, ever since the earliest roads crisscrossed civilizations. Today, digital signs are becoming ubiquitous across shopping centers, university campuses, and especially transit systems, with the New York City subway recently introducing countdown clocks that display service advisories on a ticker along the bottom of the screen, just below train arrival times. Digital signs can deliver critical content at important times, such as during emergencies, without the limitations imposed by the static nature of analog signs. News tickers on digital signs, for instance, can stretch for however long they need to, though succinctness is still highly prized. But digital signage’s rich potential to deliver immersive content also presents challenges when it comes to content modeling and governance. Are news items delivered to digital signs simply teaser or summary versions of full articles? Without a fully functional and configurable digital sign in your office, how will you preview them in context before they go live? To solve this problem for the New York City subway, the Metropolitan Transportation Authority (MTA)   within a central Drupal content management system (CMS), which synthesizes data such as train arrival times from real-time feeds and transit messages administered in the CMS for arbitrary delivery to any platform across the network. How to present content items in digital signs also poses problems. As the following figure illustrates, do you overtake the entire screen at the risk of obscuring other information, do you leave it in a ticker that may be ignored, or do you use both depending on the priority or urgency of the content you’re presenting? While some digital signs have the benefit of touch screens and occupying entire digital kiosks, many are tasked with providing key information in as little space as possible, where users don’t have the luxury of manipulating the interface to customize the content they wish to view. The New York City subway makes a deliberate choice to allow urgent alerts to spill across the entire screen, which limits the sign’s usefulness for those who simply need to know when the next train is arriving in the interest of more important information that is relevant to all passengers—and those who need captions for loudspeaker announcements. Auditing for digital signage content Because digital signs value brevity and efficiency, digital signage content often isn’t the main focus of what’s displayed. Digital signs on the São Paulo metro, for instance, juggle service alerts, breaking news, and health advisories. For this reason, auditing digital signage content for legibility and discoverability is key to ensuring users can interact with it gracefully, regardless of how often it appears, how highly prioritized it is, or what it covers. When it comes to legibility, ask yourself these questions and consider the digital sign content you’re authoring based on these concerns:  Many digital signs use sans-serif typefaces, which are easier to read from a distance, and many also employ uppercase for all text, especially in tickers. Consider which typefaces advance rather than obscure legibility, even when the digital sign content overtakes the entire screen.  Is your digital sign content readily readable from various angles and various vantage points? Does the reflectivity of the screen impact your content’s legibility when standing just below the sign? How does your content look when it’s displayed to a user craning their neck and peering at it askew?  Digital signs are no longer just fixtures of subterranean worlds; they’re above-ground and in well-lit spaces too. Color contrast and lighting strongly influence how legible your digital sign content can be. As for discoverability, digital signs present challenges of both physical discoverability (can the sign itself be easily found and consulted?) and content discoverability (how long does a reader have to stare at the sign for the content they need to show up?): Are signs placed in prominent locations where users will come across them? The MTA was criticized for   in the New York City subway, something that can block a user from ever accessing content they need. Because digital signs can only display so much content at once, even if there’s a large amount of copy to deliver eventually, users of digital signs may need to wait too long for their desired content to appear, or the content they seek may be too deprioritized for it to show up while they’re looking at the sign. Both legibility and discoverability of digital sign content require thorough approaches when authoring, designing, and implementing content for digital signs. Usability and accessibility in digital signage content In addition to audits, in any physical environment, immersive content on digital signs requires a careful and bespoke approach to consider not only how content will be consumed on the sign itself but also all the ways in which users move around and refer to digital signage as they consult it for information. After all, our content is no longer couched in a web page or recited by a screen reader, both objects we can control ourselves; instead, it’s flashed and displayed on flat screens and kiosks in physical spaces.  Consider how the digital sign and the content it presents appear to people who use mobility aids such as wheelchairs or walkers. Is the surrounding physical environment accessible enough so that wheelchair users can easily read and discover the content they seek on a digital sign, which may be positioned too high for a seated reader? By the same token, can colorblind and dyslexic people read the chosen typeface in the color scheme it’s rendered in? Is there an aural equivalent of the content for Blind people navigating your digital signage, in close proximity to the sign itself, serving as synchronized captions? Unlike digital signage content, which is copy or media displayed in a space,   (or  )   is copy or media delivered to a device—usually a phone or watch—based on a point in space (if precise location is acquired through GPS location services) or a swath of space (typically driven by Bluetooth Low Energy beacons that have certain ranges). For smartphone and smartwatch users, GPS location services can often pinpoint a relatively accurate sense of where a person is, while Bluetooth Low Energy (BLE) beacons can triangulate their position based on devices that have Bluetooth enabled. Though BLE beacons remain a fairly finicky and untested realm of spatial technology, they’ve quickly gained traction in large shopping centers and   where users agree to receive content relevant to their current location, most often in the form of push notifications that whisk users away into a separate view with more comprehensive information. But because these tiny chunks of copy are often tightly contained and contextless, teams designing for locational content need to focus on how users interact with their devices as they move through physical spaces. Auditing for locational content Fortunately, because locational content is often delivered to the same visual devices that we use on a regular basis—smartphones, smartwatches, and tablets—auditing for content legibility can embrace many of the same principles we employ to evaluate other content. For discoverability, some of the most important considerations include:  BLE beacons are notorious for their imprecision, though they continue to improve in quality. GPS location, too, can be an inaccurate measure of where someone is at any given time. The last thing you want your customers to experience is an incorrect triangulation of where they are leading to embarrassing mistakes and bewilderment when unexpected content travels down the wire.  Because of the relative lack of precision when it comes to BLE beacons and GPS location services, placing content items too close together in a coordinate map may trigger too many notifications or resource deliveries to a user, thus overwhelming them, or a certain content item may inadvertently supersede another because they’re spaced too closely together. As push notifications and location sharing become more common, locational content is rapidly becoming an important way to funnel users toward somewhat longer-form content that might otherwise go unnoticed when a customer is in a brick-and-mortar store. Usability and accessibility in locational content Because locational content requires users to move around physical spaces and trigger triangulation, consider how different types of users will move and also whether unforeseen issues can arise. For example, researchers in Japan found that users who walk while staring at their phones are  . Is your locational content possibly creating a situation where users bump into others, or worse, get into accidents? For instance, writing copy that’s quick and to the point or preventing notifications from being prematurely dismissed could allow users to ignore their devices until they have time to safely glance at them. Limited mobility and cognitive disabilities can place many disabled users of locational content at a deep disadvantage. While gamification may encourage users to seek as many items of locational content as possible in a given span of time for promotional purposes, consider whether it excludes wheelchair users or people who encounter obstacles when switching between contexts rapidly. There are good use cases for locational content, but what’s compelling for some users might be confounding for others. Augmented reality, once the stuff of science fiction holograms and futuristic cityscapes, is becoming more available to the masses thanks to wearable AR devices, high-performing smartphones and tablets, and innovation in machine vision capabilities, though the utopian future of true “holographic” content remains as yet unrealized. Meanwhile, virtual reality has seen incredible growth over the pandemic as homebound users—by interacting with copy and media in fictional worlds—increasingly seek escapist ways to access content normally spread across flat screens. While AR and VR content is still in its infancy, the vast majority is currently couched in   that are superimposed over real-world environments or objects and can be opaque ( ) or semi-transparent (creating an eerie, shimmery film on which text or media is displayed). Thanks to advancements in machine vision, these content overlays can track the motion of perceived objects in the physical or virtual world, bamboozling us into thinking these overlays are traveling in our fields of vision just like the things we see around us do. Formerly restricted to realms like museums, expensive video games, and gimmicky prototypes, AR and VR content is now becoming much more popular among companies that are   capable of   in real-life brick-and-mortar environments, as well as virtual or imagined landscapes, like fully immersive brand experiences that transport customers to a pop-up store in their living room. To demonstrate this, my former team at Acquia Labs built an experimental proof of concept that examines   and a pilot project for grocery stores that explores what can happen when   next to consumer goods in supermarket aisles. The following illustration shows, in the context of this latter experiment, how a smartphone camera interacts with a machine vision service and a Drupal CMS to acquire information to render alongside the item. Auditing for AR and VR content Because AR and VR content, unlike other forms of immersive content, fundamentally plays in the same sandbox as the real world (or an imaginary one), legibility and discoverability can become challenging. The potential risks for AR and VR content are in many regards a fusion of the problems found in both digital signage and locational content, encompassing both physical placement and visual perspective, especially when it comes to legibility:  Is the AR or VR overlay too transparent to comfortably read the copy or view the image contained therein, or is it so opaque that it obscures its surroundings? AR and VR content must coexist gracefully with its exterior, and the two must enhance rather than obfuscate each other. Does the way your content is delivered compromise a user’s feeling of immersion in the environment behind it?  Unless you’re limited to a smartphone or similar handheld device, many AR and VR overlays, especially in immersive headsets, don’t display content or media as an immobile rectangular box, as it defeats the purpose of the illusion and can be jarring to users as they adjust their field of vision, breaking them out of the fantasy you’re hoping to create. For this reason, your AR or VR experience must not only dictate how environments and objects are angled and lit but also how the content associated with them is perceived. Is your content readable from various angles and points in the AR view or VR world? When it comes to discoverability of your AR and VR content, issues like accuracy in machine vision and triangulation of your user’s location and orientation become much more important:  Most relevantly for AR content, if your copy or media is predicated on machine vision that perceives an object by identifying it according to certain characteristics, how accurate is that prediction? Does some content go undiscovered because certain objects go undetected in your AR-enabled device?  If your content relies on the user’s current location and orientation in relation to some point in space, as is common in both AR and VR content use cases, how accurately do devices dictate correct delivery at just the right time and place? Are the ranges within which content is accessible too limited, leading to flashes of content as you take a step to the left or right? Are there locations that simply can’t be reached, leading to forever-siloed copy or media? Due to the intersection of technical considerations and design concerns, AR and VR content, like voice content and indeed other forms of immersive content, requires a concerted effort across multiple teams to ensure resources are delivered not just legibly but also discoverably. Usability and accessibility in AR and VR content Out of all the forms of immersive content we’ve covered so far, AR and VR content is possibly the medium that demands the most assiduously crafted solutions in accessibility testing and usability testing. Because AR and VR content, especially in headsets or wearable devices, requires motion through real or imagined space, its impact on accessibility cannot be overstated. Adding a third dimension—and arguably, a fourth: time—to our perception of content requires attention not only to how content is accessed but also all the other elements that comprise a fully immersive visual experience. VR headsets commonly induce   in many individuals. Poorly implemented transitions between states occurring in quick succession where content is visible and then invisible, and then visible again, can lead to epileptic seizures if not built with the utmost care. Finally, users moving quickly through spaces may inadvertently trigger vertigo in themselves or even collide with hazardous objects, resulting in potentially serious injuries. There’s a reason we aren’t wearing wearable headsets outside carefully secured environments. This is only the beginning of immersive content. Increasingly, we’re also toying with ideas that seemed harebrained even a few decades ago, like  —copy and media that can be traversed as if the content   were a navigable space. Imagine zooming in and out of tracts of text and stepping across glyphs like hopping between islands in a Super Mario game. Ambitious designers and developers are exploring this emerging concept of navigable content in exciting ways, both in and out of AR and VR. In many ways, truly navigable content is the endgame of how virtual reality presents information. Imagining an encyclopedia that we can browse like the classic   is no longer as far-fetched as we think. Consider, for instance,  , which invites you to play a character as you learn about his career, or  , where you drive an animated truck around his website. For navigable content, the risks and rewards for user experience and accessibility remain largely unexplored, just like the hazy fringes of the infinite maps VR worlds make possible. Conclusion The story of immersive content is in its early stages. As newly emerging channels for content see greater adoption, requiring us to relay resources like text and media to never-before-seen destinations like digital signage, location-enabled devices, and AR and VR overlays, the demands on our content strategy and design approaches will become both fascinating and frustrating. As seemingly fantastical new interfaces continue to emerge over the horizon, we’ll need an omnichannel content strategy to guide our own journeys as creatives and to orient the voyages of our users into the immersive. Content audits and effective content strategies aren’t just the domain of staid websites and boxy mobile or tablet interfaces—or even  . They’re a key component of our increasingly digitized spaces, too, cornerstones of immersive experiences that beckon us to consume content where we are at any moment, unmoored from a workstation or a handheld. Because it lacks long-standing motifs of the web like context and clickable links, immersive content invites us to revisit our content with a fresh perspective. How will immersive content reinvent how we deliver information like the web did only a few decades ago, like voice has done in the past ten years? Only the test of time, and the allure of immersion, will tell. Like this: \n\t\t\t\t\t\t\tRecently by Preston So\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/standards-for-writing-accessibly/", "title": "Standards for Writing Accessibly", "content": "Writing to meet WCAG2 standards can be a challenge, but it’s worthwhile. Albert Einstein, the archetypical genius and physicist, once said, “Any fool can make things bigger, more complex, and more violent. It takes a touch of genius—and a lot of courage—to move in the opposite direction.” Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Hopefully, this entire book will help you better write for accessibility. So far, you’ve learned: Why clarity is important How to structure messages for error states and stress cases How to test the effectiveness of the words you write All that should help your writing be better for screen readers, give additional context to users who may need it, and be easier to parse. But there are a few specific points that you may not otherwise think about, even after reading these pages.  Writing for Screen Readers People with little or no sight interact with apps and websites in a much different way than sighted people do. Screen readers parse the elements on the screen (to the best of their abilities) and read it back to the user. And along the way, there are many ways this could go wrong. As the interface writer, your role is perhaps most important in giving screen reader users the best context. Here are a few things to keep in mind about screen readers: The average reading time for sighted readers is two to five words per second. Screen-reader users can comprehend text being read at an average of 35 syllables per second, which is significantly faster. Don’t be afraid to sacrifice brevity for clarity, especially when extra context is needed or useful. People want to be able to skim long blocks of text, regardless of sight or audio, so it’s extremely important to structure your longform writing with headers, short paragraphs, and other content design best practices.  Write Chronologically, Not Spatially  Writing chronologically is about describing the order of things, rather than where they appear spatially in the interface. There are so many good reasons to do this (devices and browsers will render interfaces differently), but screen readers show you the most valuable reason. You’ll often be faced with writing tooltips or onboarding elements that say something like, “Click the OK button below to continue.” Or “See the instructions above to save your document.” Screen readers will do their job and read those instructions aloud to someone who can’t see the spatial relationships between words and objects. While many times, they can cope with that, they shouldn’t have to. Consider screen reader users in your language. Embrace the universal experience shared by humans and rely on their intrinsic understanding of the   paradigm. Write chronologically, as in Figure 5.5. Rather than saying: Click the OK button below to continue. (A button that scrolls you to the top of a page): Go to top. Instead, say: Next, select OK to continue. Go to beginning. Write Left to Right, Top to Bottom While you don’t want to convey spatial meaning in your writing, you still want to keep that spatial order in mind. Have you ever purchased a service or a product, only to find out later that there were conditions you didn’t know about before you paid for it? Maybe you didn’t realize batteries weren’t included in that gadget, or that signing up for that social network, you were implicitly agreeing to provide data to third-party advertisers. People who use screen readers face this all the time. Most screen readers will parse information from left to write, from top to bottom.  Think about a few things when reviewing the order and placement of your words. Is there information critical to performing an action, or making a decision, that appears after (to the right or below) an action item, like in Figure 5.5? If so, consider moving it up in the interface.  Instead, if there’s information critical to an action (rules around setting a password, for example, or accepting terms of service before proceeding), place it  the text field or action button. Even if it’s hidden in a tooltip or info button, it should be presented before a user arrives at a decision point. Don’t Use Colors and Icons Alone  If you are a sighted American user of digital products, there’s a pretty good chance that if you see a message in red, you’ll interpret it as a warning message or think something’s wrong. And if you see a message in green, you’ll likely associate that with success. But while colors aid in conveying meaning to this type of user, they don’t necessarily mean the same thing to those from other cultures. For example, although red might indicate excitement, or danger in the U.S. (broadly speaking), in other cultures it means something entirely different: In China, it represents good luck. In some former-Soviet, eastern European countries it’s the color strongly associated with Communism. In India, it represents purity.  Yellow, which we in the U.S. often use to mean “caution” (because we’re borrowing a mental model from traffic lights), might convey another meaning for people in other cultures: In Latin America, yellow is associated with death. In Eastern and Asian cultures, it’s a royal color—sacred and often imperial.  And what about users with color-blindness or low to no vision? And what about screen readers? Intrinsic meaning from the interface color means nothing for them. Be sure to add words that bear context so that if you heard the message being read aloud, you would understand what was being said, as in Figure 5.6. Describe the Action, Not the Behavior Touch-first interfaces have been steadily growing and replacing keyboard/mouse interfaces for years, so no longer are users “clicking” a link or a button. But they’re not necessarily “tapping” it either, especially if they’re using a voice interface or an adaptive device. Instead of microcopy that includes behavioral actions like: Click Tap Press See Try device-agnostic words that describe the action, irrespective of the interface, like: Choose Select View There are plenty of exceptions to this rule. If your interface requires a certain action to execute a particular function, and you need to teach the user how their gesture affects the interface (“Pinch to zoom out,” for example), then of course you need to describe the behavior. But generally, the copy you’re writing will be simpler and more consistent if you stick with the action in the context of the interface itself. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/cross-cultural-design/", "title": "Cross-Cultural Design", "content": "When I first traveled\nto Japan as an exchange student in 2001, I lived in northern Kyoto, a block\nfrom the Kitayama subway station.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. My first time using the train to get to my university was almost a disaster, even though it was only two subway stops away. I thought I had everything I needed to successfully make the trip. I double- and triple-checked that I had the correct change in one pocket and a computer printout of where I was supposed to go in the other. I was able to make it down into the station, but then I just stood at a ticket machine, dumbfounded, looking at all the flashing lights, buttons, and maps above my head ( ). Everything was so impenetrable. I was overwhelmed by the architecture, the sounds, the signs, and the language.  My eyes craved\nsomething familiar—and there it was. The ticket machine had a small button that\nsaid  ! I\npushed it but became even more lost: the instructions were poorly translated,\nand anyway, they explained a system that I couldn’t use in the first place.  Guess what saved me?\nTwo little old Japanese ladies. As they bought tickets, I casually looked over\ntheir shoulders to see how they were using the machines. First, they looked up at\nthe map to find their desired destination. Then, they noted the fare written next\nto the station. Finally, they put some money into the machine, pushed the\nbutton that lit up with their correct fare, and out popped the tickets! Wow! I\ntried it myself after they left. And after a few tense moments, I got my ticket\nand headed through the gates to the train platform. I pride myself on\nbeing a    , meaning I was raised in a culture\nother than the country named on my passport. But even with a cultural upbringing in both Nigeria\nand the US, it was one of the first times I ever had to guess my way through a\ntask with no previous reference points. And I did it!  Unfortunately, the same guesswork happens online a million times a day. People visit sites that offer them no cultural mental models or visual framework to fall back on, and they end up stumbling through links and pages. Effective visual systems can help eliminate that guesswork and uncertainty by creating layered sets of cues in the design and interface. Let’s look at a few core parts of these design systems and tease out how we can make them more culturally responsive and multifaceted.  Typography If you work on the\nweb, you deal with typography all the time. This isn’t a book about typography—others\nhave written far more eloquently and technically on the subject. What I  like to do, however, is examine some of the ways culture and identity\ninfluence our perception of type and what typographic choices designers can\nmake to help create rich cross-cultural experiences. Stereotypography I came across the word\n  a few years ago. Being African, I’m well aware of the way my continent is\nportrayed in Western media—a dirt-poor, rural monoculture with little in the\nway of technology, education, or urbanization. In the West, one of the most recognizable\ngraphic markers for things African, tribal, or uncivilized (and no, they are\nnot the same thing) is the typeface Neuland. Rob Giampietro calls it “the New\nBlack Face,” a clever play on words. In an essay, he asks an important\nquestion:  How did [Neuland and Lithos] come to signify Africans and African-Americans, regardless of how a designer uses them, and regardless of the purpose for which their creators originally intended them? ( ) From its release in 1923 and continued use through the 1940s in African-American-focused advertising, Neuland has carried heavy connotations and stereotypes of cheapness, ugliness, tribalism, and roughness. You see this even today. Neuland is used in posters for movies like  ,  , and  movies that are about jungles, wildness, and scary beasts lurking in the bush, all Western symbolism for the continent of Africa. Even MyFonts’ download page for Neuland ( ) includes tags for “Africa,” “jungle fever,” and “primitive”—tags unconnected to anything else in the product besides that racist history. Don’t make, use, or\nsell fonts this way. Here are some tips on how to avoid stereotypography when\ndefining your digital experiences:  For example, so-called “wonton” or “chop-suey” fonts, whose visual style is thought to express “Asianness” or to suggest Chinese calligraphy, have long appeared on food cartons, signs, campaign websites, and even Abercrombie & Fitch T-shirts with racist caricatures of Asians ( ). Monotype’s website, where you can buy a version called Mandarin Regular (US$35), cringingly describes the typeface’s story as “an interpretation of artistically drawn Asian brush calligraphy” ( ). Whether or not you immediately know its history, run away from any typeface that purports to represent an entire culture.   This might seem like it’s a difficult task, but the internet is a big place. I have found that, for clients who are sensitive to cultural issues, the inclusion of type designers’ names and backgrounds can be a powerful differentiator, even making its way into their branding packages as a point of pride. The world wide webfont Another common design tool\nyou should consider is webfonts—fonts specifically designed for use on websites\nand apps. One of the main selling points of webfonts is that instead of\nputting text in images, clients can use live text on their sites, which is\nbetter for SEO and accessibility. They\nare simple to implement these days, a matter of adding a line of code or\nchecking a box on a templating engine. The easiest way to get them on your site\nis by using a service like Google Fonts, Fontstand, or Adobe Fonts.  Or is it? That assumes\nthose services are actually available to your users.  Google Fonts (and every other service using Google’s Developer API) is blocked in mainland China, which means that any of those nice free fonts you chose would simply not load ( ). You can work around this, but it also helps to have a fallback font—that’s what they’re for.  When you’re building your design system, why not take a few extra steps to define some webfonts that are visible in places with content blocks? Justfont is one of the first services focused on offering a wide range of Chinese webfonts ( ). They have both free and paid tiers of service, similar to Western font services. After setting up an account, you can grab whatever CSS and   information you need.  Multiple script\nsystems  When your design work\nrequires more than one script—for instance, a Korean typeface and a Latin\ntypeface—your choices get much more difficult. Designs that incorporate more\nthan one are called multiple script systems (  for short). Combining them is an\ninteresting design challenge, one that requires extra typographic sensitivity. Luckily,\nyour multiscript choices will rarely appear on the same page together; you will\nusually be choosing fonts that work across the brand, not that work well next\nto one another visually.  Let’s take a look at an example of effective multiscript use. SurveyMonkey, an online survey and questionnaire tool, has their site localized into a variety of different languages ( ). Take note of the headers, the structure of the text in the menu and buttons, and how both fonts feel like part of the same brand.  Some tips as you attempt to choose multiscript fonts for your\nproject:  Take the time to examine how weight and contrast are used in the scripts you’re using. Find weights and sizes that give you a similar feel and give the page the right balance, regardless of the script.   Character x-heights, descenders, ascenders, and spacing can throw off the overall brand effect. For instance, Japanese characters are always positioned within a grid with all characters designed to fit in squares of equal height and width. Standard Japanese typefaces also contain Latin characters, called  . Those Latin characters will, by default, be kerned according to that same grid pattern, often leaving their spacing awkward and ill-formed. Take the extra time to find a typeface that doesn’t have features that are awkward to work with.  Initial impressions don’t always mean a typeface is the right one for your project. In an interview in the book  , Jeongmin Kwon, a typeface designer based in France, offers an example ( ). Nanum Myeongjo, a contemporary Hangul typeface, might at first glance look really similar to a seventeenth-century Latin old-style typeface—for instance, they both have angled serifs. However, Nanum Myeongjo was designed in 2008 with refined, modern strokes, whereas old-style typefaces were originally created centuries ago and echo handwritten letterforms ( ). Looking at the Google Fonts page for Nanum Myeongjo, though, none of that is clear ( ). The page automatically generates a Latin   glyph in the top left of the page, instead of a more representative Hangul character sample. If I based my multiscript font choices on my initial reactions to that page, my pairings wouldn’t accurately capture the history and design of each typeface. Visual density CSS can help you control\nvisual density—how much text, image, and other content there is relative to the\nnegative space on your page. As you read on, keep cultural variables in mind: different\ncultures value different levels of visual density. Let’s compare what are\ncommonly called  \n(Chinese, Japanese, Korean) alphabets and   (English, French, Italian, etc.) alphabets. CJK alphabets\nhave more complex characters, with shapes that are generally squarer than Latin\nletterforms. The glyphs also tend to be more detailed than Latin ones, resulting\nin a higher visual density.  Your instinct might be\nto create custom type sizes and line heights for each of your localized pages.\nThat is a perfectly acceptable option, and if you are a typophile, it may drive\nyou crazy   to\ndo it. But I’m here to tell you that­ when adding CJK languages to a design\nsystem, you can update it to account for their visual density without ripping\nout a lot of your original CSS:  The 2017 site for Typojanchi, the Korean Typography Biennale, follows this methodology ( ). Both the English and Korean texts have a   of  , and a   of  . The result? The English text takes up more space vertically, and the block of Korean text is visually denser, but both are readable and sit comfortably within the overall page design. It is useful to compare translated websites like this to see how CSS styling can be standardized across Latin and CJK pages. Text expansion factors Expansion factors calculate\nhow long strings of text will be in different languages. They use either a\ndecimal (1.8) or a percentage (180%) to calculate the length of a text string\nin English versus a different language. Of course, letter-spacing depends on\nthe actual word or phrase, but think of them as a very rough way to anticipate space\nfor text when it gets translated.  Using expansion factors is best when planning for microcopy, calls to action, and menus, rather than long-form content like articles or blog posts that can freely expand down the page. The Salesforce Lightning Design System offers a detailed expansion-factor table to help designers roughly calculate space requirements for other languages in a UI ( ).  But wait! Like\neverything in cross-cultural design, nothing is ever that simple. Japanese, for\nexample, has three scripts:  , for characters of Chinese origin,\n , for words and sounds that are not represented in  , and  ,\nfor words borrowed from other\nlanguages. The follow button is a core part of the Twitter experience. It has six characters in English (“Follow”) and four in Japanese ( ), but the Japanese version is twenty percent longer because it is in katakana, and those characters take up more space than kanji ( ). Expansion tables can struggle to accommodate the complex diversity of human scripts and languages, so don’t look to them as a one-stop or infallible solution.  Here are a few things\nyou can do keep expansion factors in mind as you design:  Of course, you should make sure your text doesn’t contain any unintentional swearwords or improper language, but tools like Foreign Ipsum are a good place to start getting your head around expansion factors ( ). As well as being general good practice in responsive design, this allows you to account for how text in your target languages expands.  Stay away from assigning a fixed width to your UI elements unless it’s unavoidable.  Just ensure that text is aligned correctly and is easy to scan. Like this: \n\t\t\t\t\t\t\tRecently by Senongo Akpem\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/usability-testing-for-voice-content/", "title": "Usability Testing for Voice Content", "content": "It’s an important time to be in voice design. Many of us are turning to voice assistants in these times, whether for comfort, recreation, or staying informed. As the interest in interfaces driven by voice continues to reach new heights around the world, so too will users’ expectations and the best practices that guide their design. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Voice interfaces (also known as voice user interfaces or VUIs) have been reinventing how we approach, evaluate, and interact with user interfaces. The impact of conscious efforts to reduce close contact between people will continue to increase users’   on all devices, whether that entails a microphone icon indicating voice-enabled search or a full-fledged voice assistant waiting patiently in the wings for an invocation. But voice interfaces present inherent challenges and surprises. In this relatively new realm of design, the intrinsic twists and turns in spoken language can make things difficult for even the most carefully considered voice interfaces. After all, spoken language is littered with   (in the  ), hesitations and pauses, and other interruptions and speech disfluencies that present puzzling problems for designers and implementers alike. Once you’ve built a voice interface that introduces information or permits transactions in a rich way for spoken language users, the easy part is done. Nonetheless, voice interfaces also surface unique challenges when it comes to usability testing and robust evaluation of your end result. But there are advantages, too, especially when it comes to accessibility and cross-channel content strategy. The fact that voice-driven content lies on the opposite extreme of the spectrum from the traditional website confers it an additional benefit: it’s an effective way to analyze and stress-test just how channel-agnostic your content truly is. The quandary of voice usability Several years ago, I led a talented team at   to design and build a voice interface for   called  , which allowed citizens of the state of Georgia to access content about key civic tasks, like registering to vote, renewing a driver’s license, and filing complaints against businesses. Based on copy drawn directly from the frequently asked questions section of the  , it was the first Amazon Alexa interface integrated with the   content management system ever built for public consumption. Built by my former colleague  , it also offered a host of impressive features, like allowing users to request the phone number of individual government agencies for each query on a topic. Designing and building web experiences for the public sector is a uniquely challenging endeavor due to requirements surrounding accessibility and frequent budgetary challenges. Out of necessity, governments need to be exacting and methodical not only in how they engage their citizens and spend money on projects but also how they incorporate new technologies into the mix. For most government entities, voice is a completely different world, with many potential pitfalls. At the outset of the project, the  , led by  , expressed their most important need: a single content model across all their content irrespective of delivery channel, as they only had resources to maintain a single rendition of each content item. Despite this editorial challenge, Georgia saw Alexa as an exciting opportunity to open new doors to accessible solutions for citizens with disabilities. And finally, because there were relatively few examples of voice usability testing at the time, we knew we would have to learn on the fly and experiment to find the right solution. Eventually, we discovered that all the traditional approaches to usability testing that we’d executed for other projects were ill-suited to the unique problems of  . And this was only the beginning of our problems. How voice interfaces improve accessibility outcomes Any discussion of voice usability must consider some of the most experienced voice interface users: people who use assistive devices. After all, accessibility has long been a bastion of web experiences, but it has only recently become  . In a world where refreshable Braille displays and screen readers prize the rendering of web-based content into synthesized speech above all, the voice interface seems like an anomaly. But in fact, the   for disabled citizens represented one of the primary motivations for Georgia’s interest in making their content available through a voice assistant.  have surfaced in recent years due to the perceived user experience benefits that voice interfaces can offer over more established assistive devices. Because screen readers make no exceptions when they recite the contents of a page, they can occasionally present superfluous information and force the user to wait longer than they’re willing. In addition, with an effective content schema, it can often be the case that voice interfaces facilitate pointed interactions with content at a more granular level than the page itself. Though it can be difficult to convince even the most forward-looking clients of accessibility’s value, Georgia has been not only a trailblazer but also a committed proponent of content accessibility beyond the web. The state was among the first jurisdictions to offer a text-to-speech (TTS) phone hotline that read web pages aloud. After all, state governments must serve   citizens equally—no ifs, ands, or buts. And while these are still early days, I can see voice assistants becoming new conduits, and perhaps more efficient channels, by which disabled users can access the content they need. Managing content destined for discrete channels Whereas voice can improve accessibility of content, it’s seldom the case that web and voice are the only channels through which we must expose information. For this reason, one piece of advice I often give to content strategists and architects at organizations interested in pursuing voice-driven content is to  . Siloing it is the same misguided approach that has led to mobile applications and other discrete experiences delivering orphaned or outdated content to a user expecting that all content on the website should be up-to-date and accessible through other channels as well. After all, we’ve trained ourselves for many years to think of content in the web-only context rather than across channels. Our closely held assumptions about links, file downloads, images, and other web-based marginalia and miscellany are all aspects of web content that translate poorly to the conversational context—and particularly the voice context. Increasingly, we all need to concern ourselves with an   that straddles all those channels in existence today and others that will doubtlessly surface over the horizon. With the advantages of structured content in Drupal 7, Georgia.gov already had a content model amenable to interlocution in the form of   (FAQs). While   because queries for content tend to come in the form of questions, the returned responses likewise need to be as voice-optimized as possible. For Georgia.gov, the need to preserve a single rendition of all content across all channels led us to perform a  , in which we read aloud all of the FAQ pages, putting ourselves in the shoes of a voice user, and identified key differences between how a user would interpret the written form and how they would parse the spoken form of that same content. After some discussion with the editorial team at Georgia, we opted to limit calls to action (e.g., “Read more”), links lacking clear context in surrounding text, and other situations confusing to voice users who cannot visualize the content they are listening to. Here’s a table containing examples of how we converted certain text on FAQ pages to counterparts more appropriate for voice. Reading each sentence aloud, one by one, helped us identify cases where users might scratch their heads and say “Huh?” in a voice context. In areas like content strategy and content governance, content audits have long been key to understanding the full picture of your content, but it doesn’t end there. Successful content audits can run the gamut from automated checks for orphaned content or overly wordy articles to more qualitative analyses of how content adheres to a specific brand voice or certain design standards. For a content strategy truly prepared for  , a holistic understanding of how users will interact with your content in a variety of situations is a baseline requirement today. Other conversational interfaces have it easier Spoken language is inherently hard. Even the most gifted orators can have trouble with it. It’s littered with mistakes, starts and stops, interruptions, hesitations, and a vertiginous range of other uniquely human transgressions. The written word, because it’s committed instantly to a mostly permanent record, is tame, staid, and carefully considered in comparison. When we talk about conversational interfaces, we need to draw a clear distinction between the range of user experiences that traffic in   rather than  . As we know from   versus the comparative transience of spoken language and oral traditions, in many ways the two couldn’t be more different from one another. The implications for designers are significant because spoken language, from the user’s perspective, lacks a graphical equivalent to which those scratching their head can readily refer. We’re dealing with the spoken word and  , not pixels, written help text, or visual affordances. Why written conversational interfaces are easier to evaluate One of the privileges that chatbots and textbots enjoy over voice interfaces is the fact that by design, they can’t hide the previous steps users have taken. Any conversational interface user working in the written medium has access to their previous history of interactions, which can stretch back days, weeks, or months: the so-called  . A flight passenger communicating with an airline through Facebook Messenger, for example, knows that they can merely scroll up in the chat history to confirm that they’ve already provided the company with their e-ticket number or frequent flyer account information. This has outsize implications for information architecture and  . Since chatbot users can consult their own written record, it’s much harder for things to go completely awry when they make a move they didn’t intend. Recollection is much more difficult when you have to remember what you said a few minutes ago off the top of your head rather than scrolling up to the information you provided a few hours or weeks ago. An effective chatbot interface may, for example, enable a user to jump back to a much earlier, specific place in a conversation’s history.An effective chatbot interface may, for example, enable a user to jump back to a much earlier, specific place in a conversation’s history. Voice interfaces that live perpetually in the moment have no such luxury. Eye tracking only works for visual components In many cases, those who work with chatbots and messaging bots (especially those leveraging text messages or other messaging services like Facebook Messenger, Slack, or WhatsApp) have the unique privilege of benefiting from a   component. Some conversational interfaces now insert other elements into the conversational flow between a machine and a person, such as   (like  ) that allow users to enter rich input or select from a range of possible responses. The success of eye tracking in more traditional usability testing scenarios highlights its appropriateness for visual interfaces such as websites, mobile applications, and others. However, from the standpoint of evaluating voice interfaces that are entirely aural, eye tracking serves only the limited (but still interesting from a research perspective) purpose of assessing where the test subject is looking while speaking with an invisible interlocutor—not whether they are able to use the interface successfully. Indeed, eye tracking is only a viable option for voice interfaces that have some visual component, like the Amazon Echo Show. Think-aloud and concurrent probing interrupt the conversational flow A well-worn approach for usability testing is  , which allows for users working with interfaces to present their frequently qualitative impressions of interfaces verbally while interacting with the user experience in question. Paired with eye tracking, think-aloud adds considerable dimension to a usability test for visual interfaces such as websites and web applications, as well as other visually or physically oriented devices. Another is   (CP). Probing involves the use of questions to gather insights about the interface from users, and  :  , in which the researcher asks questions during interactions, and  , in which questions only come once the interaction is complete. Conversational interfaces that utilize written language rather than spoken language can still be well-suited to think-aloud and concurrent probing approaches, especially for the components in the interface that require manual input, like conversational forms and other traditional UI elements interspersed throughout the conversation itself. But for voice interfaces, think-aloud and concurrent probing are highly questionable approaches and can catalyze a variety of unintended consequences, including accidental invocations of trigger words (such as Alexa mishearing “selected” as “Alexa”) and introduction of bad data (such as speech transcription registering both the voice interface and test subject). After all, in a hypothetical think-aloud or CP test of a voice interface, the user would be responsible for conversing with the chatbot while simultaneously offering up their impressions to the evaluator overseeing the test. Voice usability tests with retrospective probing  (RP), a lesser-known approach for usability testing, is seldom seen in web usability testing due to its chief weakness: the fact that we have awful memories and rarely remember what occurred mere moments earlier with anything that approaches total accuracy. (This might explain why the backscroll has joined the pantheon of rigid recordkeeping currently occupied by cuneiform, the printing press, and other means of concretizing information.) For users of voice assistants lacking scrollable chat histories, retrospective probing introduces the potential for subjects to include false recollections in their assessments or to misinterpret the conclusion of their conversations. That said, retrospective probing permits the participant to take some time to form their impressions of an interface rather than dole out incremental tidbits in a stream of consciousness, as would more likely occur in concurrent probing. What makes voice usability tests unique Voice usability tests have several unique characteristics that distinguish them from web usability tests or other conversational usability tests, but some of the same principles unify both visual interfaces and their aural counterparts. As always, “test early, test often” is a mantra that applies here, as the earlier you can begin testing, the more robust your results will be. Having an individual to administer a test and another to transcribe results or watch for signs of trouble is also an effective best practice in settings beyond just voice usability. Interference from poor soundproofing or external disruptions can derail a voice usability test even before it begins. Many large organizations will have soundproof rooms or recording studios available for voice usability researchers. For the vast majority of others, a mostly silent room will suffice, though absolute silence is optimal. In addition, many subjects, even those well-versed in web usability tests, may be unaccustomed to voice usability tests in which long periods of silence are the norm to establish a baseline for data. How we used retrospective probing to test Ask GeorgiaGov For Ask GeorgiaGov, we used the retrospective probing approach almost exclusively to gather a range of insights about how our users were interacting with voice-driven content. We endeavored to evaluate interactions with the interface early and diachronically. In the process, we asked each of our subjects to complete two distinct tasks that would require them to traverse the entirety of the interface by asking questions (conducting a search), drilling down into further questions, and requesting the phone number for a related agency. Though this would be a significant ask of any user working with a visual interface, the unidirectional focus of voice interface flows, by contrast, reduced the likelihood of lengthy accidental detours. Here are a couple of example scenarios: You have a business license in Georgia, but you’re not sure if you have to register on an annual basis. Talk with Alexa to find out the information you need. At the end, ask for a phone number for more information. You’ve just moved to Georgia and you know you need to transfer your driver’s license, but you’re not sure what to do. Talk with Alexa to find out the information you need. At the end, ask for a phone number for more information. We also peppered users with questions after the test concluded to learn about their impressions through retrospective probing: “On a scale of 1–5, based on the scenario, was the information you received helpful? Why or why not?” “On a scale of 1–5, based on the scenario, was the content presented clear and easy to follow? Why or why not?” “What’s the answer to the question that you were tasked with asking?” Because state governments also routinely deal with citizen questions having to do with potentially traumatic issues such as divorce and sexual harassment, we also offered the choice for participants to opt out of certain categories of tasks. While this testing procedure yielded compelling results that indicated our voice interface was performing at the level it needed to despite its experimental nature, we also ran into considerable challenges during the usability testing process. Restoring Amazon Alexa to its initial state and troubleshooting issues on the fly proved difficult during the initial stages of the implementation, when bugs were still common. In the end, we found that many of the same lessons that apply to more storied examples of usability testing were also relevant to Ask GeorgiaGov: the importance of testing early and testing often, the need for faithful yet efficient transcription, and the surprising staying power of bugs when integrating disparate technologies. Despite Ask GeorgiaGov’s many similarities to other interface implementations in terms of technical debt and the role of usability testing, we were overjoyed to hear from real Georgians whose engagement with their state government could not be more different from before. Conclusion Many of us may be building interfaces for voice content to experiment with newfangled channels, or to build for disabled people and people newer to the web. Now, they are necessities for many others, especially as social distancing practices continue to take hold worldwide. Nonetheless, it’s crucial to keep in mind that voice should be only one component of a channel-agnostic strategy equipped for content ripped away from its usual contexts. Building usable voice-driven content experiences can teach us a great deal about how we should envisage our milieu of content and its future in the first place. Gone are the days when we could write a page in HTML and call it a day; content now needs to be rendered through synthesized speech, augmented reality overlays, digital signage, and other environments where users will never even touch a personal computer. By focusing on structured content first and foremost with an eye toward moving past our web-based biases in developing our content for voice and others, we can better ensure the effectiveness of our content on any device and in any form factor. Eight months after we finished building Ask GeorgiaGov in 2017, we conducted a retrospective to inspect the logs amassed over the past year. The results were striking. Vehicle registration, driver’s licenses, and the state sales tax comprised the most commonly searched topics. 79.2% of all interactions were successful, an achievement for one of the first content-driven Alexa skills in production, and 71.2% of all interactions led to the issuance of a phone number that users could call for further information. But deep in the logs we implemented for the Georgia team’s convenience, we found a number of perplexing 404 Not Found errors related to a search term that kept being recorded over and over again as “Lawson’s.” After some digging and consulting the native Georgians in the room, we discovered that one of our dear users with a particularly strong drawl was repeatedly pronouncing “license” in her native dialect to no avail. As this anecdote highlights, just as no user experience can be truly perfect for everyone, voice content is an environment where imperfections can highlight considerations we missed in developing cross-channel content. And just as we have much to learn when it comes to the new shapes content can take as it jumps off the screen and out the window, it seems our voice interfaces still have a ways to go before they take over the world too. Like this: \n\t\t\t\t\t\t\tRecently by Preston So\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/jobs-to-be-done/", "title": "Jobs To Be Done", "content": "In this chapter, you’ll learn about these plays: Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. How to create a jobs-driven roadmap Using job stories to solve specific design problems How to architect the structure of a solution Testing assumptions directed by JTBD A software company I once worked for held what were called “hackweeks” once a quarter. This was a time for developers to work on “whatever they wanted,” as it was framed. Give engineers time to play around with technology, and they’re bound to find the next innovation, or so the theory went. Hackweek was a big deal for us. Dozens of people organized it, and every developer in the company stopped work to contribute to the effort. It was costly, but we were committed to hackweek. After all, new software offerings come from new development, right? Here’s how it went: small teams formed to cobble together starter projects representing the use of some new technology. At the end of the week, a panel judged the dozens of concepts that emerged, and the winning “solutions” were rewarded. But in our case, hackweek was like shooting a shotgun in the wrong direction while blindfolded and hoping to hit the target. The result was inevitably a collection of concepts looking for a problem to solve. It was innovation theater at its best. To be fair, not all hackathons are bad. Some organizations coordinate hackathons with strategic imperatives or with customer needs. And sure, it’s also good to flex creative muscles and practice collaboration across teams. But given their cost and imprecision, hackathons are often largely ineffective in producing usable concepts. The problem is not a lack of ideas—companies are usually swimming in them. Like ours, many organizations have a Darwinistic outlook on innovation: generate more and more ideas, and the best will surely rise to the top. Said another way, when looking for a needle in a haystack, the best approach is rarely to add more hay. The problem is knowing which ideas to pursue. The goal of innovation activities shouldn’t be to collect as many ideas as possible, but instead to get to the right ideas—the ones that matter most to the people you serve. But more than that, the real challenge is in overcoming the natural forces in organizations that keep good ideas down. Chief among these is uncertainty, a leading deterrent to innovation. New ideas are a gamble for risk-averse managers, even if well-expressed in a high-fidelity prototype. JTBD provides a way to increase your chances of success by first identifying the right problem to solve. Then JTBD gives you decision-making criteria for moving forward: bet on solutions that address unmet needs to create profitable differentiation. Focus first on getting the main job done for the individual and fulfilling their needs in relation to the job. From this perspective, hackathons and other idea-generating efforts can be framed by JTBD as both inputs and outputs in terms of how concepts are evaluated. After understanding the job landscape and defining the value you’re going after, you can continue using JTBD thinking to align teams around the design of your solution. Create a roadmap based on your JTBD landscape to set a common direction. Then use job stories to get everyone on the same page and tie local design efforts to the big picture and to architect the solution structure. JTBD can also guide the experiments you conduct to test your team’s assumptions. Create a Development Roadmap At its highest level, a roadmap is a sequence of development events—the relative chronological order in which features and capabilities will be built. Roadmaps serve as a central point of reference for teams to align their efforts. They show the path forward without defining individual tasks. In the age of Agile and Lean efforts, roadmaps have gotten a bad reputation. People are quick to point out—and rightfully so—that long-term plans inevitably fail: priorities change, unforeseen challenges arise, and timelines slip. The solution, they might argue, is to have no long-term plans and to work on short initiatives with the flexibility to change as needed. But while providing decision-making power to local development teams makes sense, overall alignment is still needed. An alternative way of viewing roadmaps is to see them not as a definitive project plan, but as a vision of how you’ll create an offering that customers will value. Roadmaps are not unchanging predictions of future activity, but a way to provide transparency for the sequence of steps your team will take to design solutions. The information in a roadmap helps the entire organization get aligned, not just developers. It’s a strategic communication tool reflecting intention and direction. More importantly, road mapping isn’t just about the artifact: it’s about getting a common understanding of where you’re headed. In this sense, the roadmap occupies the space between the vision and detailed project planning. JTBD can help create roadmaps that focus on the value that the organization intends to create and deliver for customers. The trick is to get the right problem to solve. Use the insights from your JTBD investigation to formulate roadmaps that are grounded in real customer need. Mapping the Road Ahead For a concrete approach to road mapping, I recommend the book  by C. Todd Lombardo, Bruce McCarthy, Evan Ryan, and Michael Conners.  In it, the authors clearly articulate the steps to creating meaningful product roadmaps. JTBD plays a key role in aligning to customer needs, as the authors write: “We recommend starting with the chunks of value you intend to deliver that will build up over time to accomplish your visions. Often this is a set of high-level customer needs, problems, or jobs to be done.” Their approach breaks down the four key elements of a good product roadmap:  The vision outlines how your customers will benefit from your offering. How will the job performer benefit from the solution? What will getting the job done look like after the solution is in place?  A roadmap must be aligned with the organization’s strategy and objectives. The goals of the business are important for measuring progress.  Rather than committing to specific dates, good roadmaps sequence work and set broad timelines for completion.  These are the key problems that customers face when completing a job, or clusters of needs that align to the overall solution to be created. JTBD helps frame the themes of your roadmap in particular. Figure 5.1 shows an example from their book of a basic roadmap overview for a fictional company, The Wombatter Hose, illustrating these main components. Note the disclaimer, as well, indicating that the roadmap is subject to change. Putting it all together, the process for creating a JTBD-driven roadmap can be broken down into four phases. Define the various elements of your overall product strategy to get agreement on how you’ll be using them. In addition to your solution vision, also define the following together with the team:  What are your business intentions? The mission is about what your organization wants to ultimately achieve.  What are your beliefs and ideals? What is the philosophy of your organization and solution? Values define the philosophy of the team and what it believes.  What are the specific goals your offerings will accomplish for the organization? Frame these in terms of outcomes, not outputs. Next, decide on the customer needs to pursue. Here, the authors of   stress the importance of grounding the roadmap in actual customer need. JTBD is central to this step. They write: “Identifying customer needs is the most important aspect of your roadmapping process. Roadmaps should be about expressing those customer needs. Therefore, most items on your roadmap will derive from a job the customer needs to accomplish or a problem the customer must solve.” As outlined in Chapter 2, “Core Concepts of JTBD,” needs are hierarchical—from high-level aspirations to main jobs and sub-jobs to micro-jobs. Figure out the top-level jobs to explore and then drill down into the specific themes to target. The “value themes,” as they are called, might come right from the job map. Locate the areas of highest underserved needs and use those stages as the categories of your roadmap themes. Or you can cluster needs to form themes that don’t necessarily follow the chronology of the job map. The important point is to ground the division of the roadmap in real-world observations of the customer’s job to be done and align the timeline to it. Next, create a sequence of value themes that your team will work toward. Timelines can be absolute, relative, or a mix of both. Absolute timelines with specific dates carry the risk of changing, which, in turn, can cause confusion or missed expectations. Relative timelines give more flexibility but still provide insight into what’s coming and why. There are various terms to use, but the timeline is often broken into three phases for near-term, mid-term, and long-term. Examples include “now, later, future” or “going, next, later” or something similar. Find what works best for you. Finally, conceptualize specific solutions to design and create. Use job stories to tie the overall project intent to customer needs, outlined in the next section. Then conceptualize solutions around getting the entire job done or the parts of it determined to be most strategically relevant to your business. After a roadmap is created, you may then need detailed project plans to track progress. A simple Kanban board can serve that purpose in many cases. Or, for more complex software development efforts, tracking software may be needed. In Agile efforts, epic planning and then sprint planning come after you have an overall roadmap. Tying the overall plan to customer needs gives the design and development teams the feeling that they are building something that matters to customers. Staying focused on customer needs helps avoid building things your customers don’t want. The nature of a job stays the same, even as features may shift. Grounding the roadmap in JTBD ensures that both its longevity and ability to absorb will change. Learn More About This Play Lombardo, C. Todd, Bruce McCarthy, Evan Ryan, and Michael Conners.   Sebastopol, CA:O’Reilly, 2018. This book distills a wealth of practical information into a compact guide on roadmapping. The authors go to great lengths to provide numerous examples and stories from real-world cases. They use a realistic, modern approach for creating a roadmap that is driven, in part, by JTBD. Align Teams to Job Stories Agile development enables teams and organizations to work in a flexible way. The approach started in software development, but has spread to other domains, including government and the military. The principles of Agile development can apply to just about any field. A key part of Agile is to break down efforts into individual units of work.   are short descriptions of features and functionality written from the perspective of the end user. Teams can focus on only a small part of the whole and make progress in a controlled way. User stories are commonly written in a three-part format. The first element indicates a user’s role in the system. The second points to a capability that enables the person to get a task done. The last part often describes a benefit or reason for using the capability. Although specific styles can vary, a typical user story resembles something like the following: As a <role> I can <capability>, so that <benefit> Examples of use stories in this format include: As a system admin, I can specify files or folders to back up based on file size, date created, and date modified. As a user, I can indicate folders not to back up so that my drive isn’t filled up with things I don’t need to be saved. As a user, I want to update the name of a document so that I can categorize it. For any given system, there may be hundreds of user stories. Some can be quite granular, such as describing a single button and why a user would click it. Stories are then organized into a backlog or repository of functionality to be built. Teams break off logical groups of user stories in sprints or two- to four-week cycles of work. Job Stories Although user stories are good for breaking down work, they typically fail to connect the solution being built with user needs. They lack an indication of   someone would behave in a certain way and what they need to get a job done. In fact, often user stories are derived from the capability being built, not from observing actual behavior.  are an alternative to user stories. They follow the tradition of breaking down efforts into smaller pieces, but through the JTBD lens. The technique was first pioneered by the product development team at Intercom, a leading marketing communications solution. They wanted to avoid leading designers with a preconceived solution, as well as tying development to the company vision and strategy. Paul Adams, an Intercom product manager, wrote about job stories for the first time, saying: “We frame every design problem in a Job, focusing on the triggering event or situation, the motivation and goal, and the intended outcome.” As a result, their job story format also has three parts. But instead of focusing on a generic role, like a “user” or an “admin,” job stories begin with a highlight on the situation and context, not the individual: When [situation], I want to [motivation], so I can [expected outcome]. Examples of job stories include: When an important new customer signs up, I want to be notified so that I can start a conversation with that person. When I visit someone’s profile page, I want to see how many posts they have in each topic so that I have an understanding of where they have the most knowledge. When I have used the application multiple times, I get nudged to contribute so that I am encouraged to participate. JTBD author and leader Alan Klement has done the most work refining the job story format.  He believes that adding more information about the circumstances shows causality better. Focusing on the context shifts attention from a persona to the situation. Klement advises that you avoid writing vague situations, but instead be as specific as possible. For instance, consider these three possible situations for the first element of job stories: When I’m hungry… When I’m lost… When I want to check my email… Instead, Klement recommends describing the circumstances in rich detail: When I’m hungry, running late to get somewhere, not sure when I’m going to eat again, and worried that I’ll soon be tired and irritable from hunger… When I’m lost in a city that I’ve never been to, don’t know the local language, and am worried that I’ll be wasting my time in places I don’t want to be in… When I want to check my email, but don’t want anyone around me to know I’m checking my email because they’ll think I’m being rude… Each of these example situations provides more context for designing an appropriate solution. Working with Job Stories Job stories are modular, giving designers and developers the flexibility to solve problems in alternative ways. Job stories are grounded in real-world insight, and they are more powerful than user stories in guiding solutions. But creating job stories is more free-form than other JTBD techniques. Still, there are patterns that you can follow. Using the elements from Chapter 2, I suggest the following structure for job stories: Examples: When I am one of the top posters while updating my social media feeds daily, I want it to show on my profile so that I can increase recognition as an expert on the subject. When I run out of materials needed while completing an art project, I want to find alternative materials so that I can maximize the number of uses of my current supplies. When preparing for my commute and running late, I want to know the current weather along my journey so that I can minimize the chance of arriving wet. Consider the last example. The first element combines information about the circumstances ( ) of getting the main job done ( ) within a stage of the process ( ). The second element points to an even smaller step or micro-job ( ). It should be formulated without reference to specific technology, but should be specific enough for designers and developers to create a specific capability. Finally, the last element can be taken right from your list of needs. In this case, the job performer ( ) wants to avoid showing up to the office wet ( ). You can leverage the elements your JTBD landscape already uncovered in research directly in the formulation of the job story statements. In researching this book, I’ve come across various alternative approaches to formulating job stories. Andrea Hill, a prominent advocate of JTBD on social media, suggests a slightly different approach. She sees the middle element pointing directly to a feature or solution of some kind, thus explicitly crossing from the problem space into the solution space. Her basic format is as follows: A job story for the previous example of commuting to work might then look like this: Steph Troeph, research and JTBD instructor in the UK, approaches job stories in yet another way. She thinks of them with this formula: Regardless of your interpretation, the key is to find a consistent structure and stick with it. The form you end up with needs to be appropriate to your team and your situation. Jobs Stories in Action Ultimately, job stories tie a local design and development effort to a broader JTBD framework. Because the format of job stories includes contextual details, they are portable. In other words, a job story should make sense without having to know the larger JTBD landscape or job map. As a result, job stories have a more “plug-and-play” versatility that is often required for Agile designs and development teams. For instance, Agile planners can manage a backlog of job stories much in the same way that they would manage user stories. If a given sprint gets slowed down or changes direction, stories not addressed can be carried over to the next sprint. Having a smaller, self-contained description of the smaller job to be done has advantages during the design and development phases. But to be clear: I have found that job stories typically   replace user stories for development completely. Instead, job stories guide and frame the conceptualization of a solution rather than track implementation. They serve best as a design tool to create or determine concept direction and design. Developers and engineers will likely still need user stories to measure the burndown rate and overall progress. Your job map provides an overall orientation to your JTBD landscape and allows you to zero in on a specific area for design and development. A roadmap gives you a high-level sequence of development with the rationale for planning activities. Job stories are more specific and guide the local design and development of features and capabilities. Follow these steps to create job stories based on your JTBD research: Base the relevant jobs and circumstances on previous interviews and observations. For each area of development in your solution, consider the steps in the main job. Then drill down and list the smaller and smaller steps as micro-jobs, using the rules of formulating JTBD. Also identify the circumstances that apply to that part of the main job in particular. Depending on the depth of your prior research and how well you and your team understand the job, you may not need to do more research to create and validate job stories. It’s never a bad idea to speak with people again and drill down on specific problems and objectives they have. During additional interviews, ask “how?” until you get more granular in understanding of subgoals and objectives. As a team, write job stories that are specific to your design and development effort. Decide on a consistent format for the job stories and stick to it. Strive to come up with unique, mutually exclusive stories that target specific jobs and circumstances. Avoid redundancy. For instance, in the previous example, you probably don’t need separate stories for commuting by train versus commuting by car. Develop the job stories that matter the most and focus on a limited set. You may end up with anywhere from three to eight job stories per project or sprint. Make job stories visible and transparent to the entire team to solve for the job stories. For instance, post a relevant list of job stories in a brainstorming session for everyone to see. Or list job stories at the beginning of a design critique so that the team has context for making comments. Use JTBD to guide design and development decisions. It’s also possible to then use the job stories to review the appropriateness of your solutions. First, the design team can use the job stories relevant to a project as heuristics. They should constantly ask if their designs are meeting the user’s goals set out in the job stories. Then you can test solutions with users against the job stories. Show users your solutions (e.g., as a mock-up or prototype) and ask them how well each addresses the job stories. This can be done in an interview-style fashion or with a survey. The job stories ultimately become a measure for success of the designs before anything is built. Job stories let you take a step back and look at the context of the job while designing a product or service. In this respect, job stories fill an important gap between the observations of customers and solution development, connecting insights into customer needs to individual features and development efforts. Related Approaches: Needs Statements Design thinking is a broad framework for creative problem solving. It is rooted in human-centered methods that seek to develop deep empathy for people and then to devise solutions that meet their needs. In design thinking, it is important to define the problem to solve before generating options for solutions. One technique to encapsulate insights from research is to generate  , greatly resembling job stories in form. But these statements differ from “needs,” as defined in Chapter 2, in that need statements in design thinking are not specifically limited to the outcomes of a getting a main job done, and they can be aspirational in nature. Need statements in design thinking also tend to be much more focused on a persona or an individual rather than the circumstances. For instance, writing for the Norman Nielsen Group, Sarah Gibbons refers to need statements representing a point-of-view for the user of a system:  “A user need statement is an actionable problem statement used to summarize who a particular user is, the user’s need, and why the need is important to that user.” Like job stories, need statements have three components: a user, a need, and a goal. The   corresponds to a goal-based persona based on research (as outlined in Chapter 4, “Defining Value”). A   is expressed independent of a feature or technology. The   is the result of meeting the need. Gibbons provides an example: Alieda, a multitasking, tech-savvy mother of two, needs to quickly and confidently compare options without leaving her comfort zone in order to spend more time doing the things that really matter. Note that the insight at the end of this statement, “doing the things that really matter,” is very broad and hard to measure. Job stories, on the other hand, favor a more specific context and outcome. For instance, rewriting the above example through the lens of job stories might yield something like the following: When I’m multitasking and in a rush, I need a familiar way to quickly and confidently compare options so that I can minimize the time spent on finding a solution. Like need statements in design thinking, job stories also avoid the mention of features or technology. Yet, they are much more specific to a given job and its context. While both a need statement from design thinking and a job story can feed into the creative generation of solutions, job stories will provide more direct guidance without prescribing a solution. But the definition of a   in design thinking can vary greatly. For instance, IBM’s Enterprise Design Thinking approach also includes guidelines for generating statements.  Not surprisingly, there are three parts: a user, a need, and a benefit. Here’s an example from the IBM site: A developer needs a way to make sense of minimal design so that they can prototype faster. This example is much more specific than Gibbon’s approach, yet still avoids mentioning a specific solution. There are no aspirational elements, such as “pursuing lifelong dreams,” sometimes found elsewhere in design thinking. IBM’s approach to need statements is closer to the job story approach, but is also light on describing the circumstances of use. In some sense, the differences between job stories—even with the variations in format—and need statements points to a key distinction between JTBD and design thinking. The former focuses much more on the circumstances than the person’s state of mind or psychology. Where design thinking seeks to gain empathy for the individual as a starting point, JTBD seeks to understand the circumstances of accomplishing an objective before factoring in emotional and personal aspects. Learn More About This Play Klement, Alan. “Replacing the User Story with the Job Story.”   (2013); “5 Tips for Writing a Job Story,”   (2013); “Designing Features Using Job Stories,”   (2015). Klement has done the most extensive work to develop the job story technique. These three articles outline the basis for creating them. The technique has evolved slightly, but Klement points clearly to how he’s updated his approach. Klement and others have posted widely about their use for development efforts, but start with these resources. van de Keuken, Maxim. “Using Job Stories and Jobs-to-be-Done in Software Requirements Engineering.” Thesis, Utrecht University, 2017. This thesis project offers a detailed investigation of how job stories are applied to date. After illustrating the history of job stories, Van de Keuken presents the results of his original research variations in application of job stories as seen in practice. This work contributes greatly to making job stories a more formal part of software requirements engineering. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/figure-it-out/", "title": "Figure It Out", "content": "Color is, without a doubt, the visual element most often misunderstood and misused. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As mentioned earlier, when designing visual representations, color is often the first visual encoding that people use. It’s also quite limited to about a dozen, distinguishable colors. It’s a potent visual element, but one fraught with accessibility and perceptual problems. A general rule of thumb: . Start with grayscale representations. Add in color only later, where it might be really, really useful. That’s it. We can move along. Except… We need to dispel some popular beliefs about colors, beliefs that are often held up as truth, when, in fact, this is not the case. What’s presented in this short chapter is more foundational knowledge than tips for immediate application. But also, this understanding of color is—we found in retrospect—a powerful lens for understanding the concepts shared throughout this book. We see in our exploration of color this pattern: while many of the absolutes we cling to are social constructs (varying across cultures and over time), behind these changing constructs we also find some universal human constants. How Many Colors Are in the Rainbow? Let’s begin by unpacking the statement above, suggesting that we only see about a dozen colors. Actually, the human eye can perceive many more colors, perhaps a million or so. Of this million, it’s estimated that each of us—individually—can distinguish somewhere between 130 to 300 colors.  But within a cultural group, we can only share about a dozen such colors. These limitations have little to do with personal visual acuity, but rather with language: a group’s ability to see and perceive a specific color is determined by language. Do we—as a society—share the same named color value associations? We can talk about something being “ ” and feel confident in what we all see. From both a developmental perspective and an anthropological perspective, red is the first color (after white and black) that most cultures are aware of. But if I describe something as  , do we have a shared agreement as to what that named concept refers to? Perhaps you see hot pink where I see a vibrant, purply-reddish color? Another example of this language-color dependency: the Russian language has a specific word for the color that we (English speakers) perceive as light blue. To put this shared vocabulary into perspective, let’s start with something that is constant and beyond our language: the visible spectrum of light that is a rainbow. When Colors Are Constant Around the world, the meteorological phenomenon we describe as a rainbow is a constant thing. Light refracts across water droplets to create a spectrum visible to humans. What we see as colors are the wavelengths of light visible to the human eye (see  ). On either end of this visible spectrum are ultraviolet and infrared waves, which while invisible to human eyes, we know they   visible—that is, seen—by cameras and some nonhuman creatures (cats can see certain infrared frequencies, for example). Beyond this visible spectrum, we have things like gamma rays, X-rays, and radio waves, which all make up the entire spectrum of white light from the sun. But let’s stay focused on the portion of this light spectrum that is visible to humans, the part that allows us to see. Within this spectrum, the rainbow possesses millions of color combinations, as there are no clearly defined boundaries between the colors. Why then, should diverse cultures over thousands of years arrive at the same set of color language definitions? Are colors an absolute thing? Not exactly. The Subjectivity of Color Identification Consider “ROYGBIV,” which is the acronym we all learned to name the colors of the rainbow. How did we conclude, at least in Western cultures, that a rainbow has seven colors? Why not five, or six, or eleven? We have Sir Isaac Newton to thank for this. These seven colors—red, orange, yellow, green, blue, indigo, and violet—were not the result of any serious scientific inquiry. Rather, Newton was fond of the number seven. Just as there are seven musical notes in a scale, Newton believed that colors should follow a similar pattern. He might have connected this with seven days in the week or the seven known planets (at the time) in our universe. In other words, ROYGBIV was an arbitrary choice based on mystical superstition. Understanding how we arrived at these seven colors sheds light on the subjective nature of color identification. This may also explain a bit about the challenge that so many people have with indigo—that odd color that sits somewhere between blue and violet—as a separate color! But here is where we have to be careful, as we are stepping into a decades old debate: Do the number of basic color terms and the location of color category boundaries vary across languages? Or might there be a universal pattern to the color naming systems of all cultures? This Wikipedia entry sums up the debate rather nicely: There are two formal sides to the color debate, the universalist and the relativist. The universalist side claims that the biology of all human beings is all the same, so the development of color terminology has absolute universal constraints. The relativist side claims that the variability of color terms cross-linguistically (from language to language) points to more culture-specific phenomena. Because color exhibits both biological and linguistic aspects, it has become a deeply studied domain that addresses the relationship between language and thought. An Argument for Relative Linguistics We can characterize what Newton did as imposing an arbitrary number of colors upon the color spectrum. And we might conclude the same thing has happened throughout history as different people groups formed words to describe the world around them. Indeed, various studies of diverse cultures reveal that “although the physiological basis of color vision is essentially the same for all humans with normal trichromatic color vision, there is considerable diversity in the way that different languages segment the continuum of visible colors.”  In other words, the rainbow has no natural boundaries; how we slice it up into colors is a subjective thing that varies across different cultures and time. (See   for an illustration of this concept.) From one research paper, we learned that “some languages have been reported to use as few as two terms to describe all visible colors (Rosch Heider, 1972). Others have been reported to use between three and eleven (Berlin & Kay, 1969), while some (e.g., Russian; Davies and Corbett, 1997) may have twelve.” Specific examples in support of this argument:  In Russian culture, there is no generic concept of blue. Rather, Russian makes an obligatory distinction between lighter blues ( ) and darker blues ( ). The Japanese language (before the modern period) had just one word, , for both blue and green. It wouldn’t be until the year 1,000 that the word   would be introduced to distinguish a greenish shade of blue The Himba tribe from Namibia recognizes five basic colors. The Berinmo of Papua New Guinea has also reached a different conclusion as to the number of colors they recognize. While they draw no distinction between blue and green, they do “draw a distinction within what English speakers would consider yellow, with the word   on one side and   on the other.” From this, we might conclude that the colors of the rainbow do seem to be arbitrary and dependent upon language. (Connect this with earlier points we made about thoughts and cognition as layers upon layers of prior associations.) But surely, you may be thinking, color identification isn’t entirely subjective? Here’s where the research gets interesting: despite these regional differences, a fascinating and consistent pattern begins to emerge. An Argument for the Universal In the late 1960s, after studying color terms across many different languages, researchers Berlin and Kay introduced the idea that there were eleven possible basic color categories: white, black, red, green, yellow, blue, brown, purple, pink, orange, and gray. They argued a universalist theory: that color cognition is  While their research has been challenged on different grounds, what has since followed is some agreement that for all noted language differences, there is a fixed order in which color names arise. The ways in which color language evolves across cultures suggest maybe there is a universal pattern governing the direction of patterns in the evolution of colors. All cultures start with the ability to distinguish dark things from light things. This is followed by the recognition of red. After that, it might be the addition of yellow or green. And blue always seems to come last. Not every language follows the exact same path, but they adhere to this same general pattern. While the broader debate is not necessarily concluded, the general consensus seems to be that “in color, relativism appears to overlay a universalist foundation.” Why All the Fuss over Color? While this is certainly fascinating, how is this useful? We include this as a mirror to challenge assumptions. If we turn a critical eye to the commonly accepted color wheel, this was likely influenced by Newton’s original color wheel sketch. But is this the “right” way to think about colors?   We learn this from an early age and accept this way of thinking about color as absolute. But this is just one frame. This is just   of thinking about visible light. And this singular perspective has limitations, especially when used in medical, scientific, and engineering visualizations. Research papers such as “Rainbow Color Map (Still) Considered Harmful”  question the value of the rainbow color spectrum in data visualization applications. The point is simple: there are other ways we might think about color. We can look at alternatives such as perceptually ordered color spectrums, an   color map, or simply use representations of color that aren’t derived from a wheel. Tools such as ColorBrewer 2.0  or the NASA Ames Color Tool  are incredibly useful for choosing a palette more suitable for visualizing data. Since this book is concerned with how human creatures understand information, and because we so often use color to clarify, we felt it worth calling out that color and color recognition are not necessarily universal things, but are dependent on cognition, language, and biology. Understanding this allows us to challenge common assumptions about what is “true” about color and perception. Which leads us to… Color, Cultures, and Universal Associations Red means stop. Green means go. These concepts are universal, right? Not so fast. Across cultures, colors do not necessarily convey the same concept. And where we may have the same ability to identify a color, the associated meaning is just that—a learned association. Concluding that red means passion, vitality, or energy, because blood and fire are red things is   a universal idea. Neither is associating green with growth, just because nature involves so much green. (In some Chinese cultures, green can be associated with death.) At this point, please throw away those blog posts and posters about colors to choose for different cultures. While we’re keen to seek out human universals, color has proven to be something that does not have consistent meaning across cultures, or even within a culture group. Rather, the concepts we associate with particular colors are highly contextual and local, not just to a particular culture, but sometimes to smaller social groups. The meanings we point to—blue as a safe, corporate color, for example—are highly generalized assumptions, highly contextual, and mostly learned associations. The Color Purple Let’s take purple, as an example. For many centuries, purple dye was expensive and rare. Procuring purple dye was labor intensive and required collecting a secretion from sea snails. Historian David Jacoby remarked that “twelve thousand snails of Murex brandaris yield no more than 1.4 g of pure dye, enough to colour only the trim of a single garment.”  As a result of this laborious process, the high cost of producing purple clothing made this color a status symbol among kings, queens, and other rulers. If you could afford to wear purple, you were quite wealthy. The conceptual association then is one of scarcity (in this case of a particular dye), signaling something to be valued above other things. While we may still see the lingering effects of this history (the Purple Heart is among the highest honors awarded for U.S. military service), the constraint of purple as a scarce color is no longer true. As such, this color is able to take on new meanings. “Pink Is for Girls, Blue Is for Boys” To put this into perspective, let’s investigate the idea that “pink is for girls, blue is for boys.” From clothing choices to marketing toys to how we decorate bedrooms, most of us grow up believing there’s some inherent gender association built into the colors pink and blue. But, were we to travel back in time—just over 100 years—we’d find no such distinction. Or we might find the opposite association. According to University of Maryland historian Jo B. Paoletti, author of  , pink and blue weren’t always gender-specific colors. For centuries, young children mostly wore a functional white dress, and then in the early 20th century, things began to change. Consider this quote, pulled from the June 1918 issue of Earnshaw’s Infants’ Department, a trade publication: The generally accepted rule is pink for the boys, and blue for the girls. The reason is that pink, being a more decided and stronger color, is more suitable for the boy, while blue, which is more delicate and dainty, is prettier for the girl. A Smithsonian review of Paoletti’s book,  goes on to add: Other sources said blue was flattering for blonds, pink for brunettes; or blue was for blue-eyed babies, pink for brown-eyed babies, according to Paoletti. In 1927,   magazine printed a chart showing sex-appropriate colors for girls and boys according to leading U.S. stores. In Boston, Filene’s told parents to dress boys in pink. So did Best & Co. in New York City, Halle’s in Cleveland, and Marshall Field in Chicago. By the 1940s, this association had flipped. Manufacturers had settled on pink for girls and blue for boys (see   as an example of this association). Baby Boomers were raised with wearing the two colors. The point of this narrative? Color associations are learned things and can change over time. Even something as seemingly strong as the pink/blue binary was a manufactured association. To be clear, this doesn’t mean a color association is any less powerful in the moment, at a particular point in history, but these color associations do not represent any universal truths. Accordingly, it’s good to be wary of generalizations such as “blue is a safe, corporate color.” In the case of corporate associations, one generation’s “safe” may—depending on the media and actions—signal stuffy, inauthentic, or distrustful to the next generation. It all depends on the learned associations embraced—for a time—by a particular culture. Not All Colors Are Created Equal We tend to treat our color palettes like interchangeable parts. Just pick a color. Or pick some colors we all find pleasing. Consider how many of us use the default color palettes built into software tools like Excel or PowerPoint. We usually choose a pleasing color palette, with the sentiment being “as long as you can distinguish one color from another, it’s okay, right?” Not exactly. Not all colors are created equal. In terms of visual perception, some colors jump out at you while others recede into the background (see  ). This is because of variances in hue and saturation. A very bright color is going to draw more visual attention than a more desaturated color. This makes sense if we consider how things farther away from us tend to be hazier and desaturated. If something in the distance is noticed, it’s likely because it’s moving or contrasts with the surroundings. This same disparity applies to color hues. We tend to look at color charts like this one and assume that the extreme ends of red, green, and blue are on equal footing. However, because of the wavelengths of these colors and how our eyes perceive color, we see green as brighter than red, which itself is brighter than blue. How Is This Knowledge Useful? While it’s nice to think that precise color values are interchangeable (setting aside any cultural associations), your perception doesn’t work that way. In the same way that certain frequencies on the radio come in clearer than others, certain colors do the same. You need to account for, or at least consider, the unevenness of color perception. In the example in  , you see the same eight-segment pie chart. The example on the right uses all high-saturation colors while the example on the left mixes high- and low- saturation colors. Functionally, these both communicate the same thing. But consider how you   each. With the example on the right, use of high saturation is consistent; no color should be more prominent than another. But when you mix high and low saturation, as with the example on the left, the higher saturation colors tend to “pop” more—drawing you to these segments. While this chart is more aesthetically pleasing (as it uses half as many colors), it’s also a bit misleading—notice how your eye is drawn to the orange segment in the upper right. The lesson? Assuming the goal is objectivity and truthfulness, you’d want to avoid mixing saturations and hues that are unevenly perceived. If the goal were the opposite, to draw attention away from or toward a particular bit of data, you could manipulate perception by adjusting saturation and hue (not that this is being recommended!). This ability to direct attention by using bolder colors is something that everyone should be aware of and intentional about. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/building-the-woke-web/", "title": "Building the Woke Web: Web Accessibility, Inclusion & Social Justice", "content": "What would your life be like without the internet? Not if it didn’t exist at all, but if you were locked out of it? Would your days be different? Unrecognizable, even? Keeping your answers to that in mind, do you think access to the internet is a human right? Do we need to be able to access it to fully participate in modern society? To answer “yes” to these questions would have been unthinkable 20 years ago. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Living without internet Globally, over 40% of people still  . That lack of access and the issues it creates have helped motivate digital equity initiatives like   and the  . Having no access to the internet creates problems in many parts of modern life. In the UK, bank branches are closing, forcing many to do their banking online. Many utilities now require internet access to request or amend services, or get better deals. Civil services, such as registering to vote, are increasingly online. As this continues, people who have no access to broadband or who have limited access to mobile data fall behind—this often includes homeless people, elderly people, and those on low incomes who are already operating at a disadvantage. In the UK, only   are online. Approximately 1 in 5 adults with a disability in the UK have  , and they make up half of the people who have not accessed the internet in the last three months. Globally, the UN target for affordable mobile data is  , and yet many   reaching this goal. Not having access to the internet is expensive, locking you out of essential services and a surfeit of helpful information. Giving people full access to the splendors and knowledge of the online world should be imperative for everyone who works on it. Digital exclusion is when someone is unable or unwilling to access information and services online. In the UK,   in 2018. The number of people in the UK lacking basic digital skills is decreasing, but in 2018, 8% of adults in the UK (4.3 million people) were estimated to have zero basic digital skills, which means they are unable to do things like buy items online, verify information, or send an email.   to have no basic digital skills.  Being unable to send an email, submit an application online, or use a government site is a huge barrier to civic and societal engagement. Shopping in person, rather than online, can mean you are   by as much as 13%.  .  Being able to access the internet has social and psychological ramifications too.   as a risk factor for a number of health issues, as well as early death.   you feel less alone. Half of all people with disabilities surveyed   in the UK, and a quarter of them are lonely every day.   to be a captive audience to apps and websites using their data inappropriately or engaging in other unethical practices.   to interact with other people with disabilities, because they lack the tools to visit other sites, or lack other suitable websites or apps to use. Richer households are more likely to have full basic digital skills. The UK Office for National Statistics found that   are three times as likely to be in low-income bands. In 2018,   on a tablet or computer, which 68% of them said made it difficult to do homework. Further,   make up half of those living in poverty in the UK. Provide non-online options for vital services If you work in government, food supply, healthcare, or utilities, there is no excuse for not providing offline options. In doing so you are excluding some of the most marginalized people. The internet is amazing, but it is not the only way to share information. A non-exhaustive list of other barriers Having access to the internet in the first place is one issue, and feeling welcome, or even safe is quite another. Even when your broadband connection is as good as can be hoped for, there are many other ways you can be discouraged or stopped from using the internet. Trolling and threats Online harassment is one of many barriers stopping people from accessing the internet. Diane Abbott, the first black woman Member of Parliament (MPs) in the UK,   in the run-up to the 2017 General Election that decided how voters would be represented in Parliament and which party would govern. Black and Asian women MPs got 35% more abusive tweets than white women MPs. The abuse directed at Dianne Abott amounted to 10 times as much as was received by any other female MP, according to an  . Mermaids is a charity that supports transgender children and their parents in the UK. Their CEO Susie Green—herself the parent of a transgender child— . The rise in abusive and threatening comments led to Mermaids’ Twitter account having to  . Trolling isn’t an easy problem to fix. Allowing users to block certain words and hide certain replies on Twitter is a start, but listening to people from marginalized backgrounds and their complaints and ideas would be another critical place to begin.  We need to think long and hard about what good moderation looks like and what guidelines work in online spaces to ensure those accessing them don’t have to wade through a tide of bigotry. Sidelining and hiding certain groups Information and support online are vital for at-risk LGBT people, whether to help them escape dangerous situations, access support, or find community. Yet in schools, words relating to LGBT issues are  . On YouTube, v . This isn’t because the content is sexually explicit or not safe for work. It’s just discrimination. TikTok recently admitted it actively discriminates against certain kinds of users—namely the  ,  —in certain feeds, under the guise of paternalistic protection from bullying. Exclusionary design Many people with disabilities rely on screen readers and screen reader compatible sites to use the internet. Screen readers can be prohibitively expensive; while there are free options, one of the most popular screen readers at the time of writing   for a professional license. Even with  , there’s more that everyone else can do. In their February 2020 evaluation, WebAIM found that   had detectable WCAG (Web Content Accessibility Guidelines) 2 errors. The most common WCAG 2 failures—such as missing alt text for images, having empty links, and missing form labels—would be relatively simple to fix. Because they’re shared among most websites, concentrating on fixing them would have a huge overall benefit for the internet. But as long as web accessibility standards are applied without rigor, aspects of a vast number of sites remain inaccessible even once users have a screen reader or other assistive technology. Hostile conditions Inclusion is just as pertinent as accessibility, and tackling only one side of the equation will leave some people just as locked out. Accessibility without inclusion is not real accessibility. The  , wherein improving access for people with disabilities improves access for all, isn’t the only reason to increase web accessibility. We have a moral responsibility as tech workers to use any privilege we may have to facilitate, respond to, and support the efforts of marginalized people who are working to carve out accessible spaces for themselves. Hostile conditions, created or reinforced by engineering and design choices, make being on the internet harder for people who are  . They make it more difficult to access life-saving spaces, social spaces, and civic spaces—both on and offline. Thorough accessibility and real inclusion are the solutions to these problems. To survive, marginalized people must work both against and through the abuse and accessibility issues they face on online platforms, whereas everyone else gets to use the internet as they wish. This replicates the injustices of offline in the online world. An incomplete list of solutions Center the voices and experiences of the marginalized There isn’t one easy solution but to start finding the solutions that are possible we need to center  . Marginalized people with insights to share aren’t hard to find when you start listening. They are your next users, your future developers, your fledgling marketing team. Excluding them reduces your options, your appeal, and your breadth of ideas. Hire teams that are diverse on every axis Hiring inclusively creates teams full of people who aren’t like you or each other. And those kinds of teams build better products, bring better ideas to the table, and better reflect the user base of the majority of products. It is important to remember that diversity isn’t just about race or hiring women; there are neurodiverse people, people with physical disabilities, people of other genders, people from various backgrounds, and many other marginalizations than could be listed here. Proactively promote inclusion and harness your team’s diversity Help disabled and otherwise marginalized people both develop and enforce policies and practices that protect them and allow them to thrive. If there are no disabled people, or otherwise marginalized or underrepresented people on your team, take a hard look at your hiring practices, your work culture, even the layout of your office. If you can’t find these problems, hire experts. Pay specialist consultants and recruiters to root out the problems. This is an investment that makes moral, logical, and business sense. The inclusive team you build will be able to spot potential issues in a way that a squad of people who pattern match to narrow ideas of what a tech worker should look and behave like never would. Create a culture where the marginalized members of your team feel supported, feel heard, and are buoyed through their work with a sense of safety in their workplace. Avoid legal issues preemptively  and   were both sued under the  , which contains provisions to force the companies involved to change their websites. Beyonce’s case is still in progress, but Domino’s both lost their suit and had their appeal tossed out. Both cases were about visually impaired people being unable to access their sites and complete purchases. Accessibility is often seen as a costly detour from the “real work” of building projects, but that has never and will never be true. You want users, and users of all stripes want to use your products. The banks HSBC, Metro Bank, and Halifax made it hard for visually impaired users to access all of their services online. When HSBC was told they had made it difficult for a user with visual impairments to access bank statements,   The   in the UK means that these users can sue. In addition to serving the far more important goal of providing people with disabilities equal access, embracing inclusive design from the outset would have saved these companies time while enhancing their trust among the public rather than putting it at risk. Fixing the content is usually much  . Advocate for accessibility and inclusivity in any way you can, be it big or small Caption your videos, Instagram content, Facebook photos, Twitter photos, conference and meetup talks, etc  Make information needed to access your product or service available in multiple formats. Speak up against problems in your workplace; if an internal hiring tool is hard for you to use, it is hard for others. If one of your websites has errors from WCAG 2’s list, advocate for taking time to fix it. If the gender options available on forms are “man,” “woman,” and “other,” speak up yourself, tell your manager, question whether you need to collect gender information at all. Don’t stay silent. Test your website with tools, devices, and real end users Run tools like  ,  , and   during your build processes. Do manual testing with the actual devices that are used by your end-users, and test with real users with access requirements. If you’re a team of one or a few, ensure that you run these tools from MVP to finished product—the errors that are the easiest to catch and fix will mostly be caught by automated tools, and they are a great start for learning more about accessibility. Websites such as  , and there are  , Slack groups, Twitter accounts, and newsletters that are also incredibly helpful for answering any questions. The automated tools will give you the keywords to search for. Working towards an accessible, inclusive internet Web accessibility is not an optional extra. What inclusion looks like in practice will depend on your products, your users, and what you intend to achieve, but for it to be real and meaningful in any context, it cannot be an afterthought. Engineering that makes inclusion an afterthought is engineering that operates without morality and in doing so actively enacts harm. The fact that this kind of engineering is commonplace on the internet doesn’t make it OK. It just highlights that the way we have built the web is fundamentally broken. We can do better. “Wokeness,” at least as conceived by those divorced from the black experience and  , isn’t a great concept. The way it is used in popular culture makes it sound as if being a good person is a switch you flip on and off; you’re woke or ’sleep. But wokeness is not the end state, it’s the beginning of a journey. All the tenets of intersectional feminism, web accessibility, and diversity and inclusion are inextricably tied up in making the web a better place, for all and by all. Access to the internet is essential. Staying woke, and acting on that wokeness, is what will lead us to a better internet for everyone. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/a-designers-life-with-color-vision-deficiency/", "title": "Color Craft & Counterpoint: A Designer’s Life with Color Vision Deficiency", "content": "So, what is it like to be color blind and also work in the web design and development industry? I’ll answer that question throughout this article, but it’s something that’s always factored into my thoughts, given my passion for design and now my career. I wonder if having “normal” vision would have made me a better artist growing up. Would it make me better at my job now? Would I have pursued a more design-oriented career, as opposed to one that’s more dev-focused? These are just some of the things that pop into my head. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As to my job and my color vision, no, colorblindness doesn’t affect my work as much as you’d think. During design meetings, I can quickly point out areas where we need to reconsider our color palette. While reviewing layouts, I’m able to explain why we need to evaluate how—and if—we’re only conveying information with color. I like that I can bring a singular perspective to the table and a voice for others like me; I am able to offer insights that others don’t necessarily have.  When you can see a larger set of colors, it’s easy to gloss over those issues because they’re functionally invisible in the moment. If a design team doesn’t have a member who sees color differently, it’s important they find a way to test with actual users who do. There is no substitute for the real thing.  Between workarounds anyone can use when color-sensitive situations crop up, and knowing how to separate myth from actual, smart usability practices for vision differences (and which design tools to use)—I want to set the record straight on a few things about designing with color and designing for color accessibility. What it means to be color blind The term  , or CVD, more accurately reflects the type of impairment I have. When someone hears that I’m color blind, most immediately think that I can’t see colors whatsoever—that my entire field of vision is in grayscale, that I’m truly color  . The term is very misleading and confusing because most people living with CVD are able to see many colors. (There   people who have a type of CVD called “ ,” which is complete color blindness. About 1 in 30,000 people are affected, and they see the world in shades of gray.)   Red-green color blindness is the most culturally-familiar type, but CVD is a lot more interesting and varies far more in definition. So what colors   you see? I have been asked this question more times than I can count. My answer is always the same: it’s practically impossible for me to say. For me personally, colors become harder to distinguish the less bold they are. I can attest with absolute certainty that the sky is blue, a stop sign is red, the grass is green, and Big Bird is yellow. I can   those colors because—whether by design or by mother nature—they’re bold. But start placing certain colors adjacent to each other, and it becomes more difficult for me. There are no colors that I   see, rather, certain colors become muddied and start blending together. It’s not the same for everyone; that’s just my version of CVD. As light sensors go,  . Truth be told, they’re subpar compared to most species. WE are dismally color blind—as a species.  On top of that, normal, “accurate” color vision varies from person to person; only minor anatomical differences determine whether your eyes are normal, “color blind,” or have extra (!) color vision powers. Let’s unpack all of that. Without getting too technical, what I can tell you is that our retinas are responsible for our color vision.  : rods and cones. Rods are primarily responsible for reading brightness/intensity levels, while cones are more specialized for detail and for picking up a particular range of light wavelengths. A person considered to have normal color vision has three types of cones, one each for bandwidths of short, medium, and long wavelengths of light. The bandwidth each cone can perceive is shaped like a bell curve and is unique to   cone inside   eye, and there are overlaps between cones. Cones also don’t actually correspond to specific colors, but because long wavelengths fall more toward the red part of the spectrum, medium wavelengths hover closer to green, and short wavelengths tend toward blue, you’ll hear them called red, green, and blue cones, due to sheer convenience (Fig. 1). Color vision deficiencies occur because one or more of these cones is missing or has limited sensitivity (such as a narrow range), or when color perception in the brain is influenced by various  . This means that those colors in the spectrum effectively “drop out,” but since the light is still there, the brain translates it into   color based on peripheral data picked up by the other cones, combined with its brightness level. Since color vision is based on how our eyes and brain perceive light, and since our eyes have different genetic sensitivities to light, we can say that “accurate” color vision is somewhat subjective. Even people with “accurate” color vision don’t see things exactly the same way.  Some people even have a fourth cone cell in their retinas; “ ” have enhanced color differentiation due to extra sensitivity between red and green. The extra cone actually  , but ongoing studies have suggested that   might still have this fourth type of cone. There are some colors and wavelengths we can’t see because our eyes don’t have the right sensors, but for others, it’s due to anatomical make-up. The lens and cornea physically block very short wavelengths; it’s why we can’t see ultraviolet light directly, even though we have the sensor capability. For people with   (lack of a lens in one or both eyes, whether congenital or due to surgical removal), that’s not a problem; they see the color variations in near ultraviolet light naturally. Inside look at living with CVDs I think each person who has a CVD has their own set of challenges. There are also a lot of commonly-experienced situations, social and professional obstacles, and forms of discrimination and bullying we’re expected to just quietly put up with.  Vision disabilities and color vision differences are often treated as quirky, entertaining phenomena on some mysterious map between normal vision and “blind.” People with CVDs encounter condescending remarks and dismissive treatment as part of daily life. It’s an invisible and misunderstood struggle that doesn’t have to be that way. I want to make a difference, and it fuels my desire to educate people on this topic. Insults and passive-aggressive comments I’ve heard my fair share of passive-aggressive comments about my career choice. Also about my passion for art and design. Because    A question like that is condescending on two levels. One, it’s as if no one should be allowed to be an artist unless they can see colors accurately. And two, it shows a complete insularity or misconstrued awareness about color vision deficiencies. Nowadays, I work primarily as a front-end developer, but early on in my career, I designed web layouts in Photoshop. I didn’t code anything. I didn’t even write HTML. I never had an issue with colors because I was typically starting with a client’s corporate branding guidelines, so I was able to take those colors and use color palette generators to help me build out the look of my designs. I was never called out for making poor color choices, so I felt like I was doing a good job. It wasn’t until I was having a conversation with my boss, a man I looked up to as a professional, when I dropped my guard and mentioned that I was color blind. He then proceeded to question my entire decision to pursue the career I love. For a new professional, it was a pretty rough and demoralizing encounter to sit through and try to process, to say the least.  Justifying my skill set It feels as though I have had to justify my career decisions and my skill set on a regular basis over the years—as if CVD prevents me from being good at my job. By and large, it’s truthfully not something that comes up most of the time in my day-to-day work.  At this point, most coworkers only find out that I have a CVD if I talk about it. Sometimes I even get a kick out of seeing how many months can stretch out before a situation comes along where I can mention it. It’s become an increasingly minor issue over the years, what with updated software and web technologies I can put to use when needed. Life via form factor (or winging it) Think for a moment about ways that color is used to convey information in the world around you. One thing that comes to my mind would be traffic lights. Color is used to let drivers know how they should proceed. No additional information is provided in case a driver is color blind. Traffic lights also use two of the colors most commonly associated with color blindness: red and green. Thankfully, most traffic lights have a common form factor. The top light is red, the middle light is yellow, and the bottom light is green. Even if I couldn’t tell the color, as long as I can tell which light is lit, then I’m able to get the necessary information. Unfortunately, not all designs are created equal; there may be no secondary or supplemental indicator to go by. When something is only conveyed with color, that’s a gap where information can get lost on a large group of people. Everyday social interactions Exchanging stories with others who grew up color blind sounds unfailingly familiar. Most of us have had similar experiences when it comes to people first finding out. As in part Q&A, part dog and pony show. We’re   asked, “What color is this?”   and “What color does this look like?” Then we watch as the person who asked us the question has their MIND BLOWN because we can’t see the correct color. Meanwhile, getting the color correct can sometimes be worse. First, there’s a look of confusion on the asker’s face. They can’t comprehend how we can both be color blind   see color at the same time, which leads to even more questions and “tests.” It turns what could have been a brief exchange into a lengthy and technical conversation, maybe at a bad time or inconvenient location. What I ended up learning is that these encounters will never go away, since most people I come into contact with have no knowledge about color blindness. I can either get annoyed by getting asked so many questions, or I can use it as an opportunity to educate. Getting passed over for jobs The first time I was passed over for a job specifically due to my CVD was when I was a teenager. It was a part-time job after school, and I was told—point-blank—it was because I’m color blind. A position had opened up in the frame shop at a big-box crafts store I’d been working at for over a year. After having been told I was getting the position, my boss somehow found out I’m color blind, then informed me that I wasn’t qualified to work in the frames department for that very reason. That was it, no discussion. I had to watch the position go to one of my coworkers.  That may have been a minor blip on my teenage radar at the time, but little did I realize it was the first of many. Between the discrimination and frustration I dealt with at various jobs over the years, I eventually convinced myself to not tell new employers or coworkers about my color vision deficiency. I wasn’t going to lie about it if I got asked, but I wasn’t going to offer up that information unsolicited. After working in the web industry for many years, I eventually transitioned to a new approach. At this point, I have successfully proven to myself that my color vision deficiency doesn’t negatively impact my job, and that bringing it up via the lens of accessibility makes it more of a natural thing I can discuss with coworkers so we can put it to constructive use on projects. Inside look at how I do my job Relying on tools for help Being a professional front-end developer and designer with a CVD is easier than ever because there are so many tools and resources out there. Professionally, I have relied on color picker tools, websites that offer predefined color combinations, image editing software, and the mere fact that all colors can be represented by a hexadecimal value.  In front-end tasks, I’m able to modify my code editor to suit my needs, for instance. I can use light or dark mode and a wide variety of color themes. I often use high-contrast themes that have been thoughtfully designed for developers with color vision deficiencies. Tools and resources I use regularly: Trello has a nice item labelling feature that takes CVDs into consideration. Not only can users label cards based on color, they can also use stripes, zigzags, polka dots, squiggly lines, and other shapes. Visual Studio Code is my preferred code editor. I’m able to customize the interface with pre-built themes, and I can further modify those themes if I need to. I’m currently using one called Vue Theme, which I feel works really well for me. I choose themes based on what feels like the appropriate color contrast for my specific color vision deficiency. I lean toward dark backgrounds with brighter, higher-contrasting text colors that stand out against the background color. Another one of my favorites is  ’ . Whether it’s Chrome, Firefox, or Safari, I am constantly in the browser’s dev tools. There’s an ever-increasing number of features in dev tools that I can use to get the color information I need. Something I find handy is being able to Shift + click on a color value to cycle through various color formats (3 digit and 6 digit hexadecimal, RGB, HSL, and color name).  — I installed a color picker Chrome browser extension called   to help me quickly grab colors from web pages. It allows me to sample colors from any web page, and provides me with the color in every format. This provides me with a secondary reassurance that the color I wrote in my CSS is truly being rendered. I wish I could trust the code as I see it in dev tools, but occasionally my eyes play tricks on me—I would swear that the color I’m seeing rendered on the screen isn’t the color value in dev tools. When I think that’s the issue, I can just grab the eye dropper and triple-check. I use the   to make sure that the colors I’m using are in compliance with the guidelines. Accessibility and inclusion Statistically, 1 out of every 12 men and 1 out of every 200 women have a color vision deficiency. Across the world,  . Those are significant numbers to factor in, especially if all those users are hampered by usability issues. Color alone can prevent them from completing interactions, receiving pertinent information, and from having the same experience as users with better color vision. That last fact alone is reason enough to pay attention to the concerns outlined here. Color disabilities and the Web Content Accessibility Guidelines The   doesn’t specifically call out color blindness; it simply refers to visual disabilities. However, the Web Content Accessibility Guidelines  . Compliance with the WCAG helps as a first step toward ensuring your site is usable by everyone, regardless of disabilities, but keep in mind that there could be additional factors at play with your site which may be “compliant” but still create difficulties for users. Color contrast For those of us who have a CVD, one of the more prevalent issues is a site’s color  ; trouble with specific colors doesn’t necessarily mean we’ll have trouble with the site.  If a site doesn’t have the proper color contrast ratio (text color on top of background color), then the site’s information may be more difficult to see or understand. WebAIM, a non-profit organization, published reports in 2019 and 2020 outlining  . As of February 2020, 86.3% of home pages tested had insufficient contrast. So, what does that mean? It means that the information on those sites is not being conveyed equally, to everyone. That’s   on the web delivering an unequal user experience to billions of users worldwide on a daily basis. Data visualization Color contrast is not the only issue when it comes to color blindness and accessibility. Data visualization is one area in particular that often relies heavily on color to convey information. It is also a prime example of what the WCAG mentions in their success criteria:  Color is not used as the only visual means of conveying information, indicating an action, prompting a response, or distinguishing a visual element.  I follow a few accounts on Twitter that bring attention to improper use of color in data visualizations. I would recommend getting started with these—they provide a lot of useful information and raise awareness surrounding issues that those of us with a CVD face: . Thankfully, making charts, graphs, and other visual aids color accessible isn’t that difficult. There is no need to remove colors altogether. Just try to use colorblind-friendly color palettes and don’t use problematic color combinations. Make sure all the data in your charts is labeled appropriately so that your readers can get the information in multiple ways.  —a scientific online publication that focuses on large global problems such as poverty, disease, climate change, war, and inequality—has great examples of data visualizations of all types that I would consider to be colorblind-friendly. Whenever possible, I try to provide feedback from the perspective of someone who has a CVD, but I don’t make recommendations for specific color changes; I leave the color choices to those who aren’t color blind. Instead, I describe which elements I find difficult to interpret, and why. I tell them which information is getting lost on someone like me. The hope is that my feedback informs other designers of the need to make charts, tables, graphs, and maps more inclusive. Adding people with a CVD to your team As far as those of us who do have a CVD and work in the web industry: we are just as skilled and knowledgeable about our professions as anyone else, and there are plenty of ways that we can contribute to the visual aspects of projects—  regarding color. We have the ability to review designs and report back whether any information is getting lost due to poor color contrast. We can inform designers if the chosen color palette is problematic. We can be the test subjects for our fellow UX designers during their usability research. There is also another point I’d like to get across here. There is a common misconception that a designer with a CVD doesn’t have the ability to do their job effectively. Hiring managers and other coworkers often make this assumption. Much to the contrary, people with CVDs have ways they work smart to work around their limitations. I mentioned earlier about the different tools I personally use to help me in my job. There are plenty of web industry professionals like me who use features in the tools at their disposal, getting the job done right, and so seamlessly that no one would guess they are color blind. That brings me to a broader point—the importance of hiring people with disabilities. I won’t go into the many, many,   reasons why companies should do that. Rather, I’ll mention some of the benefits from a design perspective.  First and foremost, if you don’t have a disability, then how can you say conclusively that you know your product will work for those who do?  The answer is, you can’t. Not without proper testing. Sure, there are companies out there that can help designers and developers conduct usability tests. But how amazing would it be if you had team members who could provide you with that invaluable feedback throughout the duration of each project? Think about all the knowledge you’ve accumulated about your profession. Think about all of the wisdom you can teach others. Now think about all the knowledge and wisdom that could be passed on to you by teammates living with a disability. Together, you can make your products truly inclusive. Trying to do it separately will always produce and reinforce limitations. Critical CVD tips for your projects Color can enhance the message, but shouldn’t be the messenger. UX and UI designers have within their power the ability to take color blindness into consideration—or to ignore it. You can make sure information is conveyed to everyone, not just people who see color “normally.” That is a great responsibility, with real life-or-death repercussions at stake for many users. For those of us in the web industry, there are specific action items I’d like you to take away from all this. Design color palettes for “everyone” Carefully plan your color palette—not for those who are color blind, but for  . Always keep in mind that ALL the information you provide in your product needs to be easy to recognize and easy to understand by anyone who touches it. We can get too familiar with what we’re doing and forget that information is delivered in multifaceted ways, so we need to be mindful of what’s specifically being conveyed by color.  I highly recommend Geri Coady’s book,  ; it’s a fantastic resource. In it, she discusses color blindness, choosing appropriate color, compliance and testing, implementation, providing alternatives, and she includes some tips and tricks. Don’t assume, and be careful what you ask  Do not assume which colors are difficult to see—actually do the research and testing. At minimum, please  . The reason I say that is because although the ADA doesn’t call out color blindness specifically, it does call out visual disabilities. In the U.S., it is illegal in the workplace (not to mention insulting and unwise) to ask people if they have a disability. In my book, that also applies to color blindness, and while it may not be illegal to ask in non-work contexts, it is definitely personally intrusive.  However, if people volunteer to help you with your testing and they offer up that information about themselves, that’s a different matter. It may also be a good idea to reach out to some companies that specialize in user testing with people with disabilities.  Companies such as   help organizations incorporate accessibility into their daily workflows. They offer tailored training, auditing services, document remediation, and other services to help organizations achieve—and maintain—compliance with   and the WCAG. Test with colorblind simulators AND colorblind users Don’t rely on colorblind simulators alone. I could write an essay about this topic. Those simulators are not accurate enough to give you a proper understanding of color vision deficiencies. Seek out first-hand perspectives  Actually speak to someone who has a color vision deficiency to get their perspective, and listen with an open mind. I can’t recommend this enough. There is no better way to get an understanding of what it’s like to live with a CVD than to hear about it first hand. Stand up for coworkers and users Don’t make light of color vision deficiencies. It’s difficult enough living with it, let alone being an artist with it or trying to make sense of information you literally can’t see. Tools and further reading Accounts on Twitter  Usability and UX  — UX Movement  — We Are Colorblind Organizational resources   Color perception and the brain     Continuing to make progress Loving design is something that has always come naturally to me; I didn’t have to force myself down this path. Growing up, I didn’t know that I wanted the exact job that I have, but by the time I graduated high school in 2000, I knew that I wanted to combine my passions for art and computers.  I’m thankful to have been around long enough to have watched the web community evolve into what it is today. I’m thankful for all the tools that exist to help me do what I love in spite of my color vision deficiency. I’m thankful that color blindness is recognized by the WCAG, and that considerations are made for people living with color vision differences. There is a lot of information out there, and I recommend that people go out and read as much as they can on the topic. If you’re on Twitter, then follow people who have a CVD, or the organizations that deal with it in various ways. There is so much knowledge that can be gained by doing some simple research and adding it into your workflow. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/engaged-excerpt/", "title": "Mr. Roboto: Connecting with Technology", "content": "People don’t always need another human being to experience a sense of connection. The deep emotional bonds many people have with their pets proves this. (So might the popularity of the Pet Rock in the 1970s but that’s just speculation.) Even Link in   had an inanimate companion: his trusty sword (see Figure 9.1). Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. It’s also possible for people to feel that sense of connection in the context of behavior change without having direct relationships with others. By building your product in a way that mimics some of the characteristics of a person-to-person relationship, you can make it possible for your users to feel connected to it. It is possible to coax your users to fall at least a little bit in love with your products; if you don’t believe me, try to get an iPhone user to switch operating systems. It’s not just about really liking a product (although you definitely want users to really like your product). With the right design elements, your users might embark on a meaningful bond with your technology, where they feel engaged in an ongoing, two-way relationship with an entity that understands something important about them, yet is recognizably non human. This is a true emotional attachment that supplies at least some of the benefits of a human-to-human relationship. This type of connection can help your users engage more deeply and for a longer period of time with your product. And that should ultimately help them get closer to their behavior change goals. Amp Up the Anthropomorphization People can forge relationships with non humans easily because of a process called  . To anthropomorphize something means to impose human characteristics on it. It’s what happens when you see a face in the array of shapes on the right side in Figure 9.2, or when you carry on an extended conversation with your cat. People will find the human qualities in shapes that slightly resemble a face, but you can help speed that process along by deliberately imbuing your product with physical or personality features that resemble people. Voice assistants like Siri, Cortana, and Alexa, for example, are easily perceived as human-like by users thanks to their ability to carry on a conversation much like a (somewhat single-minded) person. Granted, almost nobody would mistake Alexa for a real person, but her human characteristics are pretty convincing. Some research suggests that children who grow up around these voice assistants may be less polite when asking for help, because they hear adults make demands of their devices without saying please or thank you. If you’re asking Siri for the weather report and there are little ones in earshot, consider adding the   magic words to your request. So, if you want people to anthropomorphize your product, give it some human characteristics. Think names, avatars, a voice, or even something like a catchphrase. These details will put your users’ natural anthropomorphization tendencies into hyperdrive. Everything Is Personal One thing humans do well is personalization. You don’t treat your parent the same way you treat your spouse the same way you treat your boss. Each interaction is different based on the identity of the person you’re interacting with and the history you have with them. Technology can offer that same kind of individualized experience as another way to mimic people, with lots of other benefits. Personalization is the Swiss Army Knife of the behavior change design toolkit. It can help you craft appropriate goals and milestones, deliver the right feedback at the right time, and offer users meaningful choices in context. It can also help forge an emotional connection between users and technology when it’s applied in a way that helps users feel seen and understood. Some apps have lovely interfaces that let users select colors or background images or button placements for a “personalized” experience. While these types of features are nice, they don’t scratch the itch of belonging that true personalization does. When personalization works, it’s because it reflects something essential about the user back to them. That doesn’t mean it has to be incredibly deep, but it does need to be somewhat more meaningful than whether the user has a pink or green background on their home screen. Personalized Preferences During onboarding or early in your users’ product experience, allow them to personalize preferences that will shape their experiences in meaningful ways (  just color schemes and dashboard configurations). For example, Fitbit asks people their preferred names, and then greets them periodically using their selection. Similarly, LoseIt asks users during setup if they enjoy using data and technology as part of their weight loss process (Figure 9.3). Users who say yes are given an opportunity to integrate trackers and other devices with the app; users who say no are funneled to a manual entry experience. The user experience changes to honor something individual about the user. If you can, recall back to ancient times when Facebook introduced an algorithmic sort of posts in the newsfeed. Facebook users tend to be upset anytime there’s a dramatic change to the interface, but their frustration with this one has persisted, for one core reason: Facebook to this day reverts to its own sorting algorithm as a default, even if a user has selected to organize content by date instead. This repeated insistence on their preference over users’ makes it less likely that users will feel “seen” by Facebook. Personalized Recommendations If you’ve ever shopped online, you’ve probably received personalized recommendations. Amazon is the quintessential example of a recommendation engine. Other commonly encountered personalized recommendations include Facebook’s “People You May Know” and Netflix’s “Top Picks for [Your Name Here].” These tools use algorithms that suggest new items based on data about what people have done in the past. Recommendation engines can follow two basic models of personalization. The first one is based on products or items. Each item is tagged with certain attributes. For example, if you were building a workout recommendation engine, you might tag the item of “bicep curls” with “arm exercise,” “upper arm,” and “uses weights.” An algorithm might then select “triceps pulldowns” as a similar item to recommend, since it matches on those attributes. This type of recommendation algorithm says, “If you liked this item, you will like this similar item.” The second personalization model is based on people. People who have attributes in common are identified by a similarity index. These similarity indices can include tens or hundreds of variables to precisely match people to others who are like them in key ways. Then the algorithm makes recommendations based on items that lookalike users have chosen. This recommendation algorithm says, “People like you liked these items.” In reality, many of the more sophisticated recommendation engines (like Amazon’s) blend the two types of algorithms in a hybrid approach. And they’re effective. McKinsey estimates that 35% of what Amazon sells and 75% of what Netflix users watch are recommended by these engines. Don’t Overwhelm Sometimes what appear to be personalized recommendations can come from a much simpler sort of algorithm that doesn’t take an individual user’s preferences into account at all. These algorithms might just surface the suggestions that are most popular among   users, which isn’t always a terrible strategy. Some things are popular for a reason. Or recommendations could be made in a set order that doesn’t depend on user characteristics at all. This appears to be the case with the Fabulous behavior change app that offers users a series of challenges like “drink water,” “eat a healthy breakfast,” and “get morning exercise,” regardless of whether these behaviors are already part of their routine or not. When recommendation algorithms work well, they can help people on the receiving end feel like their preferences and needs are understood. When I browse the playlists Spotify creates for me, I see several aspects of myself reflected. There’s a playlist with my favorite 90s alt-rock, one with current artists I like, and a third with some of my favorite 80s music (Figure 9.4). Amazon has a similar ability to successfully extrapolate what a person might like from their browsing and purchasing history. I was always amazed that even though I didn’t buy any of my kitchen utensils from Amazon, they somehow figured out that I have the red KitchenAid line. A risk to this approach is that recommendations might become redundant as the database of items grows. Retail products are an easy example; for many items, once people have bought one, they likely don’t need another, but algorithms aren’t always smart enough to stop recommending similar purchases (see Figure 9.5). The same sort of repetition can happen with behavior change programs. There are only so many different ways to set reminders, for example, so at some point it’s a good idea to stop bombarding a user with suggestions on the topic. Don’t Be Afraid to Learn Data-driven personalization comes with another set of risks. The more you know about users, the more they expect you to provide relevant and accurate suggestions. Even the smartest technology will get things wrong sometimes. Give your users opportunities to point out if your product is off-base, and adjust accordingly. Not only will this improve your accuracy over time, but it will also reinforce your users’ feelings of being cared for. Alfred was a recommendation app developed by Clever Sense to help people find new restaurants based on their own preferences, as well as input from their social networks. One of Alfred’s mechanisms for gathering data was to ask users to confirm which restaurants they liked from a list of possibilities (see Figure 9.6). Explicitly including training in the experience helped Alfred make better and better recommendations while also giving users the opportunity to chalk errors up to a need for more training. Having a mechanism for users to exclude some of their data from an algorithm can also be helpful. Amazon allows users to indicate which items in their purchase history should be ignored when making recommendations—a feature that comes in handy if you buy gifts for loved ones whose tastes are very different from yours. On the flip side, deliberately throwing users a curve ball is a great way to learn more about their tastes and preferences. Over time, algorithms are likely to become more consistent as they get better at pattern matching. Adding the occasional mold-breaking suggestion can prevent boredom and better account for users’ quirks. Just because someone loves meditative yoga doesn’t mean they don’t also like going mountain biking once in a while, but most recommendation engines won’t learn that because they’ll be too busy recommending yoga videos and mindfulness exercises. Every now and then add something into the mix that users won’t expect. They’ll either reject it or give it a whirl; either way, your recommendation engine gets smarter. Personalized Coaching At some point, recommendations in the context of behavior change may become something more robust: an actual personalized plan of action. When recommendations grow out of the “you might also like” phase into “here’s a series of steps that should work for you,” they become a little more complicated. Once a group of personalized recommendations have some sort of cohesiveness to systematically guide a person toward a goal, it becomes  . More deeply personalized coaching leads to more effective behavior change. One study by Dr. Vic Strecher, whom you met in Chapter 3, showed that the more a smoking cessation coaching plan was personalized, the more likely people were to successfully quit smoking. A follow-up study by Dr. Strecher’s team used fMRI technology to discover that when people read personalized information, it activates areas of their brain associated with the self (see Figure 9.7). That is, people perceive personalized information as self-relevant on a neurological level. This is important because people are more likely to remember and act on relevant information. If you want people to   something, personalize the experience that shows them how. From a practical perspective, personalized coaching also helps overcome a common barrier: People do not want to spend a lot of time reading content. If your program can provide only the most relevant items while leaving the generic stuff on the cutting room floor, you’ll offer more concise content that people may actually read. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/creative-culture-excerpt/", "title": "Connecting the Dots", "content": "Two plans: one for design, one for culture. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What I’ve found is that the DNA between both dynamics must be inextricable from one another. Creating  compassion in an environment fueled  compassion means we never lose sight of what it’s all about: people. Beyond functioning in this manner because “it’s the right thing to do,” quality of work, loyalty internally (team) and externally (users), and product innovation are all benefits to reap. Earlier we talked through the concept of “simplicity” and its application to creation and environment. Now, let’s revisit a few other examples of healthy benchmarks from a creative culture as we’ve discussed in this book: Slowing down / pausing with intent Everyone has a seat at the table The New Day One In taking a focused look at these facets, their correlation to   is readily apparent: Slowing down / pausing with intent Discovery / observation The Swedish concept of  transcends a mere “coffee break.” It’s about slowing down, the act of pausing during a typical day and making time to have a dialogue with someone (though a good cup of coffee is a vital part). I ensure this time is not only a known quantity within my team’s creative culture, but that it’s protected and actively utilized. Instead of getting a product manager’s Powerpoint wireframe in your inbox with a request to “make it look nice” or a client’s request to crank out a design for their approval by EOD, we  slow down to understand the people who will be interacting with our design (and the design’s potential impact on others, the environment and community in which it will be used, and so on). Rushing to get something done to tick an account manager’s client-appeasement box at the expense of the human experience is to sacrifice empathy, quality, and any prospect of innovation. Everyone has a seat at the table Inclusion As the very definition of cultural transparency, Nick Sarillo’s pizza parlors tack their full financial statements to a wall, daily, for all employees to see. Everyone’s hourly wage is listed on a nearby whiteboard, with the means to make more money articulated in tandem (training in more areas of business = increased hourly wage). Many managers have worked their way up in this manner, and offer training to other employees who wish to advance by taking on more responsibility. This is about collaboration yielding success to both the employee and the business, the sharing of information, and access for all; key dynamics of an inclusive culture. Inclusion in the design process enables us, as creators, to recognize our own personal biases. By identifying the exclusion in our work, we humbly set aside our assumptions; connecting with people from diverse communities, building empathy, will expand our product’s reach (access). Via engaging humans throughout our design process, listening to them, and usability testing iteratively, objective solutions that yield innovation follow suit. The New Day One Ethnography The New Day One concept evolves an employee’s first day from formulaic and sterile into directly personal and custom. Via the “Inspiration” portion of the day and venturing away from the office, we gain insight into a new team member as an individual that transcends what folio work can yield. What physical aspects of their selected location have impacted who they are? How did it inspire their way of creating, or approaching problems? Understanding the impact of spatial dynamics on an individual is vital toward an individualistic, yet ultimately holistic, view. Ethnographic research provides an environmental context to human interaction that a video-conference interview could never yield. Through direct observation, ethnography is the qualitative study of human beings in their native environment. Is the individual sitting in a high-traffic area in an office, causing frequent distraction from their work? Are they a field worker primarily utilizing a mobile device in direct sunlight, yielding paramountcolor contrast needs? By making research truly  , we gain an understanding of how those we observe see the world and how they ultimately engage with it. For the Greater Good Greater Good Studio (GGS) is a social impact-focused human- centered design firm co-founded by Sara Cantor Aye and George Aye. Their business is located within the Logan Share, a co- working space they also founded in Chicago’s Logan Square neighborhood. I reached out to the Studio to ask if I could stop by their space and observe a “morning in the life” view of their process: culture and design, organically, as both unfolded. Without hesitation, Sara (a former Northwestern University instructor) extended me an offer to join the team for observation. After signing a non- disclosure agreement, we agreed on a date for my visit. When I arrived on a Monday morning, George (formerly of IDEO) greeted me with a cup of coffee and walked me up the stairs into the naturally well-lit Logan Share space. I noticed the open seating in the co-working section was already nearly full, as he gave me a tour of the “configuration by human need and intent”-based layout and active-project areas. On long single sheets of cardboard suspended by custom-built fasteners, entire lifecycles of project- centric human-centered design artifacts were on display. Once a project is deployed, George explained, the cardboard is detached and saved for forthcoming iteration, with fresh sheets re-fastened to form the partitions of a new project space thereafter. The six core steps of the Studio’s HCD process manifest themselves in the following way: As a team, GGS functions via a working method called ROWE (Results Only Work Environment), a concept leveraged from Cali Ressler and Jody Thompson’s book  Taken from an article on the Studio’s blog, they describe the practice within GGS like this: Once a month the entire team pauses for a five-hour, non-client project block of time called “internal day.” This time is reserved for studio-centric things: team members sharing learnings from conferences they’ve attended, how to improve internal practices, past project debriefs, etc. It’s the act of pausing with intent, in full effect. Sara arrived a few minutes into my tour of the space, and the GGS team’s “BD charrette” was the first employee gathering (remote and in-person) of the morning. “BD” stands for “business development,” and in a cozy seating area, everyone had a seat at the table in all senses of the phrase. Sara and George ran through the status of a current request for proposal, then each team member had the opportunity to voice their opinion about whether the RFP should be pursued based on how it aligned with GGS’s (and their employees’) personal, values. Everyone was heard; every voice was respected. The dialogue eventually shifted to another potential new client, this time with GGS at the presentation stage. Again, everyone at the table gave their feedback on Sara and George’s presentation plan of attack and, again, every team member’s voice carried equal value and weight. The studio-wide inclusion in the business owners’ decision making was genuine, effortless, and natural. Forty-five minutes later, the group made a physical transition to a few nearby couches; less than a three-foot walk, as I eyed it. I inquired about the very minor spatial change for this next leg of the meeting and was told, “There’s a difference in purpose, so we transition to a different space.” Each member of the team then took their turn describing their weekend in three words: I got my turn as well. Changing the energy on those couches, from new business to being focused on the individual, made for a palpable climate change. In a few words everyone had a sense of what their teammates got up to over the weekend, eliciting smiles and planting the seeds for future dialogues throughout the pauses- with-intent over the rest of the day. Next: “validations.” In this final portion of the meeting (pre- project status), anyone who wanted to articulate their appreciation for a team member over the previous week did so. One person recognized their co-worker for their selfless collaboration, taking time from their own project work to help theirs get client-ready on time. Similar-but-unique “thanks” emerged from varied people; no one was required to speak up, but everyone did. After project updates I sat with Sara for a one-on-one to chat over coffee. I asked her about the synergies between their HCD process and how she interacts with her team in the office: When All is Not Good Sara went on to cite how her previous work experience shaped the leader she is today: The tactics, mindsets, organizational shifts, and operational flexibility discussed in this book are predicated upon a simple truth: a company presently supports and operates as a creative culture, or it’s genuinely willing to evolve to become one. Along the way, I’ve been primarily speaking to those who are in a position to help implement change; even at a small scale. But what about when you’re not in a position to be heard, or the position to help facilitate change? Reality isn’t always unicorns and rainbows. Bad experiences can impact us all. For example, the fabric of a company’s creative culture can become irreparably frayed thanks to management changes, acquisition, or it can lack sustainability. Whether these circumstances reveal themselves over years or overnight, your passion and evolution should never be their casualty. Sometimes, creating within an environment that’s the best fit for your growth and passions means finding a new opportunity. Like this: \n\t\t\t\t\t\t\tRecently by Justin Dauer\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/webwaste/", "title": "Webwaste", "content": "The Web is obese In 1994, there were 3,000 websites. In 2019, there were estimated to be 1.7 billion, almost one website for every three people on the planet. Not only has the number of websites exploded, the weight of each page has also skyrocketed. Between 2003 and 2019, the average webpage weight grew from about 100 KB to about 4 MB. The results? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. “In our analysis of 5.2 million pages,” Brian Dean reported for Backlinko in October 2019, “the average time it takes to fully load a webpage is 10.3 seconds on desktop and 27.3 seconds on mobile.” In 2013, Radware calculated that the average load time for a webpage on mobile was 4.3 seconds. Study after study shows that people absolutely hate slow webpages. In 2018, Google research found that 53% of mobile site visitors left a page that took longer than three seconds to load. A 2015 study by Radware found that “a site that loads in 3 seconds experiences 22% fewer page views, a 50% higher bounce rate, and a 22% fewer conversions than a site that loads in 1 second, while a site that loads in 5 seconds experiences 35% fewer page views, a 105% higher bounce rate, and 38% fewer conversions.” The causes of webpage bloat? Images and videos are mainly to blame. By 2022, it’s estimated that online videos will make up more than 82% of all consumer Internet traffic—15 times more than in 2017. However, from the code to the content, everything about Web design has become super-bloated and super-polluting. Consider that if a typical webpage that weighs 4 MB is downloaded 600,000 times, one tree will need to be planted in order to deal with the resulting pollution. They say a picture paints a thousand words. Well, 1,000 words of text takes up roughly two A4 (210 mm wide and 297 mm long) pages and weighs about 6 KB. You’d place about four images that are 9 cm x 16 cm on two A4 pages. Let’s say these images are well optimized and weigh 40 KB each. (A poorly optimized image could weigh several megabytes.) Even with such high optimization, two A4 pages of images will weigh around 160 KB. That’s 27 times more than the two A4 pages of text. A 30-second video, on the other hand, could easily weigh 3 MB. Videos create massively more pollution than text. Text is the ultimate compression technique. It is by far the most environmentally friendly way to communicate. If you want to save the planet, use more text. Think about digital weight. From an energy point of view, it’s not simply about page weight. Some pages may have very heavy processing demands once they are downloaded. Other pages, particularly those that are ad-driven, will download with lots of third-party websites hanging off them, either feeding them content, or else demanding to be fed data, often personal data on the site’s visitor. It’s like a type of Trojan Horse. You think you’re accessing one website or app, but then all these other third parties start accessing you. According to Trent Walton, the top 50 most visited websites had an average of 22 third-party websites hanging off them. The New York Times had 64, while Washington Post had 63. All these third-party websites create pollution and invade privacy. There is a tremendous amount of out-of-date content on websites. I have worked with hundreds of websites where we had to delete up to 90% of the pages in order to start seeing improvements. Poorly written, out-of-date code is also a major problem. By cleaning up its JavaScript code, Wikipedia estimated that they saved 4.3 terabytes a day of data bandwidth for their visitors. By saving those terabytes, we saved having to plant almost 700 trees to deal with the yearly pollution that would have been caused. If you want to help save the planet, reduce digital weight. Clean up your website. Before you add an image, make sure that it does something useful and it’s the most optimized image possible. Every time you add code, make sure it does something useful and it’s the leanest code possible. Always be on the lookout for waste images, waste code, waste content. Get into the habit of removing something every time you add something. Publishing is an addiction. Giving a website to an organization is like giving a pub to an alcoholic. You remember the saying, “There’s a book inside everyone”? Well, the Web let the book out. It’s happy days for a while as we all publish, publish, publish. Then… “Hi, I’m Gerry. I have a 5,000-page website.” “Hi, Gerry.” “I used to have a 500-page website, but I had no self-control. It was one more page, one more page… What harm could one more page do?” Redesign is rehab for websites. Every two to three years some manager either gets bored with the design or some other manager meets a customer who tells them about how horrible it is to find anything on the website. The design team rounds up a new bunch of fake images and fake content for the top-level pages, while carefully avoiding going near the heaving mess at the lower levels. After the launch, everyone is happy for a while (except the customers, of course) because in many organizations what is important is to be seen to be doing things and producing and launching things, rather than to do something useful. If you must do something, do something useful. That often means not doing, removing, minimizing, cleaning up. Beware the tiny tasks. We’ve used the Top Tasks method to identify what matters and what doesn’t matter to people, whether they’re buying a car, choosing a university, looking after their health, buying some sort of technology product, or whatever. In any environment we’ve carried it out in—and we’ve done it more than 500 times—there are no more than 100 things that could potentially matter. In a health environment, these might include symptoms, treatment, prevention, costs, waiting times, etc. When buying a car they might include price, engine type, warranties, service costs, etc. We’ve carried out Top Tasks surveys in some 40 countries and 30 languages, with upwards of 400,000 people voting. In every single survey the same patterns emerge. Let’s say there are 100 potential tasks. People are asked to vote on the tasks that are most important to them. When the results come in, we will find that five of the tasks will get the first 25% of the vote. 50 tasks will get the final 25% of the vote. The top five tasks get as much of the vote as the bottom 50. It’s the same pattern in Norway, New Zealand, Israel, USA, Canada, UK, Brazil, wherever. The bottom 50 are what I call the tiny tasks. When a tiny task goes to sleep at night it dreams of being a top task. These tiny tasks—the true waste generators—are highly ambitious and enthusiastic. They will do everything they can to draw attention to themselves, and one of the best ways of doing that is to produce lots of content, design, code. Once we get the Top Tasks results, we sometimes analyze how much organizational effort is going into each task. Invariably, there is an inverse relationship between the importance of the task to the customer and the effort that the organization is making in relation to these tasks. The more important it is to the customer, the less is being done; the less important it is to the customer, the more is being done. Beware of focusing too much energy, time and resources on the tiny tasks. Reducing the tiny tasks is the number one way you can reduce the number of pages and features. Save the planet. Delete the tiny tasks. A plague of useless images I was giving a talk at an international government digital conference once, and I asked people to send me examples of where digital government was working well. One suggestion was for a website in a language I don’t speak. When I visited it, I saw one of those typical big images that you see on so many websites. I thought to myself: I’m going to try and understand this website based on its images. The big image was of a well-dressed, middle-aged woman walking down the street while talking on her phone. I put on my Sherlock Holmes hat. Hmm… Something to do with telecommunications, perhaps? Why would they choose a woman instead of a man, or a group of women and men? She’s married, I deduced by looking at the ring on her finger. What is that telling me? And what about her age? Why isn’t she younger or older? And why is she alone? Questions, questions, but I’m no Sherlock Holmes. I couldn’t figure out anything useful from this image. I scrolled down the page. Ah, three more images. The first one is a cartoon-like image of a family on vacation. Hmm… The next one is of two men and one woman in a room. One of them has reached their hand out and placed it on something, but I can’t see what that something is, because the other two have placed their hands on top of that hand. It’s a type of pledge or something, a secret society, perhaps? Two of them are smiling and the third is trying to smile. What could that mean? And then the final picture is of a middle-aged man staring into the camera, neither smiling nor unsmiling, with a somewhat kind, thoughtful look. What is happening? I must admit that after examining all the visual evidence I had absolutely no clue what this government website was about. So, I translated it. It was about the employment conditions and legal status of government employees. Now, why didn’t I deduce that from the images? The Web is smothering us in useless images that create lots of pollution. These clichéd, stock images communicate absolutely nothing of value, interest or use. They are one of the worst forms of digital pollution and waste, as they cause page bloat, making it slower for pages to download, while pumping out wholly unnecessary pollution. They take up space on the page, forcing more useful content out of sight, making people scroll for no good reason. Interpublic is a very large global advertising agency. As with all advertising agencies they stress how “creative” they are, which means they love huge, meaningless, happy-clappy polluting images. When I tested their homepage, it emitted almost 8 grams of CO2 as it downloaded, putting Interpublic in the worst 10% of website polluters, according to the Website Carbon Calculator. (For comparison, the Google homepage emits 0.23 grams.) One single image on its homepage weighed 3.2 MB. This image could easily have been 10 times smaller, while losing nothing in visual appeal. The Interpublic website is like a filthy, rusty 25-year-old diesel truck, belching fumes as it trundles down the Web. Instead of optimizing images so that they’ll download faster, the opposite is often happening. High-resolution images are a major cost to the environment. If, for example, you move from a 4K resolution image to an 8K one, the file size doesn’t double, it trebles. For example, I saved an image at 4K and it was 6.9 MB. At 8K it was 18 MB. Digital “progress” and “innovation” often means an increasing stress on the environment. Everything is more. Everything is higher. Everything is faster. And everything is exponentially more demanding of the environment. Digital is greedy for energy and the more it grows the greedier it gets. We need digital innovation that reduces environmental stress, that reduces the digital footprint. We need digital designers who think about the weight of every design decision they make. We must start by trying to use the option that damages the environment least, and that is text. Don’t assume that images are automatically more powerful than text. Sometimes, text does the job better. In a test with an insurance company, it was found that a promotion for a retirement product was deemed less accurate when an image of a face was used than when text only was used. An initiative by the UK government to get people to sign up to become potential organ donors tested eight approaches. The approaches that used images were least effective. Text-only worked best. “Hello?” “Hello. Is that the Department of Useless Images?” “Yes.” “We have this contact form and we need a useless image for it.” “How about a family cavorting in a field of spring flowers with butterflies dancing in the background?” “Perfect.” There are indeed many situations where images are genuinely useful, particularly when it comes to helping people better understand how a product works or looks. Airbnb, for example, found that its growth only began to accelerate after it invested in getting quality images of the rental properties on offer. If you need to use images, optimize them and consider using real ones of real people doing real things. They say a picture paints a thousand words but sometimes it’s a thousand words of crap. Like this: \n\t\t\t\t\t\t\tRecently by Gerry McGovern\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/trans-inclusive-design/", "title": "Trans-inclusive Design", "content": "Late one night a few years ago, a panicked professor emailed me: “My transgender student’s legal name is showing on our online discussion board. How can I keep him from being outed to his classmates?” Short story: we couldn’t. The professor created an offline workaround with the student. Years later this problem persists not just in campus systems, but in many systems we use every day. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. To anyone who’d call that an unusual situation, it’s not. We are all already designing for trans users—  in the US identifies as transgender or gender non-binary (based on current estimates), and the  . We are web professionals; we can do better than an offline workaround. The choices we make impact the online and offline experiences of real people who are trans, non-binary, or gender-variant—choices that can affirm or exclude, uplift or annoy, help or harm.  The rest of this article assumes you agree with the concept that trans people are human beings who deserve dignity, respect, and care. If you are seeking a  , please read up and come back later. I’m going to cover issues touching on content, images, forms, databases, IA, privacy, and AI—just enough to get you thinking about the decisions you make every day and some specific ideas to get you started. How we can get things right Gender is expansively misconstrued as some interchangeable term for anatomical features. Unlike the constellation of   (our sex),   and varies depending on where you are in the world. It has its own diversity.  Asking for gender when it is not needed; limiting the gender options users can select; assuming things about users based on gender; or simply excluding folks from our designs are all ways we reify the man-woman gender binary in design decisions. Names are fundamentally important If we do nothing else,  . Names are the difference between past and present, invalidation and affirmation, and sometimes safety and danger.  Yet, many of the systems we use and create don’t offer name flexibility.  Many programmers and designers have a few  , such as assuming people have one moniker that they go by all the time, despite how common it is for names to change over a lifetime. People might update them after a change in marital status, family situation, or gender, or perhaps someone is known by a nickname, westernized name, or variation on a first name. In most locales,   is extremely difficult, extremely expensive, requires medical documentation, or is completely out of the question.  Changes to name  gender marker are even more complicated; they tend to be two separate, long-drawn-out processes. To make matters worse,   within the U.S. and most only recognize two genders—man and woman—rather than allowing non-binary options.Not all trans people change their names, but for those who do, it’s a serious and significant decision that shouldn’t be sabotaged. We can design systems that protect the lives and privacy of our users, respect the fluid nature of personal identity, and act as an   that helps everyone in the process. Deadnaming One need only search Twitter for “deadname app” to get an idea of how apps can leave users in the lurch. Some of the most alarming examples involve apps and sites that facilitate real-life interactions (which already involve a measure of risk for everyone). “Lyft made it completely impossible for me to change my name on its app even when it was legally changed. I reached out to their support multiple times and attempted to delete the account and start over with no result. I was completely dependent on this service for groceries, appointments, and work, and was emotionally exhausted every single time I needed a ride. I ended up redownloading Uber – even though there was a strike against the service – which I felt awful doing. But Uber allowed me to change my name without any hoops to jump through, so for the sake of my mental health, I had to.” Trans people are more likely to experience financial hardship, so using payment apps to ask for donations is often necessary. Some of these   as a matter of course, leaving them exposed and potentially at risk. There are also ramifications when linked services rely on our data sources for name information, instigating an unpredictable cascade effect with little or no recourse to prevent the sharing of sensitive details.  These are examples of deadnaming.   is what happens when someone’s previous or birth name is used, rather than the name the person uses now. Deadnaming is invalidating at the least, even as a faux pas, but can be psychologically devastating at the other extreme, even putting lives at risk.The experiences of trans, non-binary, or gender-variant folk can vary widely, and they live in   throughout the world. Many are thriving and   to resist and undo gender norms, despite the   around trans lives. Others can face hardship; trans people are more likely to be unstably housed, underemployed, underpaid, and targets of violence in and out of their homes, workplaces, and intimate relationships. The ramifications are amplified for people of color and those with disabilities, as well as those in precarious living/working situations and environments where exposure can put them in harm’s way. Design for name changes ’  Emma Humphries’   covers this nicely.   has developed policies and procedures for users who’ve transitioned, allowing users to keep their review histories intact with amended names and/or pronouns.  Allow people to use names they go by rather than their legal first names. , and only use that in conjunction with a display name field.  that allows users to change their names without legal documentation. (It’s likely that you have procedures for marriage-related name changes already.)  when connecting with other data sources to populate users’ names.  Once someone creates a username, web address, or profile URL,  .  if you’re part of an online community, and make sure to include policies around deadnaming.   last year. When people delete their accounts for whatever reason, help them make sure that their data is not lingering in your systems or in other places online. Identity management systems can be a mess, and name changes can reveal the failures among those systems, including hidden systems that users don’t see.  One Twitter user’s health insurance company  . Another user updated their display name but got an  .  Hidden information can also undermine job opportunities: “At a university as a student, I transitioned and changed my name and gender to be a woman. TWELVE YEARS later after being hired to work in the Libraries, the Libraries HR coordinator emailed me that I was listed as male still in the database. He changed it on my asking, but I have to wonder how long… was it a factor in my being turned down for jobs I applied to… who had seen that..?” Emma Humphries   that can carry out-of-date information about users. Her tips for database design include: Don’t use emails as unique IDs. Use an invariant user ID internally, and link the user’s current email and display name to it. Images Visuals should allow room for representation and imagination rather than a narrow subset of the usual suspects: figures who appear to be straight, cisgender, able-bodied, and white/Caucasian.  What we can do is feature a variety of gender presentations, as well as not assume someone’s gender identity if they buy certain items. Some companies, like   and  , offer a broad array of images representing different races, body sizes, and gender expressions on their websites and in their ads.  Many are also choosing not to hire models,   and versatility: “I got a catalog for a ‘classic menswear company’ that features zero photos of any person of any gender. Now if only I could afford an $800 blazer…”  And pay them! , Broadly has recently launched a   free for wide use.   allows users to create an avatar without selecting a gender. Information architecture How we organize information is a political act and a non-neutral decision (  for a while). This applies to gender-based classifications. Many companies that sell consumer goods incorporate gender into their product design and marketing, no matter what. The product itself might be inherently gender-neutral (such as clothing,  ,  , or even  ), but these design and marketing decisions can directly impact the information architecture of websites. , and how it can be done differently: “Nike has a ‘gender neutral’ clothing category, yet it’s listed under ‘men’ and ‘women’ in the website architecture. 🤔” Forms Forms, surveys, and other types of data gathering are surefire ways to include or exclude people. If you ask for information you don’t need or limit the options that people can select, you risk losing them as users. , including gender. Will that information be used to help someone, or sell things to your advertisers? “Why does the @CocaCola site make me select a gender just to make a purchase? Guess my family isn’t getting personalized Coke bottles for Christmas.” , you’d better have a good reason and options that include everyone. A gender field should have  , or should ask for pronouns instead. When including more than binary options, actually record the selections in your databases   answers as male/female/null, otherwise you risk losing trust when disingenuous design decisions become public.  are infrequently used these days, but it takes little work to add   to a list. For English-language sites, “Mx.” can go alongside “Mr.” and “Ms.” without fuss. United Airlines   earlier this year. Content  Your style guide should include   instead of “he/she” or “s/he,” and exclude   that exclude trans folks. Resources such as this   are a quick way to check your language and benchmark your own content guidelines.  Not everyone who can have a period, can get pregnant, or can breastfeed identifies as women or mothers—just as not everyone who identifies as women or mothers can have periods, can get pregnant, or can breastfeed. Thinx, a company that sells period underwear, has an inclusive tagline: “For people with periods.”  Groups of people aren’t “ladies and gentlemen” or “boys and girls.” They are folks, people, colleagues, “y’all,” or even “ .” —they’re just pronouns. Calling pronouns preferred suggests that they’re optional and are replacing a “true” pronoun.  about trans people. Not all trans people are interested in medically transitioning, or in “ .” They also aren’t fragile or in need of a savior. Gender is separate from sexual orientation. You can’t “tell” someone is trans. We’ve heard the story of algorithms   before her parents knew. What if an algorithm predicts or reveals information about your gender identity?  Users’ genders are assumed based on their purchase/browsing history.  A user bought something before they transitioned and it shows up in “recommended because you bought X.”  Users’ genders are not only inferred but used to predict something else based on characteristics of that gender. Even if you don’t tell big websites what your gender is, they assume one for you based on your interests. That kind of reductive essentialism can harm people of all genders. One of this article’s peer readers summed this up: “Gender markers are a poor proxy for tastes. I like dresses, cute flats, and Raspberry Pis.”  “On this day” algorithms remind users of the past, sometimes for better (“I’ve come so far”) or for worse (“ ”).  AI-based discrimination AI and surveillance software can also reinforce norms about what men’s and women’s bodies should look like, resulting in   and creating   for trans people. So, too, can  . Just because we can use AI for something—like  —doesn’t mean we  .  and perpetuate stereotypes about how people’s bodies should look. Use AI to  rather than reinforce it. Design for  Hire more types of people who represent different lived experiences. The ideas I’ve offered here are only starting points. How you choose to create space for trans folks is going to be up to you. I don’t have all the solutions here, and there is no singular trans experience. Also, language, definitions, and concepts change  . We shouldn’t use any of these facts as excuses to keep us from trying. When we start to think about design impact on trans folks, the ideas we bring into question can benefit everyone. Our designs should go beyond including—they should affirm and validate. Ideally, they will also reflect organizational cultures that support diversity and inclusion. Keep learning. Learn  . Pay trans user research participants to help validate your design assumptions. Hire trans people on your team and don’t hang them out to dry or make them do all the hard work around inclusion and equity. Make it everyone’s job to build a more just web and world for everybody. A List Apart Jake Atchison Katherine Deibel, Ph.D. Justina F. Hall Austyn Higgs Emma Humphries Tara Robertson Levi R. Walter Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/daily-ethical-design/", "title": "Daily Ethical Design", "content": "Suddenly, I realized that the people next to me might be severely impacted by my work. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I was having a quick lunch in the airport. A group of flight attendants sat down at the table next to me and started to prepare for their flight. For a while now, our design team had been working on futuristic concepts for the operations control center of these flight attendants’ airline, pushing ourselves to come up with innovative solutions enabled by the newest technologies. As the control center deals with all activities around flying planes, our concepts touched upon everything and everyone within the airline. How was I to know what the impact of my work would be on the lives of these flight attendants? And what about the lives of all the other people working at the airline? Ideally, we would have talked to all the types of employees in the company and tested our concepts with them. But, of course, there was no budget (or time) allocated to do so, not to mention we faced the hurdle of convincing (internal) stakeholders of the need. Not for the first time, I felt frustrated: practical, real-world constraints prevented me from assessing the impact and quality of my work. They prevented me from properly conducting  . What is ethical design? Right, good question. A very comprehensive definition of ethical design can be found at  : Design ethics concerns moral behavior and responsible choices in the practice of design. It guides how designers work with clients, colleagues, and the end users of products, how they conduct the design process, how they determine the features of products, and how they assess the ethical significance or moral worth of the products that result from the activity of designing. In other words, ethical design is about the “goodness”—in terms of benefit to individuals, society, and the world—of how we collaborate, how we practice our work, and what we create. There’s never a black-and-white answer for whether design is good or bad, yet there are a number of areas for designers to focus on when considering ethics. Usability Nowadays usability has conquered a spot as a basic requirement for each interface; unusable products are considered design failures. And rightly so; we have a moral obligation as designers to create products that are intuitive, safe, and free from possibly life-threatening errors. We were all reminded of usability’s importance by last year’s   in Hawaii. What if, instead of a false-positive, the operator had broadcasted a false-negative? Accessibility Like usability, inclusive design has become a standard item in the requirement list of many designers and companies. (I will never forget that time someone tried to use our website with a screen reader—and got absolutely stuck at the cookie message.) Accessible design benefits all, as it attempts to cover as many needs and capabilities as possible. Yet for each design project, there are still a lot of tricky questions to answer. Who gets to benefit from our solutions? Who is (un)intentionally left out? Who falls outside the “target customer segment”? Privacy Another day, another Facebook privacy scandal. As we’re progressing into the Data Age, the topic of privacy has become almost synonymous with design ethics. There’s a reason why more and more people use   as an alternative search engine to Google. Corporations have access to an abundance of personal information about consumers, and as designers we have the privilege—and responsibility—of using this information to shape products and services. We have to consider how much information is strictly necessary and how much people are willing to give up in exchange for services. And how can we make people aware of the potential risks  ? User involvement Overlapping largely with privacy, this focus area is about how we deal with our users and what we do with the data that we collect from them. IDEO has recently published  , which provides a comprehensive overview of the core principles and guidelines we should follow when conducting design research. Persuasion Ethics related to persuasion is about to what extent we may influence the behavior and thoughts of our users. It doesn’t take much to bring acceptable, “white hat” persuasion into gray or even dark territories. Conversion optimization, for example, can easily turn into “How do we squeeze out more revenue from our customers by  ?” Prime examples include Netflix, which convinces us to watch, watch, and watch even more, and Booking.com, which barrages our senses with urgency and social pressure. Focus The current digital landscape is addictive, distracting, and competing for attention. Designing for focus is about responsibly handling people’s most valuable resource: time. Our challenge is to limit everything that disrupts our users’ attention, lower the addictiveness of products, and create  . The Center for Humane Technology has started a useful list of   for this purpose. Sustainability What’s the impact of our work on the world’s environment, resources, and climate? Instead of continuously adding new features in the unrelenting scrum treadmill, how could we design for fewer? We’re in the position to create responsible digital solutions that enable sustainable consumer behavior and prevent overconsumption. For example, apps such as   and   allow people to order leftover food that would normally be thrashed. Or consider   and  , whose peer-to-peer platforms promote the sharing and reuse of owned products. Society The   of the Center for Human Technology is a work-in-progress collection of the negative impacts that digital technology has on society, including topics such as relationships, mental health, and democracy. Designers who are mindful of society consider the impact of their work on the global economy, communities, politics, and health. Ethics as an inconvenience Ideally, in every design project, we should assess the potential impact in all of the above-mentioned areas and take steps to prevent harm. Yet there are many legitimate, understandable reasons why we often neglect to do so. It’s easy to   moral principles, yet in the real world, with the constraints that our daily life imposes upon us, it’s seldom easy to   according to those principles. We might simply say it’s inconvenient at the moment. That there’s a lack of time or budget to consider all the ethical implications of our work. That there are many more pressing concerns that have priority right now. We might genuinely believe it’s just a small issue, something to consider later, perhaps. Mostly, we are simply   of the possible consequences of our work. And then there’s the sheer complexity of it all: it’s simply too much to simultaneously focus on. When short on time, or in the heat of approaching deadlines and impatient stakeholders, how do you incorporate all of design ethics’ focus areas? Where do you even start? Ethics as a structural practice For these reasons, I believe we need to elevate design ethics to a more practical level. We need to find ways to make ethics not an afterthought, not something to be considered separately, but rather something that’s so ingrained in our process that not doing it means   doing design at all. The only way to overcome the “inconvenience” of acting ethically is to practice   ethical design: ethics structurally integrated in our daily work, processes, and tools as designers. No longer will we have to rely on the exceptions among us; those extremely principled who are brave enough to stand up against the system no matter what kind of pressure is put upon them. Because the system will be on our side. By applying ethics daily and structurally in our design process, we’ll be able to identify and neutralize in a very early stage the potential for mistakes and misuse. We’ll increase the quality of our design and our practices simply because we’ll think things through more thoroughly, in a more conscious and structured manner. But perhaps most important is that we’ll establish a new standard for design. A standard that we can sell to our clients as the way design should be done, with ethical design processes and deliverables already included. A standard that can be taught to design students so that the newest generation of designers doesn’t know any better than to apply ethics, always. How to practice daily ethical design? At this point we’ve arrived at the question of   we can structurally integrate ethics into our design process. How do we make sure that our daily design decisions will result in a product that’s usable and accessible; protects people’s privacy, agency, and focus; and benefits both society and nature? I want to share with you some best practices that I’ve identified so far, and how I’ve tried to apply them during a recent project at Mirabeau. The goal of the project was to build a web application that provides a shaver manufacturer’s factory workers insight into the real-time availability of production materials. Connect to your organization’s mission and values By connecting our designs to the mission and values of the companies we work for, we can structurally use our design skills in a  , for moral purposes. We can challenge the company to truly live up to its promises and support it in carrying out its mission. This does, however, require you to be aware of the company’s values, and to compare these to your personal values. As I had worked with our example client before, I knew it was a company that takes care of its employees and has a strong focus on creating a better world. During the kick-off phase, we used a strategy pyramid to structure the client’s mission and values, and to agree upon success factors for the project. We translated the company’s customer-facing brand guidelines to employee-focused design principles that maintained the essence of the organization. Keep track of your assumptions Throughout our entire design process, we make assumptions for each decision that we take. By structurally keeping track of these assumptions, you’ll never forget about the limitations of your design and where the potential risks lie in terms of (harmful) impact on users, the project, the company, and society. In our example project, we listed our assumptions about user goals, content, and functionalities for each page of the application. If we were not fully sure about the value for end users, or the accuracy of a user goal, we marked it as a  . When we were unsure if data could be made available, we marked this as a  . If we were not sure whether a feature would add to the manufacturer’s business, we marked it as a  . Every week, we tested our assumptions with end users and business stakeholders through user tests and sprint demos. Each design iteration led to new questions and assumptions to be tested the next week. Aim to be proven wrong While our assumptions are the   unknowns, there are always   unknowns that we aren’t aware of but could be a huge risk for the quality and impact of our work. The only way we can identify these is by applying the scientific principle of  : seeking actively to be proven  . Only outsiders can point out to us what we miss as an individual or as a team. In our weekly user tests, we included factory workers and stakeholders with different disciplines, from different departments, and working in different contexts, to identify the edge cases that could break our concept. On one occasion, this made us reconsider the entirety of our concept. Still, we could have done better: although scalability to other factories was an important success factor, we were unable to gather input from those other factories during the project. We felt our only option was to mention this as a risk (“limit to scalability”). Use the power of checklists Let’s face it:  . (Without scrolling up the page, can you name all the focus areas of design ethics?) This is where checklists help us out: they provide knowledge in the world, so that we don’t have to process it in our easily overwhelmed memory. Simple yet powerful, a checklist is an essential tool to practice daily ethical design. In our example project, we used checklists to maintain an overview of questions and assumptions to user test, checking whether we included our design principles properly, and assessing whether we complied to the client’s values, design principles, and the agreed-upon success factors. In hindsight, we could also have taken a moment during the concept phase to go through the list of focus areas for design ethics, as well as have taken a more structural approach to check accessibility guidelines. The main challenge for daily ethical design Most ethics focus areas are quite tangible, where design decisions have immediate, often visible effects. While certainly challenging in their own right, they’re relatively easy to integrate in our daily practice, especially for experienced designers.  and the  , however, are more intangible topics; the effects of our work in these areas are distant and uncertain. I’m sure that when Airbnb was first conceived, the founders did not consider the magnitude of its   on the housing market. The same goes for Instagram, as its role in   must have been hard to foresee. Hard, but not impossible. So how do we overcome this challenge and make the impact that we have on society and the environment more immediate, more  ? Conduct Dark Reality sessions The ancient Greek philosopher Socrates used a series of questions to gradually uncover the invalidity of people’s beliefs. In a very similar way, we can uncover the assumptions and potential disastrous consequences of our concepts in a ‘Dark Reality’ session, a form of   that focuses on stress-testing a concept with challenging questions. We have to ask ourselves—or even better, somebody outside our team has to ask  — questions such as, “What is the lifespan of your product? What if the user base will be in the millions? What are the long-term effects on economy, society, and the environment? Who benefits from your design? Who loses? Who is excluded? And perhaps most importantly, how could your design be misused? (For more of these questions, Alan Cooper provided a great list in his   at Interaction 18.) The back-and-forth Q&A of the Dark Reality session will help us consider and identify our concept’s weaknesses and potential consequences. As it is a team effort, it will spark discussion and uncover differences in team members’ ethical values. Moreover, the session will result in a list of questions and assumptions that can be tested with potential users and subject matter experts. In the project for the airline control center, it resulted in more consideration for the human role in automatization and how digital interfaces can continue to support human capabilities (instead of replacing them), and reflection on the role of airports in future society. The dark reality session is best conducted during the convergent parts of the  , as these are the design phases in which we narrow down to realistic ideas. It’s vital to have a questioner from outside the team with strong interviewing skills and who doesn’t easily accept an answer as sufficient. There are helpful tools available to help structure the session, such as the   and these  . Take a step back to go forward As designers, we’re optimists by nature. We see the world as a set of problems that we can solve systematically and creatively if only we try hard enough. We intend well. However, merely having the   to do good is not going to be enough. Our mindset comes with the pitfall of (dis)missing potential disastrous consequences, especially under pressure of daily constraints. That’s why we need to regularly, systematically take a step back and consider the future impact of our work. My hope is that the practical, structural mindset to ethics introduced in this article will help us agree on a higher standard for design. Like this: \n\t\t\t\t\t\t\tRecently by Lennart Overkamp\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/resilient-management-excerpt/", "title": "Resilient Management, An Excerpt", "content": "In  , the Storming stage happens as a group begins to figure out how to work together. Previously, each person had been doing their own thing as individuals, so necessarily a few things need to be ironed out: how to collaborate, how to hit goals, how to determine priorities. Of  there may be some friction here!  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But even if your team doesn’t noticeably demonstrate this kind of internal Storming as they begin to gel, there might be some outside factors at play in your work environment that create friction. During times of team scaling and organizational change—the water we in the web industry are often swimming in—managers are responsible for things like strategy-setting, aligning their team’s work to company objectives, and unblocking the team as they ship their work.  In addition to these business-context responsibilities, managers need to be able to help their teammates navigate this storm by helping them grow in their roles and support the team’s overall progress. If you and your teammates don’t adapt and evolve in your roles, it’s unlikely that your team will move out of the Storming stage and into the Norming stage of team dynamics.  To spur this course-correction and growth in your teammates, you’ll end up wearing four different hats:  lending advice and helping to problem solve based on your own experience.  asking open questions to help your teammate reflect and introspect, rather than sharing your own opinions or quickly problem solving. finding opportunities for your teammate to level up, take on new leadership roles, and get promoted. observing behavior that is or isn’t aligned to what the team needs to be doing and sharing those observations, along with praise or suggestions.  Let’s dive in to how to choose, and when to use, each of\nthese skills as you grow your teammates, and then talk about\nwhat it looks like when teammates support the overarching\ndirection of the team.\n Mentoring When I talk to managers, I find that the vast majority have their\nmentor hats on ninety percent of the time when they’re working with their\nteammates. It’s natural!  In mentoring mode, we’re doling out advice, sharing our perspective,\nand helping someone else problem solve based on that information. Our personal\nexperiences are often what we can talk most confidently about! For this reason,\nmentorship mode can feel really good and effective for the mentor. Having that\nmentor hat on can help the other person overcome a roadblock or know which next\nsteps to take, while avoiding drastic errors that they wouldn’t have seen\ncoming otherwise.  As a mentor, it’s your responsibility to give advice that’s current and sensitive to the changing dialog happening in our industry. Advice that might work for one person (“Be louder in meetings!” or “Ask your boss for a raise!”) may undermine someone else, because members of underrepresented groups are unconsciously assessed and treated differently. For example,   that “when women are collaborative and communal, they are not perceived as competent—but when they emphasize their competence, they’re seen as cold and unlikable, in a classic ‘double bind’”.  If you are not a member of a marginalized group, and you have a\nmentee who  , please be a responsible mentor! Try to be aware of the\nway members of underrepresented groups are perceived, and the unconscious bias\nthat might be at play in your mentee’s work environment. When you have your\nmentor hat on, do lots of gut checking to make sure that your advice is going\nto be helpful in practice for your mentee. Mentoring is ideal when the mentee is new to their role or to the\norganization; they need to learn the ropes from someone who has firsthand\nexperience. It’s also ideal when your teammate is working on a problem and has\ntried out a few different approaches, but still feels stumped; this is why\npractices like pair coding can help folks learn new things.  As mentors, we want our mentees to reach beyond us, because our mentees’ success is ultimately   success. Mentorship relationships evolve over time, because each party is growing. Imaginative, innovative ideas often come from people who have never seen a particular challenge before, so if your mentee comes up with a creative solution on their own that you wouldn’t have thought of, be excited for them—don’t just focus on the ways that  done it or seen it done before. Managers often default to mentoring mode because it feels like the fastest way to solve a problem, but it falls short in helping your teammate connect their   dots. For that, we’ll look to coaching. Coaching In mentoring mode, you’re focused on both the problem and the solution. You’ll share what you as the mentor would do or have done in this situation. This means you’re more focused on yourself, and less on the person who is sitting in front of you. In coaching mode—an extremely powerful but often underutilized mode—you’re doing two primary things:   These two tools will help you become your teammate’s fiercest champion.  Open Questions “Closed” questions can only be answered with   or  .\nOpen questions often start with  ,  ,  ,  ,\n , and  . But the best open questions are about the\nproblem, not the solution. Questions that start with   tend to make\nthe other person feel judged, and questions that start with   tend\nto go into problem solving mode—both of which we want to avoid while in\ncoaching mode.  However,   questions can be authentically curious!\nWhen someone comes to you with a challenge, try asking questions like: What’s most important to you about it? What’s holding you back? What does success look like? Let’s say my teammate comes to me and says they’re ready for a\npromotion. Open questions could help this teammate explore what this promotion\nmeans and demonstrate to me what introspection they’ve already done around it.\nRather than telling them what I think is necessary for them to be promoted, I\ncould instead open up this conversation by asking them: What would you be able to do in the new level\nthat you can’t do in your current one? What skills are required in the new level? What\nare some ways that you’ve honed those skills? Who are the people already at that level that\nyou want to emulate? What about them do you want to emulate?  Their answers would give me a place to start coaching. These questions might push my teammate to think more deeply about what this promotion means, rather than allowing them to stay surface level and believe that a promotion is about checking off a lot of boxes on a list. Their answers might also open   eyes to things that I hadn’t seen before, like a piece of work that my teammate had accomplished that made a huge impact. But most important, going into coaching mode would start a two-way conversation with this teammate, which would help make an otherwise tricky conversation feel more like a shared exploration. Open\nquestions, asked from a place of genuine curiosity, help people feel seen and\nheard. However, if the way you ask your questions comes across as judgy or like\nyou’ve already made some assumptions, then your questions aren’t truly open\n(and your teammate can smell this on you!). Practice your intonation to make\nsure your open questions are   curious and open.  By the way, forming lots of open questions (instead of problem solving questions, or giving advice) is tremendously hard for most people. Don’t worry if you don’t get the hang of it at first; it takes a lot of practice and intention over time to default to coaching mode rather than mentoring mode. I promise, it’s worth it. Reflections Just like open questions, reflections help the other person feel\nseen and heard, and to explore the topic more deeply.  It’s almost comical how rarely we get the sense that the person\nwe’re talking to is actively listening to us, or focusing entirely on helping\nus connect our own dots. Help your teammates reflect by repeating back to them\nwhat you hear them say, as in: “What I’m hearing you say is that you’re\nfrustrated with how this project is going. Is that right?” “What I know to be true about you is how deeply\nyou care about your teammates’ feelings.” In each of these\nexamples, you are holding up a metaphorical mirror to your teammate, and\nhelping them look into it. You can coach them to reflect, too: “How does this new architecture project map to\nyour goals?” “Let’s reflect on where you were this time last\nyear and how far you’ve come.” Occasionally, you might get a reflection wrong; this gives the\nother person an opportunity to realize something new about their topic, like\nthe words they’re choosing aren’t quite right, or there’s another underlying\nissue that should be explored. So don’t be worried about giving a bad\nreflection; reflecting back what you’re hearing will still help your teammate. The act of reflecting can help the other person do a gut check to\nmake sure they’re approaching their topic holistically. Sometimes the act of\nreflection forces (encourages?) the other person to do some really hard work:  .\nIntrospection creates an opportunity for them to realize new aspects of the\nproblem, options they can choose from, or deeper meanings that hadn’t occurred\nto them before—which often ends up being a nice shortcut to the right solution.\nOr, even better, the right problem statement.  When you have your coaching hat on, you don’t need to have all the answers, or even fully understand the problem that your teammate is wrestling with; you’re just there as a mirror and as a question-asker, to help prompt the other person to think deeply and come to some new, interesting conclusions. Frankly, it may not feel all that effective when you’re in coaching mode, but I promise, coaching can generate   for that other person than just giving them advice or sharing your perspective.   Choose coaching when you’re looking to help someone (especially an emerging leader) hone their strategic thinking skills, grow their leadership aptitude, and craft their own path forward. Coaching mode is all about helping your teammate develop their own brain wrinkles, rather than telling them how you would do something. The introspection and creativity it inspires create deeper and longer-lasting growth.  Sponsoring While you wear the mentoring and coaching hats around your\nteammates, the sponsor hat is more often worn when they’re   around,\nlike when you’re in a 1:1 with your manager, a sprint planning meeting, or\nanother environment where someone’s work might be recognized. You might hear\nabout an upcoming project to acquire a new audience and recommend that a\nbudding user researcher take it on, or you’ll suggest to an All Hands meeting\norganizer that a junior designer should give a talk about a new pattern they’ve\nintroduced to the style guide.  Sponsorship is all about feeling   for getting\nsomeone to the next level. As someone’s sponsor, you’ll put their name in the\nring for opportunities that will get them the experience and visibility\nnecessary to grow in their role and at the organization. You will put your\npersonal reputation on the line on behalf of the person you’re sponsoring, to\nhelp get them visible and developmental assignments. It’s a powerful tool, and\nthe one most effective at helping someone get to the next level (way more so\nthan mentoring or coaching!).  The Center for Talent Innovation routinely   (PDF). Their studies have found that when someone has a sponsor, they are way more likely to have access to career-launching work. They’re also more likely to take actions that lead to even   growth and opportunities, like asking their manager for a stretch assignment or a raise.  When you’re in sponsorship mode, think about the different\nopportunities you have to offer up someone’s name. This might look like: giving visible/public recognition (company\n“shout outs,” having them present a project demo, thanking them in a launch\nemail, giving someone’s manager feedback about their good work); assigning stretch tasks and projects that are   their current skill set, to help them grow and have supporting\nevidence for a future promotion; or opening the door for them to write blog posts,\ngive company or conference talks, or contribute open-source work. Remember that members of underrepresented groups are typically  . These individuals get   of advice (often unsolicited), coffee outings, and offers to teach them new skills. But it’s much rarer for them to see support that looks like sponsorship.  This isn’t because sponsors intentionally ignore marginalized folks, but because of  . Because of how our brains (and social networks) work, the people we’re closest to tend to look mostly like us—and we draw from that same pool when we nominate people for projects, for promotions, and for hires. Until I started learning about bias in the workplace, most of the people I sponsored were white, cisgender women, like myself. Since then, I’ve actively worked to sponsor people of color and nonbinary people. It takes effort and intention to combat our default behaviors—but I know you can do it! Take a look at the daily communications you participate in: your work chat logs, the conversations you have with others, the process for figuring out who should fix a bug or work on a new project, and the processes for making your teams’ work visible (like an architecture review, code review, launch calendar, etc.). You’ll be surprised how many moments there are to sponsor someone throughout an average day. Please put in the time and intention to ensure that you’re sponsoring members of underrepresented groups, too.  Like this: \n\t\t\t\t\t\t\tRecently by Lara Hogan\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/responsible-javascript-part-2/", "title": "Responsible JavaScript: Part II", "content": "You and the rest of the dev team lobbied enthusiastically for a total re-architecture of the company’s aging website. Your pleas were heard by management—even up to the C-suite—who gave the green light. Elated, you and the team started working with the design, copy, and IA teams. Before long, you were banging out new code. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. It started out innocently enough with an   here and an   there. Before you knew it, though, you were installing production dependencies like an undergrad doing keg stands without a care for the morning after. Then you launched. Unlike the aftermath of most copious boozings, the agony didn’t start the morning after.  , no. It came months later in the ghastly form of low-grade nausea and headache of product owners and middle management wondering why conversions and revenue were both down since the launch. It then hit a fever pitch when the CTO came back from a weekend at the cabin and wondered why the site loaded so slowly on their phone—if it indeed ever loaded at all. Everyone was happy. Now   one is happy. Welcome to your first JavaScript hangover. It’s not your fault When you’re grappling with a vicious hangover, “I told you so” would be a well-deserved, if fight-provoking, rebuke—assuming you could even fight in so sorry a state. When it comes to JavaScript hangovers, there’s plenty of blame to dole out. Pointing fingers is a waste of time, though. The landscape of the web today demands that we iterate faster than our competitors. This kind of pressure means we’re likely to take advantage of any means available to be as productive as possible.   means we’re more likely—but not necessarily doomed—to build apps with more overhead, and possibly use patterns that can hurt performance and accessibility. Web development isn’t easy. It’s a long slog we rarely get right on the first try. The best part of working on the web, however, is that we don’t   to get it perfect at the start. We can make improvements after the fact, and that’s just what the second installment of   is here for. Perfection is a long ways off. For now, let’s take the edge off of that JavaScript hangover by improving your site’s, er,   in the short term. Round up the usual suspects It might seem rote, but it’s worth going through the list of basic optimizations. It’s not uncommon for large development teams—particularly those that work across many repositories or don’t use optimized boilerplate—to overlook them. Shake those trees First, make sure your toolchain is configured to perform  . If tree shaking is new to you, I wrote   you can consult. The short of it is that tree shaking is a process in which unused exports in your codebase don’t get packaged up in your production bundles. Tree shaking is available out of the box with modern bundlers such as  ,  , or  .   or  —which are not  , but rather  —won’t do this for you. A task runner doesn’t build a   like a bundler does. Rather, they perform discrete tasks on the files you feed to them with any number of plugins. Task runners   be extended with plugins to use bundlers to process JavaScript. If extending task runners in this way is problematic for you, you’ll likely need to manually audit and remove unused code. For tree shaking to be effective, the following must be true: On the off chance tree shaking isn’t occurring during your build, getting it to work may help. Of course, its effectiveness varies on a case-by-case basis. It also depends on whether the modules you import introduce  , which may influence a bundler’s ability to shake unused exports. Split that code Chances are good that you’re employing some form of  , but it’s worth re-evaluating how you’re doing it. No matter   you’re splitting code, there are two questions that are always worth asking yourself: These are important because reducing redundant code is essential to performance. Lazy loading functionality also improves performance by lowering the initial JavaScript footprint on a given page. On the redundancy front, using an analysis tool such as   can help you find out if you have a problem. Where lazy loading is concerned, it can be a bit difficult to know where to start looking for opportunities. When I look for opportunities in existing projects, I’ll search for user interaction points throughout the codebase, such as click and keyboard events, and similar candidates. Any code that requires a user interaction to run is a potentially good candidate for dynamic  . Of course, loading scripts on demand brings the possibility that interactivity could be noticeably delayed, as the script necessary for the interaction must be downloaded first. If data usage is not a concern, consider using the   to load such scripts at a low priority that won’t contend for bandwidth against critical resources.   is good, but nothing will break if it’s unsupported, as such browsers will ignore markup they doesn’t understand. Externalize third-party hosted code Ideally, you should self-host as many of your site’s dependencies as possible. If for some reason you   load dependencies from a third party,   in your bundler’s configuration. Failing to do so could mean your website’s visitors will download both locally hosted code   the same code from a third party. Let’s look at a hypothetical situation where this could hurt you: say that your site loads Lodash from a public CDN. You’ve also installed Lodash in your project for local development. However, if you fail to mark Lodash as external, your production code will end up loading a third party copy of it   to the bundled, locally hosted copy. This may   like common knowledge if you know your way around bundlers, but I’ve seen it get overlooked. It’s worth your time to check twice. If you aren’t convinced to self-host your third-party dependencies, then consider adding  ,  , or possibly even   hints for them. Doing so can lower your site’s   and—if JavaScript is critical to rendering content—your site’s  . Smaller alternatives for less overhead  is like an obscenely massive candy store, and we as developers are awed by the sheer amount of open source offerings. Frameworks and libraries allow us to extend our applications to quickly do all sorts of stuff that would otherwise take loads of time and effort. While I personally prefer to aggressively minimize the use of client-side frameworks and libraries in my projects, their value is compelling. Yet, we   have a responsibility to be a bit hawkish when it comes to what we install. When we’ve already built and shipped something that depends on a slew of installed code to run, we’ve accepted a baseline cost that only the maintainers of that code can practically address. Right? Maybe, but then again, maybe not. It depends on the dependencies used. For instance, React is extremely popular, but   is an   alternative that largely shares the same API and retains compatibility with many React add-ons.   and   are much more compact alternatives to  , which is  . Libraries such as   offer many useful methods. Yet, some of them are easily replaceable with native ES6.  , for example, is replaceable with the  .   without much effort, and without the need for pulling in a large utility library. Whatever your preferred tools are, the idea is the same: do some research to see if there are smaller alternatives, or if native language features can do the trick. You may be surprised at how little effort it may take you to seriously reduce your app’s overhead. Differentially serve your scripts There’s a good chance you’re using Babel in your toolchain to transform your ES6 source into code that can run on older browsers. Does this mean we’re doomed to serve giant bundles even to browsers that don’t need them, until the older browsers disappear altogether?  ! Differential serving helps us get around this by generating two different builds of your ES6 source: Bundle one, which contains all the transforms and polyfills required for your site to work on older browsers. You’re probably already serving this bundle right now. Bundle two, which contains   of the transforms and polyfills because it targets modern browsers. This is the bundle you’re probably not serving—at least not  . Achieving this is a bit involved.  , so there’s no need for a deep dive here. The long and short of it is that you can modify your build configuration to generate an additional but smaller version of your site’s JavaScript code, and serve it only to modern browsers. The best part is that these are savings you can achieve without sacrificing any features or functionality you already offer. Depending on your application code, the savings could be quite significant. The   for serving these bundles to their respective platforms is brief. It also works a treat in modern browsers: Unfortunately, there’s a caveat with this pattern: legacy browsers like IE 11—and even relatively modern ones such as Edge versions 15 through 18—will download   bundles. If this is an acceptable trade-off for you, then worry no further. On the other hand, you’ll need a workaround if you’re concerned about  . Here’s one potential solution that uses script injection (instead of the   tags above) to avoid double downloads on affected browsers: This script infers that if a browser supports   in the   element, it understands  . This ensures that legacy browsers only get legacy scripts and modern browsers only get modern ones. Be warned, though, that dynamically injected scripts load asynchronously by default, so set the   attribute to   if dependency order is crucial. Transpile less I’m not here to trash Babel. It’s indispensable, but lordy, it adds a   of extra stuff without your ever knowing. It pays to peek under the hood to see what it’s up to. Some minor changes in your coding habits can have a positive impact on what Babel spits out. To wit:   are a   handy ES6 feature you probably already use: The thing to pay attention to here is the   parameter, which has a default of “log.” This means if we want to invoke   with this wrapper function, we don’t need to specify  . Great, right? Except when Babel transforms this function, the output looks like this: This is an example of how, despite our best intentions, developer conveniences can backfire. What was a handful of bytes in our source has now been transformed into   larger in our production code. Uglification can’t do much about it either, as arguments can’t be reduced. Oh, and if you think   might be a worthy antidote, Babel’s transforms for them are even bulkier: Worse yet, Babel transforms this code even for projects with a   configuration  , meaning the modern bundles in your differentially served JavaScript will be affected too! You   use   to soften the blow—and that’s a fine idea, as they’re often quite a bit smaller than their more spec-compliant counterparts— . Regardless of whether you decide to enable loose transforms, here’s one way to cut the cruft of transpiled default parameters: Of course, default parameters aren’t the   feature to be wary of. For example,   gets transformed, as do   and a whole host of  . If you don’t want to avoid these features altogether, you have a couple ways of reducing their impact: This is solely my opinion, but I believe the best choice is to avoid transpilation altogether in bundles generated for modern browsers. That’s not always possible, especially if you use  , which must be transformed for   browsers, or if you’re using bleeding edge language features that aren’t widely supported. In the latter case, it might be worth asking if those features are really necessary to deliver a good user experience (they rarely are). If you arrive at the conclusion that Babel must be a part of your toolchain, then it’s worth peeking under the hood from time to time to catch suboptimal stuff Babel might be doing that you can improve on. Improvement is not a race As you massage your temples wondering when this horrid JavaScript hangover is going to lift, understand that it’s precisely when we rush to get something out there as fast as we possibly can that the user experience can suffer. As the web development community obsesses on iterating faster in the name of competition, it’s worth your time to  . You’ll find that by doing so, you may not be iterating as fast as your competitors, but   will be   than theirs. As you take these suggestions and apply them to your codebase, know that progress doesn’t spontaneously happen overnight. Web development is a job. The truly impactful work is done when we’re thoughtful and dedicated to the craft for the long haul. Focus on steady improvements. Measure, test, repeat, and your site’s user experience will improve, and you’ll get faster bit by bit over time. Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/getting-to-the-heart-of-digital-accessibility/", "title": "Getting to the Heart of Digital Accessibility", "content": "Quick! Think of the word “developer” or “coder” — what’s the first thing that comes to mind? Maybe a whiteish male in his twenties living in a busy metropolis, wearing a nerdy t-shirt and hoodie? Someone a bit like Mark Zuckerberg? Or maybe a younger Bill Gates or Sergey Brin? Any of the dudes from the HBO series  , perhaps? Certainly no one like me. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. By tech standards, I’m old. I’m also female   a mother. I live in a midwestern town you’ve never heard of and will never visit — a town where the cows vastly outnumber the people. My hair color is (almost) natural and is no longer part of the ROYGBIV collection, so I have no perceived conference street cred. I own about a thousand geeky T-shirts, but never actually wear them in public, opting for more “girly” attire (or so was pointed out by a male colleague). On the surface, I look more suited to taking notes at a PTA meeting than writing code. I’m a bit of an outsider. A tech misfit. So when my 11-year-old daughter finished her recent coding camp and excitedly declared, “Now I’m a real developer, Mom, just like you!” there was the usual parent pride, but also a small piece of me that cringed. Because, as much as I support the STEM fields, and want the next generation of girls to be coding wizard-unicorn-ninjas, I really don’t want my own daughter to be a developer. The rationale behind this bold (and maybe controversial) statement comes from a place of protection. The tech world we live in today is far from perfect. I’ve endured my share of misogyny, self-doubt, and sexual harassment. Why wouldn’t I want to protect her from all of that? The (diversity) elephant in the (computer) room You’ve heard this story before: there is not enough diversity in tech. This puzzling trend seems to continue year after year, even though numerous studies show that by including more people from underrepresented communities, a company can increase its  ,  , and  . Even with the recent push and supposed support for diversity and inclusivity from many Fortune 500 companies, women and female-identifying people still only hold  . The data from FY 2018 shows that the number of women in technical roles at three of the top tech giants was  ,  , and  . While these numbers show that there is still not enough representation for women, these numbers do reflect a slight increase from the previous year (FY 2017: Adobe 22%, Google 25%, Facebook 15%). But even with this upward trend of hiring women in tech roles, the marginal growth rate has not caught up with the real world. The tech workforce is seriously out of touch with reality if, in 2019, a demographic (women) that represents more than half the global population is still considered a minority. Sometimes this lack of diversity at the top level is blamed on a “pipeline” issue. The logic being: “If there are not enough girls who learn to code, then there will not be enough women who can code.” However, programs aimed at   have skyrocketed in the past few years. Girls now make up about   in high-school coding classes and are scoring almost identically to their male classmates on standardized math and science tests, yet, young women make up only  . I have to wonder if this steep drop in interest has more to do with lack of representation in the tech sphere, than with girls and young women simply not being “smart enough” or “not interested” in working with code? At the very least, the lack of representation certainly doesn’t help. Of course, the diversity picture becomes even more abysmal when you consider other underrepresented groups such as people of color, people from the LGBTQ community, and people with disabilities. And while I really don’t like glossing over these deeper diversity issues in tech, because they are abundant and are much more grotesque failings than the male/female ratio, I also don’t feel qualified to speak about these issues. I encourage you to look to and value the voices of others who can speak with higher authority on these deeper diversity issues, such as  ,  ,  ,  ,  ,  ,  ,  , and so many others. And for those readers who are new to the topic of diversity in tech, watch Tatiana Mac’s recent conference talk   — it’s well worth the 35 minutes of your life. The four stages in the digital accessibility journey However you look at it, the numbers don’t lie. There are some pretty significant diversity issues in tech. So how do we fix this issue before the next wave of young developers join the tech workforce? Simple: teach developers to write accessible code. This may seem like a joke to some and stretch to others, but hear me out. When we talk about accessible code, what we are really talking about at its core is inclusiveness. The actual process of writing accessible code involves rules and standards, tests and tools; but inclusive development is more abstract than that. It’s a shift in thinking. And when we rethink our approach to development, we go beyond just the base level of simple code functionality. We instead think,   is this code consumed? How can we make it even more intelligible and easier for people to use? Inclusive development means making something valuable, not just accessible, to as many people as we can. That line of thinking is a bit abstract, so let’s go through an example. Let’s say you are tasked with updating the color contrast between the text on a webpage or app and the background. What happens at each stage in the accessibility journey? — You are brand new to digital accessibility and are still trying to understand what it is and how you can implement changes in your daily workflow. You may be aware that there is a set of   that other developers follow, but you are a bit hazy on what it all means in a practical sense. — You know a bit more about digital accessibility and feel comfortable using a few testing tools, so you run an automated accessibility test on your website and it flags a possible issue with the color contrast. Based on your awareness of the guidelines, you know the   between the text and the background needs to be a certain number and that you need a tool to test this. — Feeling more confident in your knowledge of digital accessibility rules and best practices, you use a   between the text and the background. Then based on the output of the tool, you modify the hex code to meet the color contrast ratio guidelines and retest to confirm you have met the accessibility requirements for this issue. — You understand that the accessibility guidelines and tools are created with people in mind, and that code is secondary to all of that. One is the means, and the other is the end. In the color contrast example, you understand that people with low-vision or colorblindness need these color contrast changes in order to actually   the words on your web page. This is a bit of an oversimplification of the process. But I hope you get the gist — that there are different stages of digital accessibility knowledge and understanding. True beginners may not be to even stage one, but I am finding that group rarer and rarer these days. The word about digital accessibility seems to be out! Which is great; but that’s only the first hurdle. What I’m seeing now is that a lot of people stop at   or  — where you are aware of the digital accessibility guidelines, have some testing tools in your back pocket, and know how to fix some of the issues reported, but haven’t quite connected the dots to the humans they impact. From the standpoint of getting daily stuff done, stages two and three are okay stopping points. But what happens when the things you need to do are too complex for a quick fix, or you have no buy-in from your peers or management? I feel that once we get to  , and really get   these kinds of changes are needed, people will be more motivated to make those changes regardless of the challenges involved. When you arrive at stage four, you have gone beyond knowing the basic rules, testing, and coding. You recognize that digital accessibility is not just a “nice to have” but a “must have” and it becomes about quality of life for   people. This is digital inclusion. This is something you can’t unsee, you can’t unlearn, and you can’t ignore. Making digital accessibility a priority — not a requirement In my role as an accessibility trainer, I like to kick-off each session with the question: “What are you hoping to learn today about digital accessibility?” I ask this question to establish a rapport with the audience and to understand where everyone is in their accessibility journey, but I am also evaluating the level of company and individual buy-in too. There is nothing worse than showing up to teach a group that does not care to be taught. If I hear the words “I am only here because I have to be” — I know it will be an uphill battle to get them anywhere close to  , so I mentally regroup and aim for another stage. In my experience, when companies and their leaders say “Digital accessibility is a requirement,” nine times out of ten there is a motivating factor behind this sweeping declaration (for example, impending litigation, or at least the fear of it). When changes are framed as mandatory and packaged as directives from on high with little additional context, people can be resistant and will find excuses to fight or challenge the declaration, and any change can become an uphill battle. Calling something “mandatory” only speaks to  . By swapping out one word from the original declaration and saying “Digital accessibility is a priority,” companies and their leaders have reframed the conversation with their employees. When changes are framed as “working towards a solution” and discussed openly and collaboratively, people feel like they are part of the process and are more open to embracing change. In the long run, embracing change becomes part of a company’s culture and leads to innovation (and, yes, inclusion) on all levels. Calling something a priority speaks to  . Some of the excuses I often hear from clients for not prioritizing accessibility is that it is too difficult, too costly, and/or too time consuming — but is that really the case? In the same accessibility training, I lead an exercise where we look at a website with an accessibility testing tool and review any issues that came up. With the group’s help we plot out the “impact to user” versus the “remediation effort” on the part of the team. From group to group, while the plots are slightly different, one commonality is that close to 80% of the errors plotted fall into the quadrant of “simple to fix” for the team, but they also fall under “high impact” to the user. Based on this empirical data, I won’t buy the argument from clients who say that accessibility is too difficult and costly and time consuming anymore. It comes down to whether it’s a priority — for each individual and for the company as a whole. What will your coding legacy be? The   states that a monkey hitting keys at random on a typewriter for an infinite amount of time will eventually type any given text, such as the complete works of William Shakespeare. So by that same logic, a programmer hitting keys at random on a computer for an infinite amount of time will almost surely produce a website that is accessible. But where is the thought process? Where is the human element? While all the things we’ve already talked about — awareness, education, and prioritization of accessibility are important steps in making the digital world more inclusive to all — without  we are just going to keep randomly tapping away at our computers, repeating the same mistakes over and over again. The intent behind the code has to be part of the process, otherwise accessibility is just another task that has no meaning. Maybe I’m naive, but I’d like to think we’ve come to a point in our society where we want our work lives to have meaning. And that we don’t want to just hear about the positive change that is happening, but want to be part of the change. Digital accessibility is a place where this can happen! Not only does understanding and writing purpose-driven code help people with disabilities in the short-run, I believe strongly that is key to solving the overarching diversity issue in tech in the long-run. Developers who reach  , and who prioritize accessible code because they understand it’s fundamentally about  , will also be the ones who help create and cultivate an inclusive environment where people from more diverse backgrounds are also prioritized and accepted in the tech world. Because when you strip away all the styles, all the mark-up, all the cool features from a website or app — what’s left? People. And honestly, the more I learn about digital accessibility, the more I realize it’s not about the code at all. Digital accessibility is rooted in the user; and, while I ( ) can certainly teach you how to write accessible code, and build you tools, patterns, and libraries to use, I realize we can’t teach you to care. That is a choice you have to make yourself. So think for a moment — what are you leaving the next generation of developers with all that inaccessible code you haven’t given much thought to? Is it the coding legacy you really want to leave? I challenge you to do better for my daughter, her peers, and for the countless others who are not fully represented in the tech community today. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-career-management-document/", "title": "An Essential Tool for Capturing Your Career Accomplishments", "content": "Imagine you’re ready to apply for your next job. Like most busy professionals, you probably haven’t updated your résumé or your portfolio since you looked for your current job.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Now you need to update both, and you can’t remember what work you’ve done over the past few years. (In fact, you can barely remember what you’ve done over the past few months!) So you scramble to update your résumé with new content. Then you spend all weekend scraping together a new portfolio using screenshots of whatever work evidence you can find on your laptop. You submit the résumé and portfolio with your application, hoping you didn’t forget to include any major career milestones you achieved over the last few years.  This is the process most of us use to approach our job search. We wait until we’re ready to find a job, panic at our lack of résumé and portfolio, and pull together a “good enough” version of each for the job application. (Trust me, I’ve done this many times myself.) This is a stressful and ineffective way to approach a job search. There’s a much better approach you can take—and you can start working on it now, even if you’re not on the job market. A Career Management Document (CMD) is a comprehensive collection of your résumé and portfolio content. It’s a document you update regularly, over time, with all the work you’ve done.  When you’re ready to apply for your next job, you’ll have all the résumé and portfolio pieces available in your CMD. All you need to do is assemble those pieces into résumé and portfolio documents, then send the documents off with your job application. I update my CMD about once a week. I start by reviewing evidence of my recent work. I review Slack messages, Basecamp posts, emails, and any other current work-related content. I write my accomplishments in the format of résumé bullets, using the  . Then I add those bullets to the CMD.  Here are some examples from my CMD: Coached a student on writing a stronger portfolio story to showcase their advanced UX skills, resulting in the student getting a job interview. Facilitated an end-of-study analysis in under 90 minutes to help the team synthesize user research data from 12 participants. Led a remote retrospective with teams in two offices, developed actionable takeaways, and ended on time despite a delayed start. My CMD has several hundred résumé bullets, and it continues to grow. I organize content by year and by project. Within each project are responsibilities and accomplishments. I add any content to the CMD that might go into my résumé someday. I include everything I can think of, even if it seems insignificant or trivial at the time.  For example, I sometimes help with social media marketing at Center Centre, the UX design school where I’m a faculty member. I include it in my CMD. I don’t plan to pursue social media marketing as a career, but it may be relevant to a future job. Who knows—I may apply to work for an organization that makes social media marketing software someday. In that case, my social media experience could be relevant. In addition to capturing bullets for my résumé, I capture content for my portfolio. Each week, I gather screenshots of my work, photos of me working with the team, and any other artifacts I can find. I store them in an organized system I can reference later.  I also take brief notes about the work I did and store them with the artifacts. That way, if I look back at these materials a year from now, I’ll have notes about what I did during the project, reminding me of the details. For example, after I facilitated a user research analysis session late last year, I captured evidence of it for my portfolio. I included photos of the whiteboard where I recorded public notes during the session. I also captured brief notes about who attended the session, the date, and when it took place during the project.  You can use whatever tools you’d like to gather evidence of your work. I use Google Docs for the résumé portion of my CMD. I use Dropbox to store my portfolio artifacts. I create Dropbox folders with dates and project names that correspond to the contents of my CMD. The key is to collect the evidence regularly and store it in an accessible, organized way that works for you. To know if you’re storing work evidence effectively, ask yourself, “Will I understand this CMD content a year from now based on how I’m capturing and storing it today?” If the answer is “yes,” you’re in good shape. For the CMD to work when you need it, it needs to be comprehensive and up-to-date. As I mentioned before, I update my CMD once a week. I schedule thirty minutes on my calendar each week so I remember to do it.  Sometimes I have a busy week, and I can’t spend thirty minutes on my CMD. So I spend whatever amount of time I have. Some weeks, I only spend ten minutes. Ten minutes per week is better than zero minutes per week.  Occasionally, I don’t get a chance to update it because my week is so hectic. That’s OK because I’ll probably get to it the following week.  I recommend updating your CMD once a week and not once a month or once a quarter. If you wait even a month, you’ll have trouble remembering what you did three and a half weeks ago. Even worse, if you schedule a CMD update once a month and then miss it, you won’t get to it until the next month. That means you have to think back and remember two months of work, which is hard to do.  Updating your CMD every week, while the work is fresh in your mind, gets the best results. The CMD can help you prepare for your job search beyond your résumé and your portfolio.  You can use it to prepare for a job interview. Since you’re capturing work evidence from each stage of the process in your CMD, you can use that evidence to remember what you did throughout a project. Then, you can craft a story about your role on that project.  Hiring managers love to hear stories about your work during job interviews. For instance, if you’re a designer, they want to know the journey you took during your design process, from the start of a project to the end. A detailed CMD will help you remember this process so you can share it in an interview.  I’ve even used my CMD to write blog posts. I’ve been blogging regularly for the past two years, and I often refer to my CMD to remember work experience I had that’s relevant to what I’m writing. When I wrote the article “ ,” I used my CMD to remember interview preparation exercises I did with students.  The CMD can also help you track work accomplishments for your quarterly or annual performance reviews. Additionally, you can use it to write job ads when hiring for related roles on your team. Lastly, I find it rewarding to peruse my CMD now and then, especially when I look back at work I did over a year ago. The CMD serves as a record of all my professional accomplishments. This record helps me appreciate my professional growth because I see how far my skills have come over time. At Center Centre, we originally learned about the Career Management Document through the  . Manager Tools’ podcasts explain how to use a CMD for your résumé. We expanded their approach to include portfolio work as well. I recommend listening to their podcasts about creating and maintaining your CMD: We tell our students at Center Centre that preparing for your next job search is a process that starts early. It’s like saving for retirement—the sooner you start saving money, the more likely you are to be prepared when the time comes.  Similarly, collecting résumé and portfolio content ahead of time will prepare you to find your next job whenever you’re ready to do so. It also prepares you for a sudden job termination like an unexpected layoff. If you lose your job without warning, you’ll likely be under a lot of stress to find a new position. Having a CMD ready will relieve the additional stress of building a résumé and portfolio from scratch.  If you don’t have a CMD yet, now is a great time to start one. Schedule 30 minutes this week to begin crafting your repository of work accomplishments. You’ll be glad you did when you seek your next job. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-untapped-power-of-vulnerability-transparency-in-content-strategy/", "title": "The Untapped Power of Vulnerability & Transparency in Content Strategy", "content": "In marketing, transparency and vulnerability are unjustly stigmatized. The words conjure illusions of being frightened, imperfect, and powerless. And for companies that shove carefully curated personas in front of users, little is more terrifying than losing control of how people perceive the brand. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Let’s shatter this illusioned stigma.  . And companies too scared to embrace both traits in their content forfeit bona fide user-brand connections for often shallow, misleading engagement tactics that create fleeting relationships. Transparency and vulnerability are closely entwined concepts, but each one engages users in a unique way. Transparency is how much information you share, while vulnerability is the truth and meaning behind your actions and words. Combining these ideas is the trick to creating empowering and meaningful content. You can’t tell true stories of vulnerability without transparency, and to be authentically transparent you must be vulnerable. To be vulnerable, your brand and its content must be brave, genuine, humble, and open, all of which are traits that promote long-term customer loyalty. And if you’re transparent with users about who you are and about your business practices, you’re courting   who say they’re more loyal to brands that offer complete openness and   who say they give transparent companies a second chance after a bad experience. For many companies, being completely honest and open with their customers—or employees, in some cases—only happens in a crisis. Unfortunately for those businesses, using vulnerability and transparency only as a crisis management strategy diminishes how sincere they appear and can  . Unlocking the potential of being transparent and vulnerable with users isn’t a one-off tactic or quick-fix emergency response tool—it’s a commitment to intimate storytelling that embraces a user’s emotional and psychological needs, which builds a meaningful connection between the storyteller and the audience. The three storytelling pillars of vulnerable and transparent content In her book,  , sociologist Brené Brown explains that vulnerability connects us at an emotional level. She says that when we recognize someone is being vulnerable, we invest in their story and begin to develop an emotional bond. This interwoven connection encourages us to experience the storyteller’s joy and pain, and then creates a sense of community and common purpose among the person being vulnerable and the people who acknowledge that vulnerability. Three pillars in a company’s lifecycle embrace this bond and provide an outline for telling stories worthy of a user’s emotional investment. The pillars are: the origins of a company, product, idea, or situation; intimate narratives about customers’ life experiences; and insights about product success and failure. Origin stories An origin story spins a transparent tale about how a company, product, service, or idea is created. It is often told by a founder, CEO, or industry innovator. This pillar is usually used as an authentic way to provide crisis management or as a method to change how users feel about a topic, product, or your brand. Customers’ life experiences While vulnerable origin stories do an excellent job of making users trust your brand, telling a customer’s personal life story is arguably the most effective way to use vulnerability to entwine a brand with someone’s personal identity. Unlike an origin story, the customer experiences pillar is focused on being transparent about who your customers are, what they’ve experienced, and how those journeys align with values that matter to your brand. Through this lens, you’ll empower your customers to tell emotional, meaningful stories that make users feel vulnerable in a positive way. In this situation, your brand is often a storytelling platform where users share their story with the brand and fellow customers. Product and service insights Origin stories make your brand trustworthy in a crisis, and customers’ personal stories help users feel an intimate connection with your brand’s persona and mission. The last pillar, product and service insights, combines the psychological principles that make origin and customer stories successful. The outcome is a vulnerable narrative that rallies users’ excitement about, and emotional investment in, what a company sells or the goals it hopes to achieve. Vulnerability, transparency, and the customer journey The three storytelling pillars are crucial to embracing transparency and vulnerability in your content strategy because they let you target users at specific points in their journey. By embedding the pillars in each stage of the customer’s journey, you teach users about who you are, what matters to you, and why they should care. For our purposes, let’s define the user journey as: awareness; interest; consideration; conversion; and retention. Awareness People give each other   to make a good first impression. We’re not so generous with brands and websites. After discovering your content, users determine if it’s trustworthy within  . Page design and aesthetics are often  , but the information users discover after that decision shapes their long-term opinions about your brand. This snap judgement is why transparency and vulnerability are crucial within awareness content. When you only get one chance to make a positive first impression with your audience, what content is going to be more memorable? Typical marketing “fluff” about how your brand was built on a shared vision and commitment to unyielding customer satisfaction and quality products? Or an upfront, authentic, and honest story about the trials and tribulations you went through to get where you are now? Buffer, a social media management company that helped pioneer  , chose the latter option. The outcome created awareness content that leaves a positive lasting impression of the brand. In 2016, Joel Gascoigne, cofounder and CEO of Buffer, used an origin story to discuss the mistakes he and his company made that resulted in laying off 10 employees. In the blog post “ ,” Gascoigne wrote about Buffer’s over-aggressive growth choices, lack of accountability, misplaced trust in its financial model, explicit risk appetite, and overenthusiastic hiring. He also discussed what he learned from the experience, the changes Buffer made based on these lessons, the consequences of those changes, and next steps for the brand. Gascoigne writes about each subject with radical honesty and authenticity. Throughout the article, he’s personable and relatable; his tone and voice make it obvious he’s more concerned about the lives he’s irrevocably affected than the public image of his company floundering. Because Gascoigne is so transparent and vulnerable in the blog post, it’s easy to become invested in the narrative he’s telling. The result is an article that feels more like a deep, meaningful conversation over coffee instead of a carefully curated, PR-approved response. Yes, Buffer used this origin story to confront a PR crisis, but they did so in a way that encouraged users to trust the brand. Buffer chose to show up and be seen when they had no control over the outcome. And because Gascoigne used vulnerability and transparency to share the company’s collective pain, the company reaped positive press coverage and support on social media—further improving brand awareness, user engagement, and customer loyalty. However, awareness content isn’t always brand focused. Sometimes, smart awareness content uses storytelling to teach users and shape their worldviews. The   is an excellent example. The annual   evaluates how the global public perceives science. The 2019 report shows that 87 percent of people acknowledge that science is necessary to solve the world’s problems, but 33 percent are skeptical of science and believe that scientists cause as many problems as they solve. Furthermore, 57 percent of respondents are skeptical of science because of scientists’ conflicting opinions about topics they don’t understand. 3M, the multinational science conglomerate that publishes the report, says the solution for this anti-science mindset is to promote intimate storytelling among scientists and layfolk. 3M creates an origin story with its awareness content by focusing on the ins and outs of scientific research. The company is open and straightforward with its data and intentions, eliminating any second guesses users might have about the content they’re digesting. The company kicked off this strategy on three fronts, and each storytelling medium interweaves the benefits of vulnerability and transparency by encouraging researchers to tell stories that lead with how their findings benefit humanity. Every story 3M tells focuses on breaking through barriers the average person faces when they encounter science and encouraging scientists to be vulnerable and authentic with how they share their research. First, 3M began a podcast series known as  . In the podcast, 3M Chief Science Advocate Jayshree Seth interviews scientists and educators about the global perception of science and how science and scientists affect our lives. The show is currently in its second season and discusses a range of topics in science, technology, engineering, and math. Second, the company worked with science educators, journalist Katie Couric, actor Alan Alda, and former NASA astronaut Scott Kelly to develop the free  . The ebook helps STEM researchers improve how and why they communicate their work with other people—with a special emphasis on being empathetic with non-scientists. The guide breaks down how to develop communications skills, overcome common storytelling challenges, and learn to make science more accessible, understandable, and engaging for others. Last, 3M created a film series called   that explores the day-to-day lives of 3M scientists. In the short videos, scientists give the viewer a glimpse into their hobbies and home life. The series showcases how scientists have diverse backgrounds, hobbies, goals, and dreams. Unlike Buffer, which benefits directly from its awareness content, 3M’s three content mediums are designed to create a long-term strategy that changes how people understand and perceive science, by spreading awareness through third parties. It’s too early to conclude that the strategy will be successful, but it’s off to a good start.   often tops “best of” podcast lists for science lovers, and the   is a popular resource among public universities. Interest How do you court new users when word-of-mouth and organic search dominate how people discover new brands? Target their interests. Now, you can be like the hundreds of other brands that create a “10 best things” list and hope people stumble onto your content organically and like what they see. Or, you can use content to engage with people who are passionate about your industry and have genuine, open discussions about the topics that matter to you both. The latter option is a perfect fit for the product and service insights pillar, and the customers’ life experiences pillar. To succeed in these pillars you must balance discussing the users’ passions and how your brand plays into that topic against appearing disingenuous or becoming too self-promotional. Nonprofits have an easier time walking this taut line because people are less judgemental when engaging with NGOs, but it’s rare for a for-profit company to achieve this balance. SpaceX and Thinx are among the few brands that are able to walk this tightrope. Thinx, a women’s clothing brand that sells period-proof underwear, uses its blog to generate awareness, interest, and consideration content via the customers’ life experiences pillar. The blog, aptly named  , relies on transparency and vulnerability as a cornerstone to engage users about reproductive and mental health. Toni Brannagan, Thinx’s content editor, says the brand embraces transparency and vulnerability by sharing diverse ideas and personal experiences from customers and experts alike, not shying away from sensitive subjects and never misleading users about Thinx or the subjects   discusses. As a company focused on women’s healthcare, the product Thinx sells is political by nature and entangles the brand with themes of shame, cultural differences, and personal empowerment. Thinx’s strategy is to tackle these subjects head-on by having vulnerable conversations in its branding, social media ads, and   content. “Vulnerability and transparency play a role because you can’t share authentic diverse ideas and experiences about those things—shame, cultural differences, and empowerment—without it,” Brannagan says. A significant portion of Thinx’s website traffic is organic, which means  ’s interest-driven content may be a user’s first touchpoint with the brand. “We’ve seen that our most successful organic content is educational, well-researched articles, and also product-focused blogs that answer the questions about our underwear, in a way that’s a little more casual than what’s on our product pages,” Brannagan says. “In contrast, our personal essays and ‘more opinionated’ content performs better on social media and email.” Thanks in part to the blog’s authenticity and open discussions about hard-hitting topics, readers who find the brand through organic search drive the most direct conversions. Conversations with users interested in the industry or topic your company is involved in don’t always have to come from the company itself. Sometimes a single person can drive authentic, open conversations and create endearing user loyalty and engagement. For a company that relies on venture capital investments, NASA funding, and public opinion for its financial future, crossing the line between being too self-promotional and isolating users could spell doom. But SpaceX has never shied away from difficult or vulnerable conversations. Instead, the company’s founder, Elon Musk, embraces engaging with users interests in public forums like Twitter and press conferences. Musk’s tweets about SpaceX are unwaveringly authentic and transparent. He often tweets about his thoughts, concerns, and the challenges his companies face. Plus, Musk frequently engages with his Twitter followers and provides candid answers to questions many CEOs avoid discussing. This authenticity has earned him a  . Musk and SpaceX create conversations that target people’s interests and use vulnerability to equally embrace failure and success. Both the company and its founder give the public and investors an unflinching story of space exploration. And despite laying off 10 percent of its workforce in January of 2019, SpaceX is flourishing. In May 2019, its   and reported  . It also earned global media coverage from launching Musk’s Tesla Roadster into space, recently completed a test flight of its Crew Dragon space vehicle, and cemented multiple new payload contracts. By engaging with users on social media and through standard storytelling mediums, Thinx and SpaceX bolster customer loyalty and brand engagement. Consideration Modern consumers argue that ignorance is not bliss. When users are considering converting with a brand,  . Transparency remains crucial even after they convert, with 85 percent of users saying they’ll support a transparent brand during a PR crisis. Your brand must be open, clear, and honest with users; there is no longer another viable option. So how do you remain transparent while trying to sell someone a product? One solution employed by REI and Everlane is to be openly accountable to your brand and your users via the origin stories and product insights pillars. REI, a national outdoor equipment retailer, created a   that behaves as a multifaceted origin story. The program’s content highlights the company’s history and manufacturing policies, and it lets users dive into the nitty-gritty details about its factories, partnerships, product production methods, manufacturing ethics, and carbon footprint. REI also employs a classic   to let customers find the program and explore its relevant information. From a single landing page, users can easily find the program through the website’s global navigation and then navigate to every tangential topic the program encompasses. REI also publishes an annual stewardship report, where users can learn intimate details about how the company makes and spends its money. Everlane, a clothing company, is equally transparent about its supply chain. The company promotes an insider’s look into its global factories via product insights stories. These glimpses tell the personal narratives of factory employees and owners, and provide insights into the products manufactured and the materials used. Everlane also   of how they comply with the California Transparency in Supply Chains Act to guarantee ethical working conditions throughout its supply chain, including refusing to partner with human traffickers. The crucial quality that Everlane and REI share is they publicize their transparency and encourage users to explore the shared information. On each website, users can easily find information about the company’s transparency endeavors via the global navigation, social media campaigns, and product pages. The consumer response to transparent brands like REI and Everlane is overwhelmingly positive.  , which gives them comfort by knowing they’re purchasing ethical products. REI’s ownership model has further propelled the success of its transparency by using it to create unwavering customer engagement and loyalty. As a co-op where customers can “own” part of the company for a one-time $20 membership fee, REI is beholden to its members, many of which pay close attention to its supply chain and the brands REI partners with. After a deadly school shooting in Parkland, Florida, REI members urged the company to refuse to carry CamelBak products because the brand’s parent company manufactures assault-style weapons. Members argued the partnership violated REI’s supply chain ethics.  . Members rejoiced and REI earned a significant amount of positive press coverage. Conversion Imagine you’ve started incorporating transparency throughout your company, and promote the results to users. Your brand also begins engaging users by telling vulnerable, meaningful stories via the three pillars. You’re seeing great engagement metrics and customer feedback from these efforts, but not much else. So, how do you get your newly invested users to convert? Provide users with a full-circle experience. If you combine the three storytelling pillars with blatant transparency and actively promote your efforts, users often transition from the consideration stage into the conversion state. Best of all, when users convert with a company that already earned their trust on an emotional level,   and emotionally invested in its future. The crucial step in combining the three pillars is consistency. Your brand’s stories must always be authentic and your content must always be transparent. The outdoor clothing brand Patagonia is among the most popular and successful companies to maintain this consistency and excel with this strategy. Patagonia is arguably the most vocal and aggressive clothing retailer when it comes to environmental stewardship and ethical manufacturing. In some cases, the company tells users   because rampant consumerism harms the environment too much, which they care about more than profits. This level of radical transparency and vulnerability skyrocketed the company’s popularity among environmentally-conscious consumers. In 2011, Patagonia took out a   with the headline “Don’t Buy This Jacket.” In the ad, Patagonia talks about the environmental toll manufacturing clothes requires. “Consider the R2 Jacket shown, one of our best sellers. To make it required 135 liters of water, enough to meet the daily needs (three glasses a day) of 45 people. Its journey from its origin as 60 percent recycled polyester to our Reno warehouse generated nearly 20 pounds of carbon dioxide, 24 times the weight of the finished product. This jacket left behind, on its way to Reno, two-thirds [of] its weight in waste.” The ad encourages users to not buy any new Patagonia clothing if their old, ratty clothes can be repaired. To help, Patagonia launched a supplementary subdomain to its e-commerce website to support its Common Thread Initiative, which eventually got rebranded as the  . Patatgonia’s Worn Wear subdomain gets users to engage with the company about causes each party cares about. Through Worn Wear, Patagonia will repair your old gear for free. If you’d rather have new gear, you can instead sell the worn out clothing to Patagonia, and they’ll repair it and then resell the product at a discount. This interaction encourages loyalty and repeat brand-user engagement. In addition, the navigation on Patagonia’s main website practically begs users to learn about the brand’s non-profit initiatives and its commitment to ethical manufacturing. Today,   in the United States. Retention Content strategy expands through nearly every aspect of the marketing stack, including ad campaigns, which take a more controlled approach to vulnerability and transparency. To target users in the retention stage and keep them invested in your brand, your goal is to create content using the customers’ life experiences pillar to amplify the emotional bond and brand loyalty that vulnerability creates. Always took this approach and ended up with one of its most successful social media campaigns. In June 2014, Always launched its #LikeAGirl campaign to empower adolescent and teenage girls by transforming the phrase “like a girl” from a slur into a meaningful and positive statement. The campaign is centered on a video in which Always tasked children, teenagers, and adults to behave “like a girl” by running, punching, and throwing while mimicking their perception of how a girl performs the activity. Young girls performed the tasks wholeheartedly and with gusto, while boys and adults performed overly feminine and vain characterizations. The director then challenged the person on their portrayal, breaking down what doing things “like a girl” truly means. The video ends with a powerful, heart-swelling statement: “If somebody else says that running like a girl, or kicking like a girl, or shooting like a girl is something you shouldn’t be doing, that’s their problem. Because if you’re still scoring, and you’re still getting to the ball in time, and you’re still being first…you’re doing it right. It doesn’t matter what they say.” This customer story campaign put the vulnerability girls feel during puberty front and center so the topic would resonate with users and give the brand a powerful, relevant, and purposeful role in this connection,  . Consequently, the #LikeAGirl campaign was a rousing success and blew past the KPIs Always established. Initially, Always determined an “impactful launch” for the video meant 2 million video views and 250 million media impressions, the analysis states. Five years later, the campaign video has more than 66.9 million views and 42,700 comments on YouTube, with more than 85 percent of users reacting positively. Here are a few additional highlights the analysis document points out: Eighty-one percent of women ages 16–24 support Always in creating a movement to reclaim “like a girl” as a positive and inspiring statement. More than 1 million people shared the video. Thirteen percent of users created user-generated content about the campaign. The #LikeAGirl program achieved 4.5 billion global impressions. The campaign received 290 million social impressions, with 133,000 social mentions, and it caused a 195.3 percent increase in the brand’s Twitter followers. Among the reasons the #LikeAGirl content was so successful is that it aligned with Brené Brown’s concept that experiencing vulnerability creates a connection centered on powerful, shared emotions. Always then amplified the campaign’s effectiveness by using those emotions to encourage specific user behavior on social media. How do you know if you’re making vulnerable content? Designing a vulnerability-focused content strategy campaign begins by determining what kind of story you want to tell, why you want to tell it, why that story matters, and how that story helps you or your users achieve a goal. When you’re brainstorming topics, the most important factor is that you need to care about the stories you’re telling. These tales need to be meaningful because if you’re weaving a narrative that isn’t important to you, it shows. And ultimately, why do you expect your users to care about a subject if you don’t? Let’s say you’re developing a content campaign for a nonprofit, and you want to use your brand’s emotional identity to connect with users. You have a handful of possible narratives but you’re not sure which one will best unlock the benefits of vulnerability. In a Medium post about  , Cayla Vidmar presents a list of seven self-reflective questions that can reveal what narrative to choose and why. If you can answer each of Vidmar’s questions, you’re on your way to creating a great story that can connect with users on a level unrivaled by other methods. Here’s what you should ask yourself: What meaning is there in my story? Can my story help others? How can it help others? Am I willing to struggle and be vulnerable in that struggle (even with strangers)? How has my story shaped my worldview (what has it made me believe)? What good have I learned from my story? If other people discovered this good from their story, would it change their lives? While you’re creating narratives within the three pillars, refer back to Vidmar’s list to maintain the proper balance between vulnerability and transparency. What’s next? You now know that vulnerability and transparency are an endless fountain of strength, not a weakness. Vulnerable content won’t make you or your brand look weak. Your customers won’t flee at the sight of imperfection. Being human and treating your users like humans isn’t a liability. It’s time for your brand to embrace its untapped potential. Choose to be vulnerable, have the courage to tell meaningful stories about what matters most to your company and your customers, and overcome the fear of controlling how users will react to your content. Every origin story has six chapters: the discovery of a problem or opportunity; what caused this problem or opportunity; the consequences of this discovery; the solution to these consequences; lessons learned during the process; and next steps. Every customer journey narrative has six chapters: plot background to frame the customer’s experiences; the customer’s journey; how the brand plays into that journey (if applicable); how the customer’s experiences changed them; what the customer learned from this journey; and how other people can use this information to improve their lives. Narratives about product and service insights have seven chapters: an overview of the product/service; how that product/service affects users; why the product/service is important to the brand’s mission or to users; what about this product/service failed or succeeded; why did that success or failure happen; what lessons did this scenario create; and how are the brand and its users moving forward. You have the tools and knowledge necessary to be transparent, create vulnerable content, and succeed. And we need to tell vulnerable stories because sharing our experiences and embracing our common connections matters. So go ahead, put yourself out into the open, and see how your customers respond. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/responsible-javascript-part-3/", "title": "Responsible JavaScript: Part III", "content": "You’ve done everything you thought was possible to address your website’s JavaScript problem. You  . You   and  . You whittled your application code down to its most streamlined form possible. Yet, things are just not fast enough. When websites fail to perform the way we as designers and developers expect them to, we inevitably turn on ourselves: Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. These are valid inquiries, as a fair share of performance woes   originate from our own code. Yet, assigning blame solely to ourselves blinds us to the unvarnished truth that a sizable onslaught of our performance problems comes from the outside. When the third wheel crashes the party Convenience always has a price, and  .  JavaScript, in particular, is employed in a way that suggests a rapidly increasing tendency to outsource whatever it is that We (the first party) don’t want to do. At times, this is a necessary decision; it makes perfect financial and operational sense in many situations. But make no mistake,  . It’s a devil’s bargain where vendors seduce you with solutions to your problem, yet conveniently fail to remind you that you have little to no control over the side effects that solution introduces. If a third-party provider adds features to their product,   bear the brunt. If they change their infrastructure,   will feel the effects of it. Those who use your site   become frustrated, and they aren’t going to bother grappling with an intolerable user experience. You can mitigate some of the symptoms of third parties, but you can’t cure the ailment unless you remove the solutions altogether—and that’s not always practical or possible. In this installment of  , we’ll take a   less technical approach than in the  . We are going to talk more about the human side of third parties. Then, we’ll go down some of the technical avenues for how you might go about tackling the problem. Hindered by convenience When we talk about the sorry state of the web today,   in contributing to the problem. While I share the view that developer convenience has a tendency to harm the user experience, they’re not the only kind of convenience that can turn a website into a sluggish, janky mess.  can become precursors to a very thorny sort of technical debt. These conveniences are what we reach for when we can’t solve a pervasive problem on our own. They represent third-party solutions that address problems in the absence of architectural flexibility and/or adequate development resources. Whenever an inconvenience arises,   is the time to have the discussion around how to tackle it in a way that’s comprehensive. So let’s talk about what it looks like to tackle that sort of scenario from a more human angle. The problem is pain The reason third parties come into play in the first place is pain. When a decision maker in an organization has felt enough pain around a certain problem, they’re going to do a  , which is to find the fastest way to make that pain  . Markets will always find ways to address these pain points, even if the way they do so isn’t sustainable or even remotely helpful. Web accessibility overlays—third-party scripts that purport to automatically fix accessibility issues—are among the worst offenders. First, you fork over your money for  . Then you pay a wholly different sort of price when that “fix” harms the usability of your website. This is not a screed to discredit the usefulness of the tools some third-party vendors provide, but to illustrate how the adoption of third-party solutions happens, even those that are objectively awful So when a vendor rolls up and promises to solve the very painful problem we’re having, there’s a good chance someone is going to nibble. If that someone is high enough in the hierarchy, they’ll exert downward pressure on others to buy in—if not circumvent them entirely in the decision-making process. Conversely, adoption of a third-party solution can also occur when those in the trenches are under pressure and lack sufficient resources to create the necessary features themselves. Whatever the catalyst, it pays to gather your colleagues and collectively form a plan for navigating and mitigating the problems you’re facing. Create a mitigation plan Once people in an organization have latched onto a third-party solution, however ill-advised, the difficulty you’ll encounter in forcing a course change will depend on how urgent a need that solution serves. In fact, you shouldn’t try to convince proponents of the solution that their decision was wrong. Such efforts almost always backfire and can make people feel attacked and more resistant to what you’re telling them. Even worse, those efforts could create acrimony where people stop listening to each other completely, and   is a breeding ground for far worse problems to develop. Grouse and commiserate amongst your peers if you must—as I myself have often done—but put your grievances aside and   to guide your colleagues toward better outcomes. The nooks and crannies of your specific approach will depend on the third parties themselves and the structure of the organization, but the bones of it could look like the following series of questions. What problem does this solution address? There’s a reason why a third-party solution was selected, and this question will help you suss out whether the rationale for its adoption is sound. Remember, there are times decisions are made when all the necessary people are not in the room. You might be in a position where you have to react to the aftermath of that decision, but the answer to this question will lead you to a natural follow-up. How long do we intend to use the solution? This question will help you identify the solution’s shelf life. Was it introduced as a bandage, with the intent to remove it once the underlying problem has been addressed, such as in the case of an accessibility overlay? Or is the need more long-term, such as the data provided by an A/B testing suite? The other possibility is that the solution can never be effectively removed because it serves a crucial purpose, as in the case of analytics scripts.  : it’s easy to throw in, but nigh impossible to drag back out. In any case, you can’t know if a third-party script is here to stay if you don’t ask. Indeed, if you find out the solution is temporary, you can form a plan to eventually remove it from your site once the underlying problem it addresses has been resolved. Who’s the point of contact if issues arise? When a third-party solution is put into place, someone   be the point of contact for when—not  —issues arise. I’ve seen what happens (far too often) when a third-party script gets out of control. For example, when a tag manager or an A/B testing framework’s JavaScript grows slowly and insidiously because marketers aren’t cleaning out old tags or completed A/B tests. It’s for precisely these reasons that responsibility needs to be attached to a specific person in your organization for third-party solutions currently in use on your site. What that responsibility entails will differ in every situation, but could include: periodic monitoring of the third-party script’s footprint; maintenance to ensure the third-party script doesn’t grow out of control; occasional meetings to discuss the future of that vendor’s relationship with your organization; identification of overlaps of functionality between multiple third parties, and if potential redundancies can be removed; and ongoing research, especially to identify speedier alternatives that may act as better replacements for slow third-party scripts. The idea of responsibility in this context should never be an onerous, draconian obligation you yoke your teammates with, but rather an exercise in encouraging mindfulness in your colleagues. Because without mindfulness, a third-party script’s ill effects on your website   be overlooked until it becomes a grumbling ogre in the room that can no longer be ignored. Assigning responsibility for third parties can help to prevent that from happening. Ensuring responsible usage of third-party solutions If you can put together a mitigation plan and get everyone on board, the work of ensuring the responsible use of third-party solutions can begin. Luckily for you, the actual technical work will be easier than trying to wrangle people. So if you’ve made it this far, all it will take to get results is time and persistence. Load only what’s necessary It may seem obvious, but load only what’s necessary. Judging by the amount of unused first-party JavaScript I see loaded—let alone   JavaScript—it’s clearly a problem. It’s like trying to clean your house by stuffing clutter into the closets. Regardless of whether they’re actually needed, it’s not uncommon for third-party scripts to be loaded on every single page, so refer to your point of contact to figure out which pages need which third-party scripts. As an example, one of my past clients used a popular third-party tool across multiple brand sites to get a list of retailers for a given product. It demonstrated clear value, but that script only needed to be on a site’s product detail page. In reality, it was frequently loaded on   page. Culling this script from pages where it didn’t belong significantly boosted performance for non-product pages, which ostensibly reduced the friction on the conversion path. Figuring out which pages need which third-party scripts requires you to do some decidedly untechnical work. You’ll actually have to get up from your desk and talk to the person who has been assigned responsibility for the third-party solution you’re grappling with. This is very difficult work for me, but it’s rewarding when good-faith collaboration happens,   good outcomes are realized as a result. Self-host your third-party scripts This advice isn’t a secret by any stretch.   in the previous installment of this series, but it needs to be shouted from the rooftops at every opportunity: you should   as possible. Whether this is feasible depends on the third-party script in question. Is it some framework you’re grabbing from  ,  , or other similar provider? Self-host that sucker  .  and significantly reduced their start render time for their trouble. It really drives home the point that a major detriment of third-party resources is the fact that their mere existence on other servers is one of the worst performance bottlenecks we encounter. If you’re looking to self-host an analytics solution or a similar sort of script, there’s a higher level of difficulty to contend with to self-host it. You may find that some third-party scripts simply can’t be self-hosted, but that doesn’t mean it isn’t worth the trouble to find out. If you find that self-hosting isn’t an option for a third-party script, don’t fret. There are other mitigations you can try. Mask latency of cross-origin connections If you can’t self-host your third-party scripts, the next best thing is to preconnect to servers that host them. WebPageTest’s Connection View does a fantastic job of showing you which servers your site gathers resources from, as well as the latency involved in establishing connections to them.  are effective because they establish connections to third-party servers before the browser would otherwise discover them in due course. Parsing HTML takes time, and parsers are often blocked by stylesheets and other scripts. Wherever you can’t self-host third-party scripts, preconnections make perfect sense. Maybe don’t preload third-party scripts  is one of those things that sounds fantastic at first—until you consider  , as   points out. If you’re unfamiliar with preloading, it’s similar to preconnecting but goes a step further by instructing the browser to fetch a particular resource far sooner than it ordinarily would. The drawback of preloading is that while it’s great for ensuring a resource gets loaded as soon as possible, it changes the discovery order of that resource. Whenever we do this, we’re implicitly saying that other resources are less important—including resources crucial to rendering or even core functionality. It’s probably a safe bet that most of your third-party code is not as crucial to the functionality of your site as your own code. That said, if you   preload a third-party resource, ensure you’re only doing so for third-party scripts that are critical to page rendering. If you do find yourself in a position where your site’s initial rendering depends on a third-party script, refer to your mitigation plan to see what you can do to eliminate or ameliorate your dependence on it. Depending on a third party for core functionality is never a good position to be in, as you’re relinquishing a lot of control to others who might not have your best interests in mind. Lazy load non-essential third-party scripts . If you have a third-party script that doesn’t need to be loaded right away, consider lazy loading it with an  . Here’s what it might look like to   when it’s scrolled into the viewport: In the above snippet, we first set a variable to track whether we’ve loaded the Facebook SDK JavaScript. After that, an   is created that checks whether the observed element is in the viewport, and whether the Facebook SDK has been loaded. If the SDK JavaScript hasn’t been loaded, a reference to it is injected into the DOM, which will kick off a request for it. You’re not going to be able to lazy load every third-party script. Some of them simply need to do their work at page load time, or otherwise can’t be deferred. Regardless, do the detective work to see if it’s possible to lazy load at least some of your third-party JavaScript. One of the common concerns I hear from coworkers when I suggest lazy loading third-party scripts is how it can delay whatever interactions the third party provides. That’s a reasonable concern, because when you lazy load anything, a noticeable delay may occur as the resource loads. You can get around this to some extent with  . This is different than preloading, which we discussed earlier. Prefetching consumes a comparable amount of data, yes, but prefetched resources are given lower priority and are less likely to contend for bandwidth with critical resources. Staying on top of the problem Keeping an eye on your third-party JavaScript requires mindfulness bordering on hypervigilance. When you recognize poor performance for the technical debt that it truly is, you’ll naturally slip into a frame of mind where you’ll recognize and address it as you would any other kind of technical debt. Staying on top of third parties   refactoring—a sort that requires you to periodically perform tasks such as cleaning up tag managers and A/B tests, consolidating third-party solutions, eliminating any that are no longer needed, and applying the coding techniques discussed above. Moreover, you’ll need to work with your team to address this technical debt on a cyclical basis. This kind of work can’t be automated, so yes, you’ll need to knuckle down and have face-to-face, synchronous conversations with actual people. If you’re already in the habit of scheduling “cleanup sprints” on some interval, then   is the time and space for you to address performance-related technical debt, regardless of whether it involves third- or first-party code. There’s a time for feature development, but that time should not comprise the whole of your working hours. Development shops that focus only on feature development are destined to be wholly consumed by the technical debt that will inevitably result. So it will come to pass that in the fourth and final installment of this series we’ll discuss what it means to do the hard work of using JavaScript responsibly in the context of process. Therein, we’ll explore what it takes to unite your organization under the banner of making your website faster and more accessible, and therefore more usable for everyone, everywhere. Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/request-with-intent-caching-strategies-in-the-age-of-pwas/", "title": "Request with Intent: Caching Strategies in the Age of PWAs", "content": "Once upon a time, we relied on browsers to handle caching for us; as developers in those days, we had very little control. But then came   (PWAs),  , and the  —and suddenly we have expansive power over what gets put in the cache and how it gets put there. We can now cache everything we want to… and therein lies a potential problem. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Media files—especially images—make up   these days, and  . In order to improve performance, it’s tempting to cache as much of this content as possible, but should we? In most cases, no. Even with all this newfangled technology at our fingertips, great performance still hinges on a simple rule:  . To provide the best possible experience for our users without abusing their network connection or their hard drive, it’s time to put a spin on some classic best practices, experiment with media caching strategies, and play around with a few Cache API tricks that Service Workers have hidden up their sleeves. Best intentions All those lessons we learned optimizing web pages for dial-up became super-useful again when mobile took off, and they continue to be applicable in the work we do for a global audience today. Unreliable or high latency network connections are still the norm in many parts of the world, reminding us that it’s never safe to assume a technical baseline lifts evenly or in sync with its corresponding cutting edge. And that’s the thing about performance best practices: history has borne out that approaches that are good for performance now will continue being good for performance in the future. Before the advent of Service Workers, we could provide   with respect to how long they should cache a particular resource, but that was about it. Documents and assets downloaded to a user’s machine would be dropped into a directory on their hard drive. When the browser assembled a request for a particular document or asset, it would peek in the cache first to see if it already had what it needed to possibly avoid hitting the network. We have considerably more control over network requests and the cache these days, but that doesn’t excuse us from being thoughtful about the resources on our web pages. Request only what you need As I mentioned, the web today is lousy with media. Images and videos have become a dominant means of communication. They may convert well when it comes to sales and marketing, but they are hardly performant when it comes to download and rendering speed. With this in mind, each and every image (and video, etc.) should have to fight for its place on the page.  A few years back, a recipe of mine was included in a newspaper story on cooking with spirits (alcohol, not ghosts). I don’t subscribe to the print version of that paper, so when the article came out I went to the site to take a look at how it turned out. During a recent redesign, the site had decided to load all articles into a nearly full-screen modal viewbox layered on top of their homepage. This meant requesting the article required requests for all of the assets associated with the article page   all the contents and assets for the homepage. Oh, and the homepage had video ads—plural. And, yes, they auto-played. I popped open DevTools and discovered the page had blown past 15 MB in page weight. Tim Kadlec had recently launched  , so I decided to check out the damage. Turns out that the actual cost to view that page for the average US-based user was more than the cost of the print version of that day’s newspaper. That’s just messed up. Sure, I could blame the folks who built the site for doing their readers such a disservice, but the reality is that none of us go to work with the goal of worsening our users’ experiences. This could happen to any of us. We could spend days scrutinizing the performance of a page only to have some committee decide to set that carefully crafted page atop a Times Square of auto-playing video ads. Imagine how much worse things would be if we were stacking two abysmally-performing pages on top of each other! Media can be great for drawing attention when competition is high (e.g., on the homepage of a newspaper), but when you want readers to focus on a single task (e.g., reading the actual article), its value can drop from important to “nice to have.” Yes, studies have shown that images excel at drawing eyeballs, but once a visitor is on the article page,  ; we’re just making it take longer to download and more expensive to access. The situation only gets worse as we shove more media into the page.  We must do everything in our power to reduce the weight of our pages, so avoid requests for things that don’t add value. For starters, if you’re writing an article about a data breach, resist the urge to include   of some random dude in a hoodie typing on a computer in a very dark room. Request the smallest file you can Now that we’ve taken stock of what we   need to include, we must ask ourselves a critical question: How can we deliver it in the fastest way possible? This can be as simple as   for the content presented (and optimizing the heck out of it) or as complex as recreating assets entirely (for example, if switching from raster to vector imagery would be more efficient). When it comes to image formats, we don’t have to choose between performance and reach anymore. We can provide multiple options and let   decide which one to use, based on what it can handle. You can accomplish this by offering multiple   within a   or   element. Start by creating multiple formats of the media asset. For example, with WebP and JPG, it’s likely that the WebP will have a smaller file size than the JPG (but check to make sure). With those alternate sources, you can drop them into a   like this: Browsers that recognize the   element will check the   element before making a decision about which image to request. If the browser supports the MIME type “image/webp,” it will kick off a request for the WebP format image. If not (or if the browser doesn’t recognize  ), it will request the JPG.  The nice thing about this approach is that you’re serving the smallest image possible to the user without having to resort to any sort of JavaScript hackery. You can take the same approach with video files: Browsers that support WebM will request the first  , whereas browsers that don’t—but do understand MP4 videos—will request the second one. Browsers that don’t support the   element will fall back to the paragraph about downloading the file. The order of your   elements matters.  , so if you specify an optimized alternative format   a more widely compatible one, the alternative format may never get picked up.   Depending on your situation, you might consider bypassing this markup-based approach and handle things on the server instead. For example, if a JPG is being requested and the browser supports WebP (which is indicated in the   header), there’s nothing stopping you from replying with a WebP version of the resource. In fact, some CDN services— , for instance—come with this sort of functionality right out of the box. Formats aside, you may want to deliver alternate image sizes optimized for the current size of the browser’s viewport. After all, there’s no point loading an image that’s 3–4 times larger than the screen rendering it; that’s just wasting bandwidth. This is where   come in. Here’s an example: There’s a lot going on in this super-charged   element, so I’ll break it down: This   offers three size options for a given JPG: 256 px wide ( ), 512 px wide ( ), and 1024 px wide ( ). These are provided in the   attribute with corresponding  . The   defines a default image source, which acts as a fallback for browsers that don’t support  . Your choice for the default image will likely depend on the context and general usage patterns. Often I’d recommend the smallest image be the default, but if the majority of your traffic is on older desktop browsers, you might want to go with the medium-sized image. The   attribute is a   that informs the browser how the image will be rendered in different scenarios (its  ) once CSS has been applied. This particular example says that the image will be the full width of the viewport ( ) until the viewport reaches 30 em in width ( ), at which point the image will be 30 em wide. You can make the   value as complicated or as simple as you want; omitting it causes browsers to use the default value of  . You can even combine this approach with  . 🤯 All of this is to say that you have a number of tools at your disposal for delivering fast-loading media, so use them! Defer requests (when possible) Years ago, Internet Explorer 11 introduced a new attribute that enabled developers to de-prioritize specific   elements to speed up page rendering:  . That attribute never went anywhere, standards-wise, but it was a solid attempt to defer image loading until images are in view (or close to it) without having to involve JavaScript. There have been countless JavaScript-based implementations of lazy loading images since then, but recently Google also took a stab at a more declarative approach, using a different attribute:  . The   attribute supports three values (“auto,” “lazy,” and “eager”) to define how a resource should be brought in. For our purposes, the “lazy” value is the most interesting because it defers loading the resource until it reaches a   from the viewport. Adding that into the mix… This attribute offers a bit of a performance boost in Chromium-based browsers. Hopefully it will become a standard and get picked up by other browsers in the future, but in the meantime there’s no harm in including it because browsers that don’t understand the attribute will simply ignore it. This approach complements a media prioritization strategy really well, but before I get to that, I want to take a closer look at Service Workers. Manipulate requests in a Service Worker Service Workers are a special type of   with the ability to intercept, modify, and respond to all network requests via the  . They also have access to the  , as well as other asynchronous client-side data stores like   for resource storage. When a Service Worker is installed, you can hook into that event and prime the cache with resources you want to use later. Many folks use this opportunity to squirrel away copies of global assets, including styles, scripts, logos, and the like, but you can also use it to cache images for use when network requests fail. Keep a fallback image in your back pocket Assuming you want to use a fallback in more than one networking recipe, you can set up a named function that will respond with that resource: Then, within a  , you can use that function to provide that fallback image when requests for images fail at the network: When the network is available, users get the expected behavior: But when the network is interrupted, images will be swapped automatically for a fallback, and the user experience is still acceptable: On the surface, this approach may not seem all that helpful in terms of performance since you’ve essentially added an additional image download into the mix. With this system in place, however, some pretty amazing opportunities open up to you. Respect a user’s choice to save data Some users reduce their data consumption by entering a “lite” mode or turning on a “data saver” feature. When this happens, browsers will often send a   with their network requests.  Within your Service Worker, you can look for this header and adjust your responses accordingly. First, you look for the header: Then, within your   handler for images, you might choose to preemptively respond with the fallback image instead of going to the network at all: You could even take this a step further and tune   to provide alternate images based on what the original request was for. To do that you’d define several fallbacks globally in the Service Worker: Both of those files should then be cached during the Service Worker install event: Finally, within   you could serve up the appropriate image based on the URL being fetched. In my site, the avatars are pulled from  , so I test for that. With that change, I’ll need to update the   handler to pass in   as an argument to  . Once that’s done, when the network gets interrupted I end up seeing something like this: Next, we need to establish some general guidelines for handling media assets—based on the situation, of course. The caching strategy: prioritize certain media In my experience, media—especially images—on the web tend to fall into three categories of necessity. At one end of the spectrum are elements that don’t add meaningful value. At the other end of the spectrum are critical assets that   add value, such as charts and graphs that are essential to understanding the surrounding content. Somewhere in the middle are what I would call “nice-to-have” media. They   add value to the core experience of a page but are not critical to understanding the content. If you consider your media with this division in mind, you can establish some general guidelines for handling each, based on the situation. In other words, a caching strategy.  When it comes to disambiguating the critical from the nice-to-have, it’s helpful to have those resources organized into separate directories (or similar). That way we can add some logic into the Service Worker that can help it decide which is which. For example, on my own personal site, critical images are either self-hosted or come from the website for  . Knowing that, I can write regular expressions that match those domains: With that   variable defined, I can create a function that will let me know if a given image request (for example) is a high priority request or not: Adding support for prioritizing media requests only requires adding a new conditional into the   event handler, like we did with  . Your specific recipe for network and cache handling will likely differ, but here was  : We can apply this prioritized approach to many kinds of assets. We could even use it to control which pages are served cache-first vs. network-first. Keep the cache tidy The  ability to control which resources are cached to disk is a huge opportunity, but it also carries with it an equally huge responsibility not to abuse it. Every caching strategy is likely to differ, at least a little bit. If we’re publishing a book online, for instance, it might make sense to cache all of the chapters, images, etc. for offline viewing. There’s a fixed amount of content and—assuming there aren’t a ton of heavy images and videos—users will benefit from not having to download each chapter separately. On a news site, however, caching every article and photo will quickly fill up our users’ hard drives. If a site offers an indeterminate number of pages and assets, it’s   to have a caching strategy that puts hard limits on how many resources we’re caching to disk.  One way to do this is to create several different blocks associated with caching different forms of content. The more ephemeral content caches can have strict limits around how many items can be stored. Sure, we’ll still be bound to the storage limits of the device, but do we really want our website to take up 2 GB of someone’s hard drive? Here’s an example, again from my own site: Here I’ve defined several caches, each with a   used for addressing it in the Cache API and a   prefix. The   is defined elsewhere in the Service Worker, and allows me to purge all caches at once if necessary. With the exception of the   cache, which is used for static assets, every cache has a   to the number of items that may be stored. I only cache the most recent 5 pages someone has visited, for instance. Images are limited to the most recent 75, and so on. This is an approach that   outlines in his fantastic book   (which you should really read if you haven’t already— ). With these cache definitions in place, I can clean up my caches periodically and prune the oldest items. Here’s Jeremy’s recommended code for this approach: We can trigger this code to run whenever a new page loads. By running it in the Service Worker, it runs in a separate thread and won’t drag down the site’s responsiveness. We trigger it by posting a message (using  ) to the Service Worker from the main JavaScript thread: The final step in wiring it all up is setting up the Service Worker to receive the message: Here, the Service Worker listens for inbound messages and responds to the “clean up” request by running   on each of the cache buckets with a defined  . This approach is by no means elegant, but it works. It would be far better to make decisions about purging cached responses based on how frequently each item is accessed and/or how much room it takes up on disk. (Removing cached items based purely on when they were cached isn’t nearly as useful.) Sadly, we don’t have that level of detail when it comes to inspecting the caches…yet. I’m actually working to address this limitation in the Cache API right now. Your users always come first The technologies underlying Progressive Web Apps are continuing to mature, but even if you aren’t interested in turning your site into a PWA, there’s so much you can do today to improve your users’ experiences when it comes to media. And, as with every other form of inclusive design, it starts with centering on your users who are most at risk of having an awful experience. Draw distinctions between critical, nice-to-have, and superfluous media. Remove the cruft, then optimize the bejeezus out of each remaining asset. Serve your media in multiple formats and sizes, prioritizing the smallest versions first to make the most of high latency and slow connections. If your users say they want to save data, respect that and have a fallback plan in place. Cache wisely and with the utmost respect for your users’ disk space. And, finally, audit your caching strategies regularly—especially when it comes to large media files.Follow these guidelines, and every one of your users—from folks rocking a   on a rural mobile network in India to people on a high-end gaming laptop wired to a 10 Gbps fiber line in Silicon Valley—will thank you. Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/making-room-for-variation/", "title": "Making Room for Variation", "content": "Making a brand feel unified, cohesive, and harmonious while also leaving\nroom for experimentation is a tough balancing act. It’s one of the most\nchallenging aspects of a design system.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Graphic designer and Pentagram partner Paula Scher faced this\nchallenge with the visual identity for the Public Theater in New York. As she\nexplained in a talk at Beyond Tellerrand:  I began to realize that if you made everything the same, it\nwas boring after the first year. If you changed it individually for each play,\nthe theater lost recognizability. The thing to do, which I totally got for the\nfirst time after working there at this point for 17 years, is what they needed\nto have were seasons.  You could take the typography and the color system for the summer festival, the Shakespeare in the Park Festival, and you could begin to translate it into posters by flopping the colors, but using some of the same motifs, and you could create entire seasons out of the graphics. That would become its own standards manual where I have about six different people making these all year ( ). Scher’s strategy was to retain the Public Theater’s visual language every year, but to vary some of its elements ( ). Colors would be swapped. Text would skew in different directions. New visual motifs would be introduced. The result is that each season coheres in its own way, but so does the identity of the Public Theater as a whole.  Even the most robust or thoroughly planned systems will need to account for variation at some point. As soon as you release a design system, people will ask you how to deviate from it, and you’ll want to be armed with persuasive answers. In this chapter, I’m going to talk about what variation means for a design system, how to know when you need it, and how to manage it in a scalable way.  What Is Variation? We’ve spent most of this book talking about the importance of\nunity, cohesion, and harmony in a design system. So why are we talking about\nvariation? Isn’t that at odds with all of the goals we’ve set until now?  Variation is a deviation from established patterns, and it can\nexist at every level of the system. At the component level, for instance, a\nteam may discover that they need a component to behave in a slightly different\nway; maybe this particular component needs to appear without a photo, for\nexample. At a design-language level, you may have a team that has a different\naudience, so they want to adjust their brand identity to serve that audience\nbetter. You can even have variation at the level of design principles: if a\nteam is working on a product that is functionally different from your core\nproduct, they may need to adjust their principles to suit that context.  There are three kinds of deviations that come up in a design\nsystem:  typically happens when designers can’t find the information they’re looking for. They may not know that a certain solution exists within a system, so they create their own style. Clear, easy-to-find documentation and usage guidelines can help your team avoid unintentional variation.  usually results from designers not wanting to feel constrained by the system, or believing they have a better solution. Making sure your team knows how to push back on and contribute to the system can help mitigate this kind of variation.   is the goal of an expressive design system. In this case, the divergence is meaningful because it solves a very specific user problem that no existing pattern solves. We want to enable intentional, meaningful variation. To do this, we need to understand the needs and contexts for variation. Contexts for Variation  Every variation we add makes our design system more complicated. Therefore, we need to take care to find the right moments for variation. Three big contextual changes are served by variation: brand, audience, and environment.  Brand If you’re creating a system for multiple brands, each with its own\nbrand language, then your system needs to support variations to reflect those\nbrands.  The key here is to find the common core elements and then set\nsome criteria for how you should deviate. When we were creating the design\nsystem for our websites at Vox Media, we constantly debated which elements\nshould feel more expressive. Should a footer be standardized, or should we\nallow for tons of customization? We went back to our core goals: our users were\nultimately visiting our websites to consume editorial content. So the\nvariations should be in service of the content, writing style, and tone of\nvoice for each brand.  The newsletter modules across Vox Media brands were an example of unnecessary variation. They were consistent in functionality and layout, but had variations in type, color, and visual treatments like borders ( ). There was quite a bit of custom design within a very small area: Curbed’s newsletter component had a skewed background, for example, while Eater’s had a background image. Because these modules were so consistent in their user goals, we decided to unify their design and create less variation ( ). The unified design cleaned up some technical debt. In the\nprevious design, each newsletter module had CSS overrides to achieve distinct\nstyling. Some modules even had overrides on the primary button color so it\nwould work better with the background color. Little CSS overrides like this add\nup over time. Whenever we released a new change, we’d have to manually update\nthe spots containing CSS overrides.  The streamlined design also placed a more appropriate emphasis on\nthe newsletter module. While important, this module isn’t the star of the page.\nIt doesn’t need loud backgrounds or fancy shapes to command attention,\nespecially since it’s placed around article content. Variation in this module\nwasn’t necessary for expressing the brands. On the other hand, consider the variation in Vox Media’s global header components. When we were redesigning the  , its editorial teams were vocal about wanting more latitude to art-direct the page, guide attention toward big features, and showcase custom illustrations. We addressed this by creating a masthead component ( ) that sits on top of the global header on homepages. It contains a logo, tagline, date, and customizable background image. Though at the time this was a one-off component, we felt that the variation was valuable because it would strengthen the  ’s brand voice.  The   team commissions or makes original art that changes throughout the day. The most exciting part is that they can use the masthead and a one-up hero when they drop a big feature and use these flexible components to art-direct the page ( ). Soon after launch, the   masthead even got a Twitter fan account (@VergeTaglines) that tweets every time the image changes.  Though this component was built specifically for the  , it soon gained broader application with other brands that share Vox’s publishing platform, Chorus. The McElroy Family website, for example, needed to convey its sense of humor and Appalachian roots; the masthead component shines with an original illustration featuring an adorable squirrel ( ).  The  —another Chorus platform site—is very different in content, tone, and audience from The McElroy Family, but the masthead component is just as valuable in conveying the tone of the organization’s high-quality investigative journalism and breaking news coverage ( ).  Why did the masthead variation work well while the newsletter variation didn’t? The variations on the newsletter design were purely visual. When we created them, we didn’t have a strategy for how variation should work; instead, we were looking for any opportunity to make the brands feel distinct. The masthead variation, by contrast, tied directly into the brand strategy. Even though it began as a one-off for the  , it was flexible and purposeful enough to migrate to other brands.  Audience The next contextual variation comes from audience. If your\nproducts serve different audiences who all need different things, then your\nsystem may need to adapt to fit those needs.  A good example of this is Airbnb’s listing pages. In addition to\ntheir standard listings, they also have Airbnb Plus—one-of-a-kind, high quality\nrentals at higher price points. Audiences booking a Plus listing are probably\nlooking for exceptional quality and attention to detail.  Both Airbnb’s standard listing page and Plus listing page are immediately recognizable as belonging to the same family because they use many consistent elements ( ). They both use Airbnb’s custom font, Cereal. They both highlight photography. They both use many of the same components, like the date picker. The iconography is the same. However, some of the\ndesign choices convey a different attitude. Airbnb Plus uses larger\ntypography, airier vertical space, and a lighter weight of Cereal. It has a\nmore understated color palette, with a deeper color on the call to action.\nThese choices make Airbnb Plus feel like a more premium experience. You can see\nthey’ve adjusted the density, weight, and scale levers to achieve a more\nelegant and sophisticated aesthetic.  The standard listing page, on the other hand, is more functional,\nwith the booking module front and center. The Plus design pulls the density and\nweight levers in a lighter, airier direction. The standard listing page has\nless size contrast between elements, making it feel more functional.  Because they use the same core building blocks—the same typography, iconography, and components—both experiences feel like Airbnb. However, the variations in spacing, typographic weights, and color help distinguish the standard listing from the premium listing. Environment I’ve mainly been talking about adding variation to a system to\nallow for a range of content tones, but you may also need your system to scale\nbased on environmental contexts. “Environment” in this context asks: Where will\nyour products be used? Will that have an impact on the experience? Environments\nare the various constraints and pressures that surround and inform an\nexperience. That can include lighting, ambient noise, passive or active\nengagement, expected focus level, or devices.  Shopify’s Polaris design system initially grew out of Shopify’s Store\nManagement product. When the Shopify Retail team kicked off a project to design\nthe next generation  (POS) system, they realized that the\npatterns in Polaris didn’t exactly fit their needs. The POS system needed to\nwork well in a retail space, often under bright lighting. The app needed to be\nused at arm’s length, twenty-four to thirty-six inches away from the merchant.\nAnd unlike the core admin, where the primary interaction is between the\nmerchant and the UI, merchants using the POS system needed to prioritize their\ninteractions with their customers instead of the UI. The Retail team wanted\nmerchants to achieve an “eyes-closed” level of mastery over the UI so they\ncould maintain eye contact with their customers.  The Retail team decided that the existing color palette, which\nonly worked on a light background, would not be clear enough under the bright\nlights of a retail shop. The type scale was also too small to be used at arm’s\nlength. And in order for merchants to use the POS system without breaking eye\ncontact with customers, the buttons and other UI elements would need to be much\nlarger.  The Retail team recognized that the current design system didn’t support a variety of environmental scenarios. But after talking with the Polaris team, they realized that other teams would benefit from the solutions they created. The Warehouse team, for example, was also developing an app that needed to be used at arm’s length under bright lights. This work inspired the Polaris team to create a dark mode for the system ( ).  This feedback loop between product team and design system team is\na great example of how to build the right variation into your system. Build\nyour system around helping your users navigate your product more clearly and serving\ncontent needs and you’ll unlock scalable expression.  Like this: \n\t\t\t\t\t\t\tRecently by Yesenia Perez-Cruz\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/conversations-with-robots/", "title": "Conversations with Robots: Voice, Smart Agents & the Case for Structured Content", "content": "In late 2016,   that 30 percent of web browsing sessions would be done without a screen by 2020. Earlier the same year,   that half of all searches would be voice searches by 2020. Though there’s   to suggest that the 2020 picture may be more complicated than these broad-strokes projections imply, we’re already seeing the impact that voice search, artificial intelligence, and smart software agents like Alexa and Google Assistant are making on the way information is found and consumed on the web.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In addition to the indexing function that traditional search engines perform, smart agents and AI-powered search algorithms are now bringing into the mainstream two additional modes of accessing information: aggregation and inference. As a result, design efforts that focus on creating visually effective pages are no longer sufficient to ensure the integrity or accuracy of content published on the web. Rather, by focusing on providing access to information in a structured, systematic way that is legible to both humans and machines, content publishers can ensure that their content is both accessible and accurate in these new contexts, whether or not they’re producing chatbots or tapping into AI directly. In this article, we’ll look at the forms and impact of structured content, and we’ll close with a set of resources that can help you get started with a structured content approach to information design. The role of structured content In their recent book,  , Carrie Hane and Mike Atherton define structured content as content that is “planned, developed, and connected outside an interface so that it’s ready for any interface.” A structured content design approach frames content resources—like articles, recipes, product descriptions, how-tos, profiles, etc.—not as pages to be found and read, but as packages composed of small chunks of content data that all relate to one another in meaningful ways.  In a structured content design process, the relationships between content chunks are explicitly defined and described. This makes both the content chunks and the relationships between them legible to algorithms. Algorithms can then interpret a content package as the “page” I’m looking for—or remix and adapt that same content to give me a list of instructions, the number of stars on a review, the amount of time left until an office closes, and any number of other concise answers to specific questions.  Structured content is already a mainstay of many types of information on the web. Recipe listings, for instance, have been based on structured content for years. When I search, for example, “bouillabaisse recipe” on Google, I’m provided with a standard list of links to recipes, as well as an overview of recipe steps, an image, and a set of tags describing one example recipe: This “featured snippet” view is possible because the content publisher, allrecipes.com, has broken this recipe into the smallest meaningful chunks appropriate for this subject matter and audience, and then expressed information about those chunks and the relationships between them in a machine-readable way. In this example, allrecipes.com has used both semantic HTML and   to make this content not merely a page, but also legible, accessible data that can be accurately interpreted, adapted, and remixed by algorithms and smart agents. Let’s look at each of these elements in turn to see how they work together across indexing, aggregation, and inference contexts. Software agent search and semantic HTML Semantic HTML is markup that communicates information about the meaningful relationships between document elements, as opposed to simply describing how they should look on screen. Semantic elements such as heading tags and list tags, for instance, indicate that the text they enclose is a heading ( ) for the set of list items ( ) in the ordered list ( ) that follows. HTML structured in this way is both presentational and semantic because people know what headings and lists look like and mean, and algorithms can recognize them as elements with defined, interpretable relationships. HTML markup that focuses only on the   aspects of a “page” may look perfectly fine to a human reader but be completely illegible to an algorithm. Take, for example, the   website, redesigned a few years ago in collaboration with top-tier design and development partners. If I want to find information about how to pay a parking ticket, a link from the home page takes me directly to the “How to Pay a Parking Ticket” screen (scrolled to show detail): As a human reading this page, I easily understand what my options are for paying: I can pay online, in person, by mail, or over the phone. If I ask Google Assistant how to pay a parking ticket in Boston, however, things get a bit confusing: None of the links provided in the Google Assistant results take me directly to the “How to Pay a Parking Ticket” page, nor do the descriptions clearly let me know I’m on the right track. (I didn’t ask about requesting a hearing.) This is because the content on the City of Boston parking ticket page is styled to communicate content relationships visually to human readers but is not structured semantically in a way that also communicates those relationships to inquisitive algorithms. The City of Seattle’s “Pay My Ticket” page, though it lacks the polished visual style of Boston’s site, also communicates parking ticket payment options clearly to human visitors: The equivalent Google Assistant search, however, offers a much more helpful result than we see with Boston. In this case, the Google Assistant result links directly to the “Pay My Ticket” page and also lists several ways I can pay my ticket: online, by mail, and in person. Despite the visual simplicity of the City of Seattle parking ticket page, it more effectively ensures the integrity of its content across contexts because it’s composed of structured content that is marked up semantically. “Pay My Ticket” is a level-one heading ( ), and each of the options below it are level-two headings ( ), which indicate that they are subordinate to the level-one element. These elements, when designed well, communicate information hierarchy and relationships visually to readers, and semantically to algorithms. This structure allows Google Assistant to reasonably surmise that the text in these   headings represents payment options under the   heading “Pay My Ticket.” While this use of semantic HTML offers distinct advantages over the “page display” styling we saw on the City of Boston’s site, the Seattle page also shows a weakness that is typical of manual approaches to semantic HTML. You’ll notice that, in the Google Assistant results, the “Pay by Phone” option we saw on the web page was not listed. If we look at the markup of this page, we can see that while the three options found by Google Assistant are wrapped in both   and   tags, “Pay by Phone” is only marked up with an  . This irregularity in semantic structure may be what’s causing Google Assistant to omit this option from its results. Although each of these elements would look the same to a sighted human creating this page, the machine interpreting it reads a difference. While WYSIWYG text entry fields can theoretically support semantic HTML, in practice they all too often fall prey to the idiosyncrasies of even the most well-intentioned content authors. By making meaningful content structure a core element of a site’s content management system, organizations can create semantically correct HTML for every element, every time. This is also the foundation that makes it possible to capitalize on the rich relationship descriptions afforded by linked data. Linked data and content aggregation In addition to finding and excerpting information, such as recipe steps or parking ticket payment options, search and software agent algorithms also now aggregate content from multiple sources by using linked data. In its most basic form,   is “ .” Linked data extends the basic capabilities of semantic HTML by describing not only what kind of thing a page element is (“Pay My Ticket” is an  ), but also the real-world concept that thing represents: this   represents a “pay action,” which inherits the structural characteristics of “trade actions” (the exchange of goods and services for money) and “actions” (activities carried out by an agent upon an object). Linked data creates a richer, more nuanced description of the relationship between page elements, and it provides the structural and conceptual information that algorithms need to meaningfully bring data together from disparate sources.  Say, for example, that I want to gather more information about two recommendations I’ve been given for orthopedic surgeons. A search for a first recommendation, Scott Ruhlman, MD, brings up a set of links as well as a   info box containing a photo, location, hours, phone number, and reviews from the web.  If we run Dr. Ruhlman’s Swedish Hospital profile page through Google’s  , we can see that content about him is structured as small, discrete elements, each of which is marked up with descriptive types and attributes that communicate both the meaning of those attributes’ values and the way they fit together as a whole—all in a machine-readable format. In this example, Dr. Ruhlman’s profile is marked up with microdata based on the   vocabulary. Schema.org is a collaborative effort backed by Google, Yahoo, Bing, and Yandex that aims to create a common language for digital resources on the web. This structured content foundation provides the semantic base on which additional content relationships can be built. The Knowledge Graph info box, for instance, includes Google reviews, which are not part of Dr. Ruhlman’s profile, but which have been aggregated into this overview. The overview also includes an interactive map, made possible because Dr. Ruhlman’s office location is machine-readable. The search for a second recommendation, Stacey Donion, MD, provides a very different experience. Like the City of Boston site above, Dr. Donion’s profile on the Kaiser Permanente website is perfectly intelligible to a sighted human reader. But because its markup is entirely presentational, its content is virtually invisible to software agents. In this example, we can see that Google is able to find plenty of links to Dr. Donion in its standard index results, but it isn’t able to “understand” the information about those sources well enough to present an aggregated result. In this case, the Knowledge Graph knows Dr. Donion is a Kaiser Permanente physician, but it pulls in the wrong location and the wrong physician’s name in its attempt to build a Knowledge Graph display.  You’ll also notice that while Dr. Stacey Donion is an exact match in all of the listed search results—which are numerous enough to fill the first results page—we’re shown a “did you mean” link for a different doctor. Stacy Donlon, MD, is a neurologist who practices at MultiCare Neuroscience Center, which is not affiliated with Kaiser Permanente. Multicare does, however, provide semantic and linked data-rich profiles for their physicians.  Voice queries and content inference The increasing prevalence of voice as a mode of access to information makes providing structured, machine-intelligible content all the more important. Voice and smart software agents are not just freeing users from their keyboards, they’re changing user behavior. According to  , there are several important differences between voice queries and typed queries. Voice queries tend to be: longer; more likely to ask who, what, and where; more conversational; and more specific. In order to tailor results to these more specifically formulated queries, software agents have begun inferring intent and then using the linked data at their disposal to assemble a targeted, concise response. If I ask Google Assistant what time Dr. Ruhlman’s office closes, for instance, it responds, “Dr. Ruhlman’s office closes at 5 p.m.,” and displays this result:  These results are not only aggregated from disparate sources, but are interpreted and remixed to provide a customized response to my specific question. Getting directions, placing a phone call, and accessing Dr. Ruhlman’s profile page on swedish.org are all at the tips of my fingers.  When I ask Google Assistant what time Dr. Donion’s office closes, the result is not only less helpful but actually points me in the wrong direction. Instead of a targeted selection of focused actions to follow up on my query, I’m presented with the hours of operation and contact information for MultiCare Neuroscience Center. MultiCare Neuroscience Center, you’ll recall, is where Dr. Donlon—the neuroscientist Google thinks I may be looking for, not the orthopedic surgeon I’m actually looking for—practices. Dr. Donlon’s profile page, much like Dr. Ruhlman’s, is semantically structured and marked up with linked data.  To be fair, subsequent trials of this search did produce the generic (and partially incorrect) practice location for Dr. Donion (“Kaiser Permanente Orthopedics: Morris Joseph MD”). It is possible that through repeated exposure to the search term “Dr. Stacey Donion,” Google Assistant fine-tuned the responses it provided. The initial result, however, suggests that smart agents may be at least partially susceptible to the same   that affects humans, wherein the information that is easiest to recall often seems the most correct. There’s not enough evidence in this small sample to support a broad claim that algorithms have “cognitive” bias, but even when we allow for potentially confounding variables, we can see the compounding problems we risk by ignoring structured content. “Donlon,” for example, may well be a more common name than “Donion” and may be easily mistyped on a QWERTY keyboard. Regardless, the Kaiser Permanente result we’re given above for Dr. Donion is for the wrong physician. Furthermore, in the Google Assistant voice search, the interaction format doesn’t verify whether we meant Dr. Donlon; it just provides us with her facility’s contact information. In these cases, providing clear, machine-readable content can only work to our advantage. The business case for structured content design In 2012, content strategist Karen McGrane wrote that “you don’t get to decide which platform or device your customers use to access your content:   do.” This statement was intended to help designers, strategists, and businesses prepare for the imminent rise of mobile. It continues to ring true for the era of linked data. With the growing prevalence of smart assistants and voice-based queries, an organization’s website is less and less likely to be a potential visitor’s first encounter with rich content. In many cases—such as finding location information, hours, phone numbers, and ratings—this pre-visit engagement may be a user’s only interaction with an information source.  These kinds of quick interactions, however, are only one small piece of a much larger issue: linked data is increasingly key to maintaining the integrity of content online. The organizations I’ve used as examples, like the hospitals, government agencies, and colleges I’ve consulted with for years, don’t measure the success of their communications efforts in page views or ad clicks. Success for them means connecting patients, constituents, and community members with services and accurate information about the organization, wherever that information might be found. This communication-based definition of success readily applies to virtually any type of organization working to further its business goals on the web. The model of building pages and then expecting users to discover and parse those pages to answer questions, though time-tested in the pre-voice era, is quickly becoming insufficient for effective communication. It precludes organizations from participating in emergent patterns of information seeking and discovery. And—as we saw in the case of searching for information about physicians—it may lead software agents to make inferences based on insufficient or erroneous information, potentially routing customers to competitors who communicate more effectively.  By communicating clearly in a digital context that now includes aggregation and inference, organizations are more effectively able to speak to their users where users actually are, be it on a website, a search engine results page, or a voice-controlled digital assistant. They are also able to maintain greater control over the accuracy of their messages by ensuring that the correct content can be found and communicated across contexts.  Getting started: who and how Design practices that build bridges between user needs and technology requirements to meet business goals are crucial to making this vision a reality. Information architects, content strategists, developers, and experience designers all have a role to play in designing and delivering effective structured content solutions.  Practitioners from across the design community have shared a wealth of resources in recent years on creating content systems that work for humans and algorithms alike. To learn more about implementing a structured content approach for your organization, these books and articles are a great place to start: , Sara Wachter-Boettcher “ ,” Rachel Lovinger , Karen McGrane , Carrie Hane and Mike Atherton Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/emerging-ux-role-in-personalization/", "title": "UX in the Age of Personalization", "content": "If you listened to episode 180 of  , you heard two key themes: 1) personalization is now woven into much of the fabric of our digital technology, and 2) designers need to be   more involved in its creation and deployment. In my   we took a broad look at the first topic: the practice of harvesting user data to personalize web content, including the rewards (this website   me!) and risks (creepy!). In this piece, we will take a more detailed look at the UX practitioner’s emerging role in personalization design: from influencing technology selection, to data modeling, to page-level implementation. And it’s high time we did. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. A call to arms Just as UX people took up the torch around   years ago, there is a watershed moment quickly approaching for personalization strategy. Simply put, the technology in this space is far outpacing the design practice. For example, while “personalized” emails have been around forever (“Dear COOLIN, …”), it’s now estimated that some   have attempted to personalize their homepage. If that scares you, it should: the same report indicated that fewer than a third think it’s actually working. As   points out, “personalization failures are typically design failures.” Indeed, many personalization programs are still driven primarily out of marketing and IT departments, a holdover from the legacy of the inbound, “creepy” targeted ad. Fixing that model will require the same paradigm shift we’ve used to tackle other challenges in our field: intentionally moving design “upstream,” in this case to technology selection, data collection, and page-level implementation. That’s where you come in. In fact, if you’re anything like me, you’ve been doing this, quietly, already. Here are just a few examples of UX-specific tasks I’ve completed on recent design projects that had personalization aspects: aligning personalization to the  ; working with the marketing team to understand  ; identifying   (personas) that may benefit from personalized content; drafting personalization  ; assisting the technical team with  ; helping to define the user  , including first- and third-party sources; wireframing   in the information architecture;  of existing content to repurpose for personalization; writing or editing new  ; working with the design team to create  ; developing a personalization   and governance model; helping to set up and monitor results from a personalization  ; partnering with the analytics team to make  ; being a voice for the personalization program’s  ; and monitoring   to make sure people aren’t freaking the f* out. Sound familiar? Many of these are simply variants on the same, user-centered tactics you’ve relied on for years. The difference now is that personalization creates a “third dimension” of complexity relative to audience and content. We’ll define that complexity further in two parts: technical design and information design. (We should note again that the focus of this article is personalizing  , although many of the same principles also apply to email and native applications.) Part 1: Personalization technical design Influencing technology decisions When clients or internal stakeholders come to you with a desire to “do personalization,” the first thing to ask is what does that mean. As you’ve likely noticed, the technology landscape has now matured to the point where you can “personalize” a digital experience based on just about anything, from basic geolocation to complex machine learning algorithms. What’s more, such features are increasingly baked into your own CMS or readily available from third-party plugins (see chart below). So defining what personalization is—and isn’t—is a critical first step.  To accomplish this, I suggest asking two questions: 1) What   can you ethically collect on your users, and 2) which   best complement this data. Some capabilities may already exist in your current systems; some you may need to build into your future technology roadmap. The following is by no means an exhaustive list but highlights a few of the popular tactics out there today, and tools that support them:  MaxMind, HTML5 API\n  Dynamic Yield, Optimizely\n  Marketo, Oracle (BlueKai), Demandbase\n  Simpli.fi, Thinknear, Google Geofencing API.\n As you can see, the best tactic(s) can vary dramatically based on your audience and how they interact with you. For example, if you’re a high-volume, B2C ecommerce site, you may have enough click-stream data to support useful personalized product recommendations. Conversely, if you’re a B2B business with a qualified lead model and fewer unique visitors, you may be better served by third-party data to help you tailor your message based on industry type (NAICS code) or geography. To help illustrate this idea, let’s do a quick mapping of tactics relative to visitor volume and session time: The good news here is that you needn’t have a massive data platform in place; you can begin to build audience profiles simply by asking users to self-identify via quizzes or profile info. But in either scenario, your goal is the same: help guide the technology decision toward a personalization approach that provides actual value to your audience,   “because we can.” Part 2: Personalization information design Personalization deliverables Once you have a sense of the technical possibilities, it’s time to determine how the personalized experience will look. Let’s pretend we’re designing for a venture several of you inquired about in my  :  . As the name implies, this is a nonprofit that provides hugs to reindeer. RHI recently set new business goals and wants to personalize the website to help achieve them. To address this goal, we propose four  : Following the technical model we discussed earlier, the first thing we do is define our audience based on existing site interaction patterns. We discover that RHI doesn’t get a ton of organic traffic, but they do have a reasonably active set of authenticated users (existing members) as well as some paid social media campaigns. Working with the marketing team, we propose personalizing the site for three  , as follows: Segments worksheet Next, let’s determine the   we could add for these segments when they come to the site. To do this, we’ll revisit a model that we looked at previously for the  . This will help us organize the collective content or “campaign” we show each segment based on a specific personalization goal: For example, current members who are logged in might benefit from a “Make Easier” campaign of links to members-only content. Conversely,   of our three segments could benefit from a personalized “Cross-Sell” campaign to help generate awareness. Let’s capture our ideas like this: Campaigns worksheet Personalization wireframes Now let’s decide where on the site we want to run these personalized campaigns. This isn’t too dissimilar from the work you already do around templates and components, with the addition that we can now have  . You can think of these as blocks where the CMS (or third-party plugin) will be running a series of calculations to determine the user segment in real-time (or based on a previously cached profile). To get the most coverage, these are typically dropped in at the template level. Here are examples for our home page template and interior page template: Everything in white is the non-personalized, or “static,” content, which never changes, regardless of who you are. The personalized zones themselves (color-coded based on our content model) will also have an underlying   that appears if the system doesn’t get a personalized match. (Note: this is also the version of the content that is typically indexed by search engines.)  As you can see, an important rule of thumb is to personalize   the main content, not the entire page. There are a variety of reasons for this, including the risk of getting the audience wrong, effects on search indexing, and what’s known as the  , i.e., can you realistically create content for every single audience on every single component? (Hint: no.)  OK, we’re getting close! Finally, let’s look at what specifically we want the system to show in these slots. Based on our campaigns worksheet, we know how many permutations of content we need. We sit down with the creative team to design our targeted messages, including the copy, images, and calls to action. Here’s what the capital campaign (the blue zone) might look like for our three audiences: Personalization copy deck  You’re a hugging expert. But did you know you could hug two reindeers at once?  Sign up for our Two-for-One Hugs  Learn More\n  Are you a real man?  Prove It  [None]\n  Reindeer hugs are 100% kid-friendly and 200% environmentally-friendly.  Shop Our Family Plan  Learn More\n That’s a pretty good start. We would want to follow a similar approach to detail our other three content campaigns, including alerts (e.g., hugs needed in your area), make easier (e.g., member shortcuts), and enrichment content (e.g., blog articles on latest reindeer fashions). When all the campaigns are up and running, we might expect the homepage to look something like this when seen by two different audiences, simultaneously, in real-time, in different browser sessions: Part 3: Advanced personalization techniques Digital Experience Platforms Of course, all of that work was fairly manual. If you are lucky enough to be working with an advanced   (Data Management Platform) or integrated   ( ) then you have even more possibilities at your disposal. For example,   and   can help you discover segments over time that you might never have dreamed of (the study we referenced earlier showed that 26% of marketing programs have tried some form of algorithmic one-to-one approach; 68% still use rules-based targeting to segments). This can be enhanced via  , where actioning off of multiple data inputs can help you create blends of audience types (in our example, a thirty-three-year-old dad might get 60 percent Parent and 40 percent Real Man … or whatever). Likewise, on the content side,   can help you deliver more nuanced content. (For example, we might tag an article with 20 percent Reindeer Advocacy and 80 percent Hug Best Practices.) Platforms like Sitecore can even illustrate these metrics, like in this example of a pattern card: Cult of the complex While all of that is super cool, even the most tech-savvy among us will benefit from starting out “simple,” lest you fall prey to the  . The manual process of identifying your target audience and use cases, for example, is foundational to building an extensible personalization program, regardless of your tech stack. At a minimum, this approach will help you get buy-in from your team and organization vs. just telling everyone the site will be personalized in a “black box” somewhere. And even   the best-in-class products, I have yet to find seamless “one-click” personalization, where the system somehow magically does everything from finding audiences to pumping out content, all in real time. We’ll get there one day, perhaps.  But, in the meantime, it’s up to you. Like this: \n\t\t\t\t\t\t\tRecently by Colin Eagan\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/paint-the-picture-not-the-frame/", "title": "Paint the Picture, Not the Frame: How Browsers Provide Everything Users Need", "content": "Kip Williams, professor of psychology sciences at Purdue University, conducted   called “cyberball.” In his experiment, a test subject and two other participants played a computer game of catch. At a predetermined time, the test subject was excluded from the game, forcing them to only observe as the clock ran down. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The experience showed increases in self-reported levels of anger and sadness, as well as lowering levels of  . The digital version of the experiment created results that matched the results of  , meaning that these feelings occurred regardless of context. After the game was concluded, the test subject was told that the other participants were robots, not other human participants. Interestingly, the reveal of automated competitors did not lessen the negative feelings reported. In fact, it   feelings of anger, while also decreasing participants’ sense of willpower and/or self-regulation. In other words: people who feel they are rejected by a digital system will feel hurt and have their sense of autonomy reduced, even when they believe there isn’t another human directly responsible. So, what does this have to with browsers? Every adjustment to the appearance and behavior of the features browsers let you manipulate is a roll of the dice, gambling on the delight of some at the expense of alienating others. When using a browser to navigate the web, there’s  , until there isn’t. Most of the time we’re hopping from page-to-page and site-to-site, clicking links, pressing buttons, watching videos, filling out forms, writing messages, etc. But every once in awhile we stumble across something new and novel that makes us pause to figure out what’s going on. Every website and web app is its own self-contained experience, with its own ideas of how things should look and behave. Some are closer to others, but each one requires learning how to operate the interface to a certain degree. Some browsers can also have parts of their functionality and appearance altered, meaning that as with websites, there can be unexpected discrepancies. We’ll unpack some of the nuance behind some of these features, and more importantly, why most of them are better off left alone. Scroll-to-top All the major desktop browsers allow you to hit the   key on the keyboard to jump to the top of the page. Some scrollbar implementations allow you to click on the top of the scrollbar area to do the same. Some browsers allow you to type   (macOS) /   (Windows), as well. People who use assistive technology like screen readers can use things like   to navigate the same way (provided they are correctly declared in the site’s HTML). However, not every device has an easily discoverable way to invoke this functionality: many laptops don’t have a   key on their keyboard. The   functionality on iOS is difficult to discover, and can be surprising and frustrating if accidentally activated. You need   to recreate screen reader landmark navigation techniques. One commonly implemented UI solution for longer pages is the scroll-to-top button. It’s often fixed to the bottom-right corner of the screen. Activating this control will take the user to the top of the page, regardless of how far down they’ve scrolled. If your site features a large amount of content per page, it may be worth investigating this UI pattern. Try looking at analytics and/or conducting user tests to see where and how often this feature is used. The caveat being if it’s used too often, it might be worth taking a long, hard look at your information architecture and content strategy. Three things I like about the scroll-to-top pattern are: Its functionality is pretty obvious (especially if properly labeled). Provided it is designed well, it can provide a decent-sized touch target in  . For  , its touch target can be superior to narrow scroll or status bars, which can make for frustratingly small targets to hit. It does not alter or remove existing scroll behavior, augmenting it instead. If somebody is used to one way of scrolling to the top, you’re not overriding it or interrupting it. If you’re implementing this sort of functionality, I have four requests to help make the experience work for everyone (I find the   library to be a helpful starting place): Honor user requests for  . The dramatic scrolling effect of whipping from the bottom of the page to the top may be a  , a situation where the system that controls your body’s sense of physical position and orientation in the world is disrupted, causing things like headaches, nausea, vertigo, migraines, and hearing loss. Ensure keyboard focus is moved to the top of the document, mirroring what occurs visually. Applying this practice will improve   users’ experiences. Otherwise, hitting   after scrolling to the top would send the user down to the first interactive element that follows where the focus had been before they activated the scroll button. Ensure the button does not make other content unusable by obscuring it. Be sure to account for when the browser is in a zoomed-in state, not just in its default state. Be mindful of other fixed-position elements. I’ve seen my fair share of websites that also have a chatbot or   competing to live in the same space. Scrollbars If you’re old enough to remember, it was once considered fashionable to style your website scrollbars. Internet Explorer allowed this customization via  . At best, they looked great! If the designer and developer were both skilled and detail-oriented, you’d get something that looked like a natural extension of the rest of the website.  However, the stakes for a quality design were pretty high: scrollbars are part of an application’s interface, not a website’s. In inclusive design, it’s part of what we call  . External consistency is the idea that an object’s functionality is informed and reinforced by similar implementations elsewhere. It’s why you can flip a wall switch in most houses and be guaranteed the lights come on instead of flushing the toilet. While scrollbars have some minor visual differences between operating systems (and  ), they’re consistent externally in function. Scrollbars are also consistent internally, in that every window and program on the OS that requires scrolling has the same scrollbar treatment. If you customize your website’s scrollbar colors, for less technologically literate people, yet another aspect of the interface has changed without warning or instruction on how to change it back. If the user is  already confused about how things on the screen work, it’s one less familiar thing for them to cling to as stable and reliable.  You might be rolling your eyes reading this, but I’d ask you to check out   instead. In it, she describes conducting a guerilla user test at a mall, only to have the session completely derailed when she discovers someone who has never used a computer before. What she discovers is as important as it is shocking. The gist of it is that some people (even those who have used a computer before) don’t understand the nuance of the various “layers” you navigate through to operate a computer: the hardware, the OS, the browser installed on the OS, the website the browser is displaying, the website’s modals and disclosure statements, etc. To them, the experience is flat.  We should not expect these users to juggle this kind of cognitive overhead. These kinds of abstractions are crafted to be  , specifically so people can get what they want from a digital system without having to be programmers. Adding unnecessary complexity weakens these metaphors and gives users one less reference point to rely on.  Remember the cyberball experiment. When a user is already in a distressed emotional state, our poorly-designed custom scrollbar might be the death-by-a-thousand-paper-cuts moment where they give up on trying to get what they want and reject the system entirely. While Morrow’s article was written in 2011, it’s just as relevant now as it was then. More and more people are using the internet globally, and more and more services integral to living daily life are getting digitized. It’s up to us as responsible designers and developers to be sure we make everyone, regardless of device, circumstance, or ability feel welcome. In addition to unnecessarily abandoning external consistency, there is the issue of custom scrollbar styling potentially not having  . The too-light colors can create a situation where a person experiencing low-vision conditions won’t be able to perceive, and therefore operate, a website’s scrolling mechanism. This article won’t even begin to unpack the issues involved with custom implementations of scrollbars, where instead of theming the OS’s native scrollbars with CSS, one instead replaces them with a JavaScript solution. Trust me when I say I have yet to see one implemented in a way that could successfully and reliably recreate all features and functionality across all  , OSes, browsers, and  . In my opinion? Don’t alter the default appearance of an OS’s scrollbars. Use that time to work on something else instead, say, checking for and fixing color contrast problems. Scrolling The main concern about altering scrolling behavior is one of consent: it’s taking an externally consistent, system-wide behavior and suddenly altering it without permission. The term   has been coined to describe this practice. It is not to be confused with  , a more considerate treatment of scrolling behavior that honors the OS’s scrolling settings. Altering the scrolling behavior on your website or web app can fly in the face of someone’s specific, expressed preferences. For some people, it’s simply an annoyance. For people with motor control concerns, it could make moving through a site difficult. In some extreme cases, the unannounced discrepancy between the amount of scrolling and the distance traveled can also be vestibular triggers. Another consideration is if your modified scrolling behavior   who don’t use mice, touch, or trackpads to scroll.  All in all, I think  : Scrolljacking, as I shall now refer to it both sarcastically and honestly, is a failure of the web designer’s first objective; it attacks a standardised pattern and greedily assumes control over the user’s input. Highlighting Another OS feature we’re permitted to style in the browser is highlighted text. Much like scrollbars, this is an interface element that is shared by all apps on the OS, not just the browser.  Breaking the external consistency of the OS’s highlighting color has a lot of the same concerns as styled scrollbars, namely altering the expected behavior of something that functions reliably everywhere else. It’s potentially disorienting and alienating, and may deny someone’s expressed preferences. Some people highlight text as they read. If your custom highlight style has a low contrast ratio between the highlighted text color and the highlighted text’s background color, the person reading your website or web app may be unable to perceive the text they’re highlighting. The effect will cause the text to seemingly disappear as they try to read.  Other people just may not care for your aesthetic sensibilities. Both macOS and Windows allow you to specify a custom highlight color. In a scenario where someone has deliberately set a preference other than the system default, a styled highlight color may override their stated specifications.  For me, the potential risks far outweigh the vanity of a bespoke highlight style—better to just leave it be. Text resizing  to suit their needs. And that’s a good thing. We want people to be able to read our content and act upon it, regardless of whatever circumstances they may be experiencing.  For the problem of too-small text, some designers turn to text resizing widgets, a custom UI pattern that lets a person cycle through a number of preset CSS   values. Commonly found in places with heavy text content, text resizing widgets are often paired with complex, multicolumn designs. News sites are a common example. Before I dive into my concerns with text resizing widgets, I want to ask: if you find that your site needs a specialized widget to manage your text size, why not just take the simpler route and  ? Like many  , a request for a larger font size isn’t necessarily indicative of  . It’s often circumstantial, such as a situation where you’re showing a website on your office’s crappy projector. Browsers allow users to change their preferred default font size, resizing text across websites accordingly. Browsers excel at handling this setting when you write CSS that takes advantage of   and  .  Some designers may feel that granting this liberty to users somehow detracts from their intended branding. Good designers understand that there’s more to branding than just how something looks. It’s about implementing the initial design in the browser, then   to best serve the person using it. Even if things like the font size are adjusted, a strong brand will still shine through with the ease of your user flows, quality of your typography and palette, strength of your copywriting, etc. Unfortunately, custom browser text resizing widgets lack a universal approach. If you rely on browser text settings, it just works—consistently, with the same controls, gestures, and keyboard shortcuts, for every page on every website, even in  . You don’t have to write and maintain extra code, test for regressions, or write copy instructing the user on where to find your site’s text resizing widget and how to use it. Behavioral consistency is incredibly important. Browser text resizing is applied to all text on the page proportionately every time the setting is changed. These settings are also retained for the next time you visit. Not every custom text resizing widget does this, nor will it resize all content to  .  High-contrast themes When I say high-contrast themes, I’m not talking about things like a  . I’m talking about a response to people reporting that they need to   to be more visually accessible to them. Much like text resizing controls, themes that are designed to provide higher contrast color values are perplexing: if you’re taking the time to make one, why not just fix the insufficient contrast values in your regular CSS? Effectively   is a complicated, resource-intensive affair, even under ideal situations.  Most site-provided high-contrast themes are static in that the designer or developer made decisions about which color values to use, which can be a problem. Too much contrast has been known to be a trigger for things like migraines, as well as potentially making it difficult to focus for users with some forms of attention-deficit hyperactivity disorder (ADHD). The contrast conundrum leads us to a difficult thing to come to terms with when it comes to accessibility: what works for one person may actually inhibit another. Because of this, it’s important to make things open and interoperable. Leave ultimate control up to the end user so they may decide how to best interact with content. If you are going to follow through on providing this kind of feature, some advice:  . It’s a specialized Windows feature that allows a person to force a high color palette onto all aspects of the OS’s UI, including anything the browser displays. It offers four themes out of the box but also allows a user to suit their individual needs by specifying their own colors.  Your high contrast mode feature should do the same. Offer a range of themes with different palettes, and let the user pick colors that work best for them—it will guarantee that if your offerings fail, people still have the ability to self-select. Moving focus Keyboard focus is how people who rely on input such as keyboards, switch controls, voice inputs, eye tracking, and   navigate and operate digital interfaces. While you can do things like use   to move keyboard focus to the first input on a page after it loads, it is not recommended.  For people experiencing low- and no-vision conditions, it is equivalent to being abruptly and instantaneously moved to a new location. It’s a confusing and disorienting experience—there’s a reason why there’s a trope in sci-fi movies of people vomiting after being teleported for the first time.  For people with motor control concerns, moving focus without their permission means they may be transported to a place where they didn’t intend to go. Digging themselves out of this location becomes annoying at best and effort-intensive at worst. Websites without   or document landmarks to serve as navigational aids can worsen this effect. This is all about consent. Moving focus is fine so long as a person deliberately initiates an action that requires it ( , for example). I don’t come to your house and force you to click on things, so don’t move my keyboard focus unless I specifically ask you to. Let the browser handle keyboard focus. Provided you use semantic markup, browsers do this well. Some tips: Use   with care and discretion. Don’t declare   on interactive elements ( ,  ,  ,  ,  , and  ). Don’t use   that runs parallel to what you’d expect a user to click on. Instead, author your HTML in such a way that the resulting DOM  . Taking a   helps out a lot here. The clipboard and browser history The clipboard is sacred space. Don’t prevent people from copying things to it, and don’t append extra content to what they copy. The same goes for browser history and back and forward buttons. Don’t mess around with time travel, and just let the browser do its job. Wrapping up In the game part of cyberball, the fun comes from being able to participate with others, passing the ball back and forth. With the web, fun comes from being able to navigate through it. In both situations, fun stops when people get locked out, forced to watch passively from the sidelines.  Fortunately, the web doesn’t have to be one long cyberball experiment. While altering the powerful, assistive technology-friendly features of browsers can enhance the experience for some users, it carries a great risk of alienating others if changes are made with ignorance about exactly how much will be affected.  Remember that this is all in the service of what ultimately matters: creating robust experiences that allow people to successfully use your website or web app regardless of their ability or circumstance. Sometimes the best strategy is to let things be. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-for-conversions/", "title": "Designing for Conversions", "content": "What makes creative successful? Creative work often lives in the land of feeling—we can say we like something, point to how happy the client is, or talk about how delighted users will be, but can’t objectively measure feelings. Measuring the success of creative work doesn’t have to stop with feeling. In fact, we can assign it numbers, do math with it, and track improvement to show clients objectively how well our creative is working for them. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. David Ogilvy once said, “If it doesn’t sell, it isn’t creative.” While success may not be a tangible metric for us, it is for our clients. They have hard numbers to meet, and as designers, we owe it to them to think about how our work can meet those goals. We can track sales, sure, but websites are ripe with other opportunities for measuring improvements. Designing for conversions will not only make you a more effective designer or copywriter, it will make you much more valuable to your clients, and that’s something we should all seek out. Wait—what’s a conversion? Before designing for conversions, let’s establish a baseline for what, exactly, we’re talking about. A   is an action taken by the user that accomplishes a business goal. If your site sells things, a conversion would be a sale. If you collect user information to achieve your business goals, like lead aggregation, it would be a form submission. Conversions can also be things like newsletter sign-ups or even hits on a page containing important information that you need users to read. You need some tangible action to measure the success of your site—that’s your conversion. Through analytics, you know how many people are coming to your site. You can use this to measure what percentage of users are converting. This number is your  , and it’s the single greatest metric for measuring the success of a creative change. In your analytics, you can set up goals and conversion funnels to track this for you (more on conversion funnels shortly). It doesn’t matter how slick that new form looks or how clever that headline is—if the conversion rate drops, it’s not a success. In fact, once you start measuring success by conversion rate, you’ll be surprised to see how even the cleverest designs applied in the wrong places can fail to achieve your goals. Conversions aren’t always a one-step process. Many of us have multi-step forms or long check-out processes where it can be very useful to track how far a user gets. It’s possible to set up multiple goals along the way so your analytics can give you this data. This is called a  . Ideally, you’ll coordinate with the rest of your organization to get data beyond the website as well. For instance, changing button copy may lead to increased form submissions but a drop in conversions from lead to sale afterward. In this case, the button copy update probably confused users rather than selling them on the product. A good conversion funnel will safeguard against false positives like that. It’s also important to track the  , which is the percentage of  users that hit a page and leave without converting or navigating to other pages. A higher bounce rate is an indication that there’s a mismatch between the user’s expectations when landing on your site and what they find once landing there. Bounce rate is really a part of the conversion funnel, and reducing bounce rate can be just as important as improving conversion rate. Great. So how do we do that? When I was first getting started in conversion-driven design, it honestly felt a little weird. It feels shady to focus obsessively on getting the user to complete an action. But this focus is in no way about tricking the user into doing something they don’t want to do—that’s a bad business model. As Gerry McGovern has commented, if business goals don’t align with customer goals, your business has no future. So if we’re not tricking users, what   we doing? Users come to your site with a problem, and they’re looking for a solution. The goal is to find users whose problems will be solved by choosing your product. With that in mind, improving the conversion rate doesn’t mean tricking users into doing something—it means showing the   users how to solve their problem. That means making two things clear: that your product will solve the user’s problem, and what the user must do to proceed. The first of these two points is the  . This is how the user determines whether your product can solve his or her problem. It can be a simple description of the benefits, customer testimonials, or just a statement about what the product will do for the user. A page is not limited to one value proposition—it’s good to have several. (Hint: the page’s headline should almost always be a value proposition!) The user should be able to determine quickly why your product will be helpful in solving their problem. Once the value of your product has been made clear, you need to direct the user to convert with a call to action. A   tells the user what they must do to solve their problem—which, in your case, means to convert. Most buttons and links should be calls to action, but a bit of copy directly following a value proposition is a good place too. Users should never have to look around to find out what the next step is—it should be easy to spot and clear in its intention. Also, ease of access is a big success factor here. My team’s testing found that replacing a Request Information button (that pointed to a form page) with an actual form on every page significantly boosted the conversion rate. If you’re also trying to get information from a user, consider a big form at the top of the page so users can’t miss it. When they scroll down the page and are ready to convert, they remember the form and have no question as to what they have to do. So improving conversion rate (and, to some degree, decreasing bounce rate) is largely about adding clarity around the value proposition and call to action. There are other factors as well, like decreasing friction in the conversion process and improving performance, but these two things are where the magic happens, and conversion problems are usually problems with one of them. So, value propositions…how do I do those? The number one thing to remember when crafting a value proposition is that you’re not selling a product—you’re selling a solution. Value propositions begin with the user’s problem and focus on that. Users don’t care about the history of your company, how many awards you’ve won, or what clever puns you’ve come up with—they care about whether your product will solve their problem. If they don’t get the impression that it can do that, they will leave and go to a competitor. In my work with landing pages for career schools, we initially included pictures of people in graduation gowns and caps. We assumed that the most exciting part of going back to school was graduating. Data showed us that we were wrong. Our testing showed that photos of people doing the jobs they would be training for performed much better. In short, our assumption was that showing the product (the school) was more important than showing the benefit (a new career). The problem users were trying to solve wasn’t a diploma—it was a career, and focusing on the user showed a significant improvement in conversion rate. We had some clients that insisted on using their branding on the landing pages, including one school that wanted to use an eagle as their hero image because their main website had eagles everywhere. This absolutely bombed in conversions. No matter how strong or consistent your branding is, it will not outperform talking about users and their problems. Websites that get paid for clicks have mastered writing headlines this way. Clickbait headlines get a groan from copywriters—especially since they often use their powers for evil and not good—but there are some important lessons we can learn from them. Take this headline, for instance: Just like in the example above with the college graduates, we’re selling the product—not the benefit. This doesn’t necessarily show that we understand the user’s problem, and it does nothing to get them excited about our program. Compare that headline to this one: In this case, we lead with the user’s problem. That immediately gets users’ attention. We then skip to a benefit: a quick turnaround. No time is wasted talking about the product—we save that for the body copy. The headline focuses entirely on the user. In your sign-up or check-out process, always lead with the information the user is most interested in. In our case, letting the user first select their school campus and area of study showed a significant improvement over leading with contact information. Similarly, put the less-exciting content last. In our testing, users were least excited about sharing their telephone number. Moving that field to be the last one in the form decreased form abandonment and improved conversions. As designers, be cognizant of what your copywriters are doing. If the headline is the primary value proposition (as it should be), make sure the headline is the focal point of your design. Ensure the messaging behind your design is in line with the messaging in the content. If there’s a disagreement in what the user’s problem is or how your product will solve that problem, the conversion rate will suffer. Once the value proposition has been clearly defined and stated, it’s time to focus on the call to action. What about the call to action? For conversion-driven sites, a good call to action is the most important component. If a user is ready to convert and has insufficient direction on how to do so, you lose a sale at 90 percent completion. It needs to be abundantly clear to the user how to proceed, and that’s where the call to action steps in. When crafting a call to action, don’t be shy. Buttons should be large, forms should be hard to miss, and language should be imperative. A call to action should be one of the first things the user notices on the page, even if he or she won’t be thinking about it again until after doing some research on the page. Having the next step right in front of the user vastly increases the chance of conversion, so users need to know that it’s there waiting. That said, a call to action should never get in the way of a value proposition. I see this all the time: a modal window shows as soon as I get to a site, asking me to subscribe to their mailing list before I have an inkling of the value the site can give me. I dismiss these without looking, and that call to action is completely missed. Make it clear   to convert, and make it easy, but don’t ask for a conversion before the user is ready. For situations like the one above, a better strategy might be asking me to subscribe as I exit the site; marketing to visitors who are leaving  . In my former team’s tests, there were some design choices that could improve calls to action. For instance, picking a bright color that stood out from the rest of the site for the submit button did show an improvement in conversions, and  . But most of the gains here were in either layout or copy; don’t get so caught up in minor design changes that you ignore more significant changes like these. Ease of access is another huge factor to consider. As mentioned above, when my team was getting started, we had a Request Information link in the main navigation and a button somewhere on the page that would lead the user to the form. The single biggest positive change we saw involved putting a form at the top of every page. For longer forms, we would break this form up into two or three steps, but having that first step in sight was a huge improvement, even if one click doesn’t seem like a lot of effort. Another important element is headings. Form headings should ask the user to do something. It’s one thing to label a form “Request Information”; it’s another to ask them to “Request Information Now.” Simply adding  , like “now” or “today,” can change a description into an imperative action and improve conversion rates. With submit buttons, always take the opportunity to communicate value. The worst thing you can put on a submit button is the word “Submit.” We found that switching this button copy out with “Request Information” showed a significant improvement. Think about the implied direction of the interaction. “Submit” implies the user is giving something to us; “Request Information” implies we’re giving something to the user. The user is already apprehensive about handing over their information—communicate to them that they’re getting something out of the deal. Changing phrasing to be more personal to the user can also be very effective. One study showed that writing button copy in first person—for instance, “Create My Account” versus “Create Your Account”— , boosting click-through rates by 90%. Users today are fearful that their information will be used for nefarious purposes. Make it a point to reassure them that their data is safe. Our testing showed that the best way to do this is to add a link to the privacy policy (“Your information is secure!”) with a little lock icon right next to the submit button. Users will often skip right over a small text link, so that lock icon is essential—so essential, in fact, that it may be more important than the privacy policy itself. I’m somewhat ashamed to admit this, but I once forgot to create a page for the privacy policy linked to from a landing page, so that little lock icon linked out to a 404. I expected a small boost in conversions when I finally uploaded the privacy policy, but nope—nobody noticed. Reassurance is a powerful thing. Measure, measure, measure One of the worst things you can do is push out a creative change, assume it’s great, and move on to the next task.   is ideal and will allow you to test a creative change directly against the old creative, eliminating other variables like time, media coverage, and anything else you might not be thinking of. Creative changes should be applied methodically and scientifically—just because two or three changes together show an improvement in conversion rate doesn’t mean that one of them wouldn’t perform better alone. Measuring tangible things like conversion rate not only helps your client or business, but can also give new purpose to your designs and creative decisions. It’s a lot easier to push for your creative decisions when you have hard data to back up why they’re the best choice for the client or project. Having this data on hand will give you more authority in dealing with clients or marketing folks, which is good for your creative and your career. If my time in the design world has taught me anything, it’s that, in the realm of creativity, certainty can be hard to come by. So, perhaps most importantly, objective measures of success give you, and your client, the reassurance that you’re doing the right thing. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/semantics-to-screen-readers/", "title": "Semantics to Screen Readers", "content": "As a child of the ’90s, one of my favorite movie quotes is from  : “there are as many ways to live as there are people in this world, and each one deserves a closer look.” Likewise, there are as many ways to browse the web as there are people online. We each bring unique context to our web experience based on our values, technologies, environments, minds, and bodies. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites.  (ATs), which are hardware and software that help us perceive and interact with digital content, come in diverse forms. ATs can use a whole host of user input, ranging from clicks and keystrokes to minor muscle movements. ATs may also present digital content in a variety of forms, such as Braille displays, color-shifted views, and decluttered   (UIs). One more commonly known type of AT is the screen reader. Programs such as JAWS, Narrator, NVDA, and VoiceOver can take digital content and present it to users through voice output, may display this output visually on the user’s screen, and can have Braille display and/or screen magnification capabilities built in. If you make websites, you may have tested your sites with a screen reader. But how do these and other assistive programs actually access your content? What information do they use? We’ll take a detailed step-by-step view of how the process works. The semantics-to-screen-readers pipeline Accessibility   (APIs) create a useful link between user applications and the assistive technologies that wish to interact with them. Accessibility APIs facilitate communicating accessibility information about user interfaces (UIs) to the ATs. The API expects information to be structured in a certain way, so that whether a button is properly marked up in web content or is sitting inside a native app taskbar, a button is a button is a button as far as ATs are concerned. That said, screen readers and other ATs can do some app-specific handling if they wish. On the web specifically, there are some browser and screen reader combinations where accessibility API information is supplemented by access to DOM structures. For this article, we’ll focus specifically on accessibility APIs as a link between web content and the screen reader. Here’s the breakdown of how web content reaches screen readers via accessibility APIs: The   uses host language markup (HTML, SVG, etc.), and potentially roles, states, and properties from the   where needed to provide the semantics of their content. Semantic markup communicates what type an element is, what content it contains, what state it’s in, etc. The   (alternatively referred to as a “user agent”) takes this information and maps it into an accessibility API. Different accessibility APIs are available on different operating systems, so a browser that is available on multiple platforms should support multiple accessibility APIs. Accessibility API mappings are maintained on a lower level than web platform APIs, so web developers don’t directly interact with accessibility APIs. The   includes a collection of   that browsers and other apps can plumb into, and generally acts as an intermediary between the browser and the screen reader. Accessibility APIs provide interfaces for representing the structure, relationships, semantics, and state of digital content, as well as means to surface dynamic changes to said content. Accessibility APIs also allow screen readers to retrieve and interact with content via the API. Again, web developers don’t interact with these APIs directly; the rendering engine handles translating web content into information useful to accessibility APIs. Examples of accessibility APIs    (MSAA), extended with another API called   (IA2)    (UIA), the Microsoft successor to MSAA. A browser on Windows can choose to support MSAA with IA2, UIA, or both.    (AXAPI)    (ATK) and   (AT-SPI). This case is a little different in that there are actually two separate APIs: one through which browsers and other applications pass information along to (ATK) and one that ATs then call from (AT-SPI). The   uses client-side methods from these accessibility APIs to retrieve and handle information exposed by the browser. In browsers where direct access to the Document Object Model (DOM) is permitted, some screen readers may also take additional information from the DOM tree. A screen reader can also interact with apps that use differing accessibility APIs. No matter where they get their information, screen readers can dream up any interaction modes they want to provide to their users (I’ve provided links to screen reader commands at the end of this article). Testing by site creators can help identify content that feels awkward in a particular navigation mode, such as multiple links with the same text (“Learn more”), as one example. Example of this pipeline: surfacing a button element to screen reader users Let’s suppose for a moment that a screen reader wants to understand what object is next in the accessibility tree (which I’ll explain further in the next section), so it can surface that object to the user as they navigate to it. The flow will go a little something like this: Suppose that the screen reader user would now like to “click” this button. Here’s how their action flows all the way back to web content: Now that we have a general sense of the pipeline, let’s go into a little more detail on the accessibility tree. The accessibility tree The   is a hierarchical representation of elements in a UI or document, as computed for an accessibility API. In modern browsers, the accessibility tree for a given document is a separate, parallel structure to the DOM tree. “Parallel” does not necessarily mean there is a 1:1 match between the nodes of these two trees. Some elements may be excluded from the accessibility tree, for example if they are hidden or are not semantically useful (think non-focusable wrapper  s without any semantics added by a web developer). This idea of a hierarchical structure is somewhat of an abstraction. The definition of what exactly an accessibility tree is in practice has been debated and partially defined in multiple places, so implementations may differ in various ways. For example, it’s not actually necessary to generate accessible objects for every element in the DOM whenever the DOM tree is constructed. As a performance consideration, a browser could choose to deal with only a subset of objects and their relationships at a time—that is, however much is necessary to fulfill the requests coming from ATs. The rendering engine could make these computations during all user sessions, or only do so when assistive technologies are actively running. Generally speaking, modern web browsers wait until after style computation to build up any accessible objects. Browsers wait in part because generated content (such as   and  ) can contain text that can participate in calculation of the accessible object’s name. CSS styles can also impact accessible objects in other various ways: text styling can come through as attributes on accessible text ranges. Display property values can impact the computation of line text ranges. These are just a few ways in which style can impact accessibility semantics. Browsers may also use different structures as the basis for accessible object computation. One rendering engine may walk the DOM tree and cross-reference style computations to build up parallel tree structures; another engine may use only the nodes that are available in a style tree in order to build up their accessibility tree. User agent participants in the standards community are currently thinking through how we can better document our implementation details, and whether it might make sense to standardize more of these details further down the road. Let’s now focus on the branches of this tree, and explore how individual accessibility objects are computed. Building up accessible objects From API to API, an accessible object will generally include a few things: , or the type of accessible object (for example, Button). The role tells a user how they can expect to interact with the control. It is typically presented when screen reader focus moves onto the accessible object, and it can be used to provide various other functionalities, such as skipping around content via one type of object. , if specified. The name is an (ideally short) identifier that better helps the user identify and understand the purpose of an accessible object. The name is often presented when screen focus moves to the object (more on this later), can be used as an identifier when presenting a list of available objects, and can be used as a hook for functionalities such as voice commands. , if specified. We’ll use “Description” as a shorthand. The Description can be considered supplemental to the Name; it’s not the main identifier but can provide further information about the accessible object. Sometimes this is presented when moving focus to the accessible object, sometimes not; this variation depends on both the screen reader’s user experience design and the user’s chosen verbosity settings.  For simplicity’s sake, we won’t go through all of these. For your awareness, properties can include details like layout information or available interactions (such as invoking the element or modifying its value). Let’s walk through an example using markup for a simple mood tracker. We’ll use simplified property names and values, because these can differ between accessibility APIs. First up is our   element. This form doesn’t have any attributes that would give it an accessible Name, and a form landmark without a Name isn’t very useful when jumping between landmarks. Therefore,   specify that it should be mapped as a group. Here’s the beginning of our tree:  Group Next up is the  . This one doesn’t have an accessible Name either, so we’ll just nest it as an object of role “Label” underneath the form:  Group\n  Label \n Let’s add the range  , which will map into various APIs as a “Slider.” Due to the relationship created by the   attribute on the   and   attribute on the  , this slider will take its Name from the label contents. The   attribute is another id reference and points to a paragraph with some text content, which will be used for the slider’s Description. The slider object’s properties will also store “labelledby” and “describedby” relationships pointing to these other elements. And it will specify the current, minimum, and maximum values of the slider. If one of these range values were not available,  . Our updated tree:  Group\n  Label  Slider \n  On a scale of 1–10, what is your mood today? \n  Some helpful pointers about how to rate your mood. \n  [label object] \n  helperText \n  5 \n  1 \n  10 \n The paragraph will be added as a simple paragraph object (“Text” or “Group” in some APIs):  Group\n  Label  Slider \n  On a scale of 1–10, what is your mood today? \n  Some helpful pointers about how to rate your mood. \n  [label object] \n  helperText \n  5 \n  1 \n  10  Paragraph \n The final element is an example of when role semantics are added via the ARIA   attribute. This   will map as a Button with the name “Log Mood,” as buttons can take their name from their children. This button will also be surfaced as “invokable” to screen readers and other ATs; special types of buttons could provide expand/collapse functionality (buttons with the   attribute), or toggle functionality (buttons with the   attribute). Here’s our tree now:  Group\n  Label  Slider \n  On a scale of 1–10, what is your mood today? \n  Some helpful pointers about how to rate your mood. \n  [label object] \n  helperText \n  5 \n  1 \n  10  Paragraph  Button \n  Log Mood \n On choosing host language semantics Our sample markup mentions that it is preferred to use the HTML-native   element rather than a   with a   of “button.” Our buttonified   can be operated as a button via accessibility APIs, as the ARIA attribute is doing what it should—conveying semantics. But there’s a lot you can get for free when you choose native elements. In the case of  , that includes focus handling, user input handling, form submission, and basic styling. Aaron Gustafson has what he refers to as an   in particular, but generally speaking it’s great to let the web platform do the heavy lifting of semantics and interaction for us when we can. ARIA roles, states, and properties are still a great tool to have in your toolbelt. Some good use cases for these are providing further semantics and relationships that are not naturally expressed in the host language; supplementing semantics in markup we perhaps don’t have complete control over; patching potential cross-browser inconsistencies; and making custom elements perceivable and operable to users of assistive technologies. Notes on inclusion or exclusion in the tree Standards define some rules around when user agents should exclude elements from the accessibility tree. Excluded elements can include those hidden by CSS, or the   or   attributes; their children would be excluded as well. Children of particular roles (like  ) can also be excluded from the tree, unless they meet special exceptions. The full rules can be found in the  . That being said, there are still some differences between implementers, some of which include more  s and  s in the tree than others do. Notes on name and description computation How names and descriptions are computed can be a bit confusing. Some elements have special rules, and some ARIA roles allow name computation from the element’s contents, whereas others do not. Name and description computation could probably be its own article, so we won’t get into all the details here (refer to “Further reading and resources” for some links). Some short pointers: ,  , and   take precedence over other means of calculating name and description. If you expect a particular HTML attribute to be used for the name, check the  . In your scenario, it may be used for the full description instead. Generated content (  and  ) can participate in the accessible name when said name is taken from the element’s contents. That being said,  , as this content could be lost when a stylesheet fails to load or user styles are applied to the page. When in doubt, reach out to the community! Tag questions on social media with “#accessibility.” “#a11y” is a common shorthand; the “11” stands for “11 middle letters in the word ‘accessibility.’” If you find an inconsistency in a particular browser, file a bug! Bug tracker links are provided in “Further reading and resources.” Not just accessible objects Besides a hierarchical structure of objects, accessibility APIs also offer interfaces that allow ATs to interact with text. ATs can retrieve content text ranges, text selections, and a variety of text attributes that they can build experiences on top of. For example, if someone writes an email and uses color alone to highlight their added comments, the person reading the email could increase the verbosity of speech output in their screen reader to know when they’re encountering phrases with that styling. However, it would be better for the email author to include very brief text labels in this scenario. The big takeaway here for web developers is to keep in mind that the accessible name of an element may not always be surfaced in every   in every screen reader. So if your   text isn’t being read out in a particular mode, the screen reader may be primarily using text interfaces and only conditionally stopping on objects. It may be worth your while to consider using text content—even if  —instead of text via an ARIA attribute.  Accessibility API events It is the responsibility of browsers to surface changes to content, structure, and user input. Browsers do this by sending the accessibility API notifications about various events, which screen readers can subscribe to; again, for performance reasons, browsers could choose to send notifications only when ATs are active. Let’s suppose that a screen reader wants to surface changes to a live region (an element with   or  ): ATs aren’t required to do anything with the information they retrieve. This can make it a bit trickier as a web developer to figure out why a screen reader isn’t announcing a change: it may be that notifications aren’t being raised (for example, because a browser is not sending notifications for a live region dynamically inserted into web content), or the AT is not subscribed or responding to that type of event. Testing with screen readers and dev tools While conformance checkers can help catch some basic accessibility issues, it’s ideal to walk through your content manually using a variety of contexts, such as using a keyboard only; with various OS accessibility settings turned on; and at different zoom levels and text sizes, and so on. As you do this, keep in mind the  , which give general guidelines around expectations for inclusive web content. If you can test with users after your own manual test passes, all the better! Robust accessibility testing could probably be its own series of articles. In this one, we’ll go over some tips for testing with screen readers, and catching accessibility errors as they are mapped into the accessibility API in a more general sense. Screen reader testing Screen readers exist in many forms: some are pre-installed on the operating system and others are separate applications that in some cases are free to download. The   provides a list of commonly used screen reader and browser combinations among survey participants. The “Further reading and resources” section at the end of this article includes full screen reader user docs, and Deque University has a great set of   that you can refer to. Some actions you might take to test your content: Read the next/previous item. Read the next/previous line. Read continuously from a particular point. Jump by headings, landmarks, and links. Tab around focusable elements only. Get a summary of all elements of a particular type within the page. Search the page for specific content. Use table-specific commands to interact with your tables. Jump around by form field; are field instructions discoverable in this navigational mode? Use keyboard commands to interact with all interactive elements. Are your JavaScript-driven interactions still operable with screen readers (which can intercept key input in certain modes)?   includes notes on expected keyboard interactions for various widgets. Try out anything that creates a content change or results in navigating elsewhere. Would it be obvious, via screen reader output, that a change occurred? Tracking down the source of unexpected behavior If a screen reader does not announce something as you’d expect, here are a few different checks you can run:  It may be an issue with the screen reader or your expectation may not match the screen reader’s user experience design. For example, a screen reader may choose to not expose the accessible name of a static, non-interactive element. Checking the user docs or filing a screen reader issue with a simple test case would be a great place to start.  The browser in question may have an issue, there may be compatibility differences between browsers (such as a browser doing extra helpful but non-standard computations), or a screen reader’s support for a specific accessibility API may vary. Filing a browser issue with a simple test case would be a great place to start; if it’s not a browser bug, the developer can route it to the right place or make a code suggestion.  There may be something you can adjust in your code, or your expectations may differ from standards and common practices. Inspecting accessibility trees and properties in dev tools Major modern browsers provide dev tools to help you observe the structure of the accessibility tree as well as a given element’s accessibility properties. By observing which accessible objects are generated for your elements and which properties are exposed on a given element, you may be able to pinpoint issues that are occurring either in front-end code or in how the browser is mapping your content into the accessibility API. Let’s suppose that we are testing this piece of code in Microsoft Edge with a screen reader: We’re navigating the page by form field, and when we land on this text field, the screen reader just tells us this is an “edit” control—it doesn’t mention a name for this element. Let’s check the tools for the element’s accessible name. Reviewing the accessibility tree is an extra step for this particular flow but can be helpful to do. When the Accessibility Tree pane comes up, we notice there’s a tree node that just says “textbox:,” with nothing after the colon. That suggests there’s not a name for this element. (Also notice that the   around our form input didn’t make it into the accessibility tree; it was not semantically useful).  If we scroll down to the Name property—aha! It’s blank. No name is provided to the accessibility API. (Side note: some other accessibility properties are filtered out of this list by default; toggle the filter button—which looks like a funnel—in the pane to get the full list).  We realize that we didn’t associate the   with the text field; that is one strategy for providing an  . We add   to the label: And now the field has a name: In another use case, we have a breadcrumb component, where the current page link is marked with  : When navigating onto the current page link, however, we don’t get any indication that this is the current page. We’re not exactly sure how this maps into accessibility properties, so we can reference a specification like   (Core-AAM). Under the “ ” table, we find mappings for “  with non-  allowed value.” We can check for these listed properties in the Accessibility Properties pane. Microsoft Edge, at the time of writing, maps into UIA (UI Automation), so when we check AriaProperties, we find that yes, “current=page” is included within this property value. Now we know that the value is presented correctly to the accessibility API, but the particular screen reader is not using the information. As a side note, Microsoft Edge’s current dev tools expose these accessibility API properties quite literally. Other browsers’ dev tools may simplify property names and values to make them easier to read, particularly if they support more than one accessibility API. The important bit is to find if there’s a property with roughly the name you expect and whether its value is what you expect. You can also use this method of checking through the property names and values if mapping specs, like Core-AAM, are a bit intimidating! Advanced accessibility tools While browser dev tools can tell us a lot about the accessibility semantics of our markup, they don’t generally include representations of text ranges or event notifications. On Windows, the   includes advanced tools that can help debug these parts of MSAA or UIA mappings:   and   (Accessible Event Watcher). Using these tools presumes knowledge of the Windows accessibility APIs, so if this is too granular for you and you’re stuck on an issue, please reach out to the relevant browser team! There is also an Accessibility Inspector in Xcode on MacOS, with which you can inspect web content in Safari. This tool can be accessed by going to  . Diversity of experience Equipped with an accessibility tree, detailed object information, event notifications, and methods for interacting with accessible objects, screen readers can craft a browsing experience tailored to their audiences. In this article, we’ve used the term “screen readers” as a proxy for a whole host of tools that may use accessibility APIs to provide the best user experience possible. Assistive technologies can use the APIs to augment presentation or support varying types of user input. Examples of other ATs include screen magnifiers, cognitive support tools, speech command programs, and some brilliant new app that hasn’t been dreamed up yet. Further, assistive technologies of the same “type” may differ in how they present information, and users who share the same tool may further adjust settings to their liking. As web developers, we don’t necessarily need to make sure that each instance surfaces information identically, because each user’s preferences will not be exactly the same. Our aim is to ensure that no matter how a user chooses to explore our sites, content is  . By testing with a variety of assistive technologies—including but not limited to screen readers—we can help create a better web for all the many people who use it. Further reading and resources W3C developer guides\n \n W3C specifications: The docs below are known as “AAMs.” They detail how content maps into various accessibility APIs and may be less relevant to web developers’ day-to-day work. However, some have notes on how specific elements’ names and descriptions are meant to be calculated:\n \n \n \n Screen reader user docs (commands)\n \n Browser rendering engine bug trackers\n \n Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/canary-in-a-coal-mine-how-tech-provides-platforms-for-hate/", "title": "Canary in a Coal Mine: How Tech Provides Platforms for Hate", "content": "As I write this, the world is sending its thoughts and prayers to our Muslim cousins. The Christchurch act of terrorism has once again reminded the world that white supremacy’s rise is very real, that its perpetrators are no longer on the fringes of society, but centered in our holiest places of worship. People are begging us to not share videos of the mass murder or the hateful manifesto that the white supremacist terrorist wrote. That’s what he wants: for his proverbial message of hate to be spread to the ends of the earth. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. We live in a time where you can stream a mass murder and hate crime from the  . Children can access these videos, too. As I work through the pure pain, unsurprised, observing the toll on Muslim communities (as a non-Muslim, who matters least in this event), I think of the imperative role that our industry plays in this story. At time of writing, YouTube has failed to ban and to remove this video. If you search for the video (which I strongly advise against), it still comes up with a mere content warning; the same content warning that appears for casually risqué content. You can bypass the warning and watch people get murdered.   for unlivable wages. News outlets are   into their articles and publishing the hateful manifesto. Why? What does this accomplish? I was taught in journalism class that media (photos, video, infographics, etc.) should be additive (a progressive enhancement, if you will) and provide something to the story for the reader that words cannot. Is it necessary to show murder for our dear readers to understand the cruelty and finality of it? Do readers gain something more from watching fellow humans have their lives stolen from them? What psychological damage are we inflicting upon millions of people   and for what? Who benefits? The mass shooter(s) who had a message to accompany their mass murder. News outlets are thirsty for perverse clicks to garner more ad revenue. We, by way of our platforms, give agency and credence to these acts of violence, then pilfer profits from them. Tech is a money-making accomplice to these hate crimes. Christchurch is just one example in an endless array where the  . . The concept of “race realism,” which is essentially a term that white supremacists use to codify their false racist pseudo-science, was actively tested on Facebook’s platform to see how the term would sit with people who are ignorantly sitting on the fringes of white supremacy. Full-blown white supremacists don’t need this soft language. This is how radicalization works. The strategies articulated in the above article are not new. Racist propaganda predates social media platforms. What we have to be mindful with is that we’re building smarter tools with power we don’t yet fully understand: you can now have an  . Our technology is accelerating at a frightening rate, a rate faster than our reflective understanding of its impact. Combine the time-tested methods of spreading white supremacy, the power to manipulate perception through technology, and the magnitude and reach that has become democratized and anonymized. We’re staring at our own reflection in the  . The right to speak versus the right to survive Tech has proven time and time again that it voraciously protects first amendment rights above all else. (I will also take this opportunity to remind you that the first amendment of the United States offers protection to the people from the   abolishing free speech, not from  ). Evelyn Beatrice Hall writes in  , “I disapprove of what you say, but I will defend to the death your right to say it.” Fundamentally, Hall’s quote expresses that we must protect, possibly above all other freedoms, the freedom to say whatever we want to say. (Fun fact: The quote is often misattributed to Voltaire, but Hall actually wrote it to explain Voltaire’s ideologies.) And the logical anchor here is sound: We must grant everyone else the same rights that we would like for ourselves. Former   editor Sean Blanda wrote a thoughtful piece on the “ ,” where he posits that we lack tolerance for people who don’t think like us, but that we must because we might one day be on the other side. I agree in theory. But, what happens when a portion of the rights we grant to one group (let’s say, free speech to white supremacists) means the active oppression another group’s right (let’s say, every person of color’s right to live)? James Baldwin expresses this idea with a clause, “We can disagree and still love each other unless your disagreement is rooted in my oppression and denial of my humanity and right to exist.” It would seem that we have a moral quandary where two sets of rights cannot coexist. Do we protect the privilege for all users to say what they want, or do we protect all users from hate? Because of this perceived moral quandary, tech has often opted out of this conversation altogether. Platforms like Twitter and Facebook, two of the biggest offenders, continue to allow hate speech to ensue with irregular to no regulation.  as a free-speech platform and its consequence to privacy and safety, Twitter CEO Jack Dorsey said, “So we believe that we can only serve the public conversation, we can only stand for freedom of expression if people feel safe to express themselves in the first place. We can only do that if they feel that they are not being silenced.” Dorsey and Twitter are most concerned about protecting   and about not silencing people. In his mind, if he allows people to say whatever they want on his platform, he has succeeded. When asked about why he’s failed to implement AI to filter abuse like, say, Instagram had implemented, he said that he’s most concerned about being able to explain   the AI flagged something as abusive. Again, Dorsey protects the freedom of speech (and thus, the perpetrators of abuse) before the   of abuse. But he’s inconsistent about it. In a  , Twitter’s freedom of speech was not granted to ISIS. Twitter suspended 1,100 accounts related to ISIS whereas it suspended only seven accounts related to Nazis, white nationalism, and white supremacy, despite the accounts having more than seven times the followers, and tweeting 25 times more than the ISIS accounts. Twitter here made a moral judgment that the fewer, less active, and less influential ISIS accounts were somehow not welcome on their platform, whereas the prolific and burgeoning Nazi and white supremacy accounts were. So, Twitter has shown that it won’t protect free speech at   costs or for   users. We can only conclude that Twitter is either intentionally protecting white supremacy or simply doesn’t think it’s very dangerous. Regardless of which it is (I think I know), the outcome does not change the fact that white supremacy is running rampant on its platforms and many others. Let’s brainwash ourselves for a moment and pretend like Twitter does want to support freedom of speech equitably and stays neutral and fair to complete this logical exercise: Going back to the dichotomy of rights example I provided earlier, where either the right to free speech or the right to safety and survival prevail, the rights and the power will fall into the hands of the dominant group or ideologue. In case you are somehow unaware, the dominating ideologue, whether you’re a flagrant white supremacist or not, is white supremacy. White supremacy was baked into  , the country where the majority of these platforms were founded and exist. (I am not suggesting that white supremacy doesn’t exist globally, as it does, evidenced most recently by the terrorist attack in Christchurch. I’m centering the conversation intentionally around the United States as it is my lived experience and where most of these companies operate.) Facebook attempted to educate its team on white supremacy in order to address how to regulate free speech. A laugh-cry excerpt: “White nationalism and calling for an exclusively white state is not a violation for our policy unless it explicitly excludes other PCs [protected characteristics].” White nationalism is a softened synonym for white supremacy so that racists-lite can feel more comfortable with their transition into hate. White nationalism (a.k.a. white supremacy) by definition explicitly seeks to eradicate all people of color. So, Facebook should see white nationalist speech as exclusionary, and therefore a violation of their policies. Regardless of what tech leaders like Dorsey or Facebook CEO Zuckerberg say or what mediocre and uninspired condolences they might offer, inaction is an action. Companies that use terms and conditions or acceptable use policies to defend their inaction around hate speech are enabling and perpetuating white supremacy. Policies are written by humans to protect that group of human’s ideals. The message they use might be that they are protecting free speech, but hate speech is a form of free speech. So effectively, they are protecting hate speech. Well, as long as it’s for white supremacy and not the Islamic State. Whether the motivation is fear (losing loyal Nazi customers and their sympathizers) or hate (because their CEO is a white supremacist), it does not change the impact: Hate speech is tolerated, enabled, and amplified by way of their platforms. “That wasn’t our intent” Product creators might be thinking,  We cannot absolve ourselves of culpability merely because we failed to conceive such evil use cases when we built it. While we very well might not have created these platforms with the explicit intent to help Nazis or imagined it would be used to spread their hate, the reality is that our platforms   being used in this way. As product creators, it is our responsibility to protect the safety of our users by stopping those that intend to or already cause them harm. Better yet, we ought to think of this   we build the platforms to prevent this in the first place. The question to answer isn’t, “Have I made a place where people have the freedom to express themselves?” Instead we have to ask, “Have I made a place where everyone has the safety to exist?” If you have created a place where a dominant group can embroil and embolden hate against another group, you have failed to create a safe place. The foundations of hateful speech (beyond the psychological trauma of it) lead to events like Christchurch. We must protect safety over speech. The Domino Effect This week,  . What is most notable, to me, is that the groups did not break any parts of their Acceptable Use Policy. Slack issued a statement: The use of Slack by hate groups runs counter to everything we believe in at Slack and is not welcome on our platform… Using Slack to encourage or incite hatred and violence against groups or individuals because of who they are is antithetical to our values and the very purpose of Slack. That’s it. It is not illegal for tech companies like Slack to ban groups from using their proprietary software because it is a private company that can regulate users if they do not align with their vision as a company. Think of it as the “no shoes, no socks, no service” model, but for tech. Slack simply decided that supporting the workplace collaboration of Nazis around efficient ways to evangelize white supremacy was probably not in line with their company directives around inclusion. I imagine Slack also considered how their employees of color most ill-affected by white supremacy would feel working for a company that supported it, actively or not. What makes the Slack example so notable is that they acted swiftly and on their own accord. Slack chose the safety of all their users over the speech of some. When caught with their enablement of white supremacy, some companies will only budge under pressure from activist groups, users, and employees.  and after Southern Poverty Law Center (SPLC) explicitly called them out for enabling hate. SPLC had identified this fact for three years prior. PayPal had ignored them for all three years. Unfortunately, taking these “stances” against something as clearly and viscerally wrong as white supremacy is rare for companies to do. The tech industry tolerates this inaction through unspoken agreements. If Facebook doesn’t do anything about racist political propaganda,  , and Twitter doesn’t do  , it says to the smaller players in the industry that they don’t have to either. The tech industry reacts to its peers. When there is disruption, as was the case with Airbnb, who  , companies follow suit.   and Google did the same when they attempted migration. If one company, like Slack or Airbnb, decides to do something about the role it’s going to play, it creates a perverse kind of FOMO for the rest: Fear of missing out of doing the right thing and standing on the right side of history. Don’t have FOMO, do something The type of activism at those companies all started with one individual. If you want to be part of the solution, I’ve gathered some places to start. The list is not exhaustive, and, as with all things, I recommend researching beyond this abridged summary.   If you are not any of those things, then you, as a majority person, need to understand how white supremacy protects you and works in your favor. It’s not easy work, it is uncomfortable and unfamiliar, but you have the most powerful tools to fix tech. The resources are aplenty, but my favorite abridged list: I cannot emphasize this last point enough. What I say today is not new. Versions of this article have been written before. Women of color like me have voiced similar concerns not only in writing, but in design reviews, in closed door meetings to key stakeholders, in Slack DMs. We’ve blown our whistles. But here is the power of white supremacy. White supremacy is so ingrained in every single aspect of how this nation was built, how our corporations function, and who is in control. If you are not convinced of this, you are not paying attention or intentionally ignoring the truth. Queer, Muslim, disabled, trans women and nonbinary folks of color — the marginalized groups most impacted by this — are the ones who are voicing these concerns most voraciously. Speaking up requires us to enter the spotlight and outside of safety—we take a risk and are not heard. The silencing of our voices is one of many effective tools of white supremacy. Our silencing lives within every microaggression, each time we’re talked over, or not invited to partake in key decisions. In tech, I feel I am a canary in a coal mine. I have sung my song to warn the miners of the toxicity. My sensitivity to it is heightened, because of my existence. But the miners look at me and tell me that my lived experience is false. It does not align with their narrative as humans. They don’t understand why I sing. If the people at the highest echelons of the tech industry—the white, male CEOs in power—fail to listen to its most marginalized people—the queer, disabled, trans, people of color—the fate of the canaries will too become the fate of the miners. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/responsible-javascript-part-1/", "title": "Responsible JavaScript: Part I", "content": "By the numbers,  . If the trend persists, the median page will be shipping at least 400 KB of it before too long, and that’s merely what’s  . Like other text-based resources, JavaScript is almost always served compressed—but that might be the only thing we’re getting consistently right in its delivery. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Unfortunately, while reducing resource transfer time is a big part of that whole performance thing, compression has no effect on how long browsers take to process a script once it arrives in its entirety. If a server sends 400 KB of compressed JavaScript, the actual amount browsers have to process after decompression is north of a megabyte. How well devices cope with these heavy workloads depends, well, on the  .   about how adept various devices are at processing lots of JavaScript, but the truth is, the amount of time it takes to process even a trivial amount of it varies greatly between devices. Take, for example, this  , which serves around 23 KB of uncompressed JavaScript. On a mid-2017 MacBook Pro, Chrome chews through this comparably tiny payload in about 25 ms. On a  , however, that figure balloons to around 190 ms. That’s not an insignificant amount of time, but in either case, the page gets interactive reasonably fast. Now for the big question: how do you think that little Nokia 2 does on an average page? It chokes. Even on a fast connection, browsing the web on it is an exercise in patience as JavaScript-laden web pages brick it for considerable stretches of time. While devices and the networks they navigate the web on are largely improving, we’re eating those gains as trends suggest. We need to use JavaScript  . That begins with understanding   we’re building as well as   we’re building it. The mindset of “sites” versus “apps” Nomenclature can be strange in that we sometimes loosely identify things with terms that are inaccurate, yet their meanings are implicitly understood by everyone. Sometimes we overload the term “bee” to also mean “wasp”, even though the differences between bees and wasps are substantial. Those differences can motivate you to deal with each one differently. For instance, we’ll want to destroy a wasp nest, but because bees are highly beneficial and vulnerable insects, we may opt to relocate them. We can be just as fast and loose in interchanging the terms “website” and “web app”. The differences between them are less clear than those between yellowjackets and honeybees, but conflating them can bring about painful outcomes. The pain comes in the affordances we allow ourselves when something is merely a “web ” versus a fully-featured “web app.” If you’re making an informational website for a business, you’re less likely to lean on a powerful framework to manage changes in the DOM or implement client-side routing—at least, I  . Using tools so ill-suited for the task would not only be a detriment to the people who use that site but arguably less productive. When we build a web  , though,  . We’re installing packages which usher in hundreds—if not  —of dependencies,   we’re not sure are even safe. We’re also writing complicated configurations for module bundlers. In this frenzied, yet ubiquitous, sort of dev environment, it takes knowledge and vigilance to ensure what gets built is fast and accessible. If you doubt this, run   in your project’s root directory and  . Even if you do, that doesn’t account for third party scripts—of which I’m sure your site has at least a few. What we tend to forget is that the environment websites and web apps occupy is one and the same. Both are subject to the   that the large gradient of networks and devices impose. Those constraints don’t suddenly vanish when we decide to call what we build “apps”, nor do our users’ phones gain magical new powers when we do so. It’s our responsibility to evaluate who uses what we make, and accept that the conditions under which they access the internet can be different than what we’ve assumed. We need to know the purpose we’re trying to serve, and only   can we build something that admirably serves that purpose— . That means reassessing our reliance on JavaScript and how the use of it—particularly to the exclusion of HTML and CSS—can tempt us to adopt unsustainable patterns which harm performance and accessibility. Don’t let frameworks force you into unsustainable patterns I’ve been witness to some strange discoveries in codebases when working with teams that depend on frameworks to help them be highly productive. One characteristic common among many of them is that poor accessibility and performance patterns often result. Take the React component below, for example: There are some notable accessibility issues here: Knowing these things, we can refactor this component: Not only is this component now more accessible, but it also uses less JavaScript. In a world that’s drowning in JavaScript, deleting lines of it should feel downright therapeutic.  , and we should try to take advantage of that as often as possible. This is not to say that inaccessible patterns occur   when frameworks are used, but rather that a sole preference for JavaScript   eventually surface gaps in our understanding of HTML and CSS. These knowledge gaps will often result in mistakes we may not even be aware of. Frameworks can be useful tools that increase our productivity, but continuing education in core web technologies is essential to creating   experiences, no matter what tools we choose to use. Rely on the web platform and you’ll go far, fast While we’re on the subject of frameworks, it must be said that the web platform is a formidable framework of its own. As the previous section showed, we’re better off when we can rely on established markup patterns and browser features. The alternative is to reinvent them, and invite all the pain such endeavors all but guarantee us, or worse: merely   that the author of every JavaScript package we install has solved the problem comprehensively and thoughtfully. SINGLE PAGE APPLICATIONS One of the tradeoffs developers are quick to make is to adopt the single page application (SPA) model, even if it’s not a fit for the project. Yes, you   gain better perceived performance with the client-side routing of an SPA, but what do you  ? The browser’s own navigation functionality—albeit synchronous—provides a slew of benefits. For one, history is managed according to  . Users without JavaScript—be it by  —won’t lose access altogether. For SPAs to remain available when JavaScript is not, server-side rendering suddenly becomes a thing you have to consider. Accessibility is also harmed if a client-side router fails to let people know what content on the page has changed. This can leave those reliant on assistive technology to suss out what changes have occurred on the page, which can be an arduous task. Then there’s our old nemesis: overhead. Some client-side routers are very small, but when you   with  ,  , and possibly even  , you’re accepting that there’s a certain amount of code you can never optimize away—approximately 135 KB in this case. Carefully consider what you’re building and whether a client side router is worth the tradeoffs you’ll inevitably make. Typically, you’re better off without one. If you’re concerned about the perceived navigation performance, you   lean on   to speculatively fetch documents on the same origin. This has a dramatic effect on improving perceived loading performance of pages, as the document is immediately available in the cache. Because prefetches are done at a low priority, they’re also less likely to contend with critical resources for bandwidth. The primary drawback with link prefetching is that you need to be aware that it   be potentially wasteful.  , a tiny link prefetching script from Google, mitigates this somewhat by checking if the current client is on a slow connection—or has   enabled—and avoids prefetching links on cross-origins by default.  are also hugely beneficial to perceived performance for returning users, whether we use client side routing or not— .  , we get many of the same benefits as link prefetching, but with a much greater degree of control over requests and responses. Whether you think of your site as an “app” or not, adding a service worker to it is perhaps one of the most responsible uses of JavaScript that exists today. JAVASCRIPT ISN’T THE SOLUTION TO YOUR LAYOUT WOES If we’re installing a package to solve a layout problem, proceed with caution and ask “what am I trying to accomplish?” CSS is  , and requires no abstractions to use effectively. Most layout issues JavaScript packages attempt to solve, like  ,  , and even  , are solvable with CSS  . Modern layout engines like Flexbox and Grid are supported well enough that we shouldn’t need to start a project with any layout framework. CSS   the framework. When we have  , progressively enhancing layouts to adopt new layout engines is suddenly  . Using JavaScript solutions for layout and presentations problems is not new. It was something we did when we lied to ourselves in 2009 that every website had to look in IE6 exactly as it did in the more capable browsers of that time. If we’re still developing websites to look the same in every browser in 2019, we should reassess our development goals. There will   be some browser we’ll have to support that can’t do everything those modern, evergreen browsers can. Total visual parity on all platforms is not only a pursuit made in vain, it’s the principal foe of  . I’m not here to kill JavaScript Make no mistake, I have no ill will toward JavaScript. It’s given me a career and—if I’m being honest with myself—a source of enjoyment for over a decade. Like any long-term relationship, I learn more about it the more time I spend with it. It’s a mature, feature-rich language that only gets more capable and elegant with every passing year. Yet, there are times when I feel like JavaScript and I are at odds. I   critical of JavaScript. Or maybe more accurately, I’m critical of how we’ve developed a tendency to view it as a first resort to building for the web. As I pick apart yet another bundle not unlike a tangled ball of Christmas tree lights, it’s become clear that the web is   on JavaScript. We reach for it for almost everything, even when the occasion doesn’t call for it. Sometimes I wonder how vicious the hangover will be. In a series of articles to follow, I’ll be giving more practical advice to follow to stem the encroaching tide of excessive JavaScript and how we can wrangle it so that   we build for the web is usable—or at least   so—for everyone everywhere. Some of the advice will be preventative. Some will be mitigating “hair of the dog” measures. In either case, the outcomes will hopefully be the same. I believe that we all love the web and want to do right by it, but I want us to think about how to make it more resilient and inclusive for all. Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/accessibility-for-vestibular/", "title": "Accessibility for Vestibular Disorders: How My Temporary Disability Changed My Perspective", "content": "Accessibility can be tricky. There are plenty of conditions to take into consideration, and many technical limitations and weird exceptions that make it quite hard to master for most designers and developers. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I never considered myself an accessibility  , but I took great pride in making my projects Web Content Accessibility Guidelines (WCAG) compliant…ish. They would pass most automated tests, show perfectly in the accessibility tree, and work quite well with keyboard navigation. I would even try (and fail) to use a screen reader every now and then. But life would give me a lesson I would probably never learn otherwise: last October, my   life took a drastic change—I started to feel extremely dizzy, with a constant sensation of falling or spinning to the right. I was suffering from a bad case of vertigo caused by labyrinthitis that made it impossible to get   done. Vertigo can have a wide range of causes, the most common being a viral infection or tiny calcium crystal free floating in the inner ear, which is pretty much our body’s accelerometer. Any disruption in there sends the brain confusing signals about the body’s position, which causes really heavy nausea, dizziness, and headaches. If you’ve ever felt seasick, it’s quite a similar vibe. If not, think about that feeling when you just get off a rollercoaster…it’s like that, only  . For most people,  , and it normally goes away in a week or two. Incidence is really high, with some estimates claiming that up to 40% of the population suffers vertigo at least once in their lifetime. Some people live all their lives with it (or with similar symptoms caused by a range of diseases and syndromes grouped under the umbrella term of  ), with 4% of US adults reporting chronic problems with balance, and an additional 1.1% reporting chronic dizziness,  . In my case, it was a little over a month. Here’s what I learned while going through it. Slants can trigger vestibular symptoms It all started as I was out for my daily jog. I felt slightly dizzy, then suddenly my vision got totally distorted. Everything appeared further away, like looking at a fun house’s distortion mirror. I stumbled back home and rested; at that moment I believed I might have over-exercised, and that hydration, food, and rest were all I needed. Time would prove me wrong. What I later learned was that experiencing vertigo is a constant war between one of your inner ears telling the brain “everything is fine, we’re level and still” and the other ear shouting “oh my God, we’re falling, we’re falling!!!” Visual stimuli can act as an intermediary, supporting one ear’s message or the other’s. Vertigo can also work in the opposite way, with the dizziness interfering with your vision. I quickly found that when symptoms peaked, staring at a distant object would ease the falling sensation  . In the same fashion, some visual stimuli would worsen it. Vertical slants were a big offender in that sense. For instance, looking at a subtle vertical slant (the kind that you’d have to look at twice to make sure it’s not perfectly vertical) on a webpage would instantly trigger symptoms for me. Whether it was a page-long slant used to create some interest beside text or a tiny decoration to mark active tabs, looking at anything with slight slants would instantly send me into the rollercoaster. Horizontal slants (whatever the degree) and harder vertical slants wouldn’t cause these issues. My best guess is that slight vertical slants can look like forced perspective and therefore reinforce the falling-from-height sensation, so I would recommend avoiding vertical slants if you can, or make them super obvious. A slight slant looks like perspective, a harder one looks like a triangle. Target size matters (even on mouse-assisted devices) After a magnetic resonance imaging (MRI) scan, some tests to discard neurological conditions, and other treatments that proved ineffective, I was prescribed Cinnarizine. Cinnarizine is a calcium channel blocker—to put it simply, it prevents the malfunctioning inner ear “accelerometer” from sending incorrect info to the brain.  And it worked wonders. After ten days of being barely able to get out of bed, I was finally getting something closer to my normal life. I would still feel dizzy all the time, with some peaks throughout the day, but for the most part, it was much easier. At this point, I was finally able to use the computer (but still unable to produce any code at all). To make the best of it, I set on a mission to self-experiment on accessibility for vestibular disorders. In testing, I found that one of the first things that struck me was that I would always miss targets (links and buttons). I’m from the generation that grew up with desktop computers, so using a mouse is second nature. The pointer is pretty much an extension of my mind, as it is for many who use it regularly. But while Cinnarizine helped with the dizziness, it has a common side effect of negatively impacting coordination and fine motor skills (it is recommended not to drive or operate machinery while under treatment). It was not a surprise when I realized it would be much harder to get the pointer to do what I intended. The common behavior would be: moving the pointer past the link I intended to click, clicking before reaching it at all, or having to try multiple times to click on smaller targets.  of the World Wide Web Consortium (W3C)’s WCAG recommends bigger target sizes so users can activate them easily. The obvious reason for this is that it’s harder to pinpoint targets on smaller screens with coarser inputs (i.e., touchscreens of mobile devices). A fairly common practice for developers is to set bigger target sizes for smaller viewport widths (assuming that control challenges are only touch-related), while neglecting the issue on big screens expected to be used with mouse input. I know I’m guilty of that myself. Instead of targeting this behavior for just smaller screen sizes, there are plenty of reasons to create larger target sizes on   devices: it will benefit users with limited vision (when text is scaled up accordingly and colors are of sufficient contrast), users with mobility impairments such as hand tremors, and of course, users with difficulty with fine motor skills. Font size and spacing Even while “enjoying” the ease of symptoms provided by the treatment, reading   still proved to be a challenge for the following three weeks. I was completely unable to use mobile devices while suffering vertigo due to the smaller font sizes and spacing, so I was forced to use my desktop computer for everything. I can say I was experiencing something similar to users with mild forms of dyslexia or attention disorders: whenever I got to a website that didn’t follow good font styling, I would find myself reading the same line over and over again. This proves once again that accessibility is intersectional: when we improve things for a particular purpose it usually benefits users with other challenges as well. I used to believe recommendations on font styles were mostly intended for the nearsighted and those who have dyslexia. Turns out they are also critical for those with vertigo, and even for those with some cognitive differences. At the end of the day, everybody benefits from better readability. Some actions you can take to improve readability are: Keep line height to at least 1.5 times the font size (i.e.,  ). Set the spacing between paragraphs to at least 2.0 times the font size. We can do this by adjusting the margins using relative units such as  . Letter spacing should be at least 0.12 times the font size. We can adjust this by using the   CSS property, perhaps setting it in a relative unit. Make sure to have good contrast between text and its background. Keep   at a reasonable level for the given  . Some fonts have thin strokes that make them harder to read. When using thinner fonts, try to improve contrast and font size accordingly, even more than what WCAG would suggest. Choose fonts that are easy to read. There has been a large and still inconclusive debate on which font styles are better for users, but one thing I can say for sure is that popular fonts (as in fonts that the user might be already familiar with) are generally the least challenging for users with reading issues.  and fortunately are the most commonly implemented of recommendations, but even they can still fall short sometimes. So, better to follow   and your best judgement.  Another issue on which my experience with vertigo proved to be similar to that of people with dyslexia and attention disorders was how hard it was for me to keep my attention in just one place. In that sense… Animations are bad (and parallax is pure evil) Val Head has already covered   in an outstanding article, so I would recommend giving it a good read if you haven’t already. To summarize, animations can trigger nausea, dizziness, and headaches in some users, so we should use them purposely and responsibly. While most animations did not trigger my symptoms, parallax scrolling did. I’d never been a fan of parallax to begin with, as I found it confusing. And when you’re experiencing vertigo, the issues introduced by parallax scrolling compound. Really, there are no words to describe just how bad a simple parallax effect, scrolljacking, or even   would make me feel. I would rather jump on one of those 20-G centrifuges astronauts use than look at a website with parallax scrolling. Every time I encountered it, I would put the bucket beside me to good use and be forced to lie in bed for   as I felt the room spinning around me, and no meds could get me out of it. It was   bad. Though normal animations did not trigger a reaction as severe, they still posed a big problem. The extreme, conscious, focused effort it took to read would make it such that anything moving on the screen would instantly break my focus, and force me to start the paragraph all over. And I mean  . I would constantly find myself reading a website only to have the typical collapsing navigation bar on scroll distract me just enough that I’d totally lose count of where I was at. Autoplaying carousels were   annoying I would delete them using dev tools as soon as they showed up. Background videos would make me get out of the website desperately. Over time I started using mouse selection as a pointer; a visual indication of what I’d already read so I could get back to it whenever something distracted me. Then I tried custom stylesheets to disable transforms and animations whenever possible, but that also meant many websites having critical elements not appear at all, as they were implemented to start off-screen or otherwise invisible, and show up on scroll. Of course, deleting stuff via dev tools or using custom stylesheets is not something we can expect 99.99% of our users to even know about. So if anything, consider reducing animations to a minimum. Provide users with controls to turn off non-essential animations ( ) and to pause, stop, or hide them ( ). Implement animations and transitions in such a way that if the user disables them, critical elements still display. And be extra careful with parallax: my recommendation is to, at the very least, try limiting its use to the header (“hero”) only, and be mindful of getting a smooth, realistic parallax experience. My vertigo self would have said, “ ” But I guess that might be a hard idea to sell to stakeholders and designers. Also consider learning how to use the   feature query. This is a newer addition to the specs (it’s part of the   , which is at an early Editor’s Draft stage) that allows authors to apply selective styling depending on whether the user has requested the system to minimize the use of animations.  , but the day will come when we will set any moving thing inside a query for when the user has  , blocking animations from those who choose  . After about a week of wrestling websites to provide a static experience, I remembered something that would prove to be my biggest ally while the vertigo lasted: Reader mode Some browsers include a “reader mode” that strips the content from any styling choices, isolates it from any distraction, and provides a perfect WCAG compliant layout for the text to maximize readability. It is extremely helpful to provide a clear and consistent reading experience throughout multiple websites, especially for users with any kind of reading impairment. I have to confess: before experiencing my vestibular disorder, I had never used Reader Mode (the formal name varies in browsers) or even checked if my projects were compatible with it. I didn’t even think it was such a useful feature, as a quick search for “reader mode” actually returned quite a few threads by users asking how to disable it or how to take the button for it out of Firefox’s address bar. (It seems some people are unwittingly activating it…perhaps the icon is not clear enough.) Displaying the button to access Reader Mode is toggled by browser heuristics, which are based on the use (or not) of semantic tags in a page’s HTML. Unfortunately this meant not all websites provided such a “luxury.” I really wish I wouldn’t have to say this in 2019…but please,   use semantic tags. Correct   allow your website to be displayed in Reader Mode, and provide a better experience for users of screen readers. Again, accessibility is intersectional. Reader Mode proved to be extremely useful while my vertigo lasted. But there was something even better: Dark color schemes By the fourth week, I started feeling mostly fine. I opened Visual Studio Code to   to get back to work. In doing so, it served me well to find one more revelation: a light-text-on-dark-background scheme was SO much easier for me to read. (Though I still was not able to return to work at this time.) I was quite surprised, as I had always preferred light mode with dark-text-on-light-background for reading, and dark mode, with light-text-on-dark for coding. I didn’t know at the time that I was suffering from   (which is a sensitivity to light), which was one of the reasons I found it hard to read on my desktop and to use my mobile device at all. As far as I know, photophobia is not a common symptom of  , but there are many conditions that will trigger it, so it’s worth looking into for our projects’ accessibility. CSS is also planning a media query to switch color schemes. Known as  , it allows applying styles based on the user’s stated preference for dark or light theming. It’s also part of the Media Queries Level 5 spec, and at the time of writing this article  , with Mozilla planning to ship it in the upcoming Firefox 67. Luckily there’s a   that allows us to use it in most modern browsers by turning  queries into   queries, which have much better support. If PostCSS is not your cup of tea, or for whatever reason you cannot use that approach to automate switching color schemes to a user’s preference, try at least to provide a theming option in your app’s configuration. Theming has become extremely simple since the release of CSS Custom Properties, so implementing this sort of switch is relatively easy and will greatly benefit anyone experiencing photophobia. Moving on After a month and some days, the vertigo disappeared completely, and I was able to return to work without needing any meds or further treatment. It should stay that way, as for most people it’s a once-in-a-lifetime occurrence. I went back to my   life, but the experience changed my mindset for good. As I said before, I always cared for making my projects compatible for people using keyboard navigation and screen readers. But I learned the hard way that there are plenty of “invisible conditions” that are just as important to take into consideration: vestibular disorders,  , dyslexia, and color blindness, just to name a few. I was totally neglecting those most of the time, barely addressing the issues in order to pass automated tests, which means I was unintentionally annoying some users by making websites inaccessible to them. After my experience with vertigo, I’ve turned to an  . Now I ask myself, “am I leaving anyone behind with this decision?,” before dropping a single line of code. Accessibility should never be an afterthought. Making sure my projects work from the start for those with difficulties also improves the experience for everyone else. Think about how improving text styles for users with dyslexia, vertigo, or visual problems improves readability for all users, or how being able to control animations or choose a color scheme can be critical for users with attention disorders and photophobia, respectively, while also a nice feature for everybody. It also turned my workflow into a much smoother development experience, as addressing accessibility issues from the beginning can mean a slower start, but it’s also much easier and faster than trying to fix broken accessibility afterwards. I hope that by sharing my personal experience with vertigo, I’ve illustrated how we can all design and develop a better web for everybody. Remember,  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/nothing-fails-like-success/", "title": "Nothing Fails Like Success", "content": "A family buys a house they can’t afford. They can’t make their monthly mortgage payments, so they borrow money from the Mob. Now they’re in debt to the bank and the Mob, live in fear of losing their home, and must do whatever their creditors tell them to do. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Welcome to the internet, 2019. Buying something you can’t afford, and borrowing from organizations that don’t have your (or your customers’) best interest at heart, is the business plan of most internet startups. It’s why our digital services and social networks in 2019 are a   of  ,  ,  ,  ,  ,  ,  ,  , and whole new categories of unpunished ethical breaches and crimes.  From optimistically conceived origins and message statements about making the world a better place, too many websites and startups have become  , especially for marginalized and at-risk groups. Why (almost) everything sucks Twitter, for instance, needs a lot of views for advertising to pay at the massive scale its investors demand. A lot of views means you can’t be too picky about what people share. If it’s misogynists or racists inspiring others who share their heinous beliefs to bring back the 1930s, hey, it’s measurable. If a powerful elected official’s out-of-control tweeting reduces churn and increases views, not only can you pay your investors, you can even take home a bonus. Maybe it can pay for that next meditation retreat. You can cloak this basic economic trade-off in fifty layers of bullshit—say you believe in freedom of speech, or that the antidote to bad speech is more speech—but the fact is, hate speech is profitable. It’s killing our society and our planet, but it’s profitable. And the remaining makers of Twitter—the ones whose consciences didn’t send them packing years ago—no longer have a choice. The guy from the Mob is on his way over, and the   is due. Not to single out Twitter, but this is clearly the root cause of its seeming indifference to the destruction hate speech is doing to society…and will ultimately do to the platform. (But by then Jack will be able to afford to   full-time.) Other companies do other evil things to pay their vig. When you owe the Mob, you have no choice. Like sell our data. Or lie about medical research. There   internet companies (like  , or like  , makers of  , where I work) that charge money for their products and services, and use that money to grow their business. I wish more internet companies could follow that model, but it’s hard to retrofit a legitimate business model to a product that started its life as free.  And there are even some high-end news publications, such as  ,    , and  , that survive on a combination of advertising and flexible paywalls. But these options are not available to most digital publications and businesses. Return with me to those   days… Websites and internet startups used to be you and your friends making cool stuff for your other friends, and maybe building new friendships and even small communities in the process. (Even in 2019, that’s still how   websites and startups begin—as labors of love, fashioned by idealists in their spare time.)  Because they are labors of love; because we’ve spent 25 years training people to believe that  ; because, when we begin a project, we can scarcely believe anyone will ever notice or care about it—for these reasons and more, the things we make digitally, especially on the web, are offered free of charge. We labor on, excited by positive feedback, and delighted to discover that, if we keep at it, our little community will grow. Most such labors of love disappear after a year or two, as the creators drift out of touch with each other, get “real” jobs, fall in love, start families, or simply lose interest due to lack of attention from the public or the frustrations of spending weekends and holidays grinding away at an underappreciated site or app while their non-internet friends spend those same hours either having fun or earning money. Along came money But   of these startup projects catch on. And when they do, a certain class of investor smells ROI. And the naive cofounders, who never expected their product or service to really get anywhere, can suddenly envision themselves rich and Zuckerberg-famous. Or maybe they like the idea of quitting their day job, believing in themselves, and  . After all, that is an empowering and righteous vision.  Maybe they believe that by taking the initial investment, they can do more good—that their product, if developed further, can actually help people. This is often the motivation behind agreeing to an initial investment deal, especially in categories like healthcare. Or maybe the founders are problem solvers. Existing products or services in a given category have a big weakness. The problem solvers are sure that their idea is better. With enough capital, and a slightly bigger team, they can show the world how to do it right. Most inventions that have moved humankind forward followed exactly this path. It should lead to a better world (and it sometimes does). It shouldn’t produce privacy breaches and fake medicine and election-influencing bots and all the other plagues of our emerging digital civilization. So why does it? Content wants to be paid Primarily it is because these businesses have no business model. They were made and given away free. Now investors come along who can pay the founders, buy them an office, give them the money to staff up, and even help with PR and advertising to help them grow faster. Now there are salaries and insurance and taxes and office space and travel and lecture tours and sales booths at SXSW, but there is still no charge for the product. And the investor seeks a big return. And when the initial investment is no longer enough to get the free-product company to scale to the big leagues, that’s when the really big investors come in with the really big bucks. And the company is suddenly famous overnight, and “everybody” is using the product, and it’s still free, and the investors are still expecting a giant payday. Like I said—a house you can’t afford, so you go into debt to the bank and the Mob. The money trap Here it would be easy to blame capitalism, or at least untrammeled, under-regulated capitalism, which has often been a source of human suffering—not that capitalism, properly regulated, can’t also be a force for innovation which   suffering. That’s the dilemma for our society, and where you come down on free markets versus governmental regulation of businesses should be an intellectual decision, but these days it is a label, and we hate our neighbors for coming down a few degrees to the left or right of us. But I digress and oversimplify, and this isn’t a complaint about late stage capitalism per se, although it may smell like one. No, the reason small companies created by idealists too frequently turn into consumer-defrauding forces for evil has to do with the amount of profit each new phase of investor expects to receive, and how quickly they expect to receive it, and the fact that the products and services are still free. And . Nothing fails like success A friend who’s a serial entrepreneur has started maybe a dozen internet businesses over the span of his career. They’ve all met a need in the marketplace. As a consequence, they’ve all found customers, and they’ve all made a profit. Yet his investors are rarely happy.  “Most of my startups have the decency to fail in the first year,” one investor told him. My friend’s business was taking in several million dollars a year and was slowly growing in staff and customers. It was profitable. Just not obscenely so.  And internet investors don’t want a modest return on their investment. They want an obscene profit right away, or a brutal loss, which they can write off their taxes. Making them a hundred million for the ten million they lent you is good. Losing their ten million is also good—they pay a lower tax bill that way, or they use the loss to fold a company, or they make a profit on the furniture while writing off the business as a loss…whatever rich people can legally do under our tax system, which is quite a lot.  What these folks don’t want is to lend you ten million dollars and get twelve million back. You and I might go, “Wow! I just made two million dollars just for being privileged enough to have money to lend somebody else.” And that’s why you and I will never have ten million dollars to lend anybody. Because we would be grateful for it. And we would see a free two million dollars as a life-changing gift from God. But investors don’t think this way. We didn’t start the fire, but we roasted our weenies in it As much as we pretend to be a religious nation, our society worships these investors and their profits, worships companies that turn these profits, worships above all the myth of overnight success, which we use to motivate the hundreds of thousands of workers who will work nights and weekends for the owners in hopes of cashing in when the stock goes big.  Most times, even if the stock does go big, the owner has found a way to devalue it by the time it does. Owners have brilliant advisers they pay to figure out how to do those things. You and I don’t. A Christmas memory I remember visiting San Francisco years ago and scoring an invitation to Twitter’s Christmas party through a friend who worked there at the time. Twitter was, at the time, an app that worked via SMS and also via a website. Period. Some third-party companies, starting with my friends at  , had built iPhone apps for people who wanted to navigate Twitter via their newfangled iPhones instead of the web. Twitter itself hadn’t publicly addressed mobile and might not even have been thinking about it. Although Twitter was transitioning from a fun cult thing—used by bloggers who attended   in 2007—to an emerging cultural phenomenon, it was still quite basic in its interface and limited in its abilities. Which was not a bad thing. There is art in constraint, value in doing one thing well. As an outsider, if I’d thought about it, I would have guessed that Twitter’s entire team consisted of no more than 10 or 12 wild-eyed, sleep-deprived true believers.  Imagine my surprise, then, when I showed up at the Christmas party and discovered I’d be sharing dinner with hundreds of designers, developers, salespeople, and executives instead of the handful I’d naively anticipated meeting. (By now, of course, Twitter employs many thousands. It’s still not clear to an outsider why so many workers are needed.) But one thing is clear: somebody has to pay for it all. Freemium isn’t free Employees, let alone thousands of them, on inflated Silicon Valley engineer salaries, aren’t free. Health insurance and parking and meals and HR and travel and expense accounts and meetups and software and hardware and office space and amenities aren’t free. Paying for all that while striving to repay investors tenfold means making a buck any way you can.  Since the product was born free and a paywall isn’t feasible, Twitter must rely on that old standby: advertising. Advertising may not generate enough revenue to keep your hometown newspaper (or most podcasts and content sites) in business, but at Twitter’s scale, it pays.  It pays because Twitter has so many active users. And what keeps those users coming back? Too often, it’s the dopamine of relentless tribalism—folks whose political beliefs match and reinforce mine in a constant unwinnable war of words with folks whose beliefs differ. Of course, half the antagonists in a given brawl may be bots, paid for in secret by an organization that wants to make it appear that most citizens are against Net Neutrality, or that most Americans oppose even the most basic gun laws, or that our elected officials work for lizard people. The whole system is broken and dangerous, but it’s also addictive, and we can’t look away. From our naive belief that content wants to be free, and our inability to create businesses that pay for themselves, we are turning our era’s greatest inventions into engines of doom and despair. Your turn So here we are. Now what do we do about it?  It’s too late for current internet businesses (victims of their own success) that are mortgaged to the hilt in investor gelt. But could the next generation of internet startups learn from older, stable companies like Basecamp, and design products that pay for themselves via customer income—products that profit slowly and sustainably, allowing them to scale up in a similarly slow, sustainable fashion? The self-payment model may not work for apps and sites that are designed as modest amusements or communities, but maybe those kinds of startups don’t need to make a buck—maybe they can simply be labors of love, like the websites we loved in the 1990s and early 2000s. Along those same lines, can the  , and products of IndieWeb thinking like  , save us? Might they at least provide an alternative to the toxic aspects of our current social web, and restore the ownership of our data and content? And before you answer,  . On an individual and small collective basis, the IndieWeb already works. But does an IndieWeb approach scale to the general public? If it doesn’t scale  , can we, who envision and design and build, create a new generation of tools that will help give birth to a flourishing, independent web? One that is as accessible to ordinary internet users as Twitter and Facebook and Instagram?   thinks so, and he’s been right about the web for nearly 30 years. (For more about what Tantek thinks,   in Episode № 186 of The Big Web Show.) Are these approaches mere whistling against a hurricane? Are most web and internet users content with how things are? What do   think? Share your thoughts on your personal website (dust yours off!) or (irony ahoy!) on your indie or mainstream social networks of choice using hashtag  . I can’t wait to see what you have to say. Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/everyday-information-architecture-excerpt/", "title": "Everyday Information Architecture: Auditing for Structure", "content": "Just as we need to\nunderstand our content before we can recategorize it, we need to understand the\nsystem before we try to rebuild it.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Enter the structural audit: a review of the site focused solely on its menus, links, flows, and hierarchies. I know you thought we were done with audits back in Chapter 2, but hear me out! Structural audits have an important and singular purpose: to help us build a new sitemap. This isn’t about recreating the   sitemap—no, this is about experiencing the site the way users experience it. This audit is meant to track and record the structure of the site as it   works. Setting up the template First, we’re gonna need another spreadsheet. (Look, it is not   fault that spreadsheets are the perfect system for recording audit data. I don’t make the rules.) Because this involves building a spreadsheet from scratch, I keep a “template” at the top of my audit files—rows that I can copy and paste into each new audit (Fig 4.1). It’s a color-coded outline key that helps me track my page hierarchy   my place in the auditing process. When auditing thousands of pages, it’s easy to get dizzyingly lost, particularly when coming back into the sheet after a break; the key helps me stay oriented, no matter how deep the rabbit hole. Color-coding Color is the easiest, quickest way to convey page depth at a\nglance. The repetition of black text, white cells, and gray lines can have a\nnumbing effect—too many rows of sameness, and your eyes glaze over. My coloring\nmay result in a spreadsheet that looks like a twee box of macarons, but at\nleast I know, instantly, where I am. The exact colors don’t really matter, but I find that the\nfamiliar mental model of a rainbow helps with recognition—the cooler the row color,\nthe deeper into the site I know I must be.  The nested rainbow of pages is great when you’re auditing neatly nested pages—but most websites color outside the lines (pun   intended) with their structure. I leave my orderly rainbow behind to capture duplicate pages, circular links, external navigation, and other inconsistencies like:  A bright text color denotes pages that are accessible via links within page content—not through the navigation. These pages are critical to site structure but are easily overlooked. Not every page   to be displayed in the navigation menus, of course—news articles are a perfect example—but sometimes this indicates publishing errors.   These are navigation links that go to pages outside the domain. They might be social media pages, or even sites held by the same company—but if the domain isn’t the one I’m auditing, I don’t need to follow it. I  need to note its existence in my spreadsheet, so I color the text as the red flag that it is. (As a  rule, I steer clients away from placing external links in navigation, in order to maintain a consistent experience. If there’s a need to send users offsite, I’ll suggest using a contextual, on-page link.)  This mostly refers to PDFs, but can include Word files, slide decks, or anything else that requires downloading. As with external links, I want to capture anything that might disrupt the in-site browsing experience. (My audits usually filter out PDFs, but for organizations that overuse them, I’ll audit them separately to show how much “website” content is locked inside.)   Every once in a while, there’s a page that doesn’t seem to belong anywhere—maybe it’s missing from the menu, while its URL suggests it belongs in one section and its navigation scheme suggests another. These pages need to be discussed with their owners to determine whether the content needs to be considered in the new site.  These are navigation links for pages that canonically live in a different section of the site—in other words, they’re duplicates. This often happens in footer navigation, which may repeat the main navigation or surface links to deeper-but-important pages (like a Contact page or a privacy policy). I don’t want to record the same information about the page twice, but I do need to know where the crosslink is, so I can track different paths to the content. I color these cells gray so they don’t draw my attention. Note that coloring every row (and indenting, as you’ll see in a moment) can be a tedious process—unless you rely on Excel’s formatting brush. That tool applies all the right styles in just two quick clicks.  Outlines and page IDs Color-coding is half of my template; the other half is the outline, which is how I keep track of the structure itself. (No big deal, just  .) Every page in the site gets assigned an ID.   are assigning this number; it doesn’t correspond to anything but your own perception of the navigation. This number does three things for you:  Let me be completely honest: things might get goofy sometimes\nwith the decimal outline. There will come a day when you’ll find yourself\ncasually typing out “1.2.1.2.1.1.1,” and at that moment, a fellow auditor somewhere\nin the universe will ring a tiny gong for you. In addition to the IDs, I indent each level, which reinforces\nboth the numbers and the colors. Each level down—each digit in the ID, each\nchange in color—gets one indentation. I identify top-level pages with a single number: 1.0, 2.0, 3.0, etc. The next page level in the first section would be 1.1, 1.2, 1.3, and so on. I mark the homepage as 0.0, which is mildly controversial—the homepage is technically a level above—but, look: I’ve got a lot of numbers to write, and I don’t need those numbers to tell me they’re under the homepage, so this is my system. Feel free to use the numbering system that work best for you. Criteria and columns So we’ve got some secret codes for tracking hierarchy and depth, but what about other structural criteria? What are our spreadsheet  (Fig 4.2)? In addition to a column for Page ID, here’s what I cover: \nI don’t consistently fill out this column, because I already collected this\ndata back in my automated audit. I include it every twenty entries or so (and\non crosslinks or pages with unknown hierarchy) as another way of tracking\nprogress, and as a direct link into the site itself.   I include this column only if I notice a lot of\nmismatches between links, labels, and page names. Perfect agreement isn’t\nrequired; but frequent, significant differences between the language that  \nto a page and the language   may indicate\ninconsistencies in editorial approach or backend structures.  Think of this as “what does the page owner call it?” It may be\nthe H1, or an H2; it may match the link that brought you here, or the page\ntitle in the browser, or it may not.   This is for the name of the page in the metadata. Again,\nI don’t use this in every audit—particularly if the site uses the same long,\nbranded metadata title for every single page—but frequent mismatches can be\nuseful to track. \nWhile the template can indicate your level, it can’t tell you which area of the\nsite you’re in—unless you write it down. (This may differ from the section data\nyou applied to your automated audit, taken from the URL structure; here, you’re\nnoting the section where the page appears.) \nFinally, I keep a column to note specific challenges, and to track patterns I’m\nseeing across multiple pages—things like “Different template, missing subnav”\nor “Only visible from previous page.” My only caution here is that if you’re planning\nto share this audit with another person, make sure your notes are— —professional.\nUnless you enjoy anxiously combing through hundreds of entries to revise comments\nlike “Wow haha nope” (not that I would know anything about that). Depending on your project needs, there may be other columns, too.\nIf, in addition to using this spreadsheet for your new sitemap, you want to use\nit in migration planning or template mapping, you may want columns for new\nURLs, or template types.   You can get your own copy of my template as  . Feel free to tweak it to suit your style and needs; I know I always do. As long as your spreadsheet helps you understand the hierarchy and structure of your website, you’re good to go. Gathering data  Setting up the template is one thing—actually filling it out is, admittedly, another. So how do we go from a shiny, new, naive spreadsheet to a complete, jaded, seen-some-  spreadsheet? I always liked Erin Kissane’s description of the process, from  :  Big inventories involve a lot of black coffee, a few late nights, and a playlist of questionable but cheering music prominently featuring the soundtrack of object-collecting video game Katamari Damacy. It takes quite a while to exhaustively inventory a large site, but it’s the only way to really understand what you have to work with. We’re not talking about the same kind of exhaustive inventory she\nwas describing (though I   recommending Katamari music). But even our\nless intensive approach is going to require your butt in a seat, your eyes on a\nscreen, and a certain amount of patience and focus. You’re about to walk, with\nyour fingers, through most of a website. Start on the homepage. (We know that not all users start there,\nbut we’ve got to have some kind of order to this process or we’ll never get\nthrough it.) Explore the main navigation before moving on to secondary\nnavigation structures. Move left to right, top to bottom (assuming that is your\nlanguage direction) over each page, looking for the links. You want to record\nevery page you can reasonably access on the site, noting navigational and\nstructural considerations as you go.  My advice as you work:  I struggle immensely without two screens in this process, which involves constantly switching between spreadsheet and browser in rapid, tennis-match-like succession. If you don’t have access to multiple monitors, find whatever way is easiest for you to quickly flip between applications.  I generally note all visible menu links at the same level, then exhaust one section at a time. Sometimes this means I have to adjust what I initially observed, or backtrack to pages I missed earlier. You might prefer to record all data across a level before going deeper, and that would work, too. Just be consistent to minimize missed links.  On-page links, external links, and crosslinks can tell you a lot about the structure of the site, but they’re easy to overlook. Missed on-page links mean missed content; missed crosslinks mean duplicate work. (Note: the further you get into the site, the more you’ll start seeing crosslinks, given all the pages you’ve already recorded.)   A single file that’s not part of a larger pattern of file use is not going to change your understanding of the structure. Neither is recording every single blog post, quarterly newsletter, or news story in the archive. For content that’s dynamic, repeatable, and plentiful, I use an   in the page ID to denote more of the same. For example, a news archive with a page ID of 2.8 might show just one entry beneath it as 2.8.x; I don’t need to record every page up to 2.8.791 to understand that there are 791 articles on the site (assuming I noted that fact in an earlier content review).  . Save  . I cannot even begin to speak of the unfathomable heartbreak that is Microsoft Excel burning an unsaved audit to the ground.   Knowing which links to follow, which to record, and how best to\nuntangle structural confusion—that improves with time and experience. Performing\nstructural audits will not only teach you about your current site, but will\nhelp you develop fluency in systems thinking—a boon when it comes time to\ndocument the new site. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-for-cognitive-differences/", "title": "Designing for Cognitive Differences", "content": " is designing to be inclusive of as many users as possible, considering all aspects of diversity in users. With increased understanding, compassionate discussions around how to design for disabilities are becoming increasingly common in the web industry. But even with this growth, there are misconceptions: accessibility is still frequently thought of as “design for blind people” when it’s so much more than that. Users with limited motor functions and those who are hearing-impaired require separate considerations, for instance. But accessibility and inclusiveness also mean considering more than just physical symptoms. What about users with cognitive differences like inattention, anxiety, and depression? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Many affective and anxiety disorders qualify as disabilities, with inattention causing challenges on the web as well. Whatever the cause, inattention, anxiety, and depression can have a major impact on internet usage for users dealing with them. The unique issues presented by cognitive differences and the design considerations they require can be tricky to understand for people who have never dealt with them. Through this article, I’ll share some methods to accommodate these users’ unique needs. Inattention Inattention is often regarded as a joke in our industry (and just about everywhere else), but it can be a serious impediment for people who struggle with it. While Attention Deficit Hyperactivity Disorder (ADHD) is a common culprit,  , it’s not the only source of inattention. Bipolar disorder ( ), major depression ( ), and anxiety disorders ( ) can cause occasional inattention. More common conditions such as stress or sleep deprivation can cause inattention in people who don’t experience it as regularly. I’m quite familiar with inattention because I have  , which frequently causes inattention in manic phases. The term   is a bit of a misnomer, because it implies that those suffering from it have trouble paying attention to anything. It’s more accurate to say that we have to pay attention to everything—we have trouble tuning things out, and the more things that are competing for our attention, the harder it is for us to focus on anything. Designers who are able to focus normally rarely see the things that cause problems for users with inattention, but these things are everywhere, and they can make the web much harder for us to use. Some design considerations we can make to be more inclusive of users with inattention include adding an option to mute notifications at certain times, which is a more obvious solution while others are less so, such as giving users the ability to turn off design features that are distracting them. Drowning in the ocean of motion I was recently reading an article on search engine optimization, and the author saw fit to incorporate animated GIFs throughout the article. The GIFs, looped infinitely and placed prominently, didn’t add anything of substance. Worse, as I was already struggling through a manic episode, the GIFs actually prevented me from reading the article—I had to open Chrome DevTools and hide all of the GIFs to get through the content. Motion is everywhere. This simple fact of the modern internet makes designers smile, while users with inattention issues cringe.   Most users struggling with inattention won’t use Chrome DevTools to make your site usable for them, they’ll simply leave and probably end up on a competitor’s site. I cringe anytime I see an article with pointless animation, and often just click the back button. Even though I’m sure the designer or author saw the motion as beneficial, it can distract users who struggle with inattention from what they came to your site to do. Motion isn’t always bad. Sometimes you need to use subtle motion to draw attention to something, such as when a user has to click a button before changes are applied. User-initiated motions, such as hover and click effects, usually don’t distract. Your website or app doesn’t need to be a static, motionless wasteland. But if you’re going to distract your users with motion that they don’t initiate, it had better accomplish something. Unnecessary motion, like the animated GIFs I mentioned above, are nothing but a barrier for these users. If the motion is actually accomplishing something, you have to ask if what you’re drawing attention to is worth sacrificing other content on the page in return. Designers and content developers tend to use motion—autoplayed videos, animated GIFs, and CSS animations—simply to be cute or expressive. Inclusive design would use motion only to improve clarity so as not to exclude users struggling with inattention. If motion would significantly improve the experience for neurotypical users, but hurt it for users with inattention, you can give users the option to turn off motion, allowing them to choose which would be best for them. Designing forms for inattention Forms add layers of interactivity and are often at the center of what we want users to do on our websites or apps; and yet, forms are often hard to use for users who struggle with inattention. Poor design reduces clarity and increases errors; some interactions take so long that they become extremely difficult for those of us with inattention. Rather than slapping on a quick fix or letting ease of implementation define the user experience, we need to fix design issues to be more inclusive of these users. In my twelve years in the industry, there’s a phrase I hear way too often: “Why can’t the users just follow the directions?” This doesn’t show a problem with the user, but with the site or app. The problem isn’t with the directions—it’s with the design. If users are making mistakes on a form, our first instinct is to add instructions before it. There are two problems here: Most people will not read the instructions. Stats show that of the $13.8 billion of technical gadgets that were returned to the store by consumers in 20o7,  . The rest were because users did not understand how to use the products. Users hate reading instructions. Your form is so complicated that it requires instructions. A better solution would be to fix the design of the form itself so you’re not attempting to solve a design problem with content. If most users are making mistakes on a form, users with inattention will struggle even more. When this happens, figure out exactly where the errors are occurring, and fix the design of the form to target that error. For instance, if you’re receiving the wrong data for a field, it’s a sign that form labels are unclear; if you have inline-only labels, adding regular labels outside of the fields will do more than adding an explanatory note. Taking steps like this will make the process less confusing, reducing the need to have long instructions. If an explanation is needed, add it adjacent to the form field where users are having trouble, not at the top of the form where users will likely ignore it. The best option is to simplify the form so that explanations are not needed. Inattention also makes sustained concentration considerably more difficult, and the longer your form or process is, the harder it will be for users with inattention to complete in one sitting. If it is more than two steps or pages, add the functionality to save progress and come back later to finish it. Please, please, please don’t have your multi-page form time out quickly—if they come back from a break and find that your form has lost their progress, they probably won’t be starting over. Anxiety Anxiety is a fairly common problem for adults. Among adults, 19.1% have an  , but anxiety can also result from other things, like taking certain medications, withdrawal from drugs or alcohol, prolonged stress, or chronic pain. As common as anxiety is, you’d think we’d be better at designing for it than we are. Anxiety has been described as knowing that you turned off the stove, but having to turn your car around to check anyway. Users with anxiety fear that they will do something wrong when interacting with your site or app. To counteract this, provide reassurance that what they’re doing is the right thing, and make the experience forgiving if they do the wrong thing. Reassuring them reduces stress and helps to retain anxious users who are more likely to leave in the middle of a difficult process. Let users think like users Nobody goes to your site not knowing why they’re there. If users go to your site to solve a problem, they need to know where to find the solution. The problem may be common to all users, but users with anxiety will struggle more when they can’t find the answers they need or when the way forward is unclear. One of the biggest culprits of unclear user flow is basing the user experience on your company’s understanding of the problem. Companies have their own   terminology and organizational structures to address these problems  . Users likely won’t understand any of this and shouldn’t require a glossary of industry terms or internal structures in order to use your website or app. Define clear paths for users to solve common problems, and design them to address the user’s concerns; don’t give a list of the types of data you accept or organize things according to how your company receives them. If you have multiple types of users using your site (for instance, parents applying for school as well as school administrators), define clear user paths for each. Remember that many of your users will not always start on the homepage of your site. If the user paths are only clear on the homepage, then they’re not clear. Provide clear wayfinding. Even once anxious users are on the path to their solution, they need to know they’re heading in the right direction. On each step of a process, state not only what step they’re on, but what the end of that path is. Remember, anxious users may have a need to keep checking to make sure they’re in the right spot—don’t make them click the back button to do that. There’s no anxiety like form anxiety With a good chunk of anxiety being caused by the fear that you’re doing something wrong, forms are a huge stressor for anxious users. A lack of clarity on forms really harms usability and accessibility for users with anxiety, sometimes causing them to stop the process altogether. Improving clarity and providing reassurance can go a long way in reducing anxiety in these users. Every form and action should be clearly labeled with a headline that plainly states what the form does. I occasionally struggle with anxiety, and there are times when I have to glance up at the headline to double-check that I’m filling out the right form. Similarly, submit buttons should clearly state what happens when users click them. Submit buttons should have copy like “send message,” “complete purchase,” “continue to the next step,” or “sign up for our newsletter.” One of the worst things you can do with a submit button is have it just say “submit.” There’s a trend for designers to get overly clever with form labels: inline-only labels, labels that only appear when their field has focus, or even labels that start inside their field and then animate elsewhere. I’ve never encountered a situation where I was glad these overly clever solutions were in place. A label exists not only to tell users what information to put in the field, but also to confirm to users who have already filled out the form that their information is in the right place. Inline-only form labels make this impossible and cause undue stress to anxious users. Labels that cover up auto-filled text (common with labels that start inside form fields and then move somewhere else) cause similar problems. Form labels are not a medium for creative expression; they’re a tool for users to know how to use a form. This basic functionality should not be hindered. If you’re asking the user for any personal information, privacy is a huge concern, especially for users suffering from social anxiety who dread getting unexpected phone calls. Include a prominent link to your privacy policy on the form itself so it’s easy to find. Also, if it’s not immediately obvious why a piece of information is needed in your form, like a phone number, add a bit of help text to explain it. (For example, clicking a “Why do we need this?” link displays a “We need your phone number to call you in case of a mix-up with your order” tooltip.) If you don’t have a good reason for asking for a piece of personal information or can’t clearly explain why you need it, get rid of the field. And your job is not done once the user has submitted the form. Confirmation messages can be either a huge relief or a huge source of stress for anxious users. I can’t tell you how many times I’ve submitted a form online and the confirmation message just says, “Your data was submitted.” For users with anxiety, this can start the stress cycle all over again.  Confirmation messages should state: what action was taken (“Thank you for signing up for our newsletter!”); what data was posted (“Your email address, brandon.gregory@myemail.com, has been added to our distribution list.”); and what the user should do if they made a mistake (“If you want to stop receiving our newsletter at any time, you can unsubscribe on your user profile.”). Adding this little bit of reassurance can really help users struggling with anxiety to avoid undue stress. Depression Depression is not something we think about often in design, but it impacts how a lot of people use the web. About 6.7% of adults have  , and 2.8% of adults have bipolar disorder, which involves severe depression at times. Additionally, temporary or even long-term depression can be caused by traumatic events, drug use, or certain medications. The book  , by Sara Wachter-Boettcher and Eric Meyer ( ), reminds us that we can’t just design for happy users. Some of our users will be in crisis: having their order mishandled, desperately needing information that’s not readily available, or just having an exceptionally bad day. For users with depression, any ordinary day has the potential to be an exceptionally bad day or crisis, and minor annoyances in user experience can become overwhelming. Keep it easy Depression is thought of as a psychological condition, but it also has physical side effects. For instance,  —the world really does look gray for users dealing with depression. Fatigue and physical pain are common and can be hard to deal with. Everything is harder with depression. If your site or app is hard to use, many depressed users will simply not use it. A lot of the shortcuts we take in the web industry add up to insurmountable challenges for these users. A great example of this is unnecessary user registrations. Registering for a user account is a lengthy (and, for depressed users, exhausting) process. If it’s not absolutely required for a user task, you’re punishing depressed users (and probably everyone else too). If your site has a checkout process, make sure users can check out as a guest. Forcing a user to register for an account just to look at the content (I’m looking at you, Pinterest) is a great way to make sure depressed users will never look at your content. Long sign-up processes, unforgiving forms, and loss of data can quickly make depressed users give up altogether. Minor annoyances such as these can slide through the design-and-build process for our sites and apps, and impact depressed users much more than neurotypical ones. If content requires significant effort to locate, it will also be ignored by depressed users. Large blocks of endless content, like wall-to-wall tiles, force users to sift through it to find what they’re looking for. Long videos without accompanying text (that is searchable) can similarly be a deterrent. Assuming that users are so in love with your content that they will read or view every bit of it is naïve and creates a significant barrier for depressed users (and can also hinder users with inattention). Chat can be a lifesaver I get severely depressed three to six months out of the year, and talking to people is one of the hardest things I have to do. The effort required to carry on an actual conversation is immense, and it prevents me from doing a lot of things that I would ordinarily be doing. Add to that stress the stress of a botched order or customer service fiasco, and I sometimes get so stressed out, I can’t make phone calls that I need to. In these situations, any place that lets me contact them via chat instead of a phone call gains my eternal gratitude. A great example of this is the National Suicide Prevention Hotline (because if anyone knows how to design for depressed users, it’s this group), who opened their online chat in 2013. By 2015, the chat lines were open 24 hours a day. Chat lines are unfortunately frequently clogged, partly due to the influx of users and partly due to a lack of funding, but the number of chat operators is growing each year. Chat lines attract a different demographic: while the phone line is roughly a 50-50 split between male and female,   (70% of the total were women under 25). The article linked to in the paragraph above revealed some other interesting stats. The National Suicide Prevention Hotline is not the only crisis center that has caught onto this. The National Domestic Violence Hotline launched chat in 2013 and now receives 1,000–1,500 chats a month. The Rape, Abuse & Incest National Network (RAINN) has implemented a chat on their site, and they’ve found that chat users typically go into more depth about their traumatic issues than callers. And, like the National Suicide Prevention Hotline, both of these organizations are looking to scale up their chat services due to how popular they are. Businesses that regularly work with users in crisis have realized that chat is a vital tool for their users and are rapidly expanding their chat services to accommodate. Your business may not exclusively deal with crisis users, but with depression affecting a significant portion of the population, any day can be a crisis day for these users. If you have a phone line but not a chat, consider adding one. If you have a chat line and it’s constantly clogged, consider expanding the service. Disability takes many forms, as should inclusive solutions Far from being just about impaired vision and wheelchairs, disability takes many forms, and accessibility and inclusive design need to take just as many. In our industry, compassionate discussion around physical disabilities has been a huge benefit, and cognitive differences need to be part of the conversation too. Removing unnecessary distractions, reassuring users that they’re doing the right thing, and keeping things easy for users who are struggling are things we can do to accommodate these users and make them feel like you actually want them to use our sites and apps. As one of these users myself, I can say we would really appreciate your efforts. This can be just as important as including alt text for your images. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/server-to-client/", "title": "Server to Client", "content": "Before anything can happen in a browser, it must first know where to go. There are multiple ways to get somewhere: entering a URL in the address bar, clicking (or tapping) on a link on a page or in another app, or clicking on a favorite. No matter the case, these all result in what’s called a navigation. A navigation is the very first step in any web interaction, as it kicks off a chain reaction of events that culminates in a web page being loaded. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Initiating the request Once a URL has been provided to the browser to load, a few things happen under the hood. Check for HSTS First, the browser needs to determine if the URL specifies the HTTP (non-secure) scheme. If it’s an HTTP request, the browser needs to check if the domain is in the   list (HTTP Strict Transport Security). This list is comprised of both a preloaded list and a list of previously visited sites that opted-in to using HSTS; both are stored in the browser. If the requested HTTP host is in the HSTS list, a request is made to the HTTPS version of the URL instead of HTTP. This is why you’ll notice that even if you try to type http://www.bing.com into a modern browser, it will send you to https://www.bing.com instead. Check for service workers Next, the browser needs to determine if a   is available to handle the request—this is especially important in the case that the user is offline and does not have a network connection. Service workers are a relatively new feature in browsers. They enable offline-capable web sites by allowing interception of network requests (including the top-level request) so the requests can be served from a  . A service worker can be registered when a page is visited, a process that records the   to a local database. Determining whether a service worker is installed is as simple as looking up the navigated URL in that database. If a service worker exists for that given URL, it will be allowed to handle responding to the request. In the case that the new Navigation Preload feature is available in the browser, and the site makes use of it, the browser will simultaneously also consult the network for the initial navigation request. This is beneficial because it allows the browser to not block on a potentially slower service worker start up. In a case where there is no service worker to handle the initial request (or if Navigation Preload is being used), the browser moves on to consulting the networking layer. Check the network cache The browser, via the network layer, will check if there’s a fresh response in its cache. This is usually defined by the   header in the response, where setting a   can define how long the cached item is considered fresh, and setting   indicates whether it should be cached at all. And of course, if the browser finds nothing in its network cache, then a network request will be required. If there is a fresh response in the cache, it is returned back for the purposes of loading the page. If there’s a resource found but it’s not fresh, the browser may convert the request to a conditional revalidation request, which contains an   or   header that tells the server what version of the content the browser already has in its cache. The server can either tell the browser that its copy is still fresh by returning an   with no body, or tell the browser that its copy is stale by returning an   response with the new version of the resource.  Check for connection If there’s a previously established connection for the host and port for the request, the connection will be reused rather than establishing a new one. If not, the browser consults the networking layer to understand if it needs to do a   (Domain Name System) lookup. This would involve looking through the local DNS cache (which is stored on your device), and, depending on the freshness of that cache, remote name servers may also be consulted (they can be hosted by Internet Service Providers), which would eventually result in the correct IP address for the browser to connect to. In some cases, the browser may be able to predict which domains will be accessed, and connections to those domains can be primed. The page can hint to the browser which to prime connections to by using   such as   on the link tag. One such scenario where using resource hints is helpful is if a user is on a Bing search results page, and there is an expectation that the first few search results are the most likely to be visited. In this case, priming connections to those domains can help with not having to pay the cost of a DNS lookup and connection setup later on when those links are clicked. Establish connection The browser can now establish a connection with the server so the server knows it will be both sending to and receiving from the client. If we’re using  , we need to perform a TLS handshake to validate the certificate provided by the server. Send the request to the server The first request that will go over this connection is the top-level page request. Typically, this will be an HTML file that gets served from the server back to the client. Handle the response As the data is being streamed over to the client, the response data is analyzed. First, the browser checks the  .   are name-value pairs that are sent as part of the HTTP response. If the headers of the response indicate a redirect (e.g., via the Location header), the browser starts the navigation process all over again and returns to the very first step of checking if an HSTS upgrade is required. If the server response is compressed or chunked, the browser will attempt to decompress and dechunk it. As the response is being read, the browser will also kick off writing it to the network cache in parallel. Next, the browser will attempt to understand the MIME type of the file being sent to the browser, so it can appropriately interpret how to load the file. For instance, an image file will just be loaded as an image, while HTML will be parsed and rendered. If the HTML parser is engaged, the contents of the response are scanned for URLs of likely resources to be downloaded so that the browser can start those downloads ahead of time before the page even begins to render. This will be covered in more detail by the next post in this series. By this point, the requested navigation URL has been entered into the browser history, which makes it available for navigation in the back and forward functionality of the browser. Here’s a flowchart that gives you an overview of what’s been discussed so far, with a bit more detail: As you know, the page will continue to make requests, because there are many sub-resources on the page that are important for the overall experience, including images, JavaScript, and style sheets. Additionally, resources that are referenced within those sub-resources, such as background images (referenced in CSS) or other resources initiated by  ,  , or   calls. Without these, we would just have a plain page without much interactivity. As you’ve seen in both the explanation earlier and the flowchart, each resource that is requested is in part impacted by the browser’s caching policies. Caching As mentioned previously, the browser manages a  , which allows previously downloaded resources to be reused in many cases. This is particularly useful for largely unchanging resources, such as logos and JavaScript from frameworks. It’s important to take advantage of this cache as much as possible, because it can help reduce the number of outgoing network requests by instead reusing the locally available cached resource. In turn, this helps minimize the otherwise laborious and latent-prone operations that are required, improving the page load time.  Of course, the network cache has a quota that impacts both how many items will be stored and how long they’ll be stored for. This doesn’t mean that the website doesn’t get a say in the matter. Cache-Control headers in responses control the browser’s caching logic. In some cases, it’s prudent to tell the browser to not cache an item at all (such as with  ), because it is expected to always be different. In other cases, it makes sense to have the browser cache the item indefinitely via  , because the response for a given URL will never change. In such a case, it makes sense to use different URLs to point to different versions of the same resource rather than making a change to a resource of the same URL since the cached version would always be used. Of course, the network cache is not the only type of cache in the browser. There are programmatic caches that can be leveraged via JavaScript. Specifically, in the example of the service worker given above, an initial resource request for the top-level page can be intercepted by the service worker and can then use a cached item that was defined by the site by one of its programmatic caches. This is useful, because it gives the web site more control over what cached items to use when. These caches are origin-bound, which means that each domain has its own sandboxed set of caches it can control that are isolated from the caches of another domain. Origin model An origin is simply a tuple consisting of the scheme/protocol, the hostname, and the port. For instance, https://www.bing.com:443 has the HTTPS protocol, www.bing.com hostname, and 443 as the port. If any of those are different when compared to another origin, they are considered to be different origins. For instance, https://images.bing.com:443 and http://www.bing.com:80 are different origins. The origin is an important concept for the browser, because it defines how data is sandboxed and secured. In most cases, for security purposes, the browser enforces a  , which means that one origin cannot access the data of another origin—both would need to be the same origin. Specifically, in the caching case presented earlier, neither https://images.bing.com:443 nor http://www.bing.com:80 can see the programmatic cache of the other. If bing.com wanted to load a JavaScript file that is from microsoft.com, it would be making a cross-origin resource request on which the browser would enforce the same-origin policy. To allow this behavior, microsoft.com would need to cooperate with bing.com by specifying CORS ( ) headers that enable bing.com to be able to load the JavaScript file from microsoft.com. It’s good practice to set the correct CORS headers so browsers can appropriately deal with the cross-origin resource requests. Conclusion Now that you know how we go from the server to the client—and all the details in between—stay tuned to learn about the next step in loading a web page: how we go from HTML tags to the DOM. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/from-url-to-interactive/", "title": "From URL to Interactive", "content": "Imagine, if you will, that you’re behind the wheel of a gorgeous 1957 Chevy Bel Air convertible, making your way across the desert on a wide open highway. The sun is setting, so you’ve got the top down, naturally. The breeze caresses your cheek like a warm hand as your nose catches a faint whiff of …  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The car lurches and chokes before losing all power. You coast, ever more slowly, to a stop. There’s steam rising from the hood.  You reach down to pop the hood, and open the door. Getting out, you make your way around to the front of the car. As you release the latch and lift the bonnet, you get blasted in the face with even more steam. You hope it’s just water. Looking around, it’s clear the engine has overheated, but you have no idea what you’re looking at. Back home you’ve got a guy who’s amazing with these old engines, but you fell in love with the luxurious curves, the fins, the plush interior, the allure of the open road. A tumbleweed rolls by. In the distance a buzzard screeches. What’s happening under the hood? Years ago, my colleague Molly Holzschlag used a variant of this story to explain the importance of understanding our tools. When it comes to complex machines like cars, knowing how they work can really get you out of a jam when things go wrong. Fail to understand how they work and you could end up, well, buzzard food. At the time, Molly and I were trying to convince folks that learning HTML, CSS, and JavaScript was more important than learning Dreamweaver. Like many similar tools, Dreamweaver allowed you to focus on the look and feel of a website without needing to burden yourself with knowing how the HTML, CSS, and JavaScript it produced actually worked. This analogy still applies today, though perhaps more so to frameworks than WYSIWYG design tools. If you think about it, our whole industry depends on our faith in a handful of “black boxes” few of us fully understand: browsers. We hand over our HTML, CSS, JavaScript, images, etc., and then cross our fingers and hope they render the experience we have in our heads. But how do browsers do what they do? How do they take our users from a URL to a fully-rendered and interactive page? To get from URL to interactive, we’ve assembled a handful of incredibly knowledgeable authors to act as our guides. This journey will take place in four distinct legs, delivered over the course of a few weeks. Each will provide you with details that will help you do your job better. Leg 1: Server to Client Ali Alabbas understands the ins and outs of networking, and he kicks off this journey with a discussion of how our code gets to the browser in the first place. He discusses how server connections are made, caching, and how Service Workers factor into the request and response process. He also discusses the “origin model” and how to improve performance using HTTP2, Client Hints, and more. Understanding this aspect of how browsers work will undoubtedly help you make your pages download more quickly. Leg 2: tags to DOM In the second installment, Travis Leithead—a former editor of the W3C’s HTML spec—takes us through the process of parsing HTML. He covers how browsers create trees (like the DOM tree) and how those trees become element collections you can access via JavaScript. And speaking of JavaScript, he’ll even get into how the DOM responds to manipulation and to events, including touch and click. Armed with this information, you’ll be able to make smarter decisions about how and when you touch the DOM, how to reduce Time To Interactive (TTI), and how to eliminate unintended reflows. Leg 3: braces to pixels Greg Whitworth has spent much of his career in the weeds of browsers’ CSS mechanics, and he’s here to tell us how they do what they do. He explains how CSS is parsed, how values are computed, and how the cascade actually works. Then he dives into a discussion of layout, painting, and composition. He wraps things up with details concerning how hit testing and input are managed. Understanding how CSS works under the hood is critical to building resilient, performant, and beautiful websites. Leg 4:   to JIT One of JavaScript’s language designers, Kevin Smith, joins us for the final installment in this series to discuss how browsers compile and execute our JavaScript. For instance, what do browsers do when tearing down a page when users navigate away? How do they optimize the JavaScript we write to make it run even faster? He also tackles topics like writing code that works in multiple threads using workers. Understanding the inner processes browsers use to optimize and run your JavaScript can help you write code that is more efficient in terms of both performance and memory consumption. Leg 5: Semantics to Screen Readers Now that our page is generated, we need to understand how screen readers access it. Front-end developer Melanie Richards take us through a step-by-step journey. She covers a wide array of screen readers, which vary greatly and are highly customizable to users. Understanding the nuances of accessibility APIs, thorough testing approaches, and the wealth of resources available, site creators can create the most widely accessible content for the most users possible. Let’s get going I sincerely hope you’ll join us on this trip across the web and into the often foggy valley where browsers turn code into experience. Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/tags-to-dom/", "title": "Tags to DOM", "content": "In our previous segment, “ ,” we saw how a URL is requested from a server and learned all about the many conditions and caches that help optimize delivery of the associated resource. Once the browser engine finally gets the resource, it needs to start turning it into a rendered web page. In this segment, we focus primarily on HTML resources, and how the tags of HTML are transformed into the building blocks for what will eventually be presented on screen. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. To use a construction metaphor, we’ve drafted the blueprints, acquired all the permits, and collected all the raw materials at the construction site; it’s time to start building! Parsing Once content gets from the server to the client through the networking system, its first stop is the HTML parser, which is composed of a few systems working together: encoding, pre-parsing, tokenization, and tree construction. The parser is the part of the construction project metaphor where we walk through all the raw materials: unpacking boxes; unbinding pallets, pipes, wiring, etc.; and pouring the foundation before handing off everything to the experts working on the framing, plumbing, electrical, etc.  Encoding The payload of an HTTP response body can be anything from HTML text to image data. The first job of the parser is to figure out how to interpret the bits just received from the server. Assuming we’re processing an HTML document, the decoder must figure out how the text document was translated into bits in order to reverse the process.  (Remember that ultimately even text must be translated to binary in the computer. Encoding—in this case ASCII encoding—defines that a binary value such as “01000100” means the letter “D,” as shown in the figure above.) Many possible encodings exist for text—it’s the browser’s job to figure out how to properly decode the text. The server should provide hints via   headers, and the leading bits themselves can be analyzed (for a  , or BOM). If the encoding still cannot be determined, the browser can apply its best guess based on heuristics. Sometimes the only definitive answer comes from the (encoded) content itself in the form of a   html tag. Worst case scenario, the browser makes an educated guess and then later finds a contradicting   tag after parsing has started in earnest. In these rare cases, the parser must restart, throwing away the previously decoded content. Browsers sometimes have to deal with old web content (using legacy encodings), and a lot of these systems are in place to support that. When saving your HTML documents for the web today, the choice is clear: use UTF-8 encoding. Why? It nicely supports the full Unicode range of characters, has good compatibility with ASCII for single-byte characters common to languages like CSS, HTML, and JavaScript, and is likely to be the browser’s fallback default. You can tell when encoding goes wrong, because text won’t render properly (you will tend to get garbage characters or boxes where legible text is usually visible). Pre-parsing/scanning Once the encoding is known, the parser starts an initial pre-parsing step to scan the content with the goal of minimizing round-trip latency for additional resources. The pre-parser is not a full parser; for example, it doesn’t understand nesting levels or parent/child relationships in HTML. However, the pre-parser does recognize specific HTML tag names and attributes, as well as URLs. For example, if you have an   somewhere in your HTML content, the pre-parser will notice the   attribute, and queue a resource request for the dog picture via the networking system. The dog image is requested as quickly as possible, minimizing the time you need to wait for it to arrive from the network. The pre-parser may also notice certain explicit requests in the HTML such as   and  , and queue these up for processing as well. Tokenization Tokenization is the first half of parsing HTML. It involves turning the markup into individual tokens such as “begin tag,” “end tag,” “text run,” “comment,” and so forth, which are fed into the next state of the parser. The tokenizer is a state machine that transitions between the different states of the HTML language, such as “in tag open state” ( ), “in attribute name state” ( ), and “after attribute name state” ( ), doing so iteratively as each character in the HTML markup text document is read.  (In each of those example tags, the vertical pipe illustrates the tokenizer’s position.) The   (see “12.2.5 Tokenization”) currently defines   for the tokenizer. The tokenizer and parser are very adaptable: both can handle and convert any text content into an HTML document—even if code in the text is not valid HTML. Resiliency like this is one of the features that has made the web so approachable by developers of all skill levels. However, the drawback of the tokenizer and parser’s resilience is that you may not always get the results you expect, which can lead to some subtle programming bugs. (  can help you avoid bugs like this.) For those who prefer a more black-and-white approach to markup language correctness, browsers have an alternate parsing mechanism built in that treats any failure as a catastrophic failure (meaning any failure will cause the content to not render). This parsing mode uses the  , and can be enabled by sending the document to the browser with the “application/xhtml+xml”   (or   XML-based MIME type that uses elements in the  ).  Browsers may combine the pre-parser and tokenization steps together as an optimization. Parsing/tree construction The browser needs an internal (in-memory) representation of a web page, and, in the  , web standards define exactly what shape that representation should be. The parser’s responsibility is to take the tokens created by the tokenizer in the previous step, and create and insert the objects into the Document Object Model (DOM) in the appropriate way (specifically using the   of its state machine; see “12.2.6.4 The rules for parsing tokens in HTML content”). The DOM is organized into a  , so this process is sometimes referred to as tree construction. (As an aside, Internet Explorer  .) HTML parsing is complicated by the variety of error-handling cases that ensure that legacy HTML content on the web continues to have compatible structure in today’s modern browsers. For example, many HTML tags have implied end tags, meaning that if you don’t provide them, the browser auto-closes the matching tag for you. Consider, for instance, this HTML: The parser has a rule that will create an implied end tag for the paragraph, like so: This ensures the two paragraph objects in the resulting tree are siblings, as opposed to one paragraph object by ignoring the second open tag. HTML tables are perhaps the most complicated where the parser’s rules attempt to ensure that tables have the proper structure. Despite all the complicated parsing rules, once the DOM tree is created, all of the parsing rules that try to create a “correct” HTML structure are no longer enforced. Using JavaScript, a web page can rearrange the DOM tree in almost any way it likes, even if it doesn’t make sense! (For example, adding a table cell as the child of a   tag). The rendering system becomes responsible for figuring out how to deal with any weird inconsistencies like that. Another complicating factor in HTML parsing is that JavaScript can add more content to be parsed while the parser is in the middle of doing its job.   tags contain text that the parser must collect and then send to a scripting engine for evaluation. While the script engine parses and evaluates the script text, the parser waits. If the script evaluation includes invoking the  , a second instance of the HTML parser must start running ( ). To quickly revisit our construction metaphor,   and   require stopping all in-progress work to go back to the store to get some additional materials that we hadn’t realized we needed. While we’re away at the store, all progress on the construction is stalled.  All of these complications make writing a compliant HTML parser a non-trivial undertaking. Events When the parser finishes, it announces its completion via an event called  . Events are the broadcast system built into the browser that JavaScript can listen and respond to. In our construction metaphor, events are the reports that various workers bring to the foreman when they encounter a problem or finish a task. Like  , there are a variety of events that signal significant state changes in the web page such as   (meaning parsing is done, and all the resources requested by the parser, like images, CSS, video, etc., have been downloaded) and   (meaning the web page is about to be closed). Many events are specific to user input, such as the user touching the screen ( ,  , and others), using a mouse ( ,  , and others), or typing on the keyboard ( ,  , and  ). The browser creates an event object in the DOM, packs it full of useful state information (such as the location of the touch on the screen, the key on the keyboard that was pressed, and so on), and “fires” that event. Any JavaScript code that happens to be listening for that event is then run and provided with the event object.  The tree structure of the DOM makes it convenient to “filter” how frequently code responds to an event by allowing events to be listened for at any level in the tree (i.e.., at the root of the tree, in the leaves of the tree, or anywhere in between). The browser first determines where to fire the event in the tree (meaning which DOM object, such as a specific   control), and then calculates a route for the event starting from the root of the tree, then down each branch until it reaches the target (the   for example), and then back along the same path to the root. Each object along the route then has its event listeners triggered, so that listeners at the root of the tree will “see” more events than specific listeners at the leaves of the tree.  Some events can also be canceled, which provides, for example, the ability to stop a form submission if the form isn’t filled out properly. (A   event is fired from a   element, and a JavaScript listener can check the form and optionally cancel the event if fields are empty or invalid.) DOM The HTML language provides a rich feature set that extends far beyond the markup that the parser processes. The parser builds the structure of which elements contain other elements and what state those elements have initially (their attributes). The combination of the structure and state is enough to provide both a basic rendering and some interactivity (such as through built-in controls like  ,  ,  , etc.). But without the addition of CSS and JavaScript, the web would be very boring (and static). The DOM provides an additional layer of functionality both to the elements of HTML and to other objects that are not related to HTML at all. In the construction metaphor, the parser has assembled the final building—all the walls, doors, floors, and ceilings are installed, and the plumbing, electrical, gas, and such, are ready. You can open the doors and windows, and turn the lights on and off, but the structure is otherwise quite plain. CSS provides the interior details—color on the walls and baseboards, for example. (We’ll get to CSS in the next installment.) JavaScript enables access to the DOM—all the furniture and appliances inside, as well as the services outside the building, such as the mailbox, storage shed and tools, solar panels, water well, etc. We describe the “furniture” and outside “services” next. Element interfaces As the parser is constructing objects to put into the tree, it looks up the element’s name (and namespace) and finds a matching HTML interface to wrap around the object.  Interfaces add features to basic HTML elements that are specific to their   or   of element. Some generic features include: access to HTML collections representing all or a subset of the element’s children; the ability to search the element’s attributes, children, and parent elements; and importantly, ways to create new elements (without using the parser), and attach them to (or detach them from) the tree. For specific elements like  , the interface contains additional table-specific features for locating all the rows, columns, and cells within the table, as well as shortcuts for removing and adding rows and cells from and to the table. Likewise,   interfaces have features for drawing lines, shapes, text, and images. JavaScript is required to use these APIs—they are not available using HTML markup alone.  Any DOM changes made to the tree via the APIs described above (such as the hierarchical position of an element in the tree, the element’s state by toggling an attribute name or value, or any of the API actions from an element’s interface) after parsing ends will trigger a chain-reaction of browser systems whose job is to analyze the change and update what you see on the screen as soon as possible. The tree maintains many optimizations for making these repeated updates fast and efficient, such as: representing common element names and attributes via a number (using hash tables for fast identification); collection caches that remember an element’s frequently-visited children (for fast child-element iteration); and sub-tree change-tracking to minimize what parts of the whole tree get “dirty” (and will need to be re-validated). Other APIs The HTML elements and their interfaces in the DOM are the browser’s only mechanism for showing content on the screen. CSS can affect layout, but only for content that exists in HTML elements. Ultimately, if you want to see content on screen, it must be done through HTML interfaces that are part of the tree.” (For those wondering about Scalable Vector Graphics (SVG) and MathML languages—those elements must also be added to the tree to be seen—I’ve skipped them for brevity.) We learned how the parser is one way of getting HTML from the server into the DOM tree, and how element interfaces in the DOM can be used to add, remove, and modify that tree after the fact. Yet, the browser’s programmable DOM is quite vast and not scoped to just HTML element interfaces.  The scope of the browser’s DOM is comparable to the set of features that apps can use in any operating system. Things like (but not limited to): access to storage systems (databases, key/value storage, network cache storage); devices (geolocation, proximity and orientation sensors of various types, USB, MIDI, Bluetooth, Gamepads); the network (HTTP exchanges, bidirectional server sockets, real-time media streaming); graphics (2D and 3D graphics primitives, shaders, virtual and augmented reality); and multithreading (shared and dedicated execution environments with rich message passing capabilities). The capabilities exposed by the DOM continue to grow as new web standards are developed and implemented by major browser engines. Most of these “extra” APIs of the DOM are out of scope for this article, however. Moving on from markup In this segment, you’ve learned how parsing and tree construction create the foundation for the DOM: the stateful, in-memory representation of the HTML tags received from the network. With the DOM model in place, services such as the event model and element APIs enable web developers to change the DOM structure at any time. Each change begins a sequence of “re-building” work of which updating the DOM is only the first step. Going back to the construction analogy, the on-site raw materials have been formed into the structural framing of the building and built to the right dimensions with internal plumbing, electrical, and other services installed, but with no real sense yet of the building’s final look—its exterior and interior design. In the next installment, we’ll cover how the browser takes the DOM tree as input to a layout engine that incorporates CSS and transforms the tree into something you can finally see on the screen. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/var-to-jit/", "title": "var to JIT", "content": "In our previous article we described how the browser uses CSS to render beautiful pixels to the user’s screen. Although modern CSS can (and should!) be used to create highly interactive user experiences, for the last mile of interactivity, we need to dynamically update the HTML document. For that, we’re going to need JavaScript. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Bundle to bytecode For a modern web application, the JavaScript that the browser first sees will typically not be the JavaScript written by a developer. Instead, it will most likely be a bundle produced by a tool such as webpack. And it will probably be a rather large bundle containing a UI framework such as React, various   (libraries that emulate new platform features in older browsers), and an assortment of other packages found on npm. The first challenge for the browser’s JavaScript engine is to convert that big bundle of text into instructions that can be executed on a virtual machine. It needs to parse the code, and because the user is waiting on JavaScript for all that interactivity, it needs to do it fast. At a high level, the JavaScript engine parses code just like any other programming language compiler. First, the stream of input text is broken up into chunks called  . Each token represents a meaningful unit within the syntactic structure of the language, similar to words and punctuation in natural written language. Those tokens are then fed into a   that produces a tree structure representing the program. Language designers and compiler engineers like to call this tree structure an  . The resulting AST can then be analyzed to produce a list of virtual machine instructions called bytecode. The process of generating an AST is one of the more straightforward aspects of a JavaScript engine. Unfortunately, it can also be slow. Remember that big bundle of code we started out with? The JavaScript engine has to parse and build syntax trees for the entire bundle before the user can start interacting with the site. Much of that code may be unnecessary for the initial page load, and some may not even be executed at all! Fortunately, our compiler engineers have invented a variety of tricks to speed things up. First, some engines parse code on a background thread, freeing up the main UI thread for other computations.  Second, modern engines will delay the creation of in-memory syntax trees for as long as possible by using a technique called   or  . It works like this: if the engine sees a function definition that might not be executed for a while, it will perform a fast, “throwaway” parse of the function body. This throwaway parse will find any syntax errors that might be lurking within the code, but it will not generate an AST. Later, when the function is called for the first time, the code will be parsed again. This time, the engine will generate the full AST and bytecode required for execution. In the world of JavaScript, doing things twice can sometimes be faster than doing things once! The best optimizations, though, are the ones that allow us to bypass doing any work at all. In the case of JavaScript compilation, this means skipping the parsing step completely. Some JavaScript engines will attempt to cache the generated bytecode for later reuse in case the user visits the site again. This isn’t quite as simple as it sounds. JavaScript bundles can change frequently as websites are updated, and the browser must carefully weigh the cost of serializing bytecode against the performance improvements that come from caching. Bytecode to runtime Now that we have our bytecode, we’re ready to start execution. In today’s JavaScript engines, the bytecode that we generated during parsing is first fed into a virtual machine called an  . An interpreter is a bit like a CPU implemented in software. It looks at each bytecode instruction, one at a time, and decides what actual machine instructions to execute and what to do next. The structure and behavior of the JavaScript programming language is defined in a document formally known as  . Language designers like to call the structure part “syntax” and the behavior part “semantics.” The semantics of almost every aspect of the language is defined by algorithms that are written using prose-like pseudo-code. For instance, let’s pretend we are compiler engineers implementing the  . Here’s what the  :  :   >>  In the first six steps we convert the operands (the values on either side of the >>) into 32-bit integers, and then we perform the actual shift operation. If you squint, it looks a bit like a recipe. If you   squint, you might see the beginnings of a syntax-directed interpreter. Unfortunately, if we implemented the algorithms exactly as they are described in the specification, we’d end up with a very slow interpreter. Consider the simple operation of getting a property value from a JavaScript object. Objects in JavaScript are conceptually like dictionaries. Each property is keyed by a string name. Objects can also have a  . If an object doesn’t have an entry for a given string key, then we need to look for that key in the prototype. We repeat this operation until we either find the key that we’re looking for or get to the end of the prototype chain. That’s potentially a lot of work to perform every time we want to get a property value out of an object!  The strategy used in JavaScript engines for speeding up dynamic property lookup is called  . Inline caching was first developed for the language   in the 1980s. The basic idea is that the results from previous property lookup operations can be stored directly in the generated bytecode instructions. To see how this works, let’s imagine that the JavaScript engine is a towering gothic cathedral. As we step inside, we notice that the engine is chock full of objects swarming around. Each object has an identifiable shape that determines where its properties are stored. Now, imagine that we are following a series of bytecode instructions written on a scroll. The next instruction tells us to get the value of the property named “x” from some object. You grab that object, turn it over in your hands a few times to figure out where “x” is stored, and find out that it is stored in the object’s second data slot. It occurs to you that any object with this same shape  will have an “x” property in its second data slot.  You pull out your quill and make a note on your bytecode scroll indicating the shape of the object and the location of the “x” property. The next time you see this instruction you’ll simply check the shape of the object. If the shape matches what you’ve recorded in your bytecode notes, you’ll know exactly where the data is located without having to inspect the object. You’ve just implemented what’s known as a  ! But what happens if the shape of the object doesn’t match our bytecode notes? We can get around this problem by drawing a small table with a row for each shape we’ve seen. When we see a new shape, we use our quill to add a new row to the table. We now have a  . It’s not quite as fast as the monomorphic cache, and it takes up a little more space on the scroll, but if there aren’t too many rows, it works quite well. If we end up with a table that’s too big, we’ll want to erase the table, and make a note to remind ourselves to not worry about inline caching for this instruction. In compiler terms, we have a  . In general, monomorphic code is very fast, polymorphic code is almost as fast, and megamorphic code tends to be rather slow. Or, in haiku form: Interpreter to just-in-time (JIT) The great thing about an interpreter is that it can start executing code quickly, and for code that is run only once or twice, this “software CPU” performs acceptably fast. But for “hot code” (functions that are run hundreds, thousands, or millions of times) what we really want is to execute machine instructions directly on the actual hardware. We want  . As JavaScript functions are executed by the interpreter, various statistics are gathered about how often the function has been called and what kinds of arguments it is called with. If the function is run frequently with the same kinds of arguments, the engine may decide to convert the function’s bytecode into machine code. Let’s step once again into our hypothetical JavaScript engine, the gothic cathedral. As the program executes, you dutifully pull bytecode scrolls from carefully labeled shelves. For each function, there is roughly one scroll. As you follow the instructions on each scroll, you record how many times you’ve executed the scroll. You also note the shapes of the objects encountered while carrying out the instructions. You are, in effect, a  . When you open the next scroll of bytecode, you notice that this one is “hot.” You’ve executed it dozens of times, and you think it would run much faster in machine code. Fortunately, there are two rooms full of scribes that are ready to perform the translation for you. The scribes in the first room, a brightly lit open office, can translate bytecode into machine code quite fast. The code that they produce is of good quality and is concise, but it’s not as efficient as it could be. The scribes in the second room, dark and misty with incense, work more carefully and take a bit longer to finish. The code that they produce, however, is highly optimized and about as fast as possible. In compiler-speak, we refer to these different rooms as  . Different engines have different numbers of tiers depending on the tradeoffs they’ve chosen to make. You decide to send the bytecode to the first room of scribes. After working on it for a bit, using your carefully recorded notes, they produce a new scroll containing machine instructions and place it on the correct shelf alongside the original bytecode version. The next time you need to execute the function, you can use this faster set of instructions. The only problem is that the scribes made quite a few assumptions when they translated our scroll. Perhaps they assumed that a variable would always hold an integer. What happens if one of those assumptions is invalidated? In that case we must perform what’s known as a  . We pull the original bytecode scroll from the shelf, and figure out which instruction we should start executing from. The machine code scroll disappears in a puff of smoke and the process starts again. To infinity and beyond Today’s high-performance JavaScript engines have evolved far beyond the relatively simple interpreters that shipped with Netscape Navigator and Internet Explorer in the 1990s. And that evolution continues. New features are incrementally added to the language. Common coding patterns are optimized.   is maturing. A richer standard module library is being developed. As developers, we can expect modern JavaScript engines to deliver fast and efficient execution as long as we keep our bundle sizes in check and try to make sure our performance-critical code is not overly dynamic. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/progressive-web-apps-excerpt/", "title": "Progressive Web Apps: The Case for PWAs", "content": "Now that you know what a progressive web app is, you’re probably wondering if your organization would benefit from one. To determine if it makes sense for your organization, ask yourself two questions: Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. This doesn’t mean that your site needs to have every possible feature of progressive web apps. You may have no need to provide offline functionality, push notifications, or even the ability for people to install your website to their homescreen. You may only want the bare minimum: a secure site, a service worker to speed up the site, and a manifest file—things that benefit every website. Of course, you may decide that your personal website or side project doesn’t warrant the extra effort to make it into a progressive web app. That’s understandable—and in the long run, even personal websites will gain progressive web app features when the underlying content management systems add support for them. For example, both   and   have already announced their plans to bring progressive web apps to their respective platforms. Expect other platforms to follow suit. But if you’re running any kind of website that makes money for your organization, then it would behoove you to start planning for how to convert your website to a progressive web app. Companies that have deployed progressive web apps have seen increases in conversion, user engagement, sales, and advertising revenue. For example,   and user-generated ad revenue increase by 44 percent (Fig 2.1).   and a 9 percent lift in revenue per visit. The success stories for progressive web apps are so abundant that my company, Cloud Four, started a website called   to keep track of them (Fig 2.2). There’s a good chance that we’ve collected a case study from an organization similar to yours that you can use to convince your coworkers that building a progressive web app makes sense. And convincing them may be necessary. Despite the clear benefits of progressive web apps, many businesses still haven’t converted—often because they simply don’t know about PWAs yet. (So if you start building one now, you may get a jump on your competition!) But there is also a lot of confusion about what progressive web apps are capable of, where they can be used, and how they relate to native apps. This confusion creates fear, uncertainty, and doubt (FUD) that slow the adoption of progressive web apps. If you advocate for progressive web apps in your organization, you’ll likely find some confusion and possibly even encounter some resistance. So let’s equip you with arguments to cut through the FUD and convince your colleagues. Native apps and PWAs can coexist If your organization already has a native app, stakeholders may balk at the idea of   having a progressive web app—especially since the main selling point of PWAs is to enable native app features and functionality. It’s tempting to view progressive web apps as competition to native apps—much of the press coverage has adopted this storyline. But the reality is that progressive web apps make sense irrespective of whether a company has a native app. Set aside the “native versus web” debate, and focus on the experience you provide customers who interact with your organization via the web. Progressive web apps simply make sense on their own merits: they can help you reach more customers, secure your site, generate revenue, provide more reliable experiences, and notify users of updates—all as a complement to your native app. Reach more customers Not all of your current customers—and none of your potential customers—have your native app installed. Even your average customer is unlikely to have your app installed, and those customers who   have your app may still visit your site on a desktop computer. Providing a better experience on the website itself will increase the chances that current and future customers will read your content or buy your products (or even download your native app!). A progressive web app can provide that better experience. Despite what the tech press might have you believe, the mobile web is growing faster than native apps. comScore compared the top one thousand apps to the top one thousand mobile web properties and found that “ ”. And while it’s true that people spend more time in their favorite apps than they do on the web, you may have trouble convincing people to install your app in the first place.   in a typical month. Having a native app in an app store doesn’t guarantee that people will install it. It costs a lot to advertise an app and convince people to try it. According to app marketing company Liftoff,  , and that shoots up to $8.21 per install if you want someone to create an account in your app. If you’re lucky enough to get someone to install your app, the next hurdle is convincing them to continue to use it. When analyst Andrew Chen analyzed user retention data from 125 million mobile phones, he found that “  after the install. Within 30 days, it’s lost 90% of DAUs. Within 90 days, it’s over 95%” (Fig 2.3). Progressive web apps don’t have those same challenges. They’re as easy for people to discover as your website is, because they   your website. And the features of a progressive web app are available immediately. There’s no need to jump through the hoops of visiting an app store and downloading the app. Installation is fast: it happens in the background during the first site visit, and can literally be as simple as adding an icon to the home screen. As Alex Russell wrote in  : The friction of PWA installation is   lower. Our internal metrics at Google show that for similar volume of prompting for PWA banners and native app banners — the closest thing to an apples-to-apples comparison we can find —  . More than half of users who chose to install a native app from these banners fail to complete installing the app whereas PWA installation is near-instant. In short, a large and growing percentage of your customers interact with you on the web. Progressive web apps can lead to more revenue and engagement from more customers. Secure your website If you’re collecting credit cards or private information, providing a secure website for your web visitors is a must. But even if your website doesn’t handle sensitive data, it still makes sense to use HTTPS and provide a secure experience. Even seemingly innocuous web traffic can provide signals that can identify individuals and potentially compromise them. That’s not to mention the concerns raised by revelations of government snooping. It used to be that running a secure server was costly, confusing, and (seemingly) slower. Things have changed. SSL/TLS certificates used to cost hundreds of dollars, but now certificate provider   gives them out for free. Many hosting providers have integrated with certificate providers so you can set up HTTPS with a single click. And it turns out that  . Websites on HTTPS can also move to a new version of HTTP called HTTP/2. The biggest benefit is that HTTP/2 is significantly faster that HTTP/1. For many hosting providers and content delivery networks (CDNs), the moment you move to HTTPS, you get HTTP/2 with no additional work. If that wasn’t enough incentive to move to HTTPS, browser makers are using a carrot-and-stick approach for pushing websites to make the change. For the stick, Chrome has started warning users when they enter data on a site that isn’t running HTTPS. By the time you read this,   (Fig 2.4). Other browsers will likely follow suit and start to flag sites that aren’t encrypted to make sure users are aware that their data could be intercepted. For the HTTPS carrot, browsers are starting to require HTTPS to use new features. If you want to utilize the latest and greatest web tech,  . In fact, some features that used to work on nonsecure HTTP that are considered to contain sensitive data—for example, geolocation—are being restricted to HTTPS now. On second thought, perhaps this is a bit of a stick as well. A carrot stick? With all that in mind, it makes sense to set up a secure website for your visitors. You’ll avoid scary nonsecure warnings. You’ll get access to new browser features. You’ll gain speed benefits from HTTP/2. And: you’ll be setting yourself up for a progressive web app. In order to use service workers, the core technology for progressive web apps, your website   be on HTTPS. So if you want to reap the rewards of all the PWA goodness, you need to do the work to make sure your foundation is secure. Generate more revenue There are numerous studies that show a connection between the speed of a website and the amount of time and money people are willing to spend on it. DoubleClick found that “ .” Walmart found that  . Providing a fast web experience makes a big difference to the bottom line. Unfortunately, the average load time for mobile websites is  . That’s where a progressive web app can help. Progressive web apps use service workers to provide an exceptionally fast experience. Service workers allow developers to explicitly define what files the browser should store in its local cache and under what circumstances the browser should check for updates to the cached files. Files that are stored in the local cache can be accessed much more quickly than files that are retrieved from the network. When someone requests a new page from a progressive web app, most of the files needed to render that page are already stored on the local device. This means that the page can load nearly instantaneously because all the browser needs to download is the incremental information needed for that page. In many ways, this is the same thing that makes native apps so fast. When someone installs a native app, they download the files necessary to run the app ahead of time. After that occurs, the native app only has to retrieve any new data. Service workers allow the web to do something similar. The impact of progressive web apps on performance can be astounding. For example,   with their progressive web app—and it’s 90 percent smaller than their native Android app. Hotel chain Treebo launched a progressive web app and  ; conversion rates for repeat users saw a threefold increase, and their median interactive time on mobile dropped to 1.5 seconds. Ensure network reliability Mobile networks are flaky. One moment you’re on a fast LTE connection, and the next you’re slogging along at 2G speeds—or simply offline. We’ve all experienced situations like this. But our websites are still primarily built with an assumption that networks are reliable. With progressive web apps, you can create an app that continues to work when someone is offline. In fact, the technology used to create an offline experience is the same technology used to make web pages fast: service workers. Remember, service workers allow us to explicitly tell the browser what to cache locally. We can expand what is stored locally—not only the assets needed to render the app, but also the content of pages—so that people can continue to view pages offline (Fig 2.5). Using a service worker, we can even precache the shell of our application behind the scenes. This means that when someone visits a progressive web app for the first time, the whole application could be downloaded, stored in the cache, and ready for offline use without requiring the person to take any action to initiate it. For more on when precaching makes sense, see Chapter 5. Keep users engaged Push notifications are perhaps the best way to keep people engaged with an application. They prompt someone to return to an app with tantalizing nuggets of new information, from breaking news alerts to chat messages. So why limit push notifications to those who install a native application? For instance, if you have a chat or social media application, wouldn’t it be nice to notify people of new messages (Fig 2.6)? Progressive web apps—specifically our friend the service worker—make push notifications possible for any website to use. Notifications aren’t required for something to be a progressive web app, but they are often effective at increasing re-engagement and revenue: United eXtra Electronics saw   from users arriving via push notifications. Notifications contributed to   for Lancôme. Classified ads company OLX saw   using push notifications and a 146 percent higher click-through rate on ads. Carnival Cruise Line garnered  . In addition to the 24 percent of mobile users who opted in to the notifications, 16 percent of desktop users opted in as well. We’ll talk more about push notifications in Chapter 6. For now, it can be helpful to know that progressive web apps can send push notifications, just like a native app—which may help you make the case to your company. Whether you have a native app or not, a progressive web app is probably right for you. Every step toward a progressive web app is a step toward a better website. Websites   be secure. They   be fast. They would be better if they were available offline and able to send notifications when necessary. For your customers who don’t have or use your native app, providing them with a better website experience is an excellent move for your business. It’s really that simple. Like this: \n\t\t\t\t\t\t\tRecently by Jason Grigsby\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-for-interaction-modes/", "title": "Designing for Interaction Modes", "content": "We humans have developed ways of coping with digital interfaces. We have tactics. We accept shortcomings. We make do.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But why is it still so hard (on most of the internet) to avoid uphill struggles? Often, for example, a quality reading experience is only fully available via a hack, using   or a browser plug-in. I use Instapaper to send articles to my Kindle—a device that’s devoted to reading mode—because reading is not just about getting the job done. The experience itself is also important.  The best experiences result from designers matching the way the computer behaves with the way our users are thinking, feeling, and interacting. This is what user experience design is all about. And yet, because of pressures, competing priorities, and industry trends, interaction modes are often an afterthought. Prioritizing interaction modes A while back I created a persona for Cambridge University Press named Rachel Research Gatherer. The Rachel bit, I now understand, was irrelevant ( ). But naming the research gatherer mode helped my team focus on what was needed to support the gathering of scholarly articles and books. The precise ordering and arrangement of citation data, author biographies, metrics, and publication metadata was all organized around this central thought:  This focused our feature set and allowed for deprioritizing functionality related to other, non-essential modes (e.g., reading online—our research gatherers were only interested in saving PDFs to read later).  In fact, the best personas I’ve seen have always included the interaction mode (or dominant behavior) in the title, which encourages a focus on software that supports that way of interacting. Thinking about roles or demographic attributes just isn’t as helpful. Presuming that lots of research gatherers are going to show up, you want them to converse with software that is appropriately trained and has a research gathering mode that can easily be found and switched on. The leap to be made is one from understanding a human behavior to designing its matching counterpart: an appropriate computer behavior. I’ve come to think of interaction modes as aspects of the persona you want your digital product or service to have. They can codify a specific set of behaviors, morals, and manners. Moving between modes In most cases, designers have to account for multiple possible interaction modes and, crucially, the shifts between them.  Some shifts can be explicitly triggered by the user. Take Audible’s driving mode, which helps users stay safe by minimizing potential distractions: it filters out all but three controls and makes the entire upper part of the screen a giant play/pause button. Driving mode is activated by tapping on a tiny icon, but modes could equally be switched on via a link. If a link took you to “lost or stolen card” on your bank’s website, you might welcome a mode that deals with stressful situations. This might involve an appropriately short quantity of text and guidance—hopefully a quick-fix option (e.g., “freeze my card”) and directions to the nearest human support. Modes can also shift in response to implied needs. The National Trust—an organization that maintains historic and natural sites across England, Wales, and Northern Ireland—has an app whose visit mode focuses on local events and information relevant to users’ geolocation. This mode is offered to the user when they approach a National Trust property. It’s a safe bet that they’re going to prefer this mode, but they’re offered the choice to activate it anyway. It’s good manners. There are also times when there is no need to ask. Let’s consider another familiar human-computer interaction: evaluating, a mode in which the human tries to assess the quality or fitness of something, as one might do when comparison shopping for a new laptop. The computer (if trained appropriately) helps by surfacing the right metadata, summary info, reviews, and so on. A bit like research gathering, it’s a mode that might lead to reading mode, in a move from “Shall I read this?” to “I’m reading this!” A well-presented article will start with different content and functional elements than it continues with. The top of this page is all about supporting evaluation mode; then those elements fall away when the user indicates that they’ve shifted into reading mode. They show this intent by, say, scrolling slowly down the page or clicking a “read more” button. The object, in this case an article, looks different, sometimes very different, when supporting different modes. And the user might move between these modes without even registering the shift. Interaction modes are computer behaviors A simple but important distinction to make when thinking about modes: This distinction is critical, because it allows us to be so much more precise about the behavior of the components in a design system. We don’t always need to rely on individual interpretation of personae or journey maps, or remember an agreed set of design principles. We can, instead, bake our values into our modes. We can, for example, name components according to the mode they’re intended to support rather than just to create more purposeful and consistent designs (though these are great things to aim for). Interaction modes also offer us a design tool that can help tame our technology, giving it manners that work in a variety of contexts. And in our world of agentive AI, chatbottery, and algorithms, getting a grip on this conduct is becoming increasingly important.  Two moral questions As time goes on, we have more and more powerful controls available to us in fast digital mediums. There’s an increasing need to recognize that poor usability is not the only factor to watch out for. We need to be working design ethics into our decision making. It could start with a simple moral question for design teams: how much are you going to help your users interact in the way that they would prefer? If they’re reading, how many ads (or other distractions) are you going to throw in their faces? Even though users might prefer ads to paying for content, there are better and worse ways to show people ads. Deliberately designing for a reading mode will give you a better shot at reconciling this conflict in a good way, allowing you to create the best reading space possible within the constraints. Compromises would become more deliberate and (hopefully) less damaging.  A second, less obvious, moral question is this: when should we use design to encourage a more appropriate way of interacting than the user’s default? In my article about  , I looked at some ways to slow the user’s experience (using roadblocks, speed bumps, or diversions in the design) when thoughtfulness is needed. The user could be agreeing to give a third party access to their data. Or they might be remortgaging their house. On these kinds of occasions, it’s right to encourage a slower, more attentive mode. One way to approach this question is to capture the interaction modes that your users want or need, on a chart like this: To start off, this could just be an expert-led evaluation or a group   exercise along the following lines: Ideally, you want all your modes to fall close to a diagonal line that stretches from top right to bottom left of your chart. The amount of thoughtfulness we encourage (or leave space for) in each mode would then be roughly in proportion to the amount of thought required. This ethical line makes it look a little like there is only one way to get things right: precisely x amount of thought required = x amount of thought encouraged. It’s hard (and maybe impossible) to measure such things precisely, but that shouldn’t put us off, considering the relative needs in play. If nothing else, the visualization reminds us that there are many more ways to get design wrong than to get it right.  If you find the interaction modes you’re currently supporting don’t fall on the ethical line, you’ll want to move them with your team’s next design effort. Ultimately, deciding where to move interaction modes requires a degree of honest reflection and the willingness to shift any annoying or abusive experiences toward assisting or awakening ones.  While most designers want to assist and awaken (and avoid abusing or annoying) our users, even a small team will have disagreements about the right path to take. And powerful drivers outside the team, from business models to technology trends, heavily influence design decisions. These factors need our greatest focus if we are to resist following zombie patterns (“our competitors have introduced sexy new feature X so we’d better do it too”) or the tendency to pander (often in the name of UX) to short-term interests. You might be rightly proud of being able to offer a current account opening experience that only takes  , but are you sure that this is right for everyone you’re offering it to? Don’t some folks need some extra guidance around how to configure things? Don’t people need to understand the commitments they’re making? Adding this kind of consideration to the design process can pull against the push for speed and help designers resist the deployment of persuasion techniques in inappropriate contexts.  Where to draw the line But how can we know which techniques are inappropriate? It can be hard to make a call on this. For example, testimonials and reviews can help reassure the user and build trust. They   also discourage independent research, but they’re hardly an abusive play. Someone might want to place a pop-up ad directly in the middle of your user’s reading experience, arguing that it is encouraging thoughtfulness about a product that would be in the user’s long-term interests to know about in that context. And they might be right. For me, this is where good research comes in. We need to know the contexts for which more thoughtful engagement is appropriate to help our users achieve their long-term goals. We have to test our designs for whether they deliver comprehension and fair outcomes over a long timeframe. Only then can we know which of our nudges fall on the ethical line. Getting over your squeamishness You might feel squeamish about defining your users’ best interests for them. How do we dare to presume? Shouldn’t we just lay the facts and choices out there, and let people make all the decisions themselves?  I think there are two solid reasons for getting over this squeamishness. First, design decisions have moral consequences whether you intend them or not. As Tristan Harris puts it, “ ” It is better, therefore, to make your decisions with some deliberateness and transparency. Second, people are not as individual as we like to think we are. There are common misconceptions that lead to poor choices. To support choosing the right mortgage, for example, designers might reasonably seek out the things that typically trip people up (and are important to know). We need to convey the mechanics of the product: how the interest gets calculated, where fees and charges might come into play, and so on. We do this so we can be sure that the user knows their commitments and that they have the best possible chance of selecting something that meets their long-term needs. Bringing dark patterns into the light To help prioritize these considerations, you might add an understanding or clarifying mode to your chart. Just adding it to the chart will help get   on the agenda. Making space for this conversation will help force dark patterns into the light. Where things are less clear-cut, we might at least acknowledge the need for further research to help add in richer consideration of users and their needs. Like this: \n\t\t\t\t\t\t\tRecently by Andrew Grimes\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/taming-data-with-javascript/", "title": "Taming Data with JavaScript", "content": "I love data. I also love JavaScript. Yet, data and client-side JavaScript are often considered mutually exclusive. The industry typically sees data processing and aggregation as a back-end function, while JavaScript is just for displaying the pre-aggregated data. Bandwidth and processing time are seen as huge bottlenecks for dealing with data on the client side. And, for the most part, I agree. But there are situations where processing data in the browser makes perfect sense. In those use cases, how can we be successful? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Think about the data Working with data in JavaScript requires both complete data and an understanding of the tools available without having to make unnecessary server calls. It helps to draw a distinction between trilateral data and summarized data.  consists of raw, transactional data. This is the low-level detail that, by itself, is nearly impossible to analyze. On the other side of the spectrum you have your  . This is the data that can be presented in a meaningful and thoughtful manner. We’ll call this our  . Most important to developers are the data structures that reside between our transactional details and our fully composed data. This is our “sweet spot.” These datasets are aggregated but contain more than what we need for the final presentation. They are multidimensional in that they have two or more different dimensions (and multiple measures) that provide flexibility for how the data can be presented. These datasets allow your end users to shape the data and extract information for further analysis. They are small and performant, but offer enough detail to allow for insights that you, as the author, may not have anticipated. Getting your data into perfect form so you can avoid any and all manipulation in the front end doesn’t need to be the goal. Instead, get the data reduced to a multidimensional dataset. Define several key dimensions (e.g., people, products, places, and time) and measures (e.g., sum, count, average, minimum, and maximum) that your client would be interested in. Finally, present the data on the page with form elements that can slice the data in a way that allows for deeper analysis. Creating datasets is a delicate balance. You’ll want to have enough data to make your analytics meaningful without putting too much stress on the client machine. This means coming up with clear, concise requirements. Depending on how wide your dataset is, you might need to include a lot of different dimensions and metrics. A few things to keep in mind: Is the variety of content an edge case or something that will be used frequently? Go with the 80/20 rule: 80% of users generally need 20% of what’s available. Is each dimension finite? Dimensions should always have a predetermined set of values. For example, an ever-increasing product inventory might be too overwhelming, whereas product categories might work nicely. When possible, aggregate the data—dates especially. If you can get away with aggregating by years, do it. If you need to go down to quarters or months, you can, but avoid anything deeper. Less is more. A dimension that has fewer values is better for performance. For instance, take a dataset with 200 rows. If you add another dimension that has four possible values, the most it will grow is 200 * 4 = 800 rows. If you add a dimension that has 50 values, it’ll grow 200 * 50 = 10,000 rows. This will be compounded with each dimension you add. In multidimensional datasets, avoid summarizing measures that need to be recalculated every time the dataset changes. For instance, if you plan to show averages, you should include the total and the count. Calculate averages dynamically. This way, if you are summarizing the data, you can recalculate averages using the summarized values. Make sure you understand the data you’re working with before attempting any of the above. You could make some wrong assumptions that lead to misinformed decisions. Data quality is always a top priority. This applies to the data you are both querying and manufacturing. Never take a dataset and make assumptions about a dimension or a measure. Don’t be afraid to ask for   or other documentation about the data to help you understand what you are looking at. Data analysis is not something that you guess. There could be business rules applied, or data could be filtered out beforehand. If you don’t have this information in front of you, you can easily end up composing datasets and visualizations that are meaningless or—even worse—completely misleading. The following code example will help explain this further.  Our use case For our example we will use   from “Where U.S. Refugees Come From—and Go—in Charts.” We’ll build a small app that shows us the number of refugees arriving in a selected state for a selected year. Specifically, we will show one of the following depending on the user’s request: total arrivals for a state in a given year; total arrivals for all years for a given state; and total arrivals for all states in a given year. The UI for selecting your state and year would be a simple form: The code will: We do not want to pass excessively large datasets over the wire to browsers for two main reasons: bandwidth and CPU considerations. Instead, we’ll aggregate the data on the server with Node.js. How to get your data structure into place AJAX and the Fetch API There are a number of ways with JavaScript to retrieve data from an external source. Historically you would use an  . XHR is widely supported but is also fairly complex and requires several different methods. There are also libraries like   or  . These can be helpful to reduce complexity and provide cross-browser support. These might be an option if you are already using these libraries, but we want to opt for native solutions whenever possible. Lastly, there is the more recent  . This is  , but it is straightforward and chainable. And if you are using a transpiler (e.g.,  ), it will convert your code to a more widely supported equivalent. For our use case, we’ll use the Fetch API to pull the data into our application: This code is a snippet from the main.js in the GitHub repo The   method sends a request for the data, and we convert the results to JSON. To ensure that the next statement doesn’t execute until after the complete dataset is retrieved, we use the   method and do all our data processing within that block. Lastly, we   any errors. Our goal here is to identify the key dimensions we need for reporting—year and state—before we aggregate the number of arrivals for those dimensions, removing country of origin and destination city. You can refer to the Node.js script   from the GitHub repo for more details on how we accomplished this. It generates the   file loaded by   above. Multidimensional data The goal of multidimensional formatting is flexibility: data detailed enough that the user doesn’t need to send a query back to the server every time they want to answer a different question, but summarized so that your application isn’t churning through the entire dataset with every new slice of data. You need to anticipate the questions and provide data that formulates the answers. Clients want to be able to do some analysis without feeling constrained or completely overwhelmed. As with most APIs, we’ll be working with JSON data.   is a standard that is used by most APIs to send data to applications as objects consisting of name and value pairs. Before we get back to our use case, let’s look at a sample multidimensional dataset: With your dataset properly aggregated, we can use JavaScript to further analyze it. Let’s take a look at some of JavaScript’s native array methods for composing data. How to work effectively with your data via JavaScript The   method of the   prototype ( ) takes a function that tests every item in the array, returning another array containing only the values that passed the test. It allows you to create meaningful subsets of the data based on select dropdown or text filters. Provided you included meaningful, discrete dimensions for your multidimensional dataset, your user will be able to gain insight by viewing individual slices of data. The   method of the   prototype ( ) takes a function and runs every array item through it, returning a new array with an equal number of elements. Mapping data gives you the ability to create related datasets. One use case for this is to map ambiguous data to more meaningful, descriptive data. Another is to take metrics and perform calculations on them to allow for more in-depth analysis. The   method of the   prototype ( ) takes a function and runs every array item through it, returning an aggregated result. It’s most commonly used to do math, like to add or multiply every number in an array, although it can also be used to concatenate strings or do many other things. I have always found this one tricky; it’s best learned through example. When presenting data, you want to make sure it is summarized in a way that gives insight to your users. Even though you have done some general-level summarizing of the data server-side, this is where you allow for further aggregation based on the specific needs of the consumer. For our app we want to add up the total for every entry and show the aggregated result. We’ll do this by using   to iterate through every record and add the current value to the accumulator. The final result will be the sum of all values (total) for the array. Applying these functions to our use case Once we have our data, we will assign  an event to the “Get the Data” button that will present the appropriate subset of our data. Remember that we have several hundred items in our JSON data. The code for binding data via our button is in our main.js: If you leave either the state or year blank, that field will default to “All.” The following code is available in  . You’ll want to look at the   function, which is where we keep the lion’s share of the functionality for aggregation and filtering. When a state or a year is blank, it will default to “All” and we will filter down our dataset to that particular dimension, and summarize the metric for all rows in that dimension. When both a year and a state are entered, we simply filter on the values. We now have a working example where we: Start with a raw, transactional dataset; Create a semi-aggregated, multidimensional dataset; And dynamically build a fully composed result. Note that once the data is pulled down by the client, we can manipulate the data in a number of different ways without having to make subsequent calls to the server. This is especially useful because if the user loses connectivity, they do not lose the ability to manipulate the data. This is useful if you are creating a progressive web app (PWA) that needs to be available offline. (If you are not sure if your web app should be a PWA,   can help.) Once you get a firm handle on these three methods, you can create just about any analysis that you want on a dataset. Map a dimension in your dataset to a broader category and summarize using reduce. Combined with  , you can map this data into charts and graphs to allow a fully customizable data visualization. Conclusion This article gives a better sense of what is possible in JavaScript when working with data. As I mentioned, client-side JavaScript is in no way a substitute for translating and transforming data on the server, where the heavy lifting should be done. But by the same token, it also shouldn’t be completely ruled out when datasets are treated properly. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/flexible-typesetting/", "title": "What is Typesetting?", "content": "Typesetting is the most important part of typography, because most text is meant to be read, and typesetting involves preparing text for reading. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. You’re already great at typesetting. Think about it. You choose good typefaces. You determine font sizes and line spacing. You decide on the margins that surround text elements. You set media query breakpoints. All of that is typesetting. Maybe you’re thinking,   Relax. You make better decisions than you realize. Some people will try to make you feel inferior; ignore them. Your intuition is good. Practice, and your skills will improve. Make a few solid decisions; then build on them. I’ll help you get started. In this chapter, I’ll identify the value of typesetting and its place within the practice of typography. I’ll talk about pressure, a concept I use throughout this book to explain why typeset texts sometimes feel awkward or wrong. I’ll also discuss how typesetting for the web differs from traditional typesetting. Why does typesetting matter? Typesetting shows readers you care. If your work looks good and feels right, people will stick around—not only because the typography is comfortable and familiar, but also because you show your audience respect by giving their experience your serious attention ( ). Sure, you could buy the “it” font of the moment (you know, the font all the cool people are talking about). You could use a template that promises good typography. You could use a script that spiffs up small typographic details. None of these things is necessarily bad in and of itself. But when you take shortcuts, you miss opportunities to care about your readers, the text in your charge, and the practice of typography, all of which are worthwhile investments. Spending time on these things can feel overwhelming, but the more you do it, the easier and more fun it becomes. And you can avoid feeling overwhelmed by focusing on the jobs type does. Imagine yourself in a peaceful garden. You feel the soft sun on your arms, and take a deep breath of fresh, clean air. The smell of flowers makes you feel happy. You hear honeybees hard at work, water trickling in a nearby brook, and birds singing. Now imagine that this garden needs a website, and you’re trying to find the right typeface. Sorry to spoil the moment! But hey, if you do this right, the website could give people the same amazing feeling as sitting in the garden itself. If you’re anything like me, your first instinct will be to recall sensations from the imaginary garden and look for a typeface with shapes that evoke similar sensations. But this is not a good way to choose among thousands upon thousands of fonts, because it’s too easy to end up with typefaces that—as charming as they may seem at first—don’t do their jobs. You’ll get disappointed and go right back to relying on shortcuts. Finding typefaces that are appropriate for a project, and that evoke the right mood, is easier and more effective if you know they’re good at the jobs you need them to do. The trick is to eliminate type that won’t do the job well ( ). Depending on the job, some typefaces work better than others—and some don’t work well at all. Detailed, ornate type is not the best choice for body text, just as traditional text typefaces are not great for signage and user interfaces. Sleek, geometric fonts can make small text hard to read. I’ll come back to this at the beginning of Chapter 3. Considering these different jobs helps you make better design decisions, whether you’re selecting typefaces, tending to typographic details, or making text and layout feel balanced. We’ll do all of that in this book. Typesetting covers type’s most important jobs Typesetting, or the act of  , consists of typographic jobs that form the backbone of a reading experience: body text (paragraphs, lists, subheads) and small text (such as captions and asides). These are type’s most important jobs. The other parts of typography—which I call   and   type—exist to bring people to the typeset text, so they can read and gather information ( ). Let’s go over these categories of typographic jobs one by one.   well makes it easy for people to read and comprehend textual information. It covers jobs like paragraphs, subheads, lists, and captions.   turns visitors and passersby into readers, by catching their attention in an expressive, visual way. It’s for jobs like large headlines, titles, calls to action, and “hero” areas.   helps people scan and process complicated information, and find their way, by being clear and organized. This is for jobs like tabular data, navigation systems, infographics, math, and code. Arranging and calibrating type, and the jobs they facilitate, are extremely important, but I won’t spend much time discussing them in this book except to put them in context and explain where in my process I usually give them attention. They deserve their own dedicated texts. This book focuses specifically on setting type, for several reasons. First, typesetting is critical to the success of our projects. Although the decisions we make while typesetting are subtle almost to the point of being unnoticeable, they add up to give readers a gut feeling about the work. Typesetting lays a strong foundation for everything else. It also happens to be more difficult than other parts of typography. Good type for typesetting is harder to find than good type for other activities. Good typesetting decisions are harder to make than decisions about arranging type or calibrating type. Furthermore, typesetting can help us deeply understand the web’s inherent flexibility, which responsive web design has called attention to so well. The main reason I make a distinction between typesetting, arranging type, and calibrating type is because these different activities each require text to   in different ways. In sum, typesetting matters because it is critical for readers, it supports other typographic activities, the difficult decisions informing it take practice, and its nature can help us understand flexibility and responsiveness on the web. A command of typesetting makes us better designers. Why do some websites feel wrong? It’s not hard to find websites that just feel, well, sort of wrong. They’re everywhere. The type they use is not good, the font size is too small (or too big), lines of text are too long (or comically short), line spacing is too loose or too tight, margins are either too small or way too big, and so on ( ). It’s logical to think that websites feel wrong because, somewhere along the line, a typographer made bad decisions. Remember that a   is someone who makes type; a   is someone who uses type to communicate. In that sense, we are all typographers, even if we think of what we do as designing, or developing, or editing. For more than 500 years, the job of a typographer has been to decide how text works and looks, and over those years, typographers have made some beautiful stuff. So if some websites feel wrong, it must be because the typographers who worked on them were inexperienced, or lazy, or had no regard for typographic history. Right? Except that even the best typographers, who have years of experience, who have chosen a good typeface for the job at hand, who have made great typesetting decisions, who work hard and respect tradition—even those people can produce websites that feel wrong. Websites just seem to look awful in one way or another, and it’s hard to say why. Something’s just not quite right. In all likelihood, it’s the typesetting. Specifically, websites feel wrong when they put   on typographic relationships. Typographic relationships Have you ever chosen a new font for your blog template, or an existing project, and instinctively adjusted the font size or line spacing to make it feel better? Those typesetting adjustments help because the typeface itself, as well as its font size,   (a typographic term for the length of lines of text), and line spacing all work together to make a text block feel balanced. (We’ll return to text blocks in more detail in Chapter 3.) This balance is something we all instinctively notice; when it’s disrupted, we sense pressure. But let’s continue for a moment with this example of choosing a new font. We sense pressure every time we choose a new font. Why? Because each typeface is sized and positioned in unique ways by its designer ( ). In Chapter 2, we’ll take a closer look at  , which are instances of one or more characters. For now, suffice it to say that glyphs live within a bounding box called the  , which is a built-in part of a font file. Type designers decide how big, small, narrow, or wide glyphs are, and where they are positioned, within this box. The em box is what becomes our CSS-specified font size—it maps to the CSS content area. So when we select a new typeface, the visible font size of our  —the chunk of text to which we are applying styles— often changes, throwing off its balance. This means we need to carefully adjust the font size and then the measure, which depends on both the typeface and the font size. Finally, we adjust line spacing, which depends on the typeface, font size, and measure. I’ll cover how to fine-tune all of these adjustments in Chapter 4. Making so many careful adjustments to one measly text block seems quite disruptive, doesn’t it? Especially because the finest typographic examples in history—the work we admire, the work that endures—commands a compositional balance.  , of course, refers to a work of art or design in its \nentirety. Every text block, every shape, every space in a composition relates to another. If one text block is off-kilter, the whole work suffers. I’m sure you can see where I’m headed with this. The web puts constant pressure on text blocks, easily disrupting their balance in myriad ways. Pressure There are no “correct” fonts, font sizes, measures, or line heights. But relationships among these aspects of a text block determine whether reading is easier or harder. Outside forces can apply pressure to a balanced, easy-to-read text block, making the typesetting feel wrong, and thus interfering with reading. We just discussed how choosing a new typeface introduces pressure. The same thing happens when our sites use local fonts that could be different for each reader, or when webfonts fail to load and our text is styled with fallback fonts. Typefaces are not interchangeable. When they change, they cause pressure that we have to work hard to relieve. We also experience pressure when the font size changes ( ). Sometimes, when we’re designing sites, we increase font size to better fill large  —the viewing area on our screens—or decrease it to better fit small ones. Readers can even get involved, by increasing or decreasing font size themselves to make text more legible. When font size changes, we have to consider whether our typeface, measure, and line spacing are still appropriate. Changes to the width of our text block also introduce pressure ( ). When text blocks stretch across very wide screens, or are squeezed into very narrow viewports, the entire composition has to be reevaluated. We may find that our text blocks need new boundaries, or a different font size, or even a different typeface, to make sure they maintain a good internal balance—and feel right for the composition. (This may seem fuzzy right now, but it will become clearer in Chapters 5 and 6, I promise.) We also experience pressure when we try to manage white space without considering the relationships in our text blocks ( ). When we predetermine our line height with a baseline grid, or when we adjust the margins that surround text as if they were part of a container into which text is poured rather than an extension of the balance in the typesetting, we risk destroying relationships among compositional white spaces— not only the white spaces in text blocks (word spacing, line spacing), but also the smaller white spaces built into our typefaces. These relationships are at risk whenever a website flexes, whenever a new viewport size comes along. Typesetting for the web can only be successful if it relieves inevitable pressures like these. The problem is that we can’t see all of the pressures we face, and we don’t yet have the means (the words, the tools) to address what we   see. Yet our natural response, based on centuries of typographic control, is to try to make better decisions. But on the web, that’s like trying to predict the weather. We can’t decide whether to wear a raincoat a year ahead of time. What we can do is   and be ready to use it under certain conditions. Typographers are now in the business of making sure text has a raincoat. We can’t know when it’ll be needed, and we can’t force our text to wear it, but we can make recommendations based on conditional instructions. For the first time in hundreds of years,  , the role of the typographer has changed. We no longer decide; we make suggestions. We no longer choose typefaces, font size, line length, line spacing, and margins; we prepare and instruct text to make those choices for itself. We no longer determine page shape and quality; we respond to our readers’ contexts and environments. These changes may seem like a weakness compared to the command we have always been able to exercise. But they are in fact an incredible strength, because they mean that typeset text has the potential to fit everyone just right. In theory, at least, the web is universal. The primary design principle underlying the web’s usefulness and growth is universality. We must now practice a   typography that strives to work for everyone. To start, we need to acknowledge that typography is  ,   to each reader, and unequivocally  . Like this: \n\t\t\t\t\t\t\tRecently by Tim Brown\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/make-something-great-become-an-open-source-contributor/", "title": "Make Something Great: Become an Open Source Contributor", "content": "My first contribution to Bootstrap was a tiny line of CSS. It was a no-brainer to merge, but the feeling of seeing that bit of code in the project’s codebase was unreal and addictive. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. You may think that open source is not for you. After all, it has always been a developer-dominant ecosystem. But code is by no means the only thing a piece of software is made of. Open source is first and foremost about community. Whether you’re a designer, developer, writer, doctor, or lawyer, there are many paths to the open source world. Learn what you need to know to set out on your journey, from first steps to becoming a core contributor. It might change your career. It’s OK if you don’t code Developers think about their work logically. They break problems down into solvable pieces to make things work. They will devote themselves to crafting an API or a data structure, and optimize those solutions for performance and reusability. Unfortunately, this deconstruction often results in a Swiss Army knife of an interface, with a design that reflects the underlying data structures and APIs available. Diversity is what can take open source from where it is to where it could be. This is why the open source community needs you. Not only diversity in perspective, but also diversity of gender, location, cultures, and social backgrounds. Together these become greater than the sum of their parts. Designers Most people who contribute to an open source project are also users of the software. But designers look at the project from a different perspective. Their job is to defend the user, especially those that are not able to contribute to the project but still need the software. They make sure that everyone working on the project understands users’ needs and stays focused on them as the community makes decisions. Writers Let’s face it: writing is really hard! Designers and developers are usually bad at it. But it’s so valuable to an open source community, where members have to collaborate and communicate remotely, asynchronously, and, more often than not, in a non-native language. Documentation, especially on open source projects, is rarely up-to-date. It’s worse when it involves the documentation meant for contributors. Information for getting started with a project frequently has gaps, with important information missing. Also, like developers who dedicate themselves to different pieces of a software project, different types of writers can contribute to different pieces of a project’s messaging. They can team up with designers and subject matter experts to write copy for user interfaces, landing pages, or help documentation.  was a technical writer in the NetBeans community. Through his documentation, articles, and getting-started guides, he helped thousands of Java developers navigate their way around the project. His contributions had a profound impact, and he became the most acclaimed person in the community. Without communication, you have no community. What you write may be the reason why someone decides to get involved. It can make the difference between someone feeling welcome or feeling lost. Your contribution as a writer is invaluable. Developers that don’t want to code Coding is optional; even software developers don’t always code. There’s administrative work too! Replying to issues, reviewing contributions, and helping users on forums, chats, Reddit, or Stack Overflow is as important to the success of the project as writing code. Subject matter experts Participation in open source projects is by no means limited to software engineers, designers, and writers. Lawyers, other engineers, and even   and other specialists can find a place to apply their knowledge too. So if you thought open source projects were just for developers, think again. There is a place for you and every single contribution is important. Why bother? In 2013, Jay Balunas, the cofounder of  , a small open source project, saw that more than 85% of its Android code was written by a single developer:  . Jay had received some funding, so he reached out, offering him a job on the spot. But Daniel turned it down. Why would someone turn down a paid position and want to continue working for free? Passos lived thousands of miles away, in Rio de Janeiro. He also didn’t speak any English. Not about to lose a great developer that had already proven his worth, Jay solved the problem. He made the position remote, and sent an English teacher to Daniel’s house every week. This story may sound too good to be true. But this may describe the careers of more people than you think—people who did not start out contributing to open source ever expecting anything in return. They would probably describe their experience starting out as a labor of love. Getting a job offer shouldn’t be your only motivation to contribute to an open source project. If it is, you’ll likely be frustrated with the results. Working for free You may have a problem with working for free, especially when there seems to be plenty of well-paid work to go around. Why should you work in a vulnerable environment with total strangers, without ever receiving compensation? If you are in your early twenties, willing to work all night for the love of this industry, and have few pressing expenses, then building up your professional reputation on open source projects and sharing your ideas is a great thing to do. It’s how we all got started, how I and the majority of my peers found our voices. On a professional level, among the biggest assets you have are your connections. But not everyone lives in a major tech industry area. Not everyone can attend industry conferences or participate in hackathons. The open source community opens a network of passionate and talented people from around the world. To become part of it, you don’t have to worry about whiteboarding exercises, interviews, or whether you have a degree from the right university. But you may be disappointed if you contribute to an open source project just to get a job. Open source is volunteer work, just like helping other not-for-profit and community organizations that need people in order to stay open and reach as many people as possible. It should be approached from a place of wanting to give back to your community and contributing to a worthy cause. , and it’s often not a question of a person’s technical skills. Many companies today require applicants to participate in a months-long interview process, and complete hours of coding and design challenges that are unpaid, are unrecognized, and become the company’s property. In the case of Daniel Passos, by contributing to a project over time, he was able to demonstrate what he was capable of building, how he collaborated with others, and how passionate he was. This let him get past job requirements that aren’t related to the work but that are used to deny qualified job applicants all the time. This results in people who pay it forward: Daniel has since mentored many people in the community, including me. As a contributor, you will be able to experiment and play with bleeding-edge techniques at a scale that you would hardly find on a personal project or in a hackathon scenario. It’s also an opportunity to continue working with technologies that you might not get to use anymore in other work. And if you have been away from making things for a long time, an open source project is a great way to get back on track. Last but not least, it’s hard to explain with words the feeling you get when your name appears on a project. The positive feedback loop of being part of something larger than yourself is what makes open source addictive. Just ask what happened when a couple of people took over the blogging tool   when it was abandoned by its creator. Finding your community If all of this sounds good to you, it’s time to find your people. Start by taking a look at what you like and use. Ask yourself what problems you would like to solve. If you are passionate about something, there is probably a community around it. If you enjoy working with a particular technology, you have options spanning the entire programming realm. For example, if you are like me and enjoy working with CSS, you can contribute to projects like  ,  ,  ,  , or  , or design systems like  ,  , or  , among  . GitHub has a great   you can use to find a group. If you would like to work on use cases that you don’t get to in your day job, like healthcare software, for example, you can find   and see what kind of contributions they need. OpenMRS is a great example of a project that benefits people outside the industry and that would never be successful with millions of developers but no designers, writers, or subject matter experts. Respect Brian Leathem, a notable open source developer, describes working on an open source project as being like working behind a glass wall. Every single action you take will be visible, transparent, and recorded. This makes you vulnerable, but a healthy community will make you feel welcome and comfortable. Check your project’s code of conduct before you contribute. Never tolerate harassment, bullying of any kind, or unkindness. If it happens and the members don’t act swiftly to enforce their code of conduct, they don’t deserve you. Communication Having said that, it’s essential to have a thick skin. Frame any criticism you will receive as a learning opportunity. When interacting with others, commit to setting aside ego for something bigger. Be humble, stay positive, have good arguments, and remain open-minded. Being able to connect with people who are very different from you will be critical. You may collaborate with someone from a part of the world where communication styles and customs are different. For example, some cultures expect you to be very assertive if you care deeply about something. This is very different than cultures where it’s impolite to disagree in an open forum. Trust As you take your first steps, you might notice that thriving open source communities are supported by people who trust each other. Learn to trust and to be trusted by showing what you are able to do, admitting when you are wrong or don’t know something, and letting people do their work. Approach your first contributions from a place of humility. Once you gain an understanding of how people like to work with one another, you will be able to make a bigger dent with bolder contributions. My very first contribution was to AeroGear, a small open source project. I downloaded the codebase to my computer, made my design changes, zipped the files, and sent an email to the community mailing list. To say that the community had trouble understanding the improvements I had made to the user experience would be an understatement. I felt terribly lost, and a little rejected. I really wanted to become a part of this open source project, but I didn’t know where to begin. So I asked for help, and the community had endless patience with me, even when I destroyed the repository a few times. The toolbox To participate in an open source project, you will need to shed any fears you may have of using the command line and working with version control. However, many open source projects are hosted on Github, where you might be able to avoid some of this if you do not code and are posting sketches, making changes to copy, or writing documentation. The command line Level Up Tutorials has a   about the command line if you are a visual learner. Their   is a good place to start. If you prefer to read,   is excellent. Git For getting started with version control,  . There are many Git desktop apps like  ,  , or   that will help you visualize what Git does. I still highly recommend becoming familiar with the Git command-line tool. It’s a steeper learning curve, but you’ll get a return on your investment. Communication channels Every community has its communication channels. There is almost always a mailing list where the most important decisions are made. GitHub’s Issues feature is used for contribution issue tracking. Forums are common for user discussions. Chat among contributors has traditionally been on IRC, but Slack, Rocket.Chat, and Gitter have become more popular, including for user discussions. Find out where your community hangs out, and get to know its members. Making your first contribution The harder part of getting started with open source is finding a community and becoming familiar with how it operates and communicates. If you have cleared that hurdle, you are more than ready to begin contributing. Start small, and  . Look at the issues for a small task you feel comfortable doing. On some projects they are tagged as “help wanted” or “good first issue.” Documentation is also a great place to start. Go through the “getting started” guides and see if they make sense to a newcomer, like you. Can you improve them, make them more clear? Look for a typo or a grammar mistake. Contributions like these are easy to merge and are a perfect starting point. If you want to contribute to a project in ways other than working on the code, these issues are good ways to introduce yourself and what you can do. For example, if you are a designer, a project will sometimes, but not always, be looking for UI designs. But in most cases, even on projects with very little UI, like a utility or a service, there will be usability problems that need solutions. By starting with pointing out unclear information and offering lots of quick solutions to a problem, you can start to demonstrate both your expertise and your passion. Sometimes, changes or further explanation will be requested. Other times you’ll break things, and that’s OK.   I hadn’t tested the result. Mark Otto, the leader of the project, took the time to write a comment explaining where I made a mistake and how I might fix it. He didn’t have to do that; I should have known better. The gesture and the respect for my time as a contributor made me want to help the project even more. Leveling up Here is a secret: you don’t need to make a ton of commits to become a top contributor. React is probably the most active open source project today, and  . They can even be five   that you’ve fixed in the docs! And you can make an even greater impact in smaller communities with that level of contribution. Commit to contribute If you value the idea of open source, you are worthy of contributing to a project, earning recognition, and being a respected member of a community. If you have different expertise, experience, or points of view about a project, we need you even more. At the end of the day, without people contributing to the community, the web will not remain open and free. Rachel Andrew   how she’s seen people of her generation taking a step back, as she started to feel the pressure of the finite amount of time she has. Pioneers of the modern web like her paid it forward. Can you? Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/coding-with-clarity-part-ii/", "title": "Coding with Clarity: Part II", "content": "As any developer who works with other developers can attest, if code is unclear, problems occur. In   of this series, I went over some principles to improve clarity in our code to prevent problems that can arise from unclear code. As our apps get larger, clarity becomes even more important, and we need to take extra care to ensure that our code is easy to read, understand, and modify or extend. This article discusses some more-advanced principles related to object-oriented programming (OOP) to improve clarity in larger apps. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The Law of Demeter Imagine you’re an office manager at an apartment complex. The end of the month comes and the rent is due. You go through the drop box in the office and find checks from most of your tenants. But among the neatly-folded checks is a messy note on a scrap of paper that instructs you to unlock apartment 309, open the top drawer of the dresser on the left side of the bed, and remove the money from the tenant’s wallet. Oh, and don’t let the cat out! If you’re thinking that’s ridiculous, yeah, you’re right. To get the rent money each month, you shouldn’t be required to know how a tenant lays out their apartment and where they store their wallet. It’s just as ridiculous when we write our code this  way. The  , or  , states that a unit of code should require only limited knowledge of other code units and should only talk to close friends. In other words, your class should not have to reach several levels deep into another class to accomplish what it needs to. Instead, classes should provide abstractions to make any of its internal data available to the rest of the application. ( ) As an example, let’s say we have a class for a department in your office. It includes various bits of information, including a manager. Now, let’s say we have another bit of code that wants to email one of these managers. Without the Law of Demeter, here’s how that function might look: Very tedious! And on top of that, if anything changes with the implementation of the manager in the   class, there’s a good chance this will break. What we need is a level of abstraction to make this function’s job easier. We can add this method to our   class: With that, the first function can be rewritten as this: This not only makes the function much cleaner and easier to understand, but it makes it easier to update the   class if needed (although that can also be dangerous, as we’ll discuss later). You won’t have to look for every place that tries to access its internal information, you just update the internal method.  Setting up our classes to enforce this can be tricky. It helps to draw a distinction between traditional OOP objects and data structures. Data structures should expose   and contain no behavior. OOP objects should expose   and limit access to data. In languages like C, these are separate entities, and you have to explicitly choose one of these types. In JavaScript, the lines are blurred a bit because the object type is used for both. Here’s a data structure in JavaScript: Note how the data is easily accessible. That’s the whole point. However, if we want to expose behavior, per best practice, we’d want to hide the data using internal variables on a class: Now, if you’re thinking that’s unnecessary, you’re correct in this case—there’s not much point to having getters and setters in a simple object like this one. Where getters and setters become important is when internal logic is involved: This is still a small example, but you can see how the getter and setter here are doing more than just obfuscating the data. We can attach logic and validation to these methods that consumers of a   object shouldn’t have to worry about. And if the logic changes, we can change it on the getter and setter without finding and changing every bit of code that tries to get and set those properties. Even if there’s no internal logic when you’re building your app, there’s no guarantee that you won’t need it later. You don’t have to know what you’ll need in the future, you just have to leave space so you can add it later. Limiting access to data in an object that exposes behavior gives you a buffer to do this in case the need arises later. As a general rule, if your object exposes behavior, it’s an OOP object, and it should not allow direct access to the data; instead, it should provide methods to access it safely, as in the above example. However, if the point of the object is to expose data, it’s a data structure, and it should not also contain behavior. Mixing these types muddies the water in your code and can lead to some unexpected (and sometimes dangerous) uses of your object’s data, as other functions and methods may not be aware of all of the internal logic needed for interacting with that data. The interface segregation principle Imagine you get a new job designing cars for a major manufacturer. Your first task: design a sports car. You immediately sit down and start sketching a car that’s designed to go fast and handle well. The next day, you get a report from management, asking you to turn your sports car into a sporty minivan. Alright, that’s weird, but it’s doable. You sketch out a sporty minivan. The next day, you get another report. Your car now has to function as a boat as well as a car. Ridiculous? Well, yes. There’s no way to design one vehicle that meets the needs of all consumers. Similarly, depending on your app, it can be a bad idea to code one function or method that’s flexible enough to handle everything your app could throw at it. The   states that no client should be forced to depend on methods it does not use. In simpler terms, if your class has a plethora of methods and only a few of them are used by each user of the object, it makes more sense to break up your object into several more focused objects or interfaces. Similarly, if your function or method contains several branches to behave differently based on what data it receives, that’s a good sign that you need different functions or methods rather than one giant one. One big warning sign for this is flags that get passed into functions or methods. Flags are Boolean variables that significantly change the behavior of the function if true. Take a look at the following function: In this case, the function is split up into two different exclusive branches—there’s no way both branches are going to be used, so it makes more sense to break this up into separate functions, since we know if the person is a manager when we call it. That’s a simplified example. An example closer to the actual definition of the interface segregation principle would be if a module contained numerous methods for dealing with employees and separate methods for dealing with managers. In this case, it makes much more sense to split the manager methods off into a separate module, even if the manager module is a child class of the employee module and shares some of the properties and methods. Please note: flags are not automatically evil. A flag can be fine if you’re using it to trigger a small optional step while most of the functionality remains the same for both cases. What we want to avoid is using flags to create “clever” code that makes it harder to use, edit, and understand. Complexity can be fine as long as you’re gaining something from it. But if you’re adding complexity and there’s no significant payoff, think about why you’re coding it that way. Unnecessary dependencies can also happen when developers try to implement features they think they might need in the future. There are a few problems with this. One, there’s a considerable cost to pay now in both development time and testing time for features that won’t be used now—or possibly at all. Two, it’s unlikely that the team will know enough about future requirements to adequately prepare for the future. Things will change, and you probably won’t know   things will change until phase one goes out into production. You should write your functions and methods to be open to extend later, but be careful trying to guess what the future holds for your codebase. Adhering to the interface segregation principle is definitely a balancing act, as it’s possible to go too far with abstractions and have a ridiculous number of objects and methods. This, ironically, causes the same problem: added complexity without a payoff. There’s no hard rule to keep this in check—it’s going to depend on your app, your data, and your team. But there’s no shame in keeping things simple if making them complex does not help you. In fact, that’s usually the best route to go. The open/closed principle Many younger developers don’t remember the days before web standards changed development. (Thanks, Jeffrey Zeldman, for making our lives easier!) It used to be that whenever a new browser was released, it had its own interpretation of things, and developers had to scramble to find out what was different and how it broke all of their websites. There were articles and blog posts written quickly about new browser quirks and how to fix them, and developers had to drop everything to implement those fixes before clients noticed that their websites were broken. For many of the brave veterans of the first browser war, this wasn’t just a nightmare scenario—it was part of our job. As bad as that sounds, it’s easy for our code to do the same thing if we’re not careful about how we modify it. The   states that software entities (classes, modules, functions, etc.) should be open for extension but closed for modification. In other words, your code should be written in such a way that it’s easy to add new functionality while you disallow  changing existing functionality. Changing existing functionality is a great way to break your app, often without realizing it. Just like browsers rely on web standards to keep new releases from breaking our sites, your code needs to rely on its own internal standards for consistency to keep your code from breaking in unexpected ways. Let’s say your codebase has this function: A pretty simple function. But then, there’s a new use case where you need just the last name.   should you modify the above function like so: That solves your new problem, but it modifies existing functionality and will break every bit of code that was using the old version. Instead, you should extend functionality by creating a new function: Or, if we want to make it more flexible: This is a simple example, but it’s easy to see how modifying existing functionality can cause major problems. Even if you’re able to locate every call to your function or method, they all have to be tested—the open/closed principle helps to reduce testing time as well as unexpected errors. So what does this look like on a larger scale? Let’s say we have a function to grab some data via an   and do something with it: That’s great if you’re always going to be doing the same thing with that data. But how many times does that happen? If we do   with that data, coding the function that way means we’ll need another function to do almost the same thing. What would work better would be to code our request function to accept a callback function as an argument: With the function coded this way, it’s much more flexible and useful to us, because it’s easy to add in new functionality without modifying existing functionality. Passing a function as a parameter is one of the most useful tools we have in keeping our code extensible, so keep this one in mind when you’re coding as a way to future-proof your code. Keeping it clear Clever code that increases complexity without improving clarity helps nobody. The bigger our apps get, the more clarity matters, and the more we have to plan to make sure our code is clear. Following these guidelines helps improve clarity and reduce overall complexity, leading to fewer bugs, shorter timelines, and happier developers. They should be a consideration for any complex app. Thanks A special thanks to Zell Liew of   for lending his technical oversight to this article. Learn JavaScript is a great resource for moving your JavaScript expertise from beginner to advanced, so it’s worth checking out to further your knowledge! Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/conversational-semantics/", "title": "Conversational Semantics", "content": "As Alexa, Cortana, Siri, and even customer support chat bots become the norm, we have to start carefully considering not only how our content looks but how it could sound. We can—and should—use HTML and ARIA to make our content structured, sensible, and most importantly, meaningful. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Content, confined Most bots and digital assistants work from specially-coded data sets, APIs, and models, but there are more than 4.5 billion pages of content on the web, trapped, in many cases, within our websites. Articles, stories, blog posts, educational materials, books, and marketing messages—all on the web, but in many cases unusable in a non-visual context. A few projects—search spiders most notably—are working to turn our messy, unstructured web pages into something usable. But we can do more—a lot more—to facilitate that and enable our web pages to be more usable by both real people and the computers that power voice-based user experiences. Let’s release our content from the screen and empower it to go anywhere and everywhere. We can help it find its way into virtual assistants and other voice-response technologies—and even voiceless chat bots—without having to code and re-code that content over and over into multiple, redundant formats. We can even enable our users to actively engage with our content by filling in forms and manipulating widgets on the web purely via voice. It’s all possible, but we need to start by taking a long, hard look at our markup. Consider this   element: Sure, it is visually   as italics, but it also adds emphasis to the content within. HTML is chock full of elements that are useful for conveying meaning, nuance, and relationships. Being aware of them enables us to author more expressive documents. Ignoring them can undermine the usability of the content we’re marking up. When we create a web page, we need to be mindful of the conversation we are creating with our customers in the process, and choose elements with intent and care. One of the best indicators for how HTML will make it into our virtual assistants is another assistive technology:  . Not only do screen readers do as their name implies, they also enable users to rapidly navigate a page in various ways, and provide mechanisms that translate visual design constructs—proximity, proportion, etc.—into useful information. At least they do when documents are authored thoughtfully. So, let’s jump in and look at some solid examples of how we can both create more meaningful documents and empower them to be more usable in “headless” UIs. Powerful phrases We’ll start by looking at what are called “phrasing” elements. The emphasis you saw earlier is an example of this element type. We used to call them “inline” elements because, by default, they are visibly displayed as inline text. But “phrasing” is a much more accurate description of the role they play in our web pages, because, well, they mark up phrases. We saw this example earlier: Here, the word “really” is marked for emphasis. I’m unaware of any current speech synthesizer that audibly emphasizes text like we do, but it’s still early days in the grand scheme of things. I’m sure it’ll happen—there’s been a lot of focus on building more human-sounding voices—and it could sound something like this: Your browser doesn’t support HTML5 audio, but you can   instead. Sometimes emphasis is not enough. When we want to indicate that content is vital for our customers to pay attention to, the   element is the right way to go. “Strong” means “of strong importance.” Visually,   and   are displayed as italics (as mentioned previously) and bold, respectively. Now we also have the   and   elements, which are rendered exactly the same as   and  , respectively. In the early days of the web, that led many of us—myself included—to believe they were interchangeable. And with   and   being shorter to write, they proliferated on the web. Semantically, however, the   and   elements are quite different from their doppelgängers. The   element is similar to the emphasis element, but more generic. It is used to indicate an alternate voice or mood. It could be used to indicate sarcasm, idiomatic remarks, and shifts in language. In the latter example, you might also notice that I’ve indicated that the phrase “joie de vivre” is in another language—French—using the   attribute. This attribute lets the digital assistant know it may want to shift its pronunciation. Your browser doesn’t support HTML5 audio, but you can   instead. Admittedly, replicating this   is still a little rough, but with time, this too will no doubt improve. The   element is used for content that should be set apart—or “stylistically offset”—from the surrounding text. It does not indicate that the phrase is of any greater importance though. I like to use it for names of people and products. Keywords would be another option. Books, films, and other media have their own element, which I’ll get to in a moment. Functionally, the   element is a lot like a  —generic phrasing content albeit with a shorter tag. Since I mentioned movies and books, I’ll quickly bring up the   element, which is for the title of cited or referenced works. Specialized syntax HTML has other specialized phrasing constructs, such as   for abbreviations and acronyms. Traditionally, we’d recommended using title to provide an expansion: Sadly—as with many things on the web—  spurred screen readers to ignore the attribute altogether. Visual browsers do still provide tooltips, so they’re not completely useless, but given that screen readers don’t pay attention to the   attribute currently, it’s pretty unlikely they will be surfaced by a virtual assistant. To be honest,  . For the purposes of absolute clarity, you should introduce and explain important abbreviations and acronyms the first time they are used. There’s even  . For more technical writing, the   and   elements can be quite useful. They indicate keys a user might need to press and words and phrases that are used in writing software or coding documents: Then there’s the   element, which is used for generic phrases, as I noted earlier. It’s a meaningless element, so will not be spoken in any way differently by default. There are  , but these are the ones you’re most likely to want in most projects. Clear connections Links are also phrasing elements, but I want to call them out specifically because they provide a much richer set of options for fine-tuning how our users interact with our pages. The primary way we use links is to connect related content. It’s incredibly important to choose meaningful words and phrases as link text. Links that read generically like “click here” and “read more” are not terribly useful, especially when the text of every link is being read out to you—which is a key way headless UI users skim web pages. Make it clear where you are linking. Restructure sentences if you need to in order to provide good link text. If you are drawn to “read more” style links for their brevity, you can   by including non-visible text within a link. This gives you brief, uniform links from a visual standpoint, but also lets you provide context in headless scenarios. Here’s an example from   navigation. I’ve broken it up across a few lines to make it a little easier to follow: Within the link, I have two   elements classified as “hidden.” In my CSS, I hide the content within them from sighted users, but I  . So a sighted user will only see “speaking,” but a screen reader or digital assistant will read “a list of my speaking engagements.” You could also   on the anchor element. If that “aria-” bit in   looks weird to you, it comes from the Accessible Rich Internet Applications (ARIA) spec,  . I chose the hidden text route to give myself the flexibility to display the hidden content in certain scenarios. Some of you may be wondering why I didn’t bring up   when I mentioned the   element. It seems like a good fit, and   currently allows the attribute on   elements. The issue isn’t the spec, but rather the reality that the info in   isn’t always exposed by browsers or sought out by assistive technology on elements like  . With good reason, they’ve been much more  . It’s worth noting that hidden text in links can cause issues for folks who rely on a combination of screens and dictation software to interact with their computers. If the link text that’s displayed does not match the actual link text in the markup, a user saying the visible link text—like the word “Speaking” in the case of my site’s navigation—won’t actually activate the link. It’s also worth reiterating the importance of quality link text; don’t use   to paper over poorly-worded links or unnecessary redundancy like “read more.” We can also use links to reference content within the current document or even at a specifically-identified position in another document: At the tail end of this code sample, we have a   element that is referenced elsewhere in the document. Rather than leaving it up to the reader to find “Figure 3.3,” we can use a fragment identifier to jump the reader directly to the reference. Adding a unique id attribute to each important element in your design makes it easy for you—or others—to link directly to them. As with the   element example I shared earlier, you can inform your readers about the language of a linked page using  : That’s Spanish for “read this page in Spanish,” and the link points to a Spanish-language translation of the page. The hidden content approach is in use here, too, with sighted users only seeing “español.” You can indicate the kind of content being linked to, using the   attribute: And we also have the   keyword, which informs the browser that the file in question should be downloaded rather than presented. Again, a simple attribute that makes a simple HTML document capable of doing so much more: When encountering this type of link in a voice context, your digital assistant could prompt you to save the file to a connected storage account, like Dropbox. That’s pretty cool, but it’s worth noting that browsers will ignore the   attribute on cross-origin links for security purposes. Unfortunately that means you can’t use this approach to download files from your Content Delivery Network (CDN). Anchor elements also support non-web “pseudo” protocols. Two of the most common examples are “mailto:” for email links and “tel:” for phone numbers, but “sms:” and “webcal:” are also common. Some operating systems (and browsers) allow installed apps to register custom protocols that can provide access to in-app functionality. A word of caution though: unrecognized protocols may prompt the user to search for an application that can use it. All of this phrasing content is great, but I’ve spent a good deal of time in the weeds. Let’s pull back a bit and look at documents themselves. Sound structure As you’re no doubt aware,  . It’s hard to keep track of where you are in an interface when you can’t see it. It can also be challenging to move around when you can’t gather information about the interface based on visual cues. The more complex an interface is, the more challenging this becomes. The same is true in visual interfaces, which is why   encourages us to focus each page on a single task. This reduces the noise and raises the signal. But most web pages are the antithesis of clear and straightforward. As our screen sizes enlarged, we found more stuff to fill that space. Sharing links, related content, cross-promotions, and so on. Sometimes it’s easy to lose sight of the actual content. To combat this, screen readers provide  . One of the most common involves moving the focus carat from one interactive element to another. Traditionally that movement is done via the keyboard Tab key, but it’s also possible via voice using keywords like “next” and “previous.” In most documents, users are moving from link to link. This is why it’s so important to offer informative link text. It’s worth noting that form elements—buttons, inputs, etc.—are also part of the default tab order of a web page. Elements that would not traditionally be focusable can be included in the tab order by adding a   attribute with a value of “0” (zero) to them. This ensures critical interface components are not accidentally bypassed by users who are skimming an interface by tabbing. Incidentally, it can also  . Another mode of document traversal is browsing by heading. The various   create a natural document outline, and assistive technologies can enable users to skim content using these headings: Since only the contents of the heading elements are read out in this mode, it’s best to avoid cutesy marketing phrases, and stick to summarizing the contents of a section. More recently,   have come along, providing quick access to key parts of the page. Landmark elements were first introduced as part of ARIA. Using the   attribute, you can define the function of specific regions of a page. Consider the following: In this example, the navigation list is sitting in a   with an   of “nav.” While that’s a meaningful identifier for the purposes of styling, scripting, and anchoring, the   is not actually exposed to assistive technology as navigation. Adding a   of “navigation”, however, makes that function explicit: There are numerous role values that qualify as landmarks: banner navigation search main complementary contentinfo Landmarks also give users the opportunity to jump directly to a location within an interface, which is incredibly helpful. In a voice context, a user might be able to ask their digital assistant to “read me the navigation for this page” or “search for wooden baby toys,” and the assistant could use these landmarks to quickly respond to those commands. It’s worth noting that most of these landmarks have equivalent HTML elements. This is because HTML5 and ARIA were being developed at the same time, and both were looking to address the same limitations of the web. Here’s a rundown of ARIA landmark roles with HTML equivalents: banner – first   element not inside  navigation –  main –  complementary –  contentinfo – first   element not inside  Each HTML5 element shown here is automatically assigned its corresponding ARIA   by modern browsers and is recognized by modern assistive technologies. However, in older browser and assistive technology combinations, the automatic role assignment may not happen. That’s why it’s not uncommon to see   elements with a “navigation”   or similar even though validators will flag it as unnecessary. One last bit I want to touch on before I wrap up is the   element. We often employ a   when we want to group some elements together. That’s fine, but   is a meaningless element that adds nothing to the interface in terms of context. By contrast, other organizational elements do add value to a page:  – a paragraph; a voice synthesizer will naturally pause between them  – a list of items whose order matters  – a list of items whose order doesn’t matter  – an item in a list  – a list of terms and their associated descriptions  – a term described within a description list  – a description of a term (or terms) in a description list  – a long piece of quoted content  – referenced content (images, tables, etc.)  – the caption for a figure Some of these are among the elements categorized as  . At a higher level, there are numerous organizational elements to choose from:  – a piece of content that can stand on its own  – a section of a document or article  – preamble content for a document, article, or section  – supplementary information for a document, article, or section  – the primary content of a document  – navigational content  – complementary content There are a ton of meaningful elements out there that can enable our digital assistants to do more for our customers. And the more we use them, the more useful our assistants become, and the more powerful our users feel. For instance, using   and heading elements can enable voice commands like “Read me the top three headlines in the   today” without involving any sort of specialized data feed. A generic   gets you none of these benefits. Create conversations HTML is a truly robust and expressive language that is often overlooked and undervalued, but it has the incredible potential to nurture conversations with our users without requiring a lot of effort on our part. Simply taking the time to code web pages well will enable our sites to speak to our customers like they speak to each other. Thinking about how our sites are experienced as headless interfaces now will set the stage for more natural interactions between the real world and the digital one. Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/design-with-difficult-data/", "title": "Design with Difficult Data", "content": "You’ve been asked to design a profile screen for a mobile or web app. It will need to include an avatar, a name, a job title, and a location. You fire up Sketch or Figma. Maybe you pull out your drafting pencil or head straight to markup and CSS. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What’s your go-to fake name? Regardless of your choice in tools, you’re probably going to end up with some placeholder data. Are you the type that uses your own name, or do you conjure up your old friend,  ? Maybe you have a go-to fake name, like  . For me, it’s  . Or  , more formally. Nuno played guitar in the subtly-named early 90s band Extreme. To the younger among you, he was a touring musician with Rihanna. None of that matters for our purposes here today, except that he has a fairly long name. It may not seem like it matters what you put in for a placeholder name. It won’t end up in the final product—it’s just a variable. Well, it does matter.   It may limit the scope of options you allow yourself to consider, or more dangerously, obscure actual limits that you’ll run into later. A few obvious solutions may spring to mind: use a long placeholder name; use real data in your design. While these are a good start, it’s worth exploring more deeply how these and other practices can both improve your design process and help produce more durable products. It’s more than just fake names This is about more than just fake names. It’s also fake addresses! Fake headlines! Fake photos! When we design around limited data, the limitations bleed into our designs. The inability to deal with long strings of text is the most basic and maybe most common way components can fail when coming in contact with real data. You thought the tab would be labelled “Settings”? Well, now it’s called “Application Preferences.” Oh, and the product launches tomorrow. Length is just one of many ways that real text and data can strain a weak design. You may also encounter unanticipated line-breaks or even text that’s too short. Beware of the following areas where we tend to cheat with easy placeholder data. Account profile photos Don’t expect people to have a studio quality self-portrait with a solid white background (and be suspicious of those who do!). Many people may not be interested in uploading a photo for their account at all. Others may try to squeeze in their much-too-wide company logo into that little square or circular area. You can’t account for all possible data, but if you incorporate some of these less-than-visually-ideal cases early in your design process, your output will be that much more resilient. Thumbnails for videos and photos Not all thumbnails will be in the aspect ratio you’ve anticipated. Some might include text or images that clash unexpectedly with the surrounding page. A common issue I’ve seen is a nicely designed home page with a company logo prominently displayed at the top. Then, the video arrives and the default poster image for the video also includes the company logo. Now your beautiful home page layout looks like a logo salad. Wild variations in amounts Watch for elements containing lists where the amount of items in those lists may vary significantly. Imagine a layout with cards where each card includes a set of tags. One card may have three tags while another may have twenty-five. Tabular data can also suffer both aesthetically and in legibility when one particular cell varies wildly in length from the others. Missing elements You may create a nice layout for your site header that scales beautifully from your phone to your 27” display. Then you discover it needs a Support menu item—but there’s no room! I often start a wireframe by compiling two lists. The first contains the goals a visitor to this screen needs to accomplish. The second has the elements that need to live on this screen. Be sure to include all of the elements—from the primary content to advertisements, and down to a privacy link in the footer. It’s particularly easy to spot a site that was designed without accounting for the advertisements it includes. Viewport sizes Beyond placeholder data, we have a tendency to present our designs at the most flattering viewport sizes. Or rather, we design our layouts to look best at the sizes we choose for our mockups—particularly when we design with tools built around fixed frame sizes. In the neglected troughs of responsive design, we find two common pitfalls: the stretched mobile layout and the squished desktop design layout. Flexible design can be more accessible design We can’t spend endless amounts of our time (and our clients’ money) on every edge case imaginable. We can be more mindful of the influence of the canvas on which we create, the tools we use, and the data we design around. It’s necessary to focus attention and testing on the ways in which your site will most commonly be accessed. Things don’t have to be, and never will be, perfect at every screen size.   and embracing this fluidity is part of designing for the web. Designing with flexibility can also make your design more accessible. Those with vision impairments (which is most of us at some point in our lives) may browse with a customized minimum font size. Others may browse at a zoom level that triggers responsive layouts intended for mobile devices even on a large desktop browser. Avoid the disappointing reveal There are enough factors that can already contribute to clients and stakeholders having unrealistic expectations and being disappointed by the eventual implementation. Don’t add to this potential mismatch of expectations by showing designs that look flawless, only to have the client review them in the harsh light of real data. While you may need to convince people of the merits of your design, you’ll only set yourself up for failure if you choose to showcase an unrealistic design. Instead, indulge initially by showing the layout with ideal data   show how durable and flexible the design is by showing variations with difficult data. This not only helps people understand your design but also the value of your process and expertise. When I was a kid, I distinctly remember a door-to-door vacuum salesman jumping on a vacuum cleaner to demonstrate the durability of his product. We didn’t need a new vacuum (the immediate flaw in the whole door-to-door model), but the image stuck with me. Jump on your designs! Throw them against the wall! Fill them with garbage and show how well they hold up. For example, when showing a design to a client, show them how it adapts to various viewport widths and default font sizes. Showing a client how their site responds to browser sizes can also help them let go of the need to polish designs solely for the particular device and size they happen to use. If you’ve got a robust way of dealing with long names on a profile page, show it off! This can help your client understand that there is a whole other dimension of work (and time, and money) beyond what’s visible in a static screenshot. Garbage in, gold out? The old computer science adage reads, “garbage in, garbage out.” Instead, aim for “garbage in, hrm … not bad.” A better adage to lean on may be  : “Be conservative in what you do, be liberal in what you accept from others.” If you imagine your evil twin trying to pick apart your design, how would they break it? Maybe squish the browser to a narrow size, and enter some unusually long headlines (garbage in). Your design should respond nicely to the narrow width, and gracefully reduce the font size of particularly long headlines (gold out). With practice, you can internalize some of this process. You’ll come to know instinctively what pitfalls come with a given visual design. Much in the same way experts in accessibility or internationalization learn to quickly spot the common pitfalls that limit the universality of designs. While our intuition can help us, it can also trick us—be sure to test, and see how real people work with your product. Even as you do hone your ability to anticipate and avoid common mistakes, your mind will constantly be pulling toward the path of least resistance. Like endurance athletes training at high altitudes, exercising with ankle weights, or the pro baseball player taking practice swings with a weighted bat, we must continue to artificially increase the strain on our work. Real data isn’t good enough Much has been written on the benefits of designing with real data. My colleague  : Try not to gloss over complexity. Design work in the real world is pretty hard. If you design a fake graph, put in realistic data. If you fake redesign a site, … don’t just magically remove an ad unit. If you create a sexy fake login screen, don’t forget to include a way to recover lost passwords or usernames. … Write real copy. Lorem ipsum is for amateurs. Daniel is right—especially when it comes to interface elements where the meaning of the text is inextricable from the function. When it comes to design elements that may display widely variable contents (profile photos or names, for example), you can do better than using real data. Go beyond realistic data. Get   data. If you are able to pull in real data, dig through it for the worst cases. If you can handle the worst, the common cases will be a breeze. When redesigning an existing screen, take advantage of the current and historical data available. Dig into the extremes of the data, finding the longest and shortest titles. If you’re designing with thumbnails of photos or videos, grab a random set of real thumbnails and throw away those you know are easy to design around. When you don’t have existing data, and even when you do, create difficult examples. Write headlines that push up to and beyond the limits of what the screen can accommodate. Create thumbnail images that have their own built-in border or shadow, and see how they clash with what you’ve got in place. Sometimes difficult data can (and should) be fixed While your design should be as robust as possible, you may sometimes turn up edge cases that needn’t be so. In designing a list page with a client, we looked at their complete archive of data to see how the length of the item titles varied. The shortest title was 8 characters, and the longest was over 320, but only a handful were over 80. We worked with the client to create a design that catered to the maximum 80-character titles. Some editorial surgery was then performed on those few outliers to get them in under the limit. They ended up being better titles as a result. When dealing with content that is managed by your company, team, or client, it is also worth codifying the practices into a style guide. You needn’t spend all of your energy designing around difficult data that’s coming from down the hall. Internationalization I’ve had the privilege of working with teams at Mozilla, where pages are translated into as many as eighty languages. With such broad localization efforts, we learned to build page layouts and designs that supported both non-Latin character sets and languages with right-to-left text direction. Supporting both left-to-right and right-to-left languages requires more than just allowing text strings to reverse. The entire visual structure of your layout and design needs to be able to flip horizontally. Rather than being a frustrating limitation, you’ll find this and other similar constraints will help you develop design superpowers. In anticipation of the longer text strings in languages like German, some designers developed a process where Latin text is generated at twice the length of the source text. The W3C has a  . Capitalization can also be problematic in some locales—especially when forced with CSS. If your design really relies on   or  , either revisit the design to be more flexible, or handle capitalization in the source text (rather than via CSS) so a localization team can maintain control over capitalization. MDN is a great resource for more on  . Beware of your own cultural blindness when it comes to placeholder data during the design process. Design cheating often affects those least like yourself. Whenever possible, design with   data Much has been written (and should be read) about how our  . With modern design and prototyping tools, HTML/CSS/JS prototypes, and even static mockups, we only cheat ourselves if we aren’t pushing our designs to the breaking point. There’s always a balance to strike between making something quick and over-building. As with all things in design and on the web,  . It depends on the data, the audience, the project, and the goals. Schedule and budget are the common excuses for not delivering more robust design components. Especially on larger projects, though, learning to incorporate more difficult data into your early design process can save you time in the long run. Like that long-distance runner who improves by training in the thin air of high altitudes, by building with difficult data from the very beginning, you’ll become a stronger designer. You’ll be more aware of where and how your design may break, and be better able to communicate your process and decisions. Like this: \n\t\t\t\t\t\t\tRecently by  Steven Garrity\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/breaking-the-deadlock-between-user-experience-and-developer-experience/", "title": "Breaking the Deadlock Between User Experience and Developer Experience", "content": "In early 2013,   of all web traffic came from mobile devices; today, that number has grown  . In other parts of the world the difference is even more staggering: in African countries,  ; in India,   of traffic is mobile. This is a big deal, because     in 2017 lived  . Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. And while internet connections are getting faster, there are still dozens of countries that access the web at  . Even in developed nations, people on mobile devices see spotty coverage, flaky wifi connections, and coverage interruptions (like train tunnels or country roads).  A Google study found that  —and none of us are willing to lose half our traffic, right? User experience and performance are already aligned—in theory User experience designers and researchers lay a solid foundation for building modern web apps. By thinking about who the user is, what they’re trying to accomplish, and what environments they might be in when using our app, we already spot several performance necessities: a commuter, for example, will be accessing the app from their phone or a low-speed public wifi connection with spotty coverage. For that type of user, we know to focus on a fast load time—remember, three seconds or more and we’ll lose half our visitors—in addition to an experience that works well, even on unstable connections. And since downloading huge files will also take a long time for this user, reducing the amount of code we ship becomes necessary as well. UX and performance have issues in practice My sister   dogs. Once, as a kid, she attack-hugged our dog and loved it so hard that it panicked and bit her. The web community’s relationship with UX is not unlike my sister’s with dogs: we’re trying   to love our users that we’re making them miserable. Our efforts to measure and improve UX are packed with tragically ironic attempts to love our users: we try to find ways to improve our app experiences by bloating them with analytics, split testing, behavioral analysis, and Net Promoter Score popovers. We stack plugins on top of third-party libraries on top of frameworks in the name of making websites “better”—whether it’s something misguided, like   to appease some executive’s burning desire to get everything “above the fold,” or something truly intended to help people, like a support chat overlay. Often the net result is a slower page load, a frustrating experience, and/or (usually “and”) a ton of extra code and assets transferred to the browser. The message we appear to be sending is, “We care so much about your experience as a user that we’re willing to grind it to a halt so we can ask you about it, and track how you use the things we build!” Making it worse by trying to make it better We’re not adding this bloat because we’re intentionally trying to ruin the experience for our users; we’re adding it because it’s comprised of tools that solve hard development problems, and so we don’t have to reinvent the wheel. When we add these tools, we’re still trying to improve the experience, but we’ve now shifted our focus to a different user: developers. There’s a large ecosystem of products and tools aimed toward making developers’ lives easier, and it’s common to roll up these developer-facing tools under the term  , or  . Stacking tools upon tools may solve our problems, but it’s creating a Jenga tower of problems for our users. This paradox—that the steps we take to make it easier to help our users are inadvertently making the experience worse for them—leads to what Nicole Sullivan calls a “deadlock between developer experience [and] user experience.” Developer experience goes beyond the tech stack Let’s talk about cooking experience (CX). When I’m at home, I enjoy cooking. (Stick with me; I have a point.) I have a cast-iron skillet, a gas range, and a prep area that I have set up just the way I like it. And if you’re fortunate enough to find yourself at my table for a weekend brunch, you’re in for one of the most delicious breakfast sandwiches of your life. However, when I’m traveling, I   cooking. The cookware in Airbnbs is always cheap IKEA pans and dull knives and cooktops with uneven heat, and I don’t know where anything is. Whenever I try to cook in these environments, the food comes out edible, but it’s certainly not great. It might be tempting to say that if I need my own kitchen to produce an edible meal, I’m just not a great cook. But really, the high-quality tools and well-designed environment in my kitchen at home creates a better CX, which in turn leads to my spending more time focused on the food and less time struggling with my tools. In the low-quality kitchens, the bad CX means I’m unable to focus on cooking, because I’m spending too much time trying to manage the hot spots in the pan or searching the drawers and cabinets for a utensil. Good developer experience is having the freedom to forget Like in cooking, if our development tools are well-suited to the task at hand, we can do excellent work without worrying about the underlying details. When I wrote my first lines of HTML and CSS, I used plain old Notepad. No syntax highlighting, autocorrect, or any other assistance available. Just me, a reference book, and a game of   to find the tag I’d forgotten to close. The experience was slow, frustrating, and painful. Today, I use an editor that not only offers syntax highlighting but also auto-completes my variable names, formats my code, identifies potential problems, helps me debug my code as I type, and even lets me   with a coworker to get help debugging a problem. An enormous number of incremental improvements now exist that let us forget about the tiny details, instead letting us focus on the task at hand. These tools aim to  , leading developers to follow best practices by default because our tools are designed to do the right thing on our behalf. It’s hard to overstate the impact on my productivity that modern development environments have made. And that’s just my editor. UX and DX are at odds with each other There is no one-size-fits-all way to build an app, but most developer tools are built with a one-size-fits-all approach. To make this work, most tools are built to solve   in a general purpose way, such as date management or cryptography. This, of course, necessitates stacking multiple tools together to achieve our goals. From a DX standpoint, this is amazing: we can almost always find an open source solution to problems that aren’t ultra-specific to the project we’re working on. However, stacking a half-dozen tools to improve our DX harms the UX of our apps. Add a few kilobytes for this tool, a few more for that tool, and before we know it we’re shipping mountains of code. In today’s front-end landscape, it’s not uncommon to see apps shipping multiple megabytes of JavaScript—just open the Network tab of your browser’s developer tools, and softly weep as you notice your favorite sites dump buckets of JavaScript into your browser. In addition to making pages slower to download, scripts put strain on our users’ devices. For someone on a low-powered phone (for example, a cheap smartphone, or an older iPhone), the download time is only the first barrier to viewing the app; after downloading, the device has to parse all that JavaScript. As an example, 1 MB of JavaScript takes roughly   on a Samsung Galaxy Note II. On a 3G connection, adding 1 MB of JavaScript can mean adding ten or more seconds to your app’s download-and-parse time. That’s   UX. Patching the holes in our UX comes at a price Of course, we can solve some of these problems. We can manually optimize our apps by loading only the pieces we actually use. We can find lightweight copies of libraries to reduce our overall bundle size. We can add performance budgets, tests, and other checks to alert us if the codebase starts getting too large. But now we’re adding audits, writing bespoke code to manage the foundation of our apps, and moving into the uncharted, unsupported territory of wiring unrelated tooling together—which means we can’t easily find help online. And once we step outside the known use cases for a given abstraction, we’re on our own. Once we find ourselves building and managing bespoke solutions to our problems, many of the DX benefits we were previously enjoying are lost. Good UX often necessitates bad DX There are a number of frameworks that exist to help developers get up and running with almost no overhead. We’re able to start building an app without first needing to learn all the boilerplate and configuration work that goes into setting up the development environment. This is a popular approach to front-end development—often referred to as “zero-config” to signify how easy it is to get up and running—because it removes the need to start from scratch. Instead of spending our time setting up the foundational code that doesn’t really vary between projects, we can start working on features immediately. This is true, in the beginning, until our app steps outside the defined use cases, which it likely will. And then we’re plunged into a world of configuration tuning, code transpilers, browser polyfills, and development servers—even for seasoned developers, this can be extremely overwhelming. Each of these tools on its own is relatively straightforward, but trying to learn how to configure a half-dozen new tools   is a very real source of fatigue and frustration. As an example, here’s how it feels to start a JavaScript project from scratch in 2018: install Node and npm; use npm to install Yarn; use Yarn to install React, Redux, Babel (and 1–5 Babel plugins and presets), Jest, ESLint, webpack, and PostCSS (plus plugins); write configuration files for Babel, Jest, ESLint, webpack, and PostCSS; write several dozen lines of boilerplate code to set up Redux; and finally start doing things that are actually related to the project’s requirements. This can add up to entire days spent setting up boilerplate code that is nearly identical between projects. Starting with a zero-config option gets us up and running   faster, but it also immediately throws us into the deep end if we ever need to do something that isn’t a standard use case. And while the open source developers who maintain these abstractions do their best to meet the needs of everyone, if we start looking at improving the UX of our individual apps, there’s a high likelihood that we’ll find ourselves off the beaten path, buried up to our elbows in Byzantine configuration files, cursing the day we chose web development as a career. Someone always pays the cost On the surface, it might look like this is just the job: web developers are paid to deliver a good UX, so we should just suck it up and suffer through the hard parts of development.  Unfortunately, this doesn’t pan out in practice. Developers are stretched thin, and most companies can’t afford to hire a specialist in accessibility, performance, and every other area that might affect UX. Even a seasoned developer with a deep understanding of her stack would likely struggle to run a full UX audit on every piece of an average web app. There are too many things to do and never enough time to do it all. That’s a recipe for trouble, and it results in things falling through the cracks. Under time pressure, this gets worse. Developers cut corners by shipping code that’s buggy with   attached. They de-prioritize UX concerns—for example, making sure screen reader users can, you know, read things—as something “to revisit later.” They make decisions in the name of hitting deadlines and budgets that, ultimately, force our users to pay the cost of our DX. Developers do the best they can with the available time and tools, but due more to a lack of time and resources than to negligence, when there’s a trade-off to be made between UX and DX, all too often the cost rolls downhill to the users. How do we break the deadlock between DX and UX? While it’s true that someone always pays the cost, there are ways to approach both UX and DX that keep the costs low or—in best-case scenarios—allow developers to pay the cost once, and reap the DX benefits indefinitely without any trade-offs in the resulting UX. Understand the cost of an outstanding user experience In any given project, we should use the ideal UX as our starting point. This ideal UX should be built from user research, lo-fi testing, and an iterative design process so we can be sure it’s actually what our users want. Once we know what the ideal UX is, we should start mapping UX considerations to technical tasks. This is the process of breaking down abstract concepts like “feels fast” into concrete metrics: how can we measure that a UX goal has been met? By converting our UX goals into measurable outcomes, we can start to get an idea of the impact, both from a UX and a DX perspective. From a planning perspective, we can get an idea of which tasks will have the largest impact on UX, and which will require the highest level of effort from the developers. This helps us understand the costs and the relative trade-offs: if something is high-effort and low-impact, maybe it’s OK to let the users pay that cost. But if something will have a high impact on UX, it’s probably not a good idea to skip it in favor of good DX. Consider the cost when choosing solutions Once we’re able to understand the relative cost and trade-offs of a given task, we can start to analyze it in detail. We already know how hard the problem is to solve, so we can start looking at the   of solving it. In general terms, there are three major categories of solving problems: Invent your own solution from scratch. Research what the smartest people in the community are doing, and apply their findings to a custom solution. Leverage the collective efforts of the open source community by using a ready-made solution. Each category comes with trade-offs, and knowing whether the costs outweigh the benefits for any given problem requires working through the requirements of the project. Without a clear map of what’s being built—and what it will cost to build it—any decisions made about tools are educated guesses at best. When to invent your own solution Early in my stint as a front-end architect at IBM, I led a project to   for front-end teams to rapidly build apps in our microservice-based architecture. We started with open source tools, but at the time nothing existed to solve the particular challenges we were facing. We ended up building  , which we open sourced in late 2017, to scratch our particular itch. In this situation, building something custom was our lowest-cost option: we knew that GraphQL would solve a critical problem for us, but no tools existed for running GraphQL in a microservice architecture. The cost of moving away from microservices was prohibitively high, and the cost of keeping things the way they were wasn’t manageable in the long term. Spending the time to create the tooling we needed paid dividends through increased productivity and improved DX for our teams. The caveat in this story, though, is that IBM is a rare type of company that has deep pockets and a huge team. Letting a team of developers work full-time to create low-level tooling—tools required just to   working on the actual goal—is rarely feasible. And while the DX improved for teams that worked with the improved data layer we implemented, the DX for our team as we built the tools was pretty rough. Sometimes the extra effort and risk is worth it long-term, but as Eric Lee says, every line of code you write is a  . Before choosing to roll a custom solution, give serious thought to whether you have the resources to manage that liability. When to apply research and lessons from experts in the field A step further up the tooling ladder, we’re able to leverage and implement the research of industry experts. We’re not   solutions anymore; we’re   the solutions designed by the foremost experts in a given field. With a little research, we have access to industry best practices for accessibility thanks to experts like   and  ; for web standards via   and  ; for performance via   and  . By leveraging the collective knowledge of the web’s leading experts, we get to not only learn what the current best practices are but also become experts ourselves by implementing those best practices. But the web moves fast, and for every solution we have time to research and implement, a dozen more will see major improvements. Keeping up with best practices becomes a thankless game of whack-a-mole, and even the very best developers can’t keep up with the entire industry’s advancements. This means that while we implement the latest techniques in one area of our app, other areas will go stale, and technical debt will start to pile up. While learning all of these new best practices feels really great, the DX of implementing those solutions can be pretty rough—in many cases making the cost higher than a given team can afford. Continued learning is an absolutely necessary part of being a web developer—we should always be working to learn and improve—but it doesn’t scale if it’s our   approach to providing a great UX. To paraphrase  , we have to look at the trade-offs, and we should make the decision that improves the team’s DX. Our goal is to make the team more productive, and we need to know where to draw the line between understanding the down-and-dirty details of each piece of our app and shipping a high-quality experience to our users in a reasonable amount of time. To put it another way: keeping up with industry best practices is an excellent tool for weighing the trade-offs between building in-house solutions or using an existing tool, but we need to make peace with the fact that there’s simply no way we can keep up with everything happening in the industry. When to use off-the-shelf solutions While it’s overwhelming to try and keep up with the rapidly changing front-end landscape, the ever-evolving ecosystem of open source tools is also an incredible source of prepaid DX. There are dozens of incredibly smart, incredibly passionate people working to solve problems on the web, and many of those solutions are open source. This gives developers like you and me unprecedented access to prepaid solutions: the community has already paid the cost, so you and I can deliver an amazing UX without giving up our DX. This class of tooling was designed with both UX and DX in mind. As best practices evolve, each project has hundreds of contributors working together to ensure that these tools are always using the best possible approach. And each has generated an ecosystem of tutorials, examples, articles, and discussion to make the DX even better. By taking advantage of the collective expertise of the web community, we’re able to sidestep all the heartache and frustration of figuring these things out;  . We can enjoy a dramatically improved DX, confident that many of the hardest parts of creating good UX are taken care of already. The trade-off—because there is always at least one—is that we need to accept and work within the assumptions and constraints of these frameworks to get the great DX. Because again, as soon as we step outside the happy path, we’re on our own again. Before adopting   solution—whether it’s open source, SaaS, or bespoke—it’s important to have a thorough understanding of what we’re trying to accomplish and to compare and contrast that understanding to the goals and limitations of a proposed tool. Otherwise we’re running a significant risk: that today’s DX improvements will become tomorrow’s technical debt. If we’re willing to accept that trade-off, we find ourselves in a great position: we get to confidently ship apps, knowing that UX is a first-class consideration at every level of our stack, and we get to work in an environment that’s optimized to give our teams an incredible DX. Deadlock is a (solvable) design problem It’s tempting to frame UX and DX as opposing forces in a zero-sum game: for one to get better, the other needs to get worse. And in many apps, that certainly appears to be the case. DX at the expense of UX is a design problem. If software is designed to make developers’ lives easier  , it’s no wonder that problems arise later on. If the user’s needs aren’t considered at the core of every decision, we see problems creep in: instead of recognizing that users will abandon our sites on mobile if they take longer than three seconds to load, our projects end up bloated and take  —and even longer on 3G. We send hundreds of kilobytes of bloat, because optimizing images or removing unused code is tedious. Simply put: we get lazy, and our users suffer for it. Similarly, if a team ignores its tools and focuses only on delivering great UX, the developers will suffer. Arduous quality assurance checklists full of manual processes can ensure that the UX of our projects is top-notch, but it’s a slog that creates a terrible, mind-numbing DX for the teams writing the code. In an industry full of developers who love to innovate and create, cumbersome checklists tend to kill employee engagement, which is ultimately bad for the users, the developers, and the whole company. But if we take a moment at the outset of our projects to consider  , we’re able to spot trade-offs, and make intelligent design decisions before problems emerge. We can treat both UX and DX as first-class concerns, and prevent putting them at odds with each other—or, at least, we can minimize the trade-offs when conflicts happen. We can provide an excellent experience for our users while also creating a robust suite of tools and frameworks that make development enjoyable and maintainable for the entire lifespan of the project. Whether we do that by choosing existing tools to take work off our plates, by spending an appropriate amount of time properly planning custom solutions, or some combination thereof, we can make a conscious effort to make smart design decisions, so we can keep users   developers happy. Like this:"},
{"url": "https://alistapart.com/article/responsive-images/", "title": "Responsive Images", "content": "I come here not to bury  , but to praise it. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Well, mostly. Historically, I like   just fine. It’s refreshingly uncomplicated, on the surface: it fires off a request for the file in its   attribute, renders the contents of that file, and provides assistive technologies with an alternative narration. It does so quickly, efficiently, and seamlessly. For most of the web’s life, that’s all   has ever had to do—and thanks to years and years of browsers competing on rendering performance, it keeps getting better at it. But there’s a fine line between “reliable” and “stubborn,” and I’ve known   to come down on both sides of it. Though I admit to inadvertently hedging my bets a   by contributing to the jQuery Mobile Project—a framework originally dedicated to helping produce “mobile sites”—I’ve always come down squarely in the responsive web design (RWD) camp. For me, the appeal of RWD wasn’t in building a layout that adapted to any viewport—though I   still think that’s pretty cool. The real appeal was in finding a technique that could adapt to the unknown-unknowns. RWD felt—and still feels—like a logical and ongoing extension of the web’s strengths: resilience, flexibility, and unpredictability. That said, I would like to call attention to one thing that m-dot sites (dedicated mobile versions of sites, usually found at a URL beginning with the letter   followed by a dot) did have over responsively designed websites, back in the day: specially tailored assets. Tailoring Assets In a responsive layout, just setting a   in your CSS ensures that your images will always   right—but it also means using image sources that are at least as large as the largest size at which they’ll be displayed. If an image is meant to be displayed anywhere from 300 pixels wide to 2000 pixels wide, that same 2000-pixel-wide image is getting served up to users in all contexts. A user on a small, low-resolution display gets saddled with all of the bandwidth costs of massive, high-resolution images, but ends up with none of the benefits. A high-resolution image on a low-resolution display looks like any other low-resolution image; it just costs more to transfer and takes longer to appear. Even beyond optimization, it wasn’t uncommon to show or hide entire blocks of content, depending on the current viewport size, during those early days of RWD. Though the practice became less common as we collectively got the hang of working responsively,   came with unique concerns when serving disparate content across breakpoints: our markup was likely to be parsed long before our CSS, so an   would have no way of knowing whether it would be displayed at the current viewport size. Even an   (or its container) set to   would trigger a request, by design. More bandwidth wasted, with no user-facing benefit. Our earliest attempts I am fortunate enough to have played a tiny part in the history of RWD, having worked alongside Filament Group and Ethan Marcotte on the   website back in 2011. It was, by any measure, a project with  . The   website redesign gave us an opportunity to prove that responsive web design was not only a viable approach to development, but that it could scale beyond the “it might be fine for a personal blog” trope—it could work for a massive news organization’s website. It’s hard to imagine that idea has ever needed proving, looking back on it now, but this was a time when standalone m-dot sites were widely considered a best practice. While working on the  , we tried developing a means of delivering larger images to devices with larger screens, beginning with the philosophy that the technique should err on the side of mobile: start with a mobile-sized and -formatted image, then swap that with a larger version depending on the user’s screen size. This way, if anything should break down, we’re still erring on the side of caution. A smaller—but still perfectly representative—image. The key to this was getting the screen’s width in JavaScript, in the   of the document, and relaying that information to the server in time to defer requests for images farther down the page. At the time, that JavaScript would be executed prior to any requests in   being made; we used that script to set a cookie about the user’s viewport size, which would be carried along with those   requests on the same page load. A bit of server-side scripting would read the cookie and determine which asset to send in response. It worked well, but it was squarely in the realm of “clever hack”—that parsing behavior wasn’t explicitly defined in any specifications. And in the end, as even the cleverest hacks are wont to do, it broke.  Believe it or not, that was good news. Prefetching—or “speculative preparsing”—is a huge part of what makes browsers feel fast: before we can even see the page, the browser starts requesting assets so they’re closer to “ready” by the time the page appears. Around the time the  ’s site launched, several major browsers made changes to the way they handled prefetching. Part of those changes meant that an image source might be requested before we had a chance to apply any of our custom logic. Now, when browsers compete on performance, users win—those improvements to speculative preparsing were great news for performance,  . But there was a disconnect here—the   request is the one that never gets made. Good ol’ reliable   was single-mindedly requesting the contents of its   faster than ever, but often the contents of those requests were inefficient from the outset, no matter how quickly the browser managed to request, parse, and render them—the assets were bigger than they’d ever need to be. The harm was being done over the wire. So we set out to find a new hack. What followed was a sordid tale of   tags and dynamically injected   tags, of   and  —     For some of you, the preceding lines will require no explanation, and for that you have my sincerest condolences. For everyone else: know that it was the stuff of scary developer campfire stories (or, I guess, scary GIF-of-a-campfire stories). Messy, hard-to-maintain hacks all the way down, relying entirely on undocumented, unreliable browser quirks. Worse than those means, though, were the ends: none of it really  . We were always left with compromises we’d be foisting on a whole swath of users—wasted requests for some, blurry images for others. It was a problem we simply couldn’t solve with sufficiently clever JavaScript; even if we had been able to, it would’ve meant working   browser-level optimizations rather than taking advantage of them. We were trying to subvert browsers’ improvements, rather than work with them. Nothing felt like the way forward. We began hashing out ideas for a native solution: if HTML5 offered us a way to solve this, what would that way look like?  A native solution What began in a shared text file eventually evolved into one of the first and largest of the W3C’s Community Groups—places where developers could build consensus and offer feedback on evolving specifications. Under the banner of the “Responsive Images Community Group,” we—well, at the risk of ruining the dramatic narrative, we argued on mailing lists. One such email, from Bruce Lawson, proposed a markup pattern for delivering context-appropriate images that fell in line with the existing rich-media elements in HTML5—like the   tag—even borrowing the   attribute. He called it  ;   was already taken as an ancient alias of  , after all. What made this proposal special was the way it used our reliable old friend  . Rather than a standalone element,   came to exist as a wrapper—and a decision engine—for an inner   element: That   inside   would give us an incredibly powerful fallback pattern—it wouldn’t be the sort of standard where we have to wait for browser support to catch up before we could make use of it. Browsers that didn’t understand   and its   elements would ignore it and still render the inner  . Browsers that   understand   could use criteria attached to   elements to tell the inner   which source file to request. Most important of all, though, it meant we didn’t have to recreate all of the features of   on a brand-new element: because   didn’t render anything in and of itself, we’d still be leaning on the performance and accessibility features of that  . This made a lot of sense to us, so we took it to the Web Hypertext Application Technology Working Group (WHATWG), one of the two groups responsible for the ongoing development of HTML. If you’ve been in the industry for a few years, this part of the story may sound a little familiar. Some of you may have caught whispers of a fight between the WHATWG’s   and the   element put forth by a scrappy band of web-standards rebels and their handsome, charismatic, and endlessly humble Chair. Some of you read the various calls to arms, or donated when we raised funds to hire Yoav Weiss to work full-time on native implementations. Some of you have RICG T-shirts, which—I don’t mind saying—were  . A lot of dust needed to settle, and when it finally did, we found ourselves with more than just one new element; edge cases begat use cases, and we discovered that   alone wouldn’t be enough to suit all of the image needs of our increasingly complex responsive layouts. We got an entire suite of enhancements to the   element as well: native options for dealing with high-resolution displays, with the size of an image in a layout, with alternate image formats—things we had never been able to do natively, prior to that point. Like this: \n\t\t\t\t\t\t\tRecently by Mat Marquis\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/web-developer-representation-in-w3c/", "title": "Web Developer Representation in W3C", "content": "During its annual general member meeting on October 19th, the   board will propose both to become a member of the   and to hire   as our representative in that standards body. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What is Fronteers? Why does it want to become a W3C member? And how can you help? Read on; we’ll start with the second question. Browser vendors have the greatest say As we all know, W3C sets the web standards. In practice, browser vendors have the greatest say in W3C. They have the most experience in implementing web standards, and they have so much at stake in the standardization process that they’re willing to allocate budget for their W3C representatives. All in all, this system works decently. Although all browser vendors have their own priorities and pet features and are willing to push them to the point of implementing them before a formal specification is available, they are all aware that building the web is a communal effort, and that their ideas won’t succeed in the long term without other vendors implementing them as well. Web developers have little say Nonetheless, it’s us web developers who are primarily responsible for actually using web standards. We have as much experience as browser vendors in the practical usage of web standards, though our viewpoint is somewhat different. It’s good when we have the web developers’ viewpoint represented at the W3C table. An example is gutters in CSS Grid. Originally, the specification did not include them, but when Rachel Andrew, as a W3C Invited Expert, was evangelizing the (then) upcoming Grid specification,  . Since she could prove that web developers working in the wild wanted them, Rachel was able to convince the CSS Working Group (CSS WG) of the need for gutters. Without her volunteering to be in the CSS WG, this might not have happened, or would have happened later, forcing web developers to work around the lack of gutters with hacks. It’s not that they don’t want our input W3C is willing, even eager, to listen to web developers. Any web developer willing to enter the W3C discussions is welcomed with open arms—in fact, the role of Invited Expert was created exactly for this reason. Lack of interest by W3C is not the problem. Instead, the problem is one of time and money. An independent web developer who participates in W3C discussions has to volunteer a lot of time—time that could otherwise be spent earning money. Serious involvement additionally means attending the face-to-face meetings held all across the globe—more time, more money. The web would be better served by having more professional viewpoints than just the browser makers’. Web developers in general would be served by having a W3C representative.  But it all comes down to money. How do we pay our W3C representative? Superficially, this is a thorny problem. What we need is an organization of web professionals that has enough income to pay not only the representative’s fee, but also their W3C membership dues and travel costs. If we don’t do it, nobody else will This problem disappears once you know such an organization actually exists: Fronteers, the professional association of Dutch front-end developers. Founded in 2007, Fronteers is best known for its   in October, but that’s not all it does. It has been locally active with workshops, meetups, a job board, and other activities for Dutch front-enders. More to the point, some of its activities are pretty profitable, and it has spent far less money than it has made in the past eleven years. That’s why the Fronteers board decided to take the plunge and propose both to become a W3C member and to hire a representative. The need is clear, we have the money, and if we don’t do it, nobody else will. Members will vote on this proposal at the annual general meeting on October 19th, and I, for one, fervently hope they’ll vote in favor. If the members agree, Fronteers will apply for W3C membership and contract Rachel Andrew as soon as is feasible. The choice for Rachel as our representative is an obvious one. Not only is she instrumental in specifying and evangelizing CSS Grid, but she is also well-acquainted with the W3C’s processes, politics, and agenda, having served as an Invited Expert for many years. We couldn’t think of any better candidate to serve as web developers’ first representative in W3C. But we can’t do it alone But that’s not all we’re planning. We want the rest of the world to become involved as well. We see Rachel as the W3C voice of web developers around the world and not just as our private Fronteers representative. Though we are taking the lead for practical reasons (and because we have the funding), we see ourselves as the creators of a framework that web communities in other countries can join—and contribute to financially. There are two practical problems we cannot solve on our own. First, while new W3C non-profit members pay only 25% of the annual W3C fee for the first two years, beginning with the third year we’ll be on the hook for the full fee. Second, W3C membership gives us the right to appoint four representatives, but that is beyond our means. Again, it all boils down to money. While we could probably afford the full annual W3C fee, and our budget might conceivably be expanded and restructured enough to hire half of a second representative, that’s about the limit of what we can do without our treasurer being afflicted with a permanent sadface and other stress-induced symptoms. If we want to continue web developer representation in W3C beyond two years and one representative, we need outside help. We can’t do it on our own. Here’s how you can help Ask yourself: do you believe in the idea of having independent web developers’ voices represented in W3C? Do you think that it will make a difference, that it will make your work easier in the future? Do you feel this is something that has to be done? If so, please consider helping us. We would love to see other organizations of web professionals similar to Fronteers around the globe, contributing to a general fund to cover the cost of a collective W3C membership and compensating our four representatives for their time. Yes, that’s a lot of work. But we did it, so it’s possible. Besides, you likely won’t have to do the work all by yourself. If you like the idea, others will as well and will jump in to help. Collaborating for a common cause is something the web community is rather good at. Will this work? We have no idea. We do know, however, that there’s a limit to what Fronteers can do. While we’re happy to take the lead for two years, we cannot shoulder this burden permanently by ourselves. You can   at the Fronteers site, where you can also  . Rachel has also written about   over at Smashing Magazine. Like this: \n\t\t\t\t\t\t\tRecently by Peter-Paul Koch\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/psychology-of-design/", "title": "The Psychology of Design", "content": "There are a number of debates about which additional skills designers should learn. Should designers code, write, or understand business? These skills are incredibly valuable but perhaps not essential. However, I would argue that every designer should learn the fundamentals of psychology. As humans, we have an underlying “blueprint” for how we perceive and process the world around us, and the study of psychology helps us define this blueprint. As designers, we can leverage psychology to build more intuitive, human-centered products and experiences. Instead of forcing users to conform to the design of a product or experience, we can use some key principles from psychology as a guide for designing how people actually are. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But knowing where to start can be a challenge. Which principles from psychology are useful? What are some examples of these principles at work? In this article, I’ll cover the basics, and discuss the ethical implications of using psychology in design. Key principles The intersection of psychology and design is extensive. There’s an endless list of principles that occupy this space, but there are a few that I’ve found more ubiquitous than others. Let’s take a look at what these are and where they are effectively leveraged by products and experiences we interact with everyday. Hick’s Law One of the primary functions we have as designers is to synthesize information and present it in a way that it doesn’t overwhelm users—after all,  . This directly relates to our first key principle: Hick’s Law. Hick’s Law predicts that  . It was formulated by psychologists William Edmund Hick and Ray Hyman in 1952 after examining the relationship between the number of stimuli present and an individual’s reaction time to any given stimulus. It turns out there is an actual formula to represent this relationship:  . Fortunately, we don’t need to understand the math behind this formula to grasp what it means. The concept is quite simple: the time it takes for users to respond directly correlates to the number and complexity of options available. It implies that complex interfaces result in longer processing time for users, which is important because it’s related to a fundamental theory in psychology known as cognitive load.  refers to the mental processing power being used by our working memory. Our brains are similar to computer processors in that we have limited processing power: when the amount of information coming in exceeds the space available, cognitive load is incurred. Our performance suffers and tasks become more difficult, which results in missed details and even frustration. There are examples of Hick’s Law in action everywhere, but we’ll start with a common one: remote controls. As features available in TVs increased over the decades, so did the options available on their corresponding remotes. Eventually we ended up with remotes so complex that using them required either muscle memory from repeated use or a significant amount of mental processing. This led to the phenomenon known as “grandparent-friendly remote.” By taping off everything except for the essential buttons, grandkids were able to improve the usability of remotes for their loved ones, and they also did us all the favor of sharing them online. In contrast, we have smart TV remotes: the streamlined cousin of the previous example, simplifying the controls to only those absolutely necessary. The result is a remote that doesn’t require a substantial amount of working memory and therefore incurs much less cognitive load. By transferring complexity to the TV interface itself, information can be effectively organized and progressively disclosed within menus. Let’s take a look at another example of Hick’s Law. Onboarding is a crucial but risky process for new users, and few nail it as well as Slack. Instead of dropping users into a fully featured app after enduring a few onboarding slides, they use a bot (Slackbot) to engage users and prompt them to learn the messaging feature consequence-free. To prevent new users from feeling overwhelmed, Slack hides all features except for the messaging input. Once users have learned how to message via Slackbot, they are progressively introduced to additional features. This is a more effective way to onboard users because it mimics the way we actually learn: we build upon each subsequent step, and add to what we already know. By revealing features at just the right time, we enable our users to adapt to complex workflows and feature sets without feeling overwhelmed. Too many choices will increase the cognitive load for users. Break up long or complex processes into screens with fewer options. Use progressive onboarding to minimize cognitive load for new users. Miller’s Law Another key principle is Miller’s Law, which predicts that  . It originates from a paper published in 1956 by cognitive psychologist George Miller, who discussed the limits of short-term memory and memory span. Unfortunately there has been a lot of misinterpretation regarding this heuristic over the years, and it’s led to the “ ” being used to justify unnecessary limitations (for example, limiting interface menus to no more than seven items). Miller’s fascination with short-term memory and memory span centered not on the number seven, but on the concept of “chunking” and our ability to memorize information accordingly. When applied to design, chunking can be an incredibly valuable tool. Chunking describes the act of visually grouping related information into small, distinct units of information. When we chunk content in design, we are effectively making it easier to process and understand. Users can scan the content and quickly identify what they are interested in, which is aligned with how we tend to consume digital content. The simplest example of chunking can be found with how we format phone numbers. Without chunking, a phone number would be a long string of digits, which increases the difficulty to process and remember it. Alternatively, a phone number that has been formatted (chunked) becomes much easier to interpret and memorize. This is similar to how we perceive a “wall of text” in comparison to well-formatted content with appropriate headline treatments, line-length, and content length. Another example of chunking being used effectively in design is with layout. We can use this technique to help users understand underlying relationships and hierarchy by grouping content into distinctive modules. Especially in information-dense experiences, chunking can be leveraged to provide structure to the content. Not only is the result more visually pleasing, but it’s more scannable. Don’t use the “magical number seven” to justify unnecessary design limitations. Organize content into smaller chunks to help users process, understand, and memorize easily. Jakob’s Law The last principle we’ll look at is Jakob’s Law (short for Jakob’s Law of Internet User Experience), which states that  . In 2000, it was  , who described the tendency for users to develop an expectation of design patterns based on their cumulative experience from other websites. This principle encourages designers to follow common design patterns in order to avoid confusing users, which can result in higher cognitive load. I know what you’re thinking: if all websites followed the same design patterns, that would make for quite the boring web. The answer is yes, that is probably true. But there is something incredibly valuable to be found in familiarity for users, which leads us to another fundamental concept in psychology that is valuable for designers: mental models. A   is what we think we know about a system, especially about how it works. Whether it’s a website or a car, we form models of how a system works, and then we apply that model to new situations where the system is similar. In other words, we use knowledge we already have from past experiences when interacting with something new. Mental models are valuable for designers, because we can  . Consequently, users can easily transfer their knowledge from one product or experience to another without taking time to understand how the new system works. Good user experiences are made possible when the designer’s mental model is aligned with the user’s mental model. The task of shrinking the gap between our mental models and those of our users is one of our biggest challenges, and to achieve this we use a variety of methods: user interviews, personas, journey maps, empathy maps, and more. The point of all this is to gain a deeper insight into not only the goals and objectives of our users but also their pre-existing mental models, and how that applies to the product or experience we are designing. Have you ever wondered why form controls look the way they do? It’s because the humans designing them had a mental model for what these elements should look like, which they based on control panels they were already familiar with in the physical world. Things like form toggles, radio inputs, and even buttons originated from the design of their tactile counterparts. As designers, we must close the gap that exists between our mental models and that of our users. It’s important we do this because there will be problems when they aren’t aligned, which can affect how users perceive the products and experiences we’ve helped build. This misalignment is called  , and it occurs when a familiar product is suddenly changed. Take for example Snapchat, which rolled out a major redesign in early 2018. They launched a reformatted layout, which in turn confused users by making it difficult to access features they used on a daily basis. These unhappy users immediately took to Twitter and expressed their disapproval en masse. Even worse was the subsequent migration of users to Snapchat’s competitor, Instagram. Snapchat had failed to ensure the mental model of their users would be aligned with the redesigned version of their app, and the resulting discordance caused major backlash. But major redesigns don’t always have to result in backlash—just ask Google. Google has a history of allowing users to opt in to redesigned versions of their products like Google Calendar, YouTube, and Gmail. When they launched the new version of YouTube in 2017 after years of essentially the same design, they allowed desktop users to ease into the new Material Design UI without having to commit. Users could preview the new design, gain some familiarity, submit feedback, and even revert to the old version if they preferred it. As a result, the inevitable mental model discordance was avoided by simply empowering users to switch when they were ready. Users will transfer expectations they have built around one familiar product to another that appears similar. By leveraging existing mental models, we can create superior user experiences in which the user can focus on their task rather than learning new models. Minimize discordance by empowering users to continue using a familiar version for a limited time. Recap You might be thinking, “These principles are great, but how do I use them in my projects?” While nothing will replace actual user research and data specific to our projects, we can use these psychological principles to serve as a guide for designing more intuitive, human-centered products and experiences. Being mindful of these principles helps us create designs that consider how people actually are, as opposed to forcing them to conform to the technology. To quickly recap: Hick’s Law can help guide us to reduce cognitive load for users by minimizing choice and breaking long or complex processes into screens with fewer options. Miller’s Law teaches us to use chunking to organize content into smaller clusters to help users process, understand, and memorize easily. Jakob’s Law reminds us that users will transfer expectations they have built around one familiar product to another that appears similar. Therefore, we can leverage existing mental models to create superior user experiences. We’ve covered some key principles that are useful for building more intuitive, human-centered products and experiences. Now let’s touch on their ethical implications and how easy it can be to fall into the trap of exploiting users with psychology. A note on ethics On the one hand, designers can use psychology to create more intuitive products and experiences; on the other, they can use it to exploit how our minds work, for the sake of creating more addictive apps and websites. Let’s first take a look at why this is a problem, and then consider some potential solutions. Problem One doesn’t have to go far to see why the well-being of users being deprioritized in favor of profit is a problem. When was the last time you were on a subway, on a sidewalk, or in a car and didn’t see someone glued to their smartphone? There are some that would argue  , and that our attention is being held captive by the mini-computers that we carry with us everywhere. It wouldn’t be an exaggeration to say that the mobile platforms and social networks that connect us also put a lot of effort into how they can keep us glued, and they’re getting better at it every day. The effects of this addiction are beginning to become well-known: from sleep reduction and anxiety to deterioration of social relationships, it’s becoming apparent that the race for our attention has some unintended consequences. These effects become problematic when they start to change how we form relationships and how we view ourselves. Solution As designers, our responsibility is to create products and experiences that support and align with the goals and well-being of users. In other words, we should build technology for augmenting the human experience, not replacing it with virtual interaction and rewards. The first step in making ethical design decisions is to acknowledge how the human mind can be exploited. We must also question what we should and shouldn’t build. We can find ourselves on quite capable teams that have the ability to build almost anything you can imagine, but that doesn’t always mean we should—especially if the goals of what we are building don’t align with the goals of our users. Lastly, we must consider metrics beyond usage data. Data tells us lots of things, but what it doesn’t tell us is why users are behaving a certain way or how the product is impacting their lives. To gain insight into why, we must both listen and be receptive to our users. This means getting out from behind a screen, talking with them, and then using this qualitative research to inform how we evolve the design. Examples It’s been great to see companies taking the right steps when it comes to considering the digital well-being of users. Take for example Google, which just announced   at their latest I/O event that focus on helping people better understand their tech usage, focus on what matters most, disconnect when needed, and create healthy digital habits. Features like an app dashboard that provides a usage overview, additional control over alerts and notifications, and Family Link for setting digital ground rules for the little ones all are geared towards protecting users. Some companies are even redefining their success metrics. Instead of time on site, companies like Facebook are  . This required them to restructure their news feed algorithm to prioritize the content that people actually find valuable over the stuff we mindlessly consume. Content from friends and family now takes precedence, even if the result means users spend a little less time in their app. These examples are just a glimpse into the steps that many companies are taking, and I hope to see many more in the coming years. The technology we play a part in building can significantly impact people’s lives, and it’s crucial that we ensure that impact is positive. It’s our responsibility to create products and experiences that support and align with the goals and well-being of users. We can make ethical design decisions by acknowledging how the human mind can be exploited, consider what we should and shouldn’t build, and talk with users to gain qualitative feedback on how the products and experiences we build affect their lives. Resources There are tons of great resources we can reference for making our designs more intuitive for users. Here are a few I have referenced quite frequently: : A website I created for designers to learn more about psychological principles that relate to UX/UI design. : This hand-selected publication curated by Norbi Gaal is a great resource for anyone interested in the intersection of psychology and UX. : A world-class team of former tech \ninsiders and CEOs who are advancing thoughtful solutions to change the culture, business incentives, design techniques, and organizational \nstructures driving how technology hijacks our brains. : An absolute classic that explores the communication between object and user through design, how to optimize this communication, and ultimately how psychology plays a part in designing for how humans actually are. : A look at the importance of emotion when expressing a brand’s personality, and how designers can go beyond functionality, reliability, and usability to design for humans as opposed to machines. : A guide that provides insight into the behavioral techniques used by companies like Twitter, Instagram, and Pinterest. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-faq-as-advice-column/", "title": "The FAQ as Advice Column", "content": "Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I have a problem that may be harming my content strategy career. In my current position, no one likes FAQs … except for me. The question-and-answer format is satisfying and efficient. Whenever I mention adding an FAQ section to a website, though, I receive numerous suggestions that I should wean myself off FAQs one question at a time or go cold turkey. Perhaps that is overdoing it, but sometimes I feel like defending FAQs by pen, sword, or Dothraki horde. Should I keep my addiction to myself, or should I embrace this oddity and champion a format I believe in? Signed, \nFAQ Fanatic You’re not wrong: FAQs are as out of vogue as a fat footer. You’re also not alone. As an aspiring advice columnist, I’ve been wondering why the format is so unpopular even though it remains on many websites. In fact, in a recent   piece,   as one of many legitimate patterns of organization that you can use when writing. To address your query properly, I propose some soul-searching through a series of FAQs about FAQs. Let’s tackle the toughest question first. Can I trust FAQs? If you are a content strategist or information architect, chances are good you’ve been burned.   the FAQ can be bad news. It is a poor excuse for a proper content strategy that would generate “purposeful information” across a website. For example, if you see an FAQ, you know right away that the website is duplicating content, which often leads to discrepancies. FAQs may also lead to a bigger design issue: accordion abuse. The typical FAQ design involves expand-and-collapse features. In theory, this makes it easier for users to scan to find what they need. But in a content migration or consolidation, I’ve seen desperate freelancers or webmasters shove entire web pages under a question just to make an old page fit a new design. If a user is coming to an FAQ for a quick-hit answer, as is often the case, imagine how horrifying it can be to expand a question and see an answer the length of David Foster Wallace’s   tucked underneath. Can the FAQ and I still be friends? Ah, you must be a content author. If you’re a content author on a budget, under a deadline, or both, the FAQ will become your bestie—whether you planned on it or not. In my experience, teams bust out the FAQs not because they are lazy but because they find them to be a reliable way to structure content.  When I worked at an agency, a few of my projects were microsites that weren’t so “micro.” Some clients wanted a small site on a minimal CMS within an even more minimal timeline, but the content kept ballooning, leaving no time for true  . The only way to build the content on time was to use the FAQ as a content model or spine. Like you, I now work with people who avoid FAQs. Since my current agency specializes in site redesigns for higher-ed clients, it’s expected that the information has more structure to begin with—and it usually does. Plus, my particular agency gives information architects and content strategists more time than the norm. From the get-go, our sitemaps, wireframes, and patterns serve as a stable foundation for the content. Sometimes, though, even the most stable foundations won’t prevent the appearance of an FAQ. If a content team doesn’t get enough time to  , they’ll probably encounter numerous FAQs. They’ll need to figure out a way to get that content over to the new site somehow … which means those FAQs aren’t going anywhere. So, do I have to quit FAQs cold turkey? No. The FAQ structure has held up for so long because it is a brilliant pattern. Think the Socratic method. Or the catechism. Or Usenet. Or “ .” Or—you guessed it—“Dear Prudence,” “Dear Sugar,” or any other popular advice column. Users will always have questions, and they will always want answers. What makes FAQs troublesome is incorrect or lazy use. Lisa Wright has already shared what not to do, but perhaps the best way to start an FAQ is to choose each question with great care. For example, advice columnists spend plenty of time selecting what questions they will answer each week. In general, listeners want to hear the advice columnist flexing their mental muscles to resolve the most complicated situations. If you’re using FAQs correctly, start with the best content possible, and align that content with what both   and   want. Content authors can rely on the Q&A structure to deliver quality content on a regular basis while reassuring content consumers that they are receiving the best answers. FAQ-appropriate content What is the best content for an FAQ? Thus far, I’ve discussed choosing your questions wisely and keeping your answers short (and, yes, shorter than the answers of a typical advice columnist). Since I’ve worked in higher ed, I’ve had the chance to speak with people who support admissions and enrollment, and they spend most of their time answering frequently asked questions from students and parents. In one stakeholder interview session with the staff of a community college, it became clear that the questions the staff handled fell into two camps: the questions people ask over and over and the head-scratching edge cases. For example, questions about transcripts or financial aid awards are timeless. As for the edge cases, a full-time student might ask if he or she can get a discount if they want to take a yoga class through a community education program.  For the common content, FAQs shouldn’t repeat what’s already on the website, but they are called “frequently asked questions” for a reason. As long as you provide the content only twice—once in the FAQ and once on a relevant content page—you’re fine. Your authors shouldn’t have to manage anything past that. With an edge case, the question might be so specific that the answer wouldn’t have a clear home on any page—in my example, the yoga class question would straddle full-time registration and community education. Therefore, even though the off-the-wall question isn’t “frequently asked,” it can still live in the FAQ, and if the edge cases pile up (as they can in the world of higher ed), then you could shift these questions to a blog, which could provide a source of fresh content. I wouldn’t have known about the full-time student who wants to take a community ed class if it hadn’t emerged during the stakeholder interview. For that reason, you want to talk to customers or students and ask them what questions they’ve had in the past. If you don’t have time for that, read over user research to find out what users typically ask. Or use Google Search Console to look at the search queries that lead to your site, and figure out how well your site answers those questions. You may find that many of the queries leading to your site are written as questions. In fact, according to  , questions make up approximately 8% of search queries, so this research may help you populate your FAQ. And if you’re looking for inspiration, you could try a tool like   (free to access UK data; a monthly payment required for other regions). Type in a keyword like “college applications,” and the tool will serve up a range of questions people have asked in their search queries. The final way to articulate what works for an FAQ is to describe what doesn’t work. If your answer begins to spin into a narrative instead of a straightforward answer, you might need to add a separate page of content to your sitemap. And if your answer starts to sound too much like marketing copy, then it belongs elsewhere on the site. FAQs exist for those who are further along in the sales process or those who are already sold. Continuing to sell to that audience in an FAQ will only annoy them. When you know which questions you’re going to cover, you can start to refine the language for your main audiences: authors and consumers. FAQs for content authors: your in-house reference desk A clever content author can use an FAQ as a core research document. Armed with a CMS that has a decent back-end search, a content author will have a much easier time keeping content aligned and fact-checked if the FAQ itself is treated as a trustworthy source of information. For that reason, what Wright calls “documentation-by-FAQ” might not be the worst situation in the world, depending on how much content you’re working with. If you actually have someone tending the FAQ like a garden, your content will always change, but you can be sure of its accuracy. To convince your more skeptical peers of the value of maintaining your FAQ page or database, tell them that the FAQ is a content opportunity that may save them time. Think of how delightful it is when you get your “ ” newsletter or a podcast notification for the latest  . Whenever you add a new question or update a new fact, spread the word among your users. These updates can help feed the social-media-marketing content beast while proving that you want to keep users informed and engaged. FAQs for content consumers: give them power Speaking of keeping users informed and engaged, a good FAQ can help the audience even more than it helps content authors. The best way to ensure that the FAQ works for the audience is to give them more control over the questions and answers they see. Most FAQs, including those on higher-ed sites, chunk up the FAQs by content category, tuck answers into accordions, and stop right there. More effective FAQs, though, provide other forms of interaction. Some allow users to refine information through filters, searches, and tags so the user isn’t stuck opening and closing accordion windows. For example, the website for   has a fairly standard format, but the FAQ answers are tagged, so users have another option for navigating through the information. Other higher-ed services, like the syndicated  , answer common FAQs with videos. Changing up the format and providing text, video, and audio options help prospective students feel like they are receiving more personal attention. Beyond higher-ed FAQs, Amazon encourages users to vote FAQs up and down, Reddit-style, which can lead to fun interactions and enables the users to rate the quality—or humor—of the information they receive. You can also remind skeptics that FAQs aren’t always what they expect. The FAQ format has experienced a renaissance in the form of our newly beloved voice gadgets. Some content creators are even using their existing FAQs as the foundation for their Alexa skills. For example,   by transforming its “ ” FAQ database, working with Acquia to structure the Q&A format so Alexa can answer common questions from Georgia residents. When describing the project,  : If you say “No” to an FAQ question, Alexa skips to the next FAQ, and the next, until you say something sounds helpful or Alexa runs out of questions. When the user chooses what they want to hear, they need to know exactly what they’re committing to. We need to make sure that our [labeling]—for both titles and FAQs—is clear. Read that again, dear FAQ fanatic. The complications for Alexa skills arise in the labeling, not in the FAQ itself. In fact, it’s the FAQ content that makes Alexa skills like the one for georgia.gov possible. So I can make peace with my quirky love of the FAQ? Indeed. Let your FAQ flag fly. FAQs—or dialogues that convey information—will always exist in some way, shape, or form. As for the accordion, though, the jury is out. Like this: \n\t\t\t\t\t\t\tRecently by Caroline Roberts\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/braces-to-pixels/", "title": "Braces to Pixels", "content": "Doesn’t CSS seem like magic? Well, in this third installment of “ ” we’ll look at the journey that your browser goes through to take your CSS from braces to pixels. As a bonus, we’ll also quickly touch on how end-user interaction affects this process. We have a lot of ground to cover, so grab a cup of <insert your favorite drink’s name here>, and let’s get going. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Parsing Similar to what we learned about HTML in “ ,” once CSS is downloaded by the browser, the CSS parser is spun up to handle any CSS that it encounters. This can be CSS within individual documents, inside of   tags, or inline within the   attribute of a DOM element. All the CSS is parsed out and tokenized in accordance with the  . At the end of this process, we have a data structure with all the selectors, properties, and properties’ respective values. For example, consider the following CSS: That will result in the following data structure for easy utilization later in the process: One thing that is worth noting is that the browser exploded the shorthands of   and   into their longhand variants, as shorthands are primarily for developer ergonomics; the browser only deals with the longhands from here on. After this is done, the engine continues constructing the DOM tree, which Travis Leithead also covers in “ ”; so go read that now if you haven’t already, I’ll wait. Computation Now that we have parsed out all styles within the readily available content, it’s time to do style computation on them. All values have a standardized computed value that we try to reduce them to. When leaving the computation stage, any dimensional values are reduced to one of three possible outputs:  , a percentage, or a pixel value. For clarity, let’s take a look at a few examples of what the web developer wrote and what the result will be following computation: Now that we’ve computed all the values in our data store, it’s time to handle the cascade. Cascade Since the CSS can come from a variety of sources, the browser needs a way to determine which styles should apply to a given element. To do this, the browser uses a formula called specificity, which counts the number of tags, classes, ids, and attribute selectors utilized in the selector, as well as the number of   declarations present. Styles on an element via the inline   attribute are given a rank that wins over any style from within a   block or external style sheet. And if a web developer utilizes   on a value, the value will win over any CSS no matter its location, unless there is a   inline as well. To make this clear, let’s show a few selectors and their resulting specificity scores: So what does the engine do when the specificity is tied? Given two or more selectors of equal specificity, the winner will be whichever one appears last in the document. In the following example, the   would have a blue background. Let’s expand on our   example a little bit: Now the CSS will produce the following data structure. We’ll continue building upon this throughout the article.  Understanding origins In “ ,” Ali Alabbas discusses origins as they relate to browser navigation. In CSS, there are also origins, but they serve different purposes: user: any styles set globally within the user agent by the user; author: the web developer’s styles; and user agent: anything that can utilize and render CSS (to most web developers and users, this is a browser). The cascade power of each of these origins ensures that the greatest power lies with the user, then the author, and finally the user agent. Let’s expand our dataset a bit further and see what happens when the user sets their browser’s font size to a minimum of 2em:  Doing the cascade When the browser has a complete data structure of all declarations from all origins, it will sort them in accordance with specification. First it will sort by origin, then by specificity, and finally, by document order.  This results in the “winning” properties and values for the   (the higher up in the table, the better). For example, from the previous table, you’ll note that the user’s browser preference settings take precedence over the web developer’s styles. Now the browser finds all DOM elements that match the denoted selectors, and hangs the resulting computed styles off the matching elements, in this case a   for the  : If you wish to learn more about how the cascade works, take a look at the  . CSS Object Model While we’ve done a lot up to this stage, we’re not done yet. Now we need to update the  . The CSSOM resides within  , we need to update it so that it represents everything that has been parsed and computed up to this point. Web developers may utilize this information without even realizing it. For example, when calling into  , the same process denoted above is run, if necessary. Layout Now that we have a DOM tree with styles applied, it’s time to begin the process of building up a tree for visual purposes. This tree is present in all modern engines and is referred to as the box tree. In order to construct this tree, we traverse down the DOM tree and create zero or more CSS boxes, each having a margin, border, padding and content box. In this section, we’ll be discussing the following CSS layout concepts: : there are many types of formatting contexts, most of which web developers invoke by changing the   value for an element. Some of the most common formatting contexts are block (block formatting context, or BFC), flex, grid, table-cells, and inline. Some other CSS can force a new formatting context, too, such as  , using  , or utilizing multi-column. : this is the ancestor block that you resolve styles against. : this is the direction in which text is laid out, as dictated by the element’s writing mode. In Latin-based languages this is the horizontal axis, and in CJK languages this is the vertical axis. : this behaves exactly the same as the inline direction but is perpendicular to that axis. So, for Latin-based languages this is the vertical axis, and in CJK languages this is the horizontal axis. Resolving  Remember from the computation phase that dimension values can be one of three values:  , percentage, or pixel. The purpose of layout is to size and position all the boxes in the box tree to get them ready for painting. As a very visual person myself, I find examples can make it easier to understand how the box tree is constructed. To make it easier to follow, I will not be showing the individual CSS boxes, just the principal box. Let’s look at a basic “Hello world” layout using the following code: Once the layout is complete, the browser walks back up the box tree, resolving any   or percentage-based values that haven’t been resolved. In the image, you can see that the body and the paragraph is now encompassing all of “Hello world” because its   was set to  . Dealing with floats Now let’s get a little bit more complex. We’ll take a normal layout where we have a button that says “Share It,” and float it to the left of a paragraph of Latin text. The float itself is what is considered to be a “shrink-to-fit” context. The reason it is referred to as “shrink-to-fit” is because the box will shrink down around its content if the dimensions are  . Float boxes are one type of box that matches this layout type, but there are many other boxes, such as absolute positioned boxes (including   elements) and table cells with  -based sizing, for example. Here is the code for our button scenario: Understanding fragmentation One final aspect to touch on for how layout works is fragmentation. If you’ve ever printed a web page or used CSS Multi-column, then you’ve taken advantage of fragmentation. Fragmentation is the logic of breaking content apart to fit it into a different geometry. Let’s take a look at the same example utilizing CSS Multi-column: Painting OK, so let’s recap where we’re at to this point. We’ve taken out all the CSS content, parsed it, cascaded it onto the DOM tree, and completed layout. But we haven’t applied color, borders, shadows, and similar design treatments to the layout–adding these is known as painting.  Painting is roughly standardized by CSS, and to put it concisely (you can read the full breakdown in  ), you paint in the following order: background; border; and content. So if we take our “SHARE IT” button from earlier and follow this process, it will look something like this: Once this is completed, it is converted to a bitmap. That’s right—ultimately every layout element (even text) becomes an image under the hood. Concerning the  Now, most of our websites don’t consist of a single element. Moreover, we often want to have certain elements appear on top of other elements. To accomplish this, we can harness the power of the   to superimpose one element over another. This may feel like how we work with layers in our design software, but the only layers that exist are within the browser’s compositor. It might seem as though we’re creating new layers using  , but we’re not—so what are we doing?  What we’re doing is creating a new stacking context. Creating a new   effectively changes the order in which you paint elements. Let’s look at an example: Without   utilization, the document above would be painted in document order, which would place “Item 2” on top of “Item 1.” But because of the  , the painting order is changed. Let’s step through each phase, similar to how we stepped through our earlier layouts. The   has no bearing on color, just which element is visible to users, and hence, which text and color is visible.  Composition At this stage, we have a minimum of a single bitmap that is passed from painting to the compositor. The compositor’s job is to create a layer, or layers, and render the bitmap(s) to the screen for the end user to see. A reasonable question to ask at this point is, “Why would any site need more than one bitmap or compositor layer?” Well, with the examples that we’ve looked at thus far, we really wouldn’t. But let’s look at an example that’s a little bit more complex. Let’s say that in a hypothetical world, the Office team wants to bring Clippy back online, and they want to draw attention to Clippy by having him pulsate via a CSS transform. The code for animating Clippy could look something like this: When the browser reads that the web developer wants to animate Clippy on infinite loop, it has two options: It can go back to the repaint stage for every frame of the animation, and produce a new bitmap to send back to the compositor. Or it can produce two different bitmaps, and allow the compositor to do the animation itself on only the layer that has this animation applied. In most circumstances, the browser will choose option two and produce the following (I have purposefully simplified the amount of layers Word Online would produce for this example): Then it will re-compose the Clippy bitmap in the correct position and handle the pulsating animation. This is a great win for performance as in many engines the compositor is on its own thread, and this allows the main thread to be unblocked. If the browser were to choose option one above, it would have to block on every frame to accomplish the same result, which would negatively impact performance and responsiveness for the end user. Creating the illusion of interactivity As we’ve just learned, we took all the styles and the DOM, and produced an image that we rendered to the end user. So how does the browser create the illusion of interactivity? Welp, as I’m sure you’ve now learned, so let’s take a look at an example using our handy “SHARE IT” button as an analogy: All we’ve added here is a pseudo-class that tells the browser to change the button’s background and text color when the user hovers over the button. This begs the question, how does the browser handle this? The browser constantly tracks a variety of inputs, and while those inputs are moving it goes through a process called  . For this example, the process looks like this: To the user, this effectively creates the perception of interactivity, even though the browser is just swapping an orange image to a green one. Et voilà! Hopefully this has removed some of the mystery from how CSS goes from the braces you’ve written to rendered pixels in your browser. In this leg of our journey, we discussed how CSS is parsed, how values are computed, and how the cascade actually works. Then we dove into a discussion of layout, painting, and composition.  Now stay tuned for the final installment of this series, where one of the designers of the JavaScript language itself will discuss how browsers compile and execute our JavaScript. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/writing-for-designers-excerpt/", "title": "Writing for Designers", "content": "Shit. The writing. We forgot about the writing. The thing, the design thing…it needs words! Oh man, so many words. I thought somebody…wasn’t the client going to…shit. We’ve got to get the writing done. We’ve got to get the writing done! How are we going to get the writing done?! Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Don’t worry, friend. I’m here. We’ll get the writing done. The first step is to accept a hard truth:   has to do the writing. Some teams seem to build their whole process around   writing. They fill wireframes with   (that fake Latin text that confuses stakeholders) and write   on their buttons. I’ve been handed my share of comps where anything remotely word-based was represented by a bunch of squiggly lines. You know that comic about how to draw an owl? Step one: draw some circles. Step two: draw the rest of the fucking owl. That’s you with your squiggly lines. Rude. Everything left unwritten is a mystery box of incomplete design. These mysteries beget other mysteries, and pretty soon you’ve got dozens of screens of things that kinda-sorta-  make sense but none of them can really be final because  . Choosing words and   what appears in an interface forces us to name components, articulate choices, and explain things to the user. It’s part of design. We know this, don’t we? We knew it at the beginning of the design project, and yet here we are. Why did we wait? Writing is part of design Words are one of the most   design materials available. They convey deeply complex meanings in a compact space. They load fast. They’re easy to manipulate and easy to transmit. And the best part is, you don’t have to invent any of them! You just have to use them. Sometimes words get written off (see what I did there) as mere “details” in our designs. True details can wait until the end of your design process. Words, however, are deeply integrated throughout the user’s experience of your design. Look at your favorite app, site, or interface. Take all the words away and what do you have? Not much! Even if the particular thing you’re designing seems light on words, take a broader view and you’ll find words hiding everywhere: error messages and recovery flows confirmation screens user-visible metadata like page titles and search engine descriptions transactional emails in-app user assistance support documentation changelogs feature descriptions and marketing copy These are as much a part of the design as the layout, graphics, and animations. Designs   on words. Even if your design were simple, beautiful, and intuitive, writing can take it one step further. Writing can reinforce how you want users to think about your design. Writing can explain the approach or philosophy that underpins your design. Writing can guide users through complex processes. Writing can even help cover for the quirks and compromises in our designs—hopefully not our first resort, but valuable nonetheless. Sometimes the writing isn’t done because we’re trying to solve everything with “pure design.” Supposed UX thought leaders throw around baloney like “Good design doesn’t need explanation” and “If you have to use words, you’ve failed.” Come on. I hope my pilot knows what all those switches in the cockpit do, but I also hope they’re labeled, just in case. To keep things simple in this book, we’ll be talking about three general categories of writing you might have to do to support your design work:  Often referred to as UI copy or microcopy, this is the text that’s deeply integrated within the interface, like labels for form fields, text on buttons, navigation labels on a website, error messages, and similar. It’s often made of single words or short phrases. If the interface would “break” or be extremely hard to use if you removed this text, we’ll call it interface copy.  Writing that’s integral to the function of the site/product/app/experience, but not necessarily a direct part of the interface—the body of an onboarding email, for instance, or a description of updates to an application in a changelog. This is content focused on helping/supporting the reader.  Longer-form writing that is primarily filling a sales or promotional sort of role. This is content focused on persuading the reader. Depending on your product and organization, you might have many more buckets of content, or you may find the lines especially blurry even between these three. That’s okay! These buckets will just make things easier while we talk about writing in this book. Cool? Cool. (Oh, and “copy” is just a way to distinguish words written by a designer from the more generic idea of “text,” which could be just about anything in your system, including user-generated input.) Writing is always hard If you know someone who makes writing look easy, you’re right. They make it look easy. You can’t plan well for a difficult journey if you assume it’s going to be an easy journey. Accepting that writing is hard is an important step toward making it easier and getting it done. Writing is hard because it’s personal. Even if you’re writing about something you don’t feel strongly about, or even something you disagree with, it’s still your writing. The words you write carry a little echo of you. To get the writing done, you’re going to have to be a little vulnerable. Maybe a lot. Writing is even hard for writers—and since most people don’t realize that, they make it even harder on writers. They don’t give writers enough time to write. They don’t provide enough information to work with. They say things that minimize the difficulty of the task and the skill required to complete it. “You’re so creative! This should be easy, right? Shoot me something back before lunch.” Ugh. Unfortunately, there’s no special potion you can take to help you get the writing done, and even the most beautifully retro hipster typewriter still needs you to operate the keys. Workflow gets the writing done So if magic won’t help you get the writing done, what will? In design contexts, a useful way to think about writing is  . Workflow is a big-picture idea that accommodates all kinds of different processes, techniques, and tools. If following a recipe is a process, making dinner is a workflow. A dinner-making workflow has obvious phases—plan the meal, prep the ingredients, mix and cook things, finish and serve the meal. The specific steps and outcomes vary depending on the meal, but the basic workflow remains the same. This is also a useful way to think about design writing. No matter what you’re cooking up—no matter how custom the request and how many dietary restrictions your stakeholders might have—you’ll follow the same basic workflow each time you do the writing: Planning your workflow means choosing the tools, techniques, people, and processes that will be part of each of these four phases. Until this framework becomes old hat, I recommend explicitly planning your writing workflow. Planning is how you avoid getting stuck. You might not immediately know every single tool, step, and person you’ll need to get the writing done. But knowing even a few things, and giving yourself a basic map to follow to get the writing done, will help you learn what’s missing. Planning your workflow doesn’t need to be a long process—or even something you share with other people. You can create a formal, structured worksheet to plan it out (Fig 0.1), you could sketch it out on a whiteboard or in a notebook (Fig 0.2), or simply make some notes at the top of a new document. The important thing is to think about   you’re going to get the writing done before you start writing. You can write Mr. Hays, my high school choir teacher, was a great recruiter. When he’d ask people to try out for choir, they’d protest with some version of “Oh, no, I can’t sing.” Nonsense, he’d say: “If you can talk, you can sing. It’s all the same muscles!” And, more often than not, he’d pull that student right over to a piano and demonstrate to them that they could, in fact, sing. In case you’re skeptical, worried, or unsure about whether or not you can handle this, here’s my pitch for writing: writing is just thinking plus typing. You can think. You can type (or otherwise get text into a computer). So yes, you can write. We’re going to get into all kinds of methods about how to compose and refine text throughout this book. But at the end of the day, writing is just thinking plus typing. Have some thoughts in your head, then write them down. Do this over and over until the writing is done. Every other tip, trick, method, and process is just an improvement or distillation of this basic approach. And more good news: writing is more like design than you might think. Common design activities like framing the problem, identifying constraints, and exploring solutions are part of writing, too. Many of the methodologies one might use in UX work can be part of a writing workflow: stakeholder interviews, user research, content auditing, ideation workshops, critiques, and more. Writing is always hard, yes. But it gets easier. Good? Good. We’re making progress already. It’s time to Prepare. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-slow-death-of-internet-explorer-and-future-of-progressive-enhancement/", "title": "The Slow Death of Internet Explorer and the Future of Progressive Enhancement", "content": "My first full-time developer job was at a small company. We didn’t have BrowserStack, so we cobbled together a makeshift device lab. Viewing a site I’d been making on a busted first-generation iPad with an outdated version of Safari, I saw a distorted, failed mess. It brought home to me a quote from Douglas Crockford, who once deemed the web “the most hostile software engineering environment imaginable.”  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The “works best with Chrome” problem Because of this difficulty, a problem has emerged. Earlier this year, a   warned of “works best with Chrome” messages seen around the web. Hi Larry, we apologize for the frustration. Groupon is optimized to be used on a Google Chrome browser, and while you are definitely able to use Firefox or another browser if you'd like, there can be delays when Groupon is not used through Google Chrome. — Groupon Help U.S. (@GrouponHelpUS)  Hi Rustram. We'd always recommend that you use Google Chrome to browse the site: we've optimised things for this browser. Thanks. — Airbnb Help (@AirbnbHelp)  There are more examples of this problem. In the popular messaging app Slack, voice calls work only in Chrome. In response to help requests, Slack explains its decision like this: “It requires significant effort for us to build out support and triage issues on each browser,  .” (Emphasis mine.) Google itself has repeatedly built sites—including Google Meet, Allo, YouTube TV, Google Earth, and YouTube Studio—that block alternative browsers entirely. This is clearly a bad practice, but highlights the fact that cross-browser compatibility can be difficult and time-consuming.  The significant feature gap, though, isn’t between Chrome and everything else. Of far more significance is the increasingly gaping chasm between Internet Explorer and every other major browser. Should our development practices be hamstrung by the past? Or should we dash into the future relinquishing some users in our wake? I’ll argue for a middle ground. We can make life easier for ourselves without breaking the backward compatibility of the web.  The widening gulf Chrome, Opera, and Firefox ship new features constantly. Edge and Safari eventually catch up. Internet Explorer, meanwhile, has been all but abandoned by Microsoft, which is attempting to push Windows users toward Edge. IE receives nothing but security updates. It’s a frustrating period for client-side developers. We read about new features but are often unable to use them—due to a single browser with a diminishing market share.  Some new features are utterly trivial ( !); some are for particular use cases you may never have (WebGL 2.0, Web MIDI, Web Bluetooth). Others already feel near-essential for even the simplest sites ( , Grid). The promise and reality of progressive enhancement For content-driven sites, the question of browser support should never be answered with a simple yes or no. CSS and HTML were designed to be fault-tolerant. If a particular browser doesn’t support   or service workers or  , you can still use those features. Your website will not implode. It’ll just lack that extra stylistic flourish or performance optimization in non-supporting browsers.  Other features, such as CSS Grid, require a bit more work. Your page layout is less enhancement than necessity, and Grid has finally brought a real layout system to the web. When used with care for simple cases, Grid can gracefully fall back to older layout techniques. We could, for example, fall back to  . Flexbox is by now a taken-for-granted feature among developers, yet even that is   in IE11.  In the code above, I’m setting all the immediate children of the grid to have a specified width and a margin. For browsers that support Grid, I’ll use   in place of   and define the width of the items with the   property. It’s not difficult, but it adds bloat and complexity if it’s repeated throughout a codebase for different layouts. As we start building entire page layouts with Grid (and eventually  ), providing a fallback for IE will become increasingly arduous. By using   for complex layout tasks, we’re effectively solving the same problem twice—using two different methods to create a similar result.   Some things are imperative. People have been   since 2013, but they’re still not widely used, and you can guess why: Internet Explorer doesn’t support them. Or take Shadow DOM. People have been doing conference talks about it for more than five years. It’s finally set to land in Firefox and Edge this year, and lands in Internet Explorer … at no time in the future. You can’t patch support with transpilers or polyfills or prefixes. Users have more browsers than ever to choose from, yet IE manages to single-handedly tie us to the pre-evergreen past of the web. If developing Chrome-only websites represents one extreme of bad development practice, shackling yourself to a vestigial, obsolete, zombie browser surely represents the other. The problem with shoehorning Rather than eschew modern JavaScript features, polyfilling and transpiling have become the norm.  , yet we’re sending all browsers transpiled versions of our code. Transpilation isn’t great for performance. A single five-line   function, for example, may well transpile to twenty-five lines of code. “I feel some guilt about the current state of affairs,” Alex Russell said of  , a transpiler that predated Babel. “I see so many traces where the combination of Babel transpilation overhead and poor [webpack] foo totally sink the performance of a site. … I’m sad that we’re still playing this game.” What you can’t transpile, you can often polyfill.   has become massively popular. Chrome gets sent a blank file. Ancient versions of IE receive a giant mountain of polyfills. We are sending the largest payload to those the least equipped to deal with it—people stuck on slow, old machines. What is to be done? Prioritize content Cutting the mustard is a technique popularized by the front-end team at BBC News. The approach cuts the browser market in two: all browsers receive a base experience or core content. JavaScript is conditionally loaded only by the more capable browsers. Back in 2012, their dividing line was this: , then a lead developer at the BBC, explained the rationale: “Over the last few years I feel that our industry has gotten lazy because of the crazy download speeds that broadband has given us. Everyone stopped worrying about how large their web pages were and added a ton of JS libraries, CSS files, and massive images into the DOM. This has continued on to mobile platforms that don’t always have broadband speeds or hardware capacity to render complex code.” The  , meanwhile, entirely omits both JavaScript and stylesheets from Internet Explorer 8 and further back.  Nature.com takes a similar approach, delivering only a very limited stylesheet to anything older than IE10. Were you to break into a museum, steal an ancient computer, and open Netscape Navigator,  . A user comes to your site for the content. They didn’t come to see a pretty gradient or a nicely rounded border-radius. They certainly didn’t come for the potentially  .  Anyone who’s been developing for the web for any amount of time will have come across a browser bug. You check your new feature in every major browser and it works perfectly—except in one. Memorizing support info from caniuse.com and using progressive enhancement is no guarantee that every feature of your site will work as expected.  Regardless of how perfectly formed and well-written your code, sometimes things break through no fault of your own, even in modern browsers. If you’re not actively testing your site, bugs are more likely to reach your users, unbeknownst to you. Rather than transpiling and polyfilling and hoping for the best, we can deliver what the person came for, in the most resilient, performant, and robust form possible: unadulterated HTML. No company has the resources to actively test their site on every old version of every browser.   Rather than leaving users to a mass of polyfills and potential JavaScript errors, we give them a basic but functional experience. Make a clean break What could a mustard cut look like going forward? You   conduct a feature query using JavaScript to conditionally load the stylesheet, but relying on JavaScript introduces a brittleness that would be best to avoid. You can’t use   inside an   block, so we’re left with media queries.  The following query will prevent the CSS file from being delivered to any version of Internet Explorer and older versions of other browsers:  We’re not really interested in what particular features this query is testing for; it’s just a hacky way to split between legacy and modern browsers. The shiny, modern site will be delivered to Edge, Chrome (and Chrome for Android) 39+, Opera 26+, Safari 9+, Safari on iOS 9+, and Firefox 47+. I based the query on the work of Andy Kirk. If you want to take a cutting-the-mustard approach but have to meet different support demands, he maintains a   with a range of options. We can use the same media query to conditionally load a Javascript file. This gives us one consistent dividing line between old and modern browsers:  brings the power of CSS media queries to JavaScript. The   property is a boolean that reflects the result of the query. If the media query we defined in the   tag evaluates to true, the JavaScript file will be added to the page.  It might seem like an extreme solution. From a marketing point of view, the site no longer looks “professional” for a small amount of visitors. However, we’ve managed to improve the performance for those stuck on old technology while also opening the possibility of using the latest standards on browsers that support them. This is far from a new approach. All the way back in 2001,   stopped delivering a visual design to Netscape 4. Readership among users of that browser  . Front-end development is complicated at the best of times. Adding support for a technologically obsolete browser adds an inordinate amount of time and frustration to the development process. Testing becomes onerous. Bug-fixing looms large.  By making a clean break with the past, we can focus our energies on building modern sites using modern standards without leaving users stuck on antiquated browsers with an untested and possibly broken site. We save a huge amount of mental overhead. If your content has real value, it can survive without flashy embellishments. And for Internet Explorer users on Windows 10, Edge is preinstalled.  Developers must avoid living in a bubble of MacBook Pros and superfast connections. There’s no magic bullet that enables developers to use bleeding-edge features. You may still need   and polyfills. If you’re planning to have a large user base in Asia and Africa, you’ll need to build a site that looks great in Opera Mini and UC Browser, which have their own limitations. You might choose a different cutoff point for now, but it will increasingly pay off, in terms of both user experience and developer experience, to make use of what the modern web has to offer. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/onboarding-a-college-student-discovers-a-list-apart/", "title": "Onboarding: A College Student Discovers A List Apart", "content": "What would you say if I told you I just read and analyzed over 350 articles from   in less than six weeks? “You’re crazy!” might have passed through your lips. In that case, what would you say if I was doing it for a grade? Well, you might say that makes sense. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As a part of an Independent Research Study for my undergraduate degree, I wanted to fill in some of the gaps I had when it came to working with the World Wide Web. I wanted to know more about user experience and user interface design, however, I needed the most help getting to know the industry in general. Naturally, my professor directed me to  . At first I wasn’t sure what I was going to get out of the assignment other than the credit I needed to graduate. What could one website really tell me? As I read article after article, I realized that I wasn’t just looking at a website—I was looking at a community. A community with history in which people have struggled to build the right way. One that is constantly working to be open to all. One that is always learning, always evolving, and sometimes hard to keep up with. A community that, without my realizing it, I had become a part of. For me, the web has pretty much always been there, but now that I am better acquainted with its past, I am energized to be a part of its future. Take a look at some of the articles that inspired this change in me. A bit of history I started in the   and went back as far as November 1999. What a whirlwind that was! I had no idea what people went through and the battles that they fought to make the web what it is today. Now, I don’t mean to date any of you lovely readers, but I would have been three years old when the first business article on   was published, so everything I read until about 2010 was news to me. For instance, when I came across Jeffrey Zeldman’s “ ” that was published in 2001, I had no idea what he was talking about! The literal note I wrote for that article was: “Some sh** went down in the late 1990s???” I was in the dark until I had the chance to Google it and sheepishly ask my parents. I had the same problem with the term  . It wasn’t until I looked it up that I realized I didn’t know what it was, because I never experienced Web 1.0 (having not had access to the internet until 2004). In that short time, the industry had completely reinvented itself before I ever had a chance to log on! The other bit of history that surprised me was how long and hard people had to fight to get web standards and accessibility in line. In school I’ve always been taught to make my sites accessible, and that just seemed like common sense to me. I guess I now understand why I have mixed feelings about  . What I learned about accessibility Accessibility is one of the topics I took a lot of notes on. I was glad to see that although a lot of progress had been made in this area, people were still taking the time to write about and constantly make improvements to it. In Beth Raduenzel’s “ ,” she explains the fundamentals to remember when designing for accessibility, including considering: keyboard users; blind users; color-blind users; low-vision users; deaf and hard-of-hearing users; users with learning disabilities and cognitive limitations; mobility-impaired users; users with speech disabilities; and users with seizure disorders. It was nice to have someone clearly spell it out. However, the term “user” was used a lot. This distances us from the people we are supposed to be designing for. Anne Gibson feels the same way; in  , she states that “[web] accessibility means that   can use the web.” All people. In “ ,” Manuel Matuzović gives exact examples of this: If your site takes ten seconds to load on a mobile connection, it’s not accessible. If your site is only optimized for one browser, it’s not accessible. If the content on your site is difficult to understand, your site isn’t accessible. It goes beyond just people with disabilities (although they are certainly not to be discounted). I learned a lot of tips for designing with specific people in mind. Like including   in my code to benefit visually-impaired users, and checking the   of my site for people with color blindness and low-vision problems. One   even inspired me to download a Sketch plugin to easily check the contrast of my designs in the future. I’m more than willing to do what I can to allow my website to be accessible to all, but I also understand that it’s not an easy feat, and I will  . User research and testing methods that were new to me Nevertheless, we still keep learning. Another topic on   I desperately wanted to absorb was the countless research, testing, and development methods I came across in my readings. Every time I turn around, someone else has come up with another way of working, and I’m always trying to keep my finger in the pie. I’m happy to report that the majority of the methods I read about I already knew about and have used in my own projects at school. I’ve been doing  , personas,  , and   all along, but I was surprised by how many new practices I’d come across. , the  ,  , and   were some of the methods that piqued my curiosity. Others like  ,  ,  ,  , and   I’ve heard of before, but have never been given the opportunity to try. ,   and   are those that stood out to me. I liked that they allow you to conduct research even if you don’t have any users in front of you. I learned a lot of new terms and did a lot of research in this section. After all, it’s easy to get lost in all the jargon. The endless amount of abbreviations I spent a lot of my time Googling terms during this project—especially with the older articles that mentioned programs like   that aren’t really used anymore. One of my greatest fears in working with web design is that someone will ask me something and I will have no idea what they are talking about. When I was reading all the articles, I had the hardest time with the substantial amount of abbreviations I came across:  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , and  , just to name a few. Did you manage to get them all? Probably not. We don’t use abbreviations in school because they aren’t always clear and the professors know we won’t know what they mean. To a newbie like me, these abbreviations feel like a barrier. A wall that divides the veterans of the industry and those trying to enter it. I can’t imagine how the clients must feel. It seems as if I am not alone in my frustrations. Inayaili de León says in her article “ ,” “We want people to care about design as much as we do, but how can they if we speak to them in a foreign language?” I’m training to be a designer, I’m in Design, and I had to look up almost every abbreviation listed above. What I learned about myself Prior to taking on this assignment, I would have been very hesitant to declare myself capable of creating digital design. To my surprise, I’m not alone.   thinks, “… the constant change and adjustments that come with living on the internet can feel overwhelming.”   admits, “It’s a lot to keep track of, whether you’ve been working on the web for [twenty] years or only [twenty] months.” My fear of not knowing all the fancy lingo was lessened when I read Lyza Danger Gardner’s “ .” She is a seasoned professional who admits to not knowing it all, so I, a soon-to-be-grad, can too. I have good foundations and Google on my side for those pesky abbreviations that keep popping up. As long as I just remember to use my brain as   suggests, when I go to get a job I should do just fine. Entering the workplace Before starting this assignment, I knew I wanted to work in digital and interaction design, but I didn’t know where. I was worried I didn’t know enough about the web to be able to design for it—that all the jobs out there would require me to know coding languages I’d never heard of before, and I’d have a hard time standing out among the crowd. The articles I read on   supplied me with plenty of solid career advice. After reading articles written by designers, project managers, developers, marketers, writers, and more, I’ve come out with a better understanding of what kind of work I want to do. In the article “ ,” Katie Kovalcin makes a good point about not forcing yourself to learn skills just because you feel the need to: We’ve all heard the argument that designers need to code. And while that might be ideal in some cases, the point is to expand your personal spectrum of skills to be more useful to your team, whether that manifests itself in the form of design, content strategy, UX, or even project management. A strong team foundation begins by addressing gaps that need to be filled and the places where people can meet in the middle. I already have skills that someone desperately needs. I just need to find the right fit and expand my skills from there. Brandon Gregory also feels that hiring isn’t all about technical knowledge. In  , he says, “personality, fit with the team, communication skills, openness to change, [and] leadership potential” are just as important. Along with solid technical fundamentals and good soft skills, it seems as if having a voice is also crucial. When I read Jeffrey Zeldman’s article “ ,” it became clear to me that if I ever wanted to get anywhere with my career, I was going to have to start writing. Standout articles The writers on   have opened my eyes to many new subjects and perspectives on web design. I particularly enjoyed looking through the game design lens in Graham Herrli’s “ .” It was one of the few articles where I copied his diagram on interaction personality types and their goals into my notebook. Another article that made me consider a new perspective was “ ” by Erik Kennedy. To start with one simple element and grow from there really made something click in my head. However, I think that the   I read between Mica McPheeters and Sara Wachter-Boettcher stuck with me the most. I actually caught myself saying “hmm” out loud as I was reading along. Sara’s point about crash-test dummies being sized to the average male completely shifted my understanding about how important user-centered design is. Like, life-or-death important. There is no excuse not to test your products or services on a variety of users if this is what’s at stake! It’s an article I’m glad I read. Problems I’ve noticed in the industry During the course of my project, I noticed some things about   that I was spending so much time on. Like, for example, it wasn’t until I got to the articles that were published after 2014 that I really started to understand and relate to the content; funnily enough, that was the year I started my design degree. I also noticed that it was around this time that female writers became much more prominent on the site. Today there may be many women on  , but I must point out a lack of women of color. Shoutout to Aimee Gonzalez-Cameron for her article “ ,” a beautiful assertion for cultural inclusion on the web through user-centered design. Despite the lack of representation of women of color, I was very happy to see many writers acknowledge their privilege in the industry. Thanks to  ,  , and   for their articles. My only qualm is that the topic of privilege has only appeared on   in the last five years. Because isn’t it kinda ironic? As creators of the web we aim to allow everyone access to our content, but not everyone has access to the industry itself. Sara Wachter-Boettcher wrote an interesting   that expands on this idea, which you should read if you haven’t already. However, I won’t hold it against any of you. That’s why we are here anyway: to learn. The takeaway Looking back at this assignment, I’m happy to say that I did it. It was worth every second (even with the possible eye damage from reading off my computer screen for hours on end). It was worth it because I learned more than I had ever anticipated. I received an unexpected history lesson of the recent internet past. I was bombarded by an explosion of new terms and abbreviations. I learned a lot about myself and how I can possibly fit into this community. Most importantly, I came out on the other end with more confidence in myself and my abilities—which is probably the greatest graduation gift I could receive from a final project in my last year of university. Thanks for reading, and wish me luck! Thanks Thanks to my Interactive Design professor Michael LeBlanc for giving me this assignment and pushing me to take it further. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/cult-of-the-complex/", "title": "The Cult of the Complex", "content": "’Tis a gift to be simple. Increasingly, in our line of work, ’tis a rare gift indeed. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In an industry that extols innovation over customer satisfaction, and prefers algorithm to human judgement (forgetting that every algorithm has human bias in its DNA), perhaps it should not surprise us that toolchains have replaced know-how. Likewise, in a field whose hiring practices overwhelmingly favor young white men, it’s perhaps to be expected that web making has become something of a dick measuring competition. It was not always this way, and it needn’t stay this way. If we wish to get back to the business of quietly improving people’s lives, one thoughtful interaction at a time, we must rid ourselves of the cult of the complex. Admitting the problem is the first step in solving it. And the div cries Mary In 2001, more and more of us began using CSS to replace the   with which we’d designed the web’s earliest sites. I soon noticed something about many of our new CSS-built sites. I especially noticed it in sites built by the era’s expert backend coders, many of whom viewed HTML and CSS as baby languages for non-developers. In those days, whether from contempt for the deliberate, intentional (designed) limitations of HTML and CSS, or ignorance of the HTML and CSS framers’ intentions, many code jockeys who switched from table layouts to CSS wrote markup consisting chiefly of divs and spans. Where they meant list item, they wrote span. Where they meant paragraph, they wrote div. Where they meant level two headline, they wrote div or span with a classname of h2, or, avoiding even that tragicomic gesture toward document structure, wrote a div or span with verbose inline styling. Said div was followed by another, and another. They bred like locusts, stripping our content of structural meaning. As an early adopter and promoter of CSS via my work in The Web Standards Project (kids, ask your parents), I rejoiced to see our people using the new language. But as a designer who understood, at least on a basic level, how HTML and CSS were supposed to work together, I chafed. Cry, the beloved font tag Everyone who wrote the kind of code I just described thought they were advancing the web merely by walking away from table layouts. They had good intentions, but their executions were flawed. My colleagues and I here at   were thus compelled to explain a few things. Mainly, we argued that HTML consisting mostly of divs and spans and classnames was in no way better than table layouts for content discovery, accessibility, portability, reusability, or the web’s future. If you wanted to build for people and the long term, we said, then simple, structural, semantic HTML was best—each element deployed for its intended purpose.  This basic idea, and I use the adjective advisedly, along with other equally rudimentary and self-evident concepts, formed the basis of my 2003 book  , which the industry treated as a revelation, when it was merely common sense. The message messes up the medium When we divorce ideas from the conditions under which they arise, the result is dogma and misinformation—two things the internet is great at amplifying. Somehow, over the years, in front-end design conversations, the premise “don’t use a div when you mean a p” got corrupted into “divs are bad.” A backlash in defense of divs followed this meaningless running-down of them—as if the W3C had created the div as a forbidden fruit. So, let’s be clear. No HTML element is bad. No HTML element is good. A screwdriver is neither good nor bad, unless you try to use it as a hammer. Good usage is all about appropriateness. Divs are not bad. If no HTML5 element is better suited to an element’s purpose, divs are the best and most appropriate choice. Common sense, right? And yet. Somehow, the two preceding simple sentences are never the takeaway from these discussions. Somehow, over the years, a vigorous defense of divs led to a defiant (or ignorant) overuse of them. In some strange way, stepping back from a meaningless rejection of divs opened the door to gaseous frameworks that abuse them. Note: We don’t mind so much about the abuse of divs. After all, they are not living things. We are not purists. It’s the people who use the stuff we design who suffer from our uninformed or lazy over-reliance on these div-ridden gassy tools. And that suffering is what we protest.  -ridden, overbuilt frameworks stuffed with mystery meat offer the developer tremendous power—especially the power to build things quickly. But that power comes at a price your users pay: a hundred tons of stuff your project likely doesn’t need, but you force your users to download anyway. And that bloat is not the only problem. For who knows what evil lurks in someone else’s code? Two cheers for frameworks If you entered web design and development in the past ten years, you’ve likely learned and may rely on frameworks. Most of these are built on meaningless arrays of divs and spans—structures no better than the bad HTML we wrote in 1995, however more advanced the resulting pages may appear. And what keeps the whole monkey-works going? JavaScript, and more JavaScript. Without it, your content may not render. With it, you may deliver more services than you intended to. There’s nothing wrong with using frameworks to quickly whip up and test product prototypes, especially if you do that testing in a non-public space. And theoretically, if you know what you’re doing, and are willing to edit out the bits your product doesn’t need, there’s nothing wrong with using a framework to launch a public site. Notice the operative phrases:  . Alas, many new designers and developers (and even many experienced ones) feel like they can’t launch a new project without dragging in packages from NPM, or Composer, or whatever, with no sure idea what the code therein is doing.   Yet here we are, training an entire generation of developers to build and launch projects with untrusted code. Indeed, many designers and developers I speak with would rather dance naked in public than admit to posting a site built with hand-coded,   HTML, CSS, and JavaScript they understand and wrote themselves. For them, it’s a matter of job security and viability. There’s almost a fear that if you haven’t mastered a dozen new frameworks and tools each year (and by mastered, I mean used), you’re slipping behind into irrelevancy. HR folks who write job descriptions listing the ten thousand tool sets you’re supposed to know backwards and forwards to qualify for a junior front-end position don’t help the situation. CSS is not broken, and it’s not too hard As our jerrybuilt contraptions, lashed together with fifteen layers of code we don’t understand and didn’t write ourselves, start to buckle and hiss, we blame HTML and CSS for the faults of developers. This fault-finding gives rise to ever more complex cults of specialized CSS, with internecine sniping between cults serving as part of their charm. New sects spring up, declaring CSS is broken, only to splinter as members disagree about precisely which way it’s broken, or which external technology not intended to control layout should be used to “fix” CSS. (Hint: They mostly choose JavaScript.) Folks, CSS is not broken, and it’s not too hard. (You know what’s hard? Chasing the ever-receding taillights of the next shiny thing.) But don’t take my word for it. Check these out: CSS Grid is here; it’s logical and fairly easy to learn. You can use it to accomplish all kinds of layouts that used to require JavaScript and frameworks, plus new kinds of layout nobody’s even tried yet. That kind of power requires some learning, but it’s good learning, the kind that stimulates creativity, and its power comes at no sacrifice of semantics, or performance, or accessibility. Which makes it web technology worth mastering. The same cannot be said for our deluge of frameworks and alternative, JavaScript-based platforms. As a designer who used to love creating web experiences in code, I am baffled and numbed by the growing preference for complexity over simplicity. Complexity is good for convincing people they could not possibly do your job. Simplicity is good for everything else. Keep it simple, smarty Good communication strives for clarity. Design is its most brilliant when it appears  —most simple. The question for web designers should never be how complex can we make it. But that’s what it has become. Just as, in pursuit of “ ,” we forget the true joy reliable, invisible interfaces can bring, so too, in chasing job security, do we pile on the platform requirements, forgetting that design is about solving business and customer problems … and that baseline skills never go out of fashion. As ALA’s Brandon Gregory, writing elsewhere, explains: I talk with a lot of developers who list Angular, Ember, React, or other fancy JavaScript libraries among their technical skills. That’s great, but can you turn that mess of functions the junior developer wrote into a custom extensible object that we can use on other projects, even if we don’t have the extra room for hefty libraries? Can you code an image slider with vanilla JavaScript so we don’t have to add jQuery to an older website just for one piece of functionality? Can you tell me what recursion is and give me a real-world example? Growing pains There’s a lot of complexity to good design. Technical complexity. UX complexity. Challenges of content and microcopy. Performance challenges. This has never been and never will be an easy job. Simplicity is not easy—not for us, anyway. Simplicity means doing the hard work that makes experiences   seamless—the sweat and torture-testing and failure that eventually, with enough effort, yields experiences that seem to “just work.” Nor, in lamenting our industry’s turn away from basic principles and resilient technologies, am I suggesting that CDNs and Git are useless. Or wishing that we could go back to FTP—although I did enjoy the early days of web design,  . I’m glad I got to experience those simpler times. But I like these times just fine. And I think you do, too. Our medium is growing up, and it remains our great privilege to help shape its future while creating great experiences for our users. Let us never forget how lucky we are, nor, in chasing the ever-shinier, lose sight of the people and purpose we serve. Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/orchestrating-experiences/", "title": "Orchestrating Experiences", "content": "If you embrace the recommended collaborative approaches in your sense-making activities, you and your colleagues should build good momentum toward creating better and valuable end-to-end experiences. In fact, the urge to jump into solution mode will be tempting. Take a deep breath: you have a little more work to do. To ensure that your new insights translate into the right actions, you must collectively define what is   and hold one another accountable for aligning with it. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. , in this context, means the ideas and solutions that you commit to reflect your customers’ needs and context while achieving organizational objectives. It also means that each touchpoint harmonizes with others as part of an orchestrated system. Defining  , in this way, provides common constraints to reduce arbitrary decisions and nudge everyone in the same direction. How do you align an organization to work collectively toward the same  ? Start with some common guidelines called  . A Common DNA Experience principles are a set of guidelines that an organization commits to and follows from strategy through delivery to produce mutually beneficial and differentiated customer experiences. Experience principles represent the alignment of brand aspirations and customer needs, and they are derived from understanding your customers. In action, they help teams own their part (e.g., a product, touchpoint, or channel) while supporting consistency and continuity in the end-to-end experience. Figure 6.1 presents an example of a set of experience principles. Experience principles are not detailed standards that everyone must obey to the letter. Standards tend to produce a rigid system, which curbs innovation and creativity. In contrast, experience principles inform the many decisions required to define what experiences your product or service should create and how to design for individual, yet connected, moments. They communicate in a few memorable phrases the organizational wisdom for how to meet customers’ needs consistently and effectively. For example, look at the following:     \t Paint me a picture. Have my back. Set my expectations. Be one step ahead of me. Respect my time. Orchestrating experiences is a team sport. Many roles contribute to defining, designing, and delivering products and services that result in customer experiences. For this reason, the label experience—rather than design—reflects the value of principles better that inform and guide the organization. Experience principles are outcome oriented; design principles are process oriented. Everyone should follow and buy into them, not just designers. Experience principles are grounded in customer needs, and they keep collaborators focused on the why, what, and how of engaging people through products and services. They keep critical insights and intentions top of mind, such as the following: : How part of an experience can help people have a better understanding, or how it should conform to their mental model. : How part of an experience should support the customer emotionally, or directly address their motivations. : How part of an experience should enable someone to do something they set out to do better. : The characteristics to which an experience should adhere. : The outcomes and qualities an experience should engender in the user or customer. Many universal or heuristic principles exist to guide design work. There are visual design principles, interaction design principles, user experience principles, and any number of domain principles that can help define the best practices you apply in your design process. These are lessons learned over time that have a broader application and can be relied on consistently to inform your work across even disparate projects. It’s important to reinforce that experience principles specific to your customers’ needs provide contextual guidelines for strategy and design decisions. They help everyone focus on what’s appropriate to specific customers with a unique set of needs, and your product or service can differentiate itself by staying true to these principles. Experience principles shouldn’t compete with best practices or universal principles, but they should be honored as critical inputs for ensuring that your organization’s specific value propositions are met. Playing Together Earlier, we compared channels and touchpoints to instruments and notes played by an orchestra, but in the case of experience principles, it’s more like jazz. While each member of a jazz ensemble is given plenty of room to improvise, all players understand the common context in which they are performing and carefully listen and respond to one another (see Figure 6.2). They know the standards of the genre backward and forward, and this knowledge allows them to be creative individually while collectively playing the same tune. Experience principles provide structure and guidelines that connect collaborators while giving them room to be innovative. As with a time signature, they ensure alignment. Similar to a melody, they provide a foundation that encourages supportive harmony. Like musical style, experience principles provide boundaries for what fits and what doesn’t. Experience principles challenge a common issue in organizations: isolated soloists playing their own tune to the detriment of the whole ensemble. While still leaving plenty of room for individual improvisation, they ask a bunch of solo acts to be part of the band. This structure provides a foundation for continuity in the resulting customer journey, but doesn’t overengineer consistency and predictability, which might prevent delight and differentiation. Stressing this balance of designing the whole while distributing effort and ownership is a critical stance to take to engender cross-functional buy-in. To get broad acceptance of your experience principles, you must help your colleagues and your leadership see their value. You will need to craft value propositions for your different stakeholders, educate the stakeholders on how to use experience principles, and pilot the experience principles to show how they are used  in action. This typically requires crafting specific value propositions and education materials for different stakeholders to gain broad support and adoption. Piloting your experience principals on a project can also help others understand their tactical use. When approaching each stakeholder, consider these common values: : While different channels and media have their specific best practices, experience principles provide a common set of criteria that can be applied across an entire end-to-end experience. : Throughout the process of determining what to do strategically and how to do it tactically, experience principles ensure that customers’ needs and desires are represented in the decision-making process. : Because these constraints represent the alignment of brand aspiration and customer desire, experience principles can filter out ideas or solutions that don’t reinforce this alignment. : Used consistently, experience principles reduce ambiguity and the resultant churn when determining what concepts should move forward and how to design them well. : Experience principles are very effective in sparking new ideas with greater confidence that will map back to customer needs. (See Chapter 8, “Generating and Evaluating Ideas.”) : Through the execution lifecycle, experience principles can be used to critique touchpoint designs (i.e., the parts) to ensure that they align to the greater experience (i.e., the whole). Pitching and educating aside, your best bet for creating good experience principles that get adopted is to avoid creating them in a black box. You don’t want to spring your experience principles on your colleagues as if they were commandments from above to follow blindly. Instead, work together to craft a set of principles that everyone can follow energetically. Identifying Draft Principles Your research into the lives and journeys of customers will produce a large number of insights. These insights are  . They capture people’s current experiences—such as, their met and unmet needs, how they frame the world, and their desired outcomes. To craft useful and appropriate experience principles, you must turn these insights inside out to project what future experiences should be. If you lack strong customer insights (and the support or time to gather them), it’s still valuable to craft experience principles with your colleagues. The process of creating them provides insight into the various criteria that people are using to make decisions. It also sheds light on what your collaborators believe are the most important customer needs to meet. While not as sound as research-driven principles, your team can align around a set of guidelines to inform and critique your collective work—and then build the case for gathering insights for creating better experience principles. From the Bottom Up The leap from insights to experience principles will take several iterations. While you may be able to rattle off a few candidates based on your research, it’s well worth the time to follow a more rigorous approach in which you work from the bottom (individual insights) to the top (a handful of well-crafted principles). Here’s how to get started: Reassemble your facilitators and experience mappers, as they are closest to what you learned in your research. Go back to the key insights that emerged from your discovery and research. These likely have been packaged in maps, models, research reports, or other artifacts. You can also go back to your raw data if needed. Write each key insight on a sticky note. These will be used to spark a first pass at potential principles. For each insight, have everyone take a pass individually at articulating a principle derived from just that insight. You can use sticky notes again or a quarter sheet of 8.5″’’x 11″’ (A6) template to give people a little more structure (see Figure 6.3). At this stage, you should coach participants to avoid finding the perfect words or a pithy way to communicate a potential principle. Instead, focus on getting the core lesson learned from the insight and what advice you would give others to guide product or service decisions in the future. Table 6.1 shows a couple of examples of what a good first pass looks like. At this stage, don’t be a wordsmith. Work quickly to reframe your insights from something you know (“Most people don’t want to…”) to what should be done to stay true to this insight (“Make it easy for people…”). Work your way through all the insights until everyone has a principle for each one. Finding Patterns You now have a superset of individual principles from which a handful of experience principles will emerge. Your next step is to find the patterns within them. You can use affinity mapping to identify principles that speak to a similar theme or intent. As with any clustering activity, this may take a few iterations until you feel that you have mutually exclusive categories. You can do this in just a few steps: Select someone to be a workshop participant to present the principles one by one, explaining the intent behind each one. Cycle through the rest of the group, combining like principles and noting where principles conflict with one another. As you cluster, the dialogue the group has is as important as where the principles end up. Once things settle down, you and your colleagues can take a first pass at articulating a principle for each cluster. A simple half sheet (8.5” x 4.25” or A5) template  can give some structure to this step. Again, don’t get too precious with every word yet.  (see Figure 6.4). Get the essence down so that you and others can understand and further refine it with the other principles. You should end up with several mutually exclusive categories with a draft principle for each. Designing Principles as a System No experience principle is an island. Each should be understandable and useful on its own, but together your principles should form a system. Your principles should be complementary and reinforcing. They should be able to be applied across channels and throughout your product or service development process. See the following “Experience Principles Refinement Workshop” for tips on how to critique your principles to ensure that they work together as a complete whole. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/problem-with-patterns/", "title": "The Problem with Patterns", "content": "It started off as an honest problem with a brilliant solution. As the ways we use the web continue to grow and evolve, we, as its well-intentioned makers and stewards, needed something better than making simple collections of pages over and over again. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Design patterns, component libraries, or even style guides have become the norm for organizations big and small. Having reusable chunks of UI aids consistency and usability for users, and it lends familiarity and efficiency to designers. This in turn frees up designers’ time to focus on bigger problems, like solving for their users’ needs. In theory. The use of design patterns, regardless of their scope or complexity, should never stifle creativity or hold back design progress. In order to achieve what they promise, they should be adaptable, flexible, and scalable. A good design pattern is undeterred by context, and most importantly, is unobtrusive. Again, in theory. Before getting further into the weeds, let’s define what is meant by the term   here. You’re probably wondering what the difference is between all the different combinations of the same handful of words being used in the web community. Initially,   were small pieces of a user interface, like buttons and error messages. Design patterns go beyond the scope and function of a style guide, which deals more with documenting how something should look, feel, or work. Type scales, design principles, and writing style are usually found within the bounds of a style guide. More recently, the scope of design patterns has expanded as businesses and organizations look to work more efficiently and consistently, especially if it involves a group or family of products and services. Collections of design patterns are then commonly used to create reusable components of a larger scope, such as account sign-up, purchase checkout, or search. This is most often known as the component library. The final evolution of all these is known as a   (or a  ). This encompasses the comprehensive set of design standards, documentation, and principles. It includes the design patterns and components to achieve those standards and adhere to those principles. More often than not, a design system is still used day-to-day by designers for its design patterns or components. The service design pattern A significant reason why designing for the web has irrevocably changed like this is due to the fact that more and more products and services live on it. This is why service design is becoming much more widely valued and sought after in the industry. —unlike all of the above patterns, which focus on relatively small and compartmentalized parts of a UI—go above and beyond. They aim to incorporate an entire task or chunk of a user’s journey. For example, a credit card application can be represented by some design patterns or components, but the   to obtain a credit card is a service pattern. If thinking in terms of an analogy like  , service patterns don’t fit any one category (atoms, molecules, organisms, etc). For example, a design pattern for a form can be described as a  . It does one thing and does it well. This is the beauty of a good design pattern—it can be taken without context and used effectively across a variety of situations.  attempt to combine the goals of both design patterns and components by creating a reusable task. In theory. So, what’s the problem? The design process is undervalued Most obvious misuses of patterns are easy to avoid with good documentation, but do patterns actually result in better-designed products and services? Having a library of design components can sometimes give the impression that all the design work has been completed. Designers or developers can revert to using a library as clip art to create “off-the-shelf” solutions. Projects move quickly into development. Although patterns do help teams hesitate less and build things in shorter amounts of time, it is how and why a group of patterns and components are stitched together that results in great design. For example, when designing digital forms, using button and input fields patterns will improve familiarity and consistency, without a doubt. However, there is no magic formula for the order in which questions on a form should be presented or for how to word them. To best solve for a user’s needs, an understanding of their goals and constraints is essential. Patterns can even cause harm without considering a user’s context and the bearing it may have on their decision-making process. For example, if a user will likely be filling out a form under stress (this can be anything from using a weak connection, to holding a mobile phone with one hand, to being in a busy airport), an interface should prioritize minimizing cognitive load over the number of steps or clicks needed to complete it. This decision architecture cannot be predetermined using patterns. Patterns don’t start with user needs Components and service patterns have a tendency to serve the needs of the business or organization, not the user. If you are simply designing a way to apply for a work visa, having form field and button patterns is very useful. But any meaningful testing sessions with users will speak to how confident they felt in obtaining the necessary documents to work   abroad, not if they could simply locate a “submit” button. User needs are conflated with one another Patterns are also sometimes a result of grouping together user needs, essentially creating a set of fictional users that in reality do not exist. Users usually have one goal that they want to achieve efficiently and effectively. Assembling a group of user needs can result in a complex system trying to be everything to everyone. For example, when creating a design pattern for registering users to a service across a large organization, the challenge can very quickly move from: “How can I check the progress of my application?” \n“Can I update or change my delivery address?” \n“Can I quickly repeat or renew an application?” to: “How can   get all the details we need from users to allow them to register for an account?” The individual user needs are forgotten and replaced with a combined assumed need to “register for an account” in order to “view a dashboard.” In this case, the original problem has even been adapted to suit the design pattern instead of the other way around.   Outcomes are valued over context Even if they claim to address user context, the success of a service pattern might still be measured through an end result, output, or outcome. Situations, reactions, and emotions are still overlooked. Take mass transit, for example. When the desired outcome is to get from Point A to Point B, we may find that a large number of users need to get there  , especially if they’re headed home from work. But we cannot infer from this need that the most important goal of transportation is speed. Someone traveling alone at night or in unfamiliar surroundings may place greater importance on safety or need more guidance and reassurance from the service. Sometimes, service patterns cannot solve complex human problems like these. More often than not, an over-reliance on outcome-focused service patterns just defeats the purpose of building any empathy during the design process. For example, date pickers tend to follow a similar pattern across multiple sectors, including transport, leisure, and healthcare. Widely-used patterns like this are intuitive and familiar to most users. This does not mean that the same date picker pattern can be used seamlessly in any service. If a user is trying to book an emergency doctor appointment, the same patterns seen above are suddenly much less effective. Being presented with a full calendar of options is no longer helpful because choice is no longer the most valuable aspect of the service. The user needs to quickly see the first available appointment with minimal choices or distractions. Digital by default Because patterns are built for reuse, they sometimes encourage us to use them without much question, particularly assuming that digital technology is the solution. A   encompasses everything a user needs to complete their goal. By understanding the user’s entire journey, we start to uncover their motivations and can begin to think about new, potentially non-digital ways to solve their problems. For example, the Canadian Immigration Service receives more than 5.2 million inquiries a year by email or phone from people looking for information about applications.  One of the most common reasons behind the complaints was the time it took to complete an application over the phone. Instead of just taking this data and speeding up the process with a digital form, the product team focused on understanding the service’s users and their reasons behind their reactions and behaviors. For example, calls received were often bad-tempered, despite callers being greeted by a recorded message informing them of the length of time it could take to process an application, and advising them against verbally abusing the staff.   The team found that users were actually more concerned with the lack of information than they were with the length of time it took to process their application. They felt confused, lost, and clueless about the immigration process. They were worried they had missed an email or letter in the mail asking for missing documentation. In response to this, the team decided to change the call center’s greeting, setting the tone to a more positive and supportive one. Call staff also received additional training and began responding to questions even if the application had not reached its standard processing time. The team made sure to not define the effectiveness of the design by how short new calls were. Although the handling time for each call went up by 16 percent, follow-up calls dropped by a whopping 30 percent in fewer than eight weeks, freeing up immigration agents’ time to provide better quality information to callers. Alternatives to patterns As the needs of every user are unique, every service is also unique. To design a successful service you need to have an in-depth understanding of its users, their motivations, their goals, and their situations. While there are numerous methodologies to achieve this, a few key ones follow: Framing the problem Use research or discovery phases to unearth the real issues with the existing service or process. Contextual research sessions can help create a deeper understanding of users, which helps to ensure that the root cause of a problem is being addressed, not just the symptoms. Journey maps Journey maps are used to create a visual representation of a service through the eyes of the user. Each step a user takes is recorded against a timeline along with a series of details including: how the user interacts with the service; how the service interacts with the user; the medium of communication; the user’s emotions; and service pain points. Service teams, not product teams Setting up specialist pattern or product teams creates a disconnect with users. There may be common parts to user journeys, such as sign-up or on-boarding, but having specialist design teams will ultimately not help an organization meet user (and therefore business) needs. Teams should consider taking an end-to-end, service approach. Be open and inclusive Anyone on a wider team should be able to contribute to or suggest improvements to a design system or component library. If applicable, people should also be able to prune away patterns that are unnecessary or ineffective. This enables patterns to grow and develop in the most fruitful way. Open-sourcing pattern libraries, like the ones managed by   or  , is a good way to keep structure and process in place while still allowing people to contribute. The transparent and direct review process characteristic of the open-source spirit can also help reduce friction. Across larger organizations, this can be harder to manage, and the time commitment can contradict the intended benefits. Still, some libraries, such as the  , exist and are open to suggestions and feedback. In summary A design pattern library can range from being thorough, trying to cover all the bases, to politely broad, so as to not step on the toes of a design team. But patterns should never sacrifice user context for efficiency and consistency. They should reinforce the importance of the design process while helping an organization think more broadly about its users’ needs and its own goals. Real-world problems rarely are solved with out-of-the-box solutions. Even in service design. Like this: \n\t\t\t\t\t\t\tRecently by Cathy Dutton\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/discovery-on-a-budget-part-iii/", "title": "Discovery on a Budget: Part III", "content": "Sometimes we have the luxury of large budgets and deluxe research facilities, and sometimes we’ve got nothing but a research question and the determination to answer it. Throughout the “Discovery on a Budget” series we have discussed strategies for conducting discovery research with very few resources but lots of creativity. In   we discussed the importance of a clearly defined problem hypothesis and started our affordable research with user interviews. Then, in  , we discussed competing hypotheses and “fake-door” A/B testing when you have little to no traffic. Today we’ll conclude the series by considering the pitfalls of the most tempting and   affordable research method of all: surveys. We will also answer the question “when are you done with research and ready to build something?”  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. A quick recap on Candor Network Throughout this series I’ve used a budget-conscious, and fictitious, startup called   as my example. Like most startups, Candor Network started simply as an idea: I bet end-users would be willing to pay directly for a really good social networking tool. But there are lots of big unknowns behind that idea. What exactly would “really good” mean? What are the critical features? And what would be the central motivation for users to try yet another social networking tool?   To kick off my discovery research, I created a hypothesis based on my own personal experience: that a better social network tool would be one designed with mental health in mind. But after conducting a series of interviews, I realized that people might be   interested in a social network that focused on data privacy as opposed to mental health. I captured this insight in a second, competing hypothesis. Then I launched two corresponding “fake door” landing pages for Candor Network so I could A/B test both ideas.  For the past couple of months I’ve run an A/B test between the two landing pages where half the traffic goes to version A and half to version B. In both versions there is a short, two-question survey. To start our discussion today, we will take a more in-depth look at this seemingly simple survey, and analyze the results of the A/B test.  Surveys: Proceed with caution Surveys are probably the most used, but least useful, research tool. It is   so tempting to say, “lets run a quick survey” when you find yourself wondering about customer desires or user behavior. Modern web-based tools have made surveys incredibly quick, cheap, and simple to run. But as anyone who has ever tried running a “quick survey” can attest, they rarely, if ever, provide the insight you are looking for. , surveys are “too easy.” They are too easy to create, too easy to disseminate, and too easy to tally. This inherent ease masks the survey’s biggest flaw as a research method: it is far,   too easy to create biased, useless survey questions. And when you run a survey littered with biased, useless questions, you either (1) realize that your results are not reliable and start all over again, or (2) proceed with the analysis and make decisions based on biased results. If you aren’t careful, a survey can be a complete waste of time, or worse, lead you in the wrong direction entirely.  However, sometimes a survey is the only method at your immediate disposal. You might be targeting a user group that is difficult to reach through other convenience- or “guerilla”-style means (think of products that revolve around taboo or sensitive topics—it’s awfully hard to spring those conversations on random people you meet in a coffee shop!). Or you might work for a client that is reluctant to help locate research participants in any way beyond sending an email blast with a survey link. Whatever the case may be, there are times when a survey is the only step forward you can take. If you find yourself in that position, keep the following tips in mind.  Tip 1: Try to stick to questions about facts, not opinions If you were building a website for ordering dog food and supplies, a question like “how many dogs do you own?” can provide key demographic information not available through standard analytics. It’s the sort of question that works great in a short survey. But if you need to ask “why did you decide to adopt a dog in the first place?” then you’re much better off with a user interview. If you try asking any kind of “why” question in a survey, you will usually end up with a lot of “I don’t know” and otherwise blank responses. This is because people are, in general, not willing to write an essay on why they’ve made a particular choice (such as choosing to adopt a dog) when they’re in the middle of doing something (like ordering pet food). However, when people schedule time for a phone call, they are more than willing to talk about the “whys” behind their decisions. In short, people like to   about their opinions, but are generally too lazy or busy to   about their opinions. Save the why questions for later (and see Tip 5). Tip 2: Avoid asking about the future People live in the present, and only dream about the future. There are a lot of things outside of our control that affect what we will buy, eat, wear, and do in the future. Also, sometimes the future selves we imagine are more   than factual. For example, if you were to ask a random group of people how many times they plan to go to the gym next month, you might be (not so) surprised to see that their prediction is significantly higher than the actual number. It is much better to ask “how many times did you go to the gym this week?” as an indicator of general gym attendance than to ask about any future plans.  I asked a potentially problematic, future-looking question in the Candor Network landing page survey:  How much would you be willing to pay, per year, for Candor Network? Would not pay anything $1 $5 $10 $15 $20 $25 $30 Would pay more In this question, I’m asking participants to think about how much money they would like to spend in the future on a product that doesn’t exist yet. This question is problematic for a number of reasons, but the main issue is that people, in general, don’t know how they   feel about pricing until the exact moment they are poised to make a purchase. Relying on this question to, say, develop my income projections for an investor pitch would be unwise to say the least. (I’ll discuss what I   plan to do with the answers to this question in the next tip.) Tip 3: Know how you are going to analyze responses before you launch the survey A lot of times, people will create and send out a survey without thinking through what they are going to do with the results once they are in hand. Depending on the length and type of survey, the analysis could take a significant amount of time. Also, if you were hoping to answer some specific questions with the survey data, you’ll want to make sure you’ve thought through how you’ll arrive at those answers. I recommend that while you are drafting survey questions, you also simultaneously draft an analysis plan. In your analysis plan, think about what you are ultimately trying to learn from each survey question. How will you know when you’ve arrived at the answer? If you are doing an A/B test like I am, what statistical analysis should you run to see if there is a significant difference between the versions? You should also think about what the numbers will look like and what kinds of graphs or tables you will need to build. Ultimately, you should try to visualize what the data will look like before you gather it, and plan accordingly. For example, when I created the two survey questions on the Candor Network landing pages, I created a short analysis plan for each. Here is what those plans looked like:  Each response will go into one of two buckets: Bucket 1: said they would not pay any money; and Bucket 2: said they might pay some money. Everyone who answered “Would not pay anything” goes in Bucket 1. Everyone else goes in Bucket 2. I will interpret every response that falls into Bucket 2 as an indicator of general interest (and I’m   going to put any value on the specific answer selected). To see whether any difference in response between landing page A and B is statistically significant (i.e., attributable to more than just chance), I will use a  . (Side note: There are   we could use in this scenario, but I like chi-square because of its simplicity. It is a test that’s easy for non-statisticians to run and understand, and it errs on the conservative side.) The question only has two possible responses: “yes” and “no.” I will interpret every “yes” response as an indicator of general interest in the idea. Again, a chi-square test will show if there is a significant difference between the two landing pages.   Tip 4: Never rely on a survey by itself to make important decisions Surveys are hard to get right, and even when they are well made, the results are often approximations of what you   want to measure. However, if you pair a survey with a series of user interviews or contextual inquiries, you will have a richer, more thorough set of data to analyze. In the social sciences, this is called  . If you use multiple methods to triangulate and study the same phenomenon, you will get a richer, more complete picture. This leads me to my final tip … Tip 5: End every survey with an opportunity to participate in future research There have been many times in my career when I have launched surveys with only one objective in mind: to gather the contact information of potential study participants. In cases like these, the survey questions themselves are not   superfluous, but they are certainly secondary to the main research objective. Shortly after the survey results have been collected, I will select and email a few respondents, inviting them to participate in a user interview or usability study. If I planned on continuing Candor Network, this is absolutely what I would do.  Finally, the results According to Google Optimize, there were a total of 402 sessions in my experiment. Of those sessions, 222 saw version A and 180 saw version B. Within the experiment, I tracked how often the “submit” button on the survey was clicked, and Google Optimize tells me “no clear leader was found” on that measure of engagement. Roughly an equal number of people from each condition submitted the survey.  Here is a breakdown of the number of sessions and survey responses each condition received: When we look at the actual answers to the survey questions, we start to get some more interesting results. Plugging these figures into  , I get the following values:   = 2.7523, p = 0.097113. In general, bigger chi-square values indicate greater differences between the groups. And the   is less than 0.1, which suggests that the result is marginally significant (i.e., the result is probably not due to random chance). This gives me a modest indicator that respondents in group B, who saw the “data secure” version of the landing page, are more likely to fall into the “might pay some money” bucket. And when we look at the breakdown and chi-square calculation of question two, we see similar results.  The   = 2.9189, and   = .087545. Again, I have a modest indicator that respondents in group B are more likely to say yes to participating in future research. (If you’d like to learn more about how to run and interpret chi-square tests, the Interaction Design department at the University of California, San Diego has provided a  .) How do we know when it’s time to move on? I wish I could provide you with a formula for calculating the exact moment when the research is done and it’s time to move on to prototyping, but I’m afraid no such formula exists. There is no definitive way to determine how much research is enough. Every round of research teaches you something new, but you are always left with more questions. As Albert Einstein said, “the more I learn, the more I realize how much I don’t know.” However, with experience you come to recognize certain hallmarks that indicate it’s time to move on. Erika Hall, in her book  , described it as feeling a “satisfying click.” She says, “[O]ne way to know you’ve done enough research is to listen for the satisfying click. That’s the sound of the pieces falling into place when you have a clear idea of the problem you need to solve and enough information to start working on a solution.” ( , p. 36.) When it comes to building a product on a budget, you may also want to consider that research is relatively cheap compared to the cost of design and development. The rule I tend to follow is this: continue conducting discovery research until the questions you really want answered can only be answered by putting something in front of users. That is, wait to build something until you absolutely have to. Learn as much as you can about your target market and user base until the only way forward is to put some sketches on paper.  With Candor Network, I’m not quite there yet. There is still plenty of runway to cover in the research cycle. Now that I know that data privacy is a more motivating reason to consider paying for a social networking tool, I need to work out what other features will be essential. In the next round of research, I could do   and ask participants to give me a tour of their Facebook and other social media pages. Or I could continue with more interviews, but recruit from a different source and reach a broader demographic of participants. Regardless of the exact path I choose to take from here, the key is to focus on what the requirements would be for the ultra-private, data-secure social network that users would value.  A few parting words Discovery research helps us learn more about the users we want to help and the problems they need a solution for. It doesn’t have to be expensive either, and it definitely isn’t something that should be omitted from the development cycle. By starting with a problem hypothesis and conducting multiple rounds of research, we can ultimately save time and money. We can move from gut instincts and personal experiences to a tested hypothesis. And when it comes time to launch, we’ll know it’s from a solid foundation of research-backed understanding. Recommended reading If you’re testing the waters on a new idea and want to jump into some (budget-friendly) discovery research, here are some additional resources to help you along: , by Erika Hall , by Tomer Sharon , by Jeff Sauro and James Lewis  by Meg Dickey-Kurdziolek  by Susan Farrell  by Erika Hall  by Jeff Sauro Like this: \n\t\t\t\t\t\t\tRecently by Meg Dickey-Kurdziolek\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/your-emails-and-recipients-deserve-better-context/", "title": "Your Emails (and Recipients) Deserve Better Context", "content": "Email communication is an integral part of the user experience for nearly every web application that requires a login. It’s also one of the first interactions the user has after signing up. Yet too often both the content and context of these emails is treated as an afterthought (at best), with the critical parts that users see first—sender name and email, subject, and preheader—largely overlooked. Your users, and the great application you’ve just launched, deserve better. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. A focus on recipient experience Designing and implementing a great email recipient experience is difficult. And by the time it comes to the all-important context elements (name, subject, and so on), it’s commonly left up to the developer to simply fill something in and move on. That’s a shame, because these elements play an outsized role in the email experience, being not only the first elements seen but also the bits recipients use to identify emails when searching through their archives. Given the frequency with which they touch users, it really is time we started spending a little more effort to fine-tune them. The great news is that despite the constraints imposed on these elements, they’re relatively easy to improve, and they can have a huge impact on engagement, open rates, and recipient satisfaction. When they all work together, sender name and email, subject, and preheader provide a better experience for your recipients. So whether you’re a developer stuck fixing such oversights and winging it, or on the design or marketing team responsible for making the decisions, use the following guide to improve your recipient’s experience. And, if possible, bring it up with your whole team so it’s always a specific requirement in the future.  Details that matter As they say, the devil is in the details, and these details matter. Let’s start with a quick example that highlights a few common mistakes.  In the image below, the sender is unnecessarily repeated within the subject, wasting key initial subject characters, while the subjects themselves are all exactly the same. This makes it difficult to tell one email from the next, and the preview content doesn’t help much either since the only unique information it provides is the date (which is redundant alongside the email’s time stamp). The subject copy could be more concise as well—“Payment Successfully Processed” is helpful, but it’s a bit verbose.  Outside of the sender and the dates on the emails, there’s not much useful information until you open the email itself. Fortunately, none of these things are particularly difficult to fix. Weather Underground provides a great example of carefully crafted emails. The subject conveys the most useful information without even requiring the recipient to open the email. In addition, their strategic use of emojis helps complement that information with a very rich, yet judicious, use of subject-line space. Weather Underground also makes use of   to provide a direct link to the key information online without needing a recipient to open the email to follow a link. Gmail Inbox Actions require some extra work to set up and only work in Gmail, but they can be great if you’re sending high volumes of email. Both scenarios involve recurring emails with similar content from one to the next, but the difference is stark. With just a little effort and fine-tuning, the resulting emails are much more useful to the recipients. Let’s explore how this is done. Emphasizing unique content for recurring emails With the earlier examples, both organizations are sending recurring emails, but by focusing on unique subject lines, Weather Underground’s emails are much more helpful. Recurring emails like invoices may not contain the most glamorous content, but you still have an opportunity to make each one unique and informative. By surfacing the most important or unique information from the content of the email, there’s additional context to help the recipient know whether they need to act or not. It also makes it easier to find a specific invoice when searching through emails in the future. Clarifying the sender Who (or what) is sending this email? Is it a person? Is it automated? Do I want to hear from them? Do I trust them? Is this spam? These questions and more automatically run through our heads whenever we see an email, and the sender information provides the first clue when we start processing our inbox. Just as for caller ID on incoming phone calls, recognition and trust both play a role. As  , “If the from name doesn’t sound like it’s from someone you want to hear from, it doesn’t matter what the subject line is.” This can be even more critical on mobile devices where the sender name is the most prominent element. The first and most important step is to explicitly specify a name. You don’t want the recipient’s email client choosing what to display based on the email address alone. For instance, if you send emails from “alerts@example.com” (with no name specified), some clients will display “alerts” as the name, and others will display “alerts@example.com.” With the latter, it just feels rough around the edges. In either case, the experience is less than ideal for the sender. The technical implementation may vary depending on your stack, but at the simplest level, correct implementation is all in the string formatting. Let’s look at “Jane Doe <email@example.com>” as an example. “Jane Doe” is the name, and the email is included after the name and surrounded by angle brackets. It’s a small technical detail, but it makes a world of difference to recipients. But what name should we show? This depends on the type of email, so you’ll want to consider the sender for each email independently. For example, with a receipt or invoice you may want to use “Acme Billing.” But with a comment notification, it may be more informative for recipients if you use the commenter’s name, such as “Jane Doe via AcmeApp.” Depending on the context, you could use “with” or “from” as well, but those have an extra character, so I’ve found “via” to be the shortest and most semantically accurate option. Similarly, if your business entity or organization name is different from your product name, you should use the name that will be most familiar to your recipients.  Avoiding contact confusion In the case where you use someone’s name—like with the “Jane Doe via AcmeApp” example above—it’s important to add a reference to the app name. Since the email isn’t actually from Jane, it’s inaccurate to represent that it’s from Jane Doe directly. This can be confusing for users, but it can also create problems with address books. If you use just “Jane Doe,” your sending email address can be accidentally added to the recipient’s address book in association with Jane’s entry. Then, when they go to email Jane later, they may unwittingly send an email to “notifications@acme.com” instead of Jane. That could lead to some painful missed emails and miscommunication. The other reason is that it’s simply helpful for the recipient to know the source of the email. It’s not just from Jane, it’s from Jane via your application. You’ll also want to put yourself in your recipient’s shoes and carefully consider whether a name is recognizable to your recipient. For example, if your corporate entity name and product name aren’t the same, recipients will be much less likely to recognize the sender if you use the name of your corporate entity. So make sure to use the product name that will be most familiar to the recipient. Similarly, you’ll want to avoid using generic names that could be from any company. For example, use “Acme Billing” instead of just “Billing,” so the recipient can quickly and easily identify your product. Finally, while names are great, the underlying sending address can be just as important. In many ways, it’s the best attribute for recipients to use when filtering and organizing their inbox, and using unique email addresses or aliases for different categories of emails makes this much easier. There’s a fine line, but the simplest way to do this is to group emails into three categories: billing, support, and activity/actions. You may be able to use more, like notifications, alerts, or legal, but remember that the more you create, the more you’ll have to keep track of.  Also, keep the use of subdomains to a minimum. By consistently only sending transactional email like password resets, receipts, order updates, and other similar emails from your primary domain, users learn to view any emails from other domains as suspicious. It may seem like a minor detail, but these bits of information add up to create important signals for recipients. It is worth noting, however, that you should use a different address, and ideally a separate subdomain, for your bulk marketing emails. This helps Gmail and other inbox providers understand the type of email coming from each source, which in turn helps ensure the domain reputation for your bulk marketing emails—which is traditionally lower—doesn’t affect delivery of your more critical transactional email. Subject line utility Now that recipients have clearly identifiable and recognizable sender information, it’s time to think about the subjects of your emails. Since we’ve focused on transactional emails in the examples used so far, we’ll similarly focus on the utility of your subject line content rather than the copywriting. You can always use copywriting to improve the subject, but with transactional emails, utility comes first.  The team at MailChimp has studied   extensively, and there are a few key things to know about subjects. First, the presence of even a single word can have a meaningful impact on open rates. A   had similar findings. Words and phrases like “thank you,” “monthly,” and “thanks” see higher engagement than words like “subscription,” “industry,” and “report,” though different words will have different impacts depending on your industry, so you’ll still need to test and monitor the results. Personalization can also have an impact, but remember, personalization isn’t just about using a person’s name. It can be information like location, previous purchases, or other personal data. Just remember that it’s important to be tasteful, judicious, and relevant.  The next major point from MailChimp is that  . Or, rather, it doesn’t matter directly. After studying 6 billion emails, they found “little or no correlation between performance and subject length.” That said, when line length is considered as one aspect of your overall subject content, it can be used to help an email stand out. Clarity and utility are more important than brevity, but when used as a component to support clarity and utility, brevity can help. One final point from the Adestra report is that open rates aren’t everything. Regardless of whether someone opens an email, the words and content of your subject line leaves an impression. So even if a certain change doesn’t affect your open rates, it can still have a far-reaching impact. Clearing out redundancy The most common mistake with subjects is including redundant information. If you’ve carefully chosen the sender name and email address, there’s no need to repeat the sender name in the subject, and the characters could be better applied to telling the recipient additional useful information. Dates are a bit of a gray area, but in many cases, the email’s time stamp can suffice for handling any time-based information. On the other hand, when the key dates don’t correlate to when the email was sent, it can be helpful to include the relevant date information in the subject. With the subject of your application emails, you’ll also want to front-load the most important content to prevent it from being cut off. For instance, instead of “Your Invoice for May 2018,” you could rewrite that as “May 2018 Invoice.” Since your sender is likely “Acme Billing,” the recipient already knows it’s about billing, so the month and year is the most important part of the subject. However, “May 2018 Invoice” is a bit terse, so you may want to add something at the end to make it more friendly. Next, in situations where time stamps are relevant, avoid relying on relative dates or times. Phrases like “yesterday,” “last week,” or “two hours ago” don’t age well with email since you never know when someone will receive or read it. Similarly, when someone goes to search their email archives, relative dates aren’t helpful. If you must use relative dates, look for opportunities to add explicit dates or time stamps to add clarity.  With regularly occurring emails like reports or invoices, strive to give each message a unique subject. If every report has the subject “Your Monthly Status Report,” they can run together in a list of emails that all have the same subject. It can also make them more difficult to search later on. The same goes for invoices and receipts. Yes, invoice numbers and order numbers are technically unique, but they aren’t particularly helpful. Make sure to include useful content to help identify each email individually. Whether that’s the date, total value, listing the most expensive items, or all three, it’s easier on recipients when they can identify the contents of an email without having to open it. While open rates are central to measuring marketing emails, transactional emails are all about usefulness. So open rates aren’t as purely correlated with successful transactional emails.  There’s a case to be made that in some contexts a great transactional email doesn’t need to be opened at all for it to be useful. The earlier Weather Underground example does an excellent job communicating the key information without requiring recipients to open it. And while the subject is the best place for key content, some useful content can also be displayed using a preheader.  Making the most of preheaders If you’re not familiar with the preheader, you can think of it as a convenient name for the content at the beginning of an email. Campaign Monitor has a great write-up with in-depth advice on  . It’s simply a way of acknowledging and explicitly suggesting the text that email clients should show in the preview pane for an email. While there’s no formal specification for preheaders, and different email clients will handle them differently, they’re still widely displayed.  Most importantly, well-written and useful preheaders of 40–50 characters have been shown to increase overall engagement, particularly if delivering a concise call to action.   (signing up required) points out that preheader content is important, especially on mobile devices where subjects are truncated and it can act as a sort of extended subject. If the leading content in your email is a logo or other image, email clients will often use the alternate text for the image as the preview text. Since “Acme Logo” isn’t very helpful, it’s best to include a short summary of text at the beginning of your email. Sometimes this short summary text can interfere with the design of your email, so it’s not uncommon for the design to accommodate some visually muted—but still readable—text at the beginning. Or, as long as you’re judicious, in most cases you can safely hide preheader text entirely by using the display: none CSS declaration. Abusing this could get you caught in spam filters, but for the most part, inbox providers seem to focus on the content that is hidden rather than the fact that it’s hidden.  If your email can be designed and written such that the first content encountered is the useful content for previews, then you’re all set. In the case of receipts, invoices, or activity summaries, that’s not always easy. In those cases, a short text-based summary of the content makes a good preheader. Context element interplay The rules outlined above are great guidelines, but remember that rules are there to be broken (well, sometimes …). As long as you understand the big picture, sender, subject, and preheader can still work together effectively even if some of those rules are bent. A bit. For example, if you ensure that you have relevant and unique content in your preheader for the preview, you may be able to get away with using the same subject for each recurring email. Alternatively, there may be cases where you need to repeat the sender name in the subject.  The key is that when you’re crafting these elements, make sure you’re looking at how they work together. Sometimes a subject can be shortened by moving some content into the preheader. Alternatively, you may be able to use a more specific sender to reduce the need for a word or two in the subject. The application of these guidelines isn’t black and white. Simply being aware of the recipient’s experience is the most important factor when crafting the elements they’ll see in preview panes. Finally, a word on monitoring and testing Simple changes to the sender, subject, and preheader can significantly impact open rates and recipient experience. One critical thing to remember, however, is that while some of these improvements are guaranteed winners, monitoring and testing things like open rates and click rates is critical to validate any changes made. And since these elements can either play against each other or work together, it’s best to test combinations and view all three elements holistically. The value of getting this right really is in the details, and despite their tendency to be overlooked, taking the time to craft helpful and useful sender names and addresses, subject lines, and preheaders can drastically improve the experience for your email recipients. It’s a small investment that’s definitely worth your time. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/order-out-of-chaos-patterns-of-organization-for-writing-on-the-job/", "title": "Order Out of Chaos: Patterns of Organization for Writing on the Job", "content": "A few years ago, a former boss of mine emailed me out of the blue and asked for a resource that would help him and his colleagues organize information more effectively. Like a dutiful friend, I sent him links to a few articles and the names of some professional writing books. And I qualified my answer with that dreaded disclaimer: “Advice varies widely depending on the situation.” Implication: “You’ll just have to figure out what works best for you. So, good luck!” Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In retrospect, I could have given him a better answer. Much like the   of design that underpin so much of what designers do, there are foundational principles and patterns of organization that are relevant to any professional who must convey technical information in writing, and you can adapt these concepts to bring order out of chaos whether or not you’re a full-time writer. Recognize the primary goals: comprehension and performance Not long after I wrote my response, I revisited a book I’d read in college:  , by Carolyn D. Rude. In my role as a technical writer, I reference the book every now and then for practical advice on revising software documentation. This time, as I reviewed the chapter on organization, I realized that Rude explained the high-level goals and principles better than any other author I’d read up to that point. In short, she says that whether you are outlining a procedure, describing a product, or announcing a cool new feature, a huge amount of writing in the workplace is aimed at comprehension (here’s what X is and why you should care) and performance (here’s how to do X). She then suggests that editors choose from two broad kinds of order to support these goals:   and  . The first refers to structures that guide readers from major sections to more detailed sections to facilitate top-down learning; the second refers to structures of actions that readers need to carry out. Content-based orders typically start with nouns, whereas task-based orders typically begin with verbs. Product Overview Introduction Features\n Feature 1 Feature 2 Feature  \n Contact Support Update your title and tagline Pick a theme you love Add a header or background Add a site icon Add a widget Of course, not all writing situations fall neatly into these buckets. If you were to visit  , you would see a hybrid of content-based topics at the first level and task-based topics within them. The point is that as you begin to think about your organization, you should ask yourself:  Which of the major goals of organization (comprehension or performance) am I trying to achieve? And which broad kind of order will help me best achieve those goals? This is still pretty abstract, so let’s consider the other principles from Carolyn Rude, but with a focus on how a writer rather than an editor should approach the task of organization. Steal like an organizer: follow pre-established document structures In his book  , Austin Kleon argues that smart artists don’t actually create anything new but rather collect inspiring ideas from specific role models, and produce work that is profoundly shaped by them. “If we’re free from the burden of trying to be completely original,” he writes, “we can stop trying to make something out of nothing, and we can embrace influence instead of running away from it.” The same principle applies to the art of organization. To “steal like an organizer” means to look at what other people have written and to identify and follow pre-established structures that may apply to your situation. Doing so not only saves time and effort but also forces you to remember that your audience may already expect a particular pattern—and experience cognitive dissonance if they don’t get it. You are probably familiar with more pre-established structures than you think. News reports follow the  . Research reports often adhere to some form of the   (Introduction, Methodology, Results, and Discussion). Instruction manuals typically have an introductory section followed by tasks grouped according to the typical sequence a user would need to follow. Even troubleshooting articles tend to have a standard structure of Problem, Cause, and Solution. All this may sound like common sense, and yet many writers entirely skip this process of adapting pre-made structures. I can understand the impulse. When you face a blank screen, it feels simpler to capture the raw notes and organize it all later. That approach can certainly help you get into the flow, but it may also result in an ad hoc structure that fails to serve readers who are less familiar with your material. Instead, when you begin the writing process, start by researching available templates or pre-made structures that could support your situation. Standard word processors and content management systems already contain some good templates, and it’s easy to search for others online. Your fellow writers and designers are also good resources. If you’re contributing to a series of documents at your organization, you should get familiar with the structure of that series and learn how to work within it. Or you can do some benchmarking and steal some ideas from how other companies structure similar content.  My team once had to do our own stealing for a major project that affected about half our company. We needed to come up with a repeatable structure for standard operating procedures (SOPs) that any employee could use to document a set of tasks. Knowing SOPs to be a well-established genre, we found several recommended structures online and in books, and came up with a list of common elements. We then decided which ones to steal and arranged them into a sequence that best suited our audience. We made out like bandits. But what if there is no pre-established pattern? Or what if a pattern exists, but it’s either too simple or too complex for what you’re trying to accomplish? Or what if it’s not as user-friendly as you would like?  There may indeed be cases where you need to develop a mostly customized structure, which can be daunting. But fear not! That’s where the other principles of organization come in. Anticipate your readers’ questions (and maybe even talk to them) Recently I had an extremely frustrating user experience. While consulting some documentation to learn about a new process, I encountered a series of web pages that gave no introduction and dove straight into undefined jargon and acronyms that I had never heard of. When I visited related pages to get more context, I found the same problem. There was no background information for a newbie like me. The writers failed in this case to anticipate my questions and instead assumed a great deal of prior knowledge. Don’t make this mistake when you design your structure. Like a journalist, you need to answer the  , and   of your content, and then incorporate the answers in your structure. Anticipate common questions, such as “What is this? Where do I start? What must I know? What must I do?” This sort of critical reflection is all the more important when organizing web content, because users will almost certainly enter and exit your pages in nonlinear, unpredictable ways. If possible, you should also meet with your readers, and gather information about what would best serve them. One simple technique you could try is to create a  , an annotated matrix of sorts that my team once built after asking various teams about their information priorities. On the left axis, we listed categories of information that we thought each team needed. Along the top axis, we listed a column for each team. We then gave team representatives a chance to rank each category and add custom categories we hadn’t included. (You can learn more about the process we followed in this  .) The weakness of this approach is that it doesn’t reveal information that your audience doesn’t know how to articulate. To fill in this gap, I recommend running a few informal usability tests. But if you don’t have the time for that, building a knowledge map is better than not meeting with your readers at all, because it will help you discover structural ideas you hadn’t considered. Our knowledge map revealed multiple categories that were required across almost all teams—which, in turn, suggested a particular hierarchy and sequence to weave into our design.  Go from general to specific, familiar to new People tend to learn and digest information best by going from general to specific, and familiar to new. By remembering this principle, which is articulated in the   of learning, you can better conceptualize the structure you’re building. What are the foundational concepts of your content? They should appear in your introductory sections. What are the umbrella categories under which more detailed categories fall? The answer should determine which headings belong at the top and subordinate levels of your hierarchy. What you want to avoid is presenting new ideas that don’t flow logically from the foundational concepts and expectations that your readers bring to the table. Consider the wikiHow article “ .” It begins by defining what Dungeons and Dragons   and explaining why you need to create a character before you can start playing the game. The next section, “Part 1: Establishing the Basics,” guides the reader into subsequent foundational steps, such as deciding which version of the game to follow and printing out a character sheet. Later sections (“Selecting a gender and race,” “Choosing a class,” and “Calculating ability scores”) expand on these concepts to introduce more specific, unfamiliar ideas in an incremental fashion, leading readers up a gentle ramp into new territory. Use conventional patterns to match structure to meaning Within the general-to-specific/familiar-to-new framework, you can apply additional patterns of organization that virtually all humans understand. Whereas the pre-established document structures above are usually constructed for particular use cases or genres, other conventional patterns match more general mental models (or “schemas,” as the schema theory so elegantly puts it) that we use to make sense of the world. These patterns include  , and  . Chronological The chronological pattern reveals time or sequence. It’s appropriate for things like instructions, process flows, progress reports, and checklists. In the case of instructions, the order of tasks on a page often implies (or explicitly states) the “proper” or most common sequence for a user to follow. The wikiHow article above, for example, offers a recommended sequence of tasks for beginner players. In the case of progress reports, the sections may be ordered according to the periods of time in which work was done, as in this sample outline from the book  , by Kenneth W. Houp et al.: Introduction Summary of work completed Work completed\n Period 1 (beginning and end dates)\n Description Cost \n Period 2 (beginning and end dates)\n Description Cost \n \n Work remaining\n Period 3 (or remaining periods)\n Description of work to be done Expected cost \n \n Evaluation of work in this period Conclusions and recommendations The principles of organization listed in this article are in fact another example of the chronological pattern. As Carolyn Rude points out in her book, the principles are arranged as a sort of methodology to follow. Try starting at the top of the list and work your way down. You may find it to be a useful way to produce order out of the chaos before you. Spatial The spatial pattern refers to top-to-bottom, left-to-right structures of organization. This is a good pattern if you need to describe the components of an interface or a physical object.  Take a look at the neighbor comparison graph below, which is derived from a sample   solution offered by Oracle Utilities. Customers who see this graph would most likely view it from top to bottom and left to right. A detailed description of this feature would then describe each component in that same order. Here’s a sample outline:  Feature name\n Title Bar chart\n Efficient neighbors You Average neighbors \n Date range Performance insight\n Great Good Using more than average \n Energy use insight Comparison details (“You’re compared with 10 homes within 6 miles …”) \n Comparison-contrast The comparison-contrast pattern helps users weigh options. It’s useful when reporting the pros and cons of different decisions or comparing the attributes of two or more products or features. You see it often when you shop online and need to compare features and prices. It’s also a common pattern for feasibility studies or investigations that list options along with upsides and downsides. Cause-effect The cause-effect pattern shows relationships between actions and reactions. Writers often use it for things like troubleshooting articles, medical diagnoses, retrospectives, and root cause analyses. You can move from effect to cause, or cause to effect, but you should stick to one direction and use it consistently. For example, the   and   pages at Drugs.com follow a standard cause-effect pattern that incorporates logical follow-up sections such as “Prevention” and “Treatment”:  What Is It? (This section defines the illness and describes possible “causes.”) Symptoms (This section goes into the “effects” of the illness.) Diagnosis Expected Duration Prevention Treatment When to Call a Professional Prognosis For another example, see the “Use parallel structure for parallel sections” section below, which shows what a software troubleshooting article might look like. Order of importance The order of importance pattern organizes sections and subsections of content according to priority or significance. It is common in announcements, marketing brochures, release notes, advice articles, and FAQs.  The order of importance pattern is perhaps the trickiest one to get right. As Carolyn Rude says, it’s not always clear what the most important information is. What should come in the beginning, middle, and end? Who decides? The answers will vary according to the author, audience, and purpose. When writing release notes, for example, my team often debates which software update should come first, because we know that the decision will underscore the significance of that update relative to the others. FAQs by definition are focused on which questions are most common and thus most important, but the exact order will depend on what you perceive as being the most frequent or the most important for readers to know. (If you are considering writing FAQs, I recommend this   from technical writer Lisa Wright.) Other common patterns Alphabetical order is a common pattern that Rude doesn’t mention in detail but that you may find helpful for your situation. To use this pattern, you would simply list sections or headings based on the first letter of the first word of the heading. For example, alphabetical order is used frequently to list API methods in API documentation sites such as those for  ,  , and  . It is also common in glossaries, indexes, and encyclopedic reference materials where each entry is more or less given equal footing. The downside of this pattern is that the most important information for your audience may not appear in a prominent, findable location. Still, it is useful if you have a large and diverse set of content that defies simple hierarchies and is referenced in a non-linear, piecemeal fashion. Group related material Take a look at the lists below. Which do you find easier to scan and digest?  (Source:  .)\n If you chose the second list, that is probably because the writers relied on a widely used organizational technique:  . Grouping is the process of identifying meaningful categories of information and putting information within those categories to aid reader comprehension. Grouping is especially helpful when you have a long, seemingly random list of information that could benefit from an extra layer of logical order. An added benefit of grouping is that it may reveal where you have gaps in your content or where you have mingled types of content that don’t really belong together. To group information effectively, first analyze your content and identify the discrete chunks of information you need to convey. Then tease out which chunks fall within similar conceptual buckets, and determine what intuitive headings or labels you can assign to those buckets. Writers do this when creating major and minor sections within a book or printed document. For online content, grouping is typically done at the level of articles or topics within a web-based system, such as a wiki or knowledge base. The  , for example, groups topics within categories like “Popular articles,” “Read & organize emails,” and “Send emails.”  It’s possible to go overboard here. Too many headings in a short document or too many topics in a small help system can add unnecessary complexity. I once faced the latter scenario when I reviewed a help system written by one of my colleagues. At least five of the topics were so short that it made more sense to merge them together on a single page rather than forcing the end user to click through to separate pages. I’ve also encountered plenty of documents that contain major section headings with only one or two sentences under them. Sometimes this is fine; you may need to keep those sections for the sake of consistency. But it’s worth assessing whether such sections can simply be merged together (or conversely, whether they should be expanded to include more details). Because of scenarios like these, Carolyn Rude recommends keeping the number of groupings to around seven, give or take a few—though, as always, striking the right balance ultimately depends on your audience and purpose, as well as the amount of information you have to manage. Use parallel structure for parallel sections One of the reasons   “I came, I saw, I conquered” still sticks in our memory after thousands of years is the simple fact of parallelism. Each part of the saying follows a distinct, repetitive grammatical form that is easy to recall. Parallelism works in a similar manner with organization. By using a consistent and repetitive structure across types of information that fit in the same category, you make it easier for your readers to navigate and digest your content. Imagine you’re writing a troubleshooting guide in which all the topics follow the same basic breakdown: Problem Title, Problem, Cause, Solution, and See Also. In this case, you should make sure that each topic includes those same headings, in the exact same hierarchy and sequence, and using the exact same style and formatting. This kind of parallelism delivers a symmetry that reduces the reader’s cognitive load and clarifies the relationships of each part of your content. Deviations from the pattern not only cause confusion but can undermine the credibility of the content. Introduction Problem 1 Title\n Problem Cause Solution See Also \n Problem 2 Title\n Problem Cause Solution See Also \n Problem 3 Title\n … \n Introduction Problem 1 Title\n Problem Root causes How to Fix it Advanced Tips and tricks Related \n Problem 2 title\n Issue Steps to Fix Why did this happen, and how can I avoid it next time? See also \n Problem 3 title\n … \n This last principle is probably the easiest to grasp but may be the most difficult to enforce, especially if you are managing contributions from multiple authors. Templates and style guides are useful here because they invite authors to provide standard inputs, but you will still need to watch the content like a hawk to squash the inconsistencies that inevitably emerge. Conclusion In one sense, my response to my former boss was accurate. Given the endless variety of writing situations, there is no such thing as a single organization solution. But saying that “advice varies widely depending on the situation” doesn’t tell the whole story. There are flexible patterns and principles that can guide you in finding, customizing, and creating structures for your goals.  The key thing to remember is that structure affects meaning. The sequence of information, the categories you use, the emphasis you imply through your hierarchy—all of these decisions impact how well your audience understands what you write. Your ideal structure should therefore reinforce what you mean to say. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/webmentions-enabling-better-communication-on-the-internet/", "title": "Webmentions: Enabling Better Communication on the Internet", "content": "Over   will have been sent across the internet since the   was made a full Recommendation by the W3C—the standards body that guides the direction of the web—in early January 2017. That number is rising rapidly, and in the last few weeks I’ve seen a growing volume of chatter on social media and the blogosphere about these new “mentions” and the people implementing them. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. So what are Webmentions and why should we care?  While the technical specification published by the W3C may seem incomprehensible to most, it’s actually a straightforward and extremely useful concept with a relatively simple implementation. Webmentions help to break down some of the artificial walls being built within the internet and so help create a more open and decentralized web. There is also an expanding list of major web platforms already supporting Webmentions either natively or with easy-to-use plugins (more on this later). Put simply, Webmention is a (now) standardized protocol that enables one website address (URL) to notify another website address that the former contains a reference to the latter. It also allows the latter to verify the authenticity of the reference and include its own corresponding reference in a reciprocal way. In order to understand what a big step forward this is, a little history is needed. The rise of @mentions By now most people are familiar with the ubiquitous use of the “@” symbol in front of a username, which   and became known as   (read “at mentions” and “at replies”). For the vast majority, this is the way that one user communicates with other users on the platform, and over the past decade these @mentions, with their corresponding notification to the receiver, have become a relatively standard way of communicating on the internet. Many other services also use this type of internal notification to indicate to other users that they have been referenced directly or tagged in a post or photograph. Facebook allows it, so does Instagram. Google+ has a variant that uses + instead of @, and even the long-form article platform Medium, whose founder Ev Williams also co-founded Twitter, quickly joined the @mentions party. The biggest communications problem on the internet If you use Twitter, your friend Alice only uses Facebook, your friend Bob only uses his blog on WordPress, and your pal Chuck is over on Medium, it’s impossible for any one of you to @mention another. You’re all on different and competing platforms, none of which interoperate to send these mentions or notifications of them. The only way to communicate in this way is if you all join the same social media platforms, resulting in the average person being signed up to multiple services just to stay in touch with all their friends and acquaintances. Given the issues of privacy and identity protection, different use cases, the burden of additional usernames and passwords, and the time involved, many people don’t want to do this. Possibly worst of all, your personal identity on the internet can end up fragmented like a Horcrux across multiple websites over which you have little, if any, control.  Imagine if AT&T customers could only speak to other AT&T customers and needed a separate phone, account, and phone number to speak to friends and family on Verizon. And still another to talk to friends on Sprint or T-Mobile. The massive benefit of the telephone system is that if you have a telephone and service (from any one of hundreds or even thousands of providers worldwide), you can potentially reach anyone else using the network. Surely, with a basic architecture based on simple standards, links, and interconnections, the same should apply to the internet? The solution? Enter Webmentions! As mentioned earlier, Webmentions allow notifications between web addresses. If both sites are set up to send and receive them, the system works like this:  A Webmention is simply an @mention that works from one website to another! If she chooses, Alice can include the full text of Bob’s reply—along with his name, photo, and his article’s URL (presuming he’s made these available)—as a comment on her original post. Any new readers of Alice’s article can then see Bob’s reply underneath it. Each can carry on a full conversation from their own websites and in both cases display (if they wish) the full context and content.  User behaviors with Webmentions are a little different than they are with @mentions on Twitter and the like in that they work   websites in addition to within a particular website. They enable authors (of both the original content and the responses) to own the content, allowing them to keep a record on the web page where it originated, whether that’s a website they own or the third-party platform from which they chose to send it. Interaction examples with Webmention Webmentions certainly aren’t limited to creating or displaying “traditional” comments or replies. With the use of simple semantic microformats classes and a variety of parsers written in numerous languages, one can explicitly post bookmarks, likes, favorites, RSVPs, check-ins, listens, follows, reads, reviews, issues, edits, and even purchases. The result? Richer connections and interactions with other content on the web and a genuine two-way conversation instead of a mass of unidirectional links. We’ll take a look at some examples, but you can find more on the   alongside some other useful resources. Marginalia With Webmention support, one could architect a site to allow inline marginalia and highlighting similar to Medium.com’s relatively well-known functionality. With the clever use of  , which are well supported in major browsers, there are already   who use Webmentions to display word-, sentence-, or paragraph-level marginalia on their sites. After all, aren’t inline annotations just a more targeted version of comments? Reads As another example, and something that could profoundly impact the online news business, I might post a link on my website indicating I’ve read a particular article on, say,  . My site sends a “read” Webmention to the article, where a   or counter showing the number of read Webmentions received could be implemented. Because of the simplified two-way link between the two web pages, there is now auditable proof of interaction with the content. This could similarly work with microinteractions such as likes, favorites, bookmarks, and reposts, resulting in a clearer representation of the particular types of interaction a piece of content has received. Compared to an array of nebulous social media mini-badges that provide only basic counters, this is a potentially more valuable indicator of a post’s popularity, reach, and ultimate impact. Listens Building on the idea of using reads, one could extend Webmentions to the podcasting or online music sectors. Many platforms are reasonably good at providing download numbers for podcasts, but it is far more difficult to track the number of actual listens. This can have a profound effect on the advertising market that supports many podcasts. People can post about what they’re actively listening to (either on their personal websites or via podcast apps that could report the percentage of the episode listened to) and send “listen” Webmentions to pages for podcasts or other audio content. These could then be aggregated for demographics on the back end or even shown on the particular episode’s page as social proof of the podcast’s popularity. For additional fun, podcasters or musicians might use Webmentions in conjunction with   and audio or video content to add timecode-specific, inline comments to audio/video players to create an open standards version of  . Reviews Websites selling products or services could also accept review-based Webmentions that include star-based ratings scales as well as written comments with photos, audio, or even video. Because Webmentions are a two-way protocol, the reverse link to the original provides an auditable path to the reviewer and the opportunity to assess how trustworthy their review may be. Of course, third-party trusted sites might also accept these reviews, so that the receiving sites can’t easily cherry-pick only positive reviews for display. And because the Webmention specification includes the functionality for editing or deletion, the original author has the option to update or remove their reviews at any time. Getting started with Webmentions Extant platforms with support While the specification has only recently become a broad recommendation for use on the internet, there are  , either natively or with plugins. The simplest option, requiring almost no work, is a relatively new and excellent social media service called  , which handles Webmentions out of the box. CMSs like   and   also have Webmention functionality built in. Download and set up the open source software and you’re ready to go. If you’re working with WordPress, there’s a simple   that will allow you to begin using Webmentions—just download and activate it. (For additional functionality when displaying Webmentions, there’s also the recommended  .) Other CMSs like Drupal, ProcessWire, Elgg, Nucleus CMS, Craft, Django, and Kirby also have plugins that support the standard. A wide variety of static site generators, like Hugo and Jekyll, have   for Webmention technology as well. More are certainly coming.  If you can compose basic HTML on your website, Aaron Parecki has written an excellent primer on “ .” A weak form of Webmention support can be bootstrapped for Tumblr, WordPress.com, Blogger, and Medium   service, but the user interface and display would obviously be better if they were supported fully and natively.  As a last resort, if you’re using Tumblr, WordPress.com, Wix, Squarespace, Ghost, Joomla, Magento, or any of the other systems without Webmention, file tickets asking them to support the standard. It only takes a few days of work for a reasonably experienced developer to build support, and it substantially improves the value of the platform for its users. It also makes them first-class decentralized internet citizens. Webmentions for developers If you’re a developer or a company able to hire a developer, it is relatively straightforward to build Webmentions into your CMS or project, even potentially open-sourcing the solution as a plugin for others. For anyone familiar with the old specifications for pingback or trackback, you can think of Webmentions as a major iteration of those systems, but with easier implementation and testing, improved performance and display capabilities, and decreased spam vulnerabilities. Because the specification supports editing and deleting Webmentions, it provides individuals with more direct control of their data, which is important in light of new laws like GDPR. In addition to reading the specification, as mentioned previously, there are multiple open source implementations already written in a variety of languages that you can use directly, or as examples. There are also a   and pre-built services like  ,  ,  , and   that can be quickly leveraged. Maybe your company allows employees to spend 20% of their time on non-specific projects, as Google does. If so, I’d encourage you to take the opportunity to fbuild Webmentions support for one or more platforms—let’s spread the love and democratize communication on the web as fast as we can! And if you already have a major social platform but don’t want to completely open up to sending and receiving Webmentions, consider using Webmention functionality as a simple post API. I could easily see services like Twitter, Mastodon, or Google+ supporting the receiving of Webmentions, combined with a simple parsing mechanism to allow Webmention senders to publish syndicated content on their platform. There are already several services like  , with Hacker News-like functionality, that allow posting to them via Webmention. If you have problems or questions, I’d recommend joining the   online via IRC, web interface, Slack, or Matrix to gain access to further hints, pointers, and resources for implementing a particular Webmention solution. The expansion of Webmentions The big question many will now have is  At present, they don’t, and many may never do so. After all, locking you into their services is enabling them to leverage your content and your interactions to generate income. However, I suspect that if one of the major social platforms enabled sending/receiving Webmentions, it would dramatically disrupt the entire social space.  In the meantime, if your site already has Webmentions enabled, then congratulations on joining the next revolution in web communication! Just make sure you advertise the fact by using a button or badge.  Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/fixing-variable-scope-issues-with-ecmascript-6/", "title": "Fixing Variable Scope Issues with ECMAScript 6", "content": "Variable scope has always been tricky in JavaScript, particularly when compared to more structured languages like C and Java. For years, there wasn’t much talk about it because we had few options for really changing it. But ECMAScript 6 introduced some new features to help give developers more control of variable scope. Browser support is pretty great and these features are ready to use for most developers today. But which to choose? And what, exactly, do they do? Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. This article spells out what these new features are, why they matter, and how to use them. If you’re ready to take more control over variable scope in your projects or just want to learn the new way of doing things, read on. Variable scope: a quick primer Variable scope is an important concept in programming, but it can confuse some developers, especially those new to programming. Scope is the area in which a variable is known. Take a look at the following code: What does the console log read? Not surprisingly, it reads  . The variable   is defined outside of any function, meaning it’s defined in the  . Consequently, every function here will know what   is. In fact, even functions in other files that are included on the same page will know what this variable is. Now consider the following code: All we did was move where the variable was declared. So what does the console log read now? Well, it throws a   because   is not defined. That’s because the   declaration here is function-level, making the scope extend only within the function (and any potential functions nested in it), but not beyond. If we want a variable’s scope to be shared by two or more functions on the same level, we need to define the variable one level higher than the functions. Here’s the tricky thing: most websites and apps don’t have all of the code written by one developer. Most will have several developers touching the code, as well as third-party libraries and frameworks thrown into the mix. And even if it’s just one developer, it’s common to pull JavaScript in from several places. Because of this, it’s generally considered bad practice to define a variable in the global scope—you never know what other variables other developers will be defining. There are some workarounds to share variables among a group of functions—most notably,   and   in object-oriented JavaScript, although encapsulating data and functions in any object will accomplish this. But variables with scopes larger than necessary are generally problematic. The problem with  Alright, so we’ve got a handle on variable scope. Let’s get into something more complex. Take a look at the following code: What are the console logs? Well, inside the loop, you get the iteration variable as it increments:  ,  ,  . After that, the loop ends and we move on. Now we try to reference that same variable outside of the   loop it was created in. What do we get? The console log reads   because the   statement is function-level. If you define a variable using  , the entire function will have access to it, no matter where it is defined in that function. This can get problematic when functions become more complex. Take a look at the following code: What are the console logs?   and  . We define a variable equal to 1, and then try to redefine the same variable inside the   statement. Since those two exist in the same scope, we can’t define a new variable, even though that’s obviously what we want, and the first variable we set is overwritten inside the   statement. That right there is the biggest shortcoming with  : its scope is too large, which can lead to unintentional overwriting of data, and other errors. Large scope often leads to sloppy coding as well—in general, a variable should only have as much scope as it needs and no more. What we need is a way to declare a variable with a more limited scope, allowing us to exercise more caution when we need to. Enter ECMAScript 6. New ways to declare variables ECMAScript 6 (a new set of features baked into JavaScript, also known as ES6 or ES2015) gives us two new ways to define variables with a more limited scope:   and  . Both give us  , meaning scope can be contained within blocks of code like   loops and   statements, giving us more flexibility in choosing how our variables are scoped. Let’s take a look at both. Using  The   statement is simple: it’s mostly like  , but with limited scope. Let’s revisit that code sample from above, replacing   with  : In this case, the console logs would read   and  . This is because an   statement defines a new scope for a variable declared with  —the second variable we declare is actually a separate entity than the first one, and we can set both independently. But that doesn’t mean that nested blocks like that   statement are completely cut off from higher-level scopes. Observe: In this case, the console log would read  . The   statement has access to the variable we created outside of it and is able to log that. But what happens if we try to mix scopes? You might think that first console log would read  , but it actually throws a  , telling us that   is not defined or initialized for that scope. (The terminology varies across browsers.) JavaScript variables are   in their scope—if you declare a variable within a scope, JavaScript reserves a place for it even before you declare it. How that variable is reserved differs between   and  . In both cases here, we’re trying to use a variable before it’s defined. But the console logs behave differently. The first one, using a variable later declared with  , will read  , which is an actual variable type. The second one, using a variable later defined with  , will throw a   and tell us that we’re trying to use that variable before it’s defined/initialized. What’s going on? Before executing, JavaScript will do a quick read of the code and see if any variables will be defined, and hoist them within their scope if they are. Hoisting reserves that space, even if the variable exists in the parent scope. Variables declared with   will be auto-initialized to   within their scope,  . The big problem is that   doesn’t always mean you’re using a variable before it’s defined. Look at the following code: In this case, both console logs read  , even though different things are happening. Variables that are declared with   but have no value will be assigned a value of  ; but variables declared with   that are referenced within their scope before being declared will also return  . So if something goes wrong in our code, we have no indication which of these two things is happening. Variables defined with   are reserved in their block, but until they’re defined, they go into the  —they can’t be used and will throw an error, but JavaScript knows exactly why and will tell you. In this case, the first console log reads  , but the second throws a  , telling us the variable hasn’t been defined/initialized yet. So, using  , if we see  , we don’t know if the variable has been defined and just doesn’t have a value, or if it hasn’t been defined yet in that scope but will be. Using  , we get an indication of which of these things is happening—much more useful for debugging. Using  The   statement is very similar to  , but with one major exception: it does not allow you to change the value once initialized. (Some more complex types, like   and  , can be modified, but can’t be replaced. Primitive types, like   and  , cannot change at all.) Take a look at the following code: That code will run fine until the last line, which throws a   for assignment to a constant variable. Variables defined with   will throw this error almost any time you try to reassign one, although  . As a JavaScript developer, you might be wondering what the big deal is about immutable variables. Constant variables are new to JavaScript, but they’ve been a part of languages like C and Java for years. Why so popular? They make us think about how our code is working. There are some cases where changing a variable can be harmful to the code, like when doing calculations with pi or when you have to reference a certain HTML element over and over: If our code depends on that reference to that specific HTML element, we should make sure it can’t be reassigned. But the case for   goes beyond that. Remember our best practice of only giving variables the scope they need and no more. In that same line of thought, we should only give variables the mutability they need and no more. Zell Liew has written  , but the bottom line is that making variables immutable makes us think more about our code and leads to cleaner code and fewer surprises. When I was first starting to use   and  , my default option was  , and I would use   only if reassignment would cause harm to the code. But after learning more about programming practices, I changed my mind on this. Now, my default option is  , and I use   only if reassignment is necessary. That forces me to ask if reassignment for a variable is really necessary—most of the time, it’s not. Is there a case for  ? Since   and   allow for more careful coding, is there a case for   anymore? Well, yes. There are a few cases where you’d want to use   over the new syntax. Give these careful consideration before switching over to the new declarations. Variables for the masses Variables declared with   do have one thing that the others don’t, and it’s a big one: universal browser support. 100% of browsers support  . Support is pretty great for both   and  , but you have to consider how differently browsers handle JavaScript it doesn’t understand vs. CSS it doesn’t understand. If a browser doesn’t support a CSS feature, most of the time that’s just going to mean a display bug. Your site may not look the same as in a supporting browser, but it’s most likely still usable. If you use   and a browser doesn’t support it, that JavaScript will not work. At all. With JavaScript being such an integral part of the web today, that can be a major problem if you’re aiming to support old browsers in any way. Most support conversations pose the question, “What browsers do we want to deliver an optimal experience for?” When you’re dealing with a site containing core functionality that relies on   and  , you’re essentially asking the question, “What browsers do we want to ban from using our site?” This should be a different conversation than deciding whether you can use  . For most websites, there won’t be enough users of non-supporting browsers to worry about. But for major revenue-generating sites or sites where you’re paying for traffic, this can be a serious consideration. Make sure that risk is alright with your team before proceeding. If you need to support really old browsers but want to use   and   (and other new, ES6 constructs), one solution is to use a JavaScript transpiler like   to take care of this for you. With Babel, you can write modern JavaScript with new features and then compile it into code that’s supported by older browsers.  Sound too good to be true? Well, there are some caveats. The resulting code is much more verbose than you’d write on your own, so you end up with a much larger file than necessary. Also, once you commit to a transpiler, that codebase is going to be stuck with that solution for a while. Even if you’re writing valid ECMAScript 6 for Babel, dropping Babel later will mean testing your code all over again, and that’s a hard sell for any project team when you have a version that’s working perfectly already. When’s the next time you’re going to rework that codebase? And when is that IE8 support not going to matter anymore? It might still be the best solution for the project, but make sure you’re comparing those two timelines. And for the next trick ... There is one more thing   can do that the others can’t. This is a niche case, but let’s say you have a situation like this: So we defined   in the global scope, but later lost that reference because we defined it in a function, yet we need to reference the original variable. This might seem silly, because you can ordinarily just pass the first variable into the function or rename one of them, but there may be some situations where your level of control over the code prevents this. Well,   can do something about that. Check it out: When a variable is defined on the global scope using  , it automatically attaches itself to the global   object—something   and   don’t do. This feature helped me out once in a situation where a build script validated JavaScript before concatenating files together, so a reference to a global variable in another file (that would soon be concatenated into the same file upon compilation) threw an error and prevented compilation. That said, relying on this feature often leads to sloppy coding. This problem is most often solved with greater clarity and smaller margin of error by attaching variables to your own object: Yes, this requires an extra step, but it reduces confusion in working around something you’re not really supposed to be doing anyway. Nonetheless, there may be times when this feature of   is useful. Try to find a cleaner workaround before resorting to this one, though. Which do I use? So how do you choose? What’s the priority for using these? Here’s the bottom line. First question: are you supporting IE10 or really old versions of other browsers in any way? If the answer is yes, and you don’t want to go with a transpiler solution, you need to choose  . If you’re free to use the features that are new in ES6, start by making every variable a  . If a variable needs to be reassigned (and try to write your code so it doesn’t), switch it to  . Scoping for the future ECMAScript 6 statements like   and   give us more options for controlling variable scope in our websites and apps. They make us think about what our code is doing, and support is great. Give it careful consideration, of course, but coding with these declarations will make your codebase more stable and prepare it for the future. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/conversational-design/", "title": "Conversational Design", "content": "Texting is how we talk now. We talk by tapping tiny messages on touchscreens—we message using SMS via mobile data networks, or through apps like Facebook Messenger or WhatsApp.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In 2015, the Pew Research Center found that 64% of American adults owned a smartphone of some kind,  . We still refer to these personal, pocket-sized computers as phones, but “Phone” is now just one of many communication apps we neglect in favor of texting. Texting is the most widely used mobile data service in America. And in the wider world, four billion people have mobile phones, so 4 billion people have access to SMS or other messaging apps. For some, dictating messages into a wristwatch offers an appealing alternative to placing a call. The popularity of texting can be partially explained by the medium’s ability to offer the easy give-and-take of conversation without requiring continuous attention. Texting feels like direct human connection, made even more captivating by unpredictable lag and irregular breaks. Any typing is incidental because the experience of texting barely resembles “writing,” a term that carries associations of considered composition. In his TED talk, Columbia University linguist John McWhorter called texting “fingered conversation”—terminology I find awkward, but accurate. The physical act—typing—isn’t what defines the form or its conventions. Technology is breaking down our traditional categories of communication.  By the numbers, texting is the most compelling computer-human interaction going. When we text, we become immersed and forget our exchanges are computer-mediated at all. We can learn a lot about digital design from the inescapable draw of these bite-sized interactions, specifically the use of language. What Texting Teaches Us This is an interesting example of what makes computer-mediated interaction interesting. The reasons people are compelled to attend to their text messages—even at risk to their own health and safety—aren’t high-production values, so-called rich media, or the complexity of the feature set.  Texting, and other forms of social media, tap into something very primitive in the human brain. These systems offer always-available social connection. The brevity and unpredictability of the messages themselves triggers the release of dopamine that motivates seeking behavior and keeps people coming back for more. What makes interactions interesting may start on a screen, but the really interesting stuff happens in the mind. And language is a critical part of that. Our conscious minds are made of language, so it’s easy to perceive the messages you read not just as words but as the thoughts of another mingled with your own. Loneliness seems impossible with so many voices in your head.  With minimal visual embellishment, texts can deliver personality, pathos, humor, and narrative. This is apparent in “Texts from Dog,” which, as the title indicates, is a series of imagined text exchanges between a man and his dog. (Fig 1.1). With just a few words, and some considered capitalization, Joe Butcher (writing as October Jones) creates a vivid picture of the relationship between a neurotic canine and his weary owner. Using words is key to connecting with other humans online, just as it is in the so-called “real world.” Imbuing interfaces with the attributes of conversation can be powerful. I’m far from the first person to suggest this. However, as computers mediate more and more relationships, including customer relationships, anyone thinking about digital products and services is in a challenging place. We’re caught between tried-and-true past practices and the urge to adopt the “next big thing,” sometimes at the exclusion of all else. Being intentionally conversational isn’t easy. This is especially true in business and at scale, such as in digital systems. Professional writers use different types of writing for different purposes, and each has rules that can be learned. The love of language is often fueled by a passion for rules — rules we received in the classroom and revisit in manuals of style, and rules that offer writers the comfort of being correct outside of any specific context. Also, there is the comfort of being finished with a piece of writing and moving on. Conversation, on the other hand, is a context-dependent social activity that implies a potentially terrifying immediacy. Moving from the idea of publishing content to engaging in conversation can be uncomfortable for businesses and professional writers alike. There are no rules. There is no  . It all feels more personal. Using colloquial language, even in “simplifying” interactive experiences, can conflict with a desire to appear authoritative. Or the pendulum swings to the other extreme and a breezy style gets applied to a laborious process like a thin coat of paint. As a material for design and an ingredient in interactions, words need to emerge from the content shed and be considered from the start.  The way humans use language—easily, joyfully, sometimes painfully—should anchor the foundation of all interactions with digital systems. The way we use language and the way we socialize are what make us human; our past contains the key to what commands our attention in the present, and what will command it in the future. To understand how we came to be so perplexed by our most human quality, it’s worth taking a quick look at, oh!, the entire known history of communication technology.  The Mother Tongue Accustomed to eyeballing type, we can forget language began in our mouths as a series of sounds, like the calls and growls of other animals. We’ll never know for sure how long we’ve been talking—speech itself leaves no trace—but we do know it’s been a mighty long time.  Archaeologist Natalie Thais Uomini and psychologist Georg Friedrich Meyer concluded that  . Per the fossil record, modern humans emerged at least 190,000 years ago in the African savannah. Evidence of cave painting goes back 30,000 years (Fig 1.2).  Then, a mere 6,000 years ago, ancient Sumerian commodity traders grew tired of getting ripped off. Around 3200 BCE, one of them had the idea to track accounts by scratching wedges in wet clay tablets. Cuneiform was born.  So, don’t feel bad about procrastinating when you need to write—humanity put the whole thing off for a couple hundred thousand years! By a conservative estimate, we’ve had writing for about 4% of the time we’ve been human. Chatting is easy; writing is an arduous chore. Prior to mechanical reproduction, literacy was limited to the elite by the time and cost of hand-copying manuscripts. It was the rise of printing that led to widespread literacy; mass distribution of text allowed information and revolutionary ideas to circulate across borders and class divisions. The sharp increase in literacy bolstered an emerging middle class. And the ability to record and share knowledge accelerated all other advances in technology: photography, radio, TV, computers, internet, and now the mobile web. And our talking speakers. Every time our communication technology advances and changes, so does the surrounding culture—then it disrupts the power structure and upsets the people in charge. Catholic archbishops railed against mechanical movable type in the fifteenth century. Today, English teachers deplore texting emoji. Resistance is, as always, futile. OMG is now listed in the Oxford English Dictionary. But while these developments have changed the world and how we relate to one another, they haven’t altered our deep oral core. Orality, Say It with Me Orality knits persons into community. Today, when we record everything in all media without much thought, it’s almost impossible to conceive of a world in which the sum of our culture existed only as thoughts.  Before literacy, words were ephemeral and all knowledge was social and communal. There was no “save” option and no intellectual property. The only way to sustain an idea was to share it, speaking aloud to another person in a way that made it easy for them to remember. This was  —the first interface.  We can never know for certain what purely oral cultures were like. People without writing are   at keeping records. But we can examine oral traditions that persist for clues. The oral formula Reading and writing remained elite activities for centuries after their invention. In cultures without a writing system, oral characteristics persisted to help transmit poetry, history, law and other knowledge across generations. The epic poems of Homer rely on meter, formulas, and repetition to aid memory: Far as a man with his eyes sees into the mist of the distance \nSitting aloft on a crag to gaze over the wine-dark seaway, \nJust so far were the loud-neighing steeds of the gods overleaping. Concrete images like  ,  ,  , and   served to aid the teller and to sear the story into the listener’s memory. Biblical proverbs also encode wisdom in a memorable format: As a dog returns to its vomit, so fools repeat their folly. That is vivid.  And a saying that originated in China hundreds of years ago can prove sufficiently durable to adorn a few hundred Etsy items: A journey of a thousand miles begins with a single step. The labor of literature Literacy created distance in time and space and decoupled shared knowledge from social interaction. Human thought escaped the existential present. The reader doesn’t need to be alive at the same time as the writer, let alone hanging out around the same fire pit or agora.   Freed from the constraints of orality, thinkers explored new forms to preserve their thoughts. And what verbose and convoluted forms these could take:  The Reader will I doubt too soon discover that so large an interval of time was not spent in writing this discourse; the very length of it will convince him, that the writer had not time enough to make a shorter. There’s no such thing as an oral semicolon. And George Tullie has no way of knowing anything about his future audience. He addresses himself to a generic reader he will never see, nor receive feedback from. Writing in this manner is terrific for precision, but not good at all for interaction.  Writing allowed literate people to become hermits and hoarders, able to record and consume knowledge in total solitude, invest authority in them, and defend ownership of them. Though much writing preserved the dullest of records, the small minority of language communities that made the leap to literacy also gained the ability to compose, revise, and perfect works of magnificent complexity, utility, and beauty.  The qualities of oral culture  In  , Walter Ong explored the “psychodynamics of orality,” which is, coincidentally, quite a mouthful.  Through his research, he found that the ability to preserve ideas in writing not only increased knowledge, it altered values and behavior. People who grow up and live in a community that has never known writing are different from literate people—they depend upon one another to preserve and share knowledge. This makes for a completely different, and much more intimate, relationship between ideas and communities. In a society without writing, communication can happen only in the moment and face-to-face. It sounds like the introvert’s nightmare! Oral culture has several other hallmarks as well:  It’s impossible to step back and examine a spoken word or phrase. While the speaker can try to repeat, there’s no way to capture or replay an utterance.  Formulas and patterns are essential to transmitting and retaining knowledge. When the knowledge stops being interesting to the audience, it stops existing.  All communication is participatory and immediate. The speaker can adjust the message to the context. Conversation, contention, and struggle help to retain this new knowledge.  Everyone draws on the same themes, so not only is originality not helpful, it’s nonsensical to claim an idea as your own.  The right use of a word is determined by how it’s being used right now.  Printed books enabled mass-distribution and dispensed with handicraft of manuscripts, alienating readers from the source of the ideas, and from each other. (Ong pg. 100):  Ideas can be preserved as a thing, completely apart from the thinker.  The need and desire for private space accompanied the emergence of silent, solo reading.  Plagiarism is possible.  The ability to identify a sole author increases the value of originality and creativity.  Once a work is printed, it is final and closed. Print-based literacy ascended to a position of authority and cultural dominance, but it didn’t eliminate oral culture completely. All that studying allowed people to accumulate and share knowledge, speeding up the pace of technological change. And technology transformed communication in turn. It took less than 150 years to get from the telegraph to the World Wide Web. And with the web—a technology that requires literacy—Ong identified a return to the values of the earlier oral culture. He called this  . Then he died in 2003, before the rise of the mobile internet, when things   got interesting.  Secondary orality is:  There is no necessary delay between the expression of an idea and its reception. Physical distance is meaningless.  The number of people who can hear and see the same thing simultaneously is in the billions.  Communication invites and enables a response, which may then become part of the message.  The products of our culture reflect and influence one another. Social, ephemeral, participatory, anti-authoritarian, and opposed to individual ownership of ideas—these qualities sound a lot like internet culture. Wikipedia: Knowledge Talks When someone mentions a genre of music you’re unfamiliar with—electroclash, say, or plainsong—what do you do to find out more? It’s quite possible you type the term into Google and end up on Wikipedia, the improbably successful, collaborative encyclopedia that would be absent without the internet.  According to Wikipedia, encyclopedias have existed for around two-thousand years. Wikipedia has existed since 2001, and it’s the fifth most-popular site on the web. Wikipedia is not a publication so much as a society that provides access to knowledge. A volunteer community of “Wikipedians” continuously adds to and improves millions of articles in over 200 languages. It’s a phenomenon manifesting all the values of secondary orality:  Anyone can contribute anonymously and anyone can modify the contributions of another. The output is free. The encyclopedia articles are not attributed to any sole creator. A single article might have 2 editors or 1,000. Each article has an accompanying “talk” page where editors discuss potential improvements, and a “history” page that tracks all revisions. Heated arguments are not documented. They take place as revisions within documents. Wikipedia is disruptive in the true Clayton Christensen sense. It’s created immense value and wrecked an existing business model. Traditional encyclopedias are publications governed by authority, and created by experts and fact checkers. A volunteer project collaboratively run by unpaid amateurs shows that conversation is more powerful than authority, and that human knowledge is immense and dynamic.  In an interview with  , a British librarian expressed some disdain about Wikipedia. The main problem is the lack of authority. With printed publications, the publishers must ensure that their data are reliable, as their livelihood depends on it. But with something like this, all that goes out the window. Wikipedia is immediate, group-minded, conversational, collaborative, and intertextual— secondary orality in action—but it relies on traditionally published sources for its authority. After all, anything new that changes the world does so by fitting   the world. As we design for new methods of communication, we should remember that nothing is more valuable simply because it’s new; rather, technology is valuable when it brings us more of what’s already meaningful. From Documents to Events Pages and documents organize information in space. Space used to be more of a constraint back when we printed conversation out. Now that the internet has given us virtually infinite  space, we need to mind how conversation moves through time. Thinking about serving the needs of people in an internet-based culture requires a shift from thinking about how information occupies space—documents—to how it occupies time—events. Texting means that we’ve never been more lively (yet silent) in our communications. While we still have plenty of in-person interactions, it’s gotten easy to go without. We text grocery requests to our spouses. We click through a menu in a mobile app to summon dinner (the order may still arrive at the restaurant by fax, proving William Gibson’s maxim that the future is unevenly distributed). We exchange messages on Twitter and Facebook instead of visiting friends in person, or even   visiting friends in person. We work at home and Slack our colleagues. We’re rapidly approaching a future where humans text other humans and only speak aloud to computers. A text-based interaction with a machine that’s standing in for a human should feel like a text-based interaction with a human. Words are a fundamental part of the experience, and they are part of the design. Words should be the basis for defining and creating the design.  We’re participating in a radical cultural transformation. The possibilities manifest in systems like Wikipedia that succeed in changing the world by using technology to connect people in a single collaborative effort. And even those of us creating the change suffer from some lag. The dominant educational and professional culture remains based in literary values. We’ve been rewarded for individual achievement rather than collaboration. We seek to “make our mark,” even when designing changeable systems too complex for any one person to claim authorship. We look for approval from an authority figure. Working in a social, interactive way should feel like the most natural thing in the world, but it will probably take some doing.  Literary writing—any writing that emerges from the culture and standards of literacy—is inherently not interactive. We need to approach the verbal design not as a literary work, but as a conversation. Designing human-centered interactive systems requires us to reflect on our deep-seated orientation around artifacts and ownership. We must alienate ourselves from a set of standards that no longer apply. Most advice on “writing for the web” or “creating content” starts from the presumption that we are “writing,” just for a different medium. But when we approach communication as an assembly of pieces of content rather than an interaction, customers who might have been expecting a conversation end up feeling like they’ve been handed a manual instead. Software is on a path to participating in our culture as a peer.  So, it should behave like a person—alive and present. It doesn’t matter how much so-called machine intelligence is under the hood—a perceptive set of programmatic responses, rather than a series of documents, can be enough if they have the qualities of conversation. Interactive systems should evoke the best qualities of living human communities—active, social, simple, and present—not passive, isolated, complex, or closed off. Life Beyond Literacy Indeed, language changes lives. It builds society, expresses our highest aspirations, our basest thoughts, our emotions and our philosophies of life. But all language is ultimately at the service of human interaction. Other components of language—things like grammar and stories—are secondary to conversation. Literacy has gotten us far. It’s gotten you this far in this book. So, it’s not surprising we’re attached to the idea. Writing has allowed us to create technologies that give us the ability to interact with one another across time and space, and have instantaneous access to knowledge in a way our ancestors would equate with magic. However, creating and exchanging documents, while powerful, is not a good model for lively interaction. Misplaced literate values can lead to misery—working alone and worrying too much about posterity. So, it’s time to let go and live a little! We’re at an exciting moment. The computer screen that once stood for a page can offer a window into a continuous present that still remembers everything. Or, the screen might disappear completely.  Now we can start imagining, in an open-ended way, what constellation of connected devices any given person will have around them, and how we can deliver a meaningful, memorable experience on any one of them. We can step away from the screen and consider what set of inputs, outputs, events, and information add up to the best experience.  This is daunting for designers, sure, yet phenomenal for people. Thinking about human-computer interactions from a screen-based perspective was never truly human-centered from the start. The ideal interface is an interface that’s not noticeable at all—a world in which the distance from thought to action has collapsed and merely uttering a phrase can make it so. We’re fast moving past “computer literacy.” It’s on us to ensure all systems speak human fluently. Like this: \n\t\t\t\t\t\t\tRecently by Erika Hall\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-for-research/", "title": "Designing for Research", "content": "If you’ve spent enough time developing for the web, this piece of feedback has landed in your inbox since time immemorial: Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Every time this feedback reaches me, I’m inclined to question it: “What about the photo looks bad to you, and can you tell me  ” That’s a somewhat unfair question to counter with. The complaint is rooted in a subjective perception of image quality, which in turn is influenced by many factors. Some are technical, such as the export quality of the image or the compression method (often lossy, as is the case with JPEG-encoded photos). Others are more intuitive or perceptual, such as content of the image and how compression artifacts mingle within. Perhaps even performance plays a role we’re not entirely aware of. Fielding this kind of feedback for many years eventually lead me to design and develop  , which was my first go at building a research project on the web. I started with twenty-five photos shot by a professional photographer. With them, I generated a large pool of images at various quality levels and sizes. Images were served randomly from this pool to users who were asked to rate what they thought about their quality. Results from the first round were interesting, but not entirely clear: users seemed to have a tendency to overestimate the actual quality of images, and poor performance   to have a negative impact on perceptions of image quality, but this couldn’t be stated conclusively. A number of UX and technical issues made it necessary to implement important improvements and conduct a second round of research. In lieu of spinning my wheels trying to extract conclusions from the first round results, I decided it would be best to improve the survey as much as possible, and conduct another round of research to get better data. This article chronicles how I first built the survey, and then how I subsequently listened to user feedback to improve it. Defining the research Of the subjects within web performance, image optimization is especially vast. There’s a wide array of formats, encodings, and optimization tools, all of which are designed to make images small enough for web use while maintaining reasonable visual quality. Striking the balance between speed and quality is really what image optimization is all about. This balance between performance and visual quality prompted me to consider how people   image quality.  , in particular. Eventually, this train of thought lead to a series of questions spurring the design and development of an image quality perception survey. The idea of the survey is that users are providing   assessments on quality. This is done by asking participants to rate images without an objective reference for what’s “perfect.” This is, after all, how people view images  . A word on surveys Any time we want to quantify user behavior, it’s inevitable that a survey is at least considered, if not ultimately chosen to gather data from a group of people. After all, surveys are perfect when your goal is to get something measurable. However, the survey is a seductively dangerous tool,  . They’re easy to make and conduct, and are routinely abused in their dissemination. They’re not great tools for assessing past behavior. They’re just as bad (if not worse) at predicting future behavior. For example, the 1–10 scale often employed by customer satisfaction surveys don’t really say much of anything about how satisfied customers actually are or how likely they’ll be to buy a product in the future. The unfortunate reality, however, is that in lieu of my lording over hundreds of participants in person, the survey is the only truly practical tool I have to measure how people perceive image quality as well as if (and potentially how) performance metrics correlate to those perceptions. When I designed the survey, I kept with the following guidelines: Don’t ask participants about anything other than what their perceptions are in the moment. By the time a participant has moved on, their recollection of what they just did rapidly diminishes as time elapses. Don’t assume participants know everything you do. Guide them with relevant copy that succinctly describes what you expect of them. Don’t ask participants to provide assessments with coarse inputs. Use an input type that permits them to finely assess image quality on a scale congruent with the lossy image quality encoding range. All we can do going forward is acknowledge we’re interpreting the data we gather under the assumption that participants are being truthful and understand the task given to them. Even if the perception metrics are discarded from the data, there are still some objective performance metrics gathered that could tell a compelling story. From here, it’s a matter of defining the questions that will drive the research. Asking the right questions In research, you’re seeking answers to questions. In the case of this particular effort, I wanted answers to these questions: How accurate are people’s perceptions of lossy image quality in relation to   quality? Do people perceive the quality of JPEG images differently than  ? Does performance play a role in all of this? These are important questions. To me, however, answering the last question was the primary goal. But the road to answers was (and continues to be) a complex journey of design and development choices. Let’s start out by covering some of the tech used to gather information from survey participants. Sniffing out device and browser characteristics When measuring how people perceive image quality, devices must be considered. After all, any given device’s screen will be more or less capable than others. Thankfully, HTML features such as   and   are highly appropriate for delivering the best image for any given screen. This is vital because one’s perception of image quality can be adversely affected if an image is ill-fit for a device’s screen. Conversely, performance can be negatively impacted if an exceedingly high-quality (and therefore behemoth) image is sent to a device with a small screen. When sniffing out potential relationships between performance and perceived quality, these are factors that deserve consideration. With regard to browser characteristics and conditions, JavaScript gives us plenty of tools for identifying important aspects of a user’s device. For instance, the   property reveals which image is being shown from an array of responsive images. In the absence of  , I can somewhat safely assume support for   or   is lacking, and fall back to the   tag’s   value: Where screen capability is concerned,   tells us the   of a given device’s screen. In the absence of  , you may safely assume a fallback value of  : . Those few browsers that don’t support it (i.e., IE 10 and under) are highly unlikely to be used on high density displays. The stalwart   retrieves the rendered width of an   element, while the   interface’s   property determines whether an image has finished loaded. The latter of these two is important, because it may be preferable to discard individual results in situations where images haven’t loaded. In cases where JavaScript isn’t available, we can’t collect   of this data. When we collect ratings from users who have JavaScript turned off (or are otherwise unable to run JavaScript), I have to accept there will be gaps in the data. The basic information we’re still able to collect does provide some value. Sniffing for WebP support As you’ll recall, one of the initial questions asked was how users perceived the quality of WebP images. The HTTP   request header advertises WebP support in browsers like Chrome. In such cases, the   header might look something like this: As you can see, the WebP content type of   is one of the advertised content types in the header content. In server-side code, you can check   for the   substring. Here’s how that might look in   back-end code: In this example, I’m recording the browser’s WebP support status to a   I can use later to modify image delivery. I   use the   element with multiple  s and let the browser figure out which one to use based on the   element’s   attribute value, but this approach has clear advantages. First, it’s less markup. Second, the survey shouldn’t   choose a WebP source simply because the browser is capable of using it. For any given survey specimen, the app should randomly decide between a WebP or JPEG image. Not   participants using Chrome should rate   WebP images, but rather a random smattering of both formats. Recording performance API data You’ll recall that one of the earlier questions I set out to answer was if performance impacts the perception of image quality. At this stage of the web platform’s development, there are several APIs that aid in the search for an answer: : This API tracks performance metrics for page loads. More than that, it gives insight into specific page loading phases, such as redirect, request and response time, DOM processing, and more. : Similar to Level 2 but with key differences. The timings exposed by Level 1 of the API lack the accuracy as those in Level 2. Furthermore, Level 1 metrics are expressed in  . In the survey, data is only collected from Level 1 of the API if Level 2 is unsupported. It’s far from ideal (and also technically obsolete), but it does help fill in small gaps. : Similar to Navigation Timing, but Resource Timing gathers metrics on various loading phases of page resources rather than the page itself. Of the all the APIs used in the survey, Resource Timing is used most, as it helps gather metrics on the loading of the image specimen the user rates. : In select browsers, this API is brought into the Navigation Timing Level 2 interface when a page request replies with a   response header. This header is open-ended and can be populated with timings related to back-end processing phases. This was added to round two of the survey to quantify back-end processing time in general. : Currently only in Chrome, this API reports two paint metrics:  . Because a significant slice of users on the web use Chrome, we   be able to observe relationships between perceived image quality and paint metrics. Using these APIs, we can record performance metrics for most participants. Here’s a simplified example of how the survey uses the Resource Timing API to gather performance metrics for the loaded image specimen: If the Resource Timing API is available, and the   method returns results, an object with timings is returned, looking something like this: I grab these metrics as participants rate images, and store them in a database. Down the road when I want to write queries and analyze the data I have, I can refer to the  . With SQL and data at my fingertips, I can measure the distinct phases outlined by the model and see if correlations exist. Having discussed the technical underpinnings of how data can be collected from survey participants, let’s shift the focus to the survey’s design and user flows. Designing the survey Though surveys tend to have straightforward designs and user flows relative to other sites, we must remain cognizant of the user’s path and the impediments a user could face. The entry point When participants arrive at  , we want to be direct in our communication with them. The home page intro copy greets participants, gives them a succinct explanation of what to expect, and presents two navigation choices: From here, participants either start the survey or read a privacy policy. If the user decides to take the survey, they’ll reach a page politely asking them what their professional occupation is and requesting them to disclose any eyesight conditions. The fields for these questions can be left blank, as some may not be comfortable disclosing this kind of information. Beyond this point, the survey begins in earnest. The survey primer Before the user begins rating images, they’re redirected to  . This page describes what’s expected of participants, and explains how to rate images. While the survey is promoted on design and development outlets where readers regularly work with imagery on the web, a primer is still useful in getting everyone on the same page. The first paragraph of the page stresses that users are rating image  , not image  . This is important. Absent any context, participants may indeed rate images for their content, which is not what we’re asking for. After this clarification, the concept of lossy image quality is demonstrated with the following diagram: Lastly, the function of the rating input is explained. This could likely be inferred by most, but the explanatory copy helps remove any remaining ambiguity. Assuming your user knows everything you do is not necessarily wise. What seems obvious to one is not always so to another. The image specimen page This page is the main event and is where participants assess the quality of images shown to them. It contains two areas of focus: the image specimen and the input used to rate the image’s quality. Let’s talk a bit out of order and discuss the input first. I mulled over a few options when it came to which input   to use. I considered a   input with coarsely predefined choices, an   with a   of  , and other choices. What seemed to make the most sense to me, however, was a slider   with a   of  . A slider   is more intuitive than a text  , or a   element populated with various choices. Because we’re asking for a subjective assessment about something with such a large range of interpretation, a slider allows participants more granularity in their assessments and lends further accuracy to the data collected. Now let’s talk about the image specimen and how it’s selected by the back-end code. I decided early on in the survey’s development that I wanted images that weren’t prominent in existing stock photo collections. I also wanted uncompressed sources so I wouldn’t be presenting participants with recompressed image specimens. To achieve this, I procured images from  . The twenty-five images I settled on were minimally processed   from the photographer’s camera. The result was a cohesive set of images that felt visually related to each other. To properly gauge perception across the entire spectrum of quality settings, I needed to generate each image from the aforementioned sources at ninety-six different quality settings ranging from 5 to 100. To account for the varying widths and pixel densities of screens in the wild, each image also needed to be generated at four different widths for each quality setting: 1536, 1280, 1024, and 768 pixels, to be exact. Just the job   was made for! To top it all off, images   needed to be encoded in both JPEG and WebP formats. As a result, the survey draws randomly from 768 images   across the entire quality range, while also delivering the best image for the participant’s screen. This means that across the twenty-five image specimens participants evaluate, the survey draws from a pool of   images total. With the conception and design of the survey covered, let’s segue into how the survey was improved by implementing user feedback into the second round. Listening to feedback When I launched round one of the survey, feedback came flooding in from designers, developers, accessibility advocates, and even researchers. While my intentions were good, I inevitably missed some important aspects, which made it necessary to conduct a second round. Iteration and refinement are   to improving the usefulness of a design, and this survey was no exception. When we improve designs with user feedback, we take a project from average to something more memorable. Getting to that point means taking feedback in stride and addressing distinct, actionable items. In the case of the survey, incorporating feedback not only yielded a better user experience, it improved the integrity of the data collected. Building a better slider input Though the first round of the survey was serviceable, I ran into issues with the slider input. In round one of the survey, that input looked like this: There were two recurring complaints regarding this specific implementation. The first was that participants felt they had to align their rating to one of the labels beneath the slider track. This was undesirable for the simple fact that the slider was chosen   to encourage participants to provide nuanced assessments. The second complaint was that the submit button was disabled until the user interacted with the slider. This design choice was intended to prevent participants from simply clicking the submit button on every page without rating images. Unfortunately, this implementation was unintentionally hostile to the user and needed improvement, because it blocked users from rating images without a clear and obvious explanation as to why. Fixing the problem with the labels meant redesigning the slider as it appeared in Figure 3. I removed the labels altogether to eliminate the temptation of users to align their answers to them. Additionally, I changed the slider   to a gradient pattern, which further implied the granularity of the input. The submit button issue was a matter of how users were prompted. In round one the submit button was visible, yet the disabled state wasn’t obvious enough to some. After consulting with a colleague, I found a solution for round two: in lieu of the submit button being initially visible, it’s hidden by some guide copy: Once the user interacts with the slider and rates the image, a   event attached to the input fires, which hides the guide copy and replaces it with the submit button: This solution is less ambiguous, and it funnels participants down the desired path. If someone with JavaScript disabled visits, the guide copy is never shown, and the submit button is immediately usable. This isn’t ideal, but it doesn’t shut out participants without JavaScript. Addressing scrolling woes The survey page works especially well in portrait orientation. Participants can see all (or most) of the image without needing to scroll. In browser windows or mobile devices in landscape orientation, however, the survey image can be larger than the viewport: Working with such limited vertical real estate is tricky, especially in this case where the slider needs to be fixed to the bottom of the screen (which addressed an earlier bit of user feedback from round one testing). After discussing the issue with colleagues, I decided that animated indicators in the corners of the page could signal to users that there’s more of the image to see. When the user hits the bottom of the page, the scroll indicators disappear. Because animations may be jarring for  , a   is used to turn off this (and all other) animations if the user has a stated preference for reduced motion. In the event JavaScript is disabled, the scrolling indicators are always hidden in portrait orientation where they’re less likely to be useful and always visible in landscape where they’re potentially needed the most. Avoiding overscaling of image specimens One issue that was brought to my attention from a coworker was how the survey image seemed to expand boundlessly with the viewport. On mobile devices this isn’t such a problem, but on large screens and even modestly sized high-density displays, images can be scaled excessively. Because the responsive   tag’s   attribute specifies a maximum resolution image of  , an image can begin to overscale at as “small” at sizes over 768 pixels wide on devices with a device pixel ratio of 2. Some overscaling is inevitable and acceptable. However, when it’s excessive, compression artifacts in an image can become more pronounced. To address this, the survey image’s   is set to   for standard displays as of round two. For devices with a device pixel ratio of 2 or higher, the survey image’s   is set to half that at  : This minor (yet important) fix ensures that images aren’t scaled beyond a reasonable maximum. With a reasonably sized image asset in the viewport, participants will assess images close to or at a given image asset’s natural dimensions, particularly on large screens. User feedback is valuable. These and other UX feedback items I incorporated improved both the function of the survey and the integrity of the collected data. All it took was sitting down with users and listening to them. Wrapping up As round two of the survey gets under way, I’m hoping the data gathered reveals something exciting about the relationship between performance and how people perceive image quality. If you want to be a part of the effort,  . When round two concludes, keep an eye out here for a summary of the results! Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/meeting-design/", "title": "Meeting Design", "content": "Jane is a “do it right, or I’ll do it myself ” kind of person. She leads marketing, customer service, and information technology teams for a small airline that operates between islands of the Caribbean. Her work relies heavily on “reservation management system” (RMS) software, which is due for an upgrade. She convenes a Monday morning meeting to discuss an upgrade with the leadership from each of her three teams. The goal of this meeting is to identify key points for a proposal to upgrade the outdated software. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Jane begins by reviewing the new software’s advantages. She then goes around the room, engaging each team’s representatives in an open discussion. They capture how this software should alleviate current pain points; someone from marketing takes notes on a laptop, as is their tradition. The meeting lasts nearly three hours, which is a lot longer than expected, because they frequently loop back to earlier topics as people forget what was said. It concludes with a single follow-up action item: the director of each department will provide her with two lists for the upgrade proposal. First, a list of cost savings, and second, a list of timesaving outcomes. Each list is due back to Jane by the end of the week. The first team’s list is done early but not organized clearly. The second list provides far too much detail to absorb quickly, so Jane puts their work aside to summarize later. By the end of the following Monday, there’s no list from the third team—it turns out they thought she meant the   Friday. Out of frustration, Jane calls another meeting to address the problems with the work she received, which range from “not quite right” to “not done at all.” Based on this pace, her upgrade proposal is going to be finished two weeks later than planned. What went wrong? The plan seemed perfectly clear to Jane, but each team remembered their marching orders differently, if they remembered them at all. Jane   have a meeting experience that helps her team form more accurate memories. But for that meeting to happen, she needs to understand   those memories are formed in her team and   to form them more clearly. Better Meetings Make Better Memories If people are the one ingredient that all meetings have in common, there is one design constraint they all bring: their capacity to remember the discussion. That capacity lives in the human brain. The brain shapes everything believed to be true about the world. On the one hand, it is a powerful computer that can be trained to memorize thousands of numbers in random sequences.  But brains are also easily deceived, swayed by illusions and pre-existing biases. Those things show up in meetings as your instincts. Instincts vary greatly based on differences in the amount and type of previous experience. The paradox of ability and deceive-ability creates a weird mix of unpredictable behavior in meetings. It’s no wonder that they feel awkward. What is known about how memory works in the brain is constantly evolving. To cover that in even a little detail is beyond the scope of this book, so this chapter is not meant to be an exhaustive look at human memory. However, there are a few interesting theories that will help you be more strategic about how you use meetings to support forming actionable memories. Your Memory in Meetings The brain’s job in meetings is to accept inputs (things we see, hear, and touch) and store it as memory, and then to apply those absorbed ideas in discussion (things we say and make). See Figure 2.1. Neuroscience has identified four theoretical stages of memory, which include sensory, working, intermediate, and long-term. Understanding working memory and intermediate memory is relevant to meetings, because these stages represent the most potential to turn thought into action. Working Memory You may be familiar with the term  . Depending on the research you read, the term   has replaced   in the vocabulary of neuro- and cognitive science. I’ll use the term   here. Designing meeting experiences to support the working memory of attendees will improve meetings. Working memory collects around 30 seconds of the things you’ve recently heard and seen. Its storage capacity is limited, and that capacity varies among individuals. This means that not everyone in a meeting has the same capacity to store things in their working memory. You might assume that because you remember an idea mentioned within the last few minutes of a meeting, everyone else probably will as well. That is not necessarily the case. You can accommodate variations in people’s ability to use working memory by establishing a reasonable pace of information. The pace of information is directly connected to how well aligned attendees’ working memories become. To make sure that everyone is on the same page, you should set a pace that is deliberate, consistent, and slower than your normal pace of thought. Sometimes, concepts are presented more quickly than people can remember them, simply because the presenter is already familiar with the details. Breaking information into evenly sized, consumable chunks is what separates a great presenter from an average (or bad) one. In a meeting, slower, more broken-up pacing allows a group of people to engage in constructive and critical thinking more effectively. It gets the same ideas in everyone’s head. (For a more detailed dive into the pace of content in meetings, see Chapter 3, “Build Agendas Out of Ideas, People, and Time.”) Theoretical models that explain working memory are complex, as seen in Figure 2.2.  This model presumes two distinct processes taking place in your brain to make meaning out of what you see, what you hear, and how much you can keep in your mind. Assuming that your brain creates working memories from what you see and what you hear in different ways,   listening and seeing in meetings becomes more essential to getting value out of that time. In a meeting, absorbing something seen and absorbing something heard require different parts of the brain. Those two parts can work   to improve retention (the quantity and accuracy of information in our brain) or   to reduce retention. Nowhere is this better illustrated than in the research of Richard E. Meyer, where he has found that “people learn better from words and pictures than from words alone, but not all graphics are created equal(ly).”  When what you hear and what you see compete, it creates cognitive dissonance. Listening to someone speaking while reading the same words on a screen actually decreases the ability to commit something to memory. People who are subjected to presentation slides filled with speaking points face this challenge. But listening to someone while looking at a complementary photograph or drawing increases the likelihood of committing something to working memory. Intermediate-Term Memory Your memory should transform ideas absorbed in meetings into taking an action of some kind afterward. Triggering intermediate-term memories is the secret to making that happen. Intermediate-term memories last between two and three hours, and are characterized by processes taking place in the brain called  . Translation can be considered as a process by which the brain makes new meaning. Transcription is where that meaning is replicated (see Figures 2.3a and 2.3b). In both processes, the cells in your brain are creating new proteins using existing ones: making some “new stuff” from “existing stuff.” Here’s an example: instead of having someone take notes on a laptop, imagine if Jane sketched a diagram that helped her make sense out of the discussion, using what was stored in her working memory. The creation of that diagram is an act of translation, and theoretically Jane should be able to recall the primary details of that diagram easily for two to three hours, because it’s moving into her intermediate memory. If Jane made copies of that diagram, and the diagram was so compelling that those copies ended up on everyone’s wall around the office that would be transcription. Transcription is the (theoretical) process that leads us into longer-term stages of memory. Transcription connects understanding something within a meeting to acting on it later, well after the meeting has ended. Most of the time simple meetings last from 10 minutes to an hour, while workshops and working sessions can last anywhere from 90 minutes to a few days. Consider the duration of various stages of memory against different meeting lengths (see Figure 2.4). A well-designed meeting experience moves the right information from working to intermediate memory. Ideas generated and decisions made should materialize into actions that take place outside the meeting. Any session without breaks that lasts longer than 90 minutes makes the job of your memories moving thought into action fuzzier, and therefore more difficult. Jane’s meeting with her three teams lasted nearly three hours. That length of time spent on a single task or topic taxes people’s ability to form intermediate (actionable) memories. Action items become muddled, which leads to liberal interpretations of what each team is supposed to accomplish. But just getting agreement about a shared task in the first place is a difficult design challenge. All stages of memory are happening simultaneously, with multiple translation and transcription processes being applied to different sounds and sights. A fertile meeting environment that accommodates multiple modes of input allows memories to form amidst the cognitive chaos. Brain Input Modes During a meeting, each attendee’s brain in a meeting is either in a state of input or output. By choosing to assemble in a group, the assumption is implicit that information needs to be moved out of one place, or one brain, into another (or several others). Some meetings, like presentations, move information in one direction. The goal is for a presenting party to move information from their brain to the brains in the audience. When you are presenting an idea, your brain is in output mode. You use words and visuals to give form to ideas in the hopes that they will become memories in your audience. Your audience’s brains are receiving information; if the presentation is well designed and well executed, their ears and their eyes will do a decent job of absorbing that information accurately. In a live presentation, the output/input processes are happening synchronously. This is not like reading a written report or an email message, where the author (presenting party) has output information in absence of an audience, and the audience is absorbing information in absence of the author’s presence; that is moving information asynchronously. Like this: \n\t\t\t\t\t\t\tRecently by Kevin M. Hoffman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/planning-for-everything/", "title": "Planning for Everything", "content": "Once upon a time, there was a happy family. Every night at dinner, mom, dad, and two girls who still believed in Santa played a game. The rules are simple. Tell three stories about your day, two true, one false, and see who can detect the fib. Today I saw a lady walk a rabbit on a leash. Today I found a tooth in the kitchen. Today I forgot my underwear. The family ate, laughed, and learned together, and lied happily ever after. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. There’s truth in the tale. It’s mostly not false. We did play this game, for years, and it was fun. We loved to stun and bewilder each other, yet the big surprise was insight. In reflecting on my day, I was often amazed by oddities already lost. If not for the intentional search for anomaly, I’d have erased these standard deviations from memory. The misfits we find, we rarely recall. We observe a tiny bit of reality. We understand and remember even less. Unlike most machines, our memory is selective and purposeful. Goals and beliefs define what we notice and store.  To mental maps we add places we predict we’ll need to visit later. It’s not about the past. The intent of memory is to plan. In reflecting we look back to go forward. We search the past for truths and insights to shift the future. I’m not speaking of nostalgia, though we are all borne back ceaselessly and want what we think we had. My aim is redirection. In reflecting on inconvenient truths, I hope to change not only paths but goals. We all have times for reflection. Alone in the shower or on a walk, we retrace the steps of a day. Together at lunch for work or over family dinner, we share memories and missteps. Some of us reflect more rigorously than others. Given time, it shows. People who as a matter of habit extract underlying principles or rules from new experiences are more successful learners than those who take their experiences at face value, failing to infer lessons that can be applied later in similar situations. In Agile, the sprint retrospective offers a collaborative context for reflection. Every two to four weeks, at the end of a sprint, the team meets for an hour or so to look back. Focal questions include 1) what went well? 2) what went wrong? 3) how might  we improve? In reflecting on the plan, execution, and results, the team explores surprises, conflicts, roadblocks, and lessons. In addition to conventional analysis, a retrospective creates an opportunity for double loop learning. To edit planned actions based on feedback is normal, but revising assumptions, goals, values, methods, or metrics may effect change more profound. A team able to expand the frame may hack their habits, beliefs, and environment to be better prepared to succeed and learn. Retrospectives allow for constructive feedback to drive team learning and bonding, but that’s what makes them hard. We may lack courage to be honest, and often people can’t handle the truth. Our filters are as powerful as they are idiosyncratic, which means we’re all blind men touching a tortoise, or is it a tree or an elephant? It hurts to reconcile different perceptions of reality, so all too often we simply shut up and shut down. Search for Truth To seek truth together requires a culture of humility and respect. We are all deeply flawed and valuable. We must all speak and listen. Ideas we don’t implement may lead to those we do. Errors we find aren’t about fault, since our intent is a  future fix. And counterfactuals merit no more confidence than predictions, as we never know what would have happened if. Reflection is more fruitful if we know our own minds, but that is harder than we think. An imperfect ability to predict actions of sentient beings is a product of evolution. It’s quick and dirty yet better than nothing in the context of survival in a jungle or a tribe. Intriguingly, cognitive psychology and neuroscience have shown we use the same   to study ourselves. Self-awareness is just this same mind reading ability, turned around and employed on our own mind, with all the fallibility, speculation, and lack of direct evidence that bedevils mind reading as a tool for guessing at the thought and behavior of others. Empirical science tells us introspection and consciousness are unreliable bases for self-knowledge. We know this is true but ignore it all the time. I’ll do an hour of homework a day, not leave it to the end of vacation. If we adopt a dog, I’ll walk it. If I buy a house, I’ll be happy. I’ll only have one drink. We are more than we think, as Walt Whitman wrote in  . Do I contradict myself? \nVery well then I contradict myself \n(I am large, I contain multitudes.) Our best laid plans go awry because complexity exists within as well as without. Our chaotic, intertwingled bodyminds are ecosystems inside ecosystems. No wonder it’s hard to predict. Still, it’s wise to seek self truth, or at least that’s what I think. Upon reflection, my mirror neurons tell me I’m a shy introvert who loves reading, hiking, and planning. I avoid conflict when possible but do not lack courage. Once I set a goal, I may focus and filter relentlessly. I embrace habit and eschew novelty. If I fail, I tend to pivot rather than persist. Who I am is changing. I believe it’s speeding up. None of these traits is bad or good, as all things are double-edged. But mindful self awareness holds value. The more I notice the truth, the better my plans become. Years ago, I planned a family vacation on St. Thomas. I kept it simple: a place near a beach where we could snorkel. It was a wonderful, relaxing escape. But over time a different message made it past my filters. Our girls had been bored. I dismissed it at first. I’d planned a shared experience I recalled fondly. It hurt to hear otherwise. But at last I did listen and learn. They longed not for escape but adventure. Thus our trip to Belize. I found planning and executing stressful due to risk, but I have no regrets. We shared a joyful adventure we’ll never forget. Way back when we were juggling toddlers, we accidentally threw out the mail. Bills went unpaid, notices came, we swore we’d do better, then lost mail again. One day I got home from work to find an indoor mailbox system made with paint cans. My wife Susan built it in a day. We’ve used it to sort and save mail for 15 years. It’s an epic life hack I’d never have done. My ability to focus means I filter things out. I ignore problems and miss fixes. I’m not sure I’ll change. Perhaps it merits a prayer. God grant me the serenity \nto accept the things I cannot change, \ncourage to change the things I can, \nand wisdom to know the difference. We also seek wisdom in others. This explains our fascination with the statistics of regret. End of life wishes often include: I wish I’d taken more risks, touched more lives, stood up to bullies, been a better spouse or parent or child. I should have followed my dreams, worked and worried less, listened more. If only I’d taken better care of myself, chosen meaningful work, had the courage to express my feelings, stayed in touch. I wish I’d let myself be happy. While they do yield wisdom, last wishes are hard to hear. We are skeptics for good reason. Memory prepares for the future, and that too is the aim of regret. It’s unwise to trust the clarity of rose-colored glasses. The memory of pain and anxiety fades in time, but our desire for integrity grows. When time is short, regret is a way to rectify. I’ve learned my lesson. I’m passing it on to you. I’m a better person now. Don’t make my mistakes. It’s easy to say “I wish I’d stood up to bullies,” but hard to do at the time. There’s wisdom in last wishes but bias and self justification too. Confabulation means we edit memories with no intention to deceive. The truth is elusive. Reflection is hard. Like this: \n\t\t\t\t\t\t\tRecently by Peter Morville\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/going-offline/", "title": "Going Offline", "content": "Businesses are built on the web. Without the web, Twitter couldn’t exist. Facebook couldn’t exist. And not just businesses—Wikipedia couldn’t exist. Your favorite blog couldn’t exist without the web. The web doesn’t favor any one kind of use. It’s been deliberately designed to accommodate many and varied activities. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Just as many wonderful things are built upon the web, the web itself is built upon the internet. Though we often use the terms   and   interchangeably, the World Wide Web is just one application that uses the internet as its plumbing. Email, for instance, is another. Like the web, the internet was designed to allow all kinds of services to be built on top of it. The internet is a network of networks, all of them agreeing to use the same protocols to shuttle packets of data around. Those packets are transmitted down fiber-optic cables across the ocean floor, bounced around with Wi-Fi or radio signals, or beamed from satellites in freakin’ space. As long as these networks are working, the web is working. But sometimes networks go bad. Mobile networks have a tendency to get flaky once you’re on a train or in other situations where you’re, y’know, mobile. Wi-Fi networks work fine until you try to use one in a hotel room (their natural enemy). When the network fails, the web fails. That’s just the way it is, and there’s nothing we can do about it. Until now. Weaving the Web For as long as I can remember, the World Wide Web has had an inferiority complex. Back in the ’90s, it was outshone by CD-ROMs (ask your parents). They had video, audio, and a richness that the web couldn’t match. But they lacked links—you couldn’t link from something in one CD-ROM to something in another CD-ROM. They faded away. The web grew. Later, the web technologies of HTML, CSS, and JavaScript were found wanting when compared to the whiz-bang beauty of Flash. Again, Flash movies were much richer than regular web pages. But they were also black boxes. The Flash format seemed superior to the open standards of the web, and yet the very openness of those standards made the web an unstoppable force. Flash—under the control of just one company—faded away. The web grew. These days it’s native apps that make the web look like an underachiever. Like Flash, they’re under the control of individual companies instead of being a shared resource like the web. Like Flash, they demonstrate all sorts of capabilities that the web lacks, such as access to device APIs and, crucially, the ability to work even when there’s no network connection. The history of the web starts to sound like an endless retelling of the fable of the tortoise and the hare. CD-ROMs, Flash, and native apps outshine the web in the short term, but the web always seems to win the day somehow. Each of those technologies proved very useful for the expansion of web standards. In a way, Flash was like the R&D department for HTML, CSS, and JavaScript. Smooth animations, embedded video, and other great features first saw the light of day in Flash. Having shown their usefulness, they later appeared in web standards. The same thing is happening with native apps. Access to device features like the camera and the accelerometer is beginning to show up in web browsers. Most exciting of all, we’re finally getting the ability for a website to continue working even when the network isn’t available. Service Workers The technology that makes this bewitching offline sorcery possible is a browser feature called  . You might have heard of them. You might have heard that they’re something to do with JavaScript, and technically they are…but conceptually they’re very different from other kinds of scripts. Usually when you’re writing some JavaScript that’s going to run in a web browser, it’s all related to the document currently being displayed in the browser window. You might want to listen out for events triggered by the user interacting with the document (clicks, swipes, hovers, etc.). You might want to update the contents of the document: add some markup here, remove some text there, manipulate some values somewhere else. The sky’s the limit. And it’s all made possible thanks to the Document Object Model (DOM), a representation of what the browser is rendering. Through the combination of the DOM and JavaScript—DOM scripting, if you will—you can conjure up all sorts of wonderful magic. Well, a service worker can’t do any of that. It’s still a script, and it’s still written in the same language—JavaScript—but it has no access to the DOM. Without any DOM scripting capabilities, this kind of script might seem useless at first glance. But there’s an advantage to having a script that never needs to interact with the current document. Adding, editing, and deleting parts of the DOM can be hard work for the browser. If you’re not careful, things can get very sluggish very quickly. But if there’s a whole class of script that isn’t allowed access to the DOM, then the browser can happily run that script in parallel to its regular rendering activities, safe in the knowledge that it’s an entirely separate process. The first kind of script to come with this constraint was called a web worker. In a web worker, you could write some JavaScript to do number-crunching calculations without slowing down whatever else was being displayed in the browser window. Spin up a web worker to generate larger and larger prime numbers, for instance, and it will merrily do so in the background. A service worker is like a web worker with extra powers. It still can’t access the DOM, but it does have access to the fundamental inner workings of the browser. Browsers and servers Let’s take a step back and think about how the World Wide Web works. It’s a beautiful ballet of client and server. The client is usually a web browser—or, to use the parlance of web standards, a user agent: a piece of software that acts on behalf of the user. The user wants to accomplish a task or find some information. The URL is the key technology that will empower the user in their quest. They will either type a URL into their web browser or follow a link to get there. This is the point at which the web browser—or client—makes a request to a web server. Before the request can reach the server, it must traverse the internet of undersea cables, radio towers, and even the occasional satellite ( ). Imagine if you could leave instructions for the web browser that would be executed  . That’s exactly what service workers allow you to do ( ). Usually when we write JavaScript, the code is executed after it’s been downloaded from a server. With service workers, we can write a script that’s executed by the browser before anything else happens. We can tell the browser, “If the user asks you to retrieve a URL for this particular website, run this corresponding bit of JavaScript first.” That explains why service workers don’t have access to the Document Object Model; when the service worker is run, there’s no document yet. Getting your head around service workers A service worker is like a cookie. Cookies are downloaded from a web server and installed in a browser. You can go to your browser’s preferences and see all the cookies that have been installed by sites you’ve visited. Cookies are very small and very simple little text files. A website can set a cookie, read a cookie, and update a cookie. A service worker script is much more powerful. It contains a set of instructions that the browser will consult before making any requests to the site that originally installed the service worker. A service worker is like a virus. When you visit a website, a service worker is surreptitiously installed in the background. Afterwards, whenever you make a request to that website, your request will be intercepted by the service worker first. Your computer or phone becomes the home for service workers lurking in wait, ready to perform man-in-the-middle attacks. Don’t panic. A service worker can only handle requests for the site that originally installed that service worker. When you write a service worker, you can only use it to perform man-in-the-middle attacks on your own website. A service worker is like a toolbox. By itself, a service worker can’t do much. But it allows you to access some very powerful browser features, like the Fetch API, the Cache API, and even notifications. API stands for  , which sounds very fancy but really just means a tool that you can program however you want. You can write a set of instructions in your service worker to take advantage of these tools. Most of your instructions will be written as “when this happens, reach for this tool.” If, for instance, the network connection fails, you can instruct the service worker to retrieve a backup file using the Cache API. A service worker is like a duck-billed platypus. The platypus not only lactates, but also lays eggs. It’s the only mammal capable of making its own custard. A service worker can also…Actually, hang on, a service worker is nothing like a duck-billed platypus! Sorry about that. But a service worker is somewhat like a cookie, and somewhat like a virus, and somewhat like a toolbox. Safety First Service workers are powerful. Once a service worker has been installed on your machine, it lies in wait, like a patient spider waiting to feel the vibrations of a particular thread. Imagine if a malicious ne’er-do-well wanted to wreak havoc by impersonating a website in order to install a service worker. They could write instructions in the service worker to prevent the website ever appearing in that browser again. Or they could write instructions to swap out the content displayed under that site’s domain. That’s why it’s so important to make sure that a service worker really belongs to the site it claims to come from. As the specification for service workers puts it, they “create the opportunity for a bad actor to turn a bad day into a bad eternity.” To prevent this calamity, service workers require you to adhere to two policies: Same origin. HTTPS only. The same-origin policy means that a website at example.com can only install a service worker script that lives at example.com. That means you can’t put your service worker script on a different domain. You can use a domain like  for hosting your images and other assets, but not your service worker script. That domain wouldn’t match the domain of the site installing the service worker. The HTTPS-only policy means that https://example.com can install a service worker, but http://example.com can’t. A site running under HTTPS (the S stands for  ) instead of HTTP is much harder to spoof. Without HTTPS, the communication between a browser and a server could be intercepted and altered. If you’re sitting in a coffee shop with an open Wi-Fi network, there’s no guarantee that anything you’re reading in browser from http://newswebsite.com hasn’t been tampered with. But if you’re reading something from https://newswebsite.com, you can be pretty sure you’re getting what you asked for. Securing your site Enabling HTTPS on your site opens up a whole series of secure-only browser features—like the JavaScript APIs for geolocation, payments, notifications, and service workers. Even if you never plan to add a service worker to your site, it’s still a good idea to switch to HTTPS. A secure connection makes it trickier for snoopers to see who’s visiting which websites. Your website might not contain particularly sensitive information, but when someone visits your site, that’s between you and your visitor. Enabling HTTPS won’t stop unethical surveillance by the NSA, but it makes the surveillance slightly more difficult. There’s one exception. You can use a service worker on a site being served from localhost, a web server on your own computer, not part of the web. That means you can play around with service workers without having to deploy your code to a live site every time you want to test something. If you’re using a Mac, you can spin up a local server from the command line. Let’s say your website is in a folder called mysite. Drag that folder to the Terminal app, or open up the Terminal app and navigate to that folder using the   command to change directory. Then type: This starts a web server from the mysite folder, served over port 8000. Now you can visit localhost:8000 in a web browser on the same computer, which means you can add a service worker to the website you’ve got inside the mysite folder: http://localhost:8000. This starts a web server from the mysite folder, served over port 8000. Now you can visit localhost:8000 in a web browser on the same computer, which means you can add a service worker to the website you’ve got inside the mysite folder: http://localhost:8000. But if you then put the site live at, say, http://mysite.com, the service worker won’t run. You’ll need to serve the site from https://mysite.com instead. To do that, you need a secure certificate for your server. There was a time when certificates cost money and were difficult to install. Now, thanks to a service called Certbot, certificates are free. But I’m not going to lie: it still feels a bit intimidating to install the certificate. There’s something about logging on to a server and typing commands that makes me simultaneously feel like a l33t hacker, and also like I’m going to break everything. Fortunately, the process of using Certbot is relatively jargon-free ( ). On the  , you choose which kind of web server and operating system your site is running on. From there you’ll be guided step-by-step through the commands you need to type in the command line of your web server’s computer, which means you’ll need to have SSH access to that machine. If you’re on shared hosting, that might not be possible. In that case, check to see if your hosting provider offers secure certificates. If not, please pester them to do so, or switch to a hosting provider that can serve your site over HTTPS. Another option is to stay with your current hosting provider, but use a service like Cloudflare to act as a “front” for your website. These services can serve your website’s files from data centers around the world, making sure that the physical distance between your site’s visitors and your site’s files is nice and short. And while they’re at it, these services can make sure all of those files are served over HTTPS. Once you’re set up with HTTPS, you’re ready to write a service worker script. It’s time to open up your favorite text editor. You’re about to turbocharge your website! Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Keith\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/working-with-external-user-researchers-part-ii/", "title": "Working with External User Researchers: Part II", "content": "In the   of the   series, we explored the reasons why you might hire a user researcher on contract and helpful things to consider in choosing one. This time, we talk about getting the actual work done. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. You’ve hired a user researcher for your project. Congrats! On paper, this person (or team of people) has everything you need and more. You might think the hardest part of your project is complete and that you can be more hands off at this point. But the real work hasn’t started yet. Hiring the researcher is just the beginning of your journey.  Let’s recap what we mean by an external user researcher. Hiring a contract external user researcher means that a person or team is brought on for the duration of a contract to conduct research. This situation is most commonly found in: organizations without researchers on staff; organizations whose research staff is maxed out; and organizations that need special expertise. In other words, external user researchers exist to help you gain the insight from your users when hiring one full-time is not an option. Check out   to learn more about how to find external user researchers, the types of projects that will get you the most value for your money, writing a request for proposal, and finally, negotiating payment. Working together Remember why you hired an external researcher No project or work relationship is perfect. Before we delve into more specific guidelines on how to work well together, remember the reasons why you decided to hire an external researcher (and this specific one) for your project. Keeping them in mind as you work together will help you keep your priorities straight. External researchers are great for bringing in a fresh, objective perspective You could ask your full-time designer who also has research skills to wear the research hat. This isn’t uncommon. But a designer won’t have the same depth and breadth of expertise as a dedicated researcher. In addition, they will probably end up researching their own design work, which will make it very difficult for them to remain unbiased. Product managers sometimes like to be proactive and conduct some form of guerrilla user research themselves, but this is an even riskier idea. They usually aren’t trained on how to ask non-leading questions, for example, so they tend to only hear feedback that validates their ideas. It isn’t a secret—but it’s well worth remembering—that research participants tend to be more comfortable sharing critical feedback with someone who doesn’t work for the product that is being tested. The real work begins In our experience the most important work starts once a researcher is hired. Here are some key considerations in setting them and your own project team up for success. Be smart about the initial brain dump Do share background materials that provide important context and prevent redundant work from being done. It’s likely that some insight is already known on a topic that will be researched, so it’s important to share this knowledge with your researcher so they can focus on new areas of inquiry. Provide things such as report templates to ensure that the researcher presents their learnings in a way that’s consistent with your organization’s unique culture. While you’re at it, consider showing them where to find documentation or tutorials about your product, or specific industry jargon. Make sure people know who they are Conduct a project kick-off meeting with the external researcher and your internal stakeholders. Influence is often partially a factor of trust and relationships, and for this reason it’s sometimes easy for internal stakeholders to question or brush aside projects conducted by research consultants, especially if they disagree with research insights and recommendations. (Who is this person I don’t know trying to tell me what is best for my product?) Conduct a kick-off meeting with the broader team A great way to prevent this potential pushback is to conduct a project kick-off meeting with the external researcher and important internal stakeholders or consumers of the research. Such a meeting might include activities such as:  Team introductions. A discussion about the research questions, including an exercise for prioritizing the questions. Especially with contracted-out projects, it’s common for project teams to be tempted to add more questions—question creep—which is why it’s important to have clear priorities from the start. A summary of what’s out of scope for the research. This is another important task in setting firm boundaries around project priorities from the start so the project is completed on time and within budget. A summary of any incoming hypotheses the project team might have—in other words, what they think the answers to the research questions are. This can be an especially impactful exercise to remind stakeholders how their initial thinking changed in response to study findings upon the study being completed. A review of the project phases and timeline, and any threats that could get in the way of the project being completed on time. A review of prior research and what’s already known, if available. This is important for both the external researcher and the most important internal consumers of the research, as it’s often the case that the broader project team might not be aware of prior research and why certain questions already answered aren’t being addressed in the project at hand. Use a buddy system Appoint an internal resource who can answer questions that will no doubt arise during the project. This might include questions on how to use an internal lab, questions about whom to invite to a critical meeting, or clarifying questions regarding project priorities. This is also another opportunity to build trust and rapport between your project team and external researcher.  Conducting the research While an external researcher or agency can help plan and conduct a study for you, don’t expect them to be experts on your product and company culture. It’s like hiring an architect to build your house or a designer to furnish a room: you need to provide guidance early and often, or the end result may not be what you expected. Here are some things to consider to make the engagement more effective. Be available A good research contractor will ask lots of questions to make sure they’re understanding important details, such as your priorities and research questions, and to collect feedback on the study plan and research report. While it can sometimes feel more efficient to handle most of these types of questions over email, email can often result in misinterpretations. Sometimes it’s faster to speak to questions that require lots of detail and context rather than type a response. Consider establishing weekly remote or in-person status checks to discuss open questions and action items.  Be present If moderated sessions are part of the research, plan on observing as many of these as possible. While you should expect the research agency to provide you with a final report, you should not expect them to know which insights are most impactful to your project. They don’t have the background from internal meetings, prior decisions, and discussions about future product directions that an internal stakeholder has. Many of the most insightful findings come from conversations that happen immediately after a session with a research participant. The research moderator and client contact can share their perspectives on what the participant just did and said during their session. Be proactive Before the researcher drafts their final report, set up a meeting between them and your internal stakeholders to brainstorm over the main research findings. This will help the researcher identify more insights and opportunities that reflect internal priorities and limitations. It also helps stakeholders build trust in the research findings. In other words, it’s a waste of everyone’s time if a final report is delivered and basic questions arise from stakeholders that could have been addressed by involving them earlier. This is also a good opportunity to get feedback from stakeholders’ stakeholders, who may have a different (but just as important) influence on the project’s success. Be reasonable Don’t treat an external contractor like a PowerPoint jockey. Changing fonts and colors to your liking is fine, but only to a point. Your researcher should provide you with a polished report free from errors and in a professional format, but minute changes are not a constructive use of time and money. Focus more on decisions and recommendations than the aesthetics of the deliverables. You can prevent this kind of situation by providing any templates you want used in your initial brain dump, so the findings don’t have to be replicated in the “right” format for presenting. When it’s all said and done Just because the project has been completed and all the agreed deliverables have been received doesn’t mean you should close the door on any additional learning opportunities for both the client and researcher. At the end of the project, identify what worked, and find ways to increase buy-in for their recommendations. Tell them what happened Try to identify a check-in point in the future (such as two weeks or months) to let the researcher know what happened because of the research: what decisions were made, what problems were fixed, or other design changes. While you shouldn’t expect your researcher to be perpetually available, if you encounter problems with buy-in, they might be able to provide a quick recommendation.  Maintain a relationship While it’s typical for vendors to treat their clients to dinner or drinks, don’t be afraid to invite your external researcher to your own happy hour or event with your staff. The success of your next project may rely on getting the right researcher, and you’ll want them to be excited to make themselves available to help you when you need them again. Like this: \n\t\t\t\t\t\t\tRecently by Chelsey Glasson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-illusion-of-control-in-web-design/", "title": "The Illusion of Control in Web Design", "content": "We all want to build robust and engaging web experiences. We scrutinize every detail of an interaction. We spend hours getting the animation swing just right. We refactor our JavaScript to shave tiny fractions of a second off load times. We control absolutely everything we can, but the harsh reality is that we control less than we think. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Last week, two events reminded us, yet again, of how right Douglas Crockford was when he declared the web “the most hostile software engineering environment imaginable.” Both were serious enough to take down an entire site—actually hundreds of entire sites, as it turned out. And both were avoidable. In understanding what we control (and what we don’t), we will build resilient, engaging products for our users. What happened? The first of these incidents involved the launch of Chrome 66. With that release, Google implemented a security patch with serious implications for folks who weren’t paying attention. You might recall that   early last year. Apparently, Symantec had subcontracted the creation of certificates without providing a whole lot of oversight. Long story short, the Chrome team decided the best course of action with respect to these potentially bogus (and security-threatening) SSL certificates was to set an “end of life” for accepting them as secure. They set Chrome 66 as the cutoff. So, when Chrome 66 rolled out (an automatic, transparent update for pretty much everyone), suddenly any site running HTTPS on one of these certificates would no longer be considered secure. That’s a major problem if the certificate in question is for our primary domain, but it’s also a problem it’s for a CDN we’re using. You see, my server may be running on a valid SSL certificate, but if I have my assets—images, CSS, JavaScript—hosted on a CDN that is not secure, browsers will block those resources. It’s like   all over again. To be completely honest, I wasn’t really paying attention to this until  . Two hundred of his employer’s sites were instantly reduced to plain old semantic HTML. No CSS. No images. No JavaScript. The second incident was actually quite similar in that it also involved SSL, and specifically  . If a site relied on that CDN to serve an HTTPS-hosted version of jQuery, their users wouldn’t have received it. And if that site was dependent on jQuery to be usable … well, ouch! For what it’s worth, this isn’t the first time incidents like these have occurred. Only a few short years ago,  . With that designation in place, they spent the better part of a day blocking all requests for resources on that domain, affecting nearly all of their customers. It can be easy to shrug off news like this. Surely we’d make smarter implementation decisions if we were in charge. We’d certainly have included a local copy of jQuery  . The thing is, even with that extra bit of protection in place, we’re falling for one of the most attractive fallacies when it comes to building for the web: that we have control. Lost in transit? There are some things we do control on the web, but they may be fewer than you think. As a solo dev or team lead, we have considerable control over the HTML, CSS, and JavaScript code that ultimately constructs our sites. Same goes for the tools we use and the hosting solutions we’ve chosen. Of course, that control lessens on large teams or when others are calling the shots, though in those situations we still have an awareness of the coding conventions, tooling, and hosting environment we’re working with. Once our carefully-crafted code leaves our servers, however, all bets are off. First off, we don’t—at least in the vast majority of cases—control the network our code traverses to reach our users. Ideally our code takes an optimized path so that it reaches its destination quickly, yet any one of the servers along that path can read and manipulate the code. If you’ve heard of “man-in-the-middle” attacks, this is how they happen. For example, certain  . Gross, right? HTTPS is one way to stop this from happening (and to prevent servers from being able to snoop on our traffic), but  . Sigh. Lost in translation? Assuming no one touches our code in transit, the next thing standing between our users and our code is the browser. These applications are the gateways to (and gatekeepers of) the experiences we build on the web. And, even though the last decade has seen browser vendors coalesce around web standards, there are still differences to consider. Those differences are yet another factor that will make or break the experience our users have. While every browser vendor supports the idea and ongoing development of standards, they do so at their own pace and very much in relation to their business interests. They prioritize features that help them meet their own goals and can sometimes be reluctant or slow to implement new features. Occasionally, as happened with CSS Grid, everyone gets on board rather quickly, and  . Others, like Service Worker, can  . Still others, like Pointer Events, might get  . All of this is to say that the browser landscape is much like the Great Plains of the American Midwest: from afar  , but walking through it we’re bound to stumble into a prairie dog burrow or two. And to successfully navigate the challenges posed by the browser environment, it pays to get familiar with where those burrows lie so we don’t lose our footing. Object detection … font stacks … media queries … feature detection … these tools (and more) help us ensure our work doesn’t fall over in less-than-ideal situations. Beyond standards support, it’s important to recognize that some browsers include optimizations that can affect the delivery of your code. Opera Mini and Amazon’s Silk are examples of the class of browser often referred to as  . Proxy browsers, as their name implies, position their own proxy servers in between our domains and the end user. They use these servers to do things like optimize images, simplify markup, and jettison unsupported JavaScript in the interest of slimming the download size of our pages. Proxy browsers can be a tremendous help for users  , especially given  . If we don’t consider how these browsers can affect our pages, our site may simply collapse and splay its feet in the air like a fainting goat. Consider this JavaScript taken from  : This code is designed to insert several paragraphs into the current document and, when executed, produces this: Simple enough, right? Well, yes and no. You see, this code makes use of the   keyword, which was introduced in ECMAScript 2015 (a.k.a. ES6) to enable block-level variable scoping. It will work a treat in browsers that understand  . However, any browsers that don’t understand   will have no idea what to make of it and won’t execute   of the JavaScript—not even the parts they do understand—because they don’t know how to interpret the program. Users of Opera Mini, Internet Explorer 10, QQ, and Safari 9 would get nothing. This is a relatively simplistic example, but it underscores  .   and discovered that 0.9% of their users who should have received them—in other words, their browser supported JavaScript and they had not turned it off—didn’t for some reason. Add in the 0.2% of users whose browsers did not support JavaScript or who had turned it off, and the total non-JavaScript constituency was 1.1%, or 1 in every 93 people who visit their site. It’s worth keeping in mind that browsers must understand the entirety of our JavaScript before they can execute it. This may not be a big deal if we write all of our own JavaScript (though we all occasionally make mistakes), but it becomes a big deal when we include third-party code like JavaScript libraries, advertising code, or social media buttons. Errors in any of those codebases can cause problems for our users. Browser plugins are another form of third-party code that can negatively affect our sites. And they’re ones we don’t often consider. Back in the early ’00s, I remember spending hours trying to diagnose a site issue reported by one of my clients, only to discover it only occurred when using a particular plugin. Anger and self-doubt were wreaking havoc on me as I failed time and time again to reproduce the error my client was experiencing. It took me traveling the two hours to her office and sitting down at her desk to discover the difference between her setup and mine: a third-party browser toolbar. We don’t have the luxury of traveling to our users’ homes and offices to determine if and when a browser plugin is hobbling our creations. Instead, the best defense against the unknowns of the browsing environment is to always design our sites with a universally usable baseline. Lost in interpretation? Regardless of everything discussed so far, when our carefully crafted website finally reaches its destination, it has one more potential barrier to success: us. Specifically, our users. More broadly, people. Unless our product is created solely for the consumption of some other life form or machine, we’ve got to consider the ultimate loss of control when we cede it to someone else. Over the course of my twenty years of building websites for customers, I’ve always had the plaintive voice of   Randal Graves in the back of my head: “This job would be great if it wasn't for the f—ing customers.” I’m not happy about that. It’s an arrogant position (surely), yet an easy one to lapse into. When we design and build for people like us, we exclude everyone who isn’t like us. And that’s most people. I’m going to put on my business hat here—Fedora? Bowler? Top hat?—and say that artificially limiting our customer base is probably not in our company’s best interest. Not only will it limit our potential revenue growth, it could actually reduce our income if we become  . Our efforts to build robust experiences on the web must account for the actual people that use them (or may want to use them). That means ensuring our sites work for people who experience motor impairments, vision impairments, hearing impairments, vestibular disorders, and other things we aggregate under the heading of “accessibility.” It also means ensuring our sites work well for users in a variety of contexts: on large screens, small screens, even in-between screens. Via mouse, keyboard, stylus, finger, and even voice. In dark, windowless offices, glass-walled conference rooms, and out in the midday sun. Over blazingly fast fiber and painfully slow cellular networks. Wherever people are, however they access the web, whatever special considerations need to be made to accommodate them … we should build our products to support them. That may seem like a tall order, but consider this: removing access barriers for one group has a far-reaching ripple effect that benefits others. The roadside curb cut is  . It was originally designed for wheelchair access, but stroller-pushing parents, children on bicycles, and even that UPS delivery person hauling a tower of Amazon boxes down Seventh Avenue all benefit from that rather simple consideration.  Maybe you’re more of a numbers person. If so, consider designing your interface such that it’s easier to use by someone who only has use of one arm. Every year, about 26,000 people in the U.S. permanently lose the use of an upper extremity. That’s a drop in the bucket compared to an overall population of nearly 326 million people. But that’s a permanent impairment. There are two other forms of impairment to consider: temporary and situational. Breaking your arm can mean you lose use of that hand—maybe your dominant one—for a few weeks. About 13 million Americans suffer an arm injury like this every year. Holding a baby is a situational impairment in that you can put it down and regain use of your arm, but the feasibility of that may depend greatly on the baby’s temperament and sleep schedule. About 8 million Americans welcome this kind of impairment—sweet and cute as it may be—into their home each year, and this particular impairment can last for over a year. All of this is to say that designing an interface that’s usable with one hand (or via voice) can help   (about 6% of the population) effectively use your service. Finally, and in many ways coming full circle, there’s the copy we employ. Clear, well-written, and appropriate copy is the bedrock of great experiences on the web. When we draft copy, we should do so with a good sense of how our users talk to one another. That doesn’t mean we should pepper our legalese with slang, but it does mean we should author copy that is easily understood. It should be written at an appropriate reading level, devoid of unnecessary jargon and idioms, and approachable to both native and non-native speakers alike. Nestled in the gentle embrace of our (hopefully) semantic, server-rendered HTML, the copy we write is one of the only experiences of our sites we can pretty much guarantee our users will have. Old advice, still relevant Recognizing all of the ways our carefully-crafted experiences can be rendered unusable can be more than a little disheartening. No one likes to spend their time thinking about failure. So don’t. Don’t focus on all of the bad things you can’t control. Focus on what you   control. Start simply. Code defensively. User-test the heck out of it. Recognize the chaos. Embrace it. And   that will work no matter what the internet throws at them. Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/priority-guides-a-content-first-alternative-to-wireframes/", "title": "Priority Guides: A Content-First Alternative to Wireframes", "content": "No matter your role, if you’ve ever been involved in a digital design project, chances are you’re familiar with wireframes. After all, they’re among the most popular and widely used tools when designing websites, apps, dashboards, and other digital user interfaces. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But they do have their problems, and wireframes are so integrated into the accepted way of working that many don’t consider those drawbacks. That’s a shame, because the tool’s downsides can seriously undermine user-centricity. Ever lose yourself in aesthetic details when you should have been talking about content and functionality? We have!  That’s why we use an alternative that avoids the pitfalls of wireframes: the  . It not only keeps our process user-centered and creates more valuable designs for our users (whether used alongside wireframes or as a direct replacement), it’s also improved team engagement, collaboration, and design workflows. The problem with wireframes  appropriately defines the wireframe as “a visual guide that represents the skeletal framework of a website. … [It] depicts the page layout or arrangement of the website’s content, including interface elements and navigational systems.” In other words, wireframes are sketches that represent the potential website (or app) in a simplified way, including the placement and shape of any interface elements. They range from low-fidelity rough sketches on paper to high-fidelity colored, textual screens in a digital format.  Because of their visual nature, wireframes are great tools for sketching and exploring design ideas, as well as communicating those ideas to colleagues, clients, and stakeholders. And since they’re so easy to create and adapt with tools such as   or  , you also have something to user test early in the design process, allowing usability issues to be addressed sooner than might otherwise be possible.  But although these are all valuable characteristics of wireframes, there are also some significant downsides. The illusion of final design Wireframes can provide the illusion that a design is final, or at least in a late stage of completion. Regardless of how carefully you explain to clients or stakeholders that these first concepts are just early explorations and not final—maybe you even decorated them with big “DRAFT” stickers—too often they’ll still enthusiastically exclaim, “Looks good, let’s start building!”  Killing creativity and engagement At Mirabeau, we’ve noticed that wireframes tend to kill creativity. We primarily work in multidisciplinary teams consisting of (among others) interaction (UX) designers, visual designers, front-end developers, and functional testers. But once an interaction designer has created a wireframe, it’s hard for many (we’re not saying all) visual designers to think outside the boundaries set by that wireframe and challenge the ideas it contains. As a result, the final designs almost always resemble the wireframes. Their creativity impaired, the visual designers were essentially just coloring in the wireframes.  Undermining user-centricity As professionals, we naturally care about how something looks and is presented. So much so that we can easily lose ourselves for hours in the fine details, such as alignment, sizing, coloring, and the like, even on rough wireframes intended only for internal use. Losing time means losing focus on what’s valuable for your user: the content, the product offering, and the functionality.  Static, not responsive A wireframe (even multiple wireframes) can’t capture the responsive behavior that is so essential to modern web design. Even though digital design tools are catching up in efficiently designing for different screen sizes (here’s hoping   will deliver), each of the resulting wireframes is still just a static image.  Inconvenient for developers and functional testers Developers and functional testers work with code, and a wireframe sketch or picture provides little functional information and isn’t directly translatable into code (not  , anyway). This lack of clarity around how the design should behave can lead to developers and testers making decisions about functionality or responsiveness without input from the designer, or having to frequently check with the designer to find out if a feature is working correctly. Perhaps less of a problem for a mature team or project where there’s plenty of experience with, and knowledge of, the product, but all too often this (unnecessary) collaboration means more development work, a slower process, and wasted time.  To overcome these wireframe pitfalls, about five years ago we adopted priority guides. Our principal interaction designer, Paul Versteeg, brought the tool to Mirabeau, and we’ve been improving and fine-tuning our way of working with them ever since, with great results.  So what are priority guides? As far as we know, credit for the invention of priority guides goes to Drew Clemens, who first introduced the concept in his   on the Smashing Magazine website in 2012. Since that time, however, it seems that priority guides have received little attention, either from the web and app design industry or within related education establishments.  Simply put, a priority guide contains content and elements for a mobile screen, sorted by hierarchy from top to bottom and without layout specifications. The hierarchy is based on relevance to users, with the content most critical to satisfying user needs and supporting user (and company) goals higher up.  The format of a priority guide is not fixed: it can be   (we personally prefer Sketch), or it can be  , made with paper and Post-its. Most importantly, a priority guide is automatically content-first, with a strong focus on providing best value for users. Diving a bit deeper, the following example shows the exact same page as shown in the wireframe images presented earlier in this article. It consists of the title “Book a flight,” real content (yes, even the required legal notice!), several sections of information, and annotations that explain components and functionality. When comparing the content to the high-fidelity wireframe, you’ll notice that the order of the sections is not the same. The step indicator, for example, is shown at the bottom of the priority guide, as the designer decided it’s   the most important information on the page. Conversely, the most important information—flight information and prices—is now placed near the top.  Annotations are an important part of priority guides, as they provide explanations of the functionalities and page behavior, name the component types, and link the priority guide of one page to the priority guides of other pages. In this example, you can find descriptions of what happens when a user interacts with a button or link, such as opening a layover screen to display flight details or loading a a flight selection page.  The advantages of priority guides Of course, we can debate for hours whether the creator of, or team responsible for, the above priority guide has chosen the correct priorities and functionalities, but that goes beyond the scope of this article. Instead, let’s name the main advantages that priority guides offer over wireframes. Suitable for responsive design Wireframes are static images, requiring multiple screenshots to cover the full spectrum from mobile to desktop. Priority guides, on the other hand, give an overview of content hierarchy   of screen size (assuming user goals remain the same on different devices). Ever since responsive design became standard practice within Mirabeau, priority guides have been an essential addition to our design toolkit.  Focused on solving problems and serving needs When creating priority guides, you automatically focus on solving the users’ problems, serving their needs, and supporting them to reach their goals. The interface is always filled with content that communicates a message or helps the user. By designing content-first, you’re always focused on serving the user. No time wasted on aesthetics and layout There’s no need for interaction designers to waste time on aesthetics and layout in the early phases of the design process. Priority guides help avoid the focus shifting away from the content and user toward specific layout elements too early, and keep us from falling into the “designer trap” of visual perfectionism.  Facilitating visual designers’ creativity Priority guides provide the opportunity for designers to explore extravagant ideas on how to best support and delight the user without visual boundaries set by interaction designers. Even when you’re the only designer on your team, working as both interaction and visual designer, it’s hard to move past how those first wireframes looked, even when confronted with new content.  Developers and testers get “HTML” early in the process The structure of a priority guide is very similar to HTML, allowing the developer to start laying the groundwork for future development early on. Similarly, testers get a checklist for testing, allowing them to begin building those tests straight away. The result is early feedback on the feasibility of the designs, and we’ve found priority guides have significantly speeded up the collaborative process of design and development at Mirabeau.  How to create priority guides There are a number of baselines and steps that we’ve found useful when creating priority guides. We’ve fine-tuned them over the years as we’ve applied this new approach to our projects, and conducted workshops explaining priority guides to the Dutch design community.  The baselines Your priority guide should only contain   that’s relevant to the user. Lorem ipsum, or any other type of placeholder text, doesn’t communicate how the page supports users in reaching their goals. Moreover,   when making priority guides. Instead, include only content and functionality. Remember that a priority guide is never a deliverable—it’s merely a tool to facilitate discussion among the designers, developers, testers, and stakeholders involved in the project.  Priority guides should always have a  . By constraining yourself this way, you automatically think mobile-first and consider which information is most important (and so should be at the top of the screen). Also, since the menu is typically more or less the same on every screen of your website or app, we recommend   of your priority guide. It’ll help you focus on the screen you’re designing for, and the guide won’t be cluttered with unnecessary distractions.  Step 1: determine the goal(s) Before jumping to the solution, it’s important to take a step back and consider why you’re making this priority guide. What is the purpose of the page? What goal or goals does the user have? And what goal or goals does the business have? The answers to these questions will both guide your user research and determine which content will add more value to users and the business, and so have higher priority.  Step 2: research and understand the user There are many methods for  , and the method or methods chosen will largely depend on the situation and project. However, when creating priority guides, we’ve definitely found it useful to generate personas, affinity diagrams, and experience maps to help create a visual summary of any research findings.  Step 3: determine the content topics The aim of this stage is to use your knowledge of the user and the business to determine which specific content and topics will best support their goals in each phase of the customer journey. Experience has taught us that co-creating this content outline with users, clients, copywriters, and stakeholders can be highly beneficial. The result is a   that each page should contain.  Step 4: create a high-level priority guide Use the list of topics to create a   priority guide. Which is the most important topic? Place that one on the top. Which is the second most important topic? That one goes below the first. It’s a straightforward prioritization process that should be continued until all the (relevant) topics have found a place in the priority list. It’s important to question the importance of each topic, not only in comparison to other topics, but also whether the topic should really be on the page at all. And we’ve found that starting on paper definitely helps avoid focusing too much on the little visual details, which can happen if using a digital design tool (“pixel-fixing”).  Step 5: create a detailed priority guide Now it’s time to start adding the details. For each topic, determine the detailed, real content that will appear on the page. Also, start thinking about any functionalities the page may need. When you have multiple priority guides for multiple pages, indicate how and where these pages are connected in a sitemap format.  We often use this first schematic shape of the product to identify flows, test if the concept is complete, and determine whether the current content and priorities effectively serve users’ needs and help solve their problems. More than once it has allowed us to identify that a content plan needed to be altered to achieve the outcome we were targeting. And because priority guides are quick and easy to produce, iterating at this stage saved a lot of time and effort. Step 6: user testing and (further) iteration The last (continuous) step involves testing and iterating your priority guides. Ask users what they think about the information presented in the priority guides (yes, it is possible to do usability testing with priority guides!), and gather feedback from stakeholders. The input gained from these sessions can then be used to validate and reprioritize the information, and to add or adapt functionalities, followed by further testing as needed.  Find out what works for you Over the years we’ve seen many variations on the process described above. Some designers work entirely with paper and Post-its, while others prefer to create priority guides in a digital design tool from scratch. Some go no further than high-level priority guides, while others use detailed priority guides as a guideline for their entire project.  The key is to experiment, and take the time to find out which approach works best for you and your team. What remains important no matter your process, however, is the need to always keep the focus on user and business goals, and to continuously ask yourself what each piece of content or functionality adds to these goals.  Conclusion For us here at Mirabeau, priority guides have become a highly efficient tool for designing user-first, content-first, and mobile-first, overcoming many of the significant pitfalls that come from relying only on wireframes. Wireframes do have their uses, and in many situations it’s valuable to be able to visualize ideas and discuss them with team members, clients, or stakeholders. Sketching concepts as wireframes to test ideas can also be useful, and sometimes we’ll even generate wireframes to gain new insights into how to improve our priority guides! Overall, we’ve found that priority guides are more useful at the start of a project, when in the phase of defining the purpose and content of screens. Wireframes, on the other hand, are more useful for sketching and communicating ideas and visual concepts. Just don’t   with wireframes, and make sure you always stay focused on what’s important.  Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/were-looking-for-people-who-love-to-write/", "title": "We’re Looking for People Who Love to Write", "content": "Here at  ,  , and that means you. What should you write about? Glad you asked! Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. You should write about topics that keep you up at night, passions that make you the first to show up in the office each morning, ideas that matter to our community and about which you have a story to tell or an insight to share.  We’re not looking for case studies about your company or thousand-foot overviews of topics most ALA readers already know about (i.e., you don’t have to tell   readers that Sir Tim Berners-Lee invented the web). But you also don’t have to write earth-shaking manifestos or share new ways of working that will completely change the web. A  , or   about an industry best practice make excellent ALA articles. Where we’ve been Although   covers everything from accessible UX and product design to advanced typography and content and business strategy, the sweet spot for an   article is one that combines UI design (and design  ) with front-end code, especially when it’s innovative. Thus our most popular article of the past ten years was Ethan Marcotte’s “ ”—a marriage of design and code, accessible to people with diverse backgrounds at differing levels of expertise. In the decade-plus before that, our most popular articles were Douglas Bowman’s “ ” and Dan Cederholm’s “ ”—again, marriages of design and code, and mostly in the nature of clever workarounds (because CSS in 2004 didn’t really let us design pages as flexibly and creatively, or even as reliably, as we wanted to). From hacks to standards Although clever front-end tricks like Sliding Doors, and visionary re-imaginings of the medium like Responsive Web Design, remain our most popular offerings, the magazine has offered fewer of them in recent years, focusing more on UX and strategy. To a certain extent, if a front-end technique isn’t earth-changing (i.e., isn’t more than just a technique), and if it isn’t semantic, inclusive, accessible, and progressively enhanced, we don’t care how flashy it is—it’s not for us. The demand to create more powerful layouts was also, in a real way, satisfied by the rise of   and shared libraries—another reason for us to have eased off front-end tricks (although not all frameworks and libraries are equally or in some cases even acceptably semantic, inclusive, accessible, and progressively enhanced—and, sadly, many of their users don’t know or care). Most importantly, now that   of   without hacks, any responsible web design publication will want to ease off on the flow of front-end hacks, in favor of standards-based education, from basic to advanced. Why would any editor or publisher (or framework engineer, for that matter) recommend that designers use 100 pounds of fragile JavaScript when a dozen lines of stable CSS will do? It will be interesting to see what happens to the demand for layout hack articles in Medium and web design publications and communities over the next twelve months. It will also be interesting to see what becomes of frameworks  . But that’s not   problem. Our problem is finding the best ideas for  ’s readers, and working with the industry’s best old and new writers to polish those ideas to near-perfection. After all, even more than being known for genius one-offs like Responsive Web Design and Sliding Doors of CSS,  has spent its life introducing future-friendly, user-focused design advances to this community, i.e.,               were the rage,         when Flash was the rage,         on the web years before Typekit was a gleam in Jeff Veen’s eye,       in   when most design-y websites thought single-spaced 7px Arial was plenty big enough, promoting accessible design solutions, user-focused solutions, independent content and communities, and so on.  Call to action Great, industry-changing articles are still what we want most, whether they’re front-end, design, content, or strategy-focused. And changing the industry doesn’t have to mean inventing a totally new way of laying out pages or evaluating client content. It can also mean coming up with a compelling argument in favor of an important but embattled best practice. Or sharing an insightful story that helps those who read it be more empathetic and more ethical in their daily work.  Who will write the next 20 years of great   articles?  .  Publishing on   isn’t as easy-peasy as dashing off a post on your blog, but the results—and the audience—are worth it. And when you write for  , you never write alone: our industry-leading editors, technical editors, and copyeditors are ready to help you polish your best idea from good to great.  Come share with us! Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/so-you-want-to-write-an-article/", "title": "So You Want to Write an Article?", "content": "So you want to write an article. Maybe you’ve got a great way of organizing your CSS, or you’re a designer who has a method of communicating really well with developers, or you have some insight into how to best use a new technology. Whatever the topic, you have insights, you’ve read  , and you’re ready to write and submit your first article for a major publication. Here’s the thing: most article submissions suck. Yours doesn’t have to be one of them. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. At  , we want to see great minds in the industry write the next great articles, and you could be one of our writers. I’ve been on the editorial team here for about nine months now, and I’ve written a fair share of articles here as well. Part of what I do is review article submissions and give feedback on what’s working and what’s not. We publish different kinds of articles, but many of the submissions I see—particularly from newer writers—fall into the same traps. If you’re trying to get an article published in   or anywhere else, knowing these common mistakes can help your article’s chances of being accepted. Keep introductions short and snappy Did you read the introduction above? My guess is a fair share of readers skipped straight to this point. That’s pretty typical behavior, especially for articles like this one that offer several answers to one clear question. And that’s totally fine. If you’re writing, realize that some people will do the same thing. There are some things you can do to improve the chances of your intro being read, though. Try to open with a bang.   has perhaps the best example of this I’ve ever seen: “I won an Emmy for keeping a website free of dick pics.” When I saw that in the submission, I was instantly hooked and read the whole thing. It’s hilarious, it shows she has expertise on managing content, and it shows that the topic is more involved and interesting than it may at first seem. A more straightforward introduction to the topic of content procurement would seem very boring in comparison. Your ideas are exciting, so show that right away if you can. A funny or relatable story can also be a great way to lead into an article—just keep it brief! If you can’t open with a bang, keep it short. State the problem, maybe put something about why it matters or why you’re qualified to write about it, and get to the content as quickly as possible. If a line in your introduction does not add value to the article, delete it. There’s little room for meandering in professional articles, but there’s absolutely no room for it in introductions. Get specific Going back to my first article submission for  , way before I joined the team, I wanted to showcase my talent and expertise, and I thought the best way to do this was to showcase   of it in one article. I wrote an overview of professional skills for web professionals. There was some great information in there, based on my years of experience working up through the ranks and dealing with workplace drama. I was so proud when I submitted the article. It wasn’t accepted, but I got some great feedback from the editor-in-chief: get more specific. The most effective articles I see deal with one central idea. The more disparate ideas I see in an article, the less focused and impactful the article is. There will be exceptions to this, of course, but those are rarer than articles that suffer for this. Don’t give yourself a handicap by taking an approach that fails more often than it succeeds. Covering one idea in great detail, with research and examples to back it up, usually goes a lot further in displaying your expertise than an overview of a bunch of disparate thoughts. Truth be told, a lot of people have probably arrived at the same ideas you have. The insights you have are not as important as your evidence and eloquence in expressing them. Can an overview article work? Actually, yes, but you need to frame it within a specific problem. One great example I saw was an overview of web accessibility (which has not been published yet). The article followed a fictional project from beginning to end, showing how each team on the project could work toward a goal of accessibility. But the idea was not just accessibility—it was how leaders and project managers could assign responsibility in regards to accessibility. It was a great submission because it began with a problem of breadth and offered a complete solution to that problem. But it only worked because it was written specifically for an audience that needed to understand the whole process. In other words, the comprehensive nature of the article was the entire point, and it stuck to that. Keep your audience in mind You have a viewpoint. A problem I frequently see with new submissions is forgetting that the audience also has its viewpoint. You have to know your audience and remember how the audience’s mindset matches yours—or doesn’t. In fact, you’ll probably want to state in your introduction who the intended audience is to hook the right readers. To write a successful article, you have to keep that audience in mind and write for it specifically. A common mistake I see writers make is using an article to vent their frustrations about the people who won’t listen to them. The problem is that the audience of our publication usually agrees with the author on these points, so a rant about why he or she is right is ultimately pointless. If you’re writing for like-minded people, it’s usually best to assume the readers agree with you and then either delve into how to best accomplish what you’re writing about or give them talking points to have that conversation in their workplace. Write the kind of advice you wish you’d gotten when those frustrations first surfaced. Another common problem is forgetting what the audience already knows—or doesn’t know. If something is common knowledge in your industry, it doesn’t need another explanation. You might link out to another explanation somewhere else just in case, but there’s no need to start from scratch when you’re trying to make a new point. At the same time, don’t assume that all your readers have the same expertise you do. I wrote  —something many JavaScript developers are not familiar with. Rather than spend half the article giving an overview of object-oriented programming, though, I provided some links at the beginning of the article that gave a good overview. Pro tip: if you can link out to articles from the same publication you’re submitting to, publications will appreciate the free publicity. Defining your audience can also really help with knowing their viewpoint. Many times when I see a submission with two competing ideas, they’re written for different audiences. In my article I mentioned above, I provide some links for developers who may be new to object-oriented programming, but the primary audience is developers who already have some familiarity with it and want to go deeper. Trying to cater to both audiences wouldn’t have doubled the readership—it would have reduced it by making a large part of the article less relevant to readers. Keep it practical I’ll admit, of all these tips, this is the one I usually struggle with the most. I’m a writer who loves ideas, and I love explaining them in great detail. While there are some readers who appreciate this, most are looking for some tangible ways to improve something. This isn’t to say that big concepts have no place in professional articles, but you need to ask why they are there. Is your five-paragraph explanation of the history of your idea necessary for the reader to make the improvements you suggest? This became abundantly clear to me in my first submission of  . I love psychology and initially included a lengthy section up-front on how our self-esteem springs from the strengths we leaned on growing up. While this fascinated me, it wasn’t right for an audience of web professionals who wanted advice on how to improve their working relationships. Based on feedback I received, I removed the section entirely and added a section on how to manage your own ego in the workplace—much more practical, and that ended up being a favorite section in the final piece. Successful articles solve a problem. Begin with the problem—set it up in your introduction, maybe tell a little story that illustrates how this problem manifests—and then build a case for your solution. The problem should be clear to the reader very early on in the article, and the rest of the article should all be related to that problem. There is no room for meandering and pontification in a professional article. If the article is not relevant and practical, the reader will move on to something else. The litmus test for determining the practicality of your article is to boil it down to an outline. Of course all of your writing is much more meaningful than an outline, but look at the outline. There should be several statements along the lines of “Do this,” or “Don’t do this.” You can have other statements, of course, but they should all be building toward some tangible outcome with practical steps for the reader to take to solve the problem set up in your introduction. It’s a hard truth you have to learn as a writer that you’ll be much more in love with your ideas than your audience will. Writing professional articles is not about self-expression—it’s about helping and serving your readers. The more clear and concise the content you offer, the more your article will be read and shared. Support what you say Your opinions, without evidence to support them, will only get you so far. As a writer, your ideas are probably grounded in a lot of real evidence, but your readers don’t know that—you’ll have to show it. How do you show it? Write a first draft and get your ideas out. Then do another pass to look for stories, stats, and studies to support your ideas. Trying to make a point without at least one of these is at best difficult and at worst empty hype. Professionals in your industry are less interested in platitudes and more interested in results. Having some evidence for your claims goes a long way toward demonstrating your expertise and proving your point. Going back to  , on defusing workplace drama, I had an abstract point to prove, and I needed to show that my insights meant something. My editor on that article was fantastic and asked the right questions to steer me toward demonstrating the validity of my ideas in a meaningful way. Personal stories made up the backbone of the article, and I was able to find social psychology studies to back up what I was saying. These illustrations of the ideas ended up being more impactful than the ideas themselves, and the article was very well-received in the community. Storytelling can be an amazing way to bring your insights to life. Real accounts or fictional, well-told stories can serve to make big ideas easier to understand, and they work best when representing typical scenarios, not edge cases. If your story goes against common knowledge, readers will pick up on that instantly and you’ll probably get some nasty comments. Never use a story to prove a point that doesn’t have any other hard evidence to back it up—use stories to illustrate points or make problems more relatable. Good stories are often the most memorable parts of articles and make your ideas and assertions easier to remember. Stats are one of the easiest ways to make a point. If you’re arguing that ignoring website accessibility can negatively impact the business, some hard numbers are going to say a lot more than stories. If there’s a good stat to prove your point, always include it, and always be on the lookout for relevant numbers. As with stories, though, you should never try to use stats to distort the truth or prove a point that doesn’t have much else to support it. Mark Twain once said, “There are three kinds of lies: lies, damned lies, and statistics.” You shouldn’t decide what to say and then scour the internet for ways to back it up. Base your ideas on the numbers, don’t base your selection of facts on your idea. Studies, including both user experience studies and social psychology experiments, are somewhere in between stories and stats, and a lot of the same advantages and pitfalls also apply. A lot of studies can be expressed as a story—write a quick bit from the point of view of the study participant, then go back and explain what’s really going on. This can be just as engaging and memorable as a good story, but studies usually result in stats, which usually serve to make the stories significantly more authoritative. And remember to link out to the study for people who want to read more about it! Just make sure your study wasn’t disproved by later studies. In my first article, linked above, I originally referenced a study to introduce the bystander effect, but an editor wisely pointed out that there’s actually a lot of evidence against that interpretation of the well-known study. Interpretations can change over time, especially as new information comes out. I found a later, more relevant study that illustrated the point better and was less well-known, so it made for a better story. Kill your darlings Early twentieth century writer and critic Arthur Quiller-Couch once said in a speech, “Whenever you feel an impulse to perpetrate a piece of exceptionally fine writing, obey it—whole-heartedly—and delete it before sending your manuscript to press.  ” Variants of this quote were repeated by many authors throughout the twentieth century, and it’s just as true today as when he originally said it. What does that mean for your article? Great prose, great analogies, great stories—any bits of brilliant writing that you churn out—only mean as much as they contribute to the subject at hand. If it doesn’t contribute anything, it needs to be killed. When getting your article ready for submission, your best friend will be the backspace or delete key on your keyboard. Before submitting, do a read-through for the express purpose of deleting whatever you can to trim down the article. Articles are not books. Brevity is a virtue, and it usually ends up being one of the most important virtues in article submissions. Your intro should have a clear thesis so readers know what the article is about. For every bit of writing that follows it, ask if it contributes to your argument. Does it illustrate the problem or solution? Does it give the reader empathy for or understanding of the people you’re trying to help? Does it give them guidance on how to have these conversations in their workplaces? If you can’t relate a sentence back to your original thesis, it doesn’t matter how brilliant it is—it should be deleted. Humor can be useful, but many jokes serve as little more than an aside or distraction from the main point. Don’t interrupt your train of thought with a cute joke—use a joke to make your thoughts more clear. It doesn’t matter how funny the joke is; if it doesn’t help illustrate or reinforce one of your points, it needs to go. There are times when a picture really is worth a thousand words. Don’t go crazy with images and illustrations in your piece, but if a quick graphic is going to save you a lengthy explanation, go that route. So what are you waiting for? The industry needs great advice in articles, and many of you could provide that. The points I’ve delved into in this article aren’t just formalities and vague ideas; the editing team at   has weighed in, and these are problems we see often that weaken articles and make them less accessible to readers. Heeding this advice will strengthen your professional articles, whether you plan to submit to   or anywhere else. The next amazing article in   could be yours, and we hope to see you get there. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/working-with-external-user-researchers-part-i/", "title": "Working with External User Researchers: Part I", "content": "You’ve got an idea or perhaps some rough sketches, or you have a fully formed product nearing launch. Or maybe you’ve launched it already. Regardless of where you are in the product lifecycle, you know you need to get input from users. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. You have a few sound options to get this input: use a full-time user researcher or contract out the work (or maybe a combination of both). Between the three of us, we’ve run a user research agency, hired external researchers, and worked as freelancers. Through our different perspectives, we hope to provide some helpful considerations.  Should you hire an external user researcher? First things first–in this article, we focus on   external user researchers, meaning that a person or team is brought on for the duration of a contract to conduct the research. Here are the most common situations where we find this type of role: : It would be great if companies validated their work with users during every iteration. But unfortunately, in real-world projects, user research happens at less frequent intervals, meaning there might not be enough work to justify hiring a full-time researcher. For this reason, it sometimes makes sense to use external people as needed. : In other cases, particularly with large companies, there may already be user researchers on the payroll. Sometimes these researchers are specific to a particular effort, and other times the researchers themselves function as internal consultants, helping out with research across multiple projects. Either way, there is a finite amount of research staff, and sometimes the staff gets overbooked. These companies may then pull in additional contract-based researchers to independently run particular projects or to provide support to full-time researchers. : Even if a company does have user research on staff and those researchers have time, it’s possible that there are specialized kinds of user research for which an external contract-based researcher is brought on. For example, they may want to do research with representative users who regularly use screen readers, so they bring in an accessibility expert who also has user research skills. Or they might need a researcher with special quantitative skills for a certain project. Why hire an external researcher vs. other options? : You could hire a full-time designer who also has research skills. But a designer usually won’t have the same level of research expertise as a dedicated researcher. Additionally, they may end up researching their own designs, making it extremely difficult to moderate test sessions without any form of bias. : While it’s common for enthusiastic product managers to want to conduct their own guerilla user research, this is often a bad idea. Product managers tend to hear feedback that validates their ideas and most often aren’t trained on how to ask non-leading questions. : You could also bring on a researcher in a staff augmentation role, meaning someone who works for you full-time for an extended period of time, but who is not considered a full-time employee. This can be a bit harder to justify. For example, there may be legal requirements that you’d have to pass if you directly contract an individual. Or you could find someone through a staffing agency–fewer legal hurdles, but likely far pricier. If these options don’t sound like a good fit for your needs, hiring an external user researcher on a project-specific basis could be the best solution for you. They give you exactly what you need without additional commitment or other risks. They may be a freelancer (or a slightly larger microbusiness), or even a team farmed out for a particular project by a consulting firm or agency. What kinds of projects would you contract a user researcher for? You can reasonably expect that anyone or any company that advertises their skillset as user research likely can do the full scope of   efforts—from usability studies of all kinds, to card sorts, to ethnographic and exploratory work.  Contracting out quantitative work is a bit riskier. An analogy that comes to mind is using TurboTax to file your taxes. While TurboTax may be just fine for many situations, it’s easy to overlook what you don’t know in terms of more complicated tax regulations, which can quickly get you in trouble. Similarly, with quantitative work, there’s a long list of diverse, specialized quantitative skills (e.g., logs analysis, conjoint, Kano, and multiple regression). Don’t assume someone advertising as a general quantitative user researcher has the exact skills you need. Also, for some companies, quantitative work comes with unique user privacy considerations that can require special internal permissions from legal and privacy teams.  But if the topic of your project is pretty easy to grasp and absorb without needing much specialized technical or organizational insight, hiring an external researcher is generally a great option. What are the benefits to hiring an external researcher? A new, objective perspective is one major benefit to hiring an external researcher. We all suffer from design fixation and are influenced by organizational politics and perceived or real technical constraints. Hiring an unbiased external researcher can uncover more unexpected issues and opportunities. Contracting a researcher can also expand an internal researcher’s ability to influence. Having someone else moderate research studies frees up in-house researchers to be part of the conversations among stakeholders that happen while user interviews are being observed. If they are intuitively aware of an issue or opportunity, they can emphasize their perspective during those critical, decision-making moments that they often miss out on when they moderate studies themselves. In these situations, the in-house team can even design the study plan, draft the discussion guide, and just have the contractor moderate the study. The external researcher may then collaborate with the in-house researcher on the final report.  More candid and honest feedback can come out of hiring an external researcher. Research participants tend to be more comfortable sharing more critical feedback with someone who doesn’t work for the company whose product is being tested. Lastly, if you need access to specialized research equipment or software (for example, proprietary online research tools), it can be easier to get it via an external researcher. How do I hire an external user researcher? So you’ve decided that you need to bring on an external user researcher to your team. How do you get started? Where to find them : Don’t wait until you need help to start networking and collecting a list of external researchers. Be proactive. Go to UX events in your local region. You’ll meet consultants and freelancers at those events, as well as people who have contracted out research and can make recommendations. You won’t necessarily have the opportunity for deep conversations, but you can continue a discussion over coffee or drinks! : Along those same lines, when you anticipate a need at some point in the future, seek out trusted UX colleagues at your company and elsewhere. Ask them to connect you with people that they may have worked with. What about a request for proposal (RFP)? Your company may require you to specify your need in the form of an RFP, which is a document that outlines your project needs and specifications, and asks for bids in response.  An RFP provides these benefits: It keeps the playing field level, and anyone who wants to bid on a project can (in theory). You can be very specific about what you’re looking for, and get bids that can be easy to compare on price. On the other hand, an RFP comes with limitations: You may think your requirements were very specific, but respondents may interpret them in different ways. This can result in large quote differences. You may be eliminating smaller players—those freelancers and microbusinesses who may be able to give you the highest level of seniority for the dollar but don’t have the staff to respond to RFPs quickly. You may be forced to be very concrete about your needs when you are not yet sure what you’ll actually need. When it comes to RFPs, the most important thing to remember is to clearly and thoroughly specify your needs. Don’t forget to include small but important details that can matter in terms of pricing, such as answers to these questions: Who is responsible for recruitment of research participants? How many participants do you want included? Who will be responsible for distributing participant incentives? Who will be responsible for localizing prototypes? How long will sessions be? Over how many days and locations will they be? What is the format of expected deliverables? Do you want full, transcribed videos, or video clips? It’s these details that will ultimately result in receiving informed proposals that are easy to compare. Do a little digging on their backgrounds Regardless of how you find a potential researcher, make sure you check out their credentials if you haven’t worked with them before. At the corporate level, review the company: Google them and make sure that user research seems to be one of their core competencies. The same is true when dealing with a freelancer or microbusiness: Google them and see whether you get research-oriented results, and also check them out on social media. Certainly feel free to ask for references if you don’t already have a direct connection, but take them with a grain of salt. Between the self-selecting nature of a reference, and a potential reference just trying to be nice to a friend, these can never be fully trusted. One of the strongest indicators of experience and quality work is if a researcher has been hired by the same client for more than one project over time. Larger agencies, individual researchers, or something in-between? So you’ve got a solid sense of what research you need, and you’ve got several quality options to choose from. But external researchers come in all shapes and sizes, from single freelancers to very large agencies. How do you choose what’s best for your project while still evaluating the external researchers fairly?  do have some distinct advantages—namely that you’ve got a large company to back up the project. Even if one researcher isn’t available as expected (for example, if the project timeline slips), another can take their place. They also likely have a whole infrastructure for dealing with contracts like yours. On the other hand, this larger infrastructure may add extra burden on your side. You may not know who exactly is going to be working on your project, or their level of seniority or experience. Changes in scope will likely be more involved. Larger infrastructure also likely means higher costs.  also have some key advantages. You will likely have more control over contracting requirements. They are also likely to be more flexible—and less costly. In addition, if they were referred to you, you will be working with a specific resource that you can get to know over multiple projects. Bringing on individual researchers can incur a little more risk. You will need to make sure that you can properly justify hiring an external researcher instead of an employee. (In the United States, the IRS has a variety of tests to make sure it is OK.) And if your project timeline slips, you run a greater risk of losing the researcher to some other commitment without someone to replace them. , a step between an individual researcher and a large firm, has some advantages over hiring an individual. Contracting an established business may involve less red tape, and you will still have the personal touch of knowing exactly who is conducting your research. An established business also shows a certain level of commitment, even if it’s one person. For example, a microbusiness could represent a single freelancer, but it could also involve a very small number of employees or established relationships with trusted subcontractors (or both). Whatever the configuration,  don’t expect a business of this size to have the ability to readily respond to RFPs. The money question Whether you solicit RFPs or get a single bid, price quotes will often differ significantly. User research is not a product but rather a customized and sophisticated effort around your needs. Here are some important things to consider:  Different researchers are going to interpret your needs in different ways. A good price quote clearly details any assumptions that are going into pricing so you can quickly see if something is misaligned.  A quote is going to be a reflection of the overall seniority of the team, their salaries and benefits, the cost of any business resources they use, and a reasonable profit margin for the business.  Some organizations may balance having a high volume of work with less profit per project. Other organizations may take more of a boutique approach: more selectivity over projects taken on, with added flexibility to focus on those projects, but also with a higher profit margin.  Some consultants and agencies are in the practice of rarely saying no to a request, even if they are at capacity in terms of their workload. In these instances, it can be a common practice to multiply a quote by as much as three—if you say no, no harm done given they’re at capacity. However, if you say yes, the substantial profit is worth the cost for them to hire additional resources and to work temporarily above capacity in the meantime. To determine whether a researcher or research team is right for you, you’ll certainly need to look at the big picture, including pricing, associated assumptions, and the seniority and background of the individuals who are doing the work. Remember, it’s always OK to negotiate If you have a researcher or research team that you want to work with but their pricing isn’t in line with your budget, let them know. It could be that the quote is just based on faulty assumptions. They may expect you to negotiate and are willing to come down in price; they may also offer alternative, cheaper options with them. Next steps Hiring an external user researcher typically brings a long list of benefits. But like most relationships, you’ll need to invest time and effort to foster a healthy working dynamic between you, your external user researcher, and your team. Stay tuned for the next installment, where we’ll focus on how to collaborate together. Like this: \n\t\t\t\t\t\t\tRecently by Chelsey Glasson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/mental-illness-in-the-web-industry/", "title": "Mental Illness in the Web Industry", "content": "The picture of the tortured artist has endured for centuries: creative geniuses who struggle with their metaphorical demons and don’t relate to life the same way as most people. Today, we know some of this can be attributed to mental illness: depression, anxiety, bipolar disorder, and many others. We have   and plenty of anecdotal information that fuels the popular belief in a link between creativity and mental illness. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But science has also started asking questions about the link between mental illness and creativity. A recent study has suggested that  . In the web industry, whether designer, dev, copywriter, or anything else, we’re often creative professionals. The numbers suggest that mental illness hits the web industry especially hard. Our industry has made great strides in compassionate discussion of disability, with a focus on accessibility and events like  . But even though   and  , issues related to diversity, inclusion, and   are still a major problem for our industry. Understanding and acceptance of mental health issues is an area that needs growth and attention just like many others. When it comes to mental health, we aren’t quite as understanding as we think we are. According to  , 57% of the general population believes that society at large is caring and sympathetic toward people with mental illness; but only 25% of people with mental health symptoms believed the same thing. Society is less understanding and sympathetic regarding mental illness than it thinks it is. Where’s the disconnect?  What does it look like in our industry? It’s usually not negligence or ill will on anybody’s part. It has a lot more to do with people just not understanding the prevalence and reality of mental illness in the workplace. We need to begin discussing mental illness as we do any other personal challenge that people face. This article is no substitute for a well-designed scientific study or a doctor’s advice, and it’s not trying to declare truths about mental illness in the industry. And it certainly does not intend to lump together or equalize any and all mental health issues, illnesses, or conditions. But it does suspect that plenty of people in the industry struggle with their mental health at some point or another, and we just don’t seem to talk about it. This doesn’t seem to make sense in light of the sense of community that web professionals have been proud of for decades.  We reached out to a few people in our industry who were willing to share their unique stories to bring light to what mental health looks like for them in the workplace. Whether you have your own struggles with mental health issues or just want to understand those who do, these stories are a great place to start the conversation. Meet the contributors : I’ve been designing websites since the late ’90s, starting out in UI design, evolving into an IA, and now in a UX leadership role. Over my career, I’ve contributed to many high-profile projects, organized local UX events, and done so in spite of my personal roadblocks. : I’ve been working in the web industry since 2006, first as a designer, then as a developer, then as a manager/technical leader. I’m also a staff member and regular contributor at  . I was diagnosed with bipolar disorder in 2002 and almost failed out of college because of it, although I now live a mostly normal life with a solid career and great family. I’ve been very open about my condition and have done some writing on it on   to help spread awareness and destigmatize mental illnesses. : I’ve been building and running websites since 1999, both professionally and for fun. Worked for newspapers, software companies, and design agencies, in both permanent and freelance roles, almost always creating front-end solutions, concentrating on a user-centered approach. : I’ve been messing around with the web since MySpace was a thing, figuring out how to customize themes and make random animations fall down from the top of my profile. Professionally, I’ve been in the field since 2010, freelancing while in college before transitioning to work at small agencies and in-house for a spell after graduation. I focus on creating solid digital experiences, employing my love for design with [a] knack for front-end development. Most recently, I started a small design studio, but decided to jump back into more steady contract and full-time work, after the stress of owning a small business took a toll on my mental health. It was a tough decision, but I had to do what was best for me. I also lead my local AIGA chapter and recently got my 200-hour-yoga-teacher certification. : I also started tinkering with the web on Myspace, and started working on websites to help pay my way through college. I just always assumed I would do something else to make a living. Then, I was diagnosed with bipolar disorder. My [original non-web] field was not a welcoming and supportive place for that, so I had to start over, in more ways than one. The web industry hadn’t gone anywhere, and it’s always been welcoming to people with random educational histories, so I felt good about being able to make a living and staying healthy here. But because of my experience when I first tried to be open about my illness, I now keep it a secret. I’m not ashamed of it; in fact, it’s made me live life more authentically. For example, in my heart, I knew I wanted to work on the web the entire time. The struggle is real Mental health issues are as numerous and unique as the people who struggle with them. We asked the contributors what their struggles look like, particularly at work in the web industry.  : I have an interesting mix of ADD, dyslexia, and complex PTSD. As a result, I’m an incomplete person, in a perpetual state of self-doubt, toxic shame, and paralyzing anxiety. I’ve had a few episodes in my past where a requirement didn’t register or a criticism was taken the wrong way and I’ve acted less than appropriately (either through panic, avoidance, or anger). When things go wrong, I deal with emotional flashbacks for weeks. Presenting or reading before an audience is a surreal experience as well. I go into a zone where I’m never sure if I’m speaking coherently or making any sense at all until I’ve spoken with friends in the audience afterward. This has had a negative effect on my career, making even the most simple tasks anxiety-driven. : I actually manage to at least look like I have everything together, so most people don’t know I have bipolar until I tell them. On the inside, I struggle—a lot. There are bouts of depression where I’m exhausted all day and deal with physical pain, and bursts of mania where I take unnecessary risks and make inappropriate outbursts, and I can switch between these states with little or no notice. It’s a balancing act to be sure, and I work very hard to keep it together for the people in my life. : After the sudden death of my mother, I started suffering from panic attacks. One of which came on about 30 mins after getting to work, I couldn’t deal with the attack at work, so suddenly went home without telling anyone. Only phoning my boss from a lay-by after I’d been in tears at the side of the road for a while. The attacks also triggered depression, which has made motivation when I’m working from home so hard that I actually want to spend more time at the office. Luckily my employer is very understanding and has been really flexible. : Depending upon the time of year, I struggle greatly, with the worst making it nearly impossible to leave my apartment. As most folks often say, I’ve gotten rather good at appearing as though I’ve got my shit together—typically, most people I interact with have no idea what I’m going through unless I let them in. It wasn’t until recently that my mental health began to make a public appearance, as the stress of starting my own business and attempting to “have it all” made it tough to continue hiding it. There are definitely spans of time where depression severely affects my ability to create and interface with others, and “fake it till ya make it” doesn’t even cut it. I’m currently struggling with severe anxiety brought on by stress. Learning to manage that has been a process. : I have been fortunate to be a high-functioning bipolar person for about 5 years now, so there really isn’t a struggle you can really see. The struggle is the stress and anxiety of losing that stability, and especially of people finding out. I take medication, have a routine, a support system, and a self-care regimen that is the reason why I am stable, but if work starts [to] erode my work-life balance, I can’t protect that time and energy anymore. In the past, this has started to happen when I’ve been asked to routinely pull all-nighters, work over the weekend, travel often, or be surrounded by a partying and drinking culture at work. Many people burn out under those conditions, but for me, it could be dangerous and send me into a manic episode, or even [make me] feel suicidal. I struggle with not knowing how far I can grow in my career, because a lot of the things you do to prove yourself and to demonstrate that you’re ready for more responsibility involves putting more on your plate. What’s the point of going after a big role if it’ll mean that I won’t be able to take care of myself? The FOMO [(fear of missing out)] gets bad. Making it work There are different ways that people can choose to—or choose not to—address the mental problems they struggle with. We’re ultimately responsible for making our own mental health decisions, and they are different for everyone. In the meantime, the rent has to get paid. Here’s how our contributors cope with their situations at work to make it happen. : I started seeing a therapist, which has been an amazing help. I’ve also worked to change my attitude about criticism—I ask more clarifying questions, looking to define the problem, rather than get mad, defensive, or sarcastic. I’ve learned to be more honest with my very close coworkers, making them aware of my irrational shortcomings and asking for help. Also, because I’ve experienced trauma in personal and professional life, I’m hypersensitive to the emotions of others. Just being around a heated argument or otherwise heightened situation could put my body into a panic. I have to take extra special care in managing personalities, making sure everyone in a particular situation feels confident that they’re set up for success. : Medicine has worked very well for me, and I’m very lucky in that regard. That keeps most of my symptoms at a manageable level. Keeping my regular schedule and maintaining some degree of normalcy is a huge factor in remaining stable. Going to work, sleeping when I should, and keeping some social appointments, while not always easy, keep me from slipping too far in either direction. Also, writing has been a huge outlet for me and has helped others to better understand my condition as well. Finding some way to express what you’re going through is huge. : I had several sessions of bereavement counseling to help with the grief. I also made efforts to try and be more physically active each day, even if just going for a short walk on my lunch break. Working had become a way of escaping everything else that was going on at the time. Before the depression I used to work from home two days a week, however found these days very hard being on my own. So I started working from the office every weekday. Thankfully, through all of this, my employer was incredibly supportive and simply told me to do what I need to do. And it’s made me want to stay where I work more than before, as I realize how lucky I am to have their support. : Last winter I enrolled in a leadership/yoga teacher training [program] with a goal of cultivating a personal practice to better manage my depression and anxiety. Making the jump to be in an uncomfortable situation and learn the value of mindfulness has made a huge difference in my ability to cope with stress. Self-care is really big for me, and being aware of when I need to take a break. I’ve heard it called  . I often take on too much and learning to say no has been huge. Therapy and a daily routine have been incredibly beneficial as well. : The biggest one is medicine, it’s something I will take for the rest of my life and it’s worth it to me. I did a form of therapy called Dialectical Behavioral Therapy for a couple of years. The rest is a consistent regimen of self-care, but there are a couple of things that are big for work. Not working nights or weekends, keeping it pretty 9–5. Walking to and from the office or riding my bike. I started a yoga practice immediately after getting diagnosed, and the mental discipline it’s given me dampens the intensity of how I react to stressful situations at work. This isn’t to say that I will refuse to work unless it’s easy. Essentially, if something catches on fire, these coping strategies help me keep my shit together for long enough to get out.  Spreading awareness There are a lot of misconceptions about mental illness, in the web industry as much as anywhere else. Some are benign but annoying; others are pretty harmful. Here are some of the things we wish others knew about us and our struggles. : Nothing about my struggle is rational. It seems as if my body is wired to screw everything up and wallow in the shame of it. I have to keep moving, working against myself to get projects as close to perfect as possible. However, I   wired to really care about people, and that is probably why I’ve been successful in UX. : Just because I look strong doesn’t mean I don’t need support. Just because I have problems doesn’t mean I need you to solve them. Sometimes, just checking in or being there is the best thing for me. I don’t want to be thought of as broken or fragile (although I admit, sometimes I am). I am more than my disorder, but I can’t completely ignore it either. Also, there are still a lot of stigmas surrounding mental illness, to the point that I didn’t feel safe admitting to my disorder to a boss at a previous job. Mental illnesses are medical conditions that are often classified as legitimate disabilities, but employees may not be safe admitting that they have one—that’s the reality we live with. : For others who are going through grief-related depression, I would say that talking about it with friends, family, and even strangers helps you process it a lot. And the old cliché that time is a healer really is true. Also, for any employers, be supportive [of those] with mental health conditions—as supportive as you would [be of those] with physical health situations. They will pay you back. : I am a chronically ambitious human. Oftentimes, this comes from a place of working and doing versus dealing with what is bothering or plaguing me at the time. Much of my community involvement came from a place of needing a productive outlet. Fortunately or unfortunately, I have accomplished a lot through that—however, there are times where I simply need a break. I’m learning to absorb and understand that, as well as become OK with it. : I wish people knew how much it bothers me to hear the word bipolar being used as an adjective to casually describe things and people. It’s not given as a compliment, and it makes it less likely that I will ever disclose my illness publicly. I also wish people knew how many times I’ve come close to just being open about it, but held back because of the other major diversity and inclusion issues in the tech industry. Women have to deal with being called moody and erratic. People stereotype the ethnic group I belong to as being fiery and ill-tempered. Why would I give people another way to discriminate against me? Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-king-vs-pawn-game-of-ui-design/", "title": "The King vs. Pawn Game of UI Design", "content": "If you want to improve your UI design skills, have you tried looking at chess? I know it sounds contrived, but hear me out. I’m going to take a concept from chess and use it to build a toolkit of UI design strategies. By the end, we’ll have covered color, typography, lighting and shadows, and more. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But it all starts with rooks and pawns. I want you to think back to the first time you ever played chess (if you’ve never played chess, humor me for a second—and no biggie; you will still understand this article). If your experience was anything like mine, your friend set up the board like this: And you got your explanation of all the pieces.  This is probably the most common way of explaining chess, and it’s enough to make me hate board games forever. I don’t want to sit through an arbitrary lecture. I want to  . One particular chess player happens to agree with me. His name is Josh Waitzkin, and he’s actually pretty good. Not only at chess (where he’s a grandmaster), but also at Tai Chi Push Hands (he’s a world champion) and Brazilian Jiu Jitsu (he’s the first black belt under 5x world champion Marcelo Garcia). Now he trains financiers to go from the top 1% to the top .01% in their profession. Point is:  Now here’s the crazy part. When Josh teaches you chess, the board looks like  : Whoa. Compared to what we saw above, this is  . And, if you know how to play chess, it’s even more mind-blowing that someone would start teaching with this board. In the actual game of chess, you   see a board like this. Someone would have won   ago. This is the chess equivalent of a street fight where both guys break every bone in their body, dislocate both their arms, can hardly see out of their swollen eyes, yet continue to fight for another half-hour. What gives? Here’s Josh’s thinking:  . That sounds pretty lofty, but I think it makes sense when you consider it. There are lots of things to distract a beginning chess player by a fully-loaded board, but   in a king-pawn situation is fundamentally important to chess: using two pieces to apply pressure together; which spaces are “hot”; and the difference between driving for a   and a  . Are you wondering if I’m ever going to start talking about design? Glad you asked. The simplest possible scenario What if, instead of trying to design an   (nav, text, input controls, a logo, etc.), we consciously started by designing the  ? We deliberately limit the playing field to   and see what we learn? Let’s try. What is the simplest possible element? I vote that it’s a button. This is the most basic, default button I could muster. It’s Helvetica (default font) with a 16px font size (pretty default) on a plain, Sketch-default-blue rectangle. It’s 40px tall (nice, round number) and has 20px of horizontal padding on each side. So yeah, I’ve already made a bunch of design decisions, but can we agree I basically just used default values instead of making decisions for principled, design-related reasons? Now let’s start playing with this button. What properties are modifiable here? the font (and text styling) the color the border radius the border the shadows These are just the first things that come to my mind. There are even more, of course. Typography Playing with the font is a pretty easy place to start. Now I’ve changed the font to Moon ( ). It’s rounded and soft, unlike Helvetica, which felt a little more squared-off—or at least not as overtly friendly. The funny thing is: do you see how the perfectly square edges now look a tad awkward with the rounded font? Let’s round the corners a bit. Bam. Nice. That’s a 3px border radius. But that’s kind of weird, isn’t it? We adjusted the border radius of a button because of the   in our font. I wouldn’t want you thinking fonts are just loosey-goosey works of art that only work when you say the right incantations. No,  . Shapes have connotations. It’s not rocket science. Here’s another popular font, DIN. Specifically, this is a version called DIN 2014 ( ). It’s the epitome of a squared-off-but-still-readable font. A bit harsh and no-nonsense, but in a bureaucratic way. It’s the official font of the German government, and it looks the part. So let’s test our working hypothesis with DIN. How does DIN look with those rounded corners? Well, we need to compare it to square corners now, don’t we? Ahhh, the squared-off corners are better here. It’s a much more consistent feel. Now look at our two buttons with their separate fonts. Which is more readable? I think Moon has a slight advantage here. DIN’s letters just look too cramped by comparison. Let’s add a bit of letter-spacing. When we add some letter-spacing, it’s far more relaxed. This is a key law of typography:  . Why? Because unless a font   have lowercase characters, it was designed for sentence-case reading, and characters in uppercase words will ALWAYS appear too cramped. (Moon is the special exception here—it only has uppercase characters, and notice how the letter-spacing is   the font.) We’ll review later, but so far we’ve noticed two things that apply not just to buttons, but to all elements: Rounded fonts go better with rounded shapes; squared-off fonts with squared-off shapes. Fonts designed for sentence case should be letter-spaced when used in words that are all uppercase. Let’s keep moving for now. Color Seeing the plain default Sketch blue is annoying me. It’s   to be changed into something that matches the typefaces we’re using. How can a   match a  ? Well, I’ll hand it to you. This one   a bit more loosey-goosey. For our Moon button, we want something a bit more friendly. To me, a staid blue says  . How do you inject some fun into it? Well, like all problems of  , it helps to think in the   (hue, saturation, and brightness). When we boil color down to three intuitive numbers, we give ourselves levers to pull. For instance, let’s look at hue. We have two directions we can push hue: down to aqua or up to indigo. Which sounds more in line with Moon? To me, aqua does. A bit less staid, a bit more Caribbean sea. Let’s try it. We’ll move the hue to 180° or so. Ah, Moon Button, now you’ve got a beach vibe going on. You’re a vibrant sea foam! This is a critical lesson about color. “Blue” is not a monolith; it’s a starting point. I’ve  , and this comes up again and again: just because blue was one color in kindergarten doesn’t mean that we can’t find interesting variations around it as designers. Aqua is a great variation with a much cooler feel, but it’s also much harder to read that white text. So now we have another problem to fix. “Hard to read” is actually a numerically-specific property. The World Wide Web Consortium has published  , and if we use a tool to test those, we find we’re lacking in a couple departments. According to   (which is my preferred Sketch plugin for checking contrast—check out Lea Verou’s   for a similar web-based tool), we’ve failed our contrast guidelines across the board! How do you make the white text more legible against the aqua button? Let’s think of our HSB properties again.  Let’s decrease it. That much should be obvious.  We’re going to increase it. Why? Because we’re contrasting with white text, and white has a saturation of zero. So a higher saturation will naturally stand out more.  We’ll leave this alone since we like its vibe. But if the contrast continued to be too low, you could lower the aqua’s luminosity by  . So now, we’ve got a teal button: Much better? Much better. For what it’s worth, I’m not particularly concerned about missing the AAA standard here.   as relative descriptors of how much contrast there is, not as an absolute benchmark of, say, some particular percentage of people to being able to read the text. The gold standard is—as always—to test with real people. AAA is best to hit, but at times, AA may be as good as you’re going to get with the colors you have to work with. Some of the ideas we’ve used to make a button’s blue a bit more fun   legible against white are actually deeper lessons about color that apply to almost everything else you design: Think in HSB, as it gives you intuitive levers to pull when modifying color. If you like the general feel of a color, shifting the hue in either direction can be a baseline for getting interesting variations on it (e.g., we wanted to spice up the default blue, but not by, say, changing it to red). Modify saturation and brightness at the same time (but always in opposite directions) to increase or decrease contrast. OK, now let’s switch over to our DIN button. What color goes with its harsh edges and squared-off feel? The first thing that comes to mind is black. But let’s keep brainstorming. Maybe a stark red would also work. Or even a construction-grade orange. (But not the red and orange together. Yikes! In general, two adjacent hues with high saturations will not look great next to each other.) Now, ignoring that the text of this is “Learn More” and a button like this probably doesn’t need to be   orange, I want you to pay attention to the colors I’m picking. We’re trying to maintain consistency with the official-y, squared-off DIN. So the colors we go to naturally have some of the same connotations:  . Sure, this match-a-color-and-a-font business is   subjective, but there’s something solid to it: note that the words I used to describe the colors (“stark” and “construction-grade”) apply equally well to DIN—a fact I am only noticing now, not something done intentionally. Want to match a color with a font? This is another lesson applicable to all of branding. It’s best to  , then match everything to those. Practically by accident, we’ve uncovered something fundamental in the branding design process. Shadows Let’s shift gears to work with   for a bit. There are a couple directions we could go with shadows, but the two main categories are (for lack of better terms): realistic shadows; and cartoon-y shadows. Here’s an example of each: The top button’s shadow is more  . It behaves like a shadow in the real world. The bottom button’s shadow is a bit lower-fidelity. It shows that the button is raised up, but it’s a cartoon version, with a slightly unrealistic, idealized bottom edge—and without a normal shadow, which would be present in the real world. The bottom works better for the button we’re crafting. The smoothness, the friendliness, the cartoon fidelity—it all goes together. As for our DIN button? I’m more ambivalent here. Maybe the shadow is for a hover state, à la  ? In any case, with a black background, a darkened bottom edge is impossible—you can’t get any darker than black. By the way, you may not have noticed it above, but the black button has a much stronger shadow. Compare: The teal button’s shadow is 30%-opacity black, shifted 1 pixel down on the y-axis, with a 2-pixel blur (0 1px 2px). The black button’s is 50%-opacity black, shifted 2 pixels down on the y-axis, with a 4-pixel blur (0 2px 4px). What’s more, the stronger shadow looks   on the teal button. Why is that? The answer, like so many questions that involve color, is in  . When we put the button’s background in luminosity blend mode, converting it to a gray of equal natural lightness, we see something interesting. The shadow, at its darkest, is basically as dark as the button itself. Or, at least, the rate of change of luminosity is steady between each row of pixels. The top row is the button itself, not shadow. Shadows that are too close to the luminosity of their element’s backgrounds will appear too strong. And while this may sound like an overly specific lesson, it’s actually broadly applicable across elements. You know where else you see it? Borders Let’s put a border on our teal button. Now the way I’ve added this border is something that a bunch of people have thought of: make the border translucent black so that it works  . In this case, I’ve used a single-pixel-wide border of 20%-opacity black. However, if I switch the background color to a more standard blue, which is naturally a lot less luminous, that border all but disappears. In fact, to see it on blue just as much as you can see it on teal, you’ve got to crank up black’s opacity to something like 50%. This is a generalizable rule: when you want to  , it needs to be a more opaque black to show up the same amount on less luminous background colors. Where else would you apply this idea? Spoiler alert:  ! Each of these buttons has the same shadow (0 2px 3px) except for different opacities. The top two buttons’ shadows have opacity 20%, and the bottom two have opacity 40%. Note how what’s fine on a white background (top left) is hardly noticeable on a dark background (top right). And what’s too dark on a white background (lower left) works fine on a dark background (lower right). Icons I want to change gears one more time and talk about icons. Here’s the download icon from Font Awesome, my least favorite icon set of all time. I dislike it, not only because it’s completely overused, but also because the icons are really  . Yet most of the time, they’re used in  . They just don’t fit. You can see it works better with a soft, rounded font. I’m less opposed to   sort of thing. But there’s still a problem:  ! The dots are never going to show up at size, and even the space between the arrow and the disk is a fraction of a pixel in practice. Compared to the letterforms, it doesn’t look like quite the same style. But what good is my complaining if I don’t offer a solution? Let’s create a new take on the “download” icon, but with some different guiding principles: We’ll use a   that’s equivalent (or basically equivalent) to the  . We’ll use corner radii that are similar to the corner radii of our font: squared off for DIN, rounded for Moon. We’ll use a simpler icon shape so the differences are easy to see. Let’s see how it looks: I call this “drawing with the same pen.” Each of these icons looks like it could basically be a character in the font used in the button. And   the point here. I’m not saying all icons will appear this way, but for an icon that appears inline with text like this, it’s a fantastic rule of thumb. Wrapping it up Now this is just the beginning. Buttons can take   of styles. But we’ve got a good start here considering we  . In doing so, we covered a bunch of the things that are focal points of my day-to-day work as a UI designer: lighting and shadows; color; typography; consistency; and brand. And the lessons we’ve learned in those areas are fundamental to the   of UI design, not just one element. Recall: Letterforms are shapes. You can analyze fonts as sets of shapes, not simply as works of art. You should letter-space uppercase text, since most fonts were designed for sentence case. Think in HSB to modify colors. You can find more interesting variations on a “basic” color (like a CSS default shade of blue or red) by tweaking the hue in either direction. Saturation and brightness are levers that you can move in opposite directions to control luminosity. Find colors that match the same descriptors that you would give your typeface and your overall brand. Use darker shadows or black borders on darker backgrounds—and vice versa. For inline icons, choose or design them to appear as though they were drawn with the same pen as the font you’re using. You can thank Josh Waitzkin for making me a pedant. I know, you just read an entire essay on  . But next time you’re struggling with a redesign or even something you’re designing from scratch, try stripping out all the elements that you   you should be including already, and just mess around with the simplest players on the board. Get a feel for the fundamentals, and go from there. Weird? Sure. But if it’s good enough for a grandmaster, I’ll take it. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/css-the-definitive-guide-4th-edition/", "title": "CSS: The Definitive Guide, 4th Edition", "content": "In addition to filtering, CSS offers the ability to determine how elements are   together. Take, for example, two elements that partially overlap due to positioning. We’re used to the one in front obscuring the one behind. This is sometimes called  , in that you can see whatever is behind the element as long as some (or all) of it has alpha channel values less than  . Think of, for example, how you can see the background through an element with  , or in the areas of a PNG or GIF87a that are set to be transparent. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But if you’re familiar with image-editing programs like Photoshop or GIMP, you know that image layers which overlap can be blended together in a variety of ways. CSS has gained the same ability. There are two blending strategies in CSS (at least as of late 2017): blending entire elements with whatever is behind them, and blending together the background layers of a single element. Blending Elements In situations where elements overlap, it’s possible to change how they blend together with the property  . mix-blend-mode : normal | multiply | screen | overlay | darken | lighten | colordodge | color-burn | hard-light | soft-light | difference | exclusion | hue | saturation | color | luminosity \n : normal \n : All elements \n : As declared \n : No \n : No The way the CSS specification puts this is: “defines the formula that must be used to mix the colors with the backdrop.” That is to say, the element is blended with whatever is behind it (the “backdrop”), whether that’s pieces of another element, or just the background of its parent element. The default,  , means that the element’s pixels are shown as is, without any mixing with the backdrop, except where the alpha channel is less than  . This is the “simple alpha compositing” mentioned previously. It’s what we’re all used to, which is why it’s the default value. A few examples are shown in Figure 19-6. For the rest of the mix-blend-mode keywords, I’ve grouped them into a few categories. Let’s also nail down a few definitions: The   is the element that has   applied to it. The   is whatever is behind that element. This can be other elements, the background of the parent element, and so on. A   is the color component of a given pixel: R, G, and B If it helps, think of the foreground and backdrop as images that are layered atop one another in an image-editing program. With  , you can change the blend mode applied to the top image (the foreground). Darken, Lighten, Difference, and Exclusion These blend modes might be called simple-math modes—they achieve their effect by directly comparing values in some way, or using simple addition and subtraction to modify pixels: : Each pixel in the foreground is compared with the corresponding pixel in the backdrop, and for each of the R, G, and B values (the pixel components), the smaller of the two is kept. Thus, if the foreground pixel has a value corresponding to   and the backdrop pixel is  , the resulting pixel will be  . : This blend is the inverse of darken: when comparing the R, G, and B components of a foreground pixel and its corresponding backdrop pixel, the larger of the two values is kept. Thus, if the foreground pixel has a value corresponding to   and the backdrop pixel is  , the resulting pixel will be  . : The R, G, and B components of each pixel in the foreground are compared to the corresponding pixel in the backdrop, and the absolute value of subtracting one from the other is the final result. Thus, if the foreground pixel has a value corresponding to   and the backdrop pixel is  , the resulting pixel will be  . If one of the pixels is white, the resulting pixel will be the inverse of the non-white pixel. If one of the pixels is black, the result will be exactly the same as the non-black pixel. : This blend is a milder version of  . Rather than being |   |, the formula is  , where   and   are values in the range from 0-1. For example, an exclusion calculation of an orange ( ) and medium gray ( ) will yield  . For the red component, the math is  , which reduces to  , corresponding to 50%. For the blue and green components, the math is  , which again reduces to  . Compare this to  , where the result would be  , since each component is the absolute value of subtracting one from the other. This last definition highlights the fact that for all blend modes, the actual values being operated on are in the range 0-1. The previous examples showing values like   are normalized from the 0-1 range. In other words, given the example of applying the   blend mode to   and  , the actual operation is as follows:  is  . Similarly,   corresponds to  . Each component is subtracted from the corresponding component, and the absolute value taken. Thus,  . This could be expressed as  , or (by multiplying each component by 255) as  . From all this, you can perhaps understand why the full formulas are not written out for every blend mode we cover. If you’re interested in the fine details, each blend mode’s formula is provided in the “Compositing and Blending Level 1” specification. Examples of the blend modes in this section are depicted in Figure 19-7. Multiply, Screen, and Overlay These blend modes might be called the multiplication modes—they achieve their effect by multiplying values together: : Each pixel component in the foreground is multiplied by the corresponding pixel component in the backdrop. This yields a darker version of the foreground, modified by what is underneath. This blend mode is  , in that the result will be exactly the same even if you were to swap the foreground with the back‐drop. : Each pixel component in the foreground is inverted (see   in the earlier section “Color Filtering” on page 948), multiplied by the inverse of the corresponding pixel component in the backdrop, and the result inverted again. This yields a lighter version of the foreground, modified by what is underneath. Like  ,   is symmetric. : This blend is a combination of   and  . For foreground pixel components darker than 0.5 (50%), the   operation is carried out; for foreground pixel components whose values are above 0.5,   is used. This makes the dark areas darker, and the light areas lighter. This blend mode is   symmetric, because swapping the foreground for the backdrop would mean a different pattern of light and dark, and thus a different pattern of multiplying versus screening. Examples of these blend modes are depicted in Figure 19-8. Hard and Soft Light There blend modes are covered here because the first is closely related to a previous blend mode, and the other is just a muted version of the first: : This blend is the inverse of   blending. Like  , it’s a combination of   and  , but the determining layer is the backdrop. Thus, for back‐drop pixel components darker than 0.5 (50%), the   operation is carried out; for backdrop pixel components lighter than 0.5,   is used. This makes it appear somewhat as if the foreground is being projected onto the backdrop with a projector that employs a harsh light. : This blend is a softer version of  . That is to say, it uses the same operation, but is muted in its effects. The intended appearance is as if the foreground is being projected onto the backdrop with a projector that employs a diffuse light. Examples of these blend modes are depicted in Figure 19-9. Color Dodge and Burn Color dodging and burning are interesting modes, in that they’re meant to lighten or darken a picture with a minimum of change to the colors themselves. The terms come from old darkroom techniques performed on chemical film stock: : Each pixel component in the foreground is inverted, and the component of the corresponding backdrop pixel component is divided by the inverted foreground value. This yields a brightened backdrop unless the foreground value is 0, in which case the backdrop value is unchanged. : This blend is a reverse of color-dodge: each pixel component in the backdrop is inverted, the inverted backdrop value is divided by the unchanged value of the corresponding foreground pixel component, and the result is then inverted. This yields a result where the darker the backdrop pixel, the more its color will burn through the foreground pixel. Examples of these blend modes are depicted in Figure 19-10. Hue, Saturation, Luminosity, and Color The final four blend modes are different than those we’ve seen before, because they do not perform operations on the R/G/B pixel components. Instead, they perform operations to combine the hue, saturation, luminosity, and color of the foreground and backdrop in different ways: : For each pixel, combines the luminosity and saturation levels of the backdrop with the hue angle of the foreground. : For each pixel, combines the hue angle and luminosity level of the backdrop with the saturation level of the foreground. : For each pixel, combines the luminosity level of the backdrop with the hue angle and saturation level of the foreground. : For each pixel, combines the hue angle and saturation level of the backdrop with the luminosity level of the foreground. Examples of these blend modes are depicted in Figure 19-11. These blend modes can be a lot harder to grasp without busting out raw formulas, and even those can be confusing if you aren’t familiar with how things like saturation and luminosity levels are determined. If you don’t feel like you quite have a handle on how they work, the best thing is to practice with a bunch of different images and simple color patterns. Two things to note: Remember that an element always blends with its backdrop. If there are other elements behind it, it will blend with them; if there’s a patterned background on the parent element, the blending will be done against that pattern. Changing the opacity of a blended element will change the outcome, though not always in the way you might expect. For example, if an element with   is also given  , then the difference calculations will be scaled by 80%. More precisely, a scaling factor of 0.8 will be applied to the color-value calculations. This can cause some operations to trend toward flat middle gray, and others to shift the color changes. Like this: \n\t\t\t\t\t\t\tRecently by  Eric Meyer\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/design-like-a-teacher/", "title": "Design Like a Teacher", "content": "In 2014, the clinic where I served as head of communications and digital strategy switched to a new online patient portal, a change that was mandated by the electronic health record (EHR) system we used. The company that provides the EHR system held several meetings for the COO and me to learn the new tool and provided materials to give to patients to help them register for and use the new portal. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As the sole person at my clinic working on any aspect of user experience, I knew the importance of knowing the audience when implementing an initiative like the patient portal. So I was skeptical of the materials provided to the patients, which assumed a lot of knowledge on their part and focused on the cool features of the portal rather than on why patients would actually want to use it. By the time the phone rang for the fifth time on the first day of the transition, I knew my suspicion that the patient portal had gone wrong in the user experience stage was warranted. Patients were getting stuck during every phase of the process—from wondering why they should use the portal to registering for and using it. My response was to ask patients what they had tried so far and where they were getting stuck. Then I would try to explain why they might want to use the portal. Sometimes I lost patients completely; they just refused to sign up. They had a bad user experience trying to understand how a portal fit into their mental model of receiving healthcare, and I had a terrible user experience trying to learn what I needed to do to guide patients through the migration. To borrow a phrase from Dave Platt, the lead instructor of the UX Engineering course I currently help teach,   was extremely high. I realized three important things in leading this migration: When people get stuck, their frustration prevents them from providing information up front. They start off with “I’m stuck” and don’t offer additional feedback until you pull it out of them. (If you felt a tremor just then, that was every IT support desk employee in the universe nodding emphatically.) In trying to get them unstuck, I had to employ skills that drew on my work outside of UX. There was no choice; I had a mandate to reach an adoption rate of at least 60%. The overarching goal was really to help these patients learn to do something different than what they were used to, whether that was deal with a new interface or deal with an interface for the first time at all. Considering these three realizations led me to a single, urgent conclusion that has transformed my UX practice: user experience is really a way of defining and planning what we want a user to learn, so we also need to think about our own work as  . It follows, then, that user experience toolkits need to include developing a teaching mindset. But what does that mean? And what’s the benefit? Let’s use this patient portal story and the three realizations above as a framework for considering this. Helping users get unstuck Research on teaching and learning has produced two concepts that can help explain why people struggle to get unstuck and what to do about it: 1)   and 2) the  . Much like you work your muscles through weight resistance to develop physical strength, you work your brain through   to develop mental strength—to learn. There are three kinds of cognitive load:  ,  , and  . In the case of the patient portal, intrinsic cognitive load was responsible for a user actually signing up for the portal and using it for the first time. Germane cognitive load was devoted to a user making sense of this experience and storing it so that it can be repeated in the future with increasing fluency. My job in salvaging the user experience was to figure out what was extraneous in the process of using the portal so that I could help users focus on what they needed to know to use it effectively. Additionally, we all have a threshold for comfortably exploring and figuring something out with minimal guidance. This threshold moves around depending on the task and is called your  . It lays between the spaces where you can easily do a task on your own and where you cannot do a task at all without help. Effective learning happens in this zone by offering the right support, at the right time, in the right amount. When you’re confronted with an extremely frustrated person because of a user experience you have helped create (or ideally, before that scenario happens), ask yourself a couple questions: Think about your creation in terms of the immediate task and everything else. Consider (or reconsider) all the feelings, thoughts, contexts, and everything else that could make up the space around that task. What proportion of effort goes to the task versus to everything in the space around it? After that, think about how easy or difficult it is to achieve that task. Are you offering the right support, at the right time, in the right amount? What new questions might you need to ask to figure that out? Making use of “unrelated” skill sets When you were hired, you responded to a job description that included specific bullet points detailing the skills you should have and duties you would be responsible for fulfilling. You highlighted everything about your work that showed you fit that description. You prepared your portfolio, and demonstrated awareness of the recent writings from UX professionals in the field to show you can hold a conversation about how to “do” this work. You looked incredibly knowledgeable. In research on teaching and learning, we also explore the idea of   we know in addition to   we know. Some people believe that knowledge is universally true and is out there to be uncovered and explored. Others believe that knowledge is subjective because it is uncovered and explored  . This is called  . If we accept constructivism, it means that we open ourselves to learning from each other in how we conceptualize and practice UX based on   besides what job descriptions ask. How do we methodically figure out the what else? By asking better questions. Part of teaching and learning in a constructivist framework is understanding that the name of the game is facilitation, not lecturing (you might have heard the cute phrase, “Guide on the side, not sage on the stage”). Sharing knowledge is actually about asking questions to evoke reflection and then conversation to connect the dots. Making time to do this can help you recall and highlight the “unrelated” skills that you may have buried that would actually serve you well in your UX work. For example:  All of this is in service to helping ourselves unlock more productive communication with our clients. In the patient portal case, I relied very heavily on my master’s degree in international relations, which taught me about how to ask questions to methodically untangle a problem into more manageable chunks, and listen for what a speaker is   saying between the lines. When you don’t speak the same language, your emotional intelligence and empathy begin to heighten as you try to relate on a broader human level. This helped me manage patient expectations to navigate them to the outcome I needed, even though this degree was meant to prepare me to be a diplomat. As you consider how you’re feeling in your current role, preparing for a performance review, or plotting your next step, think about your whole body of experience. What are the themes in your work that you can recall dealing with in other parts of your life (at any point)? What skills are you relying on that, until you’ve now observed them, you didn’t think very much about but that have a heavy influence on your style of practice or that help make you effective when you work with your intended audiences? Unlearn first, then learn When Apple wanted to win over consumers in their bid to make computers a household item, they had to help them embrace what a machine with a screen and some keys could accomplish. In other words, to convince consumers it was worth it to learn how to use a computer, they first had to help consumers unlearn their reliance on a desk, paper, file folders, and pencils. Apple integrated this unlearning and learning into one seamless experience by creating a graphical user interface that used digital representations of objects people were already familiar with—desks, paper, file folders, and pencils. But the solution may not always be that literal. There are two concepts that can help you support your intended audiences as they transition from one system or experience to another. The first concept, called a  , relates to the belief that people are capable of constructing and developing intelligence in any given area, as opposed to a fixed mindset, which holds that each of us is born with a finite capacity for some level of skill. It’s easy to tell if someone has a fixed mindset if they say things like, “I’m too old to understand new technology,” or “This is too complicated. I’ll never get it.” The second is  , which divides motivation into two types:  . Self-determination theory states that in learning, your desire to persevere is not just about having motivation at all, but about what kind of motivation you have. Intrinsic motivation comes from within yourself; extrinsic comes from the world around you. Thanks to this research and subsequent studies, we know that intrinsic motivation is vital to meaningful learning and skill development (think about the last time you did an HR training and liked it). This appears in our professional practice as the ever-favored endeavor to generate “buy-in.” What we’re really saying is, “How do I get someone to feel motivated on their own to be part of this or do this thing, instead of me having to reward them or somehow provide an incentive?” Many resources on getting buy-in are about the end goal of getting someone to do what you want. While this is important, conducting this as a teaching process allows you to step back and make space for the other person’s active contribution to a dialogue where you also learn something, even if you don’t end up getting buy-in: \n For the majority of patients I worked with, transitioning to a new portal was almost fully an extrinsically motivated endeavor—if they didn’t switch, they didn’t get to access their health information, such as lab results, which is vital for people with chronic diseases. They did it because they had to. And many patients ran into a fixed-mindset wall as they confronted bad design: “I can’t understand this. I’m not very good at the computer. I don’t understand technology. Why do I have to get my information this way?” I especially spent a lot of time on exploring why some users felt the portal was complicated (i.e., the first bullet point above), because not only did I want them to switch to it, but I wanted them to switch  . First I had to help them unlearn some beliefs about their capabilities and what it means to access information online, and then I could help them successfully set up and use this tool. While you’re researching the experience you’re going to create around a product, service, or program, ask questions not just about the thing itself but about the circumstances or context. What are the habits or actions someone might need to stop doing, or unlearn, before they adopt what you’re creating? What are the possible motivators in learning to do the something different? Among those, what is the ratio of extrinsic to intrinsic? Do you inadvertently cause an inflammation of fixed mindset? How do you instead encourage a growth mindset? Where we go from here Ultimately, I hit the target: about 70% of patients who had been using the old portal migrated to the new tool. It took some time for me to realize I needed to create a process rather than react  to individual situations, but gradually things started to smooth out as I knew what bumps in the road to expect. I also walked back even further and adjusted our communications and website content to speak to the fears and concerns I now knew patients experienced. Eventually, we finished migrating existing patients, and the majority of patients signing onto this portal for the first time were new to the clinic overall (so they would not have used the previous portal). To my knowledge the interface design never improved in any profound way, but we certainly lodged a lot of technical tickets to contribute to a push for feature changes and improvements. Although this piece contains a lot of information, it essentially boils down to asking questions as you always do, but from a different angle to uncover more blind spots. The benefit is a more thorough understanding of who you intend to serve and a more empathetic process for acquiring that understanding. Each section is specifically written to give you a direct idea of a question or prompt you can use the next time you have an opportunity in your own work. I would love to hear how deepening your practice in this way works for you—please comment or feel free to find me on Twitter! Like this: \n\t\t\t\t\t\t\tRecently by Aimee Gonzalez-Cameron\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/my-accessibility-journey-what-ive-learned-so-far/", "title": "My Accessibility Journey: What I’ve Learned So Far", "content": "Last year I gave a talk about CSS and accessibility at the   in Linz, Austria. Afterward, an attendee asked why I was interested in accessibility: Did I or someone in my life have a disability? Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I’m used to answering this question—to which the answer is no—because I get it all the time. A lot of people seem to assume that a personal connection is the only reason someone would care about accessibility. This is a problem. For the web to be truly accessible, everyone who makes websites needs to care about accessibility. We tend to use our own abilities as a baseline when we’re designing and building websites. Instead, we need to keep in mind our diverse users and their diverse abilities to make sure we’re creating inclusive products that aren’t just designed for a specific range of people. Another reason we all should think about accessibility is that it makes us better at our jobs. In 2016 I took part in  , a competition held by   and  . The objective was to build a compelling web experience that worked without JavaScript and could be delivered in 10 kB. On top of that, the site had to be accessible. At the time, I knew about some accessibility basics like using semantic HTML, providing descriptions for images, and  . But there was still a lot to learn. As I dug deeper, I realized that there was far more to accessibility than I had ever imagined, and that making accessible sites basically means doing a great job as a developer (or as a designer, project manager, or writer). Accessibility is exciting Web accessibility is not about a certain technology. It’s not about writing the most sophisticated code or finding the most clever solution to a problem; it’s about users and whether they’re able to use our products. The focus on users is the main reason why I’m specializing in accessibility rather than solely in animation, performance, JavaScript frameworks, or WebVR. Focusing on users means I have to keep up with pretty much every web discipline, because users will load a page, deal with markup in some way, use a design, read text, control a JavaScript component, see animation, walk through a process, and navigate. What all those things have in common is that they’re performed by someone in front of a device. What makes them exciting is that we don’t know which device it will be, or which operating system or browser. We also don’t know how our app or site will be used, who will use it, how fast their internet connection will be, or how powerful their device will be. Making accessible sites forces you to engage with all of these variables—and pushes you, in the process, to do a great job as a developer. For me, making accessible sites means making fast, resilient sites with great UX that are fun and easy to use even in conditions that aren’t ideal. I know, that sounds daunting. The good news, though, is that I’ve spent the last year focusing on some of those things, and I’ve learned several important lessons that I’m happy to share. 1. Accessibility is a broad concept Many people, like me pre-2016, think making your site accessible is synonymous with making it accessible to people who use screen readers. That’s certainly hugely important, but it’s only one part of the puzzle. Accessibility means access for everyone: If your site takes ten seconds to load on a mobile connection, it’s not accessible. If your site is only optimized for one browser, it’s not accessible. If the content on your site is difficult to understand, your site isn’t accessible. It doesn’t matter who’s using your website or when, where, and how they’re doing it. What matters is that they’re able to do it. The belief that you have to learn new software or maybe even hardware to get started with accessibility is a barrier for many developers. At some point you will have to learn how to use a screen reader if you really want to get everything right, but there’s a lot more to do before that. We can make a lot of improvements that help everyone, including people with visual impairments, by simply following best practices. 2. There are permanent, temporary, and situational impairments Who benefits from a keyboard-accessible site? Only a small percentage of users, some might argue.   pointed me to the  , which helped me broaden my perspective. People with permanent impairments are not the only ones who benefit from accessibility. There are also people with temporary and situational impairments who’d be happy to have an alternative way of navigating. For example, someone with a broken arm, someone who recently got their forearm tattooed, or a parent who’s holding their kid in one arm while having to check something online. When you watch a developer operate their editor, it sometimes feels like they don’t even know they have a mouse. Why not give users the opportunity to use your website in a similar way? As you think about the range of people who could benefit from accessibility improvements, the group of beneficiaries tends to grow much bigger. As Derek Featherstone has said, “ ” 3. The first step is to make accessibility a requirement I’ve been asked many times whether it’s worth the effort to fix accessibility, how much it costs, and how to convince bosses and colleagues. My answer to those questions is that you can improve things significantly without even having to use new tools, spend extra money, or ask anyone’s permission. The first step is to make accessibility a requirement—if not on paper, then at least in your head. For example, if you’re looking for a slider component, pick one that’s accessible. If you’re working on a design, make sure  . If you’re writing copy, use language that is easy to understand. We ask ourselves many questions when we make design and development decisions: Is the code clean? Does the site look nice? Is the UX great? Is it fast enough? Is it well-documented? As a first step, add one more question to your list: Is it accessible? 4. Making accessible sites is a team sport Another reason why making websites accessible sounds scary to some developers is that there is a belief that we’re the only ones responsible for getting it right. In fact, as Dennis Lembree reminds us, “ ” It’s a developer’s job to create an accessible site from a coding perspective, but there are many things that have to be taken care of both before and after that. Designs must be intuitive, interactions clear and helpful, copy understandable and readable. Relevant personas and use cases have to be defined, and tests must be carried out accordingly. Most importantly, leadership and teams have to see accessibility as a core principle and requirement, which brings me to the next point: communication. 5. Communication is key After talking to a variety of people at meetups and conferences, I think one of the reasons accessibility often doesn’t get the place it deserves is that not everyone knows what it means. Many times you don’t even have to convince your team, but rather just explain what accessibility is. If you want to get people on board, it matters how you approach them. The first step here is to listen. Talk to your colleagues and ask why they make certain design, development, or management decisions. Try to find out if they don’t approach things in an accessible way because they don’t want to, they’re not allowed to, or they just never thought of it. You’ll have better results if they don’t feel bad, so don’t try to guilt anyone into anything. Just listen. As soon as you know why they do things the way they do, you’ll know how to address your concerns. Highlight the benefits beyond accessibility You can talk about accessibility without mentioning it. For example, talk about typography and ideal character counts per line and how beautiful text is with the perfect combination of font size and line height. Demonstrate how better performance impacts conversion rates and how focusing on accessibility can promote out-of-the-box thinking that improves usability in general. Challenge your colleagues Some people like challenges. At a meetup, a designer who specializes in accessibility once said that one of the main reasons she loves designing with constraints in mind is that it demands a lot more of her than going the easy way. Ask your colleagues, Can we hit a   below 1000? Do you think you can design that component in such a way that it’s keyboard-accessible? My   has a browser—wouldn’t it be cool if we could make our next website work on that thing as well? Help people empathize In his talk “ ,” Scott O’Hara points out that it can be hard for someone to empathize if they are unaware of what they should be empathizing with. Sometimes people just don’t know that certain implementations might be problematic for others. You can help them by explaining how people who are blind or who can’t use a mouse, use the web. Even better, show   without a mouse.   are also a great of way of illustrating different circumstances under which people are surfing the web. 6. Talk about accessibility before a projects kicks off It’s of course a good thing if you’re fixing accessibility issues on a site that’s already in production, but that has its limitations. At some point, changes may be so complicated and costly that someone will argue that it’s not worth the effort. If your whole team cares about accessibility from the very beginning, before a box is drawn or a line of code is written, it’s much easier, effective, and cost-efficient to make an accessible product. 7. A solid knowledge of HTML solves a lot of problems It’s impressive to see how JavaScript and the way we use it has changed in recent years. It has become incredibly powerful and more important than ever for web development. At the same time, it seems HTML has become less important. There is an ongoing discussion about CSS in JavaScript and whether it’s more efficient and cleaner than normal CSS from a development perspective. What we should talk about instead is the excessive use of   and   elements at the expense of other elements. It makes a huge difference whether we use a  . There’s also   when it comes to accessibility. Form items need   elements, and  . Those are just a few examples of absolute basics that some of us forgot or never learned. Semantic HTML is one of the cornerstones of accessible web development. Even if we write everything in JavaScript, HTML is what is finally rendered in the user’s browser.  prevents and fixes many accessibility issues. 8. JavaScript is not the enemy, and sometimes JavaScript even improves accessibility I’m one of those people who believes that most websites should be accessible even  . That doesn’t mean that I hate JavaScript; of course not—it pays part of my rent.  , but it’s important that we use it carefully because it’s very easy to change the user experience for the worse otherwise. Not that long ago, I didn’t know that JavaScript could improve accessibility. We can leverage its power to make our websites more accessible for keyboard users. We can do things like  , adding key controls to custom components, or showing and hiding content in an accessible manner. There are many impressive and creative CSS-only implementations of common widgets, but they’re often less accessible and provide worse UX than their JavaScript equivalents. In a post about  , Sara Soueidan explains why JavaScript is important for accessibility. “Every single no-JS solution came with a very bad downside that negatively affected the user experience,” she writes. 9. It’s a good time to know vanilla CSS and JavaScript For a long time, we’ve been reliant on libraries, frameworks, grid systems, and polyfills because we demanded more of browsers than they were able to give us. Naturally, we got used to many of those tools, but from time to time we should take a step back and question if we really still need them. There were many problems that Bootstrap and jQuery solved for us, but do those problems still exist, or is it just easier for us to write   instead of  ? , but browser inconsistencies aren’t as bad as they used to be. CSS Grid Layout is supported in all major desktop browsers, and thanks to   we can still provide experiences for legacy browsers. We can do feature detection natively with  , testing has gotten much easier, and   and   help us understand what browsers are capable of. Many people use frameworks and libraries without knowing what problems those tools are solving. To decide whether it makes sense to add the extra weight to your site, you need a solid understanding of HTML, CSS, and JavaScript. Instead of increasing the page weight for older browsers, it’s often better to progressively enhance an experience. Progressively enhancing our websites—and reducing the number of requests, kilobytes, and dependencies—makes them faster and more robust, and thus more accessible. 10. Keep learning about accessibility and share your knowledge I’m really thankful that I’ve learned all this in the past few months. Previously, I was a very passive part of the web community for a very long time. Ever since I started to participate online, attend and organize events, and write about web-related topics, especially accessibility, things have changed significantly for me and I’ve grown both personally and professionally. Understanding the importance of access and inclusion, viewing things from different perspectives, and challenging my decisions has helped me become a better developer. Knowing how things should be done is great, but it’s just the first step. Truly caring, implementing, and most importantly sharing your knowledge is what makes an impact. Share your knowledge Don’t be afraid to share what you’ve learned. Write articles, talk at meetups, and give in-house workshops. The distinct culture of sharing knowledge is one of the most important and beautiful things about our industry. Go to conferences and meetups Attending conferences and meetups is very valuable because you get to meet many different people from whom you can learn. There are several   and many conferences that feature at least one accessibility talk. Organize meetups  as a life-changing experience. Meetups are very important and valuable for the community, but organizing a meetup doesn’t just bring value to attendees and speakers. As an organizer, you get to meet all these people and learn from them. By listening and by understanding how they see and approach things, and what’s important to them, you are able to broaden your horizons. You grow as a person, but you also get to meet other professionals, agencies, and companies from which you may also benefit professionally. Invite experts to your meetup or conference If you’re a meetup or conference organizer, you can have a massive impact on the role accessibility plays in our community. Invite accessibility experts to your event and give the topic a forum for discussion. Follow accessibility experts on Twitter Follow   to learn what they’re working on, what bothers them, and what they think about recent developments in inclusive web development and design in general. I’ve learned a lot from the following people:  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  ,  , and  . 11. Simply get started You don’t have to go all-in from the very beginning. If you improve just one thing, you’re already doing a great job in bringing us closer to a better web. Just get started and keep working. There are a lot of resources out there, and trying to find out how and where to start can get quite overwhelming. I’ve gathered a few sites and books that helped me; hopefully they will help you as well. The following lists are by no means exhaustive. Video series This   is a great way to get started. Rob Dodson covers many different accessibility topics in his   (a11y is short for accessibility—the number eleven stands for the number of letters omitted). Books Heydon Pickering’s  Laura Kalbag’s  Blogs Newsletters Accessible JavaScript components Resources and further reading “ ” (article) “ ” (article) “ ” (video) “ ” (article) “ ” (video) “ ” (article) “ ” (article) “ ” (article) “ ” (article) “ ” (article) “ ” (article) Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/discovery-on-a-budget-part-ii/", "title": "Discovery on a Budget: Part II", "content": "Welcome to the second installment of the “Discovery on a Budget” series, in which we explore how to conduct effective discovery research when there is no existing data to comb through, no stakeholders to interview, and no slush fund to draw upon. In   of this series, we discussed how it is helpful to articulate what you know (and what you assume) in the form of a problem hypothesis. We also covered strategies for conducting one of the most affordable and effective research methods: user interviews. In part 2 we will discuss when it’s beneficial to introduce a second, competing problem hypothesis to test against the first. We will also discuss the benefits of launching a “fake-door” and how to conduct an A/B test when you have little to no traffic. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. A quick recap In   I conducted the first round of discovery research for my budget-conscious (and fictitious!) startup,  . The original goal for Candor Network was to provide a non-addictive social media platform that users would pay for directly. I articulated that goal in the form of a problem hypothesis:  Because their business model relies on advertising, social media tools like Facebook are deliberately designed to “hook” users and make them addicted to the service. Users are unhappy with this and would rather have a healthier relationship with social media tools. They would be willing to pay for a social media service that was designed with mental health in mind. Also in part 1, I took extra care to document the assumptions that went into creating this hypothesis. They were:  Users feel that social media sites like Facebook are addictive. Users don’t like to be addicted to social media. Users would be willing to pay for a non-addictive Facebook replacement.  For the first round of research, I chose to conduct user interviews because it is a research method that is adaptable, effective, and—above all—affordable. I recruited participants from Facebook, taking care to document the bias of using a  . I carefully crafted my interview protocol, and used a number of strategies to keep my participants talking. Now it is time to review the data and analyze the results.  Analyze the data When we conduct discovery research, we look for data that can help us either affirm or reject the assumptions we made in our problem hypothesis. Regardless of what research method you choose, it’s critical that you set aside the time to objectively review and analyze the results. In practice, analyzing interview data involves creating transcriptions of the interviews and then reading them many,   times. Each time you read through the transcripts, you highlight and label sentences or sections that seem relevant or important to your research question. You can use products like  ,  , or   tool to help facilitate this process. Or, if you are on a pretty strict budget, you can simply use Google Sheets to keep track of relevant sections in one column and labels in another.  For my project, I specifically looked for data that would show whether my participants felt Facebook was addicting and whether that was a bad thing, and if they’d be willing to pay for an alternative. Here’s how that analysis played out: Facebook has a weird, hypnotizing effect on my brain. I keep scrolling and scrolling and then I like wake up and think, ‘where have I been? why am I spending my time on this?’ Overwhelmingly, my data affirms this assumption. All of my participants (eleven out of eleven) mentioned Facebook being addictive in some way.  I know a lot of people who spend a lot of time on Facebook, but I think I manage it pretty well. This assumption turned out to be a little more tricky to affirm or reject. While all of my participants described Facebook as addictive, many of them (eight out of eleven) expressed that “it wasn’t so bad” or that they felt like they were less addicted than the average Facebook user.  No, I wouldn’t pay for that. I mean, why would I pay for something I don’t think I should use so much anyway? Unfortunately for my project, I can’t readily affirm this assumption. Four participants told me they would flat-out never pay for a social media service, four participants said they would be interested in trying a paid-for “non-addictive Facebook,” and three participants said they would only try it if it became really popular and everyone else was using it.  I don’t like that they are really targeting me with those ads. It’s super creepy. In reviewing the interview transcripts, I came across one unexpected theme. More than 80% of the interviewees (nine out of eleven) said they found Facebook “creepy” because of the targeted advertising and the collection of personal data. Also, most of those participants (seven out of nine) went on to say that they would pay for a “non-creepy Facebook.” This is particularly remarkable because I   the participants how they felt about targeted advertising or the use of personal data. It always came up in the conversation organically. Whenever we start a new project, our initial ideas revolve around our own personal experiences and discomforts. I started Candor Network because I personally feel that social media is designed to be addicting, and that this is a major flaw with many of the most popular services. However, while I can affirm my first assumption, I had unclear results on the second and have to consider rejecting the third. Also, I encountered a new user experience that I previously didn’t think of or account for: that the way social media tools collect and use personal data for advertising can be disconcerting and “creepy.” As is so often the case, the data analysis showed that there are a variety of other experiences, expectations, and needs that must be accounted for if the project is to be successful. Refining the hypothesis Each time we go through the discovery research process, we start with a hypothesis, test it by gathering data, analyze the data, and arrive at a new understanding of the problem. In theory, it may be possible to take one trip through the cycle and either completely affirm or completely reject our hypothesis and assumptions. However, like with Candor Network, it is more often the case that we get a mixture of results: some assumptions can be affirmed while others are rejected, and some completely new insights come to light.  One option is to continue working with a single hypothesis, and simply refine it to account for the results of each round of research. This is especially helpful when the research   affirms your assumptions, but there is additional context and nuance you need to account for. However, if you find that your research results are pulling you in a new direction entirely, it can be useful to create a second,   hypothesis. In my example, the interview research brought to light a new concern about social media I previously hadn’t considered: the “creepy” collection of personal data. I am left wondering, Would potential customers be more attracted to the idea of a social media platform built to prevent addiction, or one built for data privacy? To answer this question, I articulated a new, competing hypothesis: Because their business model relies on advertising, social media tools like Facebook are designed to gather lots of behavior data. They then utilize this behavior data to create super-targeted ads. Users are unhappy with this, and would rather use a social media tool that does not rely on the commodification of their data to make money. They would be willing to pay for a social media service that did not track their use and behavior. I now have two hypotheses to test against one another: one focused on social media addiction, the other focused on behavior tracking and data collection.  At this point, it would be perfectly acceptable to conduct another round of interviews. We would need to change our interview protocol and find more participants, but it would still be an effective (and cheap) method to use. However, for this article I wanted to introduce a new method for you to consider, and to illustrate that a technique like A/B testing is not just for the “big guys” on the web. So I chose to conduct an A/B test utilizing two “fake-doors.” A low-cost comparative test: fake-door A/B testing A “fake-door” test is simply a marketing page, ad, button, or other asset that promotes a product that has yet to be made. Fake-door testing (or “ ”) is Zynga’s go-to method for testing ideas. They create a five-word summary of any new game they are considering, make a few ads, and put it up on various high-trafficked websites. Data is then collected to track how often users click on each of the fake-door “probes,” and only those games that attract a certain number of “conversions” on the fake-door are built. One of the many benefits of conducting a fake-door test is that it allows you to measure interest in a product   you begin to develop it. This makes it a great method for low-budget projects, because it can help you decide whether a project is worth investing in before you spend anything. However, for my project, I wasn’t   interested in measuring potential customer interest in a single product idea. I wanted to continue evaluating my original hypothesis on non-addictive social media as well as start investigating the second hypothesis on a social media platform that doesn’t record behavior data. Specifically, I wanted to see which theoretical social media platform is more attractive. So I created   fake-door landing pages—one for each hypothesis—and used Google Optimize to conduct an A/B test. Version A of the Candor Network landing page advertises the product I originally envisioned and described in my first problem hypothesis. It advertises a social network “built with mental health in mind.” Version B reflects the second problem hypothesis and my interview participants’ concerns around the “creepy” commodification of user data. It advertises a social network that “doesn’t track, use, solicit, or sell your data.” In all other respects, the landing pages are identical, and both will receive 50% of the traffic.  Running an A/B test with little to no site traffic One of the major caveats when running an A/B test is that you need to have a certain number of people participate to achieve any kind of statistically significant result. This wouldn’t be a problem if we worked at a large company with an existing customer base, as it would be relatively straightforward to find ways to direct some of the existing traffic to the test. If you’re working on a new or low-trafficked site, however, conducting an A/B test can be tricky. Here are a few strategies I recommend: Figuring out how much traffic you need to achieve statistical significance in a quantitative study is an inexact science. If we were conducting a high-stakes experiment at a more established business, we would conduct multiple rounds of pre-tests to calculate the effect size of the experiment. Then we would use a calculation like   to estimate the number of people we need to participate in the actual test. This approach is rigorous and helps avoid   or sampling bias, but it requires a lot of resources upfront (like time, money, and lots of potential participants) that we may not have access to. In general, however, you can use this rule of thumb: the bigger the difference between the variations, the fewer participants you need to see a significant result. In other words, if your A and B are very different from each other, you will need fewer participants.  When I worked at  , we would always start an A/B test on a Sunday and end it a full week later on the following Sunday. That way we could be sure we captured both weekday and weekend users. Because Weather Underground is a high-trafficked site, this always resulted in having more than enough participants to see a statistically significant result.  If you’re working on a new or low-trafficked site, however, you’ll need to run your test for longer than a week to achieve the number of test participants required. I recommend budgeting enough time so that your study can run a full six weeks. Six weeks will provide enough time to not only capture results from all your usual website traffic, but also any newcomers you can recruit through other means. I’ve got a pretty low number of followers on social media, so if I tweet or post about Candor Network, only a few people will see it. However, I know a few people and organizations that have a huge number of followers. For example,   has roughly 148k followers on Twitter, and  ’s publisher, Jeffrey Zeldman ( ), has 358k followers. I have asked them both to share the link for Candor Network with their followers. Of course, this method of advertising doesn’t cost any money, but it does cost social capital. I’m sure   and Mr. Zeldman wouldn’t appreciate it if I asked them to tweet things on my behalf on a regular basis. I recommend you use this method sparingly.  Before you create an A/B test for your new product idea, there is one major risk you need to assess: there is a chance that your experiment won’t produce any statistically significant results at all. Even if you use all of the tips I’ve outlined above and manage to get a large number of participants in your test, there is a chance that you won’t be able to “declare a winner.” This isn’t just a risk for companies that have low traffic, it is an inherent risk when running any kind of quantitative study. Sometimes there simply isn’t a clear effect on participant behavior.  Tune in next time for the last installment In the third and final installment of the “Discovery on a Budget” series, I’ll describe how I designed the incredibly short survey on the   landing page and discuss the results of my fake-door A/B test. I will also make another revision to my problem hypothesis and will discuss how to know when you’re ready to leave the discovery process (at least for now) and embark on the next phase of design: ideating over possible solutions. Like this: \n\t\t\t\t\t\t\tRecently by Meg Dickey-Kurdziolek\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/owning-the-role-of-the-front-end-developer/", "title": "Owning the Role of the Front-End Developer", "content": "When I started working as a web developer in 2009, I spent most of my time crafting HTML/CSS layouts from design comps. My work was the final step of a linear process in which designers, clients, and other stakeholders made virtually all of the decisions. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Whether I was working for an agency or as a freelancer, there was no room for a developer’s input on client work other than when we were called to answer specific technical questions. Most of the time I would be asked to confirm whether it was possible to achieve a simple feature, such as adding a content slider or adapting an image loaded from a CMS. In the ensuing years, as front-end development became increasingly challenging, developers’ skills began to evolve, leading to more frustration. Many organizations, including the ones I worked for, followed a traditional waterfall approach that kept us in the dark until the project was ready to be coded. Everything would fall into our laps, often behind schedule, with no room for us to add our two cents. Even though we were often highly esteemed by our teammates, there still wasn’t a chance for us to contribute to projects at the beginning of the process. Every time we shared an idea or flagged a problem, it was already too late. Almost a decade later, we’ve come a long way as front-end developers. After years of putting in the hard work required to become better professionals and have a bigger impact on projects, many developers are now able to occupy a more fulfilling version of the role. But there’s still work to be done: Unfortunately, some front-end developers with amazing skills are still limited to basic PSD-to-HTML work. Others find themselves in a better position within their team, but are still pushing for a more prominent role where their ideas can be fostered. Although I’m proud to believe I’m part of the group that evolved with the role, I continue to fight for our seat at the table. I hope sharing my experience will help others fighting with me. My road to earning a seat at the table My role began to shift the day I watched  , which helped me realize I had the power to start making changes to make my work more fulfilling. With his recommendation to demand responsibility whether you work for a boss or a client, Godin gave me the push I needed. I wasn’t expecting to make any big leaps—just enough to feel like I was headed in the right direction. Taking small steps within a small team My first chance to test the waters was ideal. I had recently partnered with a small design studio and we were a team of five. Since I’d always been open about my soft spot for great design, it wasn’t hard to sell them on the idea of having me begin to get a bit more involved with the design process and start giving technical feedback before comps were presented to clients. The results were surprisingly amazing and had a positive impact on everybody’s work. I started getting design hand-offs that I both approved of from a technical point of view and had a more personal connection with. For their part, the designers happily noticed that the websites we launched were more accurate representations of the comps they had handed off. My next step was to get involved with every single project from day one. I started to tag along to initial client meetings, even before any contracts had been signed. I started flagging things that could turn the development phase into a nightmare; at the same time I was able to throw around some ideas about new technologies I’d been experimenting with. After a few months, I started feeling that my skills were finally having an impact on my team’s projects. I was satisfied with my role within the team, but I knew it wouldn’t last forever. Eventually it was time for me to embark on a journey that would take me back to the classic role of the front-end developer, closer to the base of the waterfall. Moving to the big stage As my career started to take off, I found myself far away from that five-desk office where it had all started. I was now working with a much bigger team, and the challenges were quite different. At first I was amazed at how they were approaching the process: the whole team had a strong technical background, unlike any team I had ever worked with, which made collaboration very efficient. I had no complaints about the quality of the designs I was assigned to work with. In fact, during my first few months, I was constantly pushed out of my comfort zone, and my skills were challenged to the fullest. After I started to feel more comfortable with my responsibilities, though, I soon found my next challenge: to help build a stronger connection between the design and development teams. Though we regularly collaborated to produce high-quality work, these teams didn’t always speak the same language. Luckily, the company was already making an effort to improve the conversation between creatives and developers, so I had all the support I needed. As a development team, we had been shifting to modern JavaScript libraries that led us to work on our applications using a strictly component-based approach. But though we had slowly changed our mindset, we hadn’t changed the ways we collaborated with our creative colleagues. We had not properly shared our new vision; making that connection would become my new personal goal. I was fascinated by  : the idea that UX, visual design, and development teams should work in parallel, allowing for a higher level of iteration during the project. By pushing to progressively move toward a collaborative workflow, everyone on my team began to share more responsibilities and exchange more feedback throughout every project. Developers started to get involved in projects during the design phase, flagging any technical issues we could anticipate. Designers made sure they provided input and guidance after the projects started coming to life during development. Once we got the ball rolling, we quickly began seeing positive results and producing rewarding (and award-winning) work. Even though it might sound like it was a smooth transition, it required a great amount of hard work and commitment from everybody on the team. Not only did we all want to produce better work but we also needed to be willing to take a big leap away from our comfort zones and our old processes. How you can push for a seat at the table In my experience, making real progress required a combination of sharpening my skills as a front-end developer and pushing the team to improve our processes. What follows are more details about what worked for me—and could also work for you. Making changes as a developer Even though the real change in your role may depend on your organization, sometimes your individual actions can help jump-start the shift:  In multidisciplinary teams, developers are known as highly analytical, critical, and logical, but not always the most communicative of the pack. I’ve seen many who quietly complain and claim to have better ideas on how things should be handled, but bottle up those thoughts and move on to a different job. After I started voicing my concerns, proposing new ideas, and seeing small changes within my team, I experienced an unexpected boost in my motivation and noticed others begin to see my role differently.  One of the most common mistakes we tend to make is to focus only on our craft. To connect with our team and improve in our role, we need to understand our organization’s goals, our teammates’ skill sets, our customers, and basically every other aspect of our industry that we used to think wasn’t worth a developer’s time. Once I started having a better understanding of the design process, communication with my team started to improve. The same applied to designers who started learning more about the processes we use as front-end developers.  Today our responsibilities are broader and we’re constantly tasked with leading our teams into undiscovered technologies. As a front-end developer, it’s not uncommon to be required to research technologies like WebGL or VR, and introduce them to the rest of the team. We must stay current with the latest practices in our technical areas of focus. Our credibility is at stake every time our input is needed, so we must always strive to be the best developers in the business. Rethinking practices within the company In order to make the most of your role as a developer, you’ll have to persuade your organization to make key changes. This might be hard to achieve, since it tends to require taking all members of your team out of their comfort zones. For me, what worked was long talks with my colleagues, including designers, management, and fellow developers. It’s hard for a manager to turn you down when you propose an idea to improve the quality of your work and only ask for small changes. Once the rest of the team is on board, you have to work hard and start implementing these changes to keep the ball rolling:  Many companies have high standards when it comes to hiring developers but don’t take full advantage of their talent. We tend to be logical thinkers, so it’s usually a good idea to   we work on. I often had to take the first step to be invited to project kickoffs. But once I started making an effort to provide valuable input, my team started automatically involving me and other developers during the creative phase of new projects.  Problems frequently arise when teams present to clients without having looped in everyone working on the project. Once the client signs off on something, it can be risky to introduce new ideas, even if they add value. Developers, designers, and other key players must come together for team reviews before handing off any work. As a developer, sometimes you might need to raise your hand and invest some of your time to help your teammates review their work before they present it.  Whenever possible, get people in the same room. We tend to rely on technology and push to communicate only by chat and email, but there is real value in face time. It’s always a good idea to have different teammates sit together, or at least in close enough proximity for regular in-person conversation, so they can share feedback more easily during projects. If your team works remotely, you have to look for alternatives to achieve the same effect. Occasional video chats and screen sharing can help teams share feedback and interact in real time. \n  Of all the teams I’ve worked on, those that foster a knowledge-sharing culture tend to work most efficiently. Simple and casual presentations among colleagues from different disciplines can be vital to creating a seamless variety of skills across the team. So it’s important to encourage members of the team to teach and learn from each other.\n When we made the decision to use only a component-based architecture, we prepared a simple presentation for the design team that gave them an overview of how we all would benefit from the change to our process. Shortly after, the team began delivering design comps that were aligned with our new approach.\n It’s fair to say that the modern developer can’t simply hide behind a keyboard and expect the rest of the team to handle all of the important decisions that define our workflow. Our role requires us to go beyond code, share our ideas, and fight hard to improve the processes we’re involved in. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/we-write-css-like-we-did-in-the-90s-and-yes-its-silly/", "title": "We Write CSS Like We Did in the 90s, and Yes, It’s Silly", "content": "As web developers, we marvel at technology. We enjoy the many tools that help with our work: multipurpose editors, frameworks, libraries, polyfills and shims, content management systems, preprocessors, build and deployment tools, development consoles, production monitors—the list goes on. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Our delight in these tools is so strong that no one questions whether a small website actually requires any of them.   is the new  —the web developers who can’t do without their frameworks and preprocessors are no better than our peers from the 1990s who couldn’t do without FrontPage or Dreamweaver. It is true that these tools have improved our lives as developers in many ways. At the same time, they have perhaps also prevented us from improving our basic skills. I want to talk about one of those skills: the craft of writing CSS. Not of using CSS preprocessors or postprocessors, but of writing CSS itself. Why? Because CSS is second in importance only to HTML in web development, and because no one needs processors to build a site or app. Most of all, I want to talk about this because when it comes to writing CSS, it often seems that we have learned nothing since the 1990s. We still write CSS the  , with no advances in   or   and no improvements in writing  . Instead, many developers argue fiercely about each of these topics. Others simply dig in their heels and refuse to change. And a third cohort protests even the discussion of these topics. I don’t care that developers do this. But I do care about our craft. And I care that we, as a profession, are ignoring simple ways to improve our work. Let’s talk about this more after the code break. Here’s unsorted, unoptimized CSS  . And here’s CSS  : Just as in 2003, the CSS is unsorted and unoptimized. Did we learn anything over the past 15 years? Is this really the best CSS we can write? Let’s look at three areas where I believe we can easily improve the way we do our work: declaration sorting, selector sorting, and declaration repetition. Declaration sorting The 90s web developer, if he or she wrote CSS, wrote CSS as it occurred to them. Without sense or order—with no direction whatsoever. The same was true of last decade’s developer. The same is true of today’s developer, whether novice or expert. The only difference between now and then: today’s expert developer uses eight variables, because “that’s how you do it” (even with one-pagers) and because at some point in their life they may need them. In twenty-something years of web development we have somehow not managed to make our CSS consistent and easier to work on by establishing the (or even  ) common sense standard to sort declarations. (If this sounds harsh, it’s because  . Developers condemn  ,  ,  , and other useful aspects of CSS rather than concede that  .) In reality, the issue is dead simple:  Why? For one, sorting makes collaborating easier. Untrained developers can do it. Non-English speakers (such as this author) can do it. I wouldn’t be surprised to learn that even houseplants can do it. For another reason, alphabetical sorting can be automated. What’s that? Yes, one can use or write little scripts (such as  ) to sort declarations. Given the ease of sorting, and its benefits, the current state of affairs borders on the ridiculous, making it tempting to ignore our peers who don’t sort declarations, and to ban from our lives those who argue that it’s easier—or even logical—  to sort alphabetically but instead to sort based on 1) box dimensions, 2) colors, 3) grid- or flexbox-iness, 4) mood, 5) what they ate for breakfast, or some equally random basis. With this issue settled (if somewhat provocatively), on to our second problem from the 90s. Selector sorting The situation concerning selectors is quite similar.  , developers have written selectors and rules as they occurred to them. Perhaps they’ve moved them around (“Oh, that belongs with the nav”). Perhaps they’ve refactored their style sheets (“Oh, strange that site styles appear amidst notification styles”). But standardizing the order—no. Let’s take a step back and assume that order does matter, not just for aesthetics as one might think, but for collaboration. As an example, think of the letters below as selectors. Which list would be easiest to work with? The fact that one selector (a) was a duplicate that only got discovered and merged in the last row perhaps gives away my preference. But then, if you wanted to add d, e to the list, wouldn’t the order of the third row make placing the new selector easier than placing it in either of the first two rows? This example gets at the two issues caused by not sorting selectors: No one knows where to add new selectors, creating a black hole in the workflow. There’s a higher chance of both selector repetition and duplication of rules with the same selectors. Both problems get compounded in larger projects and larger teams. Both problems have haunted us since the 90s. Both problems get fixed by standardizing—through  —how selectors should be ordered. The answer in this case is not as trivial as sorting alphabetically (although we could play with the idea—the cognitive ease of alphabetical selector sorting may make it worth trying). But we can take a path similar to how the HTML spec roughly groups  , so that we first define sections, and then grouping elements, text elements, etc. (That’s also the approach of at least  , the author’s.) The point is that ideal selector sorting doesn’t just occur naturally and automatically. We can benefit from putting more thought into this problem. Declaration repetition Our third hangover from the 90s is that there is and has always been an insane amount of repetition in our style sheets. According to one analysis of more than 200 websites,  , and the repetition rate goes as high as  —meaning that, in this study at least, the typical website uses each declaration   and some  . As shown by a list of   I compiled, declaration repetition   and has even increased slightly over the years. Yes, there are reasons for repetition: notably for different target media (we may repeat ourselves for  ,  , or different viewport sizes) and, occasionally, for the cascade. That is why a  repetition rate of 10–20% seems to be acceptable. But the degree of repetition we observe right now is not acceptable—it’s an unoptimized mess that goes mostly unnoticed. What’s the solution here? One possibility is to  . We’ve seen   that this can lead to slightly more unwieldy style sheets, but we also know that in many other cases it does make them smaller and more compact. This approach of using declarations just once has at least three benefits: It reduces repetition to a more   amount. It reduces the   need for variables. Excluding outliers like Yandex, it reduces file size and payload (10–20% according to my own experience—we looked at the effects  ). No matter what practice we as a field come up with—whether to use declarations just once or follow a different path—the current level of “natural repetition” we face on sample websites is too high. We shouldn’t need to remind ourselves not to repeat ourselves if we repeat code up to  , and it’s getting outright pathetic—again excuse the strong language—if then we’re also the ones to scream for constants and variables and other features only because we’ve never stopped to question this 90s-style coding. The unnatural, more modern way of writing CSS Targeting these three areas would help us move to a more modern way of writing style sheets, one that has a straightforward but powerful way to sort declarations, includes a plan for ordering selectors, and minimizes declaration repetition. In this article, we’ve outlined some options for us to adhere to this more modern way: Sort declarations alphabetically. Use an   order system or standardize and follow a new selector order system. Try to use declarations just once. Get assistance through  . And yet there’s still great potential to improve in all of these areas. The potential, then, is what we should close with. While I’ve emphasized our “no changes since the 90s” way of writing CSS, and stressed the need for robust practices, we need more proposals, studies, and conversations around what practices are most beneficial. Beneficial in terms of writing better, more consistent CSS, but also in terms of balancing our sense of craft (our mastery of our profession) with a high degree of efficiency (automating when it’s appropriate). Striving to achieve this balance will help ensure that developers twenty years from now won’t have to write rants about hangovers from the 2010s. Like this: \n\t\t\t\t\t\t\tRecently by Jens Oliver Meiert\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/diy-web-accessibility-blueprint/", "title": "A DIY Web Accessibility Blueprint", "content": "The summer of 2017 marked a   for the millions of Americans living with a disability. On June 13th, a Southern District of Florida Judge ruled that   violated Title III of the Americans with Disabilities Act. This case marks the  , which was passed into law in 1990. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Despite spending more than   in 2016, Winn-Dixie neglected to include design considerations for users with disabilities. Some of the features that were added include online prescription refills, digital coupons, rewards card integration, and a store locator function. However, it appears that  . Because Winn-Dixie’s new website wasn’t developed to WCAG 2.0 standards, the new features it boasted were in effect only available to sighted, able-bodied users. When Florida resident Juan Carlos Gil, who is legally blind, visited the Winn-Dixie website to refill his prescriptions, he found it to be almost completely inaccessible using the same screen reader software he uses to access hundreds of other sites. Juan stated in his original complaint that he “felt as if another door had been slammed in his face.” But Juan wasn’t alone. Intentionally or not, Winn-Dixie was denying an entire group of people access to their new website and, in turn, each of the time-saving features it had to offer. What makes this case unique is that it marks the first time in history in which a public accommodations case went to trial, meaning the judge ruled the website to be a “place of public accommodation” under the ADA and therefore subject to ADA regulations. Since there are no specific ADA regulations regarding the internet, Judge Scola decided the adoption of the Web Content Accessibility Guidelines (WCAG) 2.0 Level AA to be appropriate. (Thanks to the hard work of the Web Accessibility Initiative (WAI) at the W3C, WCAG 2.0 has found widespread adoption throughout the globe,  .) Learning to have empathy Anyone with a product subscription service (think diapers, razors, or pet food) knows the feeling of gratitude that accompanies the delivery of a much needed product that arrives just in the nick of time. Imagine how much more grateful you’d be for this service if you, for whatever reason, were unable to drive and lived hours from the nearest store. It’s a service that would greatly improve your life. But   imagine that the service gets overhauled and redesigned in such a way that it is only usable by people who own cars. You’d probably be pretty upset. This subscription service example is hypothetical, yet in the United States, despite federal web accessibility requirements instituted to protect the rights of disabled Americans, this sort of discrimination happens frequently. In fact, anyone assuming the Winn-Dixie case was an isolated incident would be wrong. Web accessibility lawsuits are rising in number. The  . While some of these may be what’s known as “ ,” many of them represent plaintiffs like Juan Gil who simply want equal rights. Scott Dinin, Juan’s attorney, explained, “We’re not suing for damages. We’re only suing them to follow the laws that have been in this nation for twenty-seven years.” For this reason and many others, now is the best time to take a proactive approach to web accessibility. In this article I’ll help you create a blueprint for getting your website up to snuff. The accessibility blueprint If you’ll be dealing with remediation, I won’t sugarcoat it: successfully meeting web accessibility standards is a big undertaking, one that is achieved only when every page of a site adheres to all the guidelines you are attempting to comply with. As I mentioned earlier, those guidelines are usually WCAG 2.0 Level AA, which means meeting every Level A and AA requirement. Tight deadlines, small budgets, and competing priorities may increase the stress that accompanies a web accessibility remediation project, but with a little planning and research, making a website accessible is both reasonable and achievable. My intention is that you may use this article as a blueprint to guide you as you undertake a DIY accessibility remediation project. Before you begin, you’ll need to  , familiarize yourself with  , and learn about the  . Then you may begin to evangelize the benefits of web accessibility to those you work with. Have the conversation with leadership Securing support from company leadership is imperative to the long-term success of your efforts. There are numerous ways to broach the subject of accessibility, but, sadly, in the world of business, substantiated claims top ethics and moral obligation. Therefore I’ve found one of the most effective ways to   is to highlight the benefits.  Here are just a few to speak of: Accessible websites are inherently more usable, and consequently they get more traffic. Additionally, better user experiences result in lower bounce rates, higher conversions, and less negative feedback, which in turn typically make  . Like assistive technology, web crawlers (such as Googlebot) leverage HTML to get their information from websites, so a well marked-up, accessible website is easier to index, which makes it easier to find in search results. There are a number of  , one of which is  . Small businesses in the US that improve the accessibility of their website may be eligible for a   from the IRS. Start the movement If you can’t secure leadership backing right away, you can still form a grassroots accessibility movement within the company. Begin slowly and build momentum as you work to improve usability for all users. Though you may not have the authority to make company-wide changes, you can strategically and systematically lead the charge for web accessibility improvements. My advice is to start small. For example, begin by pushing for site-wide improvements to color contrast ratios (which would help color-blind, low-vision, and aging users) or work on making the site keyboard accessible (which would help users with mobility impairments or broken touchpads, and people such as myself who prefer not using a mouse whenever possible). Incorporate user research and A/B testing into these updates, and document the results. Use the results to champion for more accessibility improvements. Read and re-read the guidelines Build your knowledge base as you go. Learning which laws, rules, or guidelines apply to you, and understanding them, is a prerequisite to writing an accessibility plan.   There may be other guidelines that apply to you, and in some cases, additional rules, regulations, or mandates specific to your industry. Not understanding which rules apply to you, not reading them in full, or not understanding what they mean can create huge problems down the road, including excessive rework once you learn you need to make changes. Build a team Before you can start remediating your website, you’ll need to assemble a team. The number of people will vary depending on the size of your organization and website. I previously worked for a very large company with a very large website, yet the accessibility team they assembled was small in comparison to the thousands of pages we were tasked to remediate. This team included a project manager, visual designers, user experience designers, front-end developers, content editors, a couple requirements folks, and a few QA testers. Most of these people had been pulled from their full-time roles and instructed to quickly become familiar with WCAG 2.0. To help you create your own accessibility team, I will explain in detail some of the top responsibilities of the key players:  is responsible for coordinating the entire remediation process. They will help run planning sessions, keep everyone on schedule, and report the progress being made. Working closely with the requirements people, their goal is to keep every part of this new machine running smoothly.  will mainly address issues of  . In its present form, WCAG 2.0 contrast minimums only apply to text, however the much anticipated WCAG 2.1 update (due to be released in mid-2018) contains a new success criterion for  , which covers contrast minimums of all interactive elements and “graphics required to understand the content.” Visual designers should also steer clear of  .  should be checking for consistent, logical navigation and reading order. They’ll need to test that pages are   (headings are for semantic structure, not for visual styling). They’ll be checking to see that page designs are structured to appear and operate in predictable ways.  have the potential to make or break an accessible website because even the best designs will fail if implemented incorrectly. If your developers are unfamiliar with  ,  , or  , then they have a few things to learn. Developers should think of themselves as designers because they play a very important role in  . Luckily, Google offers a short,   and, via Udacity, a  . Additionally,   is a one-stop shop loaded with free pattern libraries, checklists, and accessibility resources for front-end developers.  review the copy for verbosity. Avoid using phrases that will confuse people who aren’t native language speakers. Don’t “beat around the bush” (see what I did there?). Keep content simple, concise, and easy to understand. No writing degree? No worries. There are apps that can help you   and that   like a middle school English teacher. Score bonus points by making sure link text is understandable out of context. While this is a WCAG 2.0 Level AAA guideline, it’s also easily fixed and it greatly improves the user experience for individuals with varying learning and cognitive abilities.  work in tandem with editorial, design, UX, and QA. They coordinate the work being done by these groups and document the changes needed. As they work with these teams, they manage the action items and follow up on any outstanding tasks, questions, or requests. The analysts also deliver the requirements specifications to the developers. If the changes are numerous and complex, the developers may need the analysts to provide further clarification and to help them properly implement the changes as described in the specs.  will need to be trained to the same degree as the other accessibility specialists since they will be responsible for testing the changes that are being made and catching any issues that arise. They will need to learn how to navigate a website using only a keyboard and also by properly using a screen reader (ideally a variety of screen readers). I emphasized “properly” because while anyone can download   or turn on  , it takes another level of skill to understand the difference between “getting through a page” and “getting through a page with standard keyboard controls.” Having individuals with visual, auditory, or mobility impairments on the QA team can be a real advantage, as they are more familiar with assistive technology and can test in tandem with others. Additionally, there are a variety of   you can use alongside manual testing. These tools typically catch only around 30% of common accessibility issues, so they do not replace ongoing human testing. But they can be extremely useful in helping QA learn when an update has negatively affected the accessibility of your website. Start your engines! Divide your task into pieces that make sense. You may wish to tackle all the global elements first, then work your way through the rest of the site, section by section. Keep in mind that every page must adhere to the accessibility standards you’re following for it to be deemed “accessible.” (This includes PDFs.)  Use what you’ve learned so far by way of accessibility videos, articles, and guidelines to perform an audit of your current site. While some manual testing may seem difficult at first, you’ll be happy to learn that  . Regardless of the testing being performed, keep in mind that it should always be done thoroughly and by considering a variety of users, including: keyboard users; blind users; color-blind users; low-vision users; deaf and hard-of-hearing users; users with learning disabilities and cognitive limitations; mobility-impaired users; users with speech disabilities; and users with seizure disorders. When you are in the weeds, document the patterns As you get deep in the weeds of remediation, keep track of the patterns being used. Start a knowledge repository for elements and situations. Lock down the designs and colors, code each element  to be accessible, and test these patterns across various platforms, browsers, screen readers, and devices. When you know the elements are bulletproof, save them in a pattern library that you can pull from later. Having a pattern library at your fingertips will improve consistency and compliance, and help you meet tight deadlines later on, especially when working in an agile environment. You’ll need to keep this online knowledge repository and pattern library up-to-date. It should be a living, breathing document. Cross the finish line … and keep going! Some people mistakenly believe accessibility is a set-it-and-forget-it solution. It isn’t. Accessibility is an ongoing challenge to continually improve the user experience the way any good UX practitioner does. This is why it’s crucial to get leadership on board. Once your site is fully accessible, you must begin working on the backlogs of continuous improvements. If you aren’t vigilant about accessibility, people making even small site updates can unknowingly strip the site of the accessibility features you worked so hard to put in place. You’d be surprised how quickly it can happen, so educate everyone you work with about the importance of accessibility. When everyone working on your site understands and evangelizes accessibility, your chances of protecting the accessibility of the site are much higher. It’s about the experience, not the law  with blind patron Juan Carlo Gil. Their argument is that a website does not constitute a place of accommodation, and therefore, their case should have been dismissed. This case, and others, illustrate that the legality of web accessibility is still very much in flux. However, as web developers and designers, our motivation to build accessible websites should have nothing to do with the law and everything to do with the user experience. Good accessibility is good UX. We should seek to create the best user experience for all. And we shouldn’t settle for simply meeting accessibility standards but rather strive to create an experience that delights users of all abilities. Additional resources and articles If you are ready to learn more about web accessibility standards and become the accessibility evangelist on your team, here are some additional resources that can help. Resources —an awesome full version of the WCAG 2.0 guidelines that allows you to filter success criteria by responsibility. —tota11y is an easy-to-use accessibility visualization tool from Khan Academy. The  —a ton of libraries, checklists, and accessibility resources for front-end developers. —a free two-week eLearning course that is geared toward experienced front-end developers. “ ”—a compiled list of twenty-five automated accessibility testing tools with a brief description of each one. Articles “ ”—lists seven business-savvy benefits of having an accessible website. “ ”—an awesome article that addresses how the separation of HTML and CSS affects navigation, layout, and more. “ ”—addresses negative stereotypes, ableism, and how to integrate accessibility into your testing process. “ ”—discusses how responsive web design improves UX and accessibility. “ ”—helps you identify the “low-hanging fruit” of accessibility issues and shows you how to fix them. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/ten-extras-for-great-api-documentation/", "title": "Ten Extras for Great API Documentation", "content": "If you manage to create amazing API documentation and ensure that developers have a positive experience implementing your API, they will sing the praises of your product. Continuously improving your API documentation is an investment, but it can have a huge impact. Great documentation builds trust, differentiates you from your competition, and provides marketing value.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I’ve shared some best practices for creating good API documentation in my article “ .” In this article, I delve into some research studies and show how you can both improve and fine-tune different aspects of your API documentation. Some of these extras, like readability, are closer to essentials, while others are more of a nice-to-have, like personality. I hope they give you some ideas for building the best possible docs for your product. Overview page Whoever visits your API documentation needs to be able to decide at first glance whether it is worth exploring further. You should clearly show: what your API offers (i.e., what your products do); how it works; how it integrates; and how it scales (i.e., usage limits, pricing, support, and SLAs). An overview page targets all visitors, but it is especially helpful for decision-makers. They have to see the business value: explain to them directly why a company would want to use your API. Developers, on the other hand, want to understand the purpose of the API and its feature set, so they tend to turn to the overview page for conceptual information. Show them the architecture of your API and the structure of your docs. Include an overview of different components and an introduction into the request-response behavior (i.e., how to integrate, how to send requests, and how to process responses). Provide information on the platforms on which the API is running (e.g., Java) and possible interactions with other platforms.  As the study “ ” found, without conceptual knowledge, developers struggle to formulate effective queries and to evaluate the relevance or meaning of content they find. That’s why API documentation should not only include detailed examples of API use, but also thorough introductions to the concepts, standards, and ideas in an API’s data structures and functionality. The overview page can be an important component to fulfill this role. Examples For some developers, examples play a more important role in getting started with an API than the explanations of calls and parameters. A recent study, “ ,” explored how software developers interact with API documentation: what their goals are, how they learn, where they look for information, and how they judge the quality of API docs. The role of examples The study found that after conducting an initial overview of what the API does and how it works, developers approach learning about the API in two distinct ways: some follow a top-down approach, where they try to build a thorough understanding of the API before starting to implement specific use cases, while others prefer to follow a bottom-up approach, where they start coding right away.  This latter group has a code-oriented learning strategy; they start learning by trying and extending code examples. Getting into an API is most often connected with a specific task. They look for an example that has the potential of serving as a basis to solve their problem, but once they’ve found the solution they were looking for, they usually stop learning.  Examples are essential for code-oriented learners, but all developers benefit from them. The study showed that developers often trust examples more than documentation, because if they work, they can’t be outdated or wrong. Developers often struggle with finding out where to start and how to begin with a new API—examples can become good entry points in this case. Many developers can grasp information more easily from code than text, and they can re-use code in examples for their own implementation. Examples also play other roles that are far from obvious: they automatically convey information about dependencies and prerequisites, they help identify relevant sections in the documentation when developers are scanning the page, and they intuitively show developers how code that uses the API should look. Improve your examples Because examples are such a crucial component in API documentation, better examples mean better docs. To ensure the quality of your examples, they should be complete, be programmed professionally, and work correctly. Because examples convey so much more than the actual use case, make sure to follow the style guidelines of the respective community and show best-practice approaches. Add brief, informative explanations; although examples can be self-explanatory, comments included with sample code help comprehension. Add concrete, real-life examples whenever you can. If you don’t have real examples, make sure they at least look real: use realistic variable names and functions instead of abstract ones. When including examples, you have a variety of formats and approaches to choose from: auto-generated examples, sample applications, client libraries, and examples in multiple languages. Autodoc tools like   and   automatically generate documentation from your source code and keep it up-to-date as the code changes. Use them to generate reference libraries and sample code snippets, but be aware that what you produce this way is only skeleton—not fleshed out—documentation. You will still have to add explanations, conceptual information, quick-start guides, and tutorials, and you should still pay attention to other aspects like UX and good-quality copy. On the Readme blog, they explore   in more depth through a couple of real-world examples. Working applications that use the API are a great way to show how everything works together and how the API integrates with different platforms and technologies. They are different than sample code snippets, because they are stand-alone solutions that show the big picture. As such, they are helpful to developers who would like to see how a full implementation works and to have an overall understanding of how everything in the API ties together. On the other hand, they are real products that showcase the services and quality of your API to decision makers.   offers buildable, executable source examples of how to accomplish a task using a particular technology in a wide variety of categories.      Client libraries are chunks of code that developers can add to their own development projects. They are usually available in various programming languages, and cover basic functionality for an application to be able to interact with the API. Providing them is an extra feature that requires ongoing investment from the API provider, but doing so helps developers jump-start their use of the API. GitHub follows the practical approach of offering client libraries for the languages that are used the most with their API, while linking to unsupported, community-built libraries written in other, less popular languages.  APIs are platform- and language-independent by nature. Developers can use an API’s services with the language of their choice, but this means good documentation should cover at least the most popular languages used with that particular API (e.g., C#, Java, JavaScript, Go, Objective-C, PHP, Python, Ruby, and Swift). Not only should you provide sample code and sample applications in different languages, but also these samples should reflect the best-practice approach for each language. Usability API documentation is a tool that helps developers and other stakeholders do their job. You should adapt it to the way people use it, and make it as easy to use as possible. Consider the following factors:  Developers copy and paste code examples to use them as a starting point for their own implementation. Make this process easier with either a copy button next to relevant sections or by making sections easy to highlight and copy.  When implemented well, fixing the table of contents and other navigation to the page view can prevent users from getting lost and having to scroll back up.  Minimize clicking by keeping related topics close to each other.  Developers should be able to see examples in the language of their choice. Put a language selector above the code examples section, and make sure the page remembers what language the user has selected.  Single page views can result in very long pages, so make sure people can link to certain sections of the page. If, however, a single page view doesn’t work for your docs, don’t sweat it: just break different sections into separate pages. \n \n \n Another best practice from Stripe: the language selector also changes the URL, so URLs link to the right location in the right language. \n  Consider allowing users to contribute to your docs. If you see your users edit your documentation, it indicates there might be room for improvement—in those parts of your docs or even in your code. Additionally, your users will see that issues are addressed and the documentation is frequently updated. One way to facilitate collaboration is to host your documentation on GitHub, but be aware that this will limit your options of interactivity, as GitHub hosts static files.\n Interactivity Providing an option for users to interact with your API through the documentation will greatly improve the developer experience and speed up learning. First, provide a working test API key or, even better, let your users log in to your documentation site and insert their own API key into sample commands and code. This way they can copy, paste, and run the code right away. As a next step, allow your users to make API calls directly from the site itself. For example, let them query a sample database, modify their queries, and see the results of these changes. A more sophisticated way to make your documentation more interactive is by providing a sandbox—a controlled environment where users can test calls and functions against known resources, manipulating data in real-time. Developers learn through the experience of interacting with your API in the sandbox, rather than by switching between reading your docs and trying out code examples themselves. Nordic APIs  , discusses the role of documentation in a sandboxed environment, and shows a possible implementation. To see a sandbox in action, try out the one on  . Help  also explored how developers look for help. In a natural work environment, they usually turn to their colleagues first. Then, however, many of them tend to search the web for answers instead of consulting the official product documentation. This means you should ensure your API documentation is optimized for search engines and will turn up relevant results in search queries. To make sure you have the necessary content available for self-support, include FAQs and a well-organized knowledge base. For quick help and human interaction, provide a contact form, and—if you have the capacity—a help-desk solution right from your docs, e.g., a live chat with support staff. The study also pointed at the significant role   plays: most developers interviewed mentioned the site as a reliable source of self-help. You can also support your developers’ self-help efforts and sense of community by adding your own developer forum to your developer portal or by providing an IRC or Slack channel. Changelog As with all software, APIs change and are regularly updated with new features, bug fixes, and performance improvements. When a new version of your API comes out, you have to inform the developers working with your API about the changes so they can react to them accordingly. A changelog, also called release notes, includes information about current and previous versions, usually ordered by date and version number, along with associated changes. If there are changes in a new version that can break old use of an API, put warnings on top of relevant changelogs, even on top of your release notes page. You can also bring attention to these changes by highlighting or marking them permanently. To keep developers in the loop, offer an RSS feed or newsletter subscription where they can be notified of updates to your API. Besides the practical aspect, a changelog also serves as a trust signal that the API and its documentation are actively maintained, and that the information included is up-to-date. Analytics and feedback You can do some research by getting to know your current and potential clients, talking to people at conferences, exploring your competition, and even conducting surveys. Still, you will have to go with a lot of assumptions when you first build your API docs. When your docs are up, however, you can start collecting usage data and feedback to learn how you can improve them. Find out about the most popular use cases through analytics. See which endpoints are used the most and make sure to prioritize them when working on your documentation. Get ideas for tutorials, and see which use cases you haven’t covered yet with a step-by-step walkthrough from developer community sites like Stack Overflow or your own developer forums. If a question regarding your API pops up on these channels and you see people actively discussing the topic, you should check if it’s something that you need to explain in your documentation. Collect information from your support team. Why do your users contact them? Are there recurring questions that they can’t find answers for in the docs? Improve your documentation based on feedback from your support team and see if you have been successful: have users stopped asking the questions you answered? Listen to feedback and evaluate how you could improve your docs based on them. Feedback can come through many different channels: workshops, trainings, blog posts and comments about your API, conferences, interviews with clients, or usability studies. Readability Readability is a measure of how easily a reader can understand a written text—it includes visual factors like the look of fonts, colors, and contrast, and contextual factors like the length of sentences, wording, and jargon. People consult documentation to learn something new or to solve a problem. Don’t make the process harder for them with text that is difficult to understand.  While generally you should aim for clarity and brevity from the get-go, there are some specific aspects you can work on to improve the readability of your API docs.  Expect that not all of your users will be developers and that even developers will have vastly different skills and background knowledge about your API and business domain. To cater to the different needs of different groups in your target audience, explain everything in detail, but provide ways for people already familiar with the functionality to quickly find what they are looking for, e.g., add a logically organized quick reference.  Explain everything  . Use short sentences, and make sure to be consistent with labels, menu names, and other textual content. Include a clear, straightforward explanation for each call. Avoid jargon if possible, and if not, link to domain-related definitions the first time you use them. This way you can make sure that people unfamiliar with your business domain get the help they need to understand your API.  Both the font size and the font type influence readability. Have short section titles and use title case to make it easier to scan them. For longer text, use sans serif fonts. In print, serif fonts make reading easier, but online, serif characters can blur together. Opt for fonts like Arial, Helvetica, Trebuchet, Lucida Sans, or Verdana, which was designed specifically for the web. Contrast plays an important role as well: the  , the easier the text is to read. Consider using a slightly larger font size and different typeface for code than for text to help your users’ visual orientation when switching back and forth between their code editor and your documentation.   API documentation should cater to newcomers and returning visitors alike (e.g., developers debugging their implementation). A logical structure that is easy to navigate and that allows for quick reference works for both. Have a clear table of contents and an organized list of resources, and make sections, subsections, error cases, and display states directly linkable.  As Steve Krug claims in his book about web usability,  , one of the most important facts about web users is that they don’t read, they scan. To make text easier to scan, use short paragraphs, highlight relevant keywords, and use lists where applicable.  Strive to make your API docs accessible to all users, including users who access your documentation through assistive technology (e.g., screen readers). Be aware that screen readers may often struggle with reading code and may handle navigation differently, so explore  . Learn more about  , study  , and do your best to adhere to them. Personality You’ve worked hard to get to know your audience and follow best practices to leave a good impression with your API docs. Now, as a finishing touch, you can make sure your docs “sound” and look in tune with your brand.  Although API documentation and technical writing in general don’t provide much room for experimentation in tone and style, you can still instill some personality into your docs: Use your brand book and make sure your API docs follow it to the letter. A friendly tone and simple style can work wonders. Remember, people are here to learn about your API or solve a problem. Help them by talking to them in a natural manner that is easy to understand. Add illustrations that help your readers understand any part of your API. Show how different parts relate to each other; visualize concepts and processes. Select your examples carefully so that they reflect on your product the way you want them to. Playful implementations of your API will create a different impression than more serious or enterprise use cases. If your brand allows, you can even have some fun with examples (e.g., funny examples and variable names), but don’t go overboard. You can insert some images (beyond illustrations) where applicable, but make sure they add something to your docs and don’t distract readers. Think developer portal—and beyond Although where you draw the line between API documentation and developer portal is still up for debate, most people working in technical communication seem to agree that a developer portal is an extension of API documentation. Originally, API documentation meant strictly the reference docs only, but then examples, tutorials, and guides for getting started became part of the package; yet we still called them API docs. As the market for developer communication grows, providers strive to extend the developer experience beyond API documentation to a full-fledged developer portal.  In fact, some of the ideas discussed above—like a developer forum or sandboxes—already point in the direction of building a developer portal. A developer portal is the next step in developer communication, where besides giving developers all the support they need, you start building a community. Developer portals can include support beyond docs, like a blog or videos. If it fits into the business model, they can also contain an app store where developers submit their implementations and the store provides a framework for them to manage the whole sales process. Portals connected to an API often also contain a separate area with landing pages and showcases where you can directly address other stakeholders, such as sales and marketing.  Even if you’re well into building your developer portal, you can still find ways to learn more and extend your reach. Attend and present at conferences like  ,   or   to get involved in developer relations. Use social media: tweet, join group discussions, or send a newsletter. Explore the annual   to learn more about your main target audience. Organize code and documentation sprints, trainings, and workshops. Zapier has a   you can follow to keep up with the ever-changing API economy—you will surely find your own sources of inspiration as well. I hope “ ” and this article gave you valuable insight into creating and improving your API documentation and inspire you to get started or keep going. Like this: \n\t\t\t\t\t\t\tRecently by Diana Lakatos\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/planning-for-accessibility/", "title": "Planning for Accessibility", "content": "Incorporating accessibility from the beginning is almost always easier, more effective, and less expensive than making accessibility improvements as a separate project. In fact, building accessibility into your project and processes has a wealth of business benefits. If you’re looking to make the case for accessibility—to yourself, to coworkers, or to bosses and clients—you might start here: Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites.  In the broadest terms, accessibility can make it easier for anyone to find, access, and use a website successfully. By ensuring better usability for all, accessibility boosts a site’s effectiveness and increases its potential audience.  The wider your audience, the greater your reach and commercial appeal. When a site is more accessible than other sites in the same market, it can lead to preferential treatment from people who struggled to use competitors’ sites. If a site is translated, or has more simply written content that improves automated translation, increased accessibility can lead to a larger audience by reaching people who speak other languages.  Accessible websites can cut costs in other areas of a business. On a more accessible site, more customers can complete more tasks and transactions online, rather than needing to talk to a representative one-to-one.  In a few countries, an accessible site is required by law for organizations in certain sectors—and organizations with inaccessible sites can be sued for discrimination against people with disabilities. Once you’ve made the case for incorporating accessibility into your work, the next step is to integrate an accessibility mindset into your processes. Include accessibility by default by giving accessibility proper consideration at every step in a product’s lifecycle. Building Your Team Web accessibility is the responsibility of everyone who has a hand in the design of a site. Design includes all of the decisions we make when we create a product—not just the pretty bits, but the decisions about how it works and who it’s for. This means everybody involved in the project is a designer of some sort. Each specialist is responsible for a basic understanding of their work’s impact on accessibility, and on their colleagues’ work. For example, independent consultant Anne Gibson says that information architects should keep an eye on the markup: Leadership and support While we should all be attentive to how accessibility impacts our specialism, it’s important to have leadership to help determine priorities and key areas where the product’s overall accessibility needs improvement. Project manager Henny Swan (user experience and design lead at the Paciello Group, and previously of the BBC) recommends that accessibility be owned by product managers. The product managers must consider how web accessibility affects what the organization does, understand the organization’s legal duties, and consider the potential business benefits. Sometimes people find themselves stuck within a company or team that doesn’t value accessibility. But armed with knowledge and expertise about accessibility, we can still do good work as individuals, and have a positive effect on the accessibility of a site. For example, a designer can ensure all the background and foreground text colors on their site are in good contrast, making text easier to distinguish and read. Unfortunately, without the support and understanding of our colleagues, the accessibility of a site can easily be let down in other areas. While the colors could be accessible, if another designer has decided that the body text should be set at 12 pixels, the content will still be hard to read. When accessibility is instituted as a company-wide practice, rather than merely observed by a few people within a team, it will inevitably be more successful. When everybody understands the importance of accessibility and their role in the project, we can make great websites. Professional development When you’re just starting to learn about accessibility, people in your organization will need to learn new skills and undertake training to do accessibility well. Outside experts can often provide thorough training, with course material tailor-made to your organization. Teams can also develop their accessibility skills by learning the basics through web- and book-based research, and by attending relevant conferences and other events. Both formal training and independent practice will cost time away from other work, but in return you’ll get rapid improvements in a team’s accessibility skills. New skills might mean initially slower site development and testing while people are still getting their heads around unfamiliar tools, techniques, and ways of thinking. Don’t be disheartened! It doesn’t take long for the regular practice of new skills to become second nature. You might also need to hire in outside expertise to assist you in particular areas of accessibility—it’s worth considering the capabilities of your team during budgeting and decide whether additional training and help are needed. Especially when just starting out, many organizations hire consultants or new employees with accessibility expertise to help with research and testing. When you’re trying to find the right expert for your organization’s needs, avoid just bashing “accessibility expert” into a search engine and hoping for good luck. Accessibility blogs and informational websites (see the Resources section) are probably the best place to start, as you can often find individuals and organizations who are great at teaching and communicating accessibility. The people who run accessibility websites often provide consultancy services, or will have recommendations for the best people they know. Scoping the Project At the beginning of a project, you’ll need to make many decisions that will have an impact on accessibility efforts and approaches, including: What is the purpose of your product? Who are the target audiences for your product? What are their needs, restrictions, and technology preferences? What are the goals and tasks that your product enables the user to complete? What is the experience your product should provide for each combination of user group and user goal? How can accessibility be integrated during production? Which target platforms, browsers, operating systems and assistive technologies should you test the product on? If you have answers to these questions—possibly recorded more formally in an accessibility policy (which we’ll look at later in this chapter)—you’ll have something to refer to when making design decisions throughout the creation and maintenance of the product. Keep in mind that rigid initial specifications and proposals can cause problems when a project involves research and iterative design. Being flexible during the creation of a product will allow you to make decisions based on new information, respond to any issues that arise during testing, and ensure that the launched product genuinely meets people’s needs. If you’re hiring someone outside your organization to produce your site, you need to convey the importance of accessibility to the project. Whether you’re a project manager writing requirements, a creative agency writing a brief, or a freelance consultant scoping your intent, making accessibility a requirement will ensure there’s no ambiguity. Documenting your success criteria and sharing it with other people can help everyone understand your aims, both inside and outside your organization. Budgeting Accessibility isn’t a line item in an estimate or a budget—it’s an underlying practice that affects every aspect of a project. Building an accessible site doesn’t necessarily cost more money or time than an inaccessible site, but some of the costs are different: it costs money to train your team or build alternative materials like transcripts or translations. It’s wise to consider all potential costs from the beginning and factor them into the product budget so they’re not a surprise or considered an “extra cost” when they could benefit a wide audience. You wouldn’t add a line item to make a site performant, so don’t do it for accessibility either. If you’ve got a very small budget, rather than picking and choosing particular elements that leave some users out in favor of others, consider the least expensive options that enable the widest possible audience to access your site. For example, making a carousel that can be manipulated using only the keyboard will only benefit people using keyboard navigation. On the other hand, designing a simpler interface without a carousel will benefit everyone using the site. Ultimately, the cost of accessibility depends on the size of the project, team, and whether you’re retrofitting an existing product or creating a new product. The more projects you work on, the better you’ll be able to estimate the impact and costs of accessibility. Want to read more? This excerpt from   will help you get started.   today, as well as other excellent titles from  . Like this: \n\t\t\t\t\t\t\tRecently by Laura Kalbag\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/feedback-that-gives-focus/", "title": "Feedback That Gives Focus", "content": "I have harbored a lifelong dislike of feedback. I didn’t like it in sixth grade when a kid on the bus told me my brand new sneakers were “too bright.” And I didn’t like it when a senior executive heard my pitch for a digital project and said, “I hate this idea.” Turns out my sneakers were pretty bright, and my pitch wasn’t the best idea. Still, those experiences and many others like them didn’t help me learn to stop worrying and love the feedback process. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. We can’t avoid feedback. Processing ideas and synthesizing feedback is a big part of what we do for a living. I have had plenty of opportunities to consider why both giving and receiving feedback is often so emotionally charged, so challenging to get right. And here’s what I’ve found to be true. When a project is preoccupying us at work, we often don’t think about it as something external and abstract. We think about it more like a story, with ourselves in the middle as the protagonist—the hero. That might seem melodramatic, especially if your work isn’t the kind of thing they’d make an inspirational movie about. But   to back this up: humans use stories to make sense of the world and our place within it. Our work is no different. We create a story in our heads about how far we’ve come on a project and about where we’re going. This makes discussing feedback dangerous. It’s the place where someone else swoops in and hijacks your story. Speaking personally, I notice that when I’m   feedback (and feeling frustrated), the story in my head goes like this:   How can I force them into thinking the same way I do so that we can fix everything that’s wrong with this project, and in the end, I don’t feel like a failure? Likewise, when I’m   feedback (and feeling defensive), the story goes like this:   How can I defend our work so that we keep everything that I like about this project, and in the end, I don’t feel like a failure? Both of these postures are ultimately counterproductive because they are focused inward. They’re really about avoiding shame. Both the person giving and receiving feedback are on opposing sides of the equation, protecting their turf. But like a good story, good feedback can take us  , allowing us to see the work more clearly. It can remove the artificial barrier between feedback giver and receiver, refocusing both on shared goals. Change your habits around feedback, and you can change the story of your project. Here are three ways to think about feedback that might help you do just that. Good feedback helps us understand how we got here Here’s a story for you. I was presenting some new wireframes for an app to the creative leads on the project. There were a number of stakeholders and advisors on the project, and I had integrated several rounds of their feedback into the harmonious and brilliant vision that I was presenting in this meeting. That’s the way I hoped the story would go, anyway. But at the end of the meeting, I got some of the best, worst feedback I have ever received: “We’ve gotten into our heads a little bit with this concept. Maybe it should be simpler. Maybe something more like this …” And they handed me a loose sketch on paper to illustrate a new, simpler approach. I had come for sign-off but left with a do-over. I felt ashamed. How could I have missed that? Even though that feedback was hard to hear, I walked away able to make important changes, which led to a better outcome in the end. Here are the reasons why:  Conversations (rather than written notes) make it easier to verify assumptions. When you talk face-to-face you can ask open-ended questions and clarify intent, so you don’t jump to conclusions. Talking helps you find where the trouble is much faster.  between problems in our process so far (trying to reconcile too many competing ideas) and how it led to the current result (an overly complicated product). The person who gave the feedback helped me see how we got to where we were, without assigning blame or shaming me in the process.  They didn’t try to mask the fact that the concept wasn’t working. Veiled or vague criticism does more harm than good; the same negativity comes through but without a clear sense of what to do next. Good feedback invites each person to contribute their best work No thought, no idea, can possibly be conveyed as an idea from one person to another. … Only by wrestling with the conditions of the problem … first hand … does he think. Here’s another story. I was the producer on an app-based game, and the team was working on a part of the user interface that the player would use again and again. I was convinced that the current design didn’t “feel” right. I kept pushing for a change, against the input of others, and I gave the team some specific feedback about what I wanted to see done. The designers played along and tried it out. But it became clear that my feedback wasn’t helping, and the design director (gently) stepped in and steered us out of my design tangent and back on course. John Dewey had it right in that quote above; you can’t think for someone else. And that’s exactly what I was doing: giving specific solutions without inviting the team to engage with the problem. And the results were worse for it. It’s very tempting to use feedback to cajole and control people into doing things your way. But that usually leads to mediocre results. You have a team for a reason: you can’t possibly do everything on your own. Instead, when giving feedback try to remember that you’re building a team of individual contributors that will work together to make a better end product. Here are a few feedback habits that help avoid the trap of using feedback to control, and instead, bring out the best in people. Don’t give feedback until the timing is right Feedback isn’t useful if it’s given   the work is really ready to be looked at. It’s also not useful to give feedback if you have not taken the time to look at the work and think about it in advance. If you rush either of these, the feedback will devolve into a debate about what   have been, rather than what’s actually there now. That invites confusion, defensiveness, and inefficiency. Be just specific enough Good feedback should have enough specifics to clearly identify the problem. But, usually, it’s better to   give a specific solution. The feedback in this example goes too far: The background behind the menu items is a light blue on a darker blue. This makes it hard to see some options. Change the background fill to white and add a thin, red border around each square. When an option is selected, perhaps the inside border should glow red but not fill in all the way. Instead, feedback that clearly identifies the problem is probably enough: The background behind the menu items makes it a little hard for me to see some options. Any way we might make it easier to read? Give the person whose job it is to solve the problem the room to do just that.  They might solve it in a better way that you hadn’t anticipated. Admit when you’re wrong When you acknowledge a mistake openly and without fear, it gives permission for others on the team to do the same. This refocuses energies away from ego-protection and toward problem solving. I chose to admit I got it wrong on that app project I mentioned above; the designers had it right and I told them I was glad they stuck to their guns. Saying that out loud was actually easier than I thought, and our working relationship was better for it. Good feedback tells a story about the future In my writing, as much as I could, I tried to find the good, and praise it. We’ve said that good feedback connects past assumptions and decisions to current results, without assigning blame. Good feedback also identifies issues in a timely and specific way, giving people room to find novel solutions and contribute their best work. Lastly, I’ve found that most useful feedback helps us look beyond the present state of our work and builds a shared vision of where we’re headed. One of maybe the most overlooked tools for building that shared vision is actually pretty simple: positive feedback. The best positive feedback acknowledges great work that’s already complete, doing so in a way that is future-focused.  Its purpose is to point out what we want to do   of as we move forward. In practice, I’ve found that I can become stingy with positive feedback, especially when it’s early in a project and there’s so much work ahead of us. Maybe this is because I’m afraid that mentioning the good things will distract us from what’s still in need of improvement. But ironically, the opposite is true: it becomes easier to fix what’s broken once you have something (however small) that you know is working well and that you can begin to build that larger vision around. So be equally direct about what’s working as you are with what isn’t, and you’ll find it becomes easier to rally a team around a shared vision for the future.  The first signs of that future can be found right here in the present. Like Mr. Haley said: find the good and praise it. Oh and one more thing: say thank you. Thank people for their contributions. Let me give that a try right now: It seemed wise to get some feedback from others when writing about feedback. So thanks to everyone in the PBS KIDS family of producers who generously shared their thoughts and experience with me in preparation of this article. I look forward to hearing your feedback. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/faux-grid-tracks/", "title": "Faux Grid Tracks", "content": "A little while back, there was a question posted to  : Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Is it possible to style the rows and columns of a [CSS] grid—the grid itself? I have an upcoming layout that uses what looks like a tic-tac-toe board—complete with the vertical and horizontal lines of said tic-tac-toe board—with text/icon in each grid cell. This is a question I expect to come up repeatedly, as more and more people start to explore Grid layout. The short answer is: no, it isn’t possible to do that. But it   possible to fake the effect, which is what I’d like to explore. Defining the grid Since we’re talking about tic-tac-toe layouts, we’ll need a containing element around nine elements. We could use an ordered list, or a paragraph with a bunch of  s, or a   with some  s. Let’s go with that last one. We’ll take those nine  s and put them into a three-by-three grid, with each row five ems high and each column five ems wide. Setting up the grid structure is straightforward enough: That’s it! Thanks to the auto-flow algorithm inherent in Grid layout, that’s enough to put the nine   elements into the nine grid cells. From there, creating the appearance of a grid is a matter of setting borders on the   elements. There are a lot of ways to do this, but here’s what I settled on: The result is shown in the basic layout below. This approach has the advantage of not relying on class names or what-have-you. It does fall apart, though, if the grid flow is changed to be columnar, as we can see in Figure 2. If the flow is columnar, then the border-applying rules have to get flipped, like this: That will get us back to the result we saw in Figure 1, but with the content in columnar order instead of row order. There’s no   or   in Grid like there is in flexbox, so we only have to worry about normal row and columnar flow patterns. But what if a later change to the design leads to grid items being rearranged in different ways? For example, there might be a reason to take one or two of the items and display them last in the grid, like this: Just like in flexbox, this will move the displayed grid items out of source order, placing them after the grid items that don’t have explicit   values. If this sort of rearrangement is a possibility, there’s no easy way to switch borders on and off in order to create the illusion of the inner grid lines. What to do? Attack of the filler <b>s! If we want to create standalone styles that follow grid tracks—that is, presentation aspects that aren’t directly linked to the possibly-rearranged content—then we need other elements to place and style. They likely won’t have any content, making them a sort of structural filler to spackle over the gaps in Grid’s capabilities. Thus, to the   element, we can add two   elements with identifiers. These “filler  s,” as I like to call them, could be placed anywhere inside the  , but the beginning works fine. We’ll stick with that. Then we add these styles to our original grid from  : The   means “go from the first grid line to the last grid line of  ”, regardless of how many grid lines there might be. It’s a handy pattern to use in any situation where you have a grid item meant to stretch from edge to edge of a grid. So the horizontal   has top and bottom borders, and the vertical   has left and right borders. This creates the board lines, as shown in Figure 3. Hold on a minute: we got the tic-tac-toe grid back, but now the numbers are in the wrong places, which means the  s that contain them are out of place. Here’s why: the   elements holding the actual content will no longer auto-flow into all the grid cells, because the filler  s are already occupying five of the nine cells. (They’re the cells in the center column and row of the grid.) The only way to get the   elements into their intended grid cells is to explicitly place them. This is one way to do that: That works if you know the content will always be laid out in row-then-column order. Switching to column-then-row requires rewriting the CSS. If the contents are to be placed in a jumbled-up order, then you’d have to write a rule for each  . This probably suffices for most cases, but let’s push this even further. Suppose you want to draw those grid lines without interfering with the automatic flow of the contents. How can this be done? Overgridding It would be handy if there were a property to mark elements as not participating in the grid flow, but there isn’t. So instead, we’ll split the contents and filler into their own grids, and use a third grid to put one of those grids over the other. This will necessitate a bit of structural change to make happen, because for it to work, the contents and the filler  s have to have identical grids. Thus we end up with: The first thing is to give the board and the content  s identical grids. The same grid we used before, in fact. We just change the   rule’s selector a tiny bit, to select the children of   instead: Now that the two grids have the same layout, we need to place one over the other. We could relatively position the   container and absolutely position its children, but there’s another way: use Grid. But wait—where are the rows and columns for  ? Where we’re going, we don’t need rows (or columns). Here is how the two grids end up occupying the same area with one on top of the other: So   is given a one-cell grid, and its two children are explicitly placed in that single cell. Thus one sits over the other, as with positioning—but unlike positioning, the outer grid’s size is dictated by the layout of its children. It will resize to surround them, even if we later change the inner grids to be larger (or smaller). We can see this in practice in Figure 4, where the outer grid is outlined in purple in Firefox’s Grid inspector tool. And that’s it. We could take further steps, like using   to layer the board on top of the content (by default, the element that comes later in the source displays on top of the element that comes earlier), but this will suffice for the case we have here. The advantage is that the content  , having only its own contents to worry about, can make use of   and   to rearrange things. As an example, you can do things like the following and you won’t need all of the   grid item placements from our earlier CSS. Figure 5 shows the result. Caveats The downside here, and it’s a pretty big one, is that the board and content grids are only minimally aware of each other. The reason the previous example works is the grid tracks are of fixed size, and none of the content is overflowing. Suppose we wanted to make the columns and rows resize based on content, like this: This will fall apart quickly, with the board lines not corresponding to the layout of the actual content. At all. In other words, this overlap technique sacrifices one of Grid’s main strengths: the way grid cells relate to other grid cells. In cases where content size is predictable but ordering is not, it’s a reasonable trade-off to make. In other cases, it probably isn’t a good idea. Bear in mind that this really only works with layouts where sizes and placements are always known, and where you sometimes have to layer grids on top of one another. If your Filler   comes into contact with an implicitly-placed grid item in the same grid as it occupies, it will be blocked from stretching. (Explicitly-placed grid items, i.e., those with author-declared values for both   and  , do not block Filler  s.) Why is this useful? I realize that few of us will need to create a layout that looks like a tic-tac-toe board, so you may wonder why we should bother. We may not want octothorpe-looking structures, but there will be times we want to style an entire column track or highlight a row. Since CSS doesn’t (yet) offer a way to style grid cells, areas, or tracks directly, we have to stretch elements over the parts we want to style independently from the elements that contain content. There is   directly to CSS in the Working Group’s GitHub repository, where   can add your thoughts and proposals. But why  ? Why? I use  s for the decorative portions of the layout because they’re purely decorative elements. There’s no content to strongly emphasize or to boldface, and semantically a   isn’t any better or worse than a  . It’s just a hook on which to hang some visual effects. And it’s shorter, so it minimizes page bloat (not that a few characters will make all   much of a difference). More to the point, the  ’s complete lack of semantic meaning instantly flags it in the markup as being intentionally non-semantic. It is, in that meta sense, self-documenting. Is this all there is? There’s another way to get this precise effect: backgrounds and grid gaps. It comes with its own downsides, but let’s see how it works first. First, we set a black background for the grid container and white backgrounds for each item in the grid. Then, by using  , the black container background shows between the grid items. Simple, no Filler  s needed. What’s not to like? The first problem is that if you ever remove an item, there will be a big black block in the layout. Maybe that’s OK, but more likely it isn’t. The second problem is that grid containers do not, by default, shrink-wrap their items. Instead, they fill out the parent element, as block boxes do. Both of these problems are illustrated in Figure 6. You can use extra CSS to restrict the width of the grid container, but the background showing through where an item is missing can’t really be avoided. On the other hand, these problems could become benefits if, instead of a black background, you want to show a background image that has grid items “punch out” space, as Jen Simmons  . A third problem with using the backgrounds is when you just want solid grid lines over a varied page background, and you want that background to show through the grid items. In that case, the grid items (the  s in this case) have to have transparent backgrounds, which prevents using grid-gap to reveal a color. If the  s   chap your cerebellum, you can use generated content instead. When you generate before- and after-content pseudo-elements, Grid treats them as actual elements and makes them grid items. So using the simple markup used in the previous example, we could write this CSS instead: It’s the same as with the Filler  s, except here the generated elements draw the grid lines. This approach works just fine for any 3×3 grid like the one we’ve been playing with, but to go any further, you’ll need to get more complicated. Suppose we have a 5×4 grid instead of a 3×3. Using gradients and repeating, we can draw as many lines as needed, at the cost of more complicated CSS. This works pretty well, as shown in Figure 7, assuming you go through the exercise of explicitly assigning the grid cells similar to how  . This approach uses linear gradients to construct almost-entirely transparent images that have just a 1/20th of an em of black, and then repeating those either to the right or to the bottom. The downward gradient (which creates the horizontal lines) is stopped one gridline short of the bottom of the container, since otherwise there would be a horizontal line below the last row of items. Similarly, the rightward gradient (creating the vertical lines) stops one column short of the right edge. That’s why there are -2 values for   and  . One downside of this is the same as the Filler   approach: since the generated elements are covering most of the background, all the items have to be explicitly assigned to their grid cells instead of letting them flow automatically. The only way around this is to use something like the overgridding technique explored earlier. You might even be able to drop the generated elements if you’re overgridding, depending on the specific situation. Another downside is that if the font size ever changes, the width of the lines can change. I expect there’s a way around this problem using  , but I’ll leave that for you clever cogs to work out and share with the world. The funny part to me is that if you   use this gradient-based approach, you’re filling images into the background of the container and placing items over that … just as we did with Faux Columns. Conclusion It’s funny how some concepts echo through the years. More than a decade ago, Dan Cederholm   with background images. Now I’m showing you how to fake full-length column and row boxes with empty elements and, when needed, background images. Over time, the trick behind Faux Columns fell out of favor, and web design moved away from that kind of visual effect. Perhaps the same fate awaits Faux Grid Tracks, but I hope we see new CSS capabilities arise that allow this sort of effect without the need for trickery. We’ve outgrown so many of our old tricks. Here’s another to use while it’s needed, and to hopefully one day leave behind. Like this: \n\t\t\t\t\t\t\tRecently by  Eric Meyer\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-best-request-is-no-request-revisited/", "title": "The Best Request Is No Request, Revisited", "content": "Over the last decade, web performance optimization has been controlled by one indisputable guideline: the best request is no request. A very humble rule, easy to interpret. Every network call for a resource eliminated improves performance. Every   attribute spared, every   element dropped. But everything has changed now that  , hasn’t it? Designed for the modern web, HTTP/2 is more efficient in responding to a larger number of requests than its predecessor. So the question is: does the old rule of reducing requests still hold up? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What has changed with HTTP/2? To understand how HTTP/2 is different, it helps to know about its predecessors. A brief history follows. HTTP builds on TCP. While TCP is powerful and is capable of transferring lots of data reliably, the way HTTP/1 utilized TCP was inefficient. Every resource requested required a new TCP connection. And every TCP connection required synchronization between the client and server, resulting in an initial delay as the browser established a connection. This was OK in times when the majority of web content consisted of unstyled documents that didn’t load additional resources, such as images or JavaScript files. Updates in HTTP/1.1 try to overcome this limitation. Clients are able to use one TCP connection for multiple resources, but still have to download them in sequence. This so-called “head of line blocking” makes waterfall charts actually look like waterfalls: Also, most browsers started to open multiple TCP connections in parallel, limited to a rather low number per domain. Even with such optimizations, HTTP/1.1 is not well-suited to the considerable number of resources of today’s websites. Hence the saying “The best request is no request.” TCP connections are costly and take time. This is why we use things like concatenation, image sprites, and inlining of resources: avoid new connections, and reuse existing ones. HTTP/2 is fundamentally different than HTTP/1.1. HTTP/2 uses a single TCP connection and allows more resources to be downloaded in parallel than its predecessor. Think of this single TCP connection as one broad tunnel where data is sent through in  . On the client, all packages get reassembled into their original source. Using a couple of   elements to transfer style sheets is now as practically efficient as bundling all of your style sheets into one file. All connections use the same stream, so they also share bandwidth. Depending on the number of resources, this might mean that individual resources could take longer to be transmitted to the client side on low-bandwidth connections. This also means that resource prioritization is not done as easily as it was with HTTP/1.1: the order of resources in the document had an impact on when they begin to download. With HTTP/2, everything happens at the same time!  , but at the time of this writing, placing control over prioritization in developers’ hands is still in the distant future. The best request is no request: cherry-picking So what can we do to overcome the lack of waterfall resource prioritization? What about not wasting bandwidth? Think back to the first rule of performance optimization: the best request is no request. Let’s reinterpret the rule. For example, consider a typical webpage (in this case, from Dynatrace). The screenshot below shows a piece of online documentation consisting of different components: main navigation, a footer, breadcrumbs, a sidebar, and the main article. On other pages of the same site, we have things like a masthead, social media outlets, galleries, or other components. Each component is defined by its own markup and style sheet. In HTTP/1.1 environments, we would typically combine all component style sheets into one CSS file. The best request is no request: one TCP connection to transfer all the CSS necessary, even for pages the user hasn’t seen yet. This can result in a huge CSS file. The problem is compounded when a site uses a library like Bootstrap, which reached the 300 kB mark, adding site-specific CSS on top of it. The   amount of CSS required by any given page, in some cases, was even   of the amount loaded: There are even tools like   that aim to get rid of unused styles. The Dynatrace documentation example shown in figure 3 is built with the  , which is tailored to the site’s specific needs as opposed to Bootstrap, which is offered as a general purpose solution. All components in the company style library combined add up to 80 kB of CSS. The CSS actually used on the page is divided among eight of those components, totaling 8.1 kB. So even though the library is tailored to the specific needs of the website, the page still uses only around 10% of the CSS it downloads. HTTP/2 allows us to be much more picky when it comes to the files we want to transmit. The request itself is not as costly as it is in HTTP/1.1, so we can safely use more   elements, pointing directly to the elements used on that particular page: This, of course, is true for every sprite map or JavaScript bundle as well. By just transferring what you actually need, the amount of data transferred to your site can be reduced greatly! Compare the download times for bundle and single files shown with Chrome timings below: The first image shows that including the time required for the browser to establish the initial connection, the bundle needs about 700 ms to download on regular 3G connections. The second image shows timing values for one CSS file out of the eight that make up the page. The beginning of the response (TTFB) takes as long, but since the file is a lot smaller (less than 1 kB), the content is downloaded almost immediately. This might not seem impressive when looking at only one resource. But as shown below, since all eight style sheets are downloaded in parallel, we still can save a great deal of transfer time when compared to the bundle approach. When running the same page through   on regular 3G, we can see a similar pattern. The full bundle ( ) starts to download just after 1.5 s (yellow line) and takes 1.3 s to download; the   is around 3.5 seconds (green line):  When we split up the CSS bundle, each style sheet starts to download at 1.5 s (yellow line) and takes 315–375 ms to finish. As a result, we can reduce the time to first meaningful paint by more than one second (green line): Per our measurements, the difference between bundled and split files has more impact on slow 3G than on regular 3G. On the latter, the bundle needs a total of 4.5 s to be downloaded, resulting in a time to first meaningful paint at around 7 s: The same page with split files on slow 3G connections via webpagetest.org results in meaningful paint (green line) occurring 4 s earlier: The interesting thing is that what was considered a performance anti-pattern in HTTP/1.1—using lots of references to resources—becomes a best practice in the HTTP/2 era. Plus, the rule stays the same! The meaning changes slightly. The best request is no request: drop files and code your users don’t need! It has to be noted that the success of this approach is strongly connected to the number of resources transferred. The example above used 10% of the original style sheet library, which is an enormous reduction in file size. Downloading the whole UI library in split-up files might give different results. For example,   found that by splitting up their JavaScript bundles, the overall application size—and thus the transfer time–became drastically worse. This was mainly because of two reasons: a huge amount of JavaScript files (close to 100), and the often underestimated powers of Gzip. Gzip (and Brotli) yields higher compression ratios when there is repetition in the data it is compressing. This means that a Gzipped bundle typically has a much smaller footprint than Gzipped single files. So if you are going to download a whole set of files anyway, the compression ratio of bundled assets might outperform that of single files downloaded in parallel. Test accordingly. Also, be aware of your user base. While HTTP/2 has been  , some of your users might be limited to HTTP/1.1 connections. They will suffer from split resources. The best request is no request: caching and versioning To this point with our example, we’ve seen how to optimize the first visit to a page. The bundle is split up into separate files and the client receives only what it needs to display on a page. This gives us the chance to look into something people tend to neglect when optimizing for performance: subsequent visits. On subsequent visits we want to avoid re-transferring assets unnecessarily. HTTP headers like   (and their implementation in servers like   and  ) allow us to store files on the user’s disk for a specified amount of time. Some CDN servers default that to a few minutes. Some others to a few hours or days even. The idea is that during a session, users shouldn’t have to download what they already have in the past (unless they’ve cleared their cache in the interim). For example, the following Cache-Control header directive makes sure the file is stored in any cache available, for 600 seconds. We can leverage Cache-Control to be much more strict. In our first optimization we decided to cherry-pick resources and be choosy about what we transfer to the client, so let’s store these resources on the machine for a long period of time: The number above is one year in seconds. The usefulness in setting a high Cache-Control   value is that the asset will be stored by the client for a long period of time. The screenshot below shows a waterfall chart of the first visit. Every asset of the HTML file is requested: With properly set Cache-Control headers, a subsequent visit will result in less requests. The screenshot below shows that all assets requested on our test domain don’t trigger a request. Assets from another domain with improperly set Cache-Control headers still trigger a request, as do resources which haven’t been found: When it comes to invalidating the cached asset (which, consequently, is one of  ), we simply use a new asset instead. Let’s see how that would work with our example.  . A new file name triggers a new download. Previously, we split up our code base into reasonable chunks. A version indicator makes sure that each file name stays unique: After a change to our article styles, we would modify the version number: An alternative to keeping track of the file’s version is to set   with automation tools. It’s OK to store your assets on the client for a long period of time. However, your HTML should be more transient in most cases. Typically, the HTML file contains the information about which resources to download. Should you want your resources to change (such as loading article.v2.css instead of article.v1.css, as we just saw), you’ll need to update references to them in your HTML. Popular CDN servers cache HTML for no longer than six minutes, but you can decide what’s better suited for your application. And again, the best request is no request: store files on the client as long as possible, and don’t request them over the wire ever again. Recent Firefox and Edge editions even sport  , targeting this pattern specifically. Bottom line HTTP/2 has been designed from the ground up to address the inefficiencies of HTTP/1. Triggering a large number of requests in an HTTP/2 environment is no longer inherently bad for performance; transferring unnecessary data is. To reach the full potential of HTTP/2, we have to look at each case individually. An optimization that might be good for one website can have a negative effect on another. With all the benefits that come with HTTP/2 , the golden rule of performance optimization still applies: the best request is no request. Only this time we take a look at the actual amount of data transferred. Only transfer what your users actually need. Nothing more, nothing less. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-hidden-work-of-content/", "title": "How the Sausage Gets Made: The Hidden Work of Content", "content": "I won an Emmy for keeping a website free of dick pics. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Officially, my award certificate says I was on a team that won a 2014 Emmy for Interactive Media, Social TV Experience. The category “Social TV Experience” sounds far classier than my true contribution to the project. The award-winning Live From Space site served as a second-screen experience for a National Geographic Channel show of the same name. The show   covered the wonders of the International Space Station. The website displayed the globe as seen by astronauts, along with entertaining social data about each country crossed by the Space Station’s trajectory. One of those data points was an Instagram feed showcasing images of local cuisine. You might think that adding this feed was a relatively simple task. Include a specific channel, or feed in images tagged with the food and the country in which the images were taken, connect to an API, and boom: a stream of images from food bloggers in South Africa, Taiwan, Mexico, what have you. One exec was so impressed that he called this feature “automagical.” What he described as “automagical” was actually me sitting in front of a computer screen, scanning Instagram, hunting for the most appetizing images, avoiding the unappetizing ones, and pasting my choices into a spreadsheet for import by a developer. I wouldn’t call it automated, and I wouldn’t call it magical. As the team’s content manager, I performed this task because the Instagram API wasn’t playing nice with the developers, but we had to get that information into the site by the deadline somehow. An additional, and perhaps worse, problem was that if you found a feed of images taken in certain countries and tagged #food, you might get pictures of sausage. But we’re talking about the kinds of sausages usually discussed in locker rooms or on school buses full of junior high boys. As you can imagine, you cannot add Instagram photos tagged #food to a family-friendly site without a little effort, either in terms of getting around an API or filtering out the naughty bits. The mythical “automagical” tool You might think I’m knocking the website, but I’m not. Many creative, brilliant people worked ridiculous hours to create a gorgeous experience for which they rightly earned an award, and the images of local cuisine made up only a small slice of the site’s data. Yet I feel conflicted about my own involvement with Live From Space because most of the site’s users still have no idea how the sausage of apps and websites gets made. In fact, these people may never know because the site is no longer live. Or they may not care. Few people are aware of the rote work that goes into moving or importing data from one website to another, which causes problems if they don’t understand how long the process takes to make content happen. Unless you’re working with a pristine data source, there often is no “content hose” or “automagical” tool that cleans up data and moves it from one app or content management system to another. Unfortunately, the assumption that a “content hose” exists can lead to miscommunication, frustration, and delays when it is time to produce the work. Oftentimes, a person will need to go in, copy content, and paste that code into the new app or CMS. They must repeat this task until the app or site is ready for launch. This type of work usually spurs revolt within the workplace, and I can’t say I blame people for being upset. Unless you know some tips, tricks, and shortcuts, as I do, you have a long stretch of tedious, mind-numbing work ahead of you. Did someone say shortcuts? Yes, you do have shortcuts when it comes to pulling content into a website. Those shortcuts happen earlier in the site-building process than you may think, and they rely on making sure your entire team is involved in the content process. The most important thing when you are creating a new site or migrating an existing one is to lock down the content you want to bring in, as early as possible.  In the case of the National Geographic Channel website, the team knew it needed the map data and the coordinates, but did it really need the Instagram feed with the food data? And, when the creative team decided it needed the food data, did anyone ask questions about how the food data would be drawn into the site?  This involves building tactical questions into the creative workflow. When someone is on a creative roll, the last thing I want to do is slow them down by asking overly tactical questions. But all brainstorming sessions should include a team member who is taking notes as the ideas fly so they can ask the crucial questions later: Where will this content come from? Do we have a team member who can generate this content from a data feed or from scratch? If not, do we need to hire someone? These questions are nothing new to a content strategist, but the questions must be asked in the earliest stages of the project. Think about it: if your team is in love with an idea, and the client falls in love with it, too, then you will have a harder time changing course if you can’t create the content that makes the site run. Site updates and migrations are a little bit different in that most of the content exists, but you’d be surprised by how few team members know their content. Right now, I am working for a company that helps universities revamp their considerably large websites, and the first thing we do when making the sausage is halve the recipe. First, we use   to generate a content inventory, which we spot-check for any unusual features that might need to be incorporated into the new site. Then we pass the inventory to the client, asking them to go through the inventory and archive duplicate or old content. Once they archive the old content, they can focus on what they intend to revise or keep as is. During the first few weeks of any project, I check in with the client about how they are doing with their content archive. If they aren’t touching the content early, we schedule a follow-up meeting and essentially haunt them until they make tough decisions. Perfecting the process How do we improve the way our teams relate to content? How do we show them how the content sausage gets made without grossing anyone out? Here are a few tips:  “Content strategist” isn’t a fancy name for a writer or an editor. A good content strategist knows how to work with developers. For one site migration involving a community college, I used Screaming Frog to scrape the content from the original site. Then I passed the resulting .csv document back and forth to the developer, fine-tuning the alignment of fields each time so it would be easier for us to import the material into  , an editorial tool for digital projects.  GatherContent allows you to assign specific tasks to team members so you can divide work. Even better, GatherContent’s editorial tool allows each page to pass through specific points in the editorial process, including drafting, choosing pictures, adding tags, and uploading to the CMS.   In my current workplace, not only do we train the client on how to use the CMS, but we also provide Content Guidelines, an overview of the basic building blocks that make up a web page. I’ve shown clients how to create fields for page metadata, images, image alt text, and downloads—and we do this early so the client doesn’t wait until the last minute to dive into details.  Clever uses of tools and advance training can only go so far. At some point you will need to make sure that what is in the CMS lines up with what you intended. You may need to take your content source, remove any odd characters, shift content from one field to another, and make the content safe for work—just like removing dick pics.  Distributing the work ensures that your team members think twice before recommending content that doesn’t exist or content that needs a serious cleanup. That means each team member should sit down and copy content directly into the CMS or scrub the content that is there. An hour or two is enough to transform perspectives.  Occasionally, you will encounter people who believe their roles protect them from content. I’ve heard people ask, “Can’t we get an intern to do that?” or “Can’t we do that through Mechanical Turk?” Sometimes, these people mean well and are thinking of efficiency, but other times, their willingness to brush content off as an intern task or as a task worth a nickel or two should be alarming. It’s demeaning to those who do the work for starters, but it also shows that they are cavalier about content. Asking someone to pitch in for content creation or migration is a litmus test. If they don’t seem to take content seriously, you have to ask: just how committed are these people to serving up a quality digital experience? Do you even want them on your team in the future? By the way, I’ve seen VPs and sales team members entering content in a website, and every last one of them told me that the experience was eye-opening. People are the “automagical” ingredient None of these shortcuts and process tips are possible without some kind of hidden content work. Content is often discussed in terms of which gender does what kind of work and how they are recognized for it. This  , especially in the context of social media, but I’d like to step back and think about why this work is hidden and how we can avoid delays, employee revolts, and overall tedium in the future. Whether you’re scraping, scrubbing, copying, or pasting, the connecting thread for all hidden content work is that nearly no one thinks of it until the last minute. In general, project team members can do a better job of thinking about how content needs to be manipulated to fit a design or a data model. Then they should prepare their team and the client for the amount of work it will take to get content ready and entered into a site. By taking the initiative, you can save time, money, and sanity. If you’re really doing it right, you can make a site that’s the equivalent of a sausage … without dubious ingredients. Like this: \n\t\t\t\t\t\t\tRecently by Caroline Roberts\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/my-grandfathers-travel-logs-and-other-repetitive-tasks/", "title": "My Grandfather’s Travel Logs and Other Repetitive Tasks", "content": "My grandfather, James, was a meticulous recordkeeper. He kept handwritten journals detailing everything from his doctor visits to the daily fluctuations of stocks he owned. I only discovered this part of his life seven years after his death, when my family’s basement flooded on Christmas Eve in 2011 and we found his journals while cleaning up the damage. His travel records impressed me the most. He documented every trip he ever took, including dates, countries and cities visited, methods of travel, and people he traveled with. In total, he left the United States 99 times, visited 80 countries, and spent 1,223 days at sea on 48 ships. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I was only twenty-four when he died, so I hadn’t yet realized that I’d inherited many of his record-keeping, journaling, and collecting habits. And I had never had the chance to ask him many questions about his travels (like why he went to Venezuela twelve times or what he was doing in Syria and Beirut in the 1950s). So, in an effort to discover more about him, I decided to make an infographic of his travel logs. Today, we take for granted that we can check stocks on our phones or go online and view records from doctor visits. The kinds of repetitive tasks my grandfather did might seem excessive, especially to young web developers and designers who’ve never had to do them. But my grandfather had no recording method besides pencil and paper for most of his life, so this was a normal and especially vital part of his daily routine. Whether you’re processing Sass, minifying, or using Autoprefixer, you’re using tools to perform mundane and repetitive tasks that people previously had to do by hand, albeit in a different medium.  But what do you do when you’re faced with a problem that can’t be solved with a plugin, like my grandfather’s travel data? If you’re a designer, what’s the best way to structure unconventional data so you can just focus on designing? My idea for the travel web app was to graph each country based on the number of my grandfather’s visits. As the country he visited the most (twenty-two times), Bermuda would have a graph bar stretching 100 percent across the screen, while a country he visited eleven times (St. Thomas, for example) would stretch roughly 50 percent across, the proportions adjusted slightly to fit the name and visits. I also wanted each graph bar to be the country’s main flag color.  The big issue to start was that some of the data was on paper and some was already transcribed into a text file. I could have written the HTML and CSS by hand, but I wanted to have the option to display the data in different ways. I needed a JSON file. I tediously transcribed the remaining travel data into a tab-separated text file for the countries. I added the name, number of visits, and flag color: For the ships, I added the date and name: Manually creating a JSON file would have taken forever, so I used JavaScript to iterate through the text files and create two separate JSON files—one for countries and one for ships—which I would later merge. First, I used Node   and   to remove any quotation marks at the end of the file so as to avoid an empty object in the results: This returned the contents of the   file and stored it in a variable called  . At that point, I outputted the variable to the console, which showed that the data was lumped together into one giant string with a bunch of tabs ( ) and newlines ( ): Next, I split the string at the line breaks ( ): After  , in the console, the countries’ data lived in an array: I wanted to split each item of country data at the tabs, separating the name, number of visits, and color. To do this, I used  , which iterates and runs a function on each item, returning something new. In this case, it split the string at each tab it found and returned a new array: After I used  ,   was an array of arrays with each country and its data split into separate items: To create the final output for each country, I used  , which uses an accumulator and a function to create something new, whether that’s an object, a value, or an array. Accumulator is a fancy way of referring to the end product, which in our case is an object ( ). I knew I wanted   to contain the data. So instead of creating it on the first pass and testing whether it existed on each iteration, I added   to the resulting object. That way, it existed before I started iterating. This process returned an empty object because I hadn’t told   what to do with each array of data.  To fix this, I used   to push and add a new object for each country with the name ( ), visits ( ), and color ( ) into the end result object. Finally, I used a capitalization function on each name value to ensure formatting would be consistent. I used the same method for the   file and merged the two using  , a method that takes two objects and creates a new one. I could have created a function that took a text file and an object, or created a form-to-JSON tool, but these seemed like overkill for this project, and I had already transcribed some of the data into separate files before even conceiving of the infographic idea. The final JSON result  . I used the JSON data to create the infographic bars, defining the layout for each one with CSS Grid and dynamic styles for width and color. Check out the final product at  . I think my grandfather would have enjoyed seeing his handwritten logs transformed into a visual format that showcases the breadth of his travels. He passed away in 2005, but I remember showing him my Blackberry and explaining the internet to him, showing him how he could look at pictures from around the world and read articles. He took a sip of his martini and sort of waved his hand at the screen. I think he preferred handwritten notes and life outside of the internet, something many of us can  appreciate. After sifting through all his travel logs, I more clearly understood the importance he placed on having different experiences, meeting new people, and fearlessly exploring the world. To him, his travels were more than just dates on a page. Now they’re more than that for me, too. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/discovery-on-a-budget-part-i/", "title": "Discovery on a Budget: Part I", "content": "If you crack open any design textbook, you’ll see some depiction of the design cycle: discover, ideate, create, evaluate, and repeat. Whenever we bring on a new client or start working on a new feature, we start at the top of the wheel with discover (or discovery). It is the time in the project when we define what problem we are trying to solve and what our first approach at solving it should be.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. We commonly talk about discovery at the start of a sprint cycle at an established business, where there are things like budgets, product teams, and existing customers. The discovery process may include interviewing stakeholders or pouring over existing user data. And we always exit the discovery phase with some sort of idea to move forward with.  However, discovery is inherently different when you work at a nonprofit, startup, or fledgling small business. It may be a design team of one (you), with zero dollars to spend, and only a handful of people aware the business even exists. There are no clients to interview and no existing data to examine. This may also be the case at large businesses when they want to test the waters on a new direction without overcommitting (or overspending). Whenever you are constrained on budget, data, and stakeholders, you need to be flexible and crafty in how you conduct discovery research. But you can’t skimp on rigor and thoroughness. If the idea you exit the discovery phase with isn’t any good, your big launch could turn out to be a business-ending flop.  In this article I’ll take you through a discovery research cycle, but apply it towards a (fictitious) startup idea. I’ll introduce strategies for conducting discovery research with no budget, existing user data, or resources to speak of. And I’ll show how the research shapes the business going forward.  Write up the problem hypothesis An awful lot of ink (virtual or otherwise) has been spent on proclaiming we should all, “ .” And it has been ink spent well. When it comes to product building, a problem-focused philosophy is the cornerstone of any user-centric business.  But how, exactly, do you know when you have a problem worth solving? If you work at a large, established business you may have user feedback and data pointing you like flashing arrows on a well-marked road towards a problem worth solving. However, if you are launching a startup, or work at a larger business venturing into new territory, it can be more like hiking through the woods and searching for the next blaze mark on the trail. Your ideas are likely based on personal experiences and gut instincts.  When your ideas are based on personal experiences, assumptions, and instincts, it’s important to realize they need a higher-than-average level of tire-kicking. You need to evaluate the question “Do I have a problem worth solving?” with a higher level of rigor than you would at a company with budget to spare and a wealth of existing data. You need to take all of your ideas and assumptions and examine them thoroughly. And the best way to examine your ideas and categorize your assumptions is with a hypothesis.  As the dictionary describes, a   is “a supposition or proposed explanation made on the basis of limited evidence as a starting point for further investigation.” That also serves as a good description of why we do discovery research in the first place. We may have an idea that there is a problem worth solving, but we don’t yet know the scope or critical details. Articulating our instincts, ideas, and assumptions as a   lays a foundation for the research moving forward. Here is a general formula you can use to write a problem hypothesis: Because [assumptions and gut instincts about the problem], users are [in some undesirable state]. They need [solution idea]. For this article, I decided to “launch” a fictitious (and overly ambitious) startup as an example. Here is the problem hypothesis I wrote for my startup: Because their business model relies on advertising, social media tools like Facebook are deliberately designed to “hook” users and make them addicted to the service. Users are unhappy with this and would rather have a healthier relationship with social media tools. They would be willing to pay for a social media service that was designed with mental health in mind. You can see in this example that my assumptions are: Users feel that social media sites like Facebook are addictive. Users don’t like to be addicted to social media. Users would be willing to pay for a non-addictive Facebook replacement.  These are the assumptions I’ll be researching and testing throughout the discovery process. If I find through my research that I cannot readily affirm these assumptions, it means I might not be ready to take on Mr. Zuckerberg just yet.  The benefit of articulating our assumptions in the form of a hypothesis is that it provides something concrete to talk about, refer to, and test. The whole product team can be involved in forming the initial problem hypothesis, and you can refer back to it throughout the discovery process. Once we’ve completed the research and analyzed the results, we can edit the hypothesis to reflect our new understanding of our users and the problems we want to solve.  Now that we’ve articulated a problem hypothesis, it is time to figure out our research plan. In the following two sections, I’ll cover the research method I recommend the most for new ventures, as well as strategies for recruiting participants on a budget.  A method that is useful in all phases of design: interviews In my career as a user researcher, I have used all sorts of methods. I’ve done A/B testing, eye tracking, Wizard of Oz testing, think-alouds, contextual inquiries, and guerilla testing. But the one research method I utilize the most, and that I believe provides the most “bang for the buck,” is user interviews.  User interviews are relatively inexpensive to conduct. You don’t need to travel to a client site and you don’t need a fortune’s worth of equipment. If you have access to a phone, you can conduct an interview with participants all around the world. Yet interviews provide a wealth of information and can be used in every phase of research and design. Interviews are especially useful in discovery, because it is a method that is adaptable. As you learn more about the problem you are trying to solve, you can adapt your interview protocol to match.  To be clear, your interviewees will   tell you: what to build; or how to build it. But they absolutely   tell you: what problem they have; how they feel about it; and what the value of a solution would mean to them. And if you know the problem, how users feels about it, and the value of a solution, you are well on your way to designing the right product.  The challenge of conducting a good user interview is making sure you ask the questions that elicit that information. Here are a couple tips: “What do you like about [blank]?” “What do you dislike about [blank]?” … where you fill “[blank]” with whatever domain your future product will improve. Your objective is to gain an understanding of all aspects of the problem your potential customers face—the bad   the good. One common mistake is to spend too much time investigating what’s wrong with the current state of affairs. Naturally, you want your product to fix all the problems your customers face. However, you also need to preserve what currently works well, what is satisfying, or what is otherwise good about how users accomplish their goals currently. So it is important to ask about both in user interviews. For example, in my interviews I always asked, “What do you like about using Facebook?” And it wasn’t until my interview participant told me everything they enjoyed about Facebook that I would ask, “What do you dislike about using Facebook?” The goal of conducting interviews is to gain an exhaustive set of data to review and consider moving forward. That means you don’t want your participants to discuss   thing they like and dislike, you want them to tell you   the things they like and dislike. Here is an example of how this played out in one of the interviews I conducted: : What do you like about using Facebook? : I like seeing people on there that I wouldn’t otherwise get a chance to see and catch up with in real life. I have moved a couple times so I have a lot of friends that I don’t see regularly. I also like seeing the people I know do well, even though I haven’t seen them since, maybe, high school. But I like seeing how their life has gone. I like seeing their kids. I like seeing their accomplishments. It’s also a little creepy because it’s a window into their life and we haven’t actually talked in forever. But I like staying connected. : What else do you like about it? : Um, well it’s also sort of a convenient way of keeping contacts. There have been a few times when I was able to message people and get in touch with people even when I don’t have their address or email in my phone. I could message them through Facebook. : Great. Is there anything else you like about it? : Let me think … well I also find cool stuff to do on the weekends there sometimes. They have an events feature. And businesses, or local places, will post events and there have been a couple times where I’ve gone to something cool. Like I found a cool movie festival once that way. : That seems cool. What else do you like about using Facebook? : Uh … that’s all I think I really use it for. I can’t really think of anything else. Mainly I use it just to keep in touch with people that I’ve met over the years. From this example you can see the first feature that popped into the interviewee’s mind was their ability to keep up with friends that they otherwise wouldn’t have much opportunity to connect with anymore. That is a feature that any Facebook replacement would have to replicate. However, if I hadn’t pushed the interviewee to think of even more features they like, I might have never uncovered an important secondary feature: convenient in-app messaging. In fact, six out of the eleven people I interviewed for this project said they liked Facebook Messenger. But not a single one of them mentioned that feature  . It only came up in conversation after I probed for more. As I continued to repeat my question, the interviewee thought of one more feature they liked: local event listings. (Five out of the eleven people I interviewed mentioned this feature.) But after that, the interviewee couldn’t think of any more features to discuss. You know you can move on to the next question in the interview when your participant starts to repeat themselves or bluntly tells you they have nothing else to say. Recruit all around you, then document the bias There are all sorts of ways to recruit participants for research. You can hire an agency or use a tool like UserTesting.com. But many of those paid-for options can be quite costly, and since we are working with a shoestring budget we have roughly zero dollars to spend on recruitment. We will have to be creative.  For my project, I decided to rely on the kindness of friends and strangers I could reach through Facebook. I posted one request for participants on my personal Facebook page, and another on the  . A day after I posted my request, twenty-five friends and five strangers volunteered. This type of participant recruitment method is called  , because I was recruiting participants that were conveniently accessible to me. Since my project involved talking to people about social media sites like Facebook, it was appropriate for my first attempt at recruiting to start on Facebook. I could be sure that everyone who saw my request uses Facebook in some form or fashion. However, like all convenience sampling, my recruitment method was biased. (I’ll explain how in just a bit.) Bias is something that we should try—whenever possible—to avoid. If we have access to more sophisticated recruitment methods, we should use them. However, when you have a tight budget, avoiding recruitment bias is virtually impossible. In this scenario, our goals should be to: mitigate bias as best we can; and document all the biases we see. For my project, I could mitigate some of the biases by using a few more recruitment methods. I could go to various neighborhoods and try to recruit participants off the street (i.e., guerilla testing). If I had a little bit of money to spend, I could hang out in various coffee shops and offer folks free coffee in exchange for ten-minute interviews. These recruitment methods also fall under the umbrella of convenience sampling, but by using a variety of methods I can mitigate some of the bias I would have from using just one of them. Also, it is always important to reflect on and document how your sampling method is biased. For my project, I wrote the following in my notes: All of the people I interviewed were connected to me in some way on Facebook. Many of them I know well enough to be “friends” with. All of them were around my age, many (but not all) worked in tech in some form or fashion, and all of them but one lived in the US. Documenting bias ensures that we won’t   about the bias when it comes time to analyze and discuss the results. Let’s keep this going As the title suggests, this is just the first installment of a series of articles on the discovery process. In part two, I will analyze the results of my interviews, revise my problem hypothesis, and continue to work on my experimental startup. I will launch into another round of discovery research, but this time utilizing some different research methods, like A/B testing and fake-door testing. You can help me out by checking out this mock landing page for   (what I’ve named my fictitious startup) and taking the survey you see there. Like this: \n\t\t\t\t\t\t\tRecently by Meg Dickey-Kurdziolek\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/why-mutation-can-be-scary/", "title": "Why Mutation Can Be Scary", "content": "To   means to change in form or nature. Something that’s mutable can be changed, while something that’s immutable cannot be changed. To understand mutation, think of the X-Men. In X-Men, people can suddenly gain powers. The problem is, you don’t know when these powers will emerge. Imagine your friend turns blue and grows fur all of a sudden; that’d be scary, wouldn’t it? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In JavaScript, the same problem with mutation applies. If your code is mutable, you might change (and break) something without knowing. Objects are mutable in JavaScript In JavaScript, you can add properties to an object. When you do so after instantiating it, the object is changed permanently. It mutates, like how an X-Men member mutates when they gain powers. In the example below, the variable   mutates once you add the   property to it. We say that objects (like  ) are mutable (have the ability to  ). Mutation is pretty normal in JavaScript. You use it all the time. Let’s say you create a constant variable called   and assign   to it. Then you want to change the name of   to something else. When you change (mutate)  , did you know   gets mutated automatically? The example above illustrates why mutation can be scary—when you change one piece of your code, another piece can change somewhere else without your knowing. As a result, you’ll get bugs that are hard to track and fix. This weird behavior happens because objects are passed by reference in JavaScript. Objects are passed by reference in JavaScript To understand what “passed by reference” means, first you have to understand that each object has a unique identity in JavaScript. When you assign an object to a variable, you link the variable to the identity of the object (that is, you pass it by reference) rather than assigning the variable the object’s value directly. This is why when you compare two different objects, you get   even if the objects have the same value. When you assign   to  ,   points to the same object as  . Since   and   are the same thing, when you change  ,   gets changed automatically. Unfortunately, you don’t want   to change along with   most of the time, since it causes your code to break when you least expect it. So how do you prevent objects from mutating? Before you understand how to prevent objects from mutating, you need to know what’s immutable in JavaScript. Primitives are immutable in JavaScript In JavaScript, primitives (String, Number, Boolean, Null, Undefined, and Symbol) are immutable; you cannot change the structure (add properties or methods) of a primitive. Nothing will happen even if you try to add properties to a primitive.  doesn’t grant immutability Many people think that variables declared with   are immutable. That’s an incorrect assumption. Declaring a variable with   doesn’t make it immutable, it prevents you from assigning another value to it. When you declare an object with  , you’re still allowed to mutate the object. In the   example above, even though   is created with  ,   doesn’t prevent   from mutating. Preventing objects from mutating You can use   and assignment to prevent objects from mutating.  lets you combine two (or more) objects together into a single one. It has the following syntax:  will contain properties from all of the objects you’ve passed into  . If two conflicting properties are found, the property in a later object overwrites the property in an earlier object (in the   parameters). Solving the   mutation problem You can pass a new object as your first object to prevent existing objects from mutating. You’ll still mutate the first object though (the empty object), but that’s OK since this mutation doesn’t affect anything else. You can mutate your new object however you want from this point. It doesn’t affect any of your previous objects. But   copies references to objects The problem with   is that it performs a  —it copies properties directly from one object to another. When it does so, it also copies references to any objects. Let’s explain this statement with an example. Suppose you buy a new sound system. The system allows you to declare whether the power is turned on. It also lets you set the volume, the amount of bass, and other options. Some of your friends love loud music, so you decide to create a preset that’s guaranteed to wake your neighbors when they’re asleep. Then you invite your friends over for a party. To preserve your existing presets, you attempt to combine your loud preset with the default one. But   sounds weird. The volume is loud enough, but the bass is non-existent. When you inspect  , you’re surprised to find that there’s no bass in it! This happens because JavaScript copies over the reference to the   object. Since both   and   have a   object, the one that comes later gets copied into the new object. If you change  ,   will mutate accordingly—evidence that the reference to   gets copied over. Since   performs a shallow merge, you need to use another method to merge objects that contain nested properties (that is, objects within objects). Enter assignment. assignment  is a small library made by   from  , which is a great source for JavaScript knowledge. It helps you perform a deep merge without having to worry about mutation. Aside from the method name, the syntax is the same as  . assignment copies over values of all nested objects, which prevents your existing objects from getting mutated. If you try to change any property in   now, you’ll see that   remains as it was. assignment is just one of many libraries that help you perform a deep merge. Other libraries, including   and  , can help you do it, too. Feel free to choose from any of these libraries. Should you always use assignment over  ? As long as you know how to prevent your objects from mutating, you can use  . There’s no harm in using it as long as you know how to use it properly. However, if you need to assign objects with nested properties, always prefer a deep merge over  . Ensuring objects don’t mutate Although the methods I mentioned can help you prevent objects from mutating, they don’t guarantee that objects don’t mutate. If you made a mistake and used   for a nested object, you’ll be in for deep trouble later on. To safeguard yourself, you might want to guarantee that objects don’t mutate at all. To do so, you can use libraries like  . This library throws an error whenever you attempt to mutate an object. Alternatively, you can use   and deep-freeze. These two methods fail silently (they don’t throw errors, but they also don’t mutate the objects).  and deep-freeze  prevents direct properties of an object from changing. But it doesn’t help when you mutate a deeper property like  . To prevent a deep mutation, you can use a library called  , which recursively calls   on all objects. Don’t confuse reassignment with mutation When you reassign a variable, you change what it points to. In the following example,   is changed from   to  . When you mutate an object, it gets changed. The reference to the object stays the same. Wrapping up Mutation is scary because it can cause your code to break without your knowing about it. Even if you suspect the cause of breakage is a mutation, it can be hard for you to pinpoint the code that created the mutation. So the best way to prevent code from breaking unknowingly is to make sure your objects don’t mutate from the get-go. To prevent objects from mutating, you can use libraries like   and  , or use   and  . Take note that   and   can only prevent direct properties from mutating. If you need to prevent multiple layers of objects from mutating, you’ll need libraries like   and  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/no-more-faqs-create-purposeful-information-for-a-more-effective-user-experi/", "title": "No More FAQs: Create Purposeful Information for a More Effective User Experience", "content": "It’s normal for your website users to have recurring questions and need quick access to specific information to complete … whatever it is they came looking for. Many companies still opt for the ubiquitous FAQ (frequently asked/anticipated questions) format to address some or even all information needs. But FAQs often miss the mark because people don’t realize that creating effective user information—even when using the apparently simple question/answer format—is complex and requires careful planning. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As a technical writer and now information architect, I’ve worked to upend this mediocre approach to web content for more than a decade, and here’s what I’ve learned: instead of defaulting to an unstructured FAQ, invest in information that’s built around a comprehensive content strategy specifically designed to meet user and company goals. We call it  . The problem with FAQs Because of the internet’s Usenet heritage—discussion boards where regular contributors would produce FAQs so they didn’t have to repeat information for newbies—a lot of early websites started out by providing all information via FAQs. Well, the ‘80s called, and they want their style back!  Unfortunately, content in this simple format can often be attractive to organizations, as it’s “easy” to produce without the need to engage professional writers or comprehensively work on information architecture (IA) and content strategy. So, like zombies in a horror film, and with the same level of intellectual rigor, FAQs continue to pop up all over the web. The trouble is, this approach to documentation-by-FAQ has problems, and the information is about as far from being purposeful as it’s possible to get.  For example, when companies and organizations resort to documentation-by-FAQ, it’s often the only place certain information exists, yet users are unlikely to spend the time required to figure that out. Conversely, if information is duplicated, it’s easy for website content to get out of sync. The FAQ page can also be a dumping ground for any information a company needs to put on the website, regardless of the topic. Worse, the page’s format and structure can increase confusion and cognitive load, while including obviously invented questions and overt marketing language can result in losing users’ trust quickly. Looking at each issue in more detail: : Even on small websites, it can be hard to maintain information. On large sites with multiple authors and an unclear content strategy, information can get out of sync quickly, resulting in duplicate or even contradictory content. I once purchased food online from a company after reading in their FAQ—the content that came up most often when searching for allergy information—that the product didn’t contain nuts. However, on receiving the product and reading the label, I realized the FAQ information was incorrect, and I was able to obtain a refund. An information architecture (IA) strategy that includes clear pathways to key content not only better supports user information needs that drive purchases, but also reduces company risk. If you do have to put information in multiple locations, consider using an object-oriented content management system (CMS) so content is reused, not duplicated. (Our company open-sourced one called  .) : Humans want information to be ordered in ways they can understand, whether it’s alphabetical, time-based, or by order of operation, importance, or even frequency. The question format can disguise this organization by hiding the ordering mechanism. For example, I could publish a page that outlines a schedule of household maintenance tasks by frequency, with natural categories (in order) of daily, weekly, monthly, quarterly, and annually. But putting that information into an FAQ format, such as “How often should I dust my ceiling fan?,” breaks that logical organization of content—it’s potentially a stand-alone question. Even on a site that’s dedicated only to household maintenance, that information will be more accessible if placed within the larger context of maintenance frequency. : Users like to scan for information, so having repetitive phrases like “How do I …” that don’t relate to the specific task make it much more difficult for readers to quickly find the relevant content. In a lengthy help page with catch-all categories, like the  , users have to swim past a sea of “How do I …,” “Why can’t I …,” and “What do I …” phrases to get to the actual information. While categories can help narrow the possibilities, the user still has to take the time to find the most likely category and then the relevant question within it. The Patagonia website also shows how an FAQ section can become a catch-all. Oh, how I’d love the opportunity to restructure all that Patagonia information into purposeful information designed to address user needs at the exact right moment. So much potential! : As well as being repetitive, the question format can also be surprisingly specific, forcing users to mentally break apart the wording of the questions to find a match for   need. If a question appears to exclude the required information, the user may never click to see the answer, even if it is actually relevant. Answers can also raise additional, unnecessary questions in the minds of users. Consider the FAQ-formatted “Can I pay my bill with Venmo?” (which limits the answer to one payment type that only some users may recognize). Rewriting the question to “How can I pay my bill online?” and updating the content improves the odds that users will read the answer and be able to complete their task. However, an even better approach is to create purposeful content under the more direct and concise heading “Online payment options,” which is broad enough to cover all payment services (as a topic in the “Bill Payments” portion of a website), as well as instructions and other task-orientated information. : In most cases, questions have a longer line length than topic headings. The   illustrates when design and content strategy clash. The design truncates the question after 40 characters when the browser viewport is wider than 743 pixels. You have to click the question to find out if it holds the answer you need—far from ideal! Yet the heading “I’m a guest. How do I check the status of my reservation?” could easily have been rewritten as “Checking reservation status” or even “Guests: Checking reservation status.” Not only do these alternatives fit within the line length limitations set by the design, but the lower word count and simplified English also reduce translation costs (another issue some companies have to consider). Purposeful information Grounded in the   approach to technical documentation, the idea behind purposeful information is that users come to any type of content with a particular purpose in mind, ranging from highly specific (task completion) to general learning (increased knowledge). Different websites—and even different areas within a single website—may be aimed at different users and different purposes. Organizations also have goals when they construct websites, whether they’re around brand awareness, encouraging specific user behavior, or meeting legal requirements. Companies that meld user and organization goals in a way that feels authentic can be very successful in building brand loyalty.  Commerce sites, for example, have the goal of driving purchases, so the information on the site needs to provide content that enables effortless purchasing decisions. For other sites, the goal might be to drive user visits, encourage newsletter sign-ups, or increase brand awareness. In any scenario, burying in FAQs any pathways needed by users to complete their goals is a guaranteed way to make it less likely that the organization will meet theirs. By digging into what users need to accomplish (not a general “they need to complete the form,” but the underlying, real-world task, such as getting a shipping quote, paying a bill, accessing health care, or enrolling in college), you can design content to provide the right information at the right time and better help users accomplish those goals. As well as making it less likely you’ll need an FAQ section at all, using this approach to generate a credible IA and content strategy—the tools needed to determine a meaningful home for all your critical content—will build authority and user trust. Defining specific goals when planning a website is therefore essential if content is to be purposeful throughout the site. Common user-centered methodologies employed during both IA and content planning include  , content audits,  , user observations, and analysis of call center data and web analytics. A complex project might use multiple methodologies to define the content strategy and supporting IA to provide users with the necessary information.  The redesign of the Oliver Winery website is a good example of creating purposeful information instead of resorting to an FAQ. There was a user goal of being able to find practical information about visiting the winery (such as details regarding food, private parties, etc.), yet this information was scattered across various pages, including a partially complete FAQ. There was a company goal of reducing the volume of calls to customer support. In the redesign, a single page called “ ” was created with all the relevant topics. It is accessible from the “Visit” section and via the main navigation.  The system used is designed to be flexible. Topics are added, removed, and reordered using the CMS, and published on the “Plan Your Visit” page, which also shows basic logistical information like hours and contact details, in a non-FAQ format. Conveniently, contact details are maintained in only one location within the CMS yet published on various pages throughout the site. As a result, all information is readily available to users, increasing the likelihood that they’ll make the decision to visit the winery. If you   to include FAQs This happens. Even though there are almost always more effective ways to meet user needs than writing an FAQ, FAQs happen. Sometimes the client insists, and sometimes even the most ardent opponent (ahem) concludes that in a very particular circumstance, an FAQ can be purposeful. The most effective FAQ is one with a specific, timely, or transactional need, or one with information that users need repeated access to, such as when paying bills or organizing product returns. Good topics for an FAQ include transactional activities, such as those involved in the buying process: think shipments, payments, refunds, and returns. By being specific and focusing on a particular task, you avoid the categorization problem described earlier. By limiting questions to those that are frequently asked AND that have a very narrow focus (to reduce users having to sort through lots of content), you create more effective FAQs.  has a great example of an effective FAQ within their overall support content because they have exactly one: “Where’s My Stuff?.” Set under the “Browse Help Topics” heading, the question leads to a list of task-based topics that help users track down the location of their missing packages. Note that all of the other support content is purposeful, set in a topic-based help system that’s nicely categorized, with a search bar that allows users to dive straight in.  Conference websites, which by their nature are already focused on a specific company goal (conference sign-ups), often have an FAQ section that covers basic conference information, logistics, or the value of attending. This can be effective. However, for the reasons outlined earlier, the content can quickly become overwhelming if conference organizers try to include all information about the conference as a single list of questions, as demonstrated by  . Overdoing it can cause confusion even when the design incorporates categories and an otherwise useful UX that includes links, buttons, or tabs, such as on the  . In examining these examples, it’s apparent how much more easily users could access the information if it wasn’t presented as questions. But if you do have to use FAQs, here are my tips for creating the best possible user experience. Make it easy to find. Have a clear purpose and highly specific content in mind. Give it a clear title related to the user tasks (e.g., “Shipping FAQ” rather than just “FAQ”). Use clear, concise wording for questions. Focus questions on user goals and tasks, not on product or brand. Keep it short. Don’t include “What does FAQ stand for?” (unfortunately, not a fictional example). Instead, simply define acronyms and initialisms on first use.  Don’t define terms using an FAQ format—it’s a ticket straight to documentation hell. If you have to define terms, what you need is a glossary, not FAQs. Don’t tell your brand story or company history, or pontificate. People don’t want to know as much about your brand, product, and services as you are eager to tell them. Sorry. In the end, always remember your users Your website should be filled with purposeful content that meets users’ core needs and fulfills your company’s objectives. Do your users and your bottom line a favor and invest in effective user analysis, IA, content strategy, and documentation. Your users will be able to find the information they need, and your brand will be that much more awesome as a result.  Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/using-webfonts/", "title": "Using Webfonts", "content": "Now that you’ve selected a font, let’s put it on your website. Webfonts are defined in CSS through the   rule. If you’re a web developer, you’ve most likely written, copied and pasted, or at the very least seen an   rule. For the sake of completeness, though, let’s quickly run through a basic example: Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. This creates a new webfont family that can be referenced through the   or   shorthand property. But something’s missing here. When referencing a webfont in a font stack, always make sure to include at least one fallback font in case the webfont fails to load. Here, if Elena fails to load, the browser will fall back on the generic   font family: We’ll talk more about fallback fonts and how they can be used to make your site appear to load faster in Chapter 3. For now, let’s keep our fallback stack simple by including only the generic   and   font families. Font Families Creating a font family with multiple styles is accomplished by creating an   rule for each style and using the same   name. The following   rules create a family with a normal and bold style: You can use this font family in your CSS by referencing the family name and weight in your selectors. This applies the regular style to paragraphs and the bold style to   paragraphs: Besides  ,   also accepts the   and   property descriptors, which define styles such as italic and condensed. All three property descriptors can be used to create a single font family with multiple styles. Theoretically, this lets you create a family containing 243 individual styles (nine     × three     × nine    ). In practice, however, you’re limited to twenty-seven values, since some browsers don’t support   ( ). With luck, the remaining browsers will implement the   property soon, and you will be able to use all 243 font classifications. Font Formats The   descriptor tells a browser where to get a font file. The previous examples used a single font format, but you’ll often see URLs to multiple font formats combined with format hints, which are appended after the URL using the   syntax. Format hints tell the browser what the format of the font file at a given URL is. If you list multiple formats, modern browsers will pick the first format they support based on the format hint. Therefore, it’s important to list webfont formats in the order of best compression to least. Even though format hints are optional, always include them—they let the browser know about the format without needing to download the font. For example, if a browser does not support WOFF2, but does support WOFF, it can skip the WOFF2 font file based on the format hint. Browsers support several webfont formats: OpenType (TrueType), EOT, WOFF, and WOFF2. Some browsers also support SVG fonts, but they’re deprecated and should no longer be used (and should not be confused with the new  ). EOT, WOFF, and WOFF2 are technically not font formats. They are compressed OpenType files with varying degrees of compression. WOFF2 offers the best compression, followed by WOFF and EOT ( ). In researching coverage for all browsers, you may have come across something called the   by Fontspring. The bulletproof syntax uses EOT, WOFF2, WOFF, raw OpenType, and SVG font files for maximum browser coverage: The first URL line might look a little odd to you. Versions of Internet Explorer 8 and below do not support the syntax for multiple font formats, and treat the entire value of the   property as the URL. The bulletproof syntax tricks Internet Explorer 8 and below into thinking that the remaining URLs are part of the fragment identifier of the first URL. Because fragment identifiers are ignored when downloading files, Internet Explorer 8 and below simply use the first URL. Browsers other than Internet Explorer will skip the line because they do not support EOT. The rest of the entries are what you would expect: font formats listed in order of preference. But is the bulletproof syntax still relevant? No. In fact, I think it’s harmful. SVG fonts are deprecated and only supported by browsers that are no longer in use. Most websites support Internet Explorer 9 and up, yet the syntax lists EOT as the first preferred font format. Even though Internet Explorer 9 and up support WOFF, those versions will still download the EOT file, simply because it is listed first. Because most websites no longer support old browsers, I highly recommend using a simplified syntax. This simplified syntax covers all modern browsers, as well as slightly older ones that are still in active use, such as Android 4.4 and earlier: Even though older Android versions are still used, worldwide reliance on these browsers is rapidly dwindling. Soon you will probably be able to drop the raw OpenType format as well, and simplify the syntax even further: In this case, someone running an older browser will simply see your fallback fonts instead of the webfont. That’s fine; they can still read the content in the fallback font. (More on fallback fonts later.) There’s another possible value for the   descriptor. The   function takes the name of a local font family. If the font happens to be installed on the system, the browser will use that instead, thereby avoiding an extra download. While this may seem like a great optimization, nothing guarantees that the local font matches your webfont. You may get a different version of the font, a font with different language support, or even an entirely different font. For that reason, I usually recommend not using the   function unless you find these downsides acceptable. Want to read more? This excerpt from   will help you get started.   today, as well as other excellent titles from  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/ux-for-lizard-brains/", "title": "UX for Lizard Brains", "content": "Technology can make magic happen. In seconds, you can find all the blue sandals in a warehouse of millions of shoes. A million people can read the same article without killing one tree. You can undo, unsend, and even unfriend! But here’s the buzzkill: if unanticipated or unwelcome, the magic of technology is confusing, disorienting, and  —a UX designer’s worst nightmare.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. So how can we ensure that the magic we create is intuitive? Designers will often say, “If a design is intuitive, it behaves how a user expects it to.” Well, then … what do users  ? We want to know the following whenever we find ourselves in a new environment (physical or digital): What are the objects? Where are the objects? How do these objects relate to me? How do these objects relate to each other? What is my role as an object within this environment? In physical spaces, these don’t require explicit thought to answer. However, in digital spaces, they often do. That is because our  —the part of the brain involved in motivation, emotion, learning, and memory—evolved alongside the physics of solid objects. Consequently, users may feel unsure when designers flout the perceptual expectations forged in the physical world. Without knowing what and where the objects are, we feel blind. Navigating feels uncomfortable. Taking action might even feel impossible. The remainder of this article introduces three ways to design digital objects that “play nice” with our evolved expectations of the physical world. By doing our best to concretize the dematerialized things of our screen-based world, we give our lizard brains better affordances for understanding. Lesson one: avoid shapeshifting objects The properties of user interfaces need to be consistent for us to learn them well. We hunger for stable landmarks in the often ambiguous maze of digital interfaces. Objects in the real world don’t   change form as they change context. When I bring a new toaster home from the store, it doesn’t change into a different toaster. When I remove a vase from the cabinet, it doesn’t turn into a coffee mug. Humans expect  ; we are taken aback when objects unexpectedly change shape. Why do babies love peekaboo so much? It’s a great way to practice the fundamentals of object permanence, an important lesson in survival (e.g., just because the tiger went behind the rock does not mean it has disappeared). Because babies are still coming to terms with this concept, peekaboo makes for a rollicking good time. So we might assume that if we up the ante on the surprise-factor, the game would be even more fun, right? Nope. Researchers measuring the level of toddlers’ delight during a series of   discovered that the game loses its appeal when a   face pops up after hiding. The older the child, the more this hack kills the game. Evolution seems to be telling us: it’s not cool when objects suddenly change. But all that peekaboo practice is for naught when trying to navigate a digital world of shapeshifting objects. For instance, when this article was in the form of a Google Doc, it lived in both the Google Docs and the Google Drive environments. Depending on the environment, the article’s module changed form and function.  Moving from Docs to Drive, the shape of the document module shifts from about a 3:5 rectangular ratio to a 1:1 square ratio. If I want to see when I last opened a document, I will find that information directly on the module while in Docs; but within Drive, I must look to a disembodied side panel (not shown). Both modules have a menu of actions, but accessing it requires different interactions. (In Docs, I click the “more” icon; in Drive, I right-click the module.) Worst of all, the menu contains almost completely different options in each module! Only “Remove” and “Rename” are found in both menus. Adding insult to injury, even the icons for “Rename” are different.  We could chalk up the inconsistencies of Google Drive and Google Docs to siloed teams, but shapeshifting objects are common   products, too. On Meetup.com, the digital representation of my next meetup morphs multiple times across the site. Looking at the homepage, it displays as a big red banner at the top of the screen. Scrolling down the homepage to the calendar section, the same meetup is displayed as a white box sporting some green accents that signal my relationship with this particular object. And finally, within the context of its parent group—in this case Ladies that UX ATL—the meetup object is represented differently yet again. (Let’s not even get started on the ontological ambiguity between   and  .) Not only is my lizard brain trying to reconcile all these changes for potential threats, but these inconsistencies are making me work harder in a practical sense. I have to learn three displays for RSVP status, three positions for date and time, and three ways to find the number of people going. Every time the object changes, I have to make adjustments both to recognize it and to interact with it. These adjustments are small, but they add up across the experience. Designers can eliminate this cognitive load simply by creating a canonical object structure and sticking to it. Many users don’t log the deltas between modules explicitly. Users furrow their brows and simply do their best to relearn objects and keep track of what’s what. They might harbor a vague feeling that the website or app is “hard to use.” Or worse, they blame themselves for “stupidly” attempting to interact with an object in a way that worked in one context but does not work in their current context.  Sure, there are complex platforms where it might make sense to re-prioritize object elements depending both on who is viewing it and under what conditions. But if we design screen-by-screen instead of object-by-object, we run the risk of doing this unintentionally and arbitrarily, introducing more shapeshifting than is absolutely necessary.  Key takeaway When we move elements around within an object, we need to remember  —we are sacrificing consistency. Sometimes it will be worth it, like perhaps in professional tools used by power users. But often, our users will be happier with a single, rock-solid representation of that object. Lesson two: avoid masked objects On the flip side of shapeshifters (i.e., various packages for the same object), designers also have a tendency to shove different objects into the same package. With the good intention of designing a system of reusable parts, we’ll often create one-size-fits-all modules. This might seem like a smart simplification strategy, but it actually hinders users from distinguishing various object types. Distinguishing them is critical for the user to understand the system.  Check out this bank of candy-colored modules on my Amazon homepage. Sure they house different colors and content, but they follow the same basic structure. If the text were in Latin (or if the user were skimming rapidly, which we should always assume is true), these modules would translate as  . In looking at the first two, PRIME and FRESH, I might get the impression that these modules represent “services.” And indeed, when I click these modules, I enter sort of informational, sale-sy pages describing these services (although they follow completely different templates). But when I get to VIDEO, I have to pause.   The next module (MUSIC) brings up the same question. And the ALEXA module—will this take me to a service landing page or, perhaps, a product detail page? In fact, each module takes me to a different type of place. PRIME and FRESH take me to two separate templates for a “service.” VIDEO takes me to a detail page for  . And MUSIC opens up Amazon Music in a new tab (with no sign of the ill-recommended Eminem album). The ALEXA module takes me to another “snowflake” landing page.  Like opening identical doors in a game show (but not as fun), I never know what to expect when clicking on one of these tiles. ( ) Let’s look at one more example. The Apple App Store leverages a small rectangular thumbnail module that can house apps, curated collections, broad categories, developer-based app suites, and even operating system updates.  In both the Amazon and Apple App Store examples, instances of the modules have distinct graphics and labels, but they are the same shape and size and they are   together, like apples at the market. As a general rule of thumb in Gestalt psychology, when objects are grouped together, we assume they are the same type of thing, especially if their overall shape is identical. When the same packaging (i.e., the module) turns out to contain various types of things, as in the App Store, users may feel confused or even tricked. This is like taking a sip from your Starbucks coffee cup and getting a mouthful of orange juice: objectively tasty, but if unexpected, you might spew it onto your barista. Key takeaway Designing one-size-fits-all modules might seem like a good idea for an efficient modular system, but this practice doesn’t allow users to predict what’s “behind the door.” Instead, design packaging (i.e., modules) that reflects the unique things inside. This way users can learn to recognize and understand the objects in your system, making for a more intuitive environment. Lesson three: avoid broken objects In the real world, our environments are made of surfaces and clear edges. We rarely have the problem of understanding where one object stops and another begins. If we happen across a tangle of snuggling kittens, our brain might freeze up—not only from cuteness overload, but also because we are compelled to figure out which paws belong to which head. We want objects to be whole; if they are not, our brain does its best to connect the dots. In digital environments, an object might not only shapeshift across screens or mimic other objects, it might also be broken. The information and interaction triggers of broken objects are scattered across their digital environments.  Winc Wines, a lovely service that delivers algorithmically-recommended wine to your doorstep, prompts customers to rate their wines. Often, I’ll do this 3–4 months after receiving wines. Recently, I decided it would be a great form of procrastination to log into Winc to rate my past wines. At a dinner party I hosted in May, we drank a delicious sparkling wine. I   it was Finke’s Widow, but I’m not positive. Hesitating to give it five stars until I am sure, I need to find out when the bottle of Finke’s was delivered. On the “Ratings” tab, I see all my past wines. But delivery dates are not displayed.  Clicking into the detail view, I am presented with a generic detail page, the same view of Finke’s Widow that everyone sees. Here I can find information about the wine, but no information about my relationship with the wine—mainly, when it was delivered and how (or if) I rated it. As a wild guess, I click the “Hello, Sophia” menu, where I see a link to Order History. Seems promising. The Order History page gives me a list of orders with no preview of the wines that were included in each order.  After clicking into the April and May orders, I finally find Finke’s Widow. Mystery solved. So, can I rate the wine from here? Nope! I have to navigate back to the Ratings tab and then scroll down to find Finke’s Widow again. In the Winc world, relevant pieces of a bottle (like a customer’s order date, rating, and tasting notes) are scattered about, forcing a user to hop around to piece together the broken object. ( ) Key takeaway In the Winc world, I have to be in Order History to see a wine’s delivery date and I have to be in Ratings to tell the system how much I liked a bottle of wine. But what if I am   and one of my past wines shows up in a curated collection? I’ll want to be reminded that this wine was delivered to me six months ago and I gave it 4 stars. Or, if I haven’t rated it yet, but I remember loving it, I’ll want to add my stars then and there. I definitely do not want to navigate over to Ratings, only to have to scroll down to re-find that bottle. We need to do our best as designers to encapsulate our digital objects, making them feel whole and directly manipulable, just like in the real world. I might be more likely to use the blender in the kitchen, but it still works just as well in the garage. Building a better mind palace Humans love to concretize things. Greek orators memorized their long speeches by visualizing the speech as rooms in a palace. Sherlock Holmes himself, a genius at making connections between the most subtle clues, did so by entering his  , a visualized place where bits of information were concretized and manipulable. If the internet is the chaotic product of the human genius, this article is a call to action for designers to build a stronger mind palace for it. When we avoid shapeshifting, masking, and breaking digital objects, understanding will emerge more naturally. It’s a simple matter of making our digital environments feel a little more like the real world in which our ancestors evolved. Like this: \n\t\t\t\t\t\t\tRecently by Sophia V. Prater\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-right-way-to-select-technology-excerpt/", "title": "The Right Way to Select Technology, An Excerpt", "content": "After establishing a solid business case, enterprises will typically turn to assembling the oft-dreaded “requirements document”—or more accurately, a set of documents, spreadsheets, and diagrams that compose a multiheaded requirements package. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Large requirements packages actually provide a false sense of security. Modern digital technology entails real people interacting with screens. Technology selection leaders need to capture those interactive requirements, but also remain realistic at this phase about their inability to fully know what their enterprise really needs and will adopt eventually. This section will show how long spreadsheets full of “what” requirements really don’t work, and instead will focus on “how” a solution might work. The best way to reveal key differences among suppliers is to craft narrative “user stories” with “personas” (rough equivalent to use-cases with actors).  In other words,  . Business users have stories; so do customers, partners, developers, sysadmins, designers, auditors, and others. This section will lead you through an approach to telling those stories in a way that’s more conducive to differentiating among technology suppliers. Capture requirements that don’t suck A solid understanding of your organization’s requirements is essential to project success. Getting that understanding will involve information gathering from various stakeholder groups, potentially utilizing a variety of techniques. Note that at this stage, your requirements should be business- and user-focused, rather than detailed technical specifications. (We’ll get to those in Chapter 6, “Ask Questions That Really Matter”). The final key step here is to analyze and prioritize your requirements, in order to determine which ones to emphasize in the RFP and subsequent demos and bake-offs. How   to articulate requirements Whatever you do, avoid “check box” requirements sheets where you ask the vendor: “Can you do this, can you do that?” As a practical matter, vendors have seen all these questions and have figured out how to check all the boxes. But what’s worse is that such spreadsheets convert the understanding of what should be a human-centered, interactive activity into a bloodless series of row-by-row activities better suited for robots repeatedly performing rote tasks. The typical pitfall here starts like this: a business analyst (BA) goes around interviewing users and other stakeholders, and she ends up with a long wish list of features. Excel allows her to categorize those features, which is handy, but because of the limitless rows, her spreadsheet will tend to emphasize comprehensiveness over business impact. Don’t include the kitchen sink While it’s critical to identify your requirements, it will prove even more important to   them. Noncritical requirements can hijack the product selection process by distracting you and your vendors from what’s really important. Remember that you are   at this phase. You are trying to contrast potential suppliers and solutions. So while complete requirements are nice,   requirements are gold. We’ve seen many a project stall very early in the process when enterprises get bogged down in the minutia of trying to unearth every possible requirement. The most successful enterprises hone in on what we call  . Differentiating requirements describe use cases that are truly unique for your enterprise. Differentiating requirements are also the types of requirements that elicit very different solutions from the various vendors in the marketplace. Knowing which user journeys and outcomes are more important than others will make it easier to distinguish among vendors. It will also help you keep costs in line with your budget. Remember that excessive wish lists lead to scope-creep, overbuying, implementation delays, and ultimately, budget-busting. \n To address the challenge of priorities, the typical enterprise process asks stakeholders to rank their needs, perhaps on a scale of 1 to 5, or using MoSCoW (Must Have/Could Have/Should Have/Won’t Have) or some other methodology. Not surprisingly, this generates a scrum where users compete to identify as many rows of “Must Haves” as possible. Ultimately, someone will ask the BA to tie back each requirement row to the business case (remember that?), so she then spends several days building new tables and cross-references in Excel. Ultimately, reviewers find exceptions and variants for each feature, so new columns get added. Now the spreadsheet is too big to fit on a standard screen, let alone print out. It’s impressive … and impressively unhelpful. The government agency with the massive checklist We once advised a major U.S. federal government agency to select a new portal platform as a hub for small business advice. We came late to the process after an initial round of vendor demos had failed to differentiate clearly among the bidders. The problem was Excel. Or more specifically, the entire RFP as a 10-tab worksheet, with some sheets going hundreds of rows deeps. Most of the tabs held feature requests—notably categorized by agency department rather than customer persona—with a long series of columns annotating those features. (Our favorite: the ever-beloved “Must be easy to use” requirement.) Nearly all the features were listed as “must have.” They were rigorously cross-tabbed to a long-but vague set of business objectives, but otherwise there was no prioritization. The vendors didn’t know what to demo, although several gamely tried. Mostly, they just talked about their (voluminous) proposal responses, most of which consisted of declaring, for each row, “We can do that!” Ultimately, we were able to recraft a more user-centered approach, with a narrower scope, that vendors could reasonably demo against. Applying UCD principles There’s a different way to do this than torturing your BA— and everyone else—with long spreadsheets, and it revolves around pursuing a user-centered design (UCD) approach that emphasizes narratives, which we’ll call   here. People will disagree about the tactics of UCD, but we can generalize overall that a user-centered approach is:  to encompass the entire digital experience (and therefore not feature based) , where you initially sketch light (and therefore imperfect) requirements and refine them over time via iteration , with an emphasis on user narratives, often called “journeys” or “top tasks” There’s much more to UCD, but for our purposes, two key constructs stand out:  User archetypes that guide decisions about technology effectiveness. Personas are useful in the sense that they create a common shared understanding of the user group, but with a human existence to help keep it real.  A to-be story about the “daily life of” or a journey undertaken by key personas. User stories are exceptionally valuable here because they offer test cases against which you can compare and contrast vendor bidders. Information gathering You can chose from among numerous well-known methods for eliciting information needed to create personas and user stories.  Including existing and prospective systems diagrams, planning documents, and analytics, but also the information that flows through the anticipated technology, like catalog entries for an ecommerce site, or forms in a document management system  Including customer and employee surveys, as well as specialized questions you might want to pose in advance of any in-person meetings  A useful way to debrief groups of people, as well as experiment with more forward-looking brainstorming; customer focus groups fall into this category as well  Debriefing individual stakeholders one-on-one, where they may become more candid  Following stakeholders around for a typical duration of time; this sort of contextual inquiry is often the most useful, but also labor intensive Potentially others … Different practitioners will take different approaches, and clearly the level of effort here should be commensurate with the anticipated benefits and risks with the new technology. At Real Story Group when we’re creating personas and scenarios, we like to take a modified contextual inquiry approach. We gather individuals with similar roles in a conference room and debrief the team as a group. Using a projector, we may ask some members to log in to show specific examples of an incumbent system to the group. When we are gathering requirements for an interactive system, we make the environment as interactive as possible to get the maximum information exchange. We’ll send five questions in advance as the agenda for the workshop: The questions are deliberately open ended, to create as much of an open dialogue as possible. Note the emphasis on “top three”—we don’t want a laundry list of features, but rather the most important problems and opportunities. Sometimes, it’s hard for line employees to identify potential future opportunities, so it can be useful to introduce the whole process with an educational workshop describing industry best practices or examples of what other enterprises have done with the technology. This is particularly important when selecting a type of technology that the enterprise has never used before. The question still remains of staying aligned with the initial business plan. We like to book half-hour sessions with interested executives to understand the broader business currents and objectives underneath the technology selection effort. At this point, a lot of raw material has been accumulated. The next step is to convert it into the two core components of the future RFP: user stories and advanced Q&A. Tips You will need to invest in both information and process analysis, and this will require document analysis as well as contextual inquiry. Avoid long, undifferentiated, spreadsheet-based feature lists in favor of uncovering material necessary to create key personas and scenarios. Start with the user experience and work your way back into enterprise systems. Avoid the temptation to broaden your scope beyond the original charter. You don’t need to be perfect at this (or any other) phase, so focus inquiry into your stakeholders’ most burning problems or intense needs. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/web-typography-numerals/", "title": "Web Typography: Numerals", "content": "When it comes to numbers we have just ten digits. Throw in a comma and a period and we’ve got grand total of twelve characters. You might not think that would present much of a challenge to a typographer, but to a professional typesetter (that’s you if you’re a designer) numerals require far more nuance and variation than you might think at first glance. Numbers deserve the same care and attention as text – this excerpt reveals the numerical situations you should be looking out for, and how to tackle them to benefit your reader. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Use old-style numerals in running text In ‘Ligatures and abbreviations’ we established that writing systems based on the Latin alphabet, in addition to Greek and Cyrillic, use a bicameral script, with each letter represented by two different forms – uppercase and lower (or majuscule and minuscule, to use more formal terms). The same is true of numerals. We have at our disposal ‘uppercase’ numbers   called   or   numerals, and ‘lowercase’ numerals 0123456789 called   or   numerals. Unlike capital and lowercase letters, different forms of numbers do not convey different meanings; they are, however, an essential component of the typographer’s palette. Just as a string of capital letters in the middle of a sentence SHOUTS at your reader, so numbers set in lining numerals call undue attention to themselves. Are pounds, dollars, dates and quotas really more important than the words and ideas which give them context and meaning? Treat numbers as you would letters, making sure they don’t stand out unnecessarily. Do this by using old-style numerals in all your running text. Most modern, professional fonts will include both old-style and lining numerals as OpenType features. One or other of these styles will be used for the default numbers. More often it will be the old-style numerals, but there is no strict rule or consistency, and the choice of default is down to the type designer. It’s also the case that the vast majority of fonts are neither modern nor professional, if modern means OpenType-enabled and professional means designed with both sets of numerals. Take Georgia, for example. Designed by Matthew Carter in 1993 as a screen font for Microsoft, it is extremely well put together, elegant and appealing, and one of the most popular and widely distributed fonts in the world. But it is not packaged as an OpenType font and so only contains one set of numbers, in this case old-style numerals. Times New Roman, which is similarly widespread but, again, not as an OpenType font, is packaged only with lining numerals. Georgia and Times New Roman are so widely distributed because they are bundled free of charge with Windows and Mac operating systems. However, both these fonts – like many others – are available to buy in professional versions, which do come as OpenType fonts complete with both sets of numerals, small caps and many other features. To specify old-style numerals, set the   property with a value of  . If most of what you’re designing on a page is running text, then your best approach is to set old-style numerals so that they are inherited from the  . For legacy browsers requiring  , use the   OpenType feature tag. As explained in ‘Ligatures and abbreviations’, you can add an   rule to cater for legacy browsers that only support  : Many sans serif fonts of the early to mid-twentieth century, including Helvetica, were never designed with anything other than lining numerals. This is one of the reasons why Helvetica is rarely your best choice for body text. That said, the lining numerals are less of a problem in Helvetica than they are in some other typefaces. As we saw in ‘Designing paragraphs: line spacing’, Helvetica has a large x-height. A consequence of this is that its lowercase letters are closer in stature to its lining numerals when compared to other sans serif fonts such as Futura and Avenir, which have far smaller x-heights. Clearly Paul Renner and Adrian Frutiger, the designers of Futura and Avenir respectively, recognised the need for old-style numerals in their fonts as both these typefaces were designed with them from the start. Sadly, the versions of Futura and Avenir widely distributed with Apple devices have lining numerals as the default, and do not include old-style numerals as OpenType features (the macOS version of Avenir Next, however, does include them). Use lining numerals in headings Old-style numerals are your go-to glyphs for making numbers sit well in running text. For the same reason they are at ease with lowercase letters, so old-style numerals feel uncomfortable in close proximity to capital letters. If you set headings in anything other than sentence case, in particular ALL CAPS, or Title Case, then don’t use old-style numerals. Lining numerals will sit far more naturally in the company of uppercase letterforms. On those occasions when numbers are the star attraction, lining numerals are the way to give them the attention they crave. Old-style numerals have a wavy rhythm to them, with some numbers reaching upwards towards the capitals, some squatting at the x-height, and others ducking down below the baseline: 1234567890. This is why they work so well in continuous reading – they replicate the patterns of words in running text. However, if your reader is scanning a sequence of numbers, looking for patterns, making comparisons, or hunting for data in a list, table or other setting, they will find it far easier to do so with the familiarity and evenness of lining numerals. To specify lining numerals, set the   property with a value of  : For legacy browsers requiring  , use the   OpenType feature tag. Use proper subscripts and superscripts Subscripts and superscripts are tiny numerals which are lowered or raised. They are used in chemical and mathematical formulas, as footnote indicators, and other specialist situations. For example: ‘Caffeine  is C H N O .’ Mark this up meaningfully in HTML using the   and   elements: Browsers’ default styling for   and   is to take a regular numeral, make it a bit smaller, and raise or lower it accordingly: This works fine up to a point, but the numerals are still a little too big aesthetically and they affect the line spacing, causing unevenness in the rhythm: Most professional fonts contain properly designed subscripts and superscripts built in as OpenType features. These numerals are smaller and squatter than regular numbers, and because their position relative to other characters is part of their design, the line spacing is unaffected: To use proper subscripts and superscripts, use the   property, like this: Unfortunately, this still leaves us with a problem: the browser’s default styling is still applied. Our special subscript character is being made smaller and it’s getting moved downwards, affecting the line spacing: The styles the browser applies to our subscript characters are these: We need to remove those styles to get the desired effect, so our rule now becomes: That will work fine for browsers that support OpenType. But browsers that don’t will get C8H10N4O2, a degraded rendering compared with the browser defaults. To address this we can use an   rule to check if the browser supports   and only override the browser’s default   styling if that’s the case: For legacy browsers requiring  , use the   OpenType feature tag for superscripts, and   for subscripts. If we factor these in, we get comprehensive, backwards-compatible style rules, but where two simple properties should have done the job, we now have a far more verbose proposition: Reference notes with superscripts One particular use of superscripts is for footnotes. When you reference notes using numbers, use true superscripts in the text but full-size numbers in the notes themselves. While we’re on the subject of footnotes, it’s worth making a brief diversion into how the web improves their usability compared with the limitations of paper. Many forms of writing, including academic papers, historical novels, detailed journalism and non-fiction books such as this one, contain additional citations, explanations and thoughts referred to within the text itself. A symbol is used to connect the note to the relevant location in the text. The symbols employed as references to annotations are either superscripted numbers or an esoteric series of devices starting with asterisks* and processing through daggers† to double daggers‡ and beyond. Since the advent of mass printing in the Victorian era, the notes themselves have typically been positioned either at the bottom of the referring printed page ( ), or at the end of a chapter or the entire work ( ). However, this approach means the notes are located away from their position within the body of text. This can disturb the reader who wishes to refer to the annotation as they proceed through the text. The connected point in the text may well be halfway through a sentence in the middle of a paragraph at some point higher up the page, or on a different preceding page altogether, and attempting to return to it disrupts the reader’s rhythm. An earlier approach by medieval scribes and Renaissance printers placed notes in the margins ( ) rather than at the bottom of the page. By including notes as marginalia, the annotations are present where needed and can be read with little more than a glance away from the main text. Although side notes are an improvement on footnotes, both solutions are designed within the confines of the two-dimensional printed page. The web is an interactive medium and provides us with at least three dimensions in which to work, implying you can use the  -axis to place the note   of the main text. Enable your reader to reveal the note on demand in the very place they are reading. Put simply, link to the footnote using a conventional symbol, but have it pop up in the vicinity of the link, thus providing a thoroughly modern solution impossible within the limitations of a printed page. Want to read more? This excerpt from   will help you get started.  . Like this: \n\t\t\t\t\t\t\tRecently by Richard Rutter\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-story-of-css-grid-from-its-creators/", "title": "The Story of CSS Grid, from Its Creators", "content": "On October 17th, Microsoft’s Edge browser shipped its implementation of CSS Grid. This is a milestone for a number of reasons. First, it means that all major browsers now support this incredible layout tool. Second, it means that all major browsers rolled out their implementations in a single year(!), a terrific example of standards success and cross-browser collaboration. But third, and perhaps most interestingly, it closes the loop on a process that has been more than 20 years in the making. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Not a new idea While the modern concept of a “grid layout” has been with us since the Industrial Revolution, grids have been a design tool for centuries. As such, it shouldn’t come as a shock that grid-based layouts have been a goal of CSS since the beginning. According to Dr. Bert Bos, who co-created CSS with Håkon Wium Lie, grid-based layouts have actually been on his mind for quite some time. “CSS started as something very simple,” Bos recalled. “It was just a way to create a view of a document on a very simple small screen at the time. Twenty years ago, screens were very small. So, when we saw that we could make a style sheet for documents, we thought,  ” Looking at what books and magazines were doing with layout was a great inspiration for them. “Independent of the content on every page, it has a certain layout,” Bos said. “Page numbers are in certain places. And images are always aligned to the certain sides—left or right or in the middle. We wanted to capture that.” Early on, browser makers wrote off the idea as “too complex” to implement, but grid layout concepts kept cropping up. In 1996, Bos, Lie, and Dave Raggett came up with a “frame-based” layout model. Then, in 2005, Bos released the  , which later turned into the  . Despite enthusiasm for these concepts from the web design community, none of them  ever shipped in a browser. Once more, with feeling With grid concepts being thrown at the wall of the CSS Working Group with some regularity, folks were hopeful one of them would stick eventually. And the idea that did was a proposal from a couple of folks at Microsoft who had been looking for a more robust layout tool for one of their web-based products. Phil Cupp had been put in charge of the UI team tasked with reimagining Microsoft Intune, a computer management utility. Cupp was a big fan of  , a browser plug-in that sported robust layout tools from  , and initially had planned to go that route for building the new Intune. As it happened, however, Microsoft was in the planning stages of Windows 8 and were going to enable building apps with web technologies. Upon learning this, Cupp wanted to follow suit with Intune, but he quickly realized that the web was in desperate need of better layout options. He joined a new team so he could focus on bringing some of the rich layout options that existed in Silverlight—like grid layout—to the web. Interestingly, folks on this new team were already noticing the need. At the time, many app developers were focusing on iPhones and iPads, which only required designers to consider two different fixed canvas sizes (four, if you consider portrait and landscape). Windows had to support a ton of different screen sizes, screen resolutions, and form factors. Oh, and resizable windows. In short, Microsoft needed a robust and flexible layout tool for the web desperately if the web was going to be an option for native app development on Windows. After working extensively with various teams within Microsoft to assemble a draft specification, Cupp and his team shipped a grid layout implementation behind the   vendor prefix in Internet Explorer 10 in 2011. They followed that up with a  , which they presented to the W3C in 2012. Of course, this was not the first—or even the third—time the W3C had received a grid layout spec to consider. What was different this time, however, was that they also had an actual implementation to evaluate and critique. Also, we, as developers, finally had something we could noodle around with. Grid layout was no longer just a theoretical possibility. A handful of forward-thinking web designers and developers—Rachel Andrew, an Invited Expert to the W3C, chiefly among them—began to tinker. “I came across CSS Grid initially at a workshop that Bert Bos was leading in French. And I don’t really speak French, but I was watching the slides and trying to follow along,” Andrew recalled. “I saw him demonstrate … the Template Layout spec. I think he was really talking about it in terms of print and using this stuff to create print layouts, but as soon as I saw that, I was like,   And so I started digging into it, and finding out what he was doing, and building some examples.” “Then I saw the Microsoft implementation [of the draft Grid Layout spec], which gave me a real implementation that  . And I wanted to do that—not just because it was interesting, and I like interesting things to play with—it was because I wanted to get it out there and get other people to have a look at it. Because I’ve been doing this for a long time and I know that specs often show up, and then no one really talks about them, and they kinda disappear again. And I was absolutely determined that Grid Layout wasn’t gonna disappear, it was gonna be something that other people found out about and got excited about it. And hopefully we’d actually get it into browsers and be able to use it.” The spec evolves The draft spec that Cupp presented to the W3C, and that his team shipped in IE10, is not the  . It was a step in the right direction, but it was far from perfect. “The one [Phil Cupp submitted] was a very track-based system,” recalled Elika Etemad, an Invited Expert to the W3C and an Editor of the CSS Grid Layout Module. “There was only a numeric addressing system, there were no line names, there [were] no templates, none of that stuff. But it had a layout algorithm that they … were confident would work because they had been doing experimental implementations of it.” “The original grid that Bert [Bos] came up with … was really the reason I joined the CSS Working Group,” recalled Google’s Tab Atkins, another Editor of the CSS Grid Layout Module. “At the time, I was learning all the terrible layout hacks and seeing the possibility to just write my page layout in CSS and just have it all, kinda, work was astonishing. And then seeing the draft from Phil Cupp … and seeing it all laid out properly and with a good algorithm behind it, I knew that it was something that could actually exist now.” It was also a compelling option because, unlike previous proposals, which specified rigid layouts, this proposal was for a responsive grid system. “You can [be] explicit about the size of a grid item,” Etemad explained. “But you can also say,  . And that was what we needed to move forward.” However, the draft spec wasn’t as approachable as many on the CSS Working Group wanted it to be. So the group looked to bring in ideas from some of its earlier explorations. “What we really liked about Bert [Bos]’s proposal was that it had this very elegant interface to it that made it easy to express layouts in a way that you can intuitively see,” Etemad said. “It’s like an ASCII art format to create a template, and you could put [it] in your code, like the width of the columns and the heights of the rows. You could embed those into the same kind of like ASCII diagram, which made it a lot easier to see what you were doing.” Peter Linss, then Co-Chair of the CSS Working Group, also suggested that they incorporate the concept of grid   in the spec (instead of only talking about  ). He believed including this familiar graphic design concept would make the spec more accessible to designers. “When we were thinking initially about CSS Grid, we were thinking about it in a very app-centric model,” recalled Microsoft’s Rossen Atanassov, who is also an Editor on the spec. “But grid is nothing new. I mean, grid’s been here for a very long time. And that traditional type of grid has always been based on lines. And we’d been kind of ignoring the lines. When we realized that we could marry the two implementations—the app side and the typography side of the Grid—this for me, personally, was one of those   moments that really inspired me to continue working on Grid.” So the CSS Working Group began tweaking Microsoft’s proposal to incorporate these ideas. The final result allows you to think about Grid systems in terms of tracks or lines or templates or even all three at once. Of course, getting there wasn’t easy. Refine, repeat As you can probably imagine, reconciling three different ideas—Microsoft’s proposal, Bos’ Advanced Layout, and Linss’ addition of grid lines—wasn’t a simple cut and paste; there were a lot of tricky aspects and edge cases that needed to be worked out. “I think some of the tricky things at the beginning [were] taking all the different aspects of … the three proposals that we were trying to combine and coming up with a system that was coherent enough to gracefully accept all of that input,” Etemad said. Some ideas just weren’t feasible for phase one of a CSS grid. Bos’ concept, for instance, allowed for any arbitrary descendent of the grid to lay out as though it were a child element of the grid. That is a feature often referred to as “subgrid” and it didn’t make the cut for CSS Grid Layout 1.0. “Subgrid has been one of those things that was pointed out immediately,” Atanassov said. “And that has been a blessing and kind of a hurdle along the way. It was … one that held back the spec work for quite a bit. And it was also one that was scaring away some of the implementers. … But it’s also one of the features that I’m … most excited about going forward. And I know that we’re gonna solve it and it’s gonna be great. It’s just gonna take a little while longer.” Similarly, there were two options for handling content mapped to grid lines. On the one hand, you could let the grid itself have fixed-dimension tracks and adjust which ending grid line the overflowing content mapped to, based on how much it overflowed. Alternately, you could let the track grow to contain the content so it ended at the predefined grid line. Having both was not an option as it could create a circular dependency, so the group decided to put the grid-snapping idea on hold. Ultimately, many of these edits and punts were made in light of the CSS Working Group’s three primary goals for this spec. It needed to be: “[T]his is why designing a new layout system for CSS takes a lot of time,” Etemad said. “It takes a lot of time, a lot of effort, and a lot of love from the people who are working on it.” Where the rubber meets the road Before a Candidate Recommendation (aka, a final draft) can become a Proposed Recommendation (what we colloquially refer to as a “standard”), the W3C needs to see  . Microsoft had implemented their draft proposal, but the spec had changed a lot since then. On top of that, they wanted to see other browsers take up the torch before they committed more engineering effort to update it.   Well, they were a little gun-shy after what happened with another promising layout proposal:  . CSS Regions offered a way to flow content through a series of predefined “regions” on a page, enabling really complex layouts. Microsoft released an implementation of CSS Regions early on, behind a prefix in IE 10. A patch landed support for Regions in WebKit as well. Safari shipped it, as did Chrome (which was still running WebKit under the hood at the time). But then Google backed it out of Chrome. Firefox opposed the spec and never implemented it. So the idea is currently in limbo. Even  . Suffice it to say, Microsoft wanted to be sure Grid wouldn’t suffer the same fate as Regions before committing more engineering resources to it. “We had implementers that immediately said, ‘Wow, this is great, we should definitely do it,’” recalled Atanassov of Grid. “But [it’s] one thing … saying, ‘Yeah this is great, we should do it,’ and then there’s the next step where it’s adding resources and paying developers to go and actually implement it.” “There was desire from other implementers—one of the spec editors is from Google—but there was still hesitancy to actually push code,” recalled Microsoft’s Greg Whitworth, a member of the CSS Working Group. “And … shipping code is what matters.” In an interesting turn of events, the media company Bloomberg hired Igalia, an open source consultancy, to implement CSS Grid for both Blink and WebKit. “Back in 2013 … [we] were contacted by [Bloomberg] … because they had very specific needs regarding defining and using grid-like structures,” recalled Sergio Villar Senin, both a software engineer at and partner in Igalia. “[T]hey basically asked us to help in the development of the CSS Grid layout specification, and also [to] implement it for [Blink and WebKit].” “[Igalia’s work] helped tremendously because then developers [could] see it as possibly something that they can actually use when developing their sites,” Whitworth added. \nBut even with two ready-made implementations, some folks were still concerned the feature wouldn’t find its footing. After all, just because a rendering engine is open source doesn’t mean its stewards accept every patch. And even if they do, as happened with CSS Regions, there’s no guarantee the feature will stick around. Thankfully, a good number of designers and developers were starting to get excited about Grid and began to put pressure on browser vendors to implement it. “There was a pivotal shift with CSS Grid,” Whitworth said. “Starting with Rachel Andrew coming in and creating a ton of demos and excitement around CSS Grid with   and starting to really champion it and show it to web developers and what it was capable of and the problems that it solves.” “Then, a little bit later, Jen Simmons [a Designer Advocate at Mozilla] created something called   where she put a lot of demos that she created for CSS Grid up on the web and, again, continued that momentum and that wave of enthusiasm for CSS Grid with web developers in the community.” With thought leaders like Andrews and Simmons actively demonstrating the power and versatility of CSS Grid, the web design community grew more excited. They began to experiment on sites like  , sharing their ideas and developing their Grid layout skills. We don’t often think about it, but developer enthusiasm has the power to bolster or bury a spec. “We can write a spec, we can go implement things, but if there isn’t developer demand or usage of the features, it doesn’t really matter how much we do with that,” Whitworth said. Unfortunately, with ambitious specs like Grid, the implementation cost can often deter a browser vendor from making the commitment. Without a browser implementation enabling developers to tinker and experiment, it’s hard to build enthusiasm. Without developer enthusiasm, browser vendors are reluctant to spend the money to see if the idea gains traction. I’m sure you can see the problem here. In fact, this is partly what has doomed Regions— —at least for now. Thankfully, Bloomberg willingly played the role of benefactor and got the ball rolling for this new incarnation of CSS Grid. So, with its help, Google landed an implementation of CSS Grid in Chromium 56 for Android in January of 2017. It landed its Chrome implementation in early March, just two days after Mozilla shipped its own implementation in Firefox. Before the month was over, Opera and Safari had also shipped support for CSS Grid. Ironically, the last company to ship CSS Grid was Microsoft. But it released its implementation in Edge earlier this week. “With features on the web platform … you’re waiting for a sweet spot,” Whitworth said, just prior to Grid’s release in Edge. “You want a solid spec, you want implementer interest, and you want tons of demand from web developers. Late 2016/early 2017 was that sweet spot. All of that happened. We upgraded our implementation and are stoked to ship it.” “I don’t recall a feature ever shipping like CSS Grid has shipped. Every major browser will have shipped it within a matter of a single year, and it will be interoperable because we’ve been… implementing [it] behind flags, testing it, making future changes behind flags, and then when it was deemed stable, all the browsers are now shipping it natively.” “With everybody shipping at approximately the same time,” Atkins said, “[Grid] goes from an interesting idea you can play with to something that you just use as your only layout method without having to worry about fallbacks incredibly quickly. … [It’s been] faster than I expected any of this to work out.” What Grid means for CSS With Grid support no longer in question, we can (and should) begin to make use of this amazing tool. One of the challenges for many of us old timers who have been working with CSS for the better part of two decades, is that CSS Grid requires a whole new way of thinking about layout. “It’s not just attaching your margins and properties to each individual element and placing them,” Bos said. “[Y]ou can now have a different model, a model where you start with your layout first and then pull in the different elements into that layout.” “It is the most powerful layout tool that we have invented yet for CSS,” Atkins said. “It makes page layouts so ridiculously easy. … [P]eople have always been asking for better layouts. Just for author-ability reasons and because the hacks that we were employing weren’t as powerful as the old methods of just put[ting] it all in a big old table element—that was popular for a reason; it let you do powerful complex layouts. It was just the worst thing to maintain and the worst thing for semantics. And Grid gives you back that power and a lot more, which is kind of amazing.” “CSS Grid takes all of that complicated stuff that we had to do to [achieve] basic layouts and makes it completely unnecessary,” Etemad said. “You can talk to the CSS engine directly[—]you, yourself, without an intermediary translator.” CSS Grid offers a lot of power that many of us are only just starting to come to grips with. It will be interesting to see where we go from here. “I think it’s going to be transformative,” Etemad said. “It’s going to take CSS back to what it was meant to be, which is styling and layout language that lifts all of that logic away from the markup and allows that clean separation of content and style that we’ve been trying to get from the beginning.” “I’m excited about the future of CSS layout,” Whitworth said. “CSS Grid is not the end; it’s actually just the beginning. In IE 10 … [we shipped] CSS Regions as well as  . I think as web designers begin to utilize CSS Grid more and more, they’ll realize   we shipped all three together. And maybe we can continue what we did with CSS Grid and continue to improve upon those specifications. Get vendor desire to implement those as well. Get the community excited about them and push layout on the web even further.” “I think that now we have Grid, Exclusions makes absolute sense to have,” Andrew said. “It gives us a way to place something in [a grid] and wrap text around it, and we don’t have any other way to do that. … And then things like Regions … I would love to see that progress because … once we can build a nice grid structure, we might want to flow content through it. We don’t have a way of doing that.” “[A]s far as I’m concerned, this doesn’t stop here; this is just the start.” Getting into Grid CSS Grid Layout Module Level 1 \n CSS Grid Layout – Mozilla Developer Network \n Grid by Example – Rachel Andrew \n Grab & Go Grid Layout Patterns by Rachel Andrew \n Layout Demos by Jen Simmons \n Learn CSS Grid by Jen Simmons \n CSS Grid and Grid Inspector in Firefox \n Practical CSS Grid: Adding Grid to an Existing Design by Eric Meyer \n Progressively Enhancing CSS Layout: From Floats To Flexbox To Grid by Manuel Matuzović \n Box Alignment Cheatsheet by Rachel Andrew \n CSS Grid Layout by Rachel Andrew – An Event Apart video \n Revolutionize Your Page: Real Art Direction on the Web by Jen Simmons – An Event Apart video \n “Learn Grid Layout” video series by Rachel Andrew \n Why I love CSS Grid – a short video by Jen Simmons \n Modern Layouts: Getting Out of Our Ruts by Jen Simmons – An Event Apart video \n Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-new-css-layout-excerpt/", "title": "The New CSS Layout, An Excerpt", "content": "As we have seen, flexbox wasn’t designed for grid layouts—but this is where our newest specification is most at home. CSS Grid Layout does exactly what its name suggests: it enables the creation of grid layouts in CSS. This is  —laying things out as a row and a column at the same time. We’ll go over many more examples of Grid Layout in the rest of this book, but let’s start by seeing how Grid can solve the problem we had with making flexbox display like a grid. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In this example, I’m creating a three-column grid (Fig 3.17). My container has  , and I’ve created three equal-width columns with the   property, plus a new unit created for Grid: a flexible-length unit known as  . We’ll take a closer look at this unit in Chapter 5; for now, keep in mind that it represents a fraction of the space available in the grid container. With three tracks all set to   each, the available space is divided into three and distributed equally. This is all we need to do to get the direct child of the container to display as a grid. Unlike with flexbox, we don’t need to add any rules to the children; they will just pop themselves into each cell of the grid. As you can see, the items form a strict grid, without us needing to set any widths on them. We can solve another issue that we have with creating a flexbox grid, using properties that are part of the Grid specification. To create gaps between our flex items, in our flexbox example we used margins on the flex items and then needed to add a negative margin on the container to account for the unwanted left and right margin on the far left and right items. CSS Grid Layout includes a   property to space items out. This property is shorthand for   and  , which can also be specified individually. To demonstrate how this works, I’ve removed the margins on the items and the negative margin on the container and spaced the items out with  . You’ll produce the exact same layout as above in the browser, but without the need to mess around with margins and negative margins. Just as this book was going to print, the CSS Working Group resolved to change the name of the   properties.   will become  ,   will become  , and the   shorthand will simply be  . In addition, the definition of these properties has been moved to the Box Alignment Specification. This means that in the future, flexbox may also support gaps in the same way as Grid. Because browsers have already shipped these properties, they will alias the   names to the new names for the foreseeable future. At time of writing, no browser supports the new property names, so I’ve retained the   versions in these examples. If you want to be sure of supporting both versions, there’s no reason not to list both in your CSS, as in this example: Positioning items around the grid We can quickly move away from what flexbox allows us to do by taking advantage of our two-dimensional grid and positioning items on it. The most basic way of doing this is by using line numbers. A grid has numbered grid lines; they start from 1 for both rows and columns. Note that these lines are numbered per the writing mode of the document. Working in English, a   (LTR) language, column line 1 is on the left-hand side of the grid; row line 1 is at the top. In Arabic, a   (RTL) language, column line 1 appears on the right of the grid. The far edge of the grid (right in a LTR language and left in a RTL language) is represented by -1. You can immediately see some of the power of Grid Layout here. We can span columns   rows—something that is hard to do using existing layout methods. The background color of our cards extends to the gutter, even if the content is shorter. It’s also very easy to change how far a block spans—we can even leave white space! If I change the start line of card 3 to row line 3, we get an empty cell (Fig 3.19). Nothing can rise and land in the grid cell; this differs from the behavior of floats, which try to float up and fill the available space. Another method of positioning items on a grid involves using  . This allows you to describe your layout right in your CSS. To do this with our example, we first give each card a name with the   property. I’m just using letters   through  .  Next, I add the   property to the container. The value of this property describes what our layout should look like (Fig 3.20). There are a few things to keep in mind with  . To span across cells, we repeat the name of the area. Card 1 spans across the first two column tracks; thus   is repeated. The areas must be rectangular in nature—we can’t yet create an L-shaped area. To leave white space, and to leave a cell empty, use a full-stop character. If you replace the first   with  , that cell will remain empty when the layout is created (Fig 3.21). If your grid-area names are longer than one character, you may want to line up the visual rows and columns in the value of  . This is possible because more than one full-stop character can denote an empty cell—if they have no white space between them. You can also add more than one white-space character to space out grid-area names. This is a very nice way to work with layouts, given how easy it is to move items around. I enjoy working like this during the prototyping stage—rather than worrying about how to achieve layout, I can figure out the best way for my interface to be presented. Then I can go back to the markup to make sure it’s in a logical order based on those decisions. With these few examples, you already have enough knowledge to start using Grid Layout, and to make decisions about which layout methods to use. There is more to come, but keep in mind that although the specification is large and can do a lot of things, it is very simple at its core. You can do a lot with very little CSS. As you start building layouts, you will have questions, and will want to achieve more with these layout methods. That’s where the rest of this book comes in! Like this: \n\t\t\t\t\t\t\tRecently by Rachel Andrew\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/coding-with-clarity/", "title": "Coding with Clarity", "content": "Working code isn’t necessarily good code. Your code also needs to be easy to read, understand, and modify. It needs clarity, and to achieve that, it has to be organized well, with careful planning and proper separation of ideas taking place before you even open your code editor. Coding for clarity is something that separates the great developers from the merely good, and there are a few basic principles that can set you on that path. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites.  A List Apart  The single responsibility principle Imagine you’re working on a home project and you pick up a drill to drive a screw into a wall. When you pull the drill away from the screw, you discover that this drill has an interesting feature: it squirts a quick-drying drywall compound over the driven screw to hide it. Well, that’s great if you want to paint over the screw, but that’s not always the case. You shouldn’t have to get a second drill just to drill a hole in something. The drill would be much more usable and reliable if it just did one thing, and it would also be flexible enough to use in a variety of situations. The single responsibility principle states that a block of code should do one thing, and do it well. Like the drill above, limiting its functionality actually increases the usefulness of a block of code. Coding this way not only saves you a lot of headache, but it will save future developers on the project a lot of headache as well. Think of functions and methods in terms of responsibilities. As you increase its responsibilities, a block of code becomes less flexible and reliable, more demanding of changes, and more susceptible to errors. For the most clarity, each function or method should have one responsibility. If you’re describing what a function does and you have to use the word “and,” that function is probably too complex. What a function does should be simple enough to explain with only a descriptive function name and descriptive arguments. I was tasked recently with creating an electronic version of the Myers-Briggs personality test. I’d done this before, and when I first approached the problem a few years ago, I coded one giant function called  —it gathered the scores, generated the charts, and took care of everything in the DOM to display things to the user. The problem was that if anything had to change, you had to search through a mountain of code to figure out where to make the alteration. Also, if something went wrong in the middle of the function, it was a lot harder to find the error. So when facing the problem this time, I broke everything down into single-responsibility functions wrapped up in a module object instead. The resulting function called upon form submission looked like this: ( ) Extremely easy to read, understand, and modify—even a non-coder can make sense of this. And each of those functions does (you guessed it!) only one thing. This is the single responsibility principle in action. If I wanted to add form validation, rather than having to modify a giant working function (potentially breaking it), I could simply add a new method. This approach also enables related logic and variables to be segmented off, cutting down on conflicts for greater reliability, and it makes it very easy to reuse the function for other purposes if needed. So remember: one function, one responsibility. Large functions are where classes go to hide. If a function does lots of things that are closely tied together and that are working with the same data, it would make more sense to break it up into an object with methods, much like I did with my large form function. Command-query separation The funniest email chain I’ve ever seen was the   about a missing cat. Each time his coworker Shannon makes a request, David complies, but puts his own little twist on it and delivers something different than what was expected. The exchange is very funny and worth a read, but it’s less funny when your code does the same thing. Command-query separation provides a basis of safeguarding your code against unintended side effects to avoid surprises when functions are called. Functions fall into one of two categories:  , which perform an action, and  , which answer a question. You should not mix them. Consider the following function: This is a simplistic example—most side effects are harder to find—but you can see some potentially unanticipated side effects in action. The function name,  , tells us that the function is going to return the first name. But the first thing it does is convert the name to lowercase. The name says it’s getting something (a query), but it’s also changing the state of the data (a command)—a side effect that is not clear from the function name. Worse, the function then sets a cookie for the first name without telling us, potentially overwriting something we could have been counting on. A query function should never, ever overwrite data. A good rule of thumb is that if your function answers a question, it should return a value and   alter the state of the data. Conversely, if your function does something, it should alter the state of the data and   return a value. For maximum clarity, a function should never return a value   alter the state of the data. A better version of the code above would be: This is a basic example, but hopefully you can see how this separation can clarify intent and prevent errors. As functions and code bases become larger, separation becomes much more important, as hunting for the function definition whenever you want to use it just to find out what it does is not an efficient use of anybody’s time. Loose coupling Consider the difference between a jigsaw puzzle and Lego blocks. With a jigsaw puzzle, there’s only one way to put the pieces together, and there’s only one finished product. With Lego, you can put the pieces together any way you want to make any end result you want. If you had to pick one of these types of building block to work with before you knew what you’d be building, which would you choose?  is a measure of how much one program unit relies on others. Too much coupling (or tight coupling) is rigid and should be avoided. That’s the jigsaw puzzle. We want our code to be flexible, like Lego blocks. That’s loose coupling, and it generally results in much greater clarity. Remember, code should be flexible enough to cover a wide variety of use cases. If you find yourself copying and pasting code and making minor changes, or rewriting code because code changed somewhere else, this is tight coupling in action. (For example, to make the   function from earlier reusable, you could replace the hard-coded   with a generic ID passed to the function.) Other signs of this include hard-coded IDs in functions, too many function parameters, multiple similar functions, and large functions that violate the single responsibility principle. Tight coupling is most prevalent in a group of functions and variables that really should be a class instead, but it can also happen when classes depend on methods or properties from other classes. If you’re having trouble with interdependencies in functions, it’s probably time to think about breaking your functions into a class. I encountered this when looking at some code for a series of interactive dials. The dials had a number of variables, including dimensions, handle size, fulcrum size, and more. Because of this, the developer was forced to either use an absurd amount of function parameters or create multiple copies of each function with the variables hard-coded in each one. Additionally, each dial did something different when interacted with. This led to three sets of nearly identical functions—one for each dial. In short, coupling was increased due to the hard-coding of variables and behavior, so, like a jigsaw puzzle, there was only one way to put those pieces together. The codebase was unnecessarily complex. We solved the problem by breaking up the functions and variables into a reusable class that was instantiated for each of the three dials. We set up the class to take a function as an argument for output, so different outcomes could be configured when the individual dial objects were instantiated. As a result, we had fewer functions, and the variables were stored in only one place, making updates much easier. Classes that interact with each other can also be culprits of tight coupling. Let’s say we have a class that can create objects of another class, like a college course that can create students. Our   class works fine. But then we need to add a parameter to the constructor of the   class. Oh no! Now we have to modify our   class to account for the change in the   class. You shouldn’t have to modify a class because another class changes. This is a classic case of tight coupling. Constructor parameters can be passed as an object with the receiving object having fallback default values, which loosens coupling and means code won’t break when you add new parameters. The point is that you should build your code like Lego blocks, not like jigsaw puzzle pieces. If you find yourself facing problems similar to the ones above, the problem is probably tight coupling. High cohesion Have you ever seen a kid clean a room by stuffing everything into the closet? Sure, it works, but it’s impossible to find anything and things that don’t belong together often get placed right next to each other. The same can happen with our code if we don’t strive for a high level of cohesion.  is a measure of how much the various different program units belong together. A high level of cohesion is good and adds clarity to code blocks; a low level of cohesion is bad and leads to much confusion. Functions and methods in a code block should make sense together—they’ll have a high level of cohesion. High cohesion means sticking related things, like database functions or functions relating to a particular element, in one block or module. This helps not only with understanding how such things are laid out and where to find them, but also with preventing naming conflicts. If you have 30 functions, the chances of a conflicting name are far greater than if you have 30 methods split over four classes. If two or three functions use the same variables, they belong together; this is a great case for an object. If you have a series of functions and variables that control a page element, like a slider, it’s a great opportunity for high cohesion, so you should bundle them up into an object. Remember the example above about the class we made that decoupled the solution for the dial? That’s a great case of high cohesion as a cure for tight coupling. In that case, high cohesion and tight coupling were on opposite ends of a sliding scale, and focusing on one fixed the other. Repeated code is a sure sign of low cohesion. Similar lines of code should be broken into functions, and similar functions should be broken into classes. The rule of thumb here is that a line of code should never be repeated twice. In practice, this isn’t always possible, but for clarity’s sake you should always be thinking about how to cut down on repetition. Similarly, the same bit of data should not exist in more than one variable. If you’re defining the same bit of data in multiple places, you definitely need a class. Or if you find yourself passing references to the same HTML element to multiple functions, the reference should probably be a property in an instance of a class. Objects can even be put inside other objects to increase cohesion further. For example, you might put all AJAX functions in a single module that includes objects for form submission, grabbing content, and login syntax, like so: Conversely, you shouldn’t throw unrelated things together in the same class. An agency I used to work for had an internal API with an object called   that had a hodgepodge of common methods and variables that had nothing to do with each other. The class became huge and confusing simply because there was little thought given to cohesion. If properties are not used by multiple methods in a class, this can be a sign of low or bad cohesion. Similarly, if methods can’t be reused in a few different situations—or if a method isn’t used at all—this can also be a sign of low or bad cohesion. High cohesion helps to alleviate tight coupling, and tight coupling is a sign that greater cohesion is needed. If the two ever come into conflict, though, choose cohesion. High cohesion is generally a greater help to the developer than loose coupling, although both can usually be accomplished together. Conclusion If our code is not immediately clear, problems occur. Achieving clarity is about so much more than proper indentation—it takes careful planning from the beginning of the project. While tough to master, abiding by the principles of single responsibility, command-query separation, loose coupling, and high cohesion can improve clarity in our code greatly. It should be a consideration in any significant programming project. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/web-typography-tables/", "title": "Web Typography: Designing Tables to be Read, Not Looked At", "content": "Good designers spend a great deal of time sweating over typography. They agonise over typefaces, iterate through type scales and meticulously apply white space, all in the service of the reader. Then comes along a table with the temptation to get creative, and all thoughts of the reader go out of the window. And yet tables are there to be read, referenced and used, not merely looked at. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Set tables as text to be read Tables come in many forms. Some contain simple numbers, others are complex with mixtures of numeric data and textual information. Some require reading row by row, others are scanned vertically. The potential use for tables is as varied as the written word. They can be financial statements, bus timetables, multilanguage dictionaries, tables of contents, numerical conversions, pricing options, feature comparisons, technical specifications, and so on. Despite the huge variation in table size, complexity, contents and purpose, every table shares two simple design principles: they should be readable and support a sense of the data held within. They should not be prettied up to satisfy a sense of aesthetic when simply looked at. That said, a well-designed table can still be a thing of beauty but with the form following the function. Tables are not pictures of data: they are catalogues of data to be perused, parsed, referenced and interrogated. A well-designed table will enable the information to be read and understood, and will reveal the patterns and correlations inherent in the data. As Jan Tschichold, the virtuoso of typography design, put it in  : Tabular matter need no longer be a rather unpleasant job to design: on the contrary, it can become a really charming and artistic exercise, in no way less interesting than any other area. Wherever possible plan the readability of every table in advance. Your design process should be an investigation into making the data undemanding to read, simple to follow and easy to extract. Just as you wouldn’t design body text with the aim of fitting as many words as possible on the screen, so you shouldn’t treat designing a table as an exercise in cramming as much data as possible into one space. You might be tempted to reduce the text size of your table – and if the data is entirely numeric you might be able to get away with it. Your reader should still be able to be comfortably read and interpret the table from their normal position, without needing to lean in. Don’t stretch tables Many designers will instinctively apply a width to their tables – just as they might an image – stretching them to fill the text column or page. And that is the appeal of setting tables full-width: you can make them look somewhat image-like when viewed from afar. However, while a table spread across the screen might look preferable from a distance, on closer inspection it will be harder to read as the data will be unnecessarily separated. To add insult to injury, tables set full-width are often replete with background colours and borders to give the table further the texture of an image, when what your reader really requires is the texture of text. For the sake of your readers, avoid these temptations. You might consider making all the columns an even width. This too does nothing for the readability of the contents. Some table cells will be too wide, leaving the data lost and detached from its neighbours. Other table cells will be too narrow, cramping the data uncomfortably. Table columns should be sized according to the data they contain. Columns of small numbers should be narrow, and columns of paragraphs should be relatively wide. This sounds like a lot of effort, and for a print designer it would be, as they would have to size each column manually in their layout software. Fortunately, web browsers are very clever when it comes to laying out tables and will do all that hard work for you. Browsers have been laying out tables automatically according to complex algorithms since long before   came along – just let them do their thing. Keep table furniture and fills to a minimum The statistician and information designer Edward Tufte introduced the concept of   in his 1983 classic,  . He defines data-ink as ‘the non-erasable core of the graphic’, whereas non-data-ink is the ink used in the graphic, not to directly represent data but for scales, labels, fills and edges. Tufte goes on to define the   as the proportion of ink that is used to present actual data compared to the total amount of ink used in the entire graphic. The goal is to design a graphic with the highest possible data-ink ratio (tending towards 1.0) without eliminating what is necessary for effective communication. Where Tufte talks about graphics he includes charts, diagrams and tables, and where he uses ‘ink’ we can think of pixels. In terms of tables, he’s saying that we should remove almost everything in the design which is not data or white space. Minimise furniture, maximise information. This is an ideal first principle to bear in mind when considering the   design of a table. As a starting point, avoid any border or frame surrounding the table. This is a Victorian embellishment which is entirely unnecessary as text alignment will shape the table just fine. Try to achieve a readable table using just alignment, spacing and grouping. Avoid zebra striping, tints and fills, and any other backgrounds. These can be superficially pretty but are usually a distraction. They serve to distort the meaning of the data by highlighting every other row to the detriment of neighbouring rows. Only use tints as a subtle means of guiding your reader’s eyes, and then only if you cannot arrange the data to that end. If you choose to tint, do so only in the primary direction of reading: down if lists, across otherwise. When it comes to lines and borders between rows and columns – typographically referred to as   – the same applies: use them judiciously and preferably not at all. In   Jan Tschichold sums this up wonderfully: Tables should not be set to look like nets with every number enclosed. Try to do without rules altogether. They should be used only when they are absolutely necessary. Vertical rules are needed only when the space between columns is so narrow that mistakes will occur in reading without rules. Tables without vertical rules look better. Thin rules are better than thick ones. Avoid using row or column borders unless the data alignment, spacing and grouping are not sufficient to guide your reader’s eye. If you do need to use rules for this purpose, use them in one direction only and employ a lighter colour to reduce the impact of the lines: you are making a distinction, not constructing a barricade. Left-align text, right-align numbers, and align headings with data In the spirit of treating tables as artefacts to be read, don’t centre text within tables. Align table text as you would anywhere else; that is, aligned left. As text in tables tends to end up in narrow columns, don’t justify the text either – leave it ragged-right – or you will end up with rivers flowing down the tables, potentially causing confusion and certainly harming readability. You can hyphenate, however, particularly if the table columns would otherwise have a pronounced rag. Right-align numbers to help your reader make easier comparisons of magnitude when scanning down columns. To aid scanning in this manner you will need consistent precision of your numeric data; that is, use the same number of decimal places. For consistency and ease of understanding, match the alignment of headings to the alignment of the data. Right-align headings of numeric data and left-align headings of columns with text, for example: Align to the decimal point You may find yourself not having control of numerical precision, or perhaps the data you’re working with is rounded to the same   rather than adhering to the same precision. In this case, simply right-aligning a column of numbers will not help your reader scan down the column – small, high-precision numbers will look at first glance like a large number. Instead, align numbers to the decimal point. This will enable your reader to more readily compare magnitudes among a wider variety of data: Aligning to the decimal point was theoretically possible by using the     attribute on a   tag, but in reality it was never supported. The modern way to align numbers to a decimal point (or to any character, in fact) is through a new value of the   property, although at the time of writing this is languishing in the   Text Level 4 Module  and support is patchy at best. The syntax of the new value is simple. You include the alignment character (usually a full stop or comma) in quotes, followed by a space and your desired alignment keyword, which defaults to   if you omit it. For example, the following will centre the data and align to a decimal point as in our prior example: By specifying different alignment characters you can lay out more complex tables in a useful way; in this example, aligning digits to ‘×’ and ‘:’. Use tabular lining numerals in tables of numbers Many tables, such as financial statements or timetables, are made up mostly of numbers. Generally speaking, their purpose is to provide the reader with numeric data, presented in either columns or rows, and sometimes in a matrix of the two. Your reader may use the table by scanning down the columns, either searching for a data point or by making comparisons between numbers. Your reader may also make sense of the data by simply glancing at the column or row. It is far easier to compare numbers if the ones, tens and hundreds are all lined up vertically; that is, all the digits should occupy exactly the same width. Digits of the same width can inherently be found in monospaced fonts, and there is nothing wrong with choosing a suitable monospaced font to present a table of data (see ‘Combining typefaces’). However, many proportionally spaced fonts (those where a   is narrower than an  , and a   is wider than an  ) also come with additional sets of figures which are monospaced. These are called  . As well as being of equal width, tabular numerals will be subtly designed differently from the standard proportional numerals. For example, a   will normally have a bar for its base, and a   (zero) may be designed slightly narrower to better fit the chosen number width. Tabular numerals are usually available in old-style and lining variations. Use tabular lining numerals to provide your reader with the most effective way to reference vertically and horizontally in tables of data. To specify tabular lining numerals, set the   property with a value of   and  : The equivalent properties for legacy browsers requiring  , use the   and   OpenType feature tags. If you need to specify proportional numerals, set the   property with a value of  . For legacy browsers requiring  , use the   OpenType feature tag. Put white space to work to group and separate Having eliminated rules and fills (borders and backgrounds) from your table, you will need to apply white space to your table so your reader can make sense of it. It is at this point that you should remove from your mind’s eye all visions of spreadsheets and other such uniform grids, and think instead in terms of typography and simple gestalt grouping principles. You will primarily need to separate the data so that each element can be individually identified and read as separate from the others. To have more control over the spacing, first collapse the spacing between borders: In traditional   tables, adjacent cells each have their own distinct borders which are separated from each other, with the separation still present even if the borders are not. In the collapsed border model, adjacent table cells share borders. As we are removing (almost) all cell borders, and any we retain will be single key lines, the collapsed border model is the most appropriate. Now apply padding to the table cells to separate the data. You’ll find that adding a smaller amount of padding to the top of the cell is a useful way to provide a visually balanced separation from the rows above and below. To ensure everything lines up nicely, apply the same padding to heading cells as to data cells. Because line lengths are often very short in tables, you can reduce the line height right down. In the following example, we’ve removed all additional line spacing, but you may need more depending on your choice of font and the amount of text in the table cells. The gestalt grouping principles most useful in tables are those of proximity and similarity. Move related data closer together to be distinct from other data; in other words, space apart groups of rows or columns. A by-product of grouping rows is that the data becomes much easier to scan and refer to than if the table consisted of a succession of undifferentiated rows. Ensure data of a similar content or meaning look similar at a glance, which you can do through alignment, colour and font style. We will attend to the typographic specifics of table captions in ‘Choosing typefaces for functional text’ but it’s worth noting now how to mark up captions for tables. If you are choosing to place your table inside a   element, which is a perfectly reasonable thing to do, then use a   element before or after the table. If your table is not inside a   element, or you have multiple items in the figure, use the aptly named   element, which   provides specifically for tables. Always write the   tag immediately after the opening   tag and before any table data, like this: You can position the caption either above or below the table using the   property and a corresponding value of either   or  . The following table shows a caption and demonstrates gestalt grouping principles by separating the data into related rows: Note that, in this example, the numbers do not align to the decimal point. This is because the purpose of the table is for the reader to easily identify and extract a multiplication factor. In this instance there is no obvious use case for comparing the relative magnitudes of the factors, which is when decimal alignment would be useful. Do not over-stylise tables The French writer-aviator Antoine de Saint-Exupéry wrote    Quoting de Saint-Exupéry may have become a cliché, but his idiom is entirely apt when applied to table design. There is no need to make a table look like a spreadsheet. A spreadsheet is a tool unto itself; a table is for presenting data and information that can be read. Spreadsheet software offers a multitude of options for table styles, which add text formatting, borders, background fills and all manner of ornament. They may make pretty pictures but do nothing for table readability, so do not try to emulate them. Tables can be beautiful but they are not works of art. Instead of painting and decorating them, design tables for your reader. Adapt tables to small screens Tables regularly require a fair bit of horizontal space to display the information they contain. Even when judiciously designed and edited, a typical table may need to be wider than the 45–75 characters we normally allow for paragraphs of text. For small screens, such as phones, designing readable tables which work under such cramped conditions presents us with a serious challenge. The best approaches always deal with each table on case-by-case basis, but that’s not always possible if we need to generically style whatever comes out of a   database. One immediate approach is to use either a condensed font   a slightly smaller size (but not both smaller and condensed). In both cases, readability must remain paramount and other options should also be explored. One way to save horizontal space, particularly when you have short pieces of data but long headings, is to set the headings at an oblique angle. You can use a simple   translation to achieve the effect. You will also need to absolutely position the headings so the original width of the columns isn’t retained and they shrink to wrap the data instead. The simplest solution to help tables of any size and complexity is to let the browser lay out the table as best it can and render part of the table off-screen as necessary. Provided you then enable your reader to scroll the table sideways independently of the rest of the text, the table can be relatively easily brought into view. To do this, first wrap your table in a   element: Then apply the following simple rules to hide the portion of the table off-screen and enable your reader to scroll the table without affecting the rest of the text: It is important not to set a width on your table; the browser can then compress the table as far as it can before overflowing off the screen. To preserve readability, make good use of non-breaking spaces and   to limit the amount the data wraps in the cells. It’s better to have a readable table that requires scrolling than an unreadable one which doesn’t. You can safely linearise simple data tables when space is limited. The tables most suitable for this treatment are lists of structured data; for example, an employee directory: When there is not enough room for the table to render comfortably, we can set it with a completely different layout. This is less compact overall, and takes more space vertically, but it succeeds in fitting the table into a much narrower viewport: The two renderings of our employee directory table use exactly the same markup, comprising the conventional   elements you would expect in any table. The one addition is a   attribute on each cell enabling us to repeat the label in the list view, should we need to. There are four simple steps to turning the table into a list, using a media query and   (no JavaScript is required). You will need to apply some additional styling for aesthetics and readability, but the responsiveness described can be accomplished in these few lines of  : This technique was first popularised by Aaron Gustafson . There are many different techniques  available for making data tables responsive. Some are simple  -only methods (we’ve covered two already); others are complex, enhanced by JavaScript. When considering which technique to use, ask yourself how your reader will use the table. In particular, consider if your reader is likely to compare either rows or columns – these kinds of tables need extra attention owing to the way they are used. When being able to compare columns is important, one method is to hide non-essential fields and provide an option to turn them back on. This technique was popularised by Filament Group  using a stocks table as an example: Tables are a frequently overlooked aspect of reading, sometimes overstyled, sometimes poorly thought out. Responsiveness is a particularly thorny issue as the best solutions depend very much on the utility of the table. Tables can be packed with data, rich in content and meaning. Give them the attention they deserve. Want to read more? This excerpt from   will help you get started.  . Like this: \n\t\t\t\t\t\t\tRecently by Richard Rutter\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/what-the-failure-of-new-coke-can-teach-us-about-user-research-and-design/", "title": "What the Failure of New Coke Can Teach Us About User Research And Design", "content": "In the late 1970s, Pepsi was running behind Coca-Cola in the competition to be the leading cola. But then Pepsi discovered that in blind taste tests, people actually preferred the sweeter taste of Pepsi. To spread the word, Pepsi ran a famous advertising campaign, called the Pepsi Challenge, which showed people tasting the two brands of cola while not knowing which was which. They chose Pepsi every time. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As Pepsi steadily gained market share in the early 1980s, Coca-Cola ran the same test and found the same result—people simply preferred Pepsi when tasting the two side by side. So, after conducting extensive market research, Coca-Cola’s solution was to create a sweeter version of its famous cola—New Coke. In taste tests, people preferred the new formula of Coke to both the regular Coke formula and to Pepsi. Despite this success in tests, when the company brought New Coke to market, customers revolted. New Coke turned out to be one of the biggest blunders in marketing history. Within months, Coke returned its original formula—branded as “Coca-Cola Classic”—to the shelves.  In the end, sales showed that people preferred Coke Classic. But Coca-Cola’s research predicted just the opposite. So what went wrong? The tests had people drink one or two sips of each cola in isolation and then decide which they preferred based on that. The problem is, that’s not how people drink cola in real life. We might have a can with a meal. And we almost never drink just one or two sips. User research is just as much about the way the research is conducted as it is about the product being researched. For the purposes of designing and researching digital services and websites, the point is that people can behave differently in user research than they do in real life. We need to be conscious of the way we design and run user research sessions and the way we interpret the results to take real-life behavior into account—and avoid interpretations that lead to a lot of unnecessary work and a negative impact on the user experience. To show how this applies to web design, I’d like to share three examples taken from a project I worked on. The project was for a government digital service that civil servants use to book and manage appointments. The service would replace a third-party booking system. We were concerned with three user needs: booking an appointment; viewing the day’s appointments; and canceling an appointment. Booking an appointment We needed to give users a way to book an appointment, which consisted of selecting a location, an appointment type, and a person to see. The order of these fields matters: not all appointment types can be conducted at every location, and, not all personnel are trained to conduct every appointment type. Our initial design had three select boxes in one page. Selecting an option in the first select box would cause the values in the subsequent boxes to be updated, but because it was just a prototype we didn’t build this into the test. Users selected an option from each of the select boxes easily and quickly. But afterwards, we realized that the test didn’t really reflect how the interface would actually work. In reality, the select boxes would need to be updated dynamically with AJAX, which would slow things down drastically and affect the overall experience. We would also need a way to indicate that something was loading—like a loading spinner. This feedback would also need to be perceivable to visually-impaired users relying on a screen reader. That’s not all: each select box would need to have a submit button because  . This would also cover scenarios where there is a  , otherwise, users would be left with a broken interface. With that said, we weren’t thrilled with the idea of adding more submit buttons. One call to action is often simpler and clearer. As mentioned earlier, the order in which users select options matters, because completing each step causes the subsequent steps to be updated. For production, if the user selected options in the wrong order, things could break. However, the prototype didn’t reflect this at all—users could select anything, in any order, and proceed regardless. Users loved the prototype, but it wasn’t something we could actually give them in the end. To test this fairly and realistically, we would need to do a lot of extra work. What looked innocently like a simple prototype gave us misleading results. Our next iteration followed the   pattern; we split out each form field into a separate screen. There was no need for AJAX, and each page had a single submit button. This also stopped users from answering questions in the wrong order. As there was no longer a need for AJAX, the related accessibility considerations went away too. This tested really well. The difference was that we knew the prototype was realistic, meaning users would get a similar experience when the feature went into production. Viewing the day’s appointments We needed to give users a way to view their schedule. We laid out the appointments in a table, where each row represented an appointment. Any available time was demarcated by the word “Available.” Appointments were linked, but available times were not. In the first round of research, we asked users to look at the screen and give feedback. They told us what they liked, what they didn’t, and what they would change. Some participants told us they wanted their availability to stand out more. Others said they wanted color-coded appointment types. One participant even said the screen looked boring. During the debrief, we realized they wanted color-coded appointments because the booking system (to which they had become accustomed) had them. However, the reason they used color for appointments was that the system’s layout squeezed so much information into the screen that it was hard to garner any useful information from it otherwise. We weren’t convinced that the feedback was valuable. Accommodating these changes would have meant breaking existing patterns, which was something we didn’t want to do without being sure. We also weren’t happy about making availability more prominent, as this would make the appointments visually weaker. That is, fixing this problem could inadvertently end up creating another, equally weighted problem. We wanted to let the content do the work instead. The real problem, we thought, was asking users their opinion first, instead of giving them tasks to complete. People can be resistant to change, and the questions we asked were about their opinion, not about how to accomplish what they need to do. Ask anyone their opinion and they’ll have one. Like the Coca-Cola and Pepsi taste tests, what people feel and say in user research can be quite different than how they behave in real life. So we tested the same design again. But this time, we started each session by asking users questions that the schedule page should be able to answer. For example, we asked “Can you tell me when you’re next available?” and “What appointment do you have at 4 p.m.?” Users looked at the screen and answered each question instantly. Only afterward did we ask users how they felt about it. Naturally, they were happy—and they made no comments that would require major changes. Somewhat amusingly, this time one participant said they wanted their availability to be   prominent because they didn’t want their manager seeing they had free time. If we hadn’t changed our approach to research, we might have spent a lot of time designing something new that would have had no value for users. Canceling an appointment The last feature involved giving users a way to cancel an appointment. As we were transitioning away from using the third-party system, there was one situation where an appointment could have been booked in both that system and the application—the details of which don’t really matter. What is important is that we asked users to confirm they understood what they needed to do. The first research session had five participants. One of those participants read the prompt but missed the checkbox and proceeded to submit the form. At that point, the user was taken to the next screen. We might have been tempted to explore ways to make the checkbox more prominent, which in theory would reduce the chance of users missing it. But then again, the checkbox pattern was used across the service and had gone through many rounds of usability and accessibility testing—we knew that the visual design of the checkbox wasn’t at fault. The problem was that the prototype didn’t have form validation. In production, users would see an error message, which would stop them from proceeding. We could have spent time adding form validation, but there is a balancing act between the speed in which you want to create a throwaway prototype and having that prototype give you accurate and useful results. Summary Coca-Cola wanted its world-famous cola to test better than Pepsi. As soon as tests showed that people preferred its new formula, Coca-Cola ran with it. But like the design of the schedule page, it wasn’t the product that was wrong, it was the research. Although we weren’t in danger of making the marketing misstep of the century, the design of our tests could have influenced our interpretation of the results in such a way that it would have created a lot more work for a negative return. That’s a lot of wasted time and a lot of wasted money. Time with users is precious: we should put as much effort and thought into the way we run research sessions as we do with designing the experience. That way users get the best experience and we avoid doing unnecessary work. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/yes-that-web-project-should-be-a-pwa/", "title": "Yes, That Web Project Should Be a PWA", "content": "It seems like ever since    coined the term “Progressive Web App” in an effort to describe a new class of website, there’s been a great deal of confusion over exactly what a Progressive Web App (PWA) is. Sure, her husband, Alex Russell, put together a handy guide to the  , and they have been the subject of reams of documentation, dozens of blog posts, and equally as many conference talks. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Even with so much well-written, accessible content about PWAs freely available,  . Maybe you’ve run into one or more of these: If you’re building a PWA, you need to use a JavaScript framework. To build a PWA, start with a single page app. PWAs only make sense for “apps” your users want to install. PWAs only make sense in mobile. PWAs are an Android thing. None of these are true, but like so much misinformation these days, each contains a shred of truth that has been contorted into a falsehood. If you’re considering building a PWA, you   use a JavaScript framework or build it as a single page app, but it’s by no means necessary. They’re an option for building a PWA just like they’re an option for any other web project. After all, every PWA is (or at least should be) a website. PWAs just have some features that empower them to do more than websites have traditionally been able to … like install. But, similarly, installation is not the   of every PWA. And, while many of the first PWAs were focused on mobile and only worked on Android, PWAs are  . They’re also  ; Microsoft, Mozilla, Opera, and Samsung are all on board. Apple   (one of the technical underpinnings of PWAs), but time will tell if they’ll support aspects like installation. No matter, as  ! Sadly, misinformation like this has convinced many designers and developers (and their management teams) that PWAs aren’t appropriate for their projects. They  ! Your site—every site—should be a PWA. This approach offers benefits for every project on the web, but I’ll get to that in a minute. Before I do, I want to level-set on what, exactly, makes a PWA a PWA. If you’ve been tracking PWAs closely or have already built one, you can skim or skip the next section. If you aren’t all that familiar or don’t feel like you have a good grasp on what they are, no worries, the next section is a very brief primer that will get you up to speed quickly. So what is a PWA? As I mentioned, a PWA is a website with special powers. The term “app” in the “Progressive Web App” is not indicative of the sort of content or experience users should expect with a PWA. You shouldn’t get hung up on it;  . PWAs have the ability to connect with the operating system (and, thereby, its users) on a deeper level through installation and APIs offering capabilities like notifications, access to the address book, and more. Not all of these APIs require installation for access, but some do. It may help to think about a PWA as being a website++. What makes a PWA a PWA? Not much, actually; there are only three requirements: That’s it. Once you have those in place, your website is a Progressive Web App. At least  . Why the qualification? Well, this is where things get a little more nuanced. Back in 2015, when he debuted the PWA concept,   (or at least were capable of). Most of those characteristics are, without a doubt, how we should be building for the web. Others are not as universal and would not make sense in every kind of project. I suspect that might be one of the sources of confusion for folks considering adopting the PWA approach and it’s the reason I decided to write this article. Quality experiences and the universal benefits of PWAs In the next few sections, I will discuss several web project archetypes and how adopting some of these PWA characteristics can benefit their users. After all, that’s who we’re doing this for. But before I get to that, I want to discuss the seven characteristics of PWAs that are useful in any web project. As I mentioned, there are some characteristics of PWAs that will absolutely provide value to your users and are well worth your time and consideration. In fact, all of them are considered best practices in web design and development. First off, PWAs must be  . As I mentioned in my discussion of their technical requirements, PWAs must be running under HTTPS. Period. Thankfully, the cost of running your site under HTTPS has  . Sure,   over, but it’s worth it for so many reasons. The primary one is that it protects your users from malicious man-in-the-middle attacks  ,  ,  , or  . HTTPS ensures that both the code and content you send to your users actually arrives intact.  , but it’s an important step in protecting your users and your data. Running HTTPS is also a prerequisite for access to many of the newer (and more sensitive) APIs including   and   and for performance-boosting technologies like   and  . It’s also worth noting that   and  . I mentioned earlier that PWAs were never intended to be a mobile-only approach. PWAs are for everyone. Making your project available to more people on more devices with wildly varying operating systems, browser capabilities, system APIs, and screen sizes is only going to increase your reach and create more opportunities to be successful. This is where   and   come in. By building responsive layouts, your designs will adapt to provide the most appropriate layout given the screen real estate you have to work with, whether dependent on the dimensions of the device or on the window size set by your user. Progressive enhancement enables your projects to adapt to an even wider array of variance, in both the execution environment (device, OS, etc.) and, more importantly, your users. Progressive enhancement also helps you avoid situations where   because they happen to use a device or browser you’re unfamiliar with or haven’t tested on. It ensures your site works on any device that can access the web, regardless of its capabilities, allowing you to use your valuable time optimizing that experience for more modern browsers and devices. It’s also   in the long-run. Another quality Alex identified was that many PWAs are “app-like”. Note the  . They are not apps, but rather, provide   that users—dare I say it?—enjoy using. The more you can do to provide a consistent, seamless, effortless user experience (which is really what “app-like” is implying here),  . It’s worth noting that this doesn’t mean you have to use JavaScript; it simply means you should think about the flow your users take through your site and take every opportunity to remove the friction from the process of them accomplishing their goals. If you’ve built something, you probably want folks to find it. PWAs, by definition, are  . Your site’s content should be written in such a way that it pops up organically when people search for related topics. Don’t get all spammy, but take care to author content in a thoughtful, appropriate, and straightforward way.  Related to discoverability is that PWAs are  . If your users can reach a certain point in your site via natural navigation, you should do your best to ensure they can save their place by bookmarking it or when they re-launch their web browser and your site’s tab is re-launched. This also plays into how shareable your project is. You may also want to do yourself a favor and spend some time putting together some   and some   to make your content even more shareable. Last, but certainly not least, there’s  . This is the big one that gets developers so excited. Offline capabilities and persistent storage has, to some extent, been possible for a while now; heck, Microsoft debuted  ! Alas, while client side data stores– ,  , etc.–have definitely come of age in the last few years,  . Then came   and the  . These two technologies work in concert with the   to make, intercept, augment, and store resource requests made from within your site, meaning your users may still access your content, even if their network connection is interrupted. There are a ton of fantastic resources covering the ins and outs of Service Workers, so I’m going to skip the technical stuff and just talk about some of the neat things you can do with them:  you know your users are going to need. This can improve performance dramatically.  requested by your site so they don’t need to be retrieved from the server each time a new page is loaded. This improves performance on navigation as well as on return visits.  This prevents users from seeing the browser’s generic “You’re not connected” message.  and provide the “live” copy of a given resource if it’s available, falling back to a previously cached “stale” version if it’s not. This can also prevent users from seeing “You’re not connected” messages.  (which tend to be considerably smaller) versions of those images if the browser supports them. This strategy allows you to provide alternate image sources that improve performance   having to modify your markup. Service Workers are capable of a whole lot more—some of which I will get into shortly—and are on track to be granted many more incredibly useful features in the not too distant future. They have already proven their worth and bring value to any project on the web. For a useful list of recipes, check out   or  . Other PWA benefits by project type Now that we’ve looked at the universally-beneficial qualities of PWAs, let’s shift gears. Every project is different, but there are a handful of archetypes that most web projects tend to fall into. And each of those archetypes can derive real benefits from running as a PWA. Informational When I think about informational sites, I’m talking about the kinds of sites many of us in the industry refer to as “brochureware.” Vanity sites are a good example of this. Small business sites whose interactivity tops out at a contact for or a phone number link are another. Portfolios would also fall into this category as would many restaurant sites. In most cases, projects like these are there to serve folks wanting to know more about you, your business, a project, or something similar. In most cases, you’re not going to see a ton of repeat visits. Folks come to the site looking to find out a specific piece of information—which hopefully they can access quickly and easily—and they’re off again. They might return, but they might not, meaning the  performance gains provided by a Service Worker’s offline caching could be useful, but likely won’t have quite the level of impact it would have on a site that gets frequent repeat visits. It’s also highly unlikely—though not impossible—that someone will actually install a project like this. Depending on the type of site you’re building, you might consider integrating some device APIs. If the site is for a brick-and-mortar business, add   support. If you have sales or specials you’d like to inform your visitors about, you might consider integrating Notifications (either   or  ). Even though two of the oft-touted “major” benefits of being a PWA—install-ability and offline capability—are less applicable for informational sites, making projects like these a PWA is still beneficial. Those are just two aspects of being a PWA. Your users will thank you for building a site that works on every one of their devices, is easy to use, comes up in search, and is easily shared with their friends. Periodical Periodical sites encompass everything from a blog or newsletter or podcast to online comics, magazines, newspapers, and video programs. These sorts of projects are like informational projects, but are updated regularly (or semi-regularly). They also have an audience that is likely to return (ahem) periodically to read a new article, watch a new video, or listen to a new podcast episode. Since they share much of their DNA with informational sites—heck, a periodical may even be part of an informational site—all of the qualities that benefit informational sites benefit periodicals as well. There are, however, some capabilities that PWAs offer that periodicals are perfectly suited to take advantage of. In discussing promotions or specials, I mentioned that   could be an option for informational sites. They should be a given for a periodical site. Push Notifications provide a mechanism for your server to send an update to any instances of your Service Worker that are installed on your users’ machines. And, assuming they’ve granted you permission, those updates can be displayed to your users even if they don’t have your PWA installed or a browser tab open to your site. Don’t take this as an opportunity to spam your users, as you’ll likely lose their eyeballs and business. Instead, choose appropriate times to ping them. If your site only gets updates once or twice a week, notifying them of individual posts is probably good and can provide a nice alternative for folks who don’t use a feed reader. If you have frequent updates, consider a daily or weekly roll-up. This might even be a good candidate for some A-B testing. You could also up your game by offering an easy in-page tool for saving an article for offline reading. Why would you want to do that rather than caching everything the user ever sees using the Service Worker? Well, given the nature of a periodical, the reuse of individual content items is likely pretty low. If you cache everything the use ever sees—especially if your content contains a lot of high resolution images—you’re gonna be filling their cache up with stuff they may never want to see again. In order to be a good web citizen, you could either clean that up regularly by keeping track of the last time a resource was accessed (which, frankly, seems like a lot of work) or you could cache just the necessary long-lived resources like your CSS and JavaScript files. Then you can put your users in control by providing   that enables them to save an entry for later. Continuing our journey through Service Worker land, you could start exploring   to pull in new resources periodically. If you’re a newspaper, maybe you want to prime your users’ caches every morning with the front page and the top feature stories. If you’re a podcast, maybe you want to load in the newest episode on a regular cadence. Again, to play nicely in the sandbox, you’ll probably want to trash older articles, episodes, and so on, but this could be a great way to provide an incredibly fast experience for your users. Think about it … they launch your site and the browser already has everything it needs to render today’s issue. Magic! Finally, periodicals are one of those archetypes where the option to install your site begins to make sense. Some people like being able to hit an icon on their home screen or in the Start Menu to access their local newspaper. It’s not for everyone and may not be right for every periodical, but it’s an option. And offering your users the ability to install your PWA comes for free, so you may as well embrace it and make sure your   has been thoughtfully authored to provide a good user experience when your PWA is installed. Transactional Any site that facilitates the exchange of information could be considered transactional. The most common examples include online shops, banking and stock trading tools, travel booking systems, and payment portals. PWAs have, to a large extent, already proven their value in this area. A quick peek on   revealed the following “wins”:  increased website conversions by 20%, pageviews by 66%, sessions by 59%, and reduced bounce rate 51%.  saw a 3× increase in conversion and 160% increase in shopper sessions and first-time shoppers are 3× more likely to convert on the PWA than in native app.  saw a 17% increase in conversions, a 51% increase in mobile sessions overall and a 53% increase on iOS alone. The kicker on that last one? iOS doesn’t even support Service Workers! It’s well-known that  , so the speed improvements granted by a smart caching and offline strategy with Service Workers are incredibly important here. But there are numerous other ways PWAs can benefit transactional sites as well. Since I mentioned offline, I’ll add that your offline strategy should not begin and end with Service Workers. For a while now, we’ve used cookies to track transactional data shopping cart contents, but cookies have always been severely limited in terms of the amount of data they can store because they get sent along with every network request. With  ,  , and  , we have the ability to store more (and richer) data about the transaction taking place on the client side. Storing this information on the client makes it easier to recover from problems like a network loss. If a transaction fails, you will still have access to the data (which might have otherwise been lost in a failed POST) and you can either periodically try the transaction again or wait until you see the network is back before submitting it. Either way, adding real-time messaging about what’s going on and how you are working to resolve it will go a long way toward assuring your users that their data is not lost. If your project is highly transactional, you will definitely want to look at   as a means of keeping your users’ local data in sync with server data. For example, if you are building a banking system, synchronizing information like recent transactions and current balances will be incredibly useful to your customers. Same goes with current stock prices and balances if you’re working on a trading platform. In most transactional scenarios, notifications can be quite helpful. Borrowing on the scenario I mentioned earlier, notifications can be used to let someone know when their transaction has completed (after all, in a PWA you could complete the transaction during a Background Sync when your site isn’t running). Notifications come in a two flavors:   are triggered via JavaScript in an active page,   are sent from the server and can be delivered even when the site isn’t open. Depending on the scenario, one or the other will probably make more sense. Just be aware that Push Notifications are   as Web Notifications … yet. For transactional sites that are frequently accessed (and I realize “frequently” is a very relative term) the install-ability of a PWA is a huge win. Isolating your site within its own app container allows users to focus on the task at hand, without the distraction of other tabs. It also insulates the processes running your code from the process running all of the sites they have open in their browser. Additionally, it has less overhead since there’s no browser chrome running alongside it. All of these benefits work together to create a streamlined, frictionless experience for your users. Once installed, many operating systems will grant your project access to internal APIs. Perhaps you want to let them choose an address to ship a gift to, from their contacts. Or maybe you want to enable them to add the flights they just booked directly to their calendar. Or perhaps you want to voice-enable your app by integrating with their virtual assistant. All of those scenarios become possible in the context of a PWA, which is a huge boon for transactional websites. Social Social websites—think Twitter, Facebook, etc.—are excellent candidates for PWA-ification. In fact,  . Social sites combine aspects of periodical and transactional websites, so they naturally inherit many of the benefits of those archetypes.  , in particular, are incredibly important for sites like this, as re-engagement is crucial for the long-term success of your platform. Install-ability is also important in that regard. Performance, especially initialization speed, is going to be an important benchmark for social projects, as users will not sit around waiting for all of their feed items (and their associated imagery, videos, etc.) to load. Caching your site’s assets will help a bit, but—depending on your project goals and situation—you might consider using   to update your users’ news feeds so they are ready to go (or close to it) the next time they open it up. As transactional projects, social websites will also benefit from access to device and system APIs when installed. Most social networks, for example, request permission to peruse your Contacts to look for friends and colleagues that are also using the service. If you go that route, it’s imperative that you don’t abuse the privilege by trying to trick your users into spamming their friends with info about your service. If we don’t respect our users and their private information, we run the risk of losing access to it (and them) altogether. Software When we talk about “web apps,” often online software is what naturally comes to mind. Some examples include email clients, accounting tools, project management suites, version control systems, and photo editors. In many ways, these are software in the traditional sense, they just exist on the web instead of being installed locally … until now. Through the magic of PWAs, these software-as-a-service projects can become full-fledged desktop (and mobile) applications. This enables teams that have gone all-in on web technologies to continue (or even increase) their investment in that area without sacrificing the  convenience of install-ability on native platforms. Sure, there are absolutely some solid reasons why you might want to customize a native experience for your software, but for the vast majority of cases the web offers everything necessary to run your application … that’s why it’s on the web in the first place. Offline data stores, background synchronization, and file system access help to elevate the experience for your users, making this archetype the most obvious beneficiary from Progressive Web Apps. Institutional Some projects are, frankly, too sprawling to fall neatly into one archetype or another. I’m thinking of schools, large corporations, mammoth financial institutions. These projects are often an amalgam of many or all of the archetypes I’ve covered here. As such, all of the benefits accrued to those archetypes apply, in context of course. When looking at a large institutional project, it can be difficult to figure out how to assemble an overarching strategy for turning it into a PWA. The good news is that you don’t necessarily have to. You can carve up your project into many individual PWAs that can exist independently. Take, for example, an online learning system. You could create a PWA for the learning system itself, but you could also carve off each individual course as its own, installable PWA, with its own cache, notifications, etc. The reason you can do this is that Service Workers and Web App Manifests can be scoped. You can scope them to a specific hostname or you could even scope them to a specific path within your URL structure. While obviously more complicated, if you think of each of those courses as having a course template and you think of a Web App Manifest and Service Worker being part of that template, it becomes easier to wrap your head around. It’s your turn Progressive Web Apps may seem overly technical or beyond the needs of your project, but they’re really not. They’re just a shorthand for quality web experiences—experiences that can absolutely make a difference in our users’ lives. If you hadn’t considered building a PWA before, I hope this article has changed your mind. And if you’re already neck-deep in Service Workers, perhaps it’s given you some ideas for new ways to approach the projects you’re working on. Like this: \n\t\t\t\t\t\t\tRecently by Aaron Gustafson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/conducting-the-technical-interview/", "title": "Conducting the Technical Interview", "content": "I vividly remember my first interview as a manager. My hands were shaking as I led the candidate up the stairs to the conference room I had booked. When we got there, I went into a panic. What if I don’t ask a vital question? How do I even know what the vital questions are? What if I hire him and he’s completely unprofessional? How can I tell if he   knows JavaScript? Wait a second—does he have a prosthetic leg?   Oh no, I’m failing this interview already! Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Even if you’re familiar with  , technical interviews can be nerve-wracking. Whether you’re a new team lead or you’ve been in leadership for years, concerns and insecurities like the ones I had in my first interview can haunt you, and even well-established interview processes can fail to adequately screen candidates. Interviewing for technical positions is, in many ways, a balancing act. You look at past, present, and future; you look at soft skills and hard skills; you have to think as both a buyer and a seller; you even have to worry about company image and reputation management. There are some basic things you can do to keep that balance and best represent your company. Define the ideal role I’ll admit, for my first round of interviews, all I was looking for was someone who could tick off all the technical skills on a checklist. As I progressed in my management career, I started to learn that I never looked for the same person twice—each time I had an opening, the team had different needs, and I had to take those into account when hiring someone. Even though the job description for a front-end developer didn’t change much each time, my expectations for the ideal candidate did. That gap between the job description and the ideal role tripped me up for a long time. Before you start interviewing, you’ll need a solid written description of what you’re looking for in an ideal candidate, beyond what job postings typically go into. The job posting may say Senior Front End Developer, but if you need someone to be your CSS animation specialist and help define standards and best practices—whether now or in eight months—you’ll need to take that into account when hiring. Be future-oriented with your description: ask yourself what happens when the employee outgrows his or her role. Could this person be a supervisor, or would they even want to be? Is there an opportunity to be a   or architect at your company, if that’s the route this person chooses? Could this person one day replace you? (Remember, you’re probably not getting promoted until there’s someone to take your place.) If you have no answer to the question of what happens when an employee outgrows the role, the answer is usually found at another company. Also ask what happens if the team continues to grow. Does this person have the aptitude to pick up new skills and responsibilities as needed? How will this person respond to change? What if you have to put this person in front of a client? At a healthy company, growth is inevitable, both in size and scope. Your definition should describe someone who can grow with you and not get left behind. Define not only the technical skills, but also the soft skills needed for the role you have in mind. If you need someone to take the lead on collaborating with the Creative team, you’ll need to define what would make an employee successful in that role and hire for that. This can actually be more important than the technical skill requirements. Technical skills can be easily trained—soft skills cannot. When you do all of this, you’ll have a list of expectations for a role that probably won’t fit in a job posting. When appropriate (don’t make promises of growth), test those waters with the people you’re interviewing. Even if you determine a person would be good as a trainer, they may not want to do that, which can be a nasty surprise if you hired the person with the intent of them growing into the role a year down the road. Once you know what you’re looking for, the next step is getting them to want to work for you. Sell the job The saddest interviews for me are the ones where I find that ideal candidate I envisioned and they get away. Sometimes, they just get a higher salary somewhere else; but sometimes, they decide that they don’t like the company and want to keep looking. Both are sad, but either way, getting candidates to like your company is always in your best interest. Remember, when you’re interviewing someone, they’re also interviewing you. Don’t ever assume that your company is the only place a candidate is interviewing. It’s true that some people walk in the door with their minds made up, but many are still deciding whether they want to work for your company—and the better the candidate, the more options they’re going to have, so the more you’re going to have to sell to win them over. So how do you sell a job? A salesman will tell you it starts with knowing three things really well: the product, the competition, and the customer. The product is your company: benefits, compensation, culture, type of work, amount of work, and even location. The competition is any local business that hires similar types of people, and you’ll need to know the same things about them that you do about your own company. The customer is the job applicant. Knowing each of these things well and being able to compare them is key to winning the best candidates. Do your research not only into your own company, but your local competitors. What are your competitive advantages? What are theirs? (If you think a ping pong table is a competitive advantage, you’ll probably need to dig a little deeper.) Sometimes it’s not about what you have so much as what the competition doesn’t. If you’re seeing a lot of interviewees from a competitor, find out why and see if you can use that factor to sell your company. Learn  . There will likely be some commonalities. If you’re losing top talent because you don’t offer a benefit or they don’t like your processes, you’d be wise to revisit those. Just like the technology in our industry is constantly changing, the expectations and needs of our employees are also changing. Don’t fall behind with what you offer to your employees. Almost every candidate will have questions about what the work environment is like. You should have a little elevator speech to sum up your answer and sell your company in a minute or less. You may actually want to lead the interview with that speech to get those questions out of the way and get the candidate excited for the position before you start finding out about them. Lastly, be authentic with your interviewees. Don’t try to spin a weakness as a strength, because most people will see right through that. If you don’t believe in your company enough to be totally honest about it, why should they believe in it enough to work for you? You don’t need to hand them a comprehensive list of everything that’s wrong with your company, but don’t shy away from questions along those lines, and don’t try to reframe a shortcoming as a strength. As an example, if your company has a reputation for burning some people out, that’s important, but you can talk about the type of people who do well there rather than the people who don’t. It’s better that people find that out in the interview than after three months of training. Hire a person, not a code machine In my five years as a supervisor, I only had to fire two people. Want to guess how many of those were because they lacked technical skills? Zero. In both cases, the employees didn’t work out for non-technical reasons. There are a number of non-technical factors to look for in a candidate: personality, fit with the team, communication skills, openness to change, leadership potential, and a host of others. (That’s the real reason you’re conducting an interview and not just asking for test results.) These details don’t magically reveal themselves in the technical portion of the interview—you need to ask about them. Create a list of standard questions for candidates. Questions should be open-ended and answered with a story. Examples include: Tell us about a time when your good communication helped to solve a problem. Tell us about a time when you disagreed with your supervisor and what you did about it. Tell us about a time you successfully described a technical concept to a non-technical person. How would you explain inheritance to a junior developer? Tell us about a recent time you learned from a mistake. Order is important: ask the non-technical questions first. The technical portion of the interview can make some people nervous, and you won’t get a good gauge of who the candidate is if their thoughts are fixated on the technical questions they missed. Putting thought into screening for soft skills is vital. But remember that this is a technical interview—you have to put just as much thought into screening for technical talent. Stick to the standards And I’m not talking about web standards. If you’re not asking all developers the same questions, there’s a good chance you won’t get a fair comparison, which means a greater likelihood that you’ll fall back on   like similarity or likeability. Develop a standard set of technical questions, and a written test. The questions should allow for some discussion, but have a clearly-defined right answer.   are  . You’ll probably want to customize your list so that people can’t just look up the answers online before the interview, but lists like those will get you most of the way there. (And don’t feel like you need to come up with this list on your own. If you have technical experts at your disposal, utilize them. You’ll probably want one in the interview, too.) The written test can make or break an interview. It should not be easy, nor should it be mandatory to get every question right. When an applicant is writing out code by hand from memory, leniencies must be given for syntax—give points for partial answers and ideas. Remember what Stephen Wolfram, creator of the Wolfram Alpha answer engine, said on the subject: “One thing I’ve noticed is that in almost every area, the people who go furthest are not the ones with the best technical skills, but the ones who have the best strategy for figuring out what to do.” You’re trying to get a feel for the candidate’s problem-solving strategy, not their ability to memorize every minutia of coding syntax. There should be at least a few “fix this code” sections to see how sharp their debugging skills are. Again, you shouldn’t focus on trick questions or ridiculously obscure syntax problems—you just want to measure the candidate’s ability to think through and solve a technical problem. Questions should be relevant to what the job entails—if they’ll be expected to create custom CSS animations, make sure to ask about that—but they should avoid niche- or process-specific knowledge unless it’s vital to the position. Rule of thumb: if your company does something differently than the rest of the industry, don’t quiz them on it. Once you have the questions and test prepared, run the questions by some of your existing team members to see how they fare. If your entry-level developers get all of the questions right—probably a bad sign; if your senior developers all bomb the test—also a bad sign. In the questions, there should be some clear delineation between roles. What are the must-answer questions for mid-level developers? For seniors? There can be some flexibility here, but you should have a pretty good idea what a senior test looks like and what a mid-level test looks like. If a candidate aces your standard interview questions, you can hire them with confidence. But when the technical portion of the interview doesn’t go well, you need to know how to handle that too. Know when to move on The most awkward interview I ever conducted was with a PHP developer who freelanced and was looking for his first agency job. When we began the technical questions, I quickly realized he didn’t know as much as he thought he did. Of the 22 technical questions, he got about 2 correct. He got more and more distressed with every tough question—especially when I corrected his wrong answers—and by the end of the technical portion, he looked like he’d been punched in the stomach. That guy was not qualified for the job, and both of us knew it from question 3. This was pretty early on in my management career, so I just plowed through the entire list of questions, knowing he would fail them. Learn from my mistake: don’t do that. Let interviewees fail gracefully. Don’t interrupt them with the right answer to the question they’re struggling with, and don’t correct them if they get the answer partially right. If they get the question wrong, just move on without showing judgment. If they really can’t get a question, just tell them you’re moving on. If a person bombs the verbal questions, don’t make them sit through the written test (which will probably be much harder). Feel free to tell them right then and there that they’re not a good fit for your particular position and wish them well in their quest for work. If you think they could be a good fit for another position in your company, or if you’d like to see them back once they get a better grasp on the fundamentals, go ahead and let them know. But there’s no point in leading them on with a vague non-answer if the answer is definitely no. Conclusion Screening for technical talent can be tricky. Having a holistic view of both the role and the candidate is key to making the right hiring decision. Remember to take careful notes, even if you don’t think you’ll need them. And good luck! Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/new-a-list-apart-wants-you/", "title": "New A List Apart wants you!", "content": "As   approaches its 20th anniversary—a milestone in independent, web-based publishing—we’re once again reimagining the magazine. We want your feedback. And most of all, we want you.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. We’re getting rid of advertisers and digging back to our roots: community-based, community-built, and determinedly non-commercial. If you want to highlight local events or innovations, expand your skills, give back, or explore any other goal or idea, we’re here to support you with networking and backing from the community.  In recent years, we’ve seen our rich universe of diverse, creative blogs and sites implode—leaving fewer and fewer channels available to new voices. As more content centralizes into a handful of all-powerful networks, there’s a dreary sameness in perspective and presentation.  This creeping monopolization is a sad echo of how media worked in the 20th century. It  doesn’t reflect 21st century diversity and empowerment. It’s not the web’s promise. It’s not how it’s supposed to be.  We have no beef with networks like Twitter or Facebook, or with companies like Apple and Google that currently dominate our communal digital space. We just think diversity is about expanding and speaking up—not consolidating and homogenizing. Define the next decade with us  has always been more than a publisher; we’re an ecosystem of practitioners who are passionate about our craft. We’ll keep finding and sharing great articles—we’re just taking it to the next level.  Two ways to pitch in If you want to put your favorite skills to use, expand your professional experience, or have a goal or idea for  , we’re here to listen. And if you’d like to support us in some other way, we’ve made that easy, too. Currently there are two ways to pitch in:  Teams Use the email address at the bottom of this message to let us know if you want to create or join a team that “owns” some area you’re interested in, such as: Design & development Community service and local meetups/events Education and entry level/advanced resources Book/resource coverage and reviews Editorial: Editing, acquisitions, and email Social media, SEO, or marketing Project management Your suggestions! Membership If you don’t have time to volunteer but still want to support us, you’ll be able to offer other forms of help—for instance,   to help cover our expenses. This will also grant you membership benefits. (Details at Patreon.) Sharing is caring More about all of this will soon be revealed. Meantime, if you have feedback or questions about what we’ve shared so far, kindly fire away in the comments. (Hey, how’s that for an idea? A comments section that’s positive and not divisive.) As we imagine the next 20 years of web design, there’s a lot we don’t know—other than a strong hunch that accessible, semantic HTML will continue to be the bedrock of it all. But one thing we do know: the web, in its reach and its potential, is too important to be left to the mercies of a few powerful companies, however well-intended they may be.  If you’ve a mind to do so, please help us keep our little corner of the indie web alive and well. Help the open web stay open. Help us build the future. To get involved, email us at  —or share your thoughts in the Comments section below.  Jeffrey Zeldman, Publisher \nAaron Gustafson, Editor-in-chief \n&  Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/patterns-and-purpose/", "title": "Patterns and Purpose, an Excerpt from Animation at Work", "content": "So we can use animations to tap into users’ visual systems and give them a cognitive speed boost, terrific! But before animating every element of our designs, we must learn when and how to use this new tool: with great power comes great responsibility, and so forth. And as animation must vie with many other concerns for development and design time, it makes sense to spend our resources where they’ll go the farthest. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. This chapter sets you up with some core animation patterns and shows you how animation applies to a greater system. Then you’ll learn how to spot cognitive bottlenecks and low-hanging fruit, maximizing the impact of the animations you do invest in. Common Animation Patterns If you’ve looked at as many examples of animation on the web and in app interfaces as I have, certain patterns start to emerge. These patterns are helpful for identifying and succinctly verbalizing the purpose of an animation to others. Here are the categories I’ve found myself using the most:  take users from place to place in the information space, or transition them out of one task into another. These tend to have massive impacts on the content on the page, replacing large portions of information.  bring information on or off the page, but don’t change the user’s “location” or task. They generally add or update bits of additional content on the page.  indicates causation between two or more events, often used to connect a user’s interaction with the interface’s reaction.  explain how something works or expose its details by showing instead of telling.  do not convey new information and are purely aesthetic. Let’s have a look at each of them and see how they impact the user’s experience. Transitions The web was originally designed as a series of linked documents. Clicking on a link caused the browser to wipe the screen, often causing a telltale flash of white, before painting the next page from scratch. While this made sense in the context of linked text-based documents, it makes less sense in an era where pages share many rich design elements and belong to the same domain. Not only is it wasteful of the browser’s resources to be recreating the same page layout over and over, but it also increases users’ cognitive load when they have to reorient and reevaluate the page’s content. Animation, specifically motion, can facilitate the user’s orientation in an information space by offloading that effort to the brain’s visual cortex. Using a transition between changes in task flow or locations in information architecture ideally reinforces where the user has been, where they are going, and where they are now in one fell swoop. For example, on Nike’s  , when a user clicks a navigation arrow, the current sneaker moves out of the way while the next sneaker moves in from the opposite direction ( ). These transitions clearly show the user how they are navigating along a linear continuum of sneakers, helping them keep track of their place and reinforcing the spatial model of perusing a real-world row of sneakers. On another shoes site,  , transitions move the user from task to task ( ). After a user starts typing in the search field, the results are animated on top of a darker backdrop. This transitions the user from the browsing context to refining their search results, streamlining their focus while also reassuring them that they can get back to browsing without much effort. Supplements While transitions move the user   state to state, supplemental animations bring ancillary information   the user. Think of times when information complementary to the main content of the page appears or disappears in view: alerts, dropdowns, and tooltips are all good candidates for a supplemental animation on entry and exit. Remember that these animations need to respect the user’s Cone of Vision: will they be looking directly at a tooltip appearing next to their cursor, or will their attention need to be directed to an alert on the side of their tablet? When a user adds a product to their shopping cart on  , rather than taking them to a whole new shopping cart page, the site merely updates the user as to their cart’s contents by popping it out as a sidebar ( ). While a transition would snap the user out of browsing mode, this supplemental animation lets the user dismiss the shopping cart and continue shopping. The shopping cart sidebar uses an additional supplemental animation to quickly and subtly attract the user’s eye: a progress meter gradually fills to show how much the user needs to spend to get free shipping ( ). This shopping cart process has a third animation pattern going on: the Add to Bag button gains a spinning icon when clicked, which gives the user feedback as to its loading state ( ). Speaking of feedback… Feedback Animation can give users direct feedback about their interactions. A depressed button, a swiping gesture—both link a human action to an interface’s reaction. Or the flip side: a loading spinner on a page indicates that we’re waiting on the computer. Without visual feedback, people are left wondering if they actually clicked that “pay now” button, or if the page is really loading after all. On the  , hovering over a button causes its color to fade from red to blue, indicating that the element is interactive and ready to react to user input ( ). Button hovers are classic examples for this kind of animation, partly because the gain of giving users visual feedback on buttons is so measurable and important to business.  uses a bar of color across the top of the page as well as an animated version of their logo to indicate the page’s loading and loaded states   providing interest and reinforcing their “wild” branding ( ). Demonstrations Demonstrations are my personal favorite use of animation. They can be both entertaining   insightful. These animations put information into perspective, show what’s happening, or how something works. This makes demonstrative animations perfect partners for infographics. One thing all demonstrative animations do is tell a story, as you’ll see. “Processing…” pages are an opportunity to explain what’s happening to users while they wait. TurboTax makes good use of these processing pages ( ). After users submit their US tax forms, it banishes any remaining anxiety by showing them where their information is headed and what they can expect—all while reinforcing their brand’s friendliness and accessibility. (It also helps that the animation distracts users from a rather lengthy page load with something visually engaging!) Coin famously uses demonstrative animations to explain their consolidation card’s value proposition to curious visitors as they scroll through the site ( )—no need to press play and sit through a video ad or wade through paragraphs of expository content. This page is the very essence of “show, don’t tell.” Decorations It’s not hard to mistake decorative animations for demonstrative animations. But there is a key difference: where demonstrations bring new information into the system, decorative animations do not. They are the fats and sugars of the animation food pyramid: they make great flavor enhancers, but moderation is key. The best way to spot a purely decorative animation is to ask, “What can a user learn from this animation? Does this guide them or show them something they wouldn’t know otherwise?” If the answer is no, you might have a decorative animation on your hands. Even though they get a bad rap, decorative animations can help turn the ordinary into the extraordinary.   uses decorative animations judiciously to bring flat illustrations to life. The animations add just enough interest to allow for the visual content on the page to be more austere, letting users focus on the podcast ( ).   epically used animated illustrations to create centerpieces for a series of console reviews. These decorative animations may not have added new information, but they crucially reinforced the Polygon brand. They also helped each console review stand out from the competition, which at the time sported indistinguishable photographs of the same devices.  Want to read more? This excerpt from   will help you get started.  , as well as other excellent titles from  . Like this: \n\t\t\t\t\t\t\tRecently by Rachel Nabors\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/a-list-apart-volunteer-update/", "title": "A List Apart volunteer update", "content": "To the many wonderful souls who have so far volunteered to help  , thank you very, very much for your emails! And if you haven’t heard back from us yet,  please excuse the delay. We’ve been inundated with messages from hundreds of potential volunteers across a wide spectrum of disciplines and potential task groups, and we are going through your messages slowly and carefully, responding personally to each one. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Some of you have written asking if we might be interested in having you write for us. Gosh,   has always welcomed articles from our community. Guidelines (plus how to submit your first draft, proposal, or outline) are available at  . Please check them out—we’d love to look at any topically appropriate article you care to submit.  But writing articles is far from the only way to support and make your mark at the new (19-year-old) ALA. Meet the groups! If you’ve expressed an interested in organizing or hosting an ALA-themed monthly meet-up, or have other ideas that can help grow community, we’ll invite you to join our newly forming   group. If   is more your thing, we are starting a group for that, as well. There are other groups to come, as well—a   appears in the   on the topic, and there may be more groups to come. How these groups will work, and what they will do, is largely going to be determined by the volunteers themselves. (That’s you folks.) As we’re starting the work of supporting and organizing these groups on Basecamp, you can’t just add yourself to a group, as you could on, say, Slack. But that’s okay, because we want to approach this somewhat methodically, adding people a few at a time, and having little written conversations with you beforehand.  Our fear was that if we launched a bunch of Slack channels all at once, without speaking with each of you first, hundreds of people might add themselves the first day, but then nobody would have any direction as to what might be expected—and we might not have the   ready to provide guidance and support.  By adding you to Basecamps a few at a time, and hopefully identifying leaders in each new group as it begins forming, we hope to provide a lightly structured environment where you can design your own adventures. It takes a little longer this way, but that’s by design. (  started in 1997 as a 16,000-member message board. Big open channels are great for letting everyone speak, but not necessarily the best way to organize fragile new projects.) If you are interested in contributing to those projects, or curious about a particular area, and told us so in your initial email, we will eventually get to you and assign you to the right slot. If you haven’t yet volunteered, of course, you can still do so. (See the original post for details.) Editors, developers, and designers  \nBut wait, there’s more.  : if you have standards-oriented front-end development experience and would like to help out on day-to-day site maintenance, occasional minor upgrades, and an eventual redesign, just add yourself to  ’s Github front-end repo:  . Those with backend experience (particularly in ExpressionEngine and WordPress), you will hear from us as we work our way through your emails.  and I have also been going slowly through your mails looking for additional   help. We’ve already found and added a few very promising people to our volunteer editorial staff, and will introduce them to you soon. If you’re an editor and we haven’t added you yet, not to worry! It likely means we haven’t gotten to your email yet. (So. Much. Email!) As might be expected, a majority of those who volunteered offered their services as  ,  , or both. The number of emails we’ve received from folks with these skills is humbling, touching, and a bit overwhelming. We have not yet begun to dig through this particular pile of mail. So if you haven’t heard from us, that’s why. (But, as I just mentioned, if you’re a developer, you can add yourself to our  . So do that, if you wish, and say hi!) We love you Hope this helps clarify what’s up. We are grateful for every single email we’ve gotten. We will eventually speak with you all. Thank you all again. \nJeffrey Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/project-management-for-humans/", "title": "Project Management for Humans", "content": "I loved the game   as a kid. I played the Game Boy version for hours. It’s easy to get wrapped up in the concept of little shapes coming together in a logical way to clear a goal. The pieces complement one another, yet they all naturally work in different ways. The game has stuck with me since I was a kid (and, no, I’m not a gamer). I now have it on my phone and iPad and find myself playing it when I’m on a flight or bored, waiting for something to happen (which is never these days). Whether I’m playing the game a lot or not, the idea of making tiny boxes fit in neatly and clearing out rows of work is ingrained in my brain. It’s the project manager in me. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But here’s the thing: What project managers do on a daily basis when it comes to managing resources or staffing is similar to Tetris, and it’s a big project management challenge that we all face. The biggest difference between resourcing and Tetris? The team members we’re trying to assign tasks to aren’t blocks. They’re human beings, and they need to be treated as such. Your Team Are People, Too! Let’s move away from calling people “resources,” please. We’re really just staffing projects or assigning tasks. We’re not using people to just get things done. We’re asking them to solve challenges that are presented in our projects.  Set the Stage for Organized Resource Planning The challenge of managing a team is making sure that they stay busy and working on tasks, yet are not completely overbooked. It’s a difficult balance to find, particularly when your projects require a variety of skills at different times, which seem to change all too often. At the most basic level, you want to set up a system for tracking your projects and your team members’ time on those projects (see  ). A simple goal is to ensure that you can confidently commit to deadlines on projects with the knowledge that your team is actually available to do the related work. It seems like a simple goal, but it’s often a difficult one to keep up with due to changes on projects, changes in personal schedules (hey, life happens), and an influx of new work and requests. But it’s not an insurmountable challenge. In fact, a simple spreadsheet could help you, particularly if you’re managing a smaller team. At the core, you want to track these items:  (List them all, even the non-billable ones, or the other things that aren’t projects but end up taking a lot of time—like business development.)  (List every person you work with.)  (Track hours, days, weeks, etc. Make your best guess—based on your timeline or calendar—on how much each person will spend on a project or a task.) A couple of notes on how to use a spreadsheet to forecast team availability: This should be set up on a week-by-week basis to minimize confusion (use tabs in your spreadsheet for each new week). Always consider the “nonbillable” things that people must do (like stand-up meetings, internal tasks, sales, etc.). The final cell contains a formula that tallies the hours for you; if the hours go over your typical limit (think of a 40-hour work week), it will turn red to notify you. You’ll want to have a good idea for just how “utilized” someone should be (32 hours/week is usually a good target). You can input the actual hours logged in your time tracking system if you’d like. It could help with future estimating. (If you’re not tracking time, check in with your team on time percentages to get a gut check.) Check your estimates with your team to make sure that the hours actually align with their assessment of the task (This might help with avoiding that red number!) Communicate these hours to the entire team each week. Making sure that everyone “is in the know” will help on any project. Discussing it with individuals will help you understand effort, blockers, and possibly even different ways of working. Tools The landscape for project management tools is changing constantly. There are a number of tools in the marketplace for helping you manage and communicate this data. If you’ve working with a team of 10 or more, you might want to abandon the spreadsheet approach for something more official, organized and supported. Bonus: Many of these tools handle more than just resourcing! Here’s the thing—it’s not just about numbers. The issue that makes estimating a team’s project hours difficult is that everyone works differently. There is no way to standardize the human factor here, and that’s what makes it tough. Forget the fact that no one on your team is a robot, and they all work at their own pace. Think about sick days, vacations, client delays, changes on projects, and so on. It’s a never-ending flow of shapes that must fit into the box that is a project. Be sure to have an ongoing dialogue about your staffing plans and challenges. Match Resource Skills to Projects Projects only slow down when decisions are not made. In that magical moment when things are actually going well, you want to make sure that your team can continue the pace. The only way to do that is by connecting with your team and understanding what motivates them. Here are some things to consider:  If you have a team member who loves beer, why not put that person on the beer design site? Maybe you have multiple people who want to be on the project, but they are all busy on other projects. These are the breaks. You’ve got to do what is right for the company and your budget. If you can put interests first, it’s awesome. It won’t always work out that way for everyone, but it’s a good first step to try.  It’s as simple as getting to know each and every team member’s work. Some people are meant to create specific types of designs or experiences. It not only has to do with interests, but it also has to do with strengths within those tasks. Sure, I may love beer, but that doesn’t mean that I am meant to design the site that caters to the audience the client is trying to reach.  Projects will always change. One week you know you’re working against a firm deadline, and the next week that has changed due to the clients, the needs of the project, or some other reason someone conjured up. It’s tough to know when that change will happen, but when it does, how you’ll fill someone’s time with other work should be high on your mind.  People always extend them. Plan for that!  It’s great to know about these in advance. Be sure you know your company’s policies around vacations. You never ever want to be the PM who says “Well, you have a deadline on X date and that will conflict with your very expensive/exciting trip, so, um … no.” Ask people to request trips at least a month in advance so that you can plan ahead and make it work.  We’re all humans and that means we’re fine one day and bedridden the next. You’ve always got to be ready for a back-up plan. It shouldn’t fall on your client stakeholders to make up time, but sometimes it has to. Or sometimes you need to look for someone to pitch in on intermediate tasks to keep things of track while your “rock star” or “ninja” is getting better. Align Plans with Staffing When you’re working hard to keep up with staffing plans, you’ve got to have updated project plans. A small change in a plan could cause a change in staffing—even by a few hours—and throw everything else off. Save Yourself and Your Team from Burnout If you’re busy and not slowing down any time soon, you want to keep this spreadsheet (or tool) updated often. If you’re working at an agency, knowing what’s in your pipeline can also help you. Stay aligned with the person in charge of sales or assigning new projects so that you can anticipate upcoming needs and timelines. In some cases, you may even want to put some basic data in your spreadsheet or tool so that you can anticipate needs. Good Resourcing Can Justify More Help The value of tracking this data goes beyond your projects. It can help business owners make important decisions on growing a company. No matter what you do, be sure to communicate about staffing as much as possible. If you’re in an organization that is constantly handling change, you’ll know that it’s a tough target to hit. In fact, your numbers will often be slightly off, but you’ll find comfort in knowing that you’re doing everything you can to stay ahead of the resource crunch. At the same time, your team will appreciate that you’re doing everything you can to protect their work-life balance. Stakeholders Are Resources, Too When you’re working on a team with a project, you have to consider the stakeholders as decision makers, too. Let’s face it—no one has ever been trained to be a good client, stakeholder, or project sponsor. In addition to that, they are likely to be working on several projects with several people at one time. Life as a client can be hectic! So do everything you can to help them plan their time appropriately. In general, you should let the stakeholders know they’ll have to plan for these things:  You’ll conduct a kickoff meeting, weekly status updates, deliverable reviews, etc.  You’ll need stakeholders to wrangle calendars to get folks into said meetings.  This sounds easy, but it is not. You will need this person to spend time with all of the stakeholders to get their feedback and collate it for you to make sure there are no conflicting opinions.  There are points on every project where one person will need to make sure there is agreement and decisions can be made to keep the project moving.  Questions and requests will pop up, and you’ll need timely responses.  You might need invoices to be reviewed and approved or change requests to be reviewed and discussed. The stakeholders will need to make time to operate the project from their side of things. This is a lot of work. And just like PM work, it is very hard to quantify or plan. If you’re in good hands, you’re working with someone who has good PM skills. If not, give them the list above along with a copy of this book. But seriously, if you can assist them with planning their time, it might be as simple as including action items or to-dos for them in a weekly email or in your status report. Just remember, they are busy and want the project to run smoothly as well. Help them make that happen. TL; DR Managing projects is hard enough, but being the person to manage who works on what and when can be even more difficult. However, if you don’t keep track of this basic information, you’ll likely find it hard to meet deadlines and wrap up projects without major issues. Here are some simple things you can do to make sure your that your team stays busy, yet not completely overbooked: Set up a simple spreadsheet to forecast projects and hours per team member.\n This data should be based on what’s included in your project scopes and timelines—be sure to double-check that. You may want to check out one of the resourcing tools that are out there now. \n Be sure to account for a number of factors that you can’t necessarily control in this process—for example, interests, skill sets, moving schedules, holidays, vacations, and so on. Account for your sales process if you’re in an agency and stay ahead of new project requests. Remember that you’re dealing with people here. Want to read more? This excerpt from   will help you get started.  , as well as other excellent titles from  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/gauging-the-perception-of-lossy-images-a-study/", "title": "How People Perceive Lossy Image Quality: A Study", "content": "The notion that lossy image quality is subjective is not an unreasonable hypothesis. There are many factors that play into how humans perceive quality: screen size, image scaling, and yes, even performance. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Many research projects have tackled this subject, but I’ve recently launched   that attempts to understand how people perceive image quality in a slightly different way: in the context of performance. This image quality assessment serves up 25 different specimens, each of which is presented in a random lossy quality setting between 5 and 100, in both JPEG and WebP formats. As participants complete the survey,  ,   and   are collected (when available) from the browser, as well as other client details such as a device’s resolution, pixel density, and many other pertinent details. The real work of gathering data begins. This is where you can help out. If you have five to ten minutes to spare, please head over to   and participate. When the survey is finished, I’ll post the raw data and write and article (or two) on the findings. If further experimentation is required, that will be pursued as well. I don’t know what we’ll find out, but we’ll find out together with your input.  Thank you! Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/considering-open-source-licenses/", "title": "Considering Open Source Licenses", "content": "So you have a project that you want to use open source tools to create—well, I tip my hat off to you as a developer. But do you know the questions you need to answer before you get started? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What stage of development is your project in right now? Have you finished the planning phase? Are you going to work with a team? Will the project be split up into different modules? And so on. The principle of DRY (Don’t Repeat Yourself) has become an unwritten rule for developers. Instead of always starting from scratch on each new project, find ways to build upon previous work. This will save you time and other resources. In other words, do not reinvent the wheel; put to use the great work that others have perfected and made “freely” available for you to build upon. This principle of DRY can also be applied to open source works. When starting a new project, most developers first search carefully for frameworks, libraries, and packages that they can build on or modify to fit their needs. Best of all, there are thousands upon thousands of open source projects (OSes, frameworks, IDEs, libraries, database management systems, and so on) available for you to choose from.  Imagine your project becomes a huge hit, only to get knocked flat by licensing issues required by the works you built it with. Do you really understand what it means to use open source work in your project? As the adoption of open source keeps increasing, so does the risk of non-compliance with licensing terms—which in turn leads to an increase in the number of litigations involving open source works. One of the most recent examples  . The case is ongoing, but the direction seems to be clear from the following: To use Ghostscript for free, Hancom would have to adhere to its open-source license, the GNU General Public License (GPL). The GNU GPL requires that when you use GPL-licensed software to make some other software, the resulting software also has to be open-sourced with the same license if it’s released to the public. That means Hancom would have to open-source its entire suite of apps. Or, Hancom must pay a licensing fee to Artifex.  Now you get a bit of the picture, right? Evaluating open source options Before you settle on an open source project to use or include in your own project, go back to your big idea (that is, the project that you are developing) and answer the following questions. Once you have answered the above questions, what’s next? It’s time to answer another question. What does open source mean? What comes to your mind when you come across a work categorized as open source—free to use as you deem fit? Learn what open source really means here from the  . After reading that, do you still want to include open source work in your project? Will it derail your purpose and goal? Why are open source projects licensed? One reason why projects are licensed with an open source license is  . Open source licenses tell developers how to use your work and the limitations and restrictions that they must observe. You wouldn’t want a constant stream of emails from everyone interested in using your work—these could run into thousands of people.  At the same time, open source licenses make it easy for others to   to a project,  as opposed to a closed system. Just imagine the talents that will be able to contribute to an open source project in contrast to an in-house project. You will be able to pull in far more resources toward achieving the goal of your project; yes, you will agree that much more can be achieved this way. Licensing serves as a   for the creator of a work or body of works; others won’t go about claiming your work as their own. It makes sure that you get the credit you deserve as the author of a project. Read every license, every time Not all open source licenses are the same. Take a look at the table in   to see the types of differences you might encounter. Introduction to popular licenses Below are a few of the most popular open source licenses, with details of what power or limits they impose on you regarding usage and redistribution. MIT License A project with   you “to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the software is furnished to do so.” This means that you can use this work for your project as you deem fit (even sell derivative works) with the only conditions being that you 1) leave the MIT license intact and 2) include a copyright notice. What they mean is that you must include a notice similar to this in the license file of your work:  “[name of your project] includes code from [original creator of included work] and it is licensed under the MIT License” followed by the full MIT license text. One other thing to note before using a work with this license is that “ .” Think about a situation where you have to include works with both the MIT and GPL licenses in your project. At the end, this combination will carry the GPL license, excluding the MIT license. (You can read about the GPL license below.) Apache License This license is somewhat similar to the MIT license. You can use works with this license in your project provided that you take note of the fact that it “requires preservation of the   and  .” The Apache License term is  . You are required to explicitly state that the original work has been modified and to include the following in your license notice: The Free Software Foundation considers all versions of the Apache License to be incompatible with the previous GPL versions 1 and 2 and, furthermore, considers Apache License versions before v2.0 incompatible with GPLv3. Because of version 2.0’s patent license requirements, the Free Software Foundation recommends it over other non-copyleft licenses, specifically recommending it either for small programs or for developers who wish to use a permissive license for other reasons. GNU General Public License (GPL) 3 This license isn’t particularly permissive when compared to, say, the MIT license. But it does foster community effort greatly and it’s one of the most popular open source licenses out there. When you use work with GPL that you will be releasing to the public (or redistributing), this license   (including how-to documentation for installation and building) under the GPL license. BSD 3-Clause License This is also very similar to the MIT license; it allows you to use it for commercial projects, to redistribute, and to modify, but the copyright notice and the BSD license itself must be included. Your decision between MIT and BSD now depends on what is suitable for your project. MIT and BSD licenses differ in terms of compatibility with other open source licenses—while MIT licensed work will allow you to include other work with different license terms, BSD licensed work won’t. More on that on license compatibility below. There are   that are not covered here. They require careful reading and understanding before delving into using works they are licensed with. Ignoring the terms of an open source license Considering suitable open source licenses all boils down to avoiding lawsuits in the future. Problems foreseen are problems half-solved. But what happens if you ignore the terms of a license? Will you be prosecuted when this is uncovered? The Free Software Foundation is an organization that volunteers their resources  —kind of an open source license police. The following is a quote from their compliance page: Once we have established that a violation has occurred, we explain to the violator what they must do to come into compliance. They’ll make some appropriate changes — to their software, their product, their website, or whatever’s affected — and let us know. We check those changes, tell them about any new or outstanding issues we find, and ask them to make more changes. This back and forth goes on as long as necessary. License compatibility What about using  ? Will there be any implications? In other words, if you’re thinking of “mixing” work of different license terms in a project, this is where you have to  .  If code components that were licensed under different license conditions are compiled to form a new work, a question arises: Is the common use of the code permissible under license law? If for example code A under license X is linked with code B under license Y to form a new program, licenses X and Y must permit this. If this is the case, license compatibility exists. Perhaps you’ve found an open source work that will perfectly fit your project … But. The. License. Is. Not. Compatible! What can you do about it? First,   you are planning to use in your project. Obviously, license issues will be easier to manage when you use open source works with the same license, and one way to avoid license incompatibility is to read beyond the list of features—after reading the features section, be sure to scan down to the requirements section. As you investigate open source tools to use in your project, make “compatibility” your companion. Keep it close. In terms of compatibility, the MIT license is fairly generous; as of the time this article was written, this license   prevents you from suing the author of the work. So in general, a work licensed with an MIT license is great for most purposes. (Remember that this is not legal advice.) License infringement If a licensing case does affect you or your project, note that some legal cases pertaining to license infringement are settled out of court. You may be able to negotiate and reach a personal agreement with the author—an agreement that would allow you to use the work without infringement. Simply put, contact the author of the open source work to discuss the situation and possible compromises or alternatives they might consider. Negotiation done before embarking on your project could help clarify the license, ensure you and the author are on the same page, and avoid a legal situation entirely.  Bringing it home Consideration of open source licenses should be part of the early planning phase of your project, not after development.  To significantly reduce the risk of violations, ensure that you take open source license violations seriously and that appropriate open source policies are in place to guide your development team. Do not forget that your project will also need a license after you finish development (and production). What license will you be using? The license(s) included in the open source work used in your project will determine your own license. Most of all, as an individual developer or business entity that develops, distributes, or uses open source, you should make time to read and understand the terms and conditions of open source licenses you are using. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/what-i-talk-about-when-i-talk-about-sorting/", "title": "What I Talk About  When I Talk About Sorting: Untangling Array#sort", "content": "Sorting things is a fundamental part of our daily lives—it’s something we do everyday to make our lives easier, following all kinds of criteria. Whether you’re looking for a person’s phone number, the location of your favorite book, or even  , sorting allows us to find what we are looking for in a faster and more effective way.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. This is also the case in the world of web development. But if you thought you knew exactly how JavaScript’s Array#sort works under the hood, think twice. Scratchin’ the surface No matter your skill level, if you’re a JavaScript developer you’ve probably come across the Array#sort method at some point. Do you remember the first time you tried sorting numbers in JavaScript? You were probably astonished to discover (just like the rest of us) that the sort method does NOT sort things quite as we might expect.  You don’t know what I’m talking about? Let’s dive into some code: Wait, what? Is JavaScript nuts? In which world are 25 and 33 smaller than 4? Before you start rethinking your whole life, let’s figure this out.  Lexicographical sorting What is actually happening here is that JavaScript is sorting our numerical array in a lexicographical manner—think alphabetical order, where every value is treated as a string. The catch here is that Array#sort can take a compare function as a parameter, but if you don’t supply it, “ ” (according to the  ). This means that JavaScript will treat the following arrays in a similar fashion when calling the sort method: In this case, “80” comes before “9” because it has a smaller Unicode code point. If you don’t believe me, let’s take a look at the code point value of the first character of each: Basically the function   is simply a   of the String object that is used to get the Unicode code point value of any character at a given index. At this point, the following code shouldn’t be shocking to anybody because now we know that JavaScript is just converting all the elements in those arrays to strings and comparing their Unicode values. (Yes,   also have Unicode code point values.) Numerical sorting After all that mumbo jumbo, what if we actually JUST wanted to sort our array numerically? As stated before, we need to provide a compare function that will sort the array elements according to the return value of that compare function.  If the return value of   is less than 0,   will come before  . If the return value is greater than 0,   will come before  . If the return value is 0,   and   will remain unchanged. To compare numbers instead of strings, provide a function that subtracts   from  . Here is an example: Rollin’ in the deep During all this JavaScript sorting fun, I bet you wondered at some point about the algorithm used by the native JavaScript sort method. No? That was just me? Either way, let’s check it out. Now, here’s the thing: the ECMAScript standard doesn’t specify which algorithm should be used, so each JavaScript engine is allowed to use whatever algorithm it wants. Why should you care about this? Keep reading, but first let’s find out which engines use which algorithms. (The good thing is that most of these engines are open source so we can look at the code and check what they are using.) This isn’t a computer science article, but let’s get some things straight. Because JavaScript engines don’t use the same algorithm behind the native method, it is very likely that you’ll encounter different results when running the sort method in different browsers. You might find that elements are being sorted in a different way, or some sorts run faster than others (depending on the JavaScript engine). If your application relies crucially on sorting data, you have to pay attention to these kinds of details.  For example, Google’s V8 that powers Chrome and NodeJS uses the quick sort algorithm, which is not a  . Stability in the context of sorting means that it preserves the original order of the input set when having elements with equal values. If you have to sort a list of people in your database who were previously sorted alphabetically by last name, you might want to preserve that original order when sorting again, this time according to age and looking for people of the same age. This means you will need a stable sort.  Since each JavaScript engine implements the Array#sort method with different algorithms (that may or may not be stable), stability is not guaranteed. Let’s check an example: In V8, this is the result: Notice how the previous alphabetical order for the people who are 26 years old is not preserved? In JavaScript engines implemented with stable algorithms, this is not a problem.  Just keep in mind that the sort method will sort differently depending on where you’re running it. What if it’s crucial for your application to maintain consistent behavior across engines? Is implementing your own version of the sort method even an option? Maybe yes, maybe no. If stability and performance are high on your priority list, it’s probably yes.  Actually, implementing your own homemade JavaScript sorting function is not that difficult and takes only a few lines of code. There are plenty of books that explain how to implement the most popular sorting algorithms. Two good resources are   by Steven S. Skiena and   by Richard Neapolitan et al. You can even extend the Array prototype to define your shiny new implemented sort functions: Believe it or not, self-implemented JavaScript sorting functions can be faster than the native method, though it depends on various things, such as the amount of space you have available, the kind and quantity of data you are sorting, and the JavaScript engine you are using. Testing and benchmarking Too hard to believe? Let’s do some benchmarking! The following table shows the results of testing the native JavaScript sort method against my own implementations of  ,  , and   for dynamically created arrays with   elements. The values represent the operations per second done by each method: As mentioned before, the quantity of data to be sorted directly impacts the performance of every algorithm. Notice how insertion sort performs better than the other methods (including the native sort) for the first thousand elements. As the data input increases, insertion sort becomes slower, and for a hundred thousand elements it becomes the least performant. At this point, quick sort takes the lead. For the remaining test cases, it continues to be more performant than the native version. (It is very important to clarify that the previous benchmark was tested in Chrome 56 on macOS 10.12.3.)  Your homework now is to   on different machines, with different input sizes and different JavaScript engines to see what results you get!  JavaScript inception I might not be a fortune teller, but I bet you’re probably thinking: “How come self-implemented JavaScript sorting functions can beat the native sort C/C++ implementations?”  First of all, let’s backtrack a little bit. C/C++ implementations? Are we even sure about that? If you peeked at the source code of the JavaScript engines, perhaps you noticed that in the case of V8 and Nitro, the implementation of the sort method is actually done in JavaScript itself. Wait again, what? Am I saying that those JavaScript engines are written in JavaScript? Is this some kind of JavaScript inception? Yes, indeed.  In the world of computer science this is actually called  : the art of implementing parts of a language in that very language itself. But then again, isn’t C++ supposed to be faster than JavaScript? Yes and no. C++ programs are definitely faster than JavaScript when they operate on C++ data structures but not on JavaScript ones.  JavaScript arrays have methods like  ,  ,  , and of course  . Each one takes a callback as an argument. The method then iterates over every element of the list and invokes the callback during each iteration. This means that the execution has to switch between compiled C++ code and interpreted JavaScript, and this context switch is expensive. By staying in the same execution context within the same language, we can boost performance. If you need some proof, try comparing the performances of Array#forEach and a simple   loop. In certain cases, you may notice that an engine’s Array#sort method implementation causes unneeded overhead. Calling callback functions for every element in our array adds an extra layer of complexity to the task of simply sorting numbers. It seems that the native implementations just do more overall (in terms of error handling and features) than the simple self-implementations.  TL;DR Yes, most people are aware of Array#sort, its funky behavior, and the fact that you’ll need a compare function to achieve a numerical sort. Because JavaScript. But did you know that the algorithms used to natively implement this method vary across engines? And that this produces different results depending on where you are running it?  If you care about performance and consistency, creating your own self-implementation of the sort method might not be a wild idea. Of course, you should learn how to choose your battles depending on the needs of your applications, whether you’re handling complex databases in a NodeJS application or sorting in the front end. Don’t implement your own version for the sake of it, but take time to level the pros and cons. Only you can decide how pragmatic it is to spend time creating a homemade sort algorithm, as opposed to the native one. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/be-a-mentor/", "title": "Be a Mentor", "content": "Looking back over my eleven-year career in the web industry, I owe most of my success to two people from early on: Holly and Rebecca. Both were supervisors; but, more importantly, both were mentors. I wouldn’t be where I am today without their mentorship. Three years into my career, I got a promotion and became a supervisor myself. It was so exciting to be in a position to mentor others and give back to the community! I only had one question: how the heck do I do that? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Mentorship has always been a part of the web industry. One of the first pieces of advice given to young web professionals is to find a mentor, and many experienced web professionals are where they are today because of their mentors. I think most of us would agree that mentoring others is a great thing. But when do you start mentoring? How do you provide good mentorship? How do you find people to mentor? In short, how do you do this? The truth I learned is that just about anyone with professional experience has something to offer novice or aspiring web professionals. You don’t have to be a director or an international speaker to be a good mentor—you can start today, and it’s probably easier than you think. You just need to be  , and  . Finding opportunities You don’t need to be a supervisor to be a mentor, but if you’re not, finding someone to mentor can be intimidating. You can make this process much easier by having a few things in order and looking in the right spots. Before you seek out a mentee, you need to have demonstrable expertise to offer them. Make sure your personal website or portfolio is up to date. Try to build a professional following on Twitter or Medium to showcase your expertise. Answer some questions on StackOverflow or another forum, or write some tutorials. These will all help you in your career, and, when done well, can be mentorship opportunities in their own right. Workplaces are usually ripe with opportunities for mentorship. If you hold a manager or senior title, mentorship is an expectation; but even if you don’t, there’s always a need for showing new or younger employees the ropes. Make sure to check with your supervisor first, but there’s usually a strong need for enthusiastic and experienced mentors. Outside of work, mentorship opportunities still abound. If you’re experienced and successful in your field, you might talk with the local college (or even high school) about sharing your experience with interested students. Meetup groups are also a great place to meet people in search of an experienced mentor. Even if your area is completely devoid of others in the same field, the internet is not. Browse forums and online user groups—it won’t take long to find someone looking for a mentor. Be present A while back, I got some personal business cards printed up. I wasn’t looking for work. I meet a lot of people new to the web industry who could use someone to answer a few questions or provide feedback. I gave out about twenty business cards to friends, colleagues, and willing strangers with the explanation that I would answer their questions or review their projects. Want to guess how many used the card to contact me? Zero. That’s how many people reached out to me for feedback. The reason? Just like it’s harder to keep up with friends who move away, it’s hard to ask for feedback from someone who doesn’t seem available. People don’t think about it, or they feel bad about bothering you, or they get busy—whatever the reason, it’s a lot harder to reach out to someone who’s not present. Being present means creating opportunities for meaningful interaction. This doesn’t just mean proximity, but that’s a big part of it. If your job involves mentoring someone, sitting next to them will make this much easier. If you’re trying to mentor someone outside of work, checking in from time to time will do wonders. Lunch and coffee are amazing catalysts for mentorship. A personal connection (like a phone call or email) will go much further than an impersonal one (like my business cards). But even if you sit next to them, if you’re overwhelmed with the other aspects of your life, you’ll have the same problems. Showing that you’re too busy, even if you’re not trying to   them that, will quickly halt mentorship opportunities. Talking about how stressed out or busy you are, constantly wearing headphones, and putting off someone’s inquiries are surefire ways to do this. Make sure you’re portraying yourself as available and interested in what they have to ask you. Asking for mentorship is hard. People don’t like admitting that they don’t know something, nor do they like feeling indebted to or imposing on others. Asking for mentorship triggers these anxieties. That’s why there are so few people asking about mentorship, even though there are so many looking for it. Taking steps to ease these anxieties, like reassuring them that they’re doing well and showing them that you’re happy to help, makes it much easier for the other person to come to you. If you’re serious about mentoring, taking the initiative to schedule a check-in or review will improve the relationship greatly. The key word is  . Good mentorship cannot happen by a happy accident—it takes action on your part to make it happen. If you don’t think scheduling a meeting would be appropriate, get their contact information and send a quick email or text. This opens the door for them to talk freely about what’s going on in their life and work. If your mentee doesn’t believe that they’re important to you, they’re never going to open up and ask for help. Being present shows them that they matter to you, and that requires some intentional action on your part. Mentorship often doesn’t happen without this. Taking steps to be present in others’ lives is usually a prerequisite to mentorship. Be positive Mentorship is about enabling positive change in your mentee. While this can be done in many ways, it usually starts with either convincing or inspiring.   is very logical and is based in the present: how should you be thinking?   is more emotional and is based on the future: what could you become? While both are important, inspiring is usually the most effective way to produce change—people won’t change unless they want to, no matter how logical the argument. Inspiring requires a positive outcome to focus on, an end goal that’s enticing enough to sway someone from their current path. This can be concrete, like a better job, or abstract, like better people skills; but it’s always something that the mentee wants for their future. Here’s the catch: inspiration isn’t always something a mentee brings into a mentoring relationship. An inexperienced mentee may have no idea what they want for their future, or may have a very skewed view of what’s possible. Sometimes it’s up to the mentor to cast a vision and show the mentee what he or she may not even believe is attainable. This can only happen when you emphasize potential instead of problems, and that starts with positivity. It’s been said that attitudes are contagious. There’s actually some science behind that. When we talk to someone we perceive as similar,  : particularly their posture, behavior, speech patterns, and mannerisms. And we are very good at picking up on sentiment. A study showed that  , such as “hmm,” conveyed positive or negative emotions and evoked responses in others. Attitudes are contagious because we communicate them and people reflect them without even trying. You broadcast your sentiment to your mentees, and they pick up on it and mirror back to you what you’re feeling, even if you don’t intend to communicate it. So if you don’t focus on what inspires your mentees with your attitude and actions, there’s a good chance that they won’t either, even if your words say otherwise. Inspiring doesn’t mean ignoring the negative; it means framing the negative in the larger positive. Instead of saying, “You need to spend less time working on overly-complicated solutions,” you can say, “You can be more efficient and offer more value to your clients if you work on simplifying your approach.” The request is equivalent, but the goal is much greater. Offering a positive outcome is much more motivating than stating the immediate negative, even though the intended outcome is the same. Celebrating victories together is another great way to focus on the positive. Checking off big goals is fantastic, but it happens so infrequently that it can’t be counted on to sustain motivation. Celebrating milestones can offer some much needed encouragement along the way. If a junior developer is working toward being able to code an entire site, setting up form validation is a major milestone. If a designer is working toward being a creative director, having a coworker request their feedback can be a big achievement. You don’t have to bake them a cake, but simply acknowledging and praising these little victories can provide great help along the way toward a stronger future. Be patient Early on in my mentoring relationship with Rebecca, she stressed to me the importance of being more organized. I wish I could say I took this to heart and ran with it and totally changed my life based on that feedback, but honestly, I didn’t. Urgent things kept popping up, and it was easier to continue to deal with them in a way that was comfortable to me. Rebecca never forced me to change—she wanted it to be my decision. Eventually, I found that my methods were failing and—guess what?—I needed to be more organized. If I’d listened to Rebecca when she first gave me the advice, I would have improved much more quickly. As a mentor, this sort of thing happens all the time. Sometimes change happens slowly, and sometimes it doesn’t happen at all. What’s going on? Your mentee has come to you because he or she wants to get better—so why resist change? Motivational speaker Tony Robbins once said, “Change happens when the pain of staying the same is greater than the pain of change.” As a mentor, you’re going to have a clear view of your mentee’s pain of staying the same. Your mentee is going to have an intimate view of their own pain of changing. Never assume that both of you have a clear understanding of both of those pieces of information. If you’re lucky, your mentee will come to you after they’ve decided that they want to change. But many times, your mentee won’t know what change looks like until they work with you for a while. Your mentee may actually be shocked by how different change looks compared to what they imagined it would be. You may have to show your mentee the value of changing while disarming their anxieties. Even when the push for positive change has begun, there will be times when it will seem more like a glacier than a flowing river. Your mentee may make mistakes—sometimes the same mistake over and over. They could resist change through an arrogant or stubborn attitude. They could impede it by failing to respond to or take on good opportunities. This can be agonizing for a mentor to watch. There’s a story about a traveler who went to visit a particularly wise man to ask him what made him so much smarter than the average guy. The wise man answered, “I have made 10,000 mistakes.” The traveler, perplexed, asked how that’s different than the average guy. The wise man replied, “The average man makes 10 mistakes 1,000 times each.” Your job is not to stop your mentee from making any mistakes; it’s to stop them from making the same mistakes over and over. There will be times when you want to jump in and correct their every move. There will be times you want to give up. There will be times you want to tell them they’re not learning. Resist. If your mentee is open to change and is making progress, allowing them to fail and learn their own lessons can be an important part of the learning process. As long as your mentee is making new mistakes and not the same ones repeatedly, progress is happening. Your mentee may not be fully aware of the progress they are making. They may not see mistakes as forms of progress, or they may minimize how much they have accomplished. Sometimes, it just takes someone who has been around for longer to identify growth. Change can go much slower than you want it to. At times, it may also surprise you by moving faster than anticipated. The important thing to remember is that another person’s change does not happen on your timetable. Once change starts happening, it’ll be up to you to keep it moving toward a meaningful goal. Be productive Good feelings are great, but they don’t mean a thing if there’s no improvement. Your mentee has to work toward real goals for real-world improvement, and that’s not going to happen unless you get specific. Some structure goes a long way in helping your mentee succeed, and figuring that out beforehand can make or break the relationship. Have a schedule and stick to it. If you’re scheduling mentoring sessions haphazardly, they’re not going to happen regularly enough and they’ll just stop happening eventually. If neither party has anything for a meeting, you can cancel it, but you’d be surprised how many little things come up in regular sessions that wouldn’t necessitate their own meeting. Also, if you’re only scheduling sessions when they’re needed, there’s a tendency to only schedule sessions when something goes wrong. When that happens, mentoring sessions can feel like a punishment. Frequency is going to differ based on a lot of factors—it might be weekly or it might be once a quarter, and it might take a few sessions to figure that out. The rule of thumb is to start with more frequency. If a mentee is at a point where he or she can work independently and still make good progress, you can probably start meeting less frequently. Work together with your mentee to define an objective. Why does your mentee want to improve? An objective can be somewhat loosely defined, but it should have a specific outcome tied to the individual’s career. Being a good designer is too loose, but getting an excellent portfolio ready for a first job is much better. Being a great developer is similarly vague, but being a subject matter expert on a niche technology is much more helpful. This can and probably will end up changing as you and your mentee learn more, but it will at least give you a direction to head in. Once the objective is defined, create goals to establish milestones. Read up on   and make sure your mentee knows how to define them. Each goal should help your mentee toward his or her objective and should be a single measurable step. If a goal is not met in the specified time frame, it’s not the end of the world—just set a new one. If goals are consistently not met, you may have to have a hard conversation with your mentee about how realistic the goals are. Just make sure your mentee is constantly moving toward their objective. Make a loose agenda for your sessions. There should be some flexibility for urgent topics that come up, but you should know ahead of time what topics you want to discuss or ask about. The agenda should make sense to you and your mentee, so you’ll probably want to craft your own, but here’s one to get you started: Lastly, don’t forget to write everything down. It doesn’t matter how good your memory is; things will be lost between sessions if you don’t write them down. Write down notes for each section of your agenda, and review them before the next session. By doing this, there will be consistency between sessions, and you’ll often resolve issues that may have otherwise slipped through the cracks. Be a mentor Remember, you don’t have to be a famous speaker, a renowned expert, or even at the top of the career ladder to be a good mentor—you just have to be able to articulate what what got you where you are today to someone who’s not there yet. If you are willing to do this authentically by being present, positive, patient, and productive, you can be a great mentor today. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/focus-on-what-you-do-best-and-outsource-the-rest/", "title": "Focus on What You Do Best and Outsource the Rest", "content": "With   year after year, high quality web design and development services are in top demand. If you want to be the one to deliver those high-end results, then you’ll need to focus on playing to your strengths and be comfortable entrusting everything else to others. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Like many of us, you’re probably so occupied by managing the day-to-day and maintaining the base of clients you currently have that you don’t have the time or resources to build your web design or development business out to the next level. Why “no pain, no gain” has no place in web design One of the greatest lessons I’ve learned from working as a project and content manager is that there are times when it just doesn’t make sense to take on a task or project that’s not a good fit.  For instance:  I’ve seen developers struggle with marketing their business when they barely have enough time to complete their own workload. I’ve seen web designers hire on supplemental designers (such as video designers and animators), only to lose those new hires just as quickly as they got them because they couldn’t manage the payroll aspect properly. I’ve even seen administrative assistants given the responsibility of loading content into a CMS and, on top of that, being asked to optimize it for search despite a lack of training. While I’ve seen this problem crop up with management of medium and large-sized businesses, I think it’s much more prevalent with small business owners and independent entrepreneurs. When you think about how much of your life (personally and professionally) is wrapped up in your business, it seems to make sense to think that by consolidating tasks, cutting corners, or just taking it all on yourself, you’ll save money and time.  Here’s the problem with that sort of thinking: it’s a dangerous and highly inefficient way to conduct business when you work in web design. No matter the size of our business, we rely on proven processes and techniques to ensure that what we create is always of the highest quality. Let’s face it, we are specialists, and diluting our offering by trying to do everything isn’t fair to our clients or ourselves. My suggestion? Let more qualified people or tools tackle the “stuff” that forces you to slow down, lose productivity, and create something less than what your clients deserve. Sure, it’s scary to think about how much it will cost to outsource your accounting, your SEO, or anything else that isn’t in your wheelhouse. But think about how much momentum and overall quality of work you lose whenever you let that fear take over. I say: focus on what you do best, outsource the rest, and be happily surprised when you see how much your business soars as a result. Follow your strengths In a recent interview about the  , Jeremy Goldman of the Firebrand Group argued that in order for business owners (or any entrepreneurs really) to succeed, they must be willing to accept when they’re not great at something. Once you accept that you’re a bad fit for some tasks, you leave yourself more time to pursue the tasks you’re good at (or want to get better at). Outsourcing may result in additional costs upfront, but if you’re handing those tasks over to someone or something that can handle them more efficiently, I’d argue that you’ll save money in the long run. First, because the outsourced party will spend less time completing a task than it would have taken you. And second, because the investment frees you up to succeed at what you do, which, in turn, is where the real revenue-generating opportunities are.  The key to embracing this is through understanding your operations thoroughly, so you know what can be streamlined or outsourced. Start with an assessment of where your business currently is and where you want it to go. This will tell you exactly how you need to scale, and direct you toward the right forms of outsourcing and assistance. Before you do anything else, assess your current business model. Outline your entire process, starting with customer acquisition and ending with the close of each project. Identify areas that can be consolidated, broken up, or removed altogether. Conduct a review of last year’s work. Identify trends that resulted in positive outcomes. For instance, did a certain workflow always lead to a good profit margin? Or perhaps you found that certain types of clients or projects always led to positive results for you (profit wise) and for your client (conversion wise)? If you don’t have any data, you can seek out previous customers’ opinions to identify what worked and what did not. Review your current pricing structure (if you have one). Determine if there are any particular areas of your operation that cost more money, or bring in less profit, than they should. \nEstablish your ideal pipeline today. Figure out how many projects you can simultaneously work on, as well as how long each turnaround should be. Then, answer the following questions regarding where you expect your business to be in five years: Will you offer the same services? More? Fewer? Different? Will you specialize in services for a specific industry? What will your role in the company be? How large do you expect your client base to be? How many employees would you like to have? How much will your services be worth? Finally, make a list of what is needed to take you from where you are today to where you want to be in five years. If you’re unsure of what exactly you need, or if you want to make the process easier on yourself, keep reading. Tools that allow you to focus on what you do best Want to be more efficient? First things first then: take a closer look at the tasks that fall outside your wheelhouse. These are the ones that distract from your primary goal and that consume too much of your valuable time. By saying “no” to those tasks and finding ways to offload them to someone else, you’ll find that the costs associated with them end up being negligible after a while. The following recommendations are some of the more affordable, practical, and commonly outsourced and automated areas of web design I’ve been privy to. I’ve also included a number of tools you can use for each that will grow as your business does. Freelancers There’s no doubt that technology plays a big part in the scaling of a business. That being said, most automation still requires human supervision and maintenance. While you may not be ready to hire full-time staff at the moment (or even in the near future), you’ll want to start considering what team members you’ll need in order to reach your goals. One of the best ways to scale your team is to employ freelance or contract workers. This enables you to: Pay only for the work you need. Offload some of your work for an affordable rate. Test out new team members without the commitment of hiring full-time. Expand your service offerings to clients on an as-needed basis. Recommended tools: Freelance job sites like  ,  ,  , and   are always a good place to start. They cost a bit of money to use (in addition to freelancer costs), but I’m a fan of them since they offer a relatively low-risk way to test out new talent without the serious commitment of hiring. You’re most likely already familiar with Envato for its theme and plugin Market as well as for its Tuts+ tutorials, but did you know they also have a freelance hiring  ?  and   have also proven to be good platforms for finding freelance talent (especially if you have a solid follower base). Recruiters This isn’t one of the more popular avenues I’ve seen web design companies pursue in terms of outsourcing, but I still think it’s one worth mentioning. If you think about it, there are a number of items competing for your attention on a regular basis: Your daily workload. Clients and prospects reaching out with questions and comments. \nEverything related to your employees or contractors (HR, productivity, process improvement, etc.). Finance management. Marketing your business and services.\n And more So, when do you find time to turn your attention away from the “right here, right now” stuff and look toward finding new clients so you can expand your business and make more money? If your answer is “the weekend,” then something’s wrong. Every time you add more hours to your work week, you lose money and overall efficiency. This is where recruiters come in handy. You find someone that’s reliable, that you trust, and then you outsource the task of finding more work to them. These experts are incredibly valuable business partners who know how to sniff out those right-fit clients without breaking a sweat, while leaving you to focus on your real work. Recommended tools: I’d suggest you start by signing with a creative staffing agency like  . You’ll have the flexibility of searching for and applying to work with clients, or you can work directly with one of their representatives.  aren’t recruiters, per se, but they instead help you leverage the power of your personal network to help you find clients more easily. Want something more comprehensive where you have access to training, career coaching, and someone who takes care of your paperwork?   would be a great solution in that case! CRM software Word of mouth is a great way to get more business—especially if you have a niche or specialty. But referrals will only get you so far. You’ll eventually need to actively market your brand to prospective customers. With most of your time dedicated to the actual work that makes you money, how can you make time for cultivating relationships with potential clients? At some point, you’ll be able to hire a marketing team to handle all these matters. In the meantime, you’ll need customer relationship management (CRM) software to tide you over. These tools typically offer a variety of marketing and sales functions, including: Lead collection and management. Sales opportunity tracking. Revenue pipeline predictions and planning. Contact reminders. Email templates. Eventually, you’ll need to become more active on social media and invest in paid marketing opportunities. For now, though, get yourself a tool that will help you build relationships with prospects and customers. Recommended tools:  is a fairly easy-to-use CRM platform, as is   (see note about that below). Both of these also integrate with the  , which makes syncing up WordPress website forms with your CRM easier. If you want a simpler solution that focuses more on collecting leads from newsletters or blog signups, I’d suggest either   or  . Memberships As a web designer or developer, you know that working with a reliable content management system can do wonders for your workflow. Then you get into a platform like WordPress, Squarespace, Drupal, or Perch Runway, and you recognize it’s the extensibility of these platforms that truly make them such valuable tools. Using a CMS out of the box is a good start, but it’s not enough. Your business toolbox should include the most commonly used CMS tools, such as design templates as well as extensions. They were created to help users—novice, intermediate, and advanced—more easily and quickly build websites. If you’re reading this, then you’re aware of this already. What you might not be doing, however, is taking advantage of the plethora of memberships available. By signing up for one of these, you get instant access to a wide range of high-performance tools that help you build better websites, and in less time. Recommended tools: Considering that   run on WordPress, you can start there. Some of the more popular WordPress memberships are offered by  ,  , and  .  is also a good one to consider if you need high-performance plugins. I’d also suggest you look into  , if you haven’t already. While they’re not necessarily a membership site, having so many high-quality plugins in one place is an attractive and convenient option. Managed hosting services As a web developer, you may not be too excited when clients ask if you offer ongoing management or maintenance for their website. Yet, you might feel a little guilty in not offering these services, since you know there’s a good likelihood your clients won’t know about adding security, optimizing speed, making backups, or keeping the core platform and tools up to date. If you’re not comfortable with ongoing management of your client’s website, you can still offer it as an upgrade; only, you’ll hire an expert to manage it for you. Managed hosting providers do just that. This is a great way to upsell your clients and make a decent markup without increasing your workload. If this is something you’d rather not get involved with just now, you can always work with a low-maintenance CMS like Squarespace that doesn’t require much in the way of ongoing management. Remember: this is your business. It’s up to you how you want to run it and what sort of services you want to offer. Whatever you choose, be sure you’re working with the best provider for your needs (especially if you generally work in one CMS). They should offer a variety of packages based on business type and size, too, as this will enable you to scale your services as your needs grow. Recommended tools: For WordPress, I’d suggest you take a look at   or  .  offers both WordPress and Joomla managed hosting.  and   both have some of the more robust CMS managed hosting offerings I’ve seen, so give them a try if you want to provide more coverage options. Project management software Although it may not seem like something you need right now, a workflow and collaboration platform should be part of your business from the very start. As a business owner, you need to have a centralized hub where you can: Store documentation. Generate and save templates to streamline communication with clients, ensure consistency in project output and deliverables, and provide clear guidance to team members. Manage project workflows through a series of checklists. Gather files. Communicate with clients. Collaborate with team members. Track time spent on projects. If your business is design-focused and QA-heavy, it’s ideal that you find a project management tool that includes wireframing and/or prototyping functionality. Recommended tools:  is one of the more popular project management tools I’ve used, but its cost makes it a better choice for agencies.  is my personal favorite—something I use in my everyday work as well as personal scheduling. I’d suggest using this one for creating checklists, communicating with team members, and managing timelines.  is a good pick, especially because it includes prototyping, wireframing, and collaboration, which is essential to web design work. Accounting software How much time do you currently spend drawing up contracts, writing invoices, tracking payments, and managing your taxes? As your business grows, the amount of work you do to manage these administrative areas will increase, too. Rather than spend your time focusing on the numbers, use accounting software to take most of the guesswork out of it (especially until you have a need for a full-time accountant). In addition, you can employ certain techniques that will help you get the tasks out of your head and into a   and actionable checklist. I’d also suggest you take   to determine whether you should even be handling any accounting tasks for your business in the first place. This may just be one of those responsibilities that make more sense in the hands of someone else.  Recommended tools: I’m a big fan of  , not only because of how easy it is to use, but because it integrates with so many different programs and decreases the overall amount of work I need to do.  is another great tool to check out. I like this one because you can manage your finances and invoices, and also use it as a customer relationship management tool. For anyone just starting out, I’d suggest giving   a try. It’s free to use and is a good platform to help you ease into finance management. Summary At the end of the day, you need to focus on what you do best. Time spent doing anything else is an unnecessary drain on you and your business. If you’re looking to grow your business, it’s time to consider how you can most efficiently scale it. Review what you currently have. Then look to these tools to bring more order, control, and consistency to your operations. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/user-research-when-you-cant-talk-to-your-users/", "title": "User Research When You Can’t Talk to Your Users", "content": "It’s not breaking news to say that the core of UX, in a vacuum, is talking to your users to gather insights and then applying that information to your designs. But it’s equally true that UX does not happen in a vacuum. So what happens when you don’t have the budget or the timeline to run user tests, card sorts, or stakeholder interviews? What should you do when your company doesn’t want you bothering the paying customers who use their software? In short,  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. While the best methods for gathering user insights entail first-hand research, there are other ways to quickly glean qualitative data about your users’ wants and needs—beyond the usual   options.  For a start, companies that are new or have a smaller digital footprint can benefit from things like forums or even competitor reviews to get a better sense of the users in their industry vertical. And for more established companies, customer service logs and app reviews can be invaluable for learning what users think about specific products. Let’s check out a few techniques I like to recommend. App reviews When products have a mobile app component, I start looking at reviews posted on the App Store or Google Play. The key, in terms of user research, is to focus on the substance of what the user is saying, as opposed to the rating (i.e., one star to five stars). For instance: Is the user simply disgruntled or are they asking for a tangible feature to be added to the product? Is the user truly thrilled with some aspect of her experience using the app or is she just a brand loyalist? While reviews do tend to be rather partisan, keep in mind that users are most likely to leave feedback when motivated by an emotional reaction to the product. Emotionally-driven reviews—whether positive or negative—tend to be outliers on the bell curve, so the next step is taking all those reviews and distilling them into tangible insights. Let’s face it, when you want to improve the featureset and functionality, a general reaction to the entirety of an app doesn’t tend to be particularly actionable. Here are a few questions I always start with: Are there missing features users want to see? Do users seem confused by aspects of the UI? Are they complaining about bugs or performance issues that are popping up and making the app unusable? Do people really love a hidden feature that was put in as an afterthought with minimal prominence—something we should consider placing more front and center? Does it seem like people understand how to use the app or do they need a tutorial on first open? Also, it’s important to remember that feedback on an iOS app may or may not be applicable to an Android app (or mobile web experience), and vice versa. Customer service logs Customer service and help center personnel are  , helping them with specific struggles they encounter with the usability of your products. In other words, they’re constantly learning how users see the product and go about using it. Since user information can be sensitive, the first thing to try is asking whether service calls and contacts are being logged. If so, ask whether it’s possible to get access to the records for user research purposes. If there are no logs, or if you are unable to get access to them, see if a few brief stakeholder interviews with customer service team members is an option. Use the interviews to learn which types of problems and complaints they routinely field. Given the nature of customer service and the purpose of help centers, it’s likely that much of the feedback will be negative. Even so, these logs can still provide excellent data. In particular, the feedback can help illuminate policies and business practices that are creating a negative user experience, not to mention identify the points at which they occur during the user journey. And remember,  .  Contact form emails “Contact Us” forms and messages can be rich with direct input from your users. Obviously, the first things to look for are complaints about an aspect of the site itself. For example, are users struggling to find a feature or getting confused by a certain page on the site? Beyond that, the forms themselves can relate to aspects of the user journey that are problematic. If a brand or company does not have this feature for gathering site visitors’ opinions, it’s relatively easy to add a contact form, in terms of development effort. However, it’s important to note that if you have a contact form on your site, someone should be actively monitoring it and responding to users. Industry forums While the likes of Reddit and 4Chan have given the world of online forums some questionable connotations, the truth is that many online forums are also excellent sources of information about how digital products are operating in the wild, and how specific products and trends as a whole are influencing users. The research insights might be less obvious, but they’re easy to spot if you’re looking for them. A look at the Apple TV Apps section of Mac Rumors reveals that many users of the 4th generation Apple TV have a   not fading out video titles when a video is playing. Similarly, a brief review of the   on FlyerTalk shows that  users have questions about everything from Economy Plus seating to the Delta and American Express credit card. Reviewing this information could help Delta retool the content strategy and information architecture of their mobile app to address questions more clearly.  Many forums are industry specific, and therefore not applicable to every situation. There are just as many out there, however, that specialize in spanning numerous industries.   covers virtually any sort of traditional tech product. For video games,   offers helpful feedback from players about everything from game length and storyline to controls. For nutrition and exercise, Bodybuilding.com’s   is a top online destination for users to discuss nutrition and exercise. Of course, not every forum offers in-depth discussions regarding specific apps, websites, or even companies, but each provides great sources of information about what motivates and interests consumers in that industry vertical. Multi-topic forums can be searched for company- or product-specific threads.   (despite its aforementioned reputation) features thriving, engaged communities of actual users talking about topics of value.   offers an almost scholarly approach to the format, with many users possessing strong subject matter credentials to validate their expertise. Reviews of competitors Perhaps your brand or product is new in the market and there’s not yet enough data from any of these sources to be actionable. So what then? Find out what your potential users have to say about the competition. If you want to launch a car service, see what users say about Lyft and Uber on the App Store. Want to improve Jet? Read reviews of Amazon Prime. Do you work for InstaCart? Find out what users have to say about Fresh Direct. In summary There’s still no substitute for actually talking to your user base, whether that’s initial research in the form of stakeholder interviews or testing design iterations, but even when that’s not an option, there’s no excuse for not gathering feedback from your users.  Good UX design should always be based on user insights, not assumptions about best practices or what might translate from other products and industries. So go find out what your users are saying. From Yelp! to Glassdoor to App Store Reviews, consumers are readily sharing their opinions about businesses of every size, in every industry. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/fait-accompli-agentive-tech-is-here/", "title": "Fait Accompli: Agentive Tech Is Here", "content": "Similar to intelligence, agency can be thought of as a spectrum. Some things are more agentive than others. Is a hammer agentive? No. I mean if you want to be indulgently philosophical, you could propose that the metal head is acting on the nail per request by the rich gestural command the user provides to the handle. But the fact that it’s always available to the user’s hand during the task means it’s a tool—that is, part of the user’s attention and ongoing effort. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Less philosophically, is an internet search an example of an agent? Certainly the user states a need, and the software rummages through its internal model of the internet to retrieve likely matches. This direct cause-and-effect means that it’s more like the hammer with its practically instantaneous cause-and-effect. Still a tool. But as you saw before, when Google lets you save that search, such that it sits out there, letting you pay attention to other things, and lets you know when new results come in, now you’re talking about something that is much more clearly acting on behalf of its user in a way that is distinct from a tool. It handles tasks so that you can use your limited attention on something else. So this part of “acting on your behalf”—that it does its thing while out of sight and out of mind—is foundational to the notion of what an agent is, why it’s new, and why it’s valuable. It can help you track something you would find tedious, like a particular moment in time, or a special kind of activity on the internet, or security events on a computer network. To do any of that, an agent must monitor some stream of data. It could be something as simple as the date and time, or a temperature reading from a thermometer, or it could be something unbelievably complicated, like watching for changes in the contents of the internet. It could be data that is continuous, like wind speed, or irregular, like incoming photos. As it watches this data stream, it looks for triggers and then runs over some rules and exceptions to determine if and how it should act. Most agents work indefinitely, although they could be set to run for a particular length of time or when any other condition is met. Some agents like a spam filter will just keep doing their job quietly in the background. Others will keep going until they need your attention, and some will need to tell you right away. Nearly all will let you monitor them and the data stream, so you can check up on how they’re doing and see if you need to adjust your instructions. So those are the basics. Agentive technology watches a datastream for triggers and then responds with narrow artificial intelligence to help its user accomplish some goal. In a phrase, it’s a persistent, background assistant. If those are the basics, there are a few advanced features that a sophisticated agent might have. It might infer what you want without your having to tell it explicitly. It might adapt machine learning methods to refine its predictive models. It might gently fade away in smart ways such that the user gains competence. You’ll learn about these in Part II, “Doing,” of this book, but for now it’s enough to know that agents can be much smarter than the basic definition we’ve established here. How   Are Agents? Since most of the design and development process has been built around building good tools, it’s instructive to compare and contrast them to good agents—because they are different in significant ways. Drawing a Boundary Around Agentive Technology To make a concept clear, you need to assert a definition, give examples, and then describe its boundaries. Some things will not be worth considering because they are obviously in; some things will not be worth considering because they are obviously out; but the interesting stuff is at the boundary, where it’s not quite clear. What is on the edge of the concept, but specifically isn’t the thing? Reviewing these areas should help you get clear about what I mean by agentive technology and what lies beyond the scope of my consideration. It’s Not Assistive Technology Artificial narrow intelligences that help you perform a task are best described as assistants, or assistive technology. We need to think as clearly about assistive tech as we do agentive tech, but we have a solid foundation to design assistive tech. We have been working on those foundations for the last seven decades or so, and recent work with heads-up displays and conversational UI are making headway into best practices for assistants. It’s worth noting that the design of agentive systems will often entail designing assistive aspects, but they are not the same thing. It seems subtle at first, but consider the difference between two ways to get an international airline ticket to a favorite destination. Assistive technology would work to make all your options and the trade-offs between them apparent, helping you avoid spending too much money or winding up with a miserable, five-layover flight, as you make your selection. An agent would vigilantly watch all airline offers for the right ticket and pipe up when it had found one already within your preferences. If it was very confident and you had authorized it, it might even have made the purchase for you.  It’s Not Conversational Agents “Agent” has been used traditionally in services to mean “someone who helps you.” Think of a customer service agent. The help they give you is, 99 percent of the time, synchronous. They help you in real time, in person, or on the phone, doing their best to minimize your wait. In my mind, this is much more akin to an assistant. But even that’s troubling since “assistant” has also been used to mean “that person who helps me at my job” both synchronously—as in “please take dictation”—and agentively—as in “hold all my calls until further notice.” These blurry usages are made even blurrier because human agents and assistants can act in both agentive and assistive ways. But since I have to pick, given the base meanings of the words, I think an assistant should assist you with a task, and an agent takes agency and does things for you. So “agent” and “agentive” are the right terms for what I’m talking about. Complicating that rightness is that a recent trend in interaction design is the use of conversational user interfaces, or chatbots. These are distinguished for having users work in a command line interface inside a chat framework, interacting with software that is pretty good at understanding and responding to natural language. Canonical examples feature users purchasing airline tickets (yes, like a travel agent) or movie tickets. Because these mimic the conversations one might have with a customer service agent, they have been called conversational agents. I think they would be better described as conversational assistants, but nobody asked me, and now it’s too late. That ship has sailed. So, when I speak of agents, I am not talking about conversational agents. Agentive technology might engage its user through a conversational UI, but they are not the same thing. It’s Not Robots No. But holy processor do we love them. From Metropolis’ Maria to BB8 and even GLaDoS, we just can’t stop talking and thinking about them in our narratives. A main reason I think this is the case is because they’re easy to think about. We have lots of mental equipment for dealing with humans, and robots can be thought of as a metal-and-plastic human. So between the abstraction that is an agent, and the concrete thing that is a robot, it’s easy to conflate the two. But we shouldn’t. Another reason is that robots promise—as do agents—“ethics-free” slave labor (please note the irony marks, and see Chapter 12 “Utopia, Dystopia, and Cat Videos” for plenty of ethical questions). In this line of thinking, agents work for us, like slaves, but we don’t have to concern ourselves about their subservience or even subjugation the same way we must consider a human, because the agents and robots are programmed to be of service. There is no suffering sentience there, no longing to be free. For example, if you told your Nest Thermostat to pursue its dreams, it should rightly reply that its dream is to keep you comfortable year round. Programming it for anything else might frustrate the user, and if it is a general artificial intelligence, be cruel to the agent. Of course, robots will have software running them, which if they are to be useful, will be at times agentive. But while our expectations are that the robot’s agent stays in place, coupled as we are to a body, that’s not necessarily the case with an agent. For example, my health agent may reside on my phone for the most part, but tap into my bathroom scale when I step on it, parley with the menu when I’m at a restaurant, pop onto the crosstrainer at the gym, and jump to the doctor’s augmented reality system when I’m in her office. So while a robot may house agentive technology, and an agent may sometimes occupy a given robot, these two elements are not tightly coupled. It’s Not Service by Software I actually think this is a very useful way to think about agentive tech: service delivered by smart software. If you have studied service design, then you have a good grounding in the user-centered issues around agentive design. Users often grant agency to services to act on their behalf. For example, I grant the mail service agency to deliver letters on my behalf and agree to receive letters from others. I grant my representative in government agency to legislate on my behalf. I grant the human stock portfolio manager agency to do right by my retirement. I grant the anesthesiologist agency to keep me knocked out while keeping me alive, even though I may never meet her. But where a service delivers its value through humans working directly with the user or delivering the value “backstage,” out of sight, an agent’s backstage is its programming and the coordination with other agents. In practice, sophisticated agents may entail human processes, but on balance, if it’s mostly software, it’s an agent rather than a service. And where a service designer can presume the basic common senses and capabilities of any human in its design, those things need to be handled much differently when we’re counting on software to deliver the same thing. It’s Not Automation If you are a distinguished, long-time student of human-computer interaction, you will note similar themes from the study of automation and what I’m describing. But where automation has as its goal the removal of the human from the system, agentive technology is explicitly in service to a human. An agent might have some automated components, but the intentions of the two fields of study are distinct. Hey Wait—Isn’t Every Technology an Agent? Hello, philosopher. You’ve been waiting to ask this question, haven’t you? A light switch, you might argue, acts as an agent, monitoring a data stream that is the position of the knife switch. And when that switch changes, it turns the light on or off, accordingly.  Similarly, a key on a keyboard watches its momentary switch and when it is depressed, helpfully sends a signal to a small processor on the keyboard to translate the press to an ASCII code that gets delivered to the software that accumulates these codes to do something with them. And it does it all on your behalf. So are keys agents? Are all state-based machines? Is it turtles all the way down? Yes, if you want to be philosophical about it, that argument could be made. But I’m not sure how useful it is. A useful definition of agentive technology is less of a discrete and testable aspect of a given technology, and more of a productive way for product managers, designers, users, and citizens to think about this technology. For example, I can design a light switch when I think of it as a product, subject to industrial design decisions. But I can design a better light switch when I think of it as a problem that can be solved either manually with a switch or agentively with a motion detector or a camera with sophisticated image processing behind it. And that’s where the real power of the concept comes from. Because as we continue to evolve this skin of technology that increasingly covers both our biology and the world, we don’t want it to add to people’s burdens. We want to alleviate them and empower people to get done what needs to be done, even if we don’t want to do it. And for that, we need agents. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/web-maintainability-survey/", "title": "Web Maintainability Industry Survey: How Do We Maintain?", "content": "How often do we consider the maintenance and general maintainability of our websites and apps? What steps do we actively take to make and keep them maintainable? What stands in the way when we maintain our and other people’s projects? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Many of us, as web developers, know very well how to code something. But whether we know just as well how to maintain what we—and others—have written, that is not so clear. Our bosses and clients may not always think about maintenance down the road, either. As an   and former Googler, I’ve been   since 2008—and we have yet to gather our industry’s views on the subject. To help us all get a better picture of   we maintain and how we can maintain  , I set up a   ( ) and kindly ask for your assistance. The survey aims to collect specific practices and resources—in other words, your views on current practices (both useful and harmful) and everything you find helpful: What helps maintenance? What prevents maintenance? What resources do developers turn to for improving maintainability? The outcome of the survey and an updated guide to web maintainability will be published in a few weeks on   (and noted on  ). Thank you for your support. Like this: \n\t\t\t\t\t\t\tRecently by Jens Oliver Meiert\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/mindfulness-of-a-manual-performance-audit/", "title": "The Mindfulness of a Manual Performance Audit", "content": "As product owners or developers, we probably have a good handle on which core assets we need to make a website work. But rarely is that the whole picture. How well do we know   that loads on our sites? Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. An occasional web performance audit, done by hand,   make us aware of every last thing. What’s so great about that? Well, for starters, the process increases our mindfulness of what we are actually asking of our users. Furthermore, a bit of spreadsheet wizardry lets us shape our findings in a way that has more meaning for stakeholders. It allows us to speak to our web performance in terms of purpose, like so: Want to be able to make something like that? Follow along. Wait, don’t we have computers for this sort of thing? A manual audit may seem like pointless drudgery. Why do this by hand? Can’t we automate this somehow? That’s the whole point. We want to achieve mindfulness—not automate everything away. When we take the time to consider   that loads on a page, we get a truer picture of our work. It takes a human mind to look at every asset on a page and assign it a  . This in turn allows us to shape our data in such a way that it means something to people who don’t know what acronyms like CSS or WOFF mean. Besides, who doesn’t like a nice pie chart? Here’s the process, step by step: The audit may take half an hour to an hour the first time you do it this way, but with practice you’ll be able to do it in a few minutes. Let’s go! Gathering your performance data To get started, figure out what URL you want to evaluate. Look at your analytics and try to determine which page   is your most popular. Don’t just default to your home page. For instance, if you have a news site, articles are probably your most popular page type. If you’re analyzing a single-page app, determine what the most commonly accessed view is. You need to get your network activity at that URL into a CSV/spreadsheet format. In my experience, the easiest way to do this is to use  , whose premise is simple: give it a URL, and it will do an assessment that tries to measure perceived performance. Head over to WebPagetest and pop your URL in the big field on the homepage. However, before running the test, open the Advanced Settings panel. Make sure you’re only running one test, and set   to  . This will ensure that you don’t have duplicate requests in your data. Now, let the test run—hit the big “Start Test” button. Once you have a results page, click the link in the top right corner that says “Raw object data”. A CSV file will download with your network requests set out in a spreadsheet that you can manipulate. Navigating & scrubbing the data Now, open the CSV file in your favorite spreadsheet editor: Excel, Numbers, or (my personal favorite)  . The rest of this article will be written with Google Sheets in mind, though a similar result is certainly possible with other spreadsheet programs. At first it will probably seem like this file contains an unwieldy amount of information, but we’re only interested in a small amount of this data. These are the three columns we care about:  (column F)  (column G)  (column N) The other columns you can just ignore, hide, or delete. Or even better: select those three columns, copy them, and paste them into a   spreadsheet. Auditing each asset request With your pared-down spreadsheet, insert a new first column and label it “Purpose”. You can also include a Description/Comment column, if you wish. Next, go down each row, line by line, and assign each asset request a purpose. I suggest something like the following:  (e.g., the core HTML document, images, media—the stuff users care about)  (e.g., functional JavaScript files that you have authored, CSS, webfonts)  (e.g., Google Analytics, New Relic, etc.)  (e.g., Google DFP, any ad networks, etc.) Your Purpose names can be whatever you want. What matters is that your labels for each purpose are consistent—capitalization and all. They need to group neatly in order to generate the fancy charts later. (Pro tip: use   on this column to ensure consistency in your spreadsheet.) So how do you determine the purpose? Typically, the biggest clue is the “Host” column. You will, very quickly, start to recognize which hosts provide what. Your root URL will be where your document comes from, but you will also find:  like cloudfront.net, or cloudflare.com. Sometimes these have images (which are typically content); sometimes they host CSS or JavaScript files (functionality).  like googletagservices.com, googletagmanager.com, google-analytics.com, or js-agent.newrelic.com.  like doubleclick.net or googlesyndication.com. If you’re ever unsure of a URL, either try it out yourself in your browser, or literally google the URL. (Hint: if you don’t recognize the URL right away, it’s most likely ad-related.) Mindfulness Just doing the steps above will likely be eye-opening for you. Stopping to consider each asset on a page, and   it’s there, will help you be mindful of every single thing the page loads. You may be in for some surprises the first time you do this. A few unexpected items might turn up. A script might be loaded more than once. That social widget might be a huge page weight. Requests coming from ads might be more numerous than you thought. That’s why I suggested a Description/Comment column—you can make notes there like “WTF?” and “Can we remove this?” Augmenting your data Before you can generate fancy pie charts, you’ll need to do a little more spreadsheet wrangling. Forewarned is forearmed—extreme spreadsheet nerdery lies ahead. First, you need to translate the request sizes to kilobytes (KB), because they are initially supplied in bytes, and no human speaks in terms of bytes. Next to the column “Object Size,” insert another column called “Object Size (KB).” Then enter a formula in the first cell, something like this: Translation: you’re simply dividing the amount in the cell from the previous column (E2, in this case) by 1000. You can highlight this new cell, then drag the corner down the entire column to do the same for each row. Totaling requests Now, to figure out how many HTTP requests are related to each Purpose, you need to do a special kind of count. Insert two more columns, one labeled “Purpose Labels” and the second “Purpose Reqs.” Under Purpose Labels, in the first row, enter this formula: This assumes that your purpose assessment is column B. If it’s not, swap out the “B” in this example for your column name. This formula will go down column B and output a result if it’s  . You only need to enter this in the first cell of the column. This is one reason why having consistency in the Purpose column is important. Now, under the second column you made (Purpose Reqs) in the first cell, enter this formula: This formula will also go down column B, and do a   if it matches with something in column G (assuming column G is your Purpose Labels column). This is the easiest way to total how many HTTP requests fall into each purpose. Totaling download size by purpose Finally, you can now also total the data (in KB) for each purpose. Insert one more column and call it Purpose Download Size. In the first cell, insert the following formula: This will total the data size in column F   its purpose in column B matches G2 (i.e., your first Purpose Label from the section above). In contrast to the last two formulas, you’ll need to copy this formula and modify it for each row, making the last part (“G2”) match the row it’s on. In this case, the next one would end in “G3”. Make with the fancy charts With your assets grouped by purpose, data translated to KB, number of requests counted, and download size totaled, it will be pretty easy to generate some charts. The HTTP request chart To make an HTTP request chart, select the columns Purpose Label and Purpose Reqs (columns G and H in my example), and then go to Insert > Chart. Scroll down the list of possible charts, and choose a pie chart. Be sure to check the box marked “Use column G as labels.” Under the “Customization” tab, edit the Title to say “HTTP Requests”; under “Slice,” be sure “Value” is selected (the default is “Percentage”). We do this because the number of requests is what you want to convey here. Go ahead—tweak the colors to your liking. And   while you’re at it. Download-size chart The download-size-by-purpose pie chart is very similar. Select the columns Purpose Label and Purpose Download Size (columns G & I in my example); then go to Insert > Chart. Scroll down the list of possible charts and choose a pie chart. Be sure to check the box marked “Use column G as labels”. Under the “Customization” tab, edit the Title to say “Download Size”; under “Slice,” be sure “Value” is selected as well. We do this so we can indicate the total KB for each purpose. Or, you can grab a ready-made template. If you want to see a completed assessment, check out   on  . I’ve also made  . Feel free to go to File > Make a Copy so you can play around with it. You just need to get your page data from WebPagetest and paste in the three columns. After that, you can start your line-by-line assessment. Telling the good from the bad If you show your data to a stakeholder, they may be surprised by how much page weight goes to things like ads or analytics. On the other hand, they might respond by asking what we   be aiming for. That question is a little harder to answer. Some benchmarks get bandied about—1 MB or less, a WebPagetest Score of 1000, a Google PageSpeed score of over 90, and so on. But those are very arbitrary parameters and, depending on your project, unattainable ideals. My suggestion?   If you can come back to your stakeholders and show how two or three competitors stack up, and show them what you’re doing, that will go much further in championing performance. Remember that performance is never “done”—it can only improve. What might help your organization is doing assessments like this over time and presenting page performance as an ongoing series of bar charts. With a little effort (and luck), you should be able to demonstrate that the things your organization cares about are continually improving. If not, it will present a much more compelling case for why things need to change for the better. So you have some pretty charts. Now what? Your charts’ usefulness will vary according to the precise business needs and politics of your organization. For instance, let’s say you’re a developer, and a project manager asks you to add yet another ad-metrics script to your site. After completing an assessment like the one above, you might be able to come back and say, “Ads already constitute 40 percent of our page weight. Do you really want to pile on more?” Because you’ve ascribed   to your asset requests, you’ll be able to offer data like that. I once worked with a project manager who started pushing back on such requests because I was able to give them easy-to-understand data of this sort. I’m not saying it will always turn out this way, but you need to give decision makers information they can grasp. Remember, too, that you are in charge of the Purpose column. You can make up any purpose you want. Interested in the impact that movie files have on your site relative to everything else? Make one of your purposes “Movies.” Want to call out framework files versus files you personally author? Go for it! I hope that this article has made you want to consider, and reconsider, each and every thing you download on a given page. Each and every request. And, in the process of doing this, I hope you are equipped to call out by purpose every item you ask your users to download. That will allow you to talk with your stakeholders in a way that   understand, and will help you make the case for better performance choices. Further reading: Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/color-accessibility-workflows/", "title": "Color Accessibility Workflows", "content": " ( ) 2.0 contain recommendations from the World Wide Web Consortium (W3C) for making the web more accessible to users with disabilities, including color blindness and other vision deficiencies. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. There are three levels of conformance defined in WCAG 2.0, from lowest to highest: A, AA, and AAA. For text and images of text, AA is the minimum level that must be met. AA compliance requires text and images of text to have a   of 4.5:1. In other words, the lighter color in a pair must have four-and-a-half times as much   (an indicator of how bright a color will appear) as the darker color. This contrast ratio is calculated to include people with moderately low vision who don’t need to rely on contrast-enhancing assistive technology, as well as people with color deficiencies. It’s meant to compensate for the loss in contrast sensitivity often experienced by users with 20/40 vision, which is half of normal  . Level AAA compliance requires a contrast ratio of 7:1, which provides compensation for users with 20/80 vision, or a quarter of normal 20/20 vision. People who have a degree of vision loss more than 20/80 generally require assistive technologies with contrast enhancement and magnification capabilities.  Text that acts as pure decoration, nonessential text that appears in part of a photograph, and images of company logos do not strictly need to adhere to these rules. Nonessential or decorative text is, by definition, not essential to understanding a page’s content. Logos and wordmarks may contain textual elements that are essential to broadcasting the company’s visual identity, but not to conveying important information. If necessary, the logo may be described by using an alt attribute for the benefit of a person using screen-reader software. To learn more, check out accessibility specialist Julie Grundy’s blog post on  , where she goes into the best practices around describing alt attributes. Text size plays a big role in determining how much contrast is required. Gray text with an RGB value of (150,150,150) on a pure white background passes the AA level of compliance, as long as it’s used in headlines above 18 points. Gray text with an RGB value of (110,110,110) passes the AA level at any text size, and will be AAA compliant if used as a headline above 18 points ( ). A font displayed at 14 points may have a different level of legibility compared to another font at 14 points due to the wide diversity of type styles, so keep this in mind, especially when using very thin weights. Personally, I recommend that all body text be AAA compliant, with larger headlines and less important copy meeting AA compliance as a bare minimum. Keep in mind that these ratios refer to solid-colored text over solid-colored backgrounds, where a single color value can be measured. Overlaying text on a gradient, pattern, or photograph may require a higher contrast value or alternative placement, such as over a solid-colored strip, to provide sufficient legibility.  These compliance ratios are often what folks mean when they claim that achieving accessible design by “ticking off boxes” can only come at the cost of stifled creativity or restricted color choices. But that simply isn’t true. Experimentation with a color-contrast checker proves that many compliance ratios are quite reasonable and easy to achieve—especially if you are aware of the rules from the beginning. It would be much more frustrating to try to shift poor color choices into something compliant later in the design process, after branding colors have already been chosen. If you fight your battles up front, you’ll find you won’t feel restricted at all.  If all this talk of numbers seems confusing, I promise there’ll be no real math involved on your side. You can easily find out if your color pairs pass the test by using a color-contrast checker. Contrast checkers One of my favorite tools is Lea Verou’s   ( ). It gives you the option of entering a color code for a background and a color code for text, and it calculates the ratio for you. Contrast Ratio supports color names, hex color codes, RGBA values, HSLA values, and even combinations of each. Supporting RGBA and HSLA values means that Verou’s tool supports transparent colors, a handy feature. You can easily share the results of a check by copying and pasting the URL. Additionally, you can modify colors by changing the values in the URL string instead of using the page’s input fields. Another great tool that has the benefit of simultaneously showing whether a color combination passes both AA and AAA compliance levels is Jonathan Snook’s   ( ).  At the time of writing, Colour Contrast Check doesn’t support HSL alpha values, but it does display the calculated brightness difference and color difference values, which might interest you if you want a little more information.  Color pickers If you need help choosing accessible colors from the start, try  . This web-based tool helps designers experiment with and choose color combinations that are immediately contrast-compliant. Enter a background color as a starting point; then choose a standard font family, font size, font weight, and target WCAG compliance level. Color Safe will return a comprehensive list of suggestions that can be used as accessible text colors ( ).  Adjustment tools  When faced with color choices that fail the minimum contrast ratios, consider using something like   to help find appropriate alternatives ( ). This incredibly useful tool takes a foreground and background color pair and then presents a range of compliant options comparable to the original colors. It’s important to note that this tool works best when the colors are already close to being compliant but just need a little push—color pairs with drastically low contrast ratios may not return any suggestions at all ( ). There’s more where that came from! Check out the rest of   at  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/team-conflict-four-ways-to-deflate-the-discord-thats-killing-your-team/", "title": "Team Conflict: Four Ways to Deflate the Discord that’s Killing Your Team", "content": "It was supposed to be a simple web project. Our client needed a site that would allow users to create, deploy and review survey results. Aside from some APIs that weren’t done, I wasn’t very worried about the project. I was surprised that my product manager was spending so much time at the client’s office. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Then, she explained the problem. It seemed that the leaders of product, UX and engineering didn’t speak to each other and, as a result, she had to walk from office to office getting information and decisions. The conflicts probably started small. One bad interaction, then another, then people don’t like each other, then teams don’t work together well. The small scrape becomes a festering wound that slows things down, limits creativity and lowers morale. Somehow as a kid working my way through school I discovered I had a knack for getting around individuals or groups that were fighting with each other. I simply figured out who I needed to help me accomplish a task, and I learned how to convince, cajole or charm them into doing it. I went on to teach these skills to my teams. That sufficed for a while. But as I became a department head and an adviser to my clients, I realized it’s not enough to make it work. I needed to learn how to make it better. I needed to find a way to stop the infighting I’ve seen plague organizations my entire career. I needed to put aside my tendency to make the quick fix and have hard conversations. It’s messy, awkward and hard for team leaders to resolve conflict but the results are absolutely worth it. You don’t need a big training program, a touchy-feely retreat or an expensive consultant. Team members or team leads don’t have to like each other. What they have to do is find common ground, a measure of respect for one another, and a willingness to work together to benefit the project. Here are four ways to approach the problem. Start talking Resist the urge to wait for the perfect time to address team conflict. There’s no such thing. There will always be another deadline, another rollout, another challenge to be met. In our office, a UX designer and product manager were having trouble getting along. Rather than take responsibility, they each blamed our “process” and said we needed to clarify roles and procedures. In other words, they each wanted to be deemed “in charge” of the project. Certainly I could have taken that bullet and begun a full-on assessment of our processes and structure. By taking the blame for a bad company framework, I could have dodged some difficult conversations.  But I knew our process wasn’t the problem. First, I coached the product manager to be vulnerable, not an easy thing for him to do. I asked him to share his concerns and his desire to have a more productive relationship with the UX designer. The PM’s willingness to be uncomfortable and open about his concerns lifted the tension. Once he acknowledged the elephant in the room–namely that the UX designer was not happy working with him–the designer became more willing to risk being honest. Eventually, they were able to find a solution to their disagreements on the project, largely because they were willing to give each other a measure of respect. The worst thing I’ve seen is when leaders move people from team to team hoping that they will magically find a group of people that work well together, and work well with them. Sometimes the relocated team members have no idea that their behavior or performance isn’t acceptable. Instead of solving the problem, this just spreads the dissatisfaction. Instead, be clear right from the beginning that you want teams that will be open about challenges, feel safe discussing conflicts, and be accountable for solving them. Have a clear purpose I was working on an enterprise CMS re-design and re-platform. Our weekly review and estimation sessions were some of the most painful meetings of my career. There was no trust or shared purpose–even estimating a simple task was a big fight. When purpose and priorities are murky you are likely to find conflict. When the team doesn’t know what mountain they are trying to climb, they tend to focus on the parts of the project that are most relevant to them. With each team member jealously guarding his or her little ledge, it’s almost impossible to have cooperation. This assault on productivity is likely because the project objective is non-existent, or muddled nonsense, or so broad the team doesn’t see how it can have an impact. Or, maybe the objective is a moving target, constantly shifting. Size can be a factor.  I’ve seen enterprise teams with clear missions and startups with such world-changing objectives they can’t figure out how to ship something that costs less than a million dollars. When I’m meeting with prospects or new clients I look at three areas to see if they are having this problem: What language do they use to describe each other? Disconnected teams say “UX thinks,” “The dev team” or “product wants.” Unified teams say  How easy or hard is task estimation? Disconnected teams fight about the level of difficulty. United teams talk about tradeoffs and argue about what’s best for the product or customers. Can they easily and consistently describe their purpose? Disconnected teams don’t have a crisp and consistent answer. Unified teams nod their heads when one of their members  shares a concise  answer. If a team is disconnected, it’s likely because you haven’t given them a common goal. A single email or a fancy deck isn’t enough. Make your objectives simple and repeat them so much that the team groans every time you start. Plan conversations Years ago I was frustrated to tears by a manager who, I felt, took from me the product I spent two years building. I knew I needed to talk with him but I struggled to find a productive way to tell him why I was upset.  (Telling someone he is being a jackass is not productive.) A good friend in HR helped me script the conversation. It had three parts: I really work well when… This situation is bothering me because… What I’d like to see happen is… Leaders have an important role to play in resolving issues. When a leader decides that their person is right and another person is wrong it turns a team problem into an organization problem. Instead we should should provide perspective, context and show how actions could be misunderstood. Leaders also need to quickly, clearly and strongly call about bad behavior. When I found out one of my people raised their voice at a colleague, I made it clear that wasn’t acceptable and shouldn’t happen again. He admitted that he lost his cool, apologized and then we started working on the resolving the situation. Require accountability If you have a problem and you go to Holly Paul, an inspiring HR leader, you can expect that she will listen. You can also expect that she’ll work with you on a plan to resolve it. Most importantly  you can expect she will make sure you are doing what you said you’d do when you said you would do it. Before I met Holly I would listen to problems then try to go solve them. Now I work with the person and tell them that I will be checking back with them, often putting the reminder in my calendar during the conversation so I don’t forget. Since I started focusing on fixing conflict, I’ve seen great changes on my team. Many of them have started for the first time dealing with the people, fixing their issues and forging much stronger relationships. Our team is stronger and having a greater influence on the organization. It’s messy, awkward and hard. I’ve been working on this for a long time and I still make mistakes. I still don’t always want to push when I meet resistance. This will never be easy, but it will be worth it and it’s your responsibility as a leader. For however long these people are with you, you need to make them better as individuals and a unit. You don’t need a big training, a touchy-feely retreat or an expensive consultant. You just need to start doing the work  . The rest will come. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/practical-user-research-creating-a-culture/", "title": "Practical User Research: Creating a Culture of Learning in Large Organizations", "content": "Enterprise companies are realizing that understanding customer needs and motivations is critical in today’s marketplace. Building and sustaining new user research programs to collect these insights can be a major struggle, however. Digital teams often feel thwarted by large organizations that are slow to change and have many competing priorities for financial investments.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. As a design consultant at  , I’ve seen companies at wildly different stages of maturity related to how customer research impacts their digital work. Sometimes executives struggle to understand the value without quantifiable numbers. Other times engineering teams see customer research and usability testing as a threat to delivery dates.  While you can’t always tackle these issues directly, the great thing about large organizations is that they’re brimming with people, tools, and work practices forming an overall culture. By understanding and utilizing each of these organizational resources, digital teams can create an environment focused on learning from customers. I did some work recently for a client I’ll call WorkTech, who had this same struggle aligning their digital projects with the needs of their customers. WorkTech was attempting to redesign their entire ecommerce experience with a lean budget and team. In a roughly six month engagement, two of us from Cantina were tasked with getting the project back on track with a user-centered design approach. We had to work fast and start bringing customer insights to bear while moving the project forward. Employing a pragmatic approach that looked at people, tools, and work practices with a fresh set of eyes helped us create an environment of user research that better aligned the redesign with the needs of WorkTech’s customers. Get comfortable talking to   in different roles Effective user research programs start and end with people. Recognizing relationships and the motivations held by everyone interacting with a product or service encourages goodwill and can unearth key connections and other, less tangible benefits. To create and sustain a culture of learning in your company, find a group of users to interview—get creative, if you have to—and enlist the support of teammates and stakeholders.  Begin by taking stock of anyone connected to your product. You won’t always find a true set of end users internally, but everyone can help raise awareness of the value of user research—and they can help your team sustain forward progress. Ask yourself the following questions to find allies and research resources: What departments use your product indirectly, but have connections to people in the user roles you’re targeting? Is there a project sponsor who can help sell the value of research and connect you to additional staff that can assist in some capacity? Are there employees in other departments whose individual goals align with getting better feedback from users? Are there departments within the organization (sales, customer service) who can offer connections to customers wanting to provide candid feedback? Our WorkTech project didn’t have a formal research budget for recruiting users (or any other research task). What we did have going for us was a group of internal users who gave our team immediate access to an initial pool of research participants. The primary platform we were hired to help redesign was used by two groups: WorkTech employees and the customers they interacted with. Over time, our internal users were able to connect us with their external counterparts, amplifying the number of people offering feedback significantly.  Maximize the value of every interview While interviewing external customers, we kept an eye on the long term success of our research program and concluded each session by asking participants: If they’d be willing to join another session in the future (most were willing) If they could share names of anyone else in their network (internal or external) they thought would have feedback to offer During each conversation, we also identified distinct areas of expertise for each user. This allowed us to better target future usability testing sessions on specific pieces of functionality.  Using this approach, our pool of potential participants grew exponentially and we gained insight into the shared motivations of different user personas. Taking stock of such different groups of people using the platform also revealed opportunities that helped us prioritize different aspects of the overall redesign effort. Find helpful   that are already available or free Tools can’t create an effective user research program on their own, but they are hugely helpful during the actual execution of research. While some organizations have an appetite for purchasing dedicated “user research” platforms able to handle recruitment, scheduling, and session recordings, many others already have tools in place that bring value to the organization in different areas. If your budget is tiny (or nonexistent), you may be able to repurpose or extend the software and applications your company already uses in a way that can support talking to customers.  Consider the following: Are there current tools available in the organization (perhaps in other groups) that could be adapted for research purposes? Are users already familiar with any tools or workflows you can utilize during research activities? If new tools for automating specific tasks are out of budget, can your team build up repeatable templates and processes manually? We discovered early on at WorkTech that our internal user base had very similar toolsets because of company-wide technology purchases. Virtually all employees already had   installed and were familiar with remote conferencing and sharing their screen.  WorkTech offices and customers were spread across the continental United States, so it made sense for our sessions to be remote, moderated conversations via phone and teleconference. Using Webex allowed the internal users to focus on the actual interview, avoiding the friction they might have felt attempting to use new technology.  Leveraging pre-existing tools also meant we could expand our capabilities without incurring significant new costs. (The only other tool we introduced was a free   account, which allowed us to create simple prototypes of new UI concepts, conduct weekly usability tests, and document and share our findings quickly and easily.)  Document and define templates as you go Many digital research tools are simply well-defined starting points—templates for the various types of communication and idea capture needed. If purchasing access to these automated tools is out of the question, using a little elbow grease can be equally effective over time. At WorkTech, maintaining good documentation trails minimized the time spent creating new materials for each round of research and testing. For repeatable tasks like creating scripts and writing recruitment emails, we simply saved and organized each document as we created it. This allowed us to build a library of reusable templates over time. Even though it was a bit of a manual effort, this payoff increased with every additional round of usability testing.  Utilizing available tools eliminates another significant hurdle to getting started—time delays. In large organizations with tight purchase protocols, using repurposed and free tools can enable teams to get moving quickly. Filling in the remaining gaps with good documentation and repeatable templates covers a wide range of scenarios and doesn’t let finances act as a blocker when collecting insights from users.   Take a fresh look at your company’s  A culture of learning won’t be sustainable over the long term if the lessons learned from user research aren’t informing what is being built. Bringing research insights to bear on your product or site is where everything pays off, ensuring digital teams can focus on what delivers the highest value to customers.  Being successful here requires a keen understanding of the common processes your organization uses to get things accomplished. By being aware of an organization’s current work practices (not some utopian version), digital teams can align what they’ve learned with practices that help ensure solutions get shipped. Dig into the work practices in your organization and identify ways to meet people where they are: Are there centrally-located workspaces that can be used for posting insights and keeping research outcomes in front of the team? Are there any regularly-scheduled meetings with diverse teams that would be an opportunity to present research findings? Are there established sprint cycles or product management reviews you can align with research efforts? The WorkTech team collaborating with us on the project already had weekly meetings on the calendar, with an open agenda for high priority items. Knowing it would be important to get buy-in from this group, we set up our research and usability sessions each week on Tuesdays. This allowed us to establish a cadence where every Tuesday we tested prototypes, and every Wednesday we presented findings at the WorkTech team meeting. As new questions or design concepts to validate came up, the team was able to document them, pause any further debates, and move on to other topics of discussion. Everyone knew testing was a weekly occurrence, and within a few weeks even the most skeptical developer started asking us to get customer feedback on specific features they were struggling with. Schedule regular customer sessions even before you are “ready” Committing to a cadence of regular weekly sessions also allowed us to separate scheduling from test prep tasks. We didn’t wait to schedule sessions only when we desperately needed feedback. Because the time was already set aside each Tuesday, we simply had to develop questions and tests for the highest priority topic at that point in time. If something wasn’t quite ready, the next set of sessions was only a week away. Using these principles, we conducted 40+ sessions over the course of 12 weeks, gathering valuable insights from the two primary user groups. We were able to gather quantifiable data pointing to one design pattern over another, which minimized design debates and instilled confidence in the research program and the design. In addition to building relationships with users across the spectrum, the sessions helped us uncover several key interface issues that we were then able to design around.  Even more valuable than the interface issues were general uses cases that came to light, where the website experience was only one component in a large ecosystem of internal processes at customers’ organizations. These insights proved valuable for our redesign project, but also provided a deeper understanding of WorkTech’s customer base, helping to prove the value of research efforts to key stakeholders. Knowing the schedules and team norms in your organization is critical for creating a user research program whose insights get integrated into the design and development process. The insights of a single set of sessions are important, but creating a culture surrounding user research is more valuable to the long term success of your product or site, as is a mindset of ongoing empathy toward users. To help grow and sustain a culture of research, though, teams have to be able to prove the value in financial terms. Paul Boag said it elegantly in the third  : “Because cost is (often a) primary reason for not testing, money has to be part of your justification for testing.”  The long term success of your program will likely be tied to how well you can prove its ROI in business terms, even though the methods described here minimize the need to ask for money. In other words, translate the value of user research to terms any business person can understand. Find ways to quantify the work hours currently lost to feature debates and building un-validated features, and you’ll uncover business costs that can be eliminated. User research doesn’t have to be a big dollar, corporate initiative. By paying attention to the people, tools, and work practices within an organization, your team can demonstrate the value of user research on the ground, which will open doors to additional resources in the future. Like this:"},
{"url": "https://alistapart.com/article/integrating-animation-into-a-design-system/", "title": "Integrating Animation into a Design System", "content": "Keeping animation choreography cohesive from the outset of a project can be challenging, especially for small companies. Without a dedicated motion specialist on the team, it can be difficult to prioritize guidelines and patterns early in the design process. What’s more likely to happen is that animations will be added as the product develops. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Unsurprisingly, the ad-hoc approach can lead to inconsistencies, duplications, and rework in the long run. But it also provides space for creative explorations and discoveries of what works and what doesn’t. As useful as it is to be able to establish system foundations early, it is also ok to let the patterns emerge organically as your team experiments and finds their own voice in motion. Once there are enough animations, you might start thinking about how to ensure some consistency, and how to reuse existing patterns rather than recreate them from scratch every time. How do you transition a few odd animations to a cohesive system? I find it helpful to start by thinking about the   of animations and the   they’re designed to evoke. Start with purpose and feel Purpose Like any other element in a design system, animations must have a purpose. To integrate animation, start by looking through your interface and noting   and   you use animations in your particular product and brand. For example, at   we noticed that we primarily use animation in three ways—to indicate a state change, to add an emphasis, or to reveal extra information: A   shows that an object has changed state due to user interaction. For example, a state can change on hover or on click. Animation here is used to soften the transition between states.  animations are used to draw attention to specific information or an action, for example a nudge to encourage users to progress to the next step in the course.  animations are used to hide and reveal extra information, such as a menu being hidden to the side, a drop down, or a popover. There are no “standard” categories for the purposes of animations. Some products use a lot of standalone animations, such as animated tutorials. Some use screen transitions, others don’t. Some make personality and brand part of every animation, others group them into their own category, like in the  . The categories are specific to your interface and brand, and to how you use animation. They shouldn’t be prescriptive. Their main value is to articulate why your team should use animation, in your specific project. Feel As well as having a purpose in helping the user understand how the product works, animation also helps to express brand personality. So another aspect to consider is how animation should  . In “ ,” Val Head explains how adjectives describing brand qualities can be used for defining motion. For example, a quick soft bouncy motion can be perceived as lively and energetic, whereas steady ease-in-outs feel certain and decisive. As you look through the animation examples in your interface, list how the animation should feel, and note particularly effective examples. For example, take a look at the two animations below. While they’re both animating the entrance and exit of a popover, the animations feel different. The Marvel example on the left feels brisk through the use of bouncy easing, whereas the small movement combined with opacity and blur changes in the FutureLearn example on the right make it feel calm and subtle. There’s probably no right and wrong way to animate a popover. As far as I know it all depends on your brand and how you choose to communicate through motion. In your interface you might begin to notice animations that have the same purpose but have entirely different feels. Take note of the ones that feel right for your brand, so that you can align the other animations to them later on. Audit existing animations Once you have a rough idea of the role animation plays in your interface and how it should feel, the next step is to standardize existing animations. Like an  , you can conduct an inventory focused specifically on animations. Start by collecting all the existing animations. They can be captured with QuickTime or another screen recording application. At the same time, keep a record of them in a Google Doc, Keynote, or an Excel file—whatever suits you. Based on the purpose you defined earlier, enter categories, and then add the animations to the categories as you go. As you go through the audit, you might adjust those categories or add new ones, but it can be helpful not having to start with a blank page. For each animation add:  The effect might be difficult to describe at first (Should it be “grow” or “scale,” “wiggle” or “jiggle”?). Don’t worry about the right words yet, just describe what you see–you can refine that later.  This could be a screenshot of the animated element with a link to a video clip, or an embedded gif.  Write down the values for each example, such as 2 seconds ease.  Write down the exact values that change, such as color or size.  Finally, add the feel of the animation—is it calm or energetic, sophisticated and balanced, or surprising and playful? After the inventory of animations at FutureLearn, we ended up with a document with about 22 animations, grouped into four categories. Here’s the state change category. Define patterns of usage Once you’ve collected all the animations, you can define   of usage, based on the purpose and feel. For example, you might notice that your emphasis animations typically feel energetic and playful, and that your state change transitions are more subtle and calm. If these are the tones you want to strike throughout the system, try aligning all the animations to them. To do that, take the examples that work well (i.e. achieve the purpose effectively and have the right feel) and try out their properties with other animations from the same category. You’ll end with a handful of patterns. Develop vocabulary to describe effects Animation effects can be hard to capture in words. As Rachel Nabors noted in “ ,” sometimes people would start with “friendly onomatopoeias:  ,” which can be used as a starting point to construct shared animation vocabularies. Some effects are common and can be named after the classic animation principles (squash and stretch, anticipation, follow through, slow in and out ) or can even be borrowed from Keynote (fade in, flip, slide down, etc.), others will be specific to your product. There might also be animation effects unique to your brand that would require a distinctive name. For example, TED’s “ripple” animation in the play button is named after the ripple effect of their intro videos. Specify building blocks For designers and developers, it is useful to specify the precise building blocks that they can mix and match to create the new animations. Once you have the patterns and effects, you can extract precise values—timing, easing, and properties—and turn them into palettes. The animation palettes are similar to color swatches or a typographic scale. Timing Timing is crucial in animation. Getting the timing right is not so much about perfect technical consistency as making sure that the timing   consistent. Two elements animated with the same speed can feel completely different if they are different sizes or travel different distances. The idea of “dynamic duration” in   focuses on how fast something needs to move versus how long it should take to get there: Rather than using a single duration for all animations, adjust each duration to accommodate the distance travelled, an element’s velocity, and surface changes. , the author of  ,   that we should deal with timing in animation like we deal with headings in typography. Instead of having a single value, you’d start with a “base” and provide several incremental steps. So instead of  ,   and  , you’d have  ,  ,  . Depending on the scale of the project, the timing palette might be simple, or it might be more elaborate. Most of the animations on FutureLearn use a base timing of 0.4. If this timing doesn’t feel right, most likely your object is traveling a shorter distance (in which case use “Shorter time”) or a longer distance (in which case use “Longer time”).  Shorter travel distance  Base timing  Longer distance traveled Similar ideas used in the duration guidelines for the   are related to the “magnitude of change”: Easing Different easing values can give an animation a distinctive feel. It’s important to specify when to use each value. The easing palettes in the   provide a handy guide for when to use each value, e.g. “Springy feel. Good for drawing focus.” An easing palette can also be more generic and be written as a set of guidelines, as done in the Salesforce Lightning Design System, for example: For FutureLearn, we kept it even more simple and just limited it to two types of easing:   “for things that move” (such as scale changes and slide up/down) and   “for things that don’t move” (such as color or opacity change). Properties In addition to timing and easing values, it is useful to specify the properties that typically change in your animations, such as: Opacity Color Scale Distance Rotation Blur Elevation Again, you can specify those properties as palettes with a base number, and the incremental steps to support various use cases. For example, when specifying scaling animations at FutureLearn, we noticed that the smaller an object is, the more it needs to scale in proportion to its size, for the change to be visible. A palette for scaling objects reflects that: \nLarge objects \n \nMedium objects \n \nSmall objects \n Although there’s no perfect precision to how these properties are set up, they provide a starting point for the team and help us reduce inconsistencies in our motion language. Agree on the guiding principles If you have guiding principles, it’s easier to point to them when something doesn’t fit. Some of the principles may be specific to how your team approaches animation. For example, If your team is not yet confident with animation, it may be worth including some of the more general principles, such as “reserve it for the most important moments of the interaction” and “don’t let it get in the way of completing a task.” The guiding principles section can also include rationale for using animation in your product, and the general feel of your animation and how it connects with your brand. For example,   uses the physical movement of machines to extract the qualities they want to convey through animations, such as precision and accuracy. From the powerful strike of a printing arm to the smooth slide of a typewriter carriage, each machine movement serves a purpose and every function responded to a need. In IBM’s Design Language, the rhythmic oscillation of tape reels in motion is used in a metaphorical way to support user’s waiting experience. Guiding principles can also include spatial metaphors, which can provide a helpful mental model to people trying to create animations.   is a great example of how thinking of interface as physical “materials” can provide a common reference for designers and developers when thinking about motion in their applications. To sum up When integrating animation in design systems, try viewing it in relation to three things:  ,  , and  . Guiding principles provide general direction, patterns of usage specify when and how to apply the effects, and building blocks aid the creation of new animations. Even if your animations were initially created without a plan, bringing them together in a cohesive, documented system can help you update and build on what you have in an intentional and brand-supporting way. Further reading: \n \n \n \n Like this: \n\t\t\t\t\t\t\tRecently by Alla Kholmatova\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/user-interfaces-for-variable-fonts/", "title": "User Interfaces for Variable Fonts", "content": "The tools we design with have a unique effect on the way we work, constraining and empowering us while we explore, examine and create. Variable fonts give us a new, wide open typographic space with which to work. Instead of prescribing value to individual UI elements in a vacuum, we should take a hybrid and calculated approach to variable font interfaces. How do we structure our design tools to adapt to the new advantages variable fonts provide us with?  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Despite being ahead of their time, variable font precursors—Multiple Master and GX—didn’t see widespread adoption for  —one key reason being the lack of effective user interfaces that could communicate their creative utility to designers.  Since their  ,   have moved forward quickly, landing with various degrees of   across major browsers. With this comes the exciting ability for fonts to responsively adapt to different layouts and  . While   has become more standard, effective variable font user interfaces have yet to be adopted. A number of approaches can make variable fonts (which can house effectively any number of variations) easier to understand and use. Through design exploration and looking at prexisting examples we can see how each UI element has different benefits and drawbacks. We find that few patterns should be applied to every case.  Enabling Variable Fonts Within our design tools, variable fonts present a unique challenge, allowing users to select and change different properties of the typeface that are exposed by the typeface designer. These changes occur along an   axis—or a line that reflects variation values of a font: A variable font can have any number of axes, but these can generally be reduced down to a few commonly used axes mostly likely to be used for Responsive Design. These default axes are called   in the spec. Each one has a different set of use cases: Font Weight –  : For adapting font weight to the container size, the weight of other elements, changes to hierarchy and screen resolution Font Width –  : For fitting the width of the typeface to the width of a container Font Italicization –  : For changing how italicised the type is Font Slant –  : For changing how   the type is Font   –  : For adapting to container size, font size and adjusting hierarchy and typographic color These axes take advantage of much of the layout-based adaption variable fonts provide. Some of these concepts are best illustrated in     project: Along with some of the amazingly beautiful   to date: In these examples, the   optical size, weight and width shift at the same time as you resize the window. While a large portion of variable font axes directly correlate to layout, any number of arbitrary, non registered axes can also be created by the type designer. These can be for any type of change to the typeface in addition to interacting with the layout.     ornamental typeface is an example of this at one extreme.  Decovar sports a wide number of settings for adjusting the font’s decorative   and skeleton of the font. The limit here is the type designer’s imagination. New Spaces Variable fonts carry with them a   and can open up entire   of creative options to type, graphic and web designers. These aren’t human readable at first—they exist as  mathematical representations. However, there are proposed approaches to help us visualize and manipulate variable fonts. By exploring user interface patterns, we can better understand how to illuminate the exciting spaces within a variable font. At its foundation, this involves making variable fonts aware of their context.  Mapping UI: Context Before looking at UI, it’s worth noting that variable font axes can be directly linked to a wide range of inputs. These can be any combination of   to   and  . Certain registered axes however, make the most sense for responsive design and HTML/CSS/JS. A font’s width and weight axes are directly related to the container a set line of type can fit into. Variable fonts are able to adapt to the size of their containers—either filling them completely or at a specific set proportion. A progression of work over the years has led to fonts adapting to fit their container.     and     were early examples of scaling text to fit a responsive container.   and     swapped the width and weight version of the actual font to adapt to the container. Much of Erik Van Blokland’s previous work and   project crystalized the idea of interpolation for adjusting type to width, height and optical variations within responsive design.     links weight and width to the size of the container itself, allowing people manipulate the textbox instead of the type directly. All these strategies point to type set in relation to its container. Optical size variations can also be linked to font size, allowing important characteristics to shine at display sizes while minimizing details to ensure the font remains robust at small sizes. In 2013, Nick (with  ,  , and  ) showcased this   in Adobe InDesign. This functionality outlined in inDesign is now available for variable fonts, allowing   with a user’s font size. Through techniques like these variable fonts can to adhere to layout / container dimensions, font size, and user context. Often times however, a font itself needs to drive design and layout (in the case of most design tools like Sketch and Illustrator). In this case, we need UI to directly control the variable font. Interfaces rely on   to communicate to people how they work. UI and UX patterns carry a variety of assumptions people have built up over the years by interacting with similar controls—both physical and digital. We can break down some of these patterns and look at their advantages and disadvantages. Mapping UI: Single Axis Controls Single axis variable fonts are the most straightforward and only require one control. Toggles, sliders and knobs are all well suited for handling single axes. The most elemental of these—toggles, can be used to limit options for the sake of clarity. Toggles Toggles denote   or  : A toggle’s simplicity can reduce choices to options people care about—like toggling serifs on or off (where intermediate values are less important). Single toggle based selection menus have existed since the earliest desktop publishing interfaces. Knobs Typically knobs communicate   to a whole. Knobs are less common in digital interfaces but can be found in software plugins for  . Knobs have the advantage of being compact while having a longer control surface to house values in a given square area. Another interesting property of knobs is that they can be periodic—allowing values to wrap entirely around the knob control.     introduced knobs as a method for controlling variable fonts. Because the visible control surface isn’t straight, digital knobs have more of a learning curve (pun intended). Most knob controls alleviate this by allowing people to brush up and down to rotate the knob after it’s active or has been selected. Unless they’re large enough, knobs can also be hard to use with touch interactions. Sliders Typically horizontal sliders communicate  . Horizontal sliders are a common UI pattern across the   and  . iOS makes frequent use of this interface element: Digital sliders have the advantage of working similarly to the way   do and are easy to learn. Sliders map well to a range of two different values on opposite ends of a spectrum—users just pick a middle value. Because of this, sliders are intuitive for both touch and mouse controls—actions happen in a single, linear motion. Typically vertical sliders communicate  . Vertical sliders are typically seen in   where it’s most important to horizontally scan and compare the levels of neighboring controls. Most digital audio workstations use them for volume levels. Overall, sliders take up more space, but provide a clear and precise method for picking a specific value. Any UI element can be overused (sliders and knobs alike) and misapplied. Ultimately, application of single axis controls should be considerate of the design tool and variable font itself. One key consideration is how the interface scales to account for additional font axes. Slider interfaces have an advantage in this category by being able to unfold naturally to support a two-axis control pattern. Mapping UI: 2-Axis Controls It’s common for variable fonts to have two or more axes. In these cases, a two-axis pattern can work best to avoid an overload of UI elements and give a designer better visibility. Pads Pads typically communicate  .   allow people to adjust two variable font axes at the same time. This pattern has been used in both audio hardware and software to control parameters along an X and Y axis. Control pads are less common in digital interfaces but hold familiarity through analogous design tool patterns like color pickers, which also provide people with a field of options. X/Y control pads help reveal a larger portion of a font’s design space. They lack the directness of sliders and knobs, but provide a way for people to easily traverse through combinations of font variations. The utility of having each axis map to a single control or direction quickly diminishes as the number of axes increases. At this point, we find effectiveness shift from manipulation to visualization. Mapping UI: Multi Axis Controls and Visualizations Fonts with three or more axes (variable fonts can have virtually any number of axes) are best served with different control and visualization approaches. Each axis can be represented mathematically as a feature or dimension. Fonts with a single axis map to a slider or knob while two axis fonts can take advantage of a pad UI. Three axis variable fonts can have their axes  . At  , things shift away from UI towards more of a visualization approach, as effective digital omnidirectional controls are rare. Three and up, or   font designspaces aren’t intuitive when mapped to physical space, so the best way think of them is as the amount of ingredients in a recipe. Take a   for example: 1 cup white sugar 1/2 cup butter 2 eggs 2 teaspoons vanilla extract 1 1/2 cups all-purpose flour 1 3/4 teaspoons baking powder 1/2 cup milk Each one of these ingredients represents a different feature of the cake. When combined with heat, they work together to create the final cake. Variable font axes or features work the same way: 100% Font Width 25% Font Weight 5% Font Optical Size 10% Font Serifs 75% Font X-Height People can adjust the axis postion (or amount of each ingredient) of a variable font, all of which have an effect on the final appearance of the typeface. Certain axes, like font width and stroke contrast may work together in parallel, while others, like x-height and font width may be more independent from each other.  Designing type with +3 Variations At a certain level of complexity—a design tool’s focus should shift to serve more technical users. Type designers have their own category of challenges as they design, proof and test their fonts with intricate design spaces. Some variable fonts may have axes that are not exposed to users. There are other strategies for visualizing complex variable fonts like these. For this, we can look at the  —a topic that has already been widely studied. There’s a broad range of existing strategies, some of which can be applied to variable fonts. The following   divides these strategies into several categories: Geometric projection techniques Icon-based techniques Pixel-oriented techniques Hierarchical techniques Hybrid techniques By flattening axes, designers can see many aspects of a variable font at once. Star plots—an icon based technique—allow for the combination of multiple axes into a single chart.  Each axis extends from the center, with the sum total of a given variable font’s current settings making up the polygon shape. Other font instances can also be layered on top of the visualization with the abstraction of color.  Layers allow us to view the relationships between variable font instances. We can see how certain variable properties might be correlated with each other in a design space and between masters. Similar approaches, like  , are better structured to show relationships between axes.    on visualizing multiple dimensions with parallel coordinates provides a great primer on assigning data’s dimensions to visual properties and charts. Other approaches like   group things based off arbitrary features. These methods help us make sense of large sets of information with lots of related variables. Ultimately, they work by limiting our field of view and changing the angle through which we look at a set of variations. Instead of trying to see everything at once, we can break things down into manageable slices. Good interface controls allow us to quickly change our viewing perspective and organize axes. This UI is just as important as the visualizations themselves. Mapping Controls Variable font UI is most effective when it adapts along with the font. Thus, the more information a variable font can provide to the design program the better. Axes that are similar can be grouped together and collapsed under categories in the UI (for example, grouping axes that deal with serifs vs. font weight). Currently, there are discussions around allowing certain axes to be   (and ideally ordered and grouped) in order to intelligently reveal and hide advanced functionality through   within a design app.  What axes are revealed and how they’re categorized come down to a combination of the type designer’s intent and the user’s personal preferences. Both of these are relative but important. Web designers / developers may want certain types of axes for adapting the font to their responsive design. Type designers may want to limit the number of available axes to ensure consistency or simplify licensing. In other cases, graphic designers may want access to powerful, creative variable fonts with a large number of axes (for example matching stroke weight and serifs to the thickness of other graphic elements). Because of this, variable font UI needs smart defaults that responsibly translate the type designer’s intention while retaining ability for designers to make modifications. In this line of thinking, every axis does not need to map 1:1 to a corresponding control. Multiple variable font axes can be assigned to a single macro control. On the font/type designer’s side, this would take the form as  . On the interface size, this would take the form of assignable macro controls.  Macro controls are a common UI pattern in software synthesizer interfaces—they allow  multiple parameters to be mapped to any combination of controls. Mappable controls allow people to break up and organize a design space to fit their needs. In addition to giving users the ability to sort and power multiple controls, this method can help people discover relationships between axes. In this example, changing the font weight and optical size at the same time allow you to see and select the right balance of the two.  While the axes themselves are independent of each other, the visual outcomes they produce are intertwined. Font weight and optical size are both related to each other and should be considered simultaneously when designing. This swapping of axes is comparable to   (see the reordering section) in the parallel coordinate charts mentioned earlier. In both cases, the interface can provide a smart, opinionated organization and flexibly surface new combinations. Dynamic interfaces for dynamic fonts Interfaces for variable fonts should adapt along with the fonts themselves.  There’s no single static UI pattern that will work as the best solution for all variable fonts. Instead of debating sliders and knobs, we should be exploring hybrid interfaces that take advantage of what each UI element has to offer. Likewise, UI should be considered in the context of our design tools with the acknowledgement that it will  , influencing our choices. This gives us a unique opportunity to further typographic creativity and utility. Like this: \n\t\t\t\t\t\t\tRecently by Andrew Johnson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-ten-essentials-for-good-api-documentation/", "title": "The Ten Essentials for Good API Documentation", "content": "API documentation is the number one reference for anyone implementing your API, and it can profoundly influence the developer experience. Because it describes what services an application programming interface offers and how to use those services, your  documentation will inevitably create an impression about your product—for better or for worse.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. In this two-part series I share what I’ve learned about API documentation. This part discusses the basics to help you create good API docs, while in part two, Ten Extras for Great API Documentation, I’ll show you additional ways to improve and fine-tune your documentation.   Know your audience Knowing who you address with your writing and how you can best support them will help you make decisions about the design, structure, and language of your docs. You will have to know who visits your API documentation and what they want to use it for.   Your API documentation will probably be visited and used by the following audiences.   Developers Based on their skills, experience, and role in projects, developers will generally be the largest and most diverse group. They’ll be using your docs in different ways.  At Pronovix, we started conducting developer portal workshops with our clients to help them learn more about what developers need and how to best support their work—and what they’re really looking for in API documentation. This is also supported by solid research, such as the findings published in   following a two-year research program at Merseburg University of Applied Sciences.  Developers lacking previous experience with your API tend to need the most support. They will take advantage of quickstart guides that encourage them to start using your API—clear, concise, step-by-step tutorials for the most important topics, and sample code and examples to help them understand how to use it in real projects. If you can make onboarding pleasant for newcomers, they will be more likely to devote themselves to learning every nuance of your API.   Developers already working with your API will come back repeatedly to your docs and use them as reference material. They will need quick information on all the functionality your API offers, structured in an easy to understand way to help them quickly find what they need.   Developers using your API will encounter errors from time to time and use your documentation to analyze the responses and errors that crop up.   API providers tend to focus so much on their external audience that they forget about their own developers; internal teams working on the API will use the API documentation, as well.  These are just the most common use cases.  Decision makers Decision makers like   and   will also check out your API documentation and evaluate your API. They need to determine  whether your API will be a good fit for their project or not, so it’s crucial to your business that this group can easily and quickly find what they’re looking for.  Other audiences Although not as common, journalists, technical writers, support staff, developer evangelists, and even your competition might read your API documentation.    Remember the purpose of documentation The foundation of your API documentation is a  . As a bare minimum, you should describe in detail: what each call in your API does each parameter and all of their possible values, including their types, formatting, rules, and whether or not they are required. Context-based structure People won’t read your API documentation in order, and you can’t predict which part they will land on. This means, you have to provide all the information they need in context. So following the best practices of topic-based authoring, you should include all necessary and related information in the explanation of each call.  , for example, did a great job documenting each of their API calls separately with detailed information on parameters and their possible values, along with useful tips and links to related topics. Examples In order to be able to implement your API, developers need to understand it along with the domain it refers to (e.g., ecommerce). Real world examples reduce the time they need to get familiar with your product, and provide domain knowledge at the same time.  Add the following to the description of each call: an example of how the call is made an explanation of the request sample responses Studies have shown, that  , when getting to know a new API; they start working from an example. Analysis of eye-tracking records showed that visual elements, like example code, caught the attention of developers who were scanning the page, rather than reading it line by line.  Many looked at code samples before they started reading the descriptions. Using the right examples is a surefire way to improving your API docs. I’ll explore ways to turn good API docs into great ones using examples in my upcoming post “Ten Extras for Great API Documentation”.  Error messages When something goes wrong during development, fixing the problem without detailed documentation can become a frustrating and time-consuming process. To make this process as smooth as possible, error messages should help developers understand: what the problem is; whether the error stems from their code or from the use of the API; and how to fix the problem. All possible errors—including edge cases—should be documented with error-codes or brief, human-readable information in error messages. Error messages should not only contain information related to that specific call, but also address universal topics like authentication or HTTP requests and other conditions not controlled by the API (like request timeout or unknown server error).  This   discusses best practices for server-side error handling and communication, such as returning an HTTP status code that closely matches the error condition, human-readable error messages, and machine-readable error codes. Quickstart guide Newcomers starting to implement your API face many obstacles: They are at the beginning of a steep learning curve They might not be familiar with the structure, domain, and ideas behind your API It’s difficult for them to figure out where to start. If you don’t make the learning process easier for them, they can feel overwhelmed and refrain from delving into your API.    Many developers learn best by doing, so a quickstart guide is a great option. The guide should be short and simple, aimed at newcomers, and list the minimum number of steps required to complete a meaningful task (e.g., downloading the SDK and saving one object to the platform). Quickstart guides usually have to include information about the domain and introduce domain-related expressions and methods in more detail. It’s safest to assume that the developer has never before heard of your service.   and   quickstart guides are great examples; both provide an overview of the most likely tasks you’ll want to perform with the API, as well as link you to the relevant information. They also contain links to contact someone if you need help. Tutorials Tutorials are step-by-step walkthroughs covering specific functionality developers can implement with your API, like SMS notifications, account verification, etc. Tutorials for APIs should follow the best practices for writing any kind of step-by-step help. Each step should contain all the information needed at that point—and  . This way users can focus on the task at hand and won’t be overloaded with information they don’t need.  The description of steps should be easy to follow and concise. Clarity and brevity support the learning process, and are a best practice for all kinds of documentation. Avoid jargon, if possible; users will be learning domain-related language and new technology, and jargon can instill confusion. Help them by making all descriptions as easy to understand as possible.   The walkthrough should be the smallest possible chunk that lets the user finish a task. If a process is too complex, think about breaking it down into smaller chunks. This makes sure that users can get the help they need without going through steps they’re not interested in. Universal topics To implement your API, there are some larger topics that developers will need to know about, for example:  Handled differently by each type of API, authentication (e.g., OAuth) is often a complicated and error-prone process. Explain how to get credentials, how they are passed on to the server, and show how API keys work with sample code.  For now, error handling hasn’t been standardized, so you should help developers understand how your API passes back error information, why an error occurs, and how to fix it.  You may have to document HTTP-related information as well, like content types, status codes, and caching. Dedicate a separate section to explaining these topics, and link to this section from each related API call. This way you can make sure that developers clearly see how your API handles these topics and how API calls change behavior based on them.   Layout and navigation Layout and navigation are essential to user experience, and although there is no universal solution for all API docs, there are some best practices that help users interact with the material.  Dynamic layout Most good examples of API documentation use a dynamic layout as it makes navigation easier for users than static layouts when looking for specific topics in extensive documentation. Starting with a scalable dynamic layout will also make sure you can easily expand your docs, as needed.  Single page design If your API documentation isn’t huge, go with a single page design that lets users see the overall structure at first sight. Introduce the details from there. Long, single page docs also make it possible for readers to use the browser’s search functionality.  Persistent navigation Keep navigation visible at all times. Users don’t want to scroll looking for a navigation bar that disappeared.  Multi-column layout 2- or 3-column layouts have the navigation on the left and information and examples on the right. They make comprehension easier by showing endpoints and examples in context.  Syntax highlighter Improving the readability of samples with syntax highlighting makes the code easier to understand.  If you’d like to start experimenting with a layout for your docs, you might want to check out some  .  To learn about the pros and cons of different approaches to organizing your API docs in the context of developer portals,  . Editing All writing that you publish should go through an editing process. This is common sense for articles and other publications, but it’s just as essential for technical documentation.  The writers of your API docs should aim for   and  , confirm that all the necessary information is there, and that the structure is logical and topics aren’t diluted with unnecessary content.     Editors should proofread your documentation to catch grammar mistakes, errors, and any parts that might be hard to read or difficult to understand. They should also check the docs against your style guide for technical documentation and suggest changes, if needed.  Once a section of documentation is ready to be published, it’s a good idea to show it to people in your target audience, especially any developers who haven’t worked on the documentation themselves. They can catch inconsistencies and provide insight into what’s  missing.  Although the editing process can feel like a burden when you have to focus on so many other aspects of your API, a couple of iterations can make a huge difference in the final copy and the impression you make.  Keep it up-to-date If your API documentation is out of date, users will get frustrated by bumping into features that aren’t there anymore and new ones that lack documentation. This can quickly diminish the trust you established by putting so much work into your documentation in the first place.  When maintaining your API docs, you should keep an eye on the following aspects:  Remove documentation for deprecated features and explain why they were deprecated.  Document new features before launch, and make sure there’s enough time planned for the new content to go through the editorial process.  Useful feedback you get from support, or analytics should be reflected in your docs. Chances are you can’t make your docs perfect at the first try, but based on what users are saying, you can improve them continuously. For all this to work, you will have to build a workflow for maintaining your documentation. Think about checkpoints and processes for the above mentioned aspects, editing, and publication. It also helps if you can set up a routine for reviewing your docs regularly (e.g. quarterly).  Following these best practices, you can build a solid foundation for your API documentation that can be continuously improved upon as you gain more insight into how users interact with them. Stay tuned for part two, where I give you some tips on how to turn good API docs into amazing ones. Like this: \n\t\t\t\t\t\t\tRecently by Diana Lakatos\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/guerrilla-innovation/", "title": "Guerrilla Innovation", "content": "In a culture like Google’s, having paid time to innovate is celebrated. But most of us don’t work at Google; most of us work at places that are less than thrilled when someone has a bright new idea that will be  .  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. After all, who has time to try new things when the things we’re doing now aren’t broken? No one wants to be forced to use another app, to have yet another thing they are expected to log into, only to see it die out in six months.  So how do you push an idea through? How can you innovate if you work in a less-than-innovative place? It takes more than a big idea Let’s say you just saw a demo of someone using a prototyping tool like   and you’ve got this big vision of your team incorporating it into your development process. With a tool like this, you realize, you can quickly put some concepts together for a website and make it real enough to do user testing within two days! Seems pretty invaluable.  You create an account and start exploring. It’s pretty damn awesome. You put a demo together to share with your team at your next meeting.  Your excitement is completely drained within five minutes.  “Seems like a lot of extra work.” “Why would we create a prototype just to rewrite it all in code?” “Let’s just build it Drupal.” Knife. In. Heart.   can see the value in the product, but you didn’t take the necessary steps to frame the problem you want to solve. You didn’t actually use this exciting new tool to build a case around the value it will have for your company.  So right now, to your coworkers, this is just another shiny object. In the web development world, a new shiny object comes along every couple seconds. You need to do some legwork upfront to understand the difference between what shiny object is worth your team’s time and what is, well, just another shiny object.  Anyone can come up with an idea on the fly or think they’re having an  , but real innovation takes hours of work, trying and failing over and over, a serious amount of determination, and some stealth guerrilla tactics.  Frame the problem The first step in guerilla innovation is making sure you’re solving the right problem. Just because your idea genuinely is amazing doesn’t mean it will provide genuine value. If it doesn’t solve a tangible problem or provide some sort of tangible benefit, you have little or no chance of getting your team and your company to buy into your idea.  Coolness alone isn’t enough. And “cool” is always up for interpretation.  Framing the problem allows you to look at it from many different angles and see different solutions that may not have occurred to you. By diving deep into the impact and effects your idea will have, you will start to see the larger picture and may even decide your idea wasn’t so amazing after all. Or, this discovery could lead you to a different solution that truly is innovative and life-changing.  Start at the end When your idea is implemented and everything goes as planned, what benefit will it provide?  Make a list of people who would theoretically benefit from this idea. Write down who they are and how the idea would help them. Let’s go back to our prototyping tool example. Who would benefit from it the most? The end user looking for specific content on your website. Using a prototyping tool would allow you to do more user testing earlier in the process, letting you tweak and iterate your design based on feedback that could improve the overall site experience. An improved experience would, ideally, allow visitors to find the content they are looking for more easily; the content would therefore be more useful and usable for them.  If visitors have a better experience, that could result in a better conversion rate—which in turn would help your manager’s goals as web sales improve.  That benefit could extend to your team as a whole, too: a prototyping tool could improve communication between the marketing group and the development group. Using a prototyping tool would help quickly visualize ideas so that everyone can see how the site is evolving. Questions could be asked and addressed sooner. A prototyping tool could be just the thing you need to get everyone on the same page about content and identified goals.  Identify your target audience(s) The top two audiences with the potential to get the most benefit from your innovative idea are your target audiences. If the end user of the website will receive the most benefit, then that is your primary target audience. If your manager receives a benefit as a result, then that is your secondary target audience.  Take some time to develop a persona around each of your top target audiences. A   is a document that summarizes research trends and data that have been collected about a key audience segment. Although a persona depicts a single person, it should never be based on one real individual; rather, it’s an amalgam of characteristics from many people in the real world. A persona is usually one page and includes characteristics such as attitude, goals, skill level, occupation, and background. For more on developing personas to improve user experience, check out  . When you’re waist deep in this idea in the next six months and your coworkers are complaining about the extra workload, and you’re wondering why you ever decided to do this you will look at your white board where you have your personas displayed and you will remember they are your target audience, not you. All of this extra work is for their benefit.  As you implement a workflow using a prototyping tool and the decision gets made to only do only one round of user testing instead of the three rounds that were initially discussed, you can reference your personas and ask who stands to benefit from that decision. Are you just saving time for the developers and the stakeholders in an attempt to pump out websites faster? Or will this really benefit the target audience? Do a pre-postmortem Understanding the risks of innovation does not mean backing away from your idea and giving up. When you understand the obstacles in front of you, you can more easily identify them and develop solutions before potential failures take place.  One useful exercise is to do a postmortem report even before you begin. Start anticipating the reasons the tool or project will fail so you can avoid those pitfalls. Some questions you might ask in a postmortem: Who was involved in the project? What went well with the project? What did not go well? What can we do next time to improve our results? With our prototyping example, a possible reason for failure might be the team not adopting the tool and it never gaining traction. You need the team to be on the same page and using the same workflow; lack of adoption could be detrimental to progress.  Analyze your current situation What sorts of effects are you seeing right now because of this identified problem? Gather some data to prove there is an actual problem that needs to be addressed. If your help desk continually receives calls about users unable to find a specific button on your website, for example, then you have some evidence of a bad user experience.  Do some research Ask your coworkers what they know about prototyping. Ask if they have ever experimented with any prototyping tools. Ask your end users about the content on your site. Gather some information about just how bad the user experience really is.  This is not the time to pitch your idea. You are in complete listening/observation mode. Save the elevator pitch for later, when you have all the information and are confident this is the right solution to a very specific problem and you are prepared to answer the questions that will come. Assess your tools  Are there any tools you use now that are similar to the tool you are proposing? If so, what are their benefits and downfalls? Take the UXPin example. Does your team use paper to do prototypes right now? Does the graphic designer use Photoshop to start with wireframes/prototypes before doing a high-res layout?  Having a ready list of pros and cons for the tools you currently use will help you build a case around why your solution is superior and will show that you’ve done your homework.  Check your ego Scrutinize your motivations for wanting to introduce a new tool. Do you want to try something new just to take control of a situation? If the graphic designer does a fine job using Photoshop to develop a prototype but you don’t know how to use Photoshop, that’s not a great reason to try a new tool.  However, if you have a team of six and only one person knows how to use Photoshop, choosing a more accessible tool with a shorter learning curve could be the right move.  Explore other solutions Are there other tools out there that will solve the problem you discovered? \nIf you don’t yet have room in the budget for UXPin, can something else get you by while you prove the value of this   of tool? can you use paper prototypes for a few months while the team adjusts to this new part of their workflow?  Sometimes starting with something less complex can be beneficial. Anyone can use pen and paper, but learning new software can be daunting and time-consuming.  Still think this is an awesome idea? You now understand the tangible benefits of implementing your innovative idea and you know who stands to gain from it. You can foresee both the rewards of implementing it and the potential risks of not implementing it.  Your motives are good, you’ve analyzed your current situation for similar tools or processes that may already be in place, and you’ve explored other potential solutions. You are well on your way to building a strong case around your innovative idea. At this point, you’ve put a lot of time and effort into developing it. Do you still think it’s a good idea, and are you as excited as you were when you started? If you’ve lost your drive and excitement at this point, or have been unable to visualize any real benefit, the idea may not be worth implementing. That’s okay. The way you will land on a really great idea is by testing many not-so-great ideas until you find one that fits.  Your continued excitement and drive will be necessary as you start to implement your idea and work toward gaining supporters.  Start small and fail as soon as possible Even if you’re still quite sure this idea is amazing, start small and keep an open mind. A thousand questions will come to mind as you begin using an actual product with real users.  As you start running a couple of tests, use language like “experiment” instead of “implementation.” This leaves room for error and growth. You want to know what’s not going to work as much as you want to know what is going to work. And if someone asks what you’re doing, it sounds way more innocent if you say you’re running a few experiments that you’re going to share with the team than if you say you’re implementing a prototyping tool into our web development process.  If you’re working on a current website project, try creating just one page using the prototyping tool on your own time, not as a part of the official project process. See how it goes building just one page for now. Even better, try making just one element of the page, like the header or navigation. By starting small you will have fewer variables to take into consideration. Remember, right now you’re evaluating the tool itself, not necessarily the user experience of your website.  Then take your prototype and see what kind of feedback you can get by testing it with real end users.  Is the prototype responsive? What URL did you need to use to access it? Was it easy to direct users to this URL? Can you record mouse movements or clicks, and do you need to? How are you documenting their feedback to the site? Were they able to use their own device, or did you need to provide it? What are you going to do with the feedback and observations you’ve gained? Do several tiny experiments like this, making adjustments as you go, until you’re more comfortable with the tool, its features, and the results you get from it. Your confidence with the tool will give your team confidence with it as well.  Don’t get fired Most companies don’t mind their employees doing research about their work on company time. Unfortunately, some do mind. Using your own device on your lunch hour or before and after work may be your only option.  Even if your job does allow you to research and learn on the clock, be respectful of time. Spending several months straight iterating on one idea might not be good for your next employee review. 3M designates 15 percent time for employees to focus on innovation; Google has famously allowed up to 20 percent of employee time to focus on new innovative ideas. Try to gauge what percentage of time you could reasonably spend on your research without neglecting your real job.  Be transparent about what you’re doing. Hiding it and sneaking around will give the wrong impression. Let your boss know you’re curious about a new tool and you’re just running a few experiments to explore it more.  —as I suggested earlier, these are all safe words implying no level of commitment or pressure. Win allies Presumably you have a few friends in the office; take them out to lunch and toss them the idea. Let them know about the experiments you’re running and the results you’re getting. Ask if they want to see what you’ve been working on. It might take a while for anyone to show some interest. Don’t give up if your excitement isn’t mirrored immediately and don’t be pushy. Remember, you want your colleagues to be in your corner.  Also, bouncing your idea off your coworkers is great practice for telling your boss. Your coworkers will definitely ask you a bunch of questions you haven’t thought of yet and will express viewpoints you haven’t considered.  Listen to their opposition and use their concerns to build your case. Do they think adding a new tool to the workflow will slow down the process? Explore that concern; next time you talk, offer some data and insight about how that assumption might not be true. Having your team on your side will go a long way when presenting this to your boss, but it doesn’t have to be a deal-breaker if they’re not. Sometimes our coworkers are just so scared of change that no amount of data will make them comfortable. They will likely express their concerns when you bring your idea up in front of the boss; having a prepared response makes you look confident.  Get your boss’ support Time to go up a level. Please do not put together a giant presentation, wear your best power suite, and pour your heart out onto the line. If your experience is anything like mine, you’ll just spend the rest of the day crying off and on in the bathroom.  A definitive, polished presentation can be offputting. It makes you look like you’ve already solved the whole problem. You want to appear open to suggestions—because you are.  The approach You know your relationship with your boss, and how to approach them, better than anyone else. For me, the best way is to wait for the right opening and mention the new idea in passing. Be prepared to show all of your progress and make some sort of proposal right on the spot. Make it seem easy and low-risk, with clear next steps. I’ve found it beneficial to address the concerns of your team up front to show you value their opinion and input. Bosses love teamwork.  If there isn’t clear interest from your boss, ask them what other data or information they would like to see to help support this idea. What are their concerns or hesitations?  At this point, consider asking for permission to continue to experiment on a broader level. The word “implement” really freaks people out. Trying a prototyping tool in the web-development process for three months instead of implementing it forever sounds a lot less risky.  Persevere If you can’t stick with your idea long enough to do some research and run some experiments, why should anyone else? If it truly matters to you and you can see your idea making a real change in your company or within your work environment, hang in there for the long haul.  When the graphic designers agree to use UXpin as a prototyping tool and the User Experience team (if you’re lucky enough to have a UX team, really I’m not jealous) says they will give it a try for end user testing, ask to be a part of their process. Ask them to invite you to the end-user testing sessions and the design reviews with the stakeholders.  Be in those sessions and meetings as the the idea is implemented so you can continue to reference your personas and make sure decisions are made for the right reasons. That way, you’ll be in the front row to see positive change happen as you guide your idea and hard work into something truly innovative. As your idea starts to gain traction and your experiments turn into a real process—see things through. Don’t just hand off your idea and hope for the best like a child waiting for the school bus.   the damn bus. Like this: \n\t\t\t\t\t\t\tRecently by Janice Gervais\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/gaming-the-system-and-winning/", "title": "Gaming the System…and Winning", "content": "Good intentions usually drive the “gamification” of websites—adding points, badges, and leaderboards to make them more engaging. It sounds like a great idea, but borrowing game design elements out of context is a risky way to design experiences, especially experiences intended to bring users back to a site.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Not everyone wants to spend more time on your site just to get a badge; some people simply aren’t motivated by such extrinsic rewards. When game designers include elements intended to promote deeper engagement, they look at their users through a very different lens than those of us in web design. Understanding how and why they do this can help us craft more engaging web experiences.  A game designer and a web designer looking at the same user research will most likely come up with totally different personas. Talking about many people as though they were one person can be a strength;it gives a clear vision of who we need to serve. But it’s also a limitation because this method of clustering requires us to pick certain axes and disregard others. Web designers cluster people by their needs and abilities, but in doing so, we tend to disregard their personalities. Game designers are more likely to fixate on interaction styles; they embrace personality. Let me show you what I mean. Pokémon Go has seen a meteoric rise in popularity since its release, possibly because of how well it caters to people with different personalities. In Pokémon Go, people who like to compete can “battle” in gyms; those who prefer to collaborate can go on “pokéwalks” together; and anyone with a drive to explore and push boundaries can try to “catch ’em all.” Even if a player enjoys all of these options, they’re likely to find one more motivating than the others. Ensuring that the game caters to each interaction preference enhances its appeal to a wide audience.  The same is true of web design. Adding gamification elements to draw in more visitors—but only elements that cater to competitive people—can overlook the wider audience. UX design that doesn’t target a variety of interaction styles is going to be hit-or-miss. Game designers (and educators and psychologists) segment people in ways that complement web design and user experience. I’ve put together this guide to show you how they think and how (and where and why) we can use their models. Along the way, I’ll show how those models might overlap to create one bigger framework that we can use to pinpoint strengths and weaknesses in our designs.  Making it fun Emotional design—the practice of moving interfaces beyond merely usable—is a growing field of interest among UX designers. (I highly recommend   and  .) Unsurprisingly, game designers have a theory of fun, too. A recent study performed a contextual inquiry of hardcore and casual gamers, plus interviews with their friends and family members,   that relate to interaction preference.  comes from pursuing a goal—earning rewards according to progress.  focuses on something other than winning. It encourages learning and emphasizes feelings of wonder, awe, and mystery.  caters to interaction with others; the interface becomes a mechanism for social engagement.  attract people to engage in a social context to feel something different (e.g., to gain pleasure from acting upon or inciting those around them). These styles are easy to spot on social networking sites:  Competing for likes or followers (as on Twitter) is Hard Fun. Casually browsing to find humorous new posts (as on Tumblr) is Easy Fun. Engaging with a social network to connect with other people (as on Facebook) is a People Factor. People who experience excitement from messing with other people (as on Reddit) are enjoying Altered States. Bartle’s four player types There are numerous ways of grouping people by interaction style, including Hallford and Hallford’s   and Yee’s  , but I find that these approaches roughly map to Richard Bartle’s   (particularly the three non-Troll ones). Bartle’s theory is among the most common approaches chosen by game designers (Fig 1). Suppose you have an ecommerce site for people to buy snakes. An Achiever may be motivated to engage by extrinsic factors:   The Explorer may be motivated by learning more about snakes:   The Socializer will be motivated by interactions with others:   And you’ll probably have to deal with a couple of teenaged Trolls who just want to make fun of everyone else’s snake-buying experience. Bartle also examines pairwise interactions between player types. This leads him to the following sorts of conclusions:  When there are too many Trolls, the Achievers leave, but without interesting victims, the Trolls leave and the Achievers return.  When there aren’t enough Explorers finding new things and telling others about them, the Achievers eventually get bored and leave, causing the Socializers and Trolls to leave, as well.  To reach the widest audience possible, a few Trolls are necessary because they keep the Socializer population from expanding exponentially and pushing out the Achievers and Explorers. (The only other stable equilibria involve fewer player types: either a balance of just Trolls and Achievers or else a community almost exclusively composed of Socializers.) Motivating people Another way of segmenting people is by identifying what motivates them. At a recent conference, I saw a presentation of a  . The presenters said that people’s motivations for exercise tend to cluster into distinct categories. Bartle himself didn’t focus much on motivation, so it was fascinating to see how closely the presenters’ categories align with Bartle’s: one extrinsically motivated, one self-motivated, one socially motivated. In addition to the two dimensions considered by Bartle (Players versus World and Acting versus Interacting), a third axis should be taken into account: the players’ motivations for choosing to engage. Unlike the binary nature of acting OR interacting with the player OR the world, motivations fall along a spectrum of intrinsic and extrinsic motivation (Fig 2). Ryan and Deci’s   is a framework illustrating how player types vary according to source of motivation (Fig 3). How we can motivate people to engage with a site or app depends on where their interaction style falls along this spectrum. What player type we cater to also determines how likely people are to stick around. We can motivate Achievers (or the Achiever side of people) by adding extrinsic metrics they can use to compete with others. Achievers, being extrinsically-motivated, will eventually grow bored and leave. Gamification techniques like points, badges, or leaderboards motivate Achievers extrinsically but can also give them a way to measure their growing competence (encouraging intrinsic motivation). Explorers set their own goals and are self-motivated to interact with your website. Because they’re intrinsically motivated by enjoyment of the task itself, they tend to stick around longer. (Bartle says that changes in numbers of other player types doesn’t usually impact the number of Explorers.) To promote long-term engagement of Explorers,  . Hinting that there are some Easter Eggs hidden in your site could be a great way to encourage explorers to stick around. Socializers will stick around as long as there’s enough social interaction for them. We can motivate them by adding ways to add their own thoughts to site content, such as comments on an epublishing site or reviews on an ecommerce site. If they don’t get enough external feedback from other people, they’ll leave. Adding a way to “Like” reviews or respond to other users’ comments can help to provide this feedback. Trolls set their own goal of annoying other users, but they require feedback from others to know that they’re actually being annoying. The expression “Don’t feed the Trolls” means removing this feedback loop, which we can do with moderation tools and community posting guidelines. How you choose to present rewards will encourage people with different preferred interaction styles to engage with your product. Conventional cognitive psychology wisdom suggests that irregular rewards at irregular intervals motivate continued engagement most effectively. (Expected rewards can be problematic because if people know that a reward is coming, they may work for the reward rather than focusing on the task itself.) Yet, having a variety of expected rewards can help people set goals, thus promoting Achievers.  Helping people learn to use your site When we make fairly complicated sites, people may cycle through different player types as they learn to engage with them. To see what I mean, consider the   of Kurt Lewin, which contains four stages (Fig 4).  Viewing this cycle through Bartle’s player types, it’s possible to align player characteristics with aspects of Lewin’s cycle: Achievers concretely experience the world, Explorers reflect upon what they see, Socializers abstract the world into a context they can discuss, and Trolls premeditate their approach to interactions. This mapping also works with Bartle’s axes (Fig 5). For example, someone coming to a large content site focused on do-it-yourself projects might initially be motivated to engage by their own experience with home improvement. Once they’ve engaged regularly with the site for a time, they might move to a more reflective mode, exploring more of the site. If they really get interested, they might join in the discussion forum, discussing projects with others, and this discussion will give them new ideas for projects they can create in their own life. Application of the ideas to the real world moves back to the Achiever quadrant, but may impact people in that world as well (the Troll quadrant). Thus, if we want people to engage deeply with a site or app over time (learning different aspects of it) it helps to support the many different interaction styles that people may use to engage while learning. Making it engaging Of course, when we make websites, we often talk about supporting immersion through an experience of flow. Game designers again bring light to this form of interaction. Salen and Zimmerman, authors of  , note that four parts of Mihaly Csikszentmihalyi’s flow model are necessary for flow to occur: Challenge Goals Feedback Control All four player types need all four of these to engage fully, yet each prerequisite of flow might be aligned with a player type and learning stage (Fig 6).   Achievers seek  . (They don’t set their own goals as much as Explorers, but will tackle whatever extrinsic challenge you put in front of them.) Challenge is actively experienced. Explorers set their own   to create challenge for themselves. These goals project into the future with reflection upon observation. All players need   from the game, yet Socializers thrive upon feedback from other players. Trolls seek  . (To prevent trolls, building in some form of moderation system is a way of taking away their control.) For example, a photo-sharing site might create an immersive experience by challenging people to upload a certain number of photos, letting them set their own goals for organizing content, allowing other people to give feedback about the quality of the photos or collections, and giving everyone a comfortable sense of control over their own photos and collections. Introducing artificial difficulties, like saying “Try only uploading black and white photos this week” can make the experience more game-like, presenting a challenge that people can choose to use as their own goal or not.  Bringing it all together Here is a fully overlaid model based on my own interpretation of how they’re related (Fig 7). This model might be expanded further using other four-part models from game design such as Hallford and Hallford’s   or Callois’s  . To examine how people progress through the learning stages, we might overlay David Kolb’s   (which is built upon Lewin’s model for learning). I haven’t tested all the variables here, but I hope that this grouped model can be a useful diagnostic tool, as I’ll show with the following three examples. (If you encounter evidence supporting or refuting this way of overlaying the models in your own work, please leave a comment at the end of the article explaining what you’ve found.) The model suggests that if a new feature does not succeed right away, it may largely be due to the interaction styles of the people engaging with the site or app. For example, on a start-up site I worked on, the most engaged users were the ones who had created their own reviews. When we added a discussion forum, it initially didn’t get a lot of use. One possible diagnosis of this slow beginning is that most of the people we’d attracted were Achievers, who learned through their own experiences and enjoyed the challenging hard fun of seeing who could write the most reviews. We dialed back the discussion experience to focus the site more directly on these Achievers. Another approach might have been to add a competitive element to the discussion itself; you’ve probably seen forums that rank their participants, which is a way of luring Achievers to be more social (and thus creating a more diverse community for Socializers). The Troll quadrant is certainly the one least directly mapped to by other models. One possible explanation of this is that we try not to design for Trolls. An explanation I consider more likely is that in a socially-moderated setting, there’s little opportunity for Trolls to exist. If your site is having difficulty with Trolls, the model suggests that making it more difficult for people to act upon people can mitigate the problem. Moderation tools can take away the control that trolls require, making it difficult for them to create altered emotional states. Bartle found that Explorers are rare and difficult to attract, but necessary for the long-term survival of a site. They’re the ones who try out new features to give the rest of the community things to do and discuss. One conventional approach to trying to increase site engagement is to add “gamified” elements, such as points, badges, and leaderboards. But such an approach may actually harm long-term engagement because such extrinsic motivators are unappealing to the Explorers who help the community evolve. Looking at what interaction types a site appeals to and then adding elements to appeal to others can help the site to grow a well-rounded, sustainable audience.  There’s much more that can be brought from games to make the web fun and meaningful. I hope that a greater understanding of how game designers make experiences engaging can empower web designers to craft a more intriguing and inviting web for a wide variety of people. Like this: \n\t\t\t\t\t\t\tRecently by Graham Herrli\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/using-http-2-responsibly-adapting-for-users/", "title": "Using HTTP/2 Responsibly: Adapting for Users", "content": "With HTTP/2 ticking up steadily in use, it’s clear that there’s something to this long overdue update to the protocol. Implementing it, however, not only changes how websites are delivered to the user, it demands that we think critically about how we migrate existing sites to the protocol. More importantly, it demands that we consider our users’ capabilities. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Whether you’ve already migrated your site to HTTP/2 or you’re bracing yourself to take the plunge, there are challenges when it comes to tuning your site’s front end architecture to be the most performant it can possibly be for all your users. Perhaps you’ve read about  . Perhaps you haven’t. If the latter describes you best, it’s not worth getting into the weeds here. The gist of it is that HTTP/2 optimization patterns are the opposite of those for HTTP/1. Your site will perform better on HTTP/2 if you avoid practices that   files, because caching for those resources will be more efficient when they change. In order to cope with the limitations of the aging HTTP/1 protocol, we were more than willing to sacrifice some degree of caching effectiveness for return visitors in order to speed up the initial loading of a site. Thus, techniques like scripts and CSS concatenation, image sprites, and inline assets were embraced. In a world that’s creeping toward HTTP/2, however, we’re told to abandon these practices —and for the most part, rightly so. The reality of the situation can be more complex than we initially thought. While HTTP/2 support on both the server and client side is steadily increasing, browsers that can’t understand the new protocol will linger on for some time yet—and that doesn’t just mean Internet Explorer. It also includes browsers like Safari on older versions of OS X, UC Browser, older versions of Android Browser, and Opera Mini. Sometimes we hurt the ones we love HTTP/2 support is not a one-sided affair. In order for it to work, the server must not only implement it, but the browser must also be capable of understanding the new protocol. When a browser that understands HTTP/2 begins requesting content from an HTTP/2 server, the exchange will predictably occur in, well, HTTP/2. In the case of an older browser like Internet Explorer on Windows 7 (or even a current browser such as Opera Mini), the conversation proceeds in HTTP/1.   that drives this behavior is nuanced, but it can be considered progressive enhancement in that we’re not breaking the experience for users on platforms that can’t use HTTP/2. They’re merely getting a less optimal experience. Whether you’ve made the jump and optimized your site for HTTP/2 already, considering the jump from HTTP/1, or somewhere in between, it can pay (sometimes quite literally) to understand how these optimizations can impact your site’s users. Depending on your audience’s  , a site optimized for HTTP/2 may well be detrimental for a segment of your audience.  HTTP/2 enjoys broad support among users in the global sense. According to the popular feature support index site  , HTTP/2 currently enjoys support of   of all browsers currently in use. Some fringe browsers such as IE 11 below Windows 10, and Safari on OS X below El Capitan muddle the picture a bit. You can count on at least 72% of users globally to support HTTP/2 (at least at the time of this writing). Of course, this is just the big picture, and it isn’t an indicator of what   specific audience looks like. You need to consider the source of your visitors and what browsers they tend to use. You also need to consider where your users reside in the world. In the rudimentary statistics I’ve compiled from caniuse.com, I’ve found that users in developing nations tend to use browsers that   support HTTP/2 more often than those in developed nations. Following that up with statistics from  , developing nations generally have a lower quality of internet infrastructure than developed nations. I won’t get into the data here ( ), but if you’re curious,   to get some context. The confluence of these two truths creates a challenge in how we optimize sites for our visitors. Even if you set up a web server that uses HTTP/2, there’s a segment of your audience that won’t receive the benefits because their connection to your server will be over HTTP/1. Even worse, if you’ve optimized your site for the best performance on HTTP/2, you’ve likely made your website   for users with older browsers. “Aw, hell! They should just upgrade their browser!” While some of us have said this at one time or another out of utter frustration in the face of solving a challenging problem, this is a terrible sentiment. It presupposes that the user has the   to upgrade their browser, but they’re just too damn lazy to get around to it.  The more likely problem is that users in developing nations are reliant on antiquated infrastructure or bound to a restricted data plan that makes this impractical. We need to be empathetic to this reality. It behooves you to know how many of your users are running HTTP2-capable browsers, and how many aren’t. All you need to determine this is a Google Analytics account and caniuse. caniuse is able to comb through your site’s visitor data, then give you the status of support for a particular browser feature in the context of your site’s visitors, rather than for a particular country. Perfect for determining browser support for HTTP/2 in your audience! By opening the settings panel in the site and then clicking the “Import” button under the “From Google Analytics” header, you’ll be prompted to allow caniuse to access your analytics. Here’s a real world scenario in which I’ve used this tool to determine an audience’s HTTP/2 support: My friend runs a reasonably popular blog about guitars and guitar accessories that receives roughly 30,000 pageviews per month. When I fed the site’s Google Analytics data into caniuse, it showed that the site’s audience over the most recent 30 day period had about 91% support for HTTP/2 ( ). 91%   like a high level of support for HTTP/2 —and it is! Despite that fact, you must take into consideration the raw number of pageviews from browsers fetching resources over HTTP/1 because they don’t support HTTP/2.  Some basic math reveals that this segment represents 2,700 pageviews per month. Furthermore, the quoted support of 91% includes browsers that   support HTTP/2. In this specific example, we can only be absolutely certain that around 78% of this site’s visitors support HTTP/2. This means that anywhere from 2,700 to 6,600 pageviews may be served over HTTP/1. The actual number is somewhere in between, and even though this is a minority of users, it’s still a significant number of pageviews on its own, and it may be too large for you to simply ignore. Adapting your users’ limitations By this point, we know three things: The only thing we   know at this point is how to fine-tune our content delivery so that it’s beneficial for everyone. Before we can really think about modifying how content is delivered to the user, there are a couple of things we should consider first. Is HTTP/2 right for you? Assuming you haven’t already migrated to HTTP/2, there are a few things to take into account before you invest time and resources into making the switch: Let me be totally clear: HTTP/2 is an excellent performance enhancement for large, complex sites with lots of assets that would otherwise perform poorly on HTTP/1. We just need to talk about how you might be able to mitigate some of the pain for users with less capable browsers, and that begins with identifying those users when they visit. Checking for HTTP/2 and adapting to users’ needs How you deliver content based on a given user’s HTTP protocol version depends on what technologies you have available on your host. You’ll usually use a back end language like PHP to modify the markup you send to the client. Regardless of the technology you use, there are two conditions you’re covering: The specific mechanism by which you detect HTTP/2 support will depend on the back end language you use. In PHP, we can determine the protocol version of a given connection by checking the   environment variable. Below is a one-liner that stores the HTTP/2 connection status in a variable named  : Using the   function, the   environment variable is checked for the presence of the substring  . If the substring exists,   is set to  . If not, it’s set to  . From here, it’s up to you to apply this logic to your site, but let’s look at a couple of things you   do. For instance, you could add a class of   to the   tag: Using this class, you can adapt your CSS to serve an image sprite for HTTP/1 users, and individual images for your HTTP/2 users. Or maybe serve a separate CSS file with inlined assets using the  . Speaking of serving different files, you could change your markup based on the user’s protocol version to change how you serve assets to the client: Or you could change your markup to   with the handy   function: Of course, on HTTP/2 sites, you would take any content that you’d normally inline and use   to confer the benefits of inlining without   inlining content. How you specifically adapt your site’s content delivery based on the visitor’s protocol version really depends on your specific situation. This concludes the first article! In  , we’ll: Apply these techniques to a real world scenario Use a performance testing tool to check for meaningful comparisons se a build system to generate HTTP/1-friendly assets so you can keep your workflow clean and efficient. Further reading Learn more about boosting site performance with Jeremy’s book  . Get 39% off with code  . Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/considering-how-we-use-http2/", "title": "Considering How We Use HTTP/2", "content": "It’s important to remember that HTTP/2-specific optimizations may become performance liabilities for HTTP/1 users. In the final part of this series, we’ll talk about the performance implications of such a strategy and how build tools can help you manage HTTP/1- and HTTP/2-specific assets. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Our generalized example from the previous article shows how we can adapt delivery of site assets to a user’s connection. Now let’s see how this affects performance in the real world. Observing performance outcomes Developing a testing methodology Low speed mobile connections are quite common in the developing world. Out of curiosity, I wanted to simulate HTTP/1 and HTTP/2 scenarios with   on an actual low speed mobile connection.  In a strangely fortuitous turn of events, I ran out of high speed mobile data the month I was planning to test. In lieu of extra charges, my provider simply throttles the connection speed to 2G. Perfect timing, so I tethered to my iPhone and got started.  To gauge performance in any given scenario, you need a good testing methodology. I wanted to test three distinct scenarios: The tool I selected for testing was  . sitespeed.io is a nifty command line tool—installable via Node’s package manager ( )—that’s packed with options for automating performance testing. sitespeed.io collects various page performance metrics each time it finishes a session.  To collect performance data in each scenario, I used the following command in the terminal window: There are plenty of arguments here, but the gist is that I’m testing my site’s URL using Chrome. The test will be run 200 times for each of the three scenarios, and use a viewport size of 320×480. For a full list of sitespeed.io’s runtime options,  . The test results We’re tracking three aspects of page performance: the total time it takes for the page to load, the amount of time it takes for the   event to fire on the client, and the amount of time it takes for the browser to begin painting the page.  First, let’s look at total page load times for each scenario ( ). This graph illustrates a trend that you’ll see later on. The scenarios optimized for HTTP/1 and HTTP/2 demonstrate similar levels of performance when running on their respective versions of the protocol. The slowest scenario runs on HTTP/1, yet has been optimized for HTTP/2.  In these graphs, we’re plotting two figures: the average and the 95th percentile (meaning load times are below this value 95% of the time). What this data tells me is that if I moved my site to HTTP/2 but didn’t optimize for HTTP/2-incompatible browsers, average page load time for that segment of users would be 10% slower 95% of the time. And 5% of the time, page loading might be   slower.  For a small and uncomplicated site such as my blog, this may seem insignificant, but it really isn’t. What if my site is experiencing heavy traffic? Changing how I deliver content to be more inclusive of users with limited capabilities could be the difference between a user who sticks around or one who decides to leave after waiting too long. Let’s take a look at how long it takes for the DOM to be ready in each scenario ( ). Again, we see similar levels of performance when a site is optimized for its particular protocol. For the scenario in which the site is optimized for HTTP/2 but runs on HTTP/1, the   event fires 10% more slowly than either of the “optimal” scenarios. This occurs 95% of the time. 5% of the time, however, it could be as much as  . What about time to first paint? This is arguably the most important performance metric because it’s the first point the user actually   your website. What happens to this metric when we optimize our content delivery strategy for each protocol version? ( ) The trend persists yet again. In the HTTP/1 Unoptimized scenario, paint time is 10% longer than either of the optimized scenarios 95% of the time—and nearly twice that long during the other 5%. A 10– 20% delay in page paint time is a serious concern. If you had the ability to speed up rendering for a significant segment of your audience, wouldn’t you? Another way to improve this metric for HTTP/1 users is to implement critical CSS. That’s an option for me, since my site’s CSS is 2.2KB after Brotli compression. On HTTP/2 sites, you can achieve a performance benefit similar to inlining by using the protocol’s Server Push feature. Now that we’ve examined the performance implications of tailoring our content delivery to the user’s HTTP protocol version, let’s learn how to automatically generate optimized assets for both segments of your users. Build tools can help You’re busy enough as it is. I get it. Maintaining two sets of assets optimized for two different types of users sounds like a huge pain. But this is where a build tool like   comes into the picture.  If you’re using gulp (or other automation tools like   or  ), chances are you’re already automating stuff like script minification (or  , depending on how aggressive your optimizations are.) Below is a generalized example of how you could use the   and   plugins to uglify files, and then concatenate those separate uglified assets into a single one. In this example, all scripts in the   directory are uglified by the   task. Each processed script is output separately to  . When this happens, the   task kicks in and bundles all of these scripts into a single file named  . You can then use the protocol detection technique shown in part one of this article series to change which scripts you serve based on the visitor’s protocol version. Of course, that’s not the only thing you can do with a build system. You could take the same approach to bundling with your CSS files, or even generate image sprites from separate images with the   plugin. The takeaway here is that a build system makes it easy to maintain two sets of optimized assets (among many other things, of course). It can be done easily and automatically, freeing you up to focus on development and improving performance for your site’s visitors.  Reflection We’ve seen how an HTTP/2-optimized site can perform poorly for users with HTTP/2-incompatible browsers.  But   are the capabilities of these users limited? It really depends.  Socioeconomic conditions play a big role. Users tend to buy the quality of device they can afford, so the capabilities of the “average” device varies significantly, especially between developing and developed nations.  Lack of financial resources may also drive users to restricted data plans and browsers like Opera Mini that minimize data usage. Until those browsers support HTTP/2, a significant percentage of users out there may never come on board.  Updating phone applications can also be problematic for someone on a restricted data plan. Immediate adoption can’t be expected, and some may forego browser updates in favor of preserving the remaining allotment of data on their plans. In developing nations, internet infrastructure quality is significantly behind pace with what’s in the developed world.  We can’t change the behavior of every user to suit our development preferences. What we   do, though, is identify the audience segment that can’t support HTTP/2, then make an informed decision whether or not it’s worth the effort to adapt how we deliver content to them. If a sizeable portion of the audience uses HTTP/2-incompatible browsers, we can change how we deliver content to them. We can deliver an optimized experience and give them a leg up, and we can do so while providing performance advantages for those users who   support HTTP/2. There are many people out there who face significant challenges while browsing the web. Before we fully embrace new technologies, let’s figure out how we can do so without leaving a significant segment of our audience in a lurch. The reward in what we do comes from providing solutions that work for  . Let’s adopt new technologies responsibly. It behooves us all to act with care. Further reading Learn more about boosting site performance with Jeremy’s book  . Get 39% off with code  . Like this: \n\t\t\t\t\t\t\tRecently by Jeremy Wagner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/i-dont-need-help/", "title": "I Don’t Need Help", "content": "We have no excuse…admit it. UX may brag about intuitive and pretty, but we sure suck at helping people—this one thing that most defines, most embodies great user experience. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Throughout history, there’s one recurring theme: people need help. For all we know, the need for assistance might have triggered the development of communication. It could have led to bonding among tribes and our existence today. In the future, it might be the only thing that staves off human extinction and promotes societal evolution. But if so, that begs the question: why do we find it so difficult to   or offer guidance to one another? Do we prefer to figure things out for ourselves? Are we afraid that any request for assistance would be fraught with obligations to reciprocate? Are we worried that we’ll be rejected? Or that we might not get the help we need?  People do need help. It’s a given—and a problem in the field of UX. We claim to do so much for users, but treat help as an afterthought. How come it isn’t our primary consideration? A glance at most websites, including those for large and small organizations, suggests that user assistance is treated as a cursory option—often relegated to a question mark symbol tacked onto a corner. The assumptions are: Users won’t need help; the design is intuitive. If users do want help, they’ll look for it (somewhere). Once users figure out where to look, they’ll seek help when they need it. If the same scenario were layered on real-world interactions, it would be analogous to visiting a large museum, with maps, tours, guides, and program schedules hidden in a locker at some end far off the main entrance.  Why offer help before it’s requested? Taking the guesswork out of a customer’s experience is beneficial to all involved. Consider that you’re walking into a new casual diner. Initially you may wonder if everything is self-service, and if you are expected to clear your own table. You could just stare at folks around the room and make your move based on what other diners are doing. Or, the franchisee could help you get up to speed right away. Ikea solves the what-do-I-do problem with a “Why should I clear my own table?” sign right at the center of its popular store restaurant. The sign solves two problems—it gives the customer needed information immediately and it promotes Ikea’s aim to cut costs.  Designers create user interfaces through careful planning, so one popular conclusion is that if a design has been a success, no explanation—no prominent sign—is required. But help is often sought or needed for a variety of reasons. Help could be required to explain certain fields in a form, to define the meaning of a specific icon, to parse highly technical terms, to identify new features, to illuminate hidden gestures, or to detail policies that are obtuse.  A user may immediately understand that a pencil icon opens an editing pop-up. If he doesn’t, he may well figure it out eventually but only after moments wasted in confusion.  No matter how smart a design is, unless it is customized to every user’s personality, needs, working conditions, device, domain knowledge, technical expertise, and mood, it will need some explaining. A good designer empathizes with unique concerns and takes users as they are, from practiced online mavens to casual browsers. A good design includes user assistance that is given due consideration.   When help goes wrong Sometimes websites do make dedicated attempts to help. And sometimes those attempts smack of overkill. There are video tours expertly created to take users through each feature in the product. There are slideshows with custom fonts and colorful characters that highlight everything  new and promising in the release. There are translucent overlays of clever pointers to indicate where useful action commands are located.   show that when presented with any of the above on launch of an application, a user either: The main issue with providing informational assistance as the first screen is that users do not care yet. They have not seen enough of the product to want to learn about its intricacies.  Users want to get to the product as soon as possible; they’ve already read the marketing material, gone through the registration process, perhaps even read the “Terms and Conditions.”  They do not want anything else to lengthen the delay. If forced to read through preliminary content or go through tours, they do so while disengaged and hence, promptly forget all they learned. Some applications have book-length help manuals. Immense thought and work goes into writing and creating these documents. But they exist in a separate world, removed from the application itself, expecting the user to click away from her task at hand to read and learn. Often, they are poorly designed, making the process of finding information in the “help” website a chore.  Can help intrude? Handholding, intrusive help is as frowned upon in the design world as lack of intuitiveness. Examples of this include forcing open an overlay with offers of help while the user is engaged in a task; loading screens full of product descriptions without context; or launching a product tour that must be completed before the user can access the product. This is where the need to understand the goals of the application comes in.  Is this an enterprise application with cloud-based storage, multiple server connections, and sensitive data transfers? In that case, help should become a visible priority. What if it’s an app built with a strong gamification approach? In that case, help can probably take a passive backseat.  Consider user behavior patterns while designing the help function. Some users prefer an uninterrupted reading experience—they like to dive deep into the subject matter, read every instruction, perhaps even download the content for offline reading. They rely on in-depth topic descriptions. On the other end of the spectrum, some users prefer to scan the text. They only seek help after they’ve made a mistake and will rarely go to a dedicated off-context help website. Short bites of support within the application work best for them.  Instructions offered in a non-intrusive manner can enhance an experience, whether real or virtual. Hiking on a trail with clear path markers, distance indicators, wildlife cautions, and plant and foliage descriptions would be safe and informative and hence, helpful. The “x minute read” tag in Medium posts, the   messenger in Slack, and the delineations of   in Google Apps Learning Center are all examples of help offered to users without distracting fanfare.  How to help Simply ensuring your user assistance function is visible can be enough to provide comfort. In the same way a good interface doesn’t make users think too hard, a good help function should be easy to find and access. Help can be designed to be contextual or stand-alone (a mix of both works best).  Contextual help is any form of   that is embedded within the product’s screens. It prevents disruption from user’s immediate focus. It is concise and quick to read and access. It is available when the user requests or—even better—expects it. A few examples: Tooltips that appear on hover indicating the name of an icon or button. Info-tips that open after clicking an “i” or “?” next to a form or field or any part of UI worth explaining. These should have brief content that explains the purpose/meaning of the relevant element. Ghost text that appears within a text field or next to the UI element to help users learn about the element. A panel that functions an an overlay within the product screen, providing users with more detailed help information. Quick “Getting Started” guides that merge with the interface and take users through the actions flow. Tooltips indicating feature upgrades within the UI. Hint text that demonstrates search protocols—such as suggested keywords that actually work in the application. Stand-alone help can take a more  .  Designing the help center for an application is usually a challenge. Should information architecture match the application’s architecture? How will users approach the content? Would they want every action and interface element documented? If so, how should the content be structured for easy perusal? If they don’t, how do writers prioritize topics? How much is too much? Effective search functionality can help save users from getting lost in content; a   makes it simple to locate the right topic before users get overwhelmed. And if the application’s search option is internet friendly, it will appeal even more to those users who prefer using a “real” search engine (like Google or Bing).  Documentation categorized by features or tasks allows users to filter more quickly. It is also important to identify which information warrants greater visibility—help users solve their most pressing concerns, and quickly. Customer feedback, analytics, and user research can help determine which topics your users are looking for most.  The myth of technical proficiency Enterprise applications as well as consumer applications can benefit from a well thought out help system. It’s poor logic to say that an interface is designed for “technically proficient” users who therefore won’t need any help.  A well-designed help function is more than a set of instructions in an emergency. It is thoughtful, approachable, and considerate. It knows that no quest for assistance is too small, no needed explanation is too big. It’s time we uprooted the precedents of cumbersome or “barely there” help functions. It is time to make Help  .  After all, needing help is part of the human condition. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/big-data-visualization-with-meaning/", "title": "Big Data Visualization with Meaning", "content": "The web is not the traditional home of data visualization. You might come across a bar chart here or there in your online journey on any given day, but they’ve never been an artifact of web history. It seems like that’s been changing. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. With the world becoming increasingly data-driven, we’re seeing more and more visualizations make their way onto our web pages and into our design briefs. They help us tell stories that better engage our users, and can even get them to take some kind of meaningful action. The problem is that these datasets—sometimes so large they’re literally called “big data”—can make visualization with meaning difficult. But that’s something we as designers are equipped to tackle. We just have to know what our users are hoping to gain from viewing and interacting with visualizations, and what we have to do to make their effort worthwhile.  Data has a very strong power to persuade—powerful enough to change users’ everyday behavior, especially when data is informative, clear, and actionable. We should be putting data visualizations to work on our sites, enhancing our designs to show users how data is in service to the story they’ve come to learn about. Data visualization on the web can be meaningful through allowing people to discover the smaller stories that resonate with them, customizing their user experience instead of putting them on a predetermined path.  Users attempting to interact with large and generally disconnected sets of data while navigating a site or trying to access relevant information end up facing a difficult, if not impossible, task. Our sites lose a certain measure of usability if they aren’t well-designed, even though the web is a natural medium for delivering truly interactive data.     As with all design, the approach we take when creating a user-minded visualization is based on the context and the constraints we have to work with. Good data visualizations—those with meaning—need to be accessible and human even though data is rarely described with those words. Telling a story The key to designing visualizations is to focus on something in the dataset that is relatable to and resonates with your users. I stumbled upon this while creating a visualization from the publicly available   dataset, which contains crowd-sourced information on food products from all over the world.  Although the dataset covers an extensive range of information (even down to packaging materials and number of additives), I chose to focus on comparing average sugar consumption among different countries ( ) because I was personally concerned about that topic. It turned out to be a concern for others as well and became the   for the dataset on Kaggle.  Even though I didn’t make extensive use of the dataset in my rough and ugly visualization, what I chose to focus on told a story that resonated with people because most were from the countries listed or had a growing general awareness of high sugar consumption and its effect on health. In retrospect, what’s more personal and important than your health? Selecting data points that strengthen a story with a positive result (whether that’s eating less sugar or  ) can be great, but it’s important to present a story that is as unbiased as possible and to make ethical decisions about which parts of the data we want to use while telling the story. But what exactly is a story in the context of a data visualization? We can’t kick it off with “once upon a time,” so we have to approach the idea in a different way. Whitney Quesenbery and Kevin Brooks provide these definitions of a story in their book  : Stories describe the context of a situation Stories can illustrate problems Stories can be used to help people remember Stories can be used to persuade and entertain. And I would add to the list: Stories can make you question the state of a situation. Addressing some or all of these attributes is a particular challenge for big datasets because the sheer amount of information can make finding a narrative difficult. But big or not, the principles remain the same. Visualizing any kind of data-driven story that resonates can have a powerful influence on users’ decisions.  It also stirs other questions the user might ask.  For instance, why do certain countries consume higher quantities of sugar? Are they the ones we expected? The information could challenge an assumption or two someone may have had prior to seeing the results. Just remember that visualization can be a stepping stone to further discovery, increasing the user’s knowledge and possibly affecting their everyday choices going forward. If you’re trying to embed meaning into a large visualization through the story of a dataset’s subsection, it’s important to: Discover what your users care about in the dataset. Make it relevant to their personal needs, desires, and interests. Focus on that subsection ruthlessly. Get rid of anything that doesn’t further the story your visualization is telling. Take care to make ethical, unbiased decisions about which data points you use to create visualizations that might influence your users. Be careful not to give people all the answers; allow them to ask their own questions and make their own discoveries about the data. This approach allows you to create something that not only resonates at a personal level, but also presents meaning in a way that encourages and allows users to take action. But we already have a story Though large, some big datasets already revolve around a single story. An interesting way of dealing with this particular issue is to simultaneously display different aspects of such a dataset, allowing the user to discover that meaning. This is called the “small multiples” technique. ( ) The cluster of visualizations above, for example, deals with the “story” of memory stall issues on a computer. What I find interesting about the cluster is that the heading of every visualization starts with some variation of “memory stall time.” Despite being separate visualizations, they are linked by the single story they tell and they’re presenting it from simultaneous, distinct perspectives. It’s possible for perspectives to look completely different from one another if they visualize different   of data. For instance, bar charts and area charts can harmoniously coexist if the representations are appropriate for the data they’re showing. The   illustrates how this might work ( ). It allows the user to establish their own narrative through choice of topic, such as language or place.  Framing visualizations around a personal topic (like someone’s native language) affects all associated small multiples appropriately; reframing serves to personalize the data. ( ) Storytelling through interaction It can be very useful with this approach to include an interaction in one design that is capable of affecting the others—something to help the user see relationships between data points they might not have considered before. This example from essay site   shows all Kickstarter projects across space, organized here by category and American city. ( )  The visualization is particularly interesting because it allows users to view the relationship of one variable (in this case, the project category) to others, such as American cities or project sizes. (Notice the prevalence of music projects in Nashville and game projects in Austin and Seattle).   The Lens does something similar in its visualization of the human genome ( ) by   by way of various filters.  This can be even more effective for small multiples shown across time.   shows how this approach is used on a fund manager’s website. Changing the time period of an investment fund’s performance also shows how risk rating and the growth of an investment change during that period. By leveraging intuitive web animation, we can view snapshots of the data at precise moments in time.  If the dataset is already centered around some kind of overarching story, it can be a good idea to: Display different parts of the dataset in separate visualizations simultaneously Treat these separate visualizations as individuals tailored to the data they’re presenting. (Bar charts and area charts can live together in harmony if the data makes it appropriate.) If there is interaction, ensure that it affects the entirety of your visualization approach so that the relationships between data points are more apparent Apply well-considered web animation techniques to ensure that the interaction is intuitive. There are too many stories What do we do when a dataset doesn’t have a single, big story to tell, yet we still need to visualize everything in it?  Although some datasets lack a specific focus (e.g., “memory stall time,” “fund performance,” or “all-Kickstarter-projects-ever”), data points may have internal relationships that reveal bite-sized stories. How do we create actionable meaning for those visualizations?  Simply showing data as-is, even in a visualization that seems to fit, rarely works well. In   we see relationships between Python code packages, but in a way that’s just as messy and incoherent as the data in its natural state. The lack of focus and narrative is notable. (That said, the dataset is extremely large, so a single narrative isn’t actually possible.) Since a single story isn’t possible in this situation, a better approach is to allow users to discover their   story. Your job is to facilitate that via the interaction design of the visualization.  This browser-based design in   ( ) visualizes code package relationships, too (in this case, JavaScript), but gives users what they need to explore the data in a meaningful way. Again, at first glance the visualization seems to be messy and incoherent—but look closer. Users can investigate any individual package of code, including its personal relationships (listed in the bottom left). A handy search bar has also been incorporated in the top left corner.  What makes this particular visualization more meaningful is that the user can explore it in 3D space via keyboard and mouse. Leveraging this uniquely digital capability in the browser allows users to start discovering their own story in the enormous swarm of data, “moving” toward areas in the visualization that they find more relevant to their interests or needs. ( ) Once the user finds a package or groups of packages they’re interested in exploring, they can click on one for a specific and focused view of the package in isolation, including its relationships with other packages. A  full breakdown of these relationships is posted on the left of the screen, including visual nodes linking directly to the Github page for that code package. ( ) This visualization, like the one shown before it, uses the idea of a network in order to display the immensity of the data, but it also uses intuitive interaction and lets the user explore in order to extract personally relevant meaning. It uses the modern advantages of the web to deal with the modern problems of big datasets, much like the following visualization from  . ( ) This design allows users to zero in on data they care about, choosing where they go and which breadcrumbs offer meaningful insight. If a dataset needs to be fully visualized but has smaller stories within it, it may be useful to: Show all data, but give users the ability to create chunks or segments they wish to explore Leverage the advantages of being digital. For example, explore how input devices (e.g., keyboard and mouse) can facilitate   users interact with the data. Use visual metaphors that support extensive and intricate relationship associations, such as a tree or network. Visualization with meaning Data is powerful in the right hands, and something we’re skilled at presenting in our websites. But toss in words like “big data” or “data visualization” and we second-guess ourselves instead of owning it as part of our workflow. The web is actually a great place for data visualization. Leveraging the benefits of “digital” environments and tools, we can help users get what they need from large, complicated datasets. They are looking for insights, for meaningful information presented simply, for stories that resonate—for data stories they care about. We can help them find those stories by blending in a few new techniques on our end, such as sub-selections of data, use of small multiples to show relationships between data points, or even allowing user-driven focus on the full dataset. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/long-term-design-rewriting-the-design-sales-pitch/", "title": "Long-Term Design: Rewriting the Design Sales Pitch", "content": "We run our client service businesses just like door-to-door salespeople hawking vacuum cleaners. That may seem unfair, but it’s exactly how we sell design. We’re focused on short-term wins—but we’re teaching clients to see our work as disposable. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I want to believe we’re better than that. We spend our entire careers knocking on doors and shilling our services. It’s just how we do business. Even if a potential client’s old design is working just fine, we might go for the hard sell. But that’s damaging, both to us and to our clients. This practice perpetuates the idea that design is only valuable when  .  Consider the salesperson’s pitch:  Your [design/vacuum] is old. Other people have newer ones. You’re going to lose out if you don’t buy a new one. Your family/business might even be unsafe with your current one. We believe that being a designer requires cycling through clients and booking new projects. Instead of talking about dust or maneuverability around furniture legs, the designer’s pitch is more like this: Your current design is not allowing your brand to resonate in the marketplace. It looks dated, and your competitors all recently launched new branding. You could lose market share to competitors without a more modern design. Short-term engagements are bad for our clients We write articles in phenomenal publications like this one about how design isn’t just about aesthetics—design should be a fundamental part of how a business operates, conducts market research, and creates products and services. Design is powerful and important. So we preach the doctrine of  . We work to improve accessibility and web standards for the good of all. We preach user advocacy. However, when we pitch design work to clients, so often we’re only selling the aesthetics. And, when we book the gig, we try to ship that design and get that final invoice paid so we can bring in the next client. We designers rarely stick around to see how well the design works. We begin each project with design thinking, but rarely maintain it. And because of that, each client goes shopping for another new design (or succumbs to the pitch of another designer) much sooner than they need to. Design requires time in order to deliver its full value. For example, when a new website launches, we can measure changes in analytics immediately. But that design also carries the potential for further improvements—enhancements that can be unlocked through A/B testing, analysis, and optimization. Unfortunately, the vast majority of sites are never optimized. They launch, sit for a year or two, then get replaced. Our clients aren’t getting the full return on their investments. And if you think about that even further, this “cycle of redesign” makes design less valuable. In other words, if design is only valuable when new, it isn’t very valuable in the first place. New, cheaper solutions are encroaching upon our profession, such as logo-designing software, theming algorithms, and drag & drop design tools. We fear we are being replaced by these alternatives or that the perceived value of design is decreasing. And in the next breath, we tell our clients “Let’s make a fresh, new design for you.” We can’t blame clients for trying affordable new options; we’re the ones who taught them to value “new” design in the first place. Cycling through clients is less lucrative Finding a constant stream of new clients takes a lot of effort and is a constant challenge for many designers and agencies. Freelancers spend countless hours crawling job boards and submitting their portfolios in hopes of getting hired. Agencies spend considerable resources responding to RFPs, and many employ sales staff and account managers. When designers enter more senior-level positions, they eventually face the frustration that more time is spent selling, meaning less time to design. Sales isn’t bad and will always be necessary to some degree. That said, when we spend more time on sales than we need to, compensation suffers. Naturally, reducing the time and effort on sales so we can do more design work would be more lucrative. To do this, we only need to stop knocking on new doors and instead continue to serve the clients we already have. We need to change how we structure our services and start supporting clients over the long term. Long-term work can be personally and professionally satisfying Designers have a certain obsession with making new designs, and you might think that working with the same client for a year sounds boring.  I’ll admit it: making new designs is fun. I love the act of creation and the satisfaction of making something fresh and cool. However, by cycling through clients, we’re missing out on some of the most satisfying design work there is. Few projects are as challenging or gratifying as redesigning a responsive web app that has four tiers of navigation. That might sound horribly tedious and painful at first, but solving a difficult design problem brings incredible satisfaction. Further, witnessing people benefit as a direct result of your design can be powerful and rewarding—much more rewarding than the temporary thrill of making something new. You see your design taking an active role in growing a business or in improving a person’s daily work. You see other people recognizing your design’s value. That’s a great feeling. This is often only possible when you stick around and serve the client over the long term. What it’s like working with clients over the long term For me, the idea of a long-term structure for my design services started when a client said this: I’m tired of signing a contract every 6 weeks. Can I just pay you every month instead? Now I only do retainer work. All my current clients have been with me for more than a year. In the early days of running my solo consulting business, I spent a lot of time crawling job boards, writing proposals, scheduling “nice to meet you” calls, and booked only a small fraction of projects. Some weeks, I only did sales work and didn’t get to spend even a minute on design. Fast forward a couple of years, and I can’t even remember the last time I glanced at a job board. I don’t do sales calls. I don’t respond to RFPs, search for leads, or write long proposals every week. I do more design work than ever. And, I rarely do revisions on my work because my clients trust me. My design business is completely different now that I work with clients for the long term. I find more satisfaction in my work. I solve difficult problems and enjoy seeing my clients thrive. I make more money this way, too, because I get paid for more of the time I spend at work. (I don’t bill by the hour, but another way to put this is: I’ve increased billable hours and decreased non-billable hours.) How to set up long-term client relationships If you are tired of needing a constant flow of new clients and investing in the long view sounds like a plan, here’s how to start. Look for long-term needs. Most design projects conclude when we deliver the design and the client pays the last invoice. It seems final. But this can be terrifying for the client. Many clients don’t know how to use the tools we produce for them—they don’t know how to use a website or marketing campaign, and they struggle to determine whether it’s successful. By offering support and advice after the first project concludes, you not only show that you are committed to helping the client succeed and get value from the investment (which is good for the client), but you are opening the door to future projects with that client (which is good for you). There are many, many opportunities for continuing design work with clients who have profitable and growing businesses. Long-term work doesn’t have to consist only of small updates and maintenance; it can include supporting new business initiatives and keeping the brand and assets in line. You can position yourself as a design director and advise on strategy and brand consistency. These are extremely valuable services to our clients and protect their investment in the original project. Most clients don’t know how to match all of their marketing efforts to the new brand you created for them. Or, they may want to launch a new feature or product, or weave a new ad campaign into the design you’ve created. These evolutions need design support. By sticking around after the first project and showing the value of your partnership, you can position yourself to get hired repeatedly. To be clear, long-term work is not unpaid work. Delivering a design doesn’t mean a designer should be on the hook for free support indefinitely. Depending on the client and the kind of work you do for them, there are many possible ways to structure a long-term relationship, such as: Monthly retainers Additional project phases, such as conversion rate optimization (CRO) and user testing Scheduling a check-in call a month after launching a new design Including a written analytics report in the project fee. Clients might see these as attempts to increase fees and the project scope. That’s because long-term structures can be as unfamiliar to clients as they are to designers. To address those concerns, designers need to educate our clients about the benefits and value of long-term engagements. Great ways to begin the conversation include:  Explaining that optimization will help the client see the most return from their investment Explaining that optimization will help avoid the need for a redesign later. Design’s “old money”: Big agencies and bigger accounts Long-term client service is old hat to big ad agencies; they’ve been operating like this for decades. If you read AdAge.com, you’ll see announcements about big agencies landing accounts from bigger companies to the tune of hundreds of millions of dollars. Of course, the agency doesn’t get to keep all of that—much of it goes to TV networks for ad time, and websites and print media for ad placements. But it usually means everyone gets to keep their jobs for a year. When a big account changes hands, it’s news. As in, the kind of news serious journalists cover. Agencies pour a ton of resources into landing big accounts, and, when they do, they get a year to prove their worth. Changing agencies is a major decision for big companies because it is a big investment and substantially impacts marketing success. While I don’t advocate replicating every aspect of the big agency model (especially not spec work), small agencies and even freelancers can offer long-term services to smaller clients in the same way. Consistent income and long-term relationships aren’t only for huge agencies that date back to the Mad Men era. Even operating on a smaller scale, the benefits to both designers and clients are the same. Practical freelancing concerns For me, personally, there was a lot to learn when I decided to try long-term engagements. That investment has paid off by providing me a more consistent freelancing income, reducing administrative and sales tasks and increasing my total income. That said, there are risks and complicating factors in long-term relationships. For freelancers, the risk of working with clients over the long term is that if you lose a client, you will have to work harder to refill your work schedule because your lead pipeline for new clients is slower. Worse, if you only work with a single client for a long period, it’s like putting all your eggs in one basket. Losing your only client is obviously a serious concern. Because of that risk, keeping several engagements active simultaneously is important for earning consistent income and protecting yourself if you do lose an important client. Additionally, long-term freelancing carries tax implications. The legal distinction between a salaried employee and a full-time contract worker, or even an independent contractor, varies in many countries, and some countries, such as the UK, are suspicious of long-term, full-time contract work because it can be used as a strategy by companies to avoid tax liability or to avoid providing legally required benefits. If not just for the financial stability, but also to avoid tax headaches, I recommend keeping several long-term client relationships active at once or limiting full-time engagements to shorter periods that then transition into part-time work for each client. And, of course, consult your tax advisor. If you’re working full-time for a client for a long period, such as six months to a year, you deserve benefits. While long-term work is stable and attractive for many reasons, don’t let it become a way for someone who is essentially an employer (as opposed to a “client”) to withhold compensation you deserve. Finally, writing contracts for long-term work can be complex, especially for structures like retainers. It’s always a good idea to consult a lawyer and to buy errors and omissions and general business liability insurance to protect yourself. Respect for designers and profit for clients With long-term optimization, design works better and better. And when clients see their profit increasing and that business goals are being met, they place greater trust in their designers. A long-term partner who works month after month to support a client’s business is vastly different from the door-to-door salesman. When designers behave as long-term partners, we prove the value of design and earn more respect. It also sets the stage so we can make great money while avoiding the less desirable sales work that so often invades our calendars. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/practical-design-discovery/", "title": "Practical Design Discovery", "content": "One of the hardest design problems I ever worked on was for a company that helps IT groups manage risk. Their product focused on open-source components—inexpensive and widely supported by an enormous community, but often vulnerable to security flaws.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What made this design problem hard was the complexity of the product’s underlying structure, a triangle of interrelated abstract concepts. To work through the problem, we created a series of sketches that helped us understand it.  The outcome ended up being a relatively simple prototype, a model of the overall structure of the application. Though we were chartered to create a detailed design, our client later admitted that they knew we wouldn’t get there, but that they highly valued our efforts to solve the underlying structure. Those efforts set the direction for everything else on the product. Direction-setting assertions Much like when we frame problems, we can make assertions that set direction and describe decisions about the design. These decisions will be pretty high-level, meaning they’ll deal with a holistic view of the site or product. Decisions about details come later, though you’ll see that some assertions get pretty specific as a way of clarifying and testing the direction. There are three kinds of assertions you can make about design direction:  define what the design should or shouldn’t do. These statements are grounded in research, and may be referred to as   when you can tie them to research.  establish an overall approach for the product, expressed as a central theme or idea.  describe the product in an abstract way, showing the underlying architecture, structure, flow, or approach. They offer a sense of how the product will work (without actual functionality). If you try to make tactical decisions too early, you may set a precedent without understanding how it influences what comes next—it’s difficult to trace low-level decisions back to a specific objective or problem statement. Why is the button blue? There’s no project objective in the world that can justify such a decision.  Instead, you’ll make a   low-level decisions alongside your assertions, using samples to illustrate, clarify, and demonstrate the application of the high-level decisions. For example, you might arrive at the design principle that the site’s tone should be friendly without being too casual or informal. You would demonstrate that through sample screen designs and content, showing messaging that says “Thanks!” instead of the too-formal “Thank you very much” or too-casual “You rock!” Exploring the big decisions through examples might encourage you to reconsider them, or to find places in the product experience that need variation. Perhaps the color palette is insufficient for everything you need, or the authoritative voice isn’t appropriate for certain pages. By venturing a solution, you’re not just asking, “Will this work?” You’re also asking, “Do I have enough knowledge to know whether this will work?” That is, steps toward solving the problem may trigger additional insights, or questions, about the problem. Great discovery entails providing just enough shape and definition so the team can get aligned behind them as direction for the product. Principles and implications Principles are rules that help designers evaluate their decisions about the design. They provide guidance in the form of absolute statements about what the design should or should not do. That said, no set of principles can be exhaustive. They read, sometimes, as commandments: rules that may be applicable to many different kinds of design decisions, and therefore open to interpretation. There’s no industry standard on how to write design principles, so you won’t be violating some ordinance if you use pictograms or write a dialogue. But principles are usually just one sentence, often written in the imperative: Do more with less (Microsoft Design Principles) Design for the customer and instill confidence (Intuit) Use data to make and improve decisions (Principles for 21st Century Government, Code for America) I like these, but they don’t feel specific to the product or company. Principles are most powerful when they’re directly relevant. These use more elaborate phrases that closely relate to the product: More than boxes on a screen (Google Calendar) Transitional interfaces are easier to learn and more pleasant to use (MapBox) Time matters, so build for people on the go (Windows User Experience Design Principles) Sometimes, you’ll find principles rendered as one- or two-word noun phrases, as if to complete the expression, “The Principle of ______.”: More Contrast (10 Principles of Codeacademy.com) Consistency (First Principles of Interaction Design, Bruce Tognazzini) Principles are sometimes followed by deeper descriptions and examples. My favorite variation of this comes from the  . These principles include questions for designers to ask themselves about design decisions: Does the feature allow users to express an element of themselves? Have you made the distinction between personalization and customization? Does the personalization have to be a new feature, or can it make use of existing features and information (such as the user’s location, background picture, or tile)? Regardless of the approach you take in framing the principles, use consistent language and structures, if only to make them easier to remember and use. If you lead with a verb, always lead with a verb. If you write a pithy phrase or a complete sentence to express the principle, always do that. If you write single-word principles, well, there’s a special place in purgatory for you. In my practice, I phrase principles as direct consequences of what we learned in research. I call them  , and I prefer them because they fit into the narrative: “We learned that users often lose their place in the system. The implication is that the UI should prioritize clarifying context.”  Implications answer the question, “So what?” You’ve generated a lot of data, and now need to explain why it all matters. I typically document this in a spreadsheet that identifies project questions, answers I’ve uncovered, and the resulting implications ( ). Ultimately, principles and implications do the same thing, so I won’t belabor the distinction between them. In both cases, they make an assertion that, yes, guides the designer, but also provides a test: designers can compare an idea to the principle and determine how closely it adheres to the guide.  There’s no standard for design principles, though there are lots of suggestions out there (the Resources section includes a few of the best). Here are my suggestions for crafting design principles. Be specific Principles should be as specific to the product as possible. “Easy to use” isn’t a meaningful principle, because it could apply to anything. For the project with the risk-management company I described at the beginning of this chapter, we used a number of principles. In early versions of their product, users complained that it was easy to lose their place, so they couldn’t keep track of what they were working on. This led us to the principle: Always display the user’s context within the system, so they know where they are and what they’re working on. Context became something we talked about a lot. It forced us to think carefully before moving information to a different screen, or triggering a dialog box for taking action. Because of this principle, we often asked ourselves, “Can the user tell where they are? Is loss of context here okay?” Question your choices Good principles go beyond specificity: they issue a direct challenge to designers. They force you to take a second look at your work: does the principle invalidate any of your decisions? Done right, principles should make you squirm a little. In the risk-management product, the complexity of its requirements inevitably produced dense, esoteric designs. Elaborate displays attempted to capture every nuance, pack in every detail. At the same time, our client had heard their users didn’t like the dense displays. We had to walk a fine line, and so we relied on this principle: Show just enough information to support essential decisions—no more, no less. The principle’s borderline self-contradiction provoked us to reconsider what stayed on each screen as users worked through the process.   On one hand, we wanted users to feel confident about where they were, but on the other, we didn’t want the page overwhelmed by navigation devices irrelevant to the current task. We also constantly asked ourselves, “What is ‘just enough information?’” and “What are the ‘essential decisions?’” Every iteration of the design tested the meaning of these key phrases. Inspire your team Specific and provocative principles may seem like whip-cracking:  . But a good principle also inspires you, pointing you to even loftier goals. It opens up possibilities by encouraging you to explore—and providing rationale for where you end up.  In Luke Wroblewski’s summary of a 2009 talk by Stephan Hoefnagels of Microsoft, he writes, “Goals are the mountain peaks you are trying to get to. [Design] principles are the path we use to get to the top of the mountain.” One of the driving principles for my client’s product rested on the insight that the product was focused on bad news: every display was about what was going wrong in the IT department that day, how bad it was, and what wasn’t getting done. Like most interactive products, though, this one was meant to be a pleasure to use. In short, we needed to balance the gloom and doom with the satisfaction that comes from understanding the nature and extent of the bad news. We relied on this principle: Build confidence by clearly stating risks and making the data actionable. We knew the goal was to help customers manage risk. This principle acted as the path to the top of the mountain by inspiring us to focus not just on reporting the bad news, but also on ensuring customers could do something about it. Link principles to research Principles grounded in research make for stronger statements. The death knell of any principle is arbitrariness: if a principle comes from the subjective preference of the Chief Something Officer or because it reflects the (dysfunctional) way the organization has always worked, designers will ignore it. Your principle can be otherwise perfect, but if its source is suspect, the team won’t take it seriously. The team’s participation in all discovery activities is crucial here, too. Since they helped with the research, they can also help with writing the principles. By participating in crafting principles, your team will internalize them. Seeing the principles later will trigger memories of user observations, which they can integrate into their work more readily. The Windows User Experience Design Principles came directly from research. In reading some of these principles, you can almost hear supporting quotes from users: Reduce concepts to increase confidence Small things matter, good and bad Be great at “look” and “do” Solve distractions, not discoverability UX before knobs and questions Personalization, not customization Value the lifecycle of the experience Time matters, so build for people on the go You might argue that these lack specificity. When you take into account the scope of the project, however—an entire operating system—they’re sufficiently provocative and inspirational. “Solve distractions, not discoverability” is a bold statement, offering clear opportunities to refine the design without dictating a particular solution. It opens up conversations, and steers them, too. Concepts and big ideas One of my favorite scenes in  , the television show about advertising agencies in the 1960s, is the pitch to Kodak at the end of the first season. Kodak is introducing a new product, a circular tray that makes it easy to store and show photographic slides. They call it “The Wheel,” admitting, “We know wheels aren’t seen as exciting technology.” Creative director Don Draper, the show’s main character, explains that this product isn’t about the technology: it’s about tapping into our memories and emotions. The agency then pulls the veil off their concept for the campaign: the carousel. By establishing a central concept, a team (whether in advertising or web design) has a singular source of inspiration, a template for considering ideas. And while principles can serve as guideposts, only a concept can establish a vision. With both of them in your toolkit, your team has a potentially interesting tension to draw from. Using a carousel to describe a slide projector creates a metaphor brimming with meaning and possibility. It shows two ways we can express a big idea:  carousels evoke the joy of reliving happy memories.  the spinning carousel mimics storing and displaying photographic slides from a wheel. Either approach can help us express the big idea behind our digital products and websites. (Though I’ve never worked on a project that gave us a central concept as elegant as the carousel, which employs both approaches!) How the product makes you feel The purpose and function of interactive products offer ripe opportunities for metaphors, but metaphor isn’t the only way to express a central concept. For one web application project, my team expressed the essence with the phrase, “Power with flexibility.” Doesn’t quite roll off the tongue like the word carousel, but it evoked the desired feeling: that the app should make users feel like they can do anything. We elaborated with descriptions of how people would experience unconstrained power with the product: Provide users up-to-date status so they feel in control Lower barriers to entry Allow different styles of creating new content We also described what “Power with flexibility” meant from the user’s perspective:  having the right data to shed light on immediate needs  being able to provide answers to stakeholders immediately  getting up to speed on a crucial tool right away  being able to fine-tune their content to suit different needs in different situations  seeing the application as an extension of one’s own thought process Since this essence was a succinct idea, a little elaboration helped it to resonate with both the client and the project team. How the product works Complex interactive products benefit from a central idea that describes how they work. This usually means employing a big idea to convey the underlying structure.  , for example, is a popular metaphor used on ecommerce sites. You could use it even if you weren’t working on an ecommerce site. The idea of “adding stuff to the cart” is a familiar metaphor that conveys a site’s underlying structure. We even relied on this metaphor on our career-guidance site: students would “add careers to their cart” after taking an assessment. There are a few other tried-and-true frameworks for describing the structure of a website. For web applications, there are two common ones beyond the shopping cart:  This is perhaps the most common pattern for structuring a website or digital product. The hub-and-spoke metaphor implies that the web application has a central screen, from which users may trigger all other functions.  Another typical approach consists of a list of items from which users can select for more detail—like your email inbox. Do you have to use one of these structures? Of course not. But if your site lends itself to one of these approaches, you have your   that the rest of the functionality revolves around. (That wasn’t a carousel reference. I promise.) For sites that focus on delivering content (rather than transactional functionality), the tried-and-true frameworks deal more with how the content is organized:  what the content is about, or the subject matter  what tasks the content supports (like researching products versus troubleshooting products) These aren’t the only structures for categorizing content, but they are my go-to starting points. None of these is a fully fledged design in and of itself. They are well-understood frameworks that serve as the backbone to a much larger design. They are big ideas that describe how the product works. You don’t have to rely on an abstraction or metaphor (like the carousel) to convey the big idea, but instead draw from the emerging library of understood frameworks. That they are becoming part of web design lingo is a testament to their power and flexibility. There’s more where that came from! Check out the rest of   at  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/practical-grid/", "title": "Practical CSS Grid: Adding Grid to an Existing Design", "content": "Understanding and using CSS Grid is easier than you might expect. The day Grid support shipped in Firefox 52, I decided on the spur of the moment to convert the basic layout of   to use Grid. And it was a fairly simple process—five minutes to write the grid styles, then 15-20 spent troubleshooting. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Grid allows us to literally define column and row grid lines, and then attach elements to those lines in any order we choose. That may sound like tables, but Grid is   much more than tables ever dreamed.  It means more responsive layouts, far more accessible documents, and far cleaner markup than even floats and positioning ever afforded us. It’s been decades since CSS first emerged, but it’s never contained a system anything like this. And Grid is already supported in both Chrome and Firefox, with Safari coming soon (its Technology Preview releases support Grid as of this writing). A new era in digital design is dawning  . The way things used to be Before we get to the Grid, allow me to take just a moment to explain the markup structure of meyerweb’s main pages, and the positioning-and-margins approach I’ve been using for, um, about 12 years now. Here’s how the markup is structured: Some of those IDs are idiosyncratic holdovers from my early-2000s view of layout and naming conventions.  , for example, is what most of us would call  .   stands in for  . And   is from the days before the actual   element The  s (which should probably be   these days, but never mind that now) are arranged the way they are so that if the CSS fails to load, or a speaking browser is used to browse the site, then the site’s masthead is first, the ability to search the site is second, and the main content of the page is third. After that, extra materials, site navigation, and the footer follow. All of these were stitched together into a layout by absolutely positioning the navigate and search  s. The sitemast was set to be   tall, and both the navigate and search  s were given   to show up just below it. In order to leave space for them to land, top margins were applied to the main and extra  s. ( ) Constructing the grid So that’s how things have been laid out since the middle of 2005, more or less. I fiddled with a flexbox layout at one point as an experiment, but never shipped it, because it felt clumsy to be using a one-dimensional layout tool to manage a two-dimensional layout. I probably should have converted the navigation bar to flexbox, but I got distracted by something else and never returned to the effort. Besides, Grid was coming. In the run-up to Grid support being released to the public, I was focused on learning and teaching Grid, creating test cases, and using it to build figures for publication. And then, March 7th, 2017, it shipped to the public in Firefox 52. I tweeted and posted   and   I’d put together the night before, and sat back in wonderment that the day had finally come to pass. After 20+ years of CSS, finally, a real layout system, a set of properties and values designed from the outset for that purpose. And then I decided, more or less in that moment, to convert my personal site to use Grid for its main-level layout. It took me less than five minutes to come up with the following: That’s not all I had to do, but it’s the core. Let me break it down for you. This part of the CSS sets the   element to be a   and sets up the grid lines. When you make an element a grid container, all of its children become  . (If you’ve worked with flexbox, then this pattern will be familiar to you.) So with that  , I turned all of the child  s into grid items. Next come the rows in the grid. The values in   actually define separation distances between grid lines (the same is true of  , which we’ll get to in a moment). So the value   means: “Go 192 pixels down from the top of the grid container and drop a grid line. Then drop another two such that they provide enough vertical space for the contents of the rows they define. Finally, leave one   (fraction) of distance between the third grid line and the bottom of the grid container.” ( ) The value   is pretty cool. It means just what it says: “Take up the minimum amount of space needed to fit the contents.” So for the second row, the one that will contain the navigation bar and search field, it will be as tall as the taller of the two, and no taller. Ditto for the third row, the one containing the main and extra  s. On the homepage, the main   will be taller. On subpages, that might not always be the case. In all circumstances, the row containing those two  s will always be tall enough to contain them both. With the rows figured out, next come the columns. I decided to keep things simple and just set up two. If you look at meyerweb’s home page, it appears to have three columns, but that’s only true of blog posts—a substantial but minority part of the site—and the left-side “column” is more of a sidebar inside the main column. In the original design, the sidebar ( ) is 18em wide, with some extra space to keep it away from the main column. But the column also has to fit the search box, which is a bit wider. After some experimentation, I settled on a width of  . The rest was left to flex as  . ( ) Now that I’ve used the   unit twice, a few words of explanation are in order.   stands for “fraction,” and means “a fraction of the available unconstrained space.” In this grid, there are two columns. One of them has an explicit width of  , which is thus  —there’s no room for flexibility. The rest of the column space is  —as the width of the grid container changes (say, due to changes of the browser window) the unconstrained space will change to be the container’s width minus the   of constrained space. Imagine for a moment I’d decided to split the grid into four columns, with the rightmost being   wide and the rest being equal, flexible widths. That would have looked like: Alternatively, I could have written it as: In any event, that would have caused the unconstrained space to be divided equally among the first three columns. If the grid container were   wide, the last column would be   wide, and the other three   each. (3 x 15 = 45; 45 + 20 = 65.) Shrink the grid container down   wide, and the first three columns would shrink to   each. In my case, I wanted that first column to take all of the space not given to the constrained last column, so it got  . The final result is shown in  . Placing the items With the grid lines set up, now it’s just a matter of attaching grid items to the grid lines. This can be done automatically, using the grid-flow algorithm, but this is a case where I want to place each item in a specific place. That leads to the following: For each of the six  s, I simply said, “Pin your top edge to this row line, and your left edge to this column line.” I used line numbers because that’s all I gave myself—it’s possible to assign names to grid lines, but I didn’t. (But stay tuned for an example of this, later in the article!) So, to pick one example, I set up the   portion to start on the third row line and the first column line. That means it will, by default, fill out the space from the first to second column lines, and from the third to fourth row lines. Almost all of the  s were set up in this way. The exception in this case is the  . It starts at the first column and row lines, but since I wanted it to go all the way across the grid, I set its column value to  . That means “Start at column line 1, and span across two columns.” I could have gotten the same result with the value  , which means “Go from column line 1 to column line 3.” ( ) But realize: that’s just a diagram, not the actual layout situation. Not yet, at any rate. \nSomething I want to be clear about here is that while you   explicitly assign all of your grid items to specific rows and columns, you don’t   to do so. Grid has a flow model that allows grid items to be automatically assigned to the next open grid cell, depending on the flow direction. In my case, I could have gotten away with literally just these rules: That would have ensured the masthead was two columns wide, and that the navigation   was placed in the exact grid cell I wanted. That would have left the second row’s first cell filled by navigation, and the rest of the grid cells open. Given that, the unassigned items would be flowed into the grid in source order. The masthead ( ) would be placed in the first two-column row it could find, which turns out to be the first row. The search   would flow into the next open cell, which is row 2, column 2, because row 2, column 1 is already occupied by the navigation  . After that, the main   would flow into the first open cell: row 3, column 1. Extra would go into the next cell: row 3, column 2. And then the footer would be placed into row 4, column 1. The end result would be exactly what’s shown in  . The difference would be that if I had a special page where another   was added, it could throw off the whole layout, depending on where it appeared in the HTML. By explicitly assigning my layout pieces to the places I want them, I prevent a stray element from upending everything. Given the styles I wrote, if a child element of the     added to a page, it will become a grid item. If I don’t give it an explicit place in the grid, it will end up flowed into the first available grid cell. Since the lower-right cell (row 4, column 2) is unoccupied, that’s where the extra element would be placed…assuming it isn’t set to span two columns. In that case, it would end up at the bottom of the grid, in an automatically-created fifth row. Accommodating the past It’s easy enough to set up a grid, but when you drop grid items into it, they bring all of their existing styles in with them. That might not be a big deal in some cases, but in mine, it meant all of the margins and padding I’d used to keep the layout pieces apart from each other were now messing with the placement of the grid items. You can see this in  , created using a local copy of the site. Ouch. It was time to override the pieces of the legacy layout styles I didn’t need in Grid, but did need to keep for browsers that don’t yet understand Grid. So I wrapped the whole bit in an   block. Since I wanted to constrain the grid layout to wider displays, I put an   block just inside  , and then proceeded to zero out or otherwise change the various margins and padding I didn’t need in a Grid context. Here’s how it turned out: I probably could refactor that to be more efficient, but for now, I’m going to leave it as-is. It makes clear what had to be done to which grid item—which ones needed to override   so their absolute positioning didn’t interact weirdly with the grid, which margins and padding needed to be changed, and so on. Let’s look at the end result ( ). You might be forgiven for thinking that this was much ado about not very much. Why go to all that effort just to make it look the same? The real power here, in what is admittedly a simple case, is how I no longer have to worry about overlap. The footer will always be below the main and extra  s, no matter which is taller. When I was using positioning, that was never guaranteed. Similarly, the navigation and search will always maintain a shared height, making sure neither will overlap with the content below them—and thanks to  , I don’t have to guess at how tall they might get. Grid just handles all that for me. And remember, the layout still functions in old browsers just as it always did, using positioning. I didn’t “break” the site for browsers that don’t understand Grid. The more capable Grid layout is there, waiting for browsers like Chrome and Firefox that understand it. If you want to see all this live for yourself, head over to   and inspect elements in Firefox 52 or later. There you’ll see a little waffle icon next to the   declaration on the   element. Click it, and Firefox will draw the grid lines on the page for you to scrutinize. (You can also enable a more powerful layout tool in Nightly builds of Firefox; see my post “   ” for details.) Naming conventions I mentioned earlier that it’s possible to name grid lines. I didn’t do it for my own styles because the grid I defined was so simple, but for more complicated grids, naming the lines might be useful. Using the stripped-down version of the styles, the one without all the legacy overrides, naming the grid lines would look something like this: Each of those square-bracketed words is assigned as a name to the corresponding grid line. ( ) Once those names are defined, you can refer to them in your   and   properties. For example: Much like class names, you can assign multiple names to a grid line by supplying a space-separated list. Try this one for size: You can then refer to any one of those names in your   declaration. There’s no defined limit on the number of names, but remember what comes with great power. In case you were wondering, you can mix grid line names and numbers, so something like   is completely fine. You can use any name the browser can parse, which means you can specify just about anything Unicode and your CSS file’s character encoding will allow. Grid and Flexbox A question you may have is:   Absolutely not! The two can and do work very well together. Consider the navigation bar of my design. For years, it’s been laid out using an unordered list and   for the list items. Simplified a bit, the CSS and markup looks like this: Why not   instead of  ? Because that literally wasn’t an option when I wrote the CSS for the navlinks, and I never got around to updating it. (You may be sensing a theme here.) Now I have two much better options for arranging those links: Grid and Flexbox. I could define a grid there, which would go something like this: That would essentially get the same result, only in a grid, which is far more robust than either floats or inline blocks. On the other hand, I’d be using Grid, which is a two-dimensional layout system, for a one-dimensional piece of layout. It’s certainly possible to do this, but it feels a little like overkill, and it’s not really what Grid was designed to do. Flexbox, on the other hand, is designed for exactly these kinds of situations. So I might write the following instead: Again, that would be basically the same result, but in a more robust fashion. In addition to keeping the links all lined up, the   value will let the links go to a second line if need be. And because the flexbox sits inside a grid item that’s part of a grid row whose height is  , any increase in height (due to line wrapping or whatever) will cause the entire row to become taller. That means the rows after it will move down to accommodate it. And now that I look at the markup again, I’ve realized I can simplify that markup without needing to touch any grid styles. Instead of wrapping a list with a  , I can drop the   and reassign its ID to the list. So the markup can become: After adjusting the selectors in my CSS from   to  , the resulting layout will be exactly as it was before. The   will become a grid item and a flex container. That is a thing you can do. The downside in my case would be dealing with any interactions between that change and my legacy layout, but it’s not a huge issue to solve. It’s just a matter of doing it. Letdowns So what are the down sides?  Not many, but they do exist. Most fundamentally, there’s no way to define an overall page grid that has all items relate to it. In other words, if I say: …then that sets up a 16-column flexible grid for the   element only, and its child elements are the only ones that can become grid items. I can’t reach down into the document tree and assign elements to be placed on that   grid. That’s the main reason I didn’t try to put the little sidebar bits on my blog posts into a shared grid: I literally can’t, at this point, unless I resort to ugly CSS or HTML hackery. The capability to do such things is known as  , and it hasn’t been implemented by any browsers as yet. There are questions as to exactly how it should or shouldn’t work, so there’s still plenty of hope that everything will work out in the end. It’s a disappointment that we don’t have it yet, and that lack restricts the full range of grid’s power, but hopefully only for a short while. In the meantime, I’m sure people will come up with ways to work around this limitation. A basic workaround in this case: I could define a grid that applies to every blog post individually, and arrange the pieces of each post on those nested grids. The CSS would look something like: With that, I could place the metadata, the title, and the post’s body text into the defined grid cells, using either grid line numbers or the grid names I set up. Something like: The drawback is that the metadata is then constrained to be a specific width, instead of my being able to set a column that all metadata shares, and size it by the longest bit of content.  That’s no worse than right now, where I’m setting the floated metadata to an explicit width, so this doesn’t lose me anything. It’s just a (temporarily) missed opportunity to gain something. Another limitation, one that may or may not be addressed, is that you cannot directly style grid cells. Suppose I’d wanted to put a box around the   sidebar, completely filling out that cell. I’d have to style the  . I can’t do something like this: I mean, I’m not even sure the syntax would look anything like that (probably not), and this sort of capability is only now starting to be debated by the Working Group. If you have use cases for this sort of capability, definitely share them with the world and the folks at  . The more real-world cases there are, the stronger the case for supporting them. And there will, inevitably, be bugs to fix. For example, as I was finishing this article, I discovered that in some situations, Chrome 57 can suffer from   when using Grid. It appears to be caused by having absolutely-positioned elements removed from a Grid page, and can be triggered by extensions like Window Resizer and LastPass. The good news is that a fix has been accepted for Chrome 58, so it should be fixed by the end of April 2017 at the latest. Grid power I hope this exploration of applying Grid to a live site has given you a taste of what’s possible. But I want to warn you that it’s just a taste, and a minor one at that. I was only able to scratch the surface of what the Grid syntax makes possible, so if this has captured your imagination, I strongly encourage you to experiment and then to dive into the Grid specification to see what else is possible. (Grid gaps! Dense grid packing! Inline grids! Auto-filling rows and columns!) But even more, what I explored here was the barest wrinkle on the outer edges of a scratch on the surface of everything that Grid will make possible. Sure, it can make our existing designs more flexible, robust, and simple to maintain. That’s pretty great. It also makes possible layouts we’ve never even dreamed of, because they were impossible given the tools we had available. There are new techniques, even new art movements, waiting to be discovered. We haven’t experienced a phase shift this profound since the original move from tables to CSS. I hope you’ll be a part of exploring this new realm. Resources As I said, this is at best an introduction. Want to know more? Here are some great resources to get you going:  — a collection of experiments and examples, ranging from the utilitarian to the wildly artistic  — a central hub for 11 articles by Rachel Andrew, written for the Mozilla Developer Network  — Rachel Andrew’s collection of examples, tutorials, and videos  — a great look at the union of these two layout techniques by Chen Hui Jing\n Like this: \n\t\t\t\t\t\t\tRecently by  Eric Meyer\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/widen-out-using-your-blog-to-attract-new-clients/", "title": "Widen Out: Using Your Blog to Attract New Clients", "content": "Attracting future clients on autopilot—that’s the whole point of your website, right? Most freelancers accept the story that great work attracts leads, but I’m going to be straight with you: clients have no clue you exist. What usually tips the balance isn’t your portfolio—they see plenty of those.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Not many people talk about failures they had promoting their products and services. We struggle and we hide it. It’s one of the reasons I hate to read marketing “success stories” and “How to drive traffic and make money!” posts—they seem hollow and vaguely manipulative. They also invariably circle around an answer we already know: The key to attracting non-referral clients is making it easy for them to discover you.  Simple as that is, we fail for two reasons:  Most freelancer websites are only concerned with showing portfolio work. We haven’t figured out who we want as clients, what makes them tick, or how they solve problems. We’re focused on  , not  .  Serving hits the ground running—it answers a question, solves a problem, satisfies a curiosity. There’s a difference between saying you will and  proving it with a real takeaway during the first impression. Portfolio-focused sites also don’t give Google much content to index and rank, lessening your chances of ever getting high in organic search results, much less on their radar.  Designers are “supposed” to do certain things to find clients. Well, I did all that, for years. And I had a pretty depressing success rate, considering how much time I put into it. Then I tried one thing that single-handedly turned around my freelance career. I started blogging with clients in mind. Do it your way Let me tell you about Brian Dean. Brian Dean of   gets 130,000 monthly uniques. Want know how many articles he has on his blog—in total?  30. That’s right, 30.  Readers aren’t coming because he publishes frequently—they’re coming because he writes about what they want to know and because every piece he’s got is the best on that given subject, hands down! He keeps visitors coming back to the same posts because he’s constantly improving the material little by little to ensure it’s always the best that’s out there. As people come across it—web professionals, curious readers, and potential clients—it’s building up his reputation and making it easier for people to find him via search and re-shared content links.  You don’t have to write regularly. Or much. And you don’t need an industry-rocking idea. With your expertise, you have what it takes to say something that other people consider valuable.  The key to success is making a target, then sticking it out for a few rounds of research + content creation + promotion to start. The more posts/articles you create, the more properties you have on the Monopoly board called Google. Having a few widely shared articles also kicks off a virtuous loop where all your subsequent articles get a jump start from your existing traffic. This approach is repeatable and scaleable.  (One quick heads-up: you can also expect your content to attract the “wrong type” of visitors, such as recruiters and people looking to hire someone for low-end, piecemeal work. It’s possible to turn these inquiries into opportunities by politely refusing their offer and asking if they know anyone who is seeking the type of work you do provide.) Pre-planning your content As you know, Google determines how high your page ranks for certain search terms based on factors like: Translating that, your goals are to:  Create content that is relevant to search terms visitors use Create high quality content that invites re-links and social shares Ensure that time-on-site for the specific piece of content is high. It may feel a bit unnatural to create content around ranking well on Google, but you’re actually just creating a really valuable article that answers all possible questions a reader is most likely to have about that topic.  Know what matters to clients Instead of randomly choosing a topic, it helps to be a bit strategic. After all, it’s a way to get discovered by the right people.  First, know—and learn how to write for—your intended audience. Almost any topic about your field would interest fellow professionals. But let’s recall, who is it you want to attract, first and foremost? Clients. So how do you find out what they’re searching for? When I started doing this, I began by listing questions a new client typically asks, such as: How much do your services cost? How does your [service] process work? To see the types of questions business owners and entrepreneurs ask most often, take a look at community sites where they hang out ( ). Good ones include: Based on the questions you find, you could brainstorm three topic ideas that relate to each one, or even split larger topics into separate articles. For example, instead of writing one giant piece on how much web design services cost, write about one service in each post, such as: How much does a landing page cost? How much does custom website cost? They should be written in the style of a comprehensive educational guide that teaches the visitor everything they need to know about the topic.    How much does logo design cost? This article could cover: The reason rates vary so much among designers The different types of designers they can hire (freelancer, agency, etc.) A description of the creative process for designing a logo. Write a better article Now that you’ve settled on a topic, it’s time to create a comprehensive leave-no-stone-unturned piece of content about it.  What’s “comprehensive”? It’s helpful to set a benchmark for yourself by researching other popular articles that have already been written about it. Use them as inspiration, then go and create an even better version. This both demonstrates your command of the topic and attracts links from relevant, high authority sites (which signals to Google that your site contains high quality content, triggering it to bump your page higher in the search results for those keywords). A popular tool for doing this research is  .  After you create an account, enter a topic you’re considering, then select “Traffic” in the   dropdown. ( ) Here are some of the highest trafficked articles on “web development cost.” ( ) Analyze each article and write down every single point that’s covered. Your goal is to be just as good when it’s your time to address each one. You’ll then brainstorm at least five original or interesting angles they didn’t mention or tackle extensively. This “value add” is your selling point when the time comes to start promoting the piece.  Another way to dig deep is to learn more about the authors. For instance, how does their expertise differ from yours? This can help you catch things they didn’t cover. You can also pull up every article a specific author has written on a subject, such as this   writing about “web development cost.” ( ) Other effective ways to juice up your content Use compelling (and/or controversial) examples Buttress each major point in your article with compelling (and if possible, controversial) case studies and examples.  For example, here’s an   for the London 2012 Olympics ( ). It explains why (despite the negative public reaction) the versatility and instant recognizability of the logo actually make it an example of great identity work.  Use visual assets with your article Visual assets make your article easier to read by breaking up chunks of text. For images, choose ones that instantly convey the emotion or message of a major point you make ( ). For infographics, choose ones that visually illustrate and compare data or statistics you mention in the article. A good visual asset also attracts social shares.  Interview someone interesting (and influential) Seek out people who can contribute an interesting insight or experience related to your topic. Not only does this add perspective to your article, you can ask this person to share the article with their audience (which may give you a nice traffic boost). Capture every question Before you start writing, make a list of every single possible question someone could have about this topic. Based on your research of existing articles, also include details and angles they don’t.  For example, if you’re writing an article about logo cost, details and angles that many other articles miss are: Reasons why corporate logo designs cost so much The psychology behind how logos affect brand perception  Conversion stats before and after logo redesigns Why negative public reactions don’t necessarily mean the logo design is bad. Add a call to action Avoid losing potential clients who would have contacted you later—if they hadn’t forgotten. Add something encouraging them to act right away by making it a simple click, such as a call to action (CTA) banner in every article. ( ) Promoting your article the right way Promoting your content may feel uncomfortable, but it’s important to reframe that in your mind. Instead of  “Marketing your content,” you’re “Helping people by educating and inspiring them with your well-researched, well-written information.”  Clients who don’t know about your site won’t magically enter your URL into their address bar—they have to discover you through some other source (other websites, search engines, social media). That’s why promotion and outreach are so important, and why it pays off to ask other sites to link to your content. To kick off the first wave of traffic, it helps to win a few links and social shares. From there, the new people who discover your post may also link to or share it (which in turn boosts your article’s ranking on Google). Let’s look at a few effective ways you can promote your content. Offer your actual article as a service This is  —one my very good friend and coach Brian Harris wrote about on his blog. I like to alter the technique just slightly, but here’s what to do:  Take the URL of one of the articles you found in the previous section (when you were choosing a topic to write about). Try to pick the one with the most shares.  Go to   and enter the URL to the article (use the 14-day free trial they offer to do this step).  In my case, I chose this SEO techniques article because I’m looking for clients who might be interested in my SEO consulting. ( ) Next, click the “View Shares” button to see a list of everyone who shared the post on Twitter. You can then click on the “Followers” filter at the top left to sort by users who have a sizable audience (i.e. enough money to pay you for a service). ( ) Now you have a list of people who have already shown an interest in the topic, you could reach out to them individually and see if they’d be interested in sharing yours, as well. The following example highlights a number of points.  Subject: Re: Brian’s article you shared \nBody Text: Hey AJ, I’ve been following you since last January when I saw you share Brian Dean’s article on SEO techniques. Great article, I truly enjoyed it! I couldn’t help but notice that it did not include how to convert the traffic you get from these techniques into actual leads. I’ve done SEO and lead nurturing work for 9+ years .  I just recently published a more comprehensive post on how to do everything Brian talks about as well as lead nurture and convert the traffic into actual leads, so I wanted to run this by you since you’re interested in the topic. I took a look at Wordtastic <insert their company name here>—love the app. I checked and it looks like you get a decent amount of traffic.  I came up with three ways you can improve your calls to action to get more conversions every single day (based on Brian’s advice compiled with my article above) Here is the link to the recommendations, a potential campaign, and some projected results once you implement this: [link to Google doc you put together that will blow their socks off] Would love to help you guys implement some of these strategies. -Dmitry (I’ve collected examples that seem to work really well for people; you can check out those posts here:   and  .) Join some groups where your potential clients hang out I listed these community groups earlier, but it’s worth mentioning them twice: Don’t just join—leave meaningful comments. If you do that, most groups will start to see you as a valued contributor and won’t bat an eye if you to post something that mentions your own content once in a while, like this example from a private entrepreneur group ( ) When you do share, be sure to mention a few points you’ve covered that would be highly relevant and valuable to that community.  For example, if you write an article about web design, a business community may be most interested in how to evaluate web designers in order to find one that’s reliable. Conversely, a marketing community may be most interested in how to design funnels that convert more visitors into subscribers and customers.  You can also ask a question related to your article topic to kickstart a discussion, then offer to answer any questions a group member may have. Share your links with family and friends The easiest, non-intrusive way to do this is by posting it on your Facebook feed. Add a description highlighting a few points a general audience would find interesting and worth the effort of clicks and likes. Add interesting visuals to illustrate your points Add relevant illustrations and pictures throughout your article to break up the text and keep your visitors engaged. Bonus points: use relevant visuals from your own portfolio so it does double duty prettifying your article and showcasing your skills. Improve your search ranking with some SEO basics Focus on   search keyword or phrase you want your article to rank for, then use different variations of it throughout your article, especially in your article headline and section headings.  Make sure your pages and articles load fast; you might consider caching your pages with something like   (they offer a free plan) to speed up load time. (CloudFlare shows cached versions of your files and images so visitors don’t have to wait for them to load real-time from your servers.) Compile a list of relevant sites to ask for links Remember how you looked up the most popular articles on Topic X? If you find out which sites link to those articles, why not ask them to link to your (much improved) version, too?!  Use a backlink checker tool such as   or  . ( ) Go to each site and find the names of either the site owner or, if it’s a company, the person in charge of marketing.  To find their email address, enter their site domain into   or  . These sites will tell you the most likely email format (for example: firstname@company.com). Based on the most common email format the site or company uses, you can “smart guess” the likely email of the person you wish to contact. You can send them a personalized version of this template  to ask if they may be interested in linking to your article: Hey [Name],  I was searching for some articles about [Your topic] today and I came across yours: [URL] I noticed that you link to [Article Title] – I just published something similar that [2 major points why it’s better]: [url of your article] May be worth a mention on your page.  Either way, keep up the awesome work!  Remember that infographic I mentioned earlier, the one you could create to accompany your article? You can also ask some of the other sites you found in the Backlinks tab to include it in one of their existing or future articles and credit you (earning you a link this way). Here’s the template link Luke from   used:  Hey [First Name], I really liked your article on [relevant topic to your article]. Great stuff! You actually inspired me to take this a step farther and create something even deeper. I thought I’d reach out to you because I just published an infographic on [topic] and I thought it might interest you. It covers [list of major points, stats or facts.] It’s all based on research, and I have the sources to back it up. Love to see if you may find it a good addition to your article.  Promote it in relevant Facebook groups If you develop websites (for example), find Facebook groups that discuss web development, have 500+ members, and show signs of recent activity. For a few weeks, post meaningful comments every once in a while and start interesting discussions to provide value to the community. If the group guidelines allow it—and if the timing is right—share your own article now and then, but make sure you ask a question in your post to spark a discussion. This will help the post stay on top of the group feed and members’ newsfeeds to bring you more traffic.  Content creates visibility outside your network It’s becoming tougher and tougher to stand out these days—there’s a lot of noise online. For a lot of freelancers and part time contractors, DIY service platforms and online hiring marketplaces have become the status quo for finding gigs. The quality of clients drawn to these hubs is very mixed, unfortunately, and most come because they want to pay as little as possible for the work. It is also very challenging for freelancers who don’t already have a presence there to start gaining leads right away.  Freelancers relying on word of mouth referrals also run into pitfalls. Nurturing those opportunities can be just as time intensive, not to mention leave you with limited control over when they actually convert into meaningful business. These conditions should prompt every freelancer to try something outside the box, to find uncrowded spaces for meeting and gaining clients. Strategically creating content can consistently attract the right kind of client. When a prospective client reads your article, she’ll learn something immediately useful from you and see you as a knowledgeable pro, which creates a solid start for a client-freelancer relationship.  It’s a way for you to have something in common, something to prompt a conversation. Imagine yourself at a conference talking to a person you just met—would you rather discuss an article you wrote or dive straight into discussing your hourly rate? Of course you’ll want to show off your know-how before you talk about prices!  Writing content to attract customers is a perfect strategy for this—it engages people and generates higher visibility for your work, both within and outside your network. Ok, I’ll hand this off to you now; it’s your turn to do the research and write one article in the next three weeks. That’s my challenge to you. One article in the next three weeks on your site. Are you up for the challenge?  Post in the comments which topic you would like to write and I’ll comment back with my feedback and thoughts.  Ready? Get set. Go. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/awaken-the-champion-a-b-tester-within/", "title": "Awaken the Champion A/B Tester Within", "content": "Athletes in every sport   to help them win. They use cameras, sensors, and wearables to optimize their caloric intake, training regimens, and athletic performance, using data and exploratory thinking to refine every advantage possible. It may not be an Olympic event (yet!), but A/B testing can be dominated the same way. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I talked to a website owner recently who loves the “always be testing” philosophy. He explained that he instructs his teams to always test  —the message, the design, the layout, the offer, the CTA.  I asked, “But how do they know what to pick?” He thought about it and responded, “They don’t.” Relying on intuition, experienced as your team may be, will only get you so far. To “always test something” can be a great philosophy, but testing for the sake of testing is often a massive waste of resources—as is A/B testing without significant thought and preparation.   Where standard A/B testing can answer questions like “Which version converts better?”   gives you something more important—a framework to answer questions like “  did the winning version convert better?” Changing athletes, or a waste of resources? Typical A/B testing is based on algorithms that are powered by data   the test, but we started trying a different model on our projects here at Clicktale, putting heavy emphasis on data before, during, and after the test. The results have been more interesting and strategic, not just tactical. Let’s imagine that Wheaties.org wants to reduce bounce rate and increase Buy Now clicks. Time for an A/B test, right? The site’s UX lead gets an idea to split test their current site, comparing versions with current athletes to versions featuring former Olympians.  But what if your team monitored in-page visitor behavior and saw that an overwhelming majority of site visitors do not scroll below the fold to even notice the athletes featured there? Now the idea of testing the different athlete variants sounds like a waste of time and resources, right? But something happens when you take a different vantage point. What if your team watched session replays and noticed that those who do visit the athlete profiles tend to stay on the site longer and increase the rate of “Buy Now” clicks exponentially? That may be a subset of site visitors, but it’s a subset that’s working how you want.  If the desired outcome is to leverage the great experiences built into the pages, perhaps it would be wise to bring the athlete profiles higher. Or to A/B test elements that should encourage users to scroll down. In our experience, both with A/B testing our own web properties and in aggregating the data of the 100 billion in-screen behaviors we’ve tracked, we know this to be true: testing should be powerful, focused, and actionable. In making business decisions, it helps when you’re able to see visual and conclusive evidence. Imagine a marathon runner who doesn’t pay attention to other competitors once the race begins. Now, think about one who paces herself, watches the other racers, and modifies her cadence accordingly. By doing something similar, your team can be agile in making changes and fixing bugs. Each time your team makes an adjustment, you can start another A/B test … which lets you improve the customer experience faster than if you had to wait days for the first A/B test to be completed.  The race is on Once an A/B test is underway, the machines use data-based algorithms to determine a winner. Based on traffic, conversion rate, number of variations, and the minimum improvement you want to detect, the finish line may be days or weeks away. What is an ambitious A/B tester to do? Watch session replay of each variation immediately, once you’ve received a representative number of visitors. Use them to validate funnels and quickly be alert to any customer experience issues that may cause your funnels to leak. Focus on the experience. Understanding   user behavior dominates each page is powerful, internalizing   users are behaving as they are enables you to take corrective actions mid-course and position yourself properly. The next test In your post-test assessments, again use data to understand   the winning variation succeeded with its target audience. Understanding the reason can help you prioritize future elements to test. For example, when testing a control with a promotional banner (that should increase conversions) against a variation without a promotion, a PM may conclude that the promotion is ineffective when that variation loses. Studying a heatmap of the test can reveal new insights. In this example, conversions were reduced because the banner pushed the “buy now” CTA out of sight.  In this case, as a next test, the PM may decide not to remove the banner, but rather to test it in a way that keeps the more important “buy now” CTA visible. There is a good chance such a combination will yield even better results. There are plenty of other examples of this, too. For instance, the web insights manager at a credit card company   that having the aggregate data, in the form of heatmaps, helps him continually make more informed decisions about this A/B testing. In their case, they were able to rely on data that indicated they could remove a content panel without hurting their KPIs.  Another one of our customers, GoDaddy, was able to increase conversions on its checkout page by four percent after running an A/B test. “With our volume, that was a huge, huge increase…. We also tripled our donations to Round Up for Charity,”   Ana Grace, GoDaddy’s director of ecommerce, global product management. But the optimization doesn’t stop once a test is complete; GoDaddy continues to monitor new pages after changes, and sometimes finds additional hypotheses that require testing.  What it takes to go for the gold I was not blessed with the natural athletic ability of an Olympian, but when it comes to A/B testing web assets and mobile apps, I have what I need to determine which version will be the winner. The powerful combination of behavioral analytics and big data gives athletes the knowledge they need to make the most of their assets, and it can do the same for you. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/let-emotion-be-your-guide/", "title": "Let Emotion Be Your Guide", "content": "We were sitting in a market research room in the midst of a long day of customer interviews. Across from us, a young mother was telling us about her experience bringing her daughter into the ER during a severe asthma attack. We had been interviewing people about their healthcare journeys for a large hospital group, but we’d been running into a few problems. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. First, the end-goal of the interviews was to develop a strategy for the hospital group’s website. But what we’d discovered, within the first morning of interviews aimed at creating a customer journey map, was that hospital websites were part of no one’s journey. This wasn’t wildly surprising to us—in fact it was part of the reason we’d recommended doing customer journey mapping in the first place. The hospital had a lot of disease content on their site, and we wanted to see whether people ever thought to access that content in the course of researching a condition. The answer had been a resounding no. Some people said things like, “Hmm, I’d never think to go to a hospital website. That’s an interesting idea.” Others didn’t even know that hospitals had websites. And even though we’d anticipated this response, the overwhelming consistency on this point was starting to freak out our client a little—in particular it started to freak out the person whose job it was to redesign the site. The second issue was that our interviews were falling a little flat. People were answering our questions but there was no passion behind their responses, which made it difficult to determine where their interactions with the hospital fell short of expectations. Some of this was to be expected. Not every customer journey is a thrill ride, after all. Some people’s stories were about mundane conditions.  , was one story. Another was from someone with strep throat. We didn’t expect much excitement from a story about strep throat, and we didn’t get it. But mixed in with the mundane experiences were people who had chronic conditions, or were caregivers for children, spouses, or parents with debilitating diseases, or people who had been diagnosed with cancer. And these people had been fairly flat as well. We were struggling with two problems that we needed to solve simultaneously. First: what to do with the three remaining days of interviews we had lined up, when we’d already discovered on the morning of day one that no one went to hospital websites. And second: how to get information that our client could really use. We thought that if we could just dig a little deeper underneath people’s individual stories, we could produce something truly meaningful for not only our client, but the people sitting with us in the interview rooms. We’d been following the standard protocol for journey mapping: prompting users to tell us about a specific healthcare experience they’d had recently, and then asking them at each step what they did, how they were feeling and what they were thinking. But the young mother telling us about her daughter’s chronic asthma made us change our approach. “How were you feeling when you got to the ER?” we asked. “I was terrified,” she said. “I thought my daughter was going to die.” And then, she began to cry. As user experience professionals we’re constantly reminding ourselves that we are not our users; but we are both parents and in that moment, we knew exactly what the woman in front of us meant. The entire chemistry of the room shifted. The interview subject in front of us was no longer an interview subject. She was a mother telling us about the worst day of her entire life. We all grabbed for the tissue box, and the three of us dabbed at our eyes together. And from that point on, she didn’t just tell us her story as though we were three people sitting in front of a two-way mirror.  She told us her story the way she might tell her best friend. We realized, in that interview, that this was not just another project. We’ve both had long careers in user research and user experience, but we’d never worked on a project that involved the worst day of people’s lives. There might be emotion involved in using a frustrating tool at work or shopping for the perfect gift, but nothing compares to the day you find yourself rushing to the emergency room with your child. So we decided to throw out the focus on the hospital website, concentrate on where emotion was taking us, and trust that we would be able to reconcile our findings with our client’s needs. We, as human beings, wanted to hear other human beings tell us about the difficulties of caring for a mother with Alzheimer’s disease. We wanted to know what it felt like to receive a cancer diagnosis after a long journey to many doctors across a spectrum of specialties. We wanted to understand what we could do, in any small way, to help make these Worst Days minutely less horrible, less terrifying, and less out-of-control. We knew that the client was behind the two-way mirror, concerned about the website navigation, but we also knew that we were going to get to someplace much more important and meaningful by following wherever these stories took us. We also realized that not all customer journeys are equal. We still wanted to understand what people’s journeys with strep throat and weird hand rashes looked like, because those were important too. Those journeys told us about the routine issues that we all experience whenever we come into contact with the medical establishment—the frustration of waiting endlessly at urgent care, the annoyance of finding someone who can see you at a time when you can take off from work, the importance of a doctor who listens. But we also wanted to get to the impassioned stories where the stakes and emotions were much higher, so we adjusted our questioning style accordingly. We stuck to our standard protocol for the routine medical stories. And for the high-stakes journeys, the ones that could leave us near tears or taking deep breaths at the end of the interview, we proceeded more slowly. We gave our interview subjects room to pause, sigh, and cry. We let there be silence in the room. We tried to make it not feel weird for people to share their most painful moments with two strangers. When we completed our interviews at the end of the week, we had an incredibly rich number of stories to draw from—so many, in fact, that we were able to craft a digital strategy that went far beyond what the hospital website would do. (  We kept saying to ourselves.  ) We realized that in many ways, we were limiting ourselves by thinking about a website strategy, or even a digital strategy. By connecting with the emotional content of the conversations, we started to think about a   strategy—one that would be medium-agnostic. In  , Aarron Walter encourages us to “think of our designs not as a façade for interaction, but as people with whom our audience can have an inspired conversation.” As we moved into making strategic recommendations, we thought a lot about how the hospital (like most hospitals) interacted with their patients as a bureaucratic, depersonalized entity. It was as though patients were spilling over with a hundred different needs, and the hospital group was simply silent. We also thought about what a helpful human would do at various stages of the journey, and found that there were multiple points where pushing information out to customers could make a world of difference. We heard from people diagnosed with cancer who said, “After I heard the word ‘cancer’ I didn’t hear anything else, so then I went home and Googled it and completely panicked.” So we recommended that the day after someone gets a devastating diagnosis like that, there is a follow-up email with more information, reliable information resources, and videos of other people who experienced the same thing and what it was like for them. We heard from people who spent the entire day waiting for their loved ones to get out of surgery, not knowing how much longer it would take, and worried that if they stepped out for a coffee, they would miss the crucial announcement over the loudspeaker. As a result, we proposed that relatives receive text message updates such as, “Your daughter is just starting her surgery. We expect that it will take about an hour and a half. We will text you again when she is moved to the recovery room.” The stories were so strong that we believed they would help our client refocus their attention away from the website and toward the million other touchpoints and opportunities we saw to help make the worst day of people’s lives a little less horrible. And for the most part, that is what happened. We picked a few journeys that we thought provided a window on the range of stories we’d been hearing. As we talked through some of the more heart-rending journeys there were audible gasps in the room: the story of a doctor who had refused to see a patient after she’d brought in her own research on her daughter’s condition; a woman with a worsening disease who had visited multiple doctors to try to get a diagnosis; a man who was caring for his mother-in-law, who was so debilitated by Alzheimer’s that she routinely tried to climb out the second floor bedroom window. In  , Sarah Wachter-Boettcher and Eric Meyer note that “the more users have opened up to you in the research phase” the more realistic your personas can be. More realistic personas, in turn, make it easier to imagine crisis points. And this was exactly what began to unfold as we shared our user journeys. As we told these stories, we felt a shift in the room. The clients  started to share their own unforgettable healthcare experiences. One woman pulled out her phone and showed us pictures of her tiny premature infant, wearing her husband’s wedding ring around her wrist as she lay there in an incubator, surrounded by tubes and wires. When we took a break we overheard a number of people on the client side talking over the details of these stories and coming up with ideas for how they could help that went so beyond the hospital website it was hard to believe that had been our starting point. One person pointed out that a number of journeys started in Urgent Care and suggested that perhaps the company should look at expanding into urgent care facilities. In the end, the research changed the company’s approach to the site. “We talked about the stories throughout the course of the project,” one of our client contacts told me. “There was so much raw humanity to them.” A year after the project wrapped up (even though due to organizational changes at the hospital group our strategy recommendations have yet to be implemented), our client quickly rattled off the names of a few of our customer types. It is worth noting, too, that while our recommendations went much farther than the original scope of the project, the client appreciated being able to make informed strategic decisions about the path forward. Their immediate need was a revamped website, but once they understood that this need paled in comparison to all of the other places they could have an impact on their customers’ lives, they began talking excitedly about how to make this vision a reality down the road. For us, this project changed the way we conceptualize projects, and illustrated that the framework of a website strategy or even “digital” strategy isn’t always meaningful. Because as the digital world increasingly melds with the IRL world, as customers spend their days shifting between websites, apps, texting, and face-to-face interactions, it becomes increasingly important for designers and researchers to drop the distinctions we’ve drawn around where an interaction happens, or where emotion spikes. Before jumping in however, it is important to prep the team about how, and most importantly,   your interview questions probe into how customers are feeling. When you get into the interview room, coaxing out these emotional stories requires establishing emotional rapport quickly, and making it a safe place for participants to express themselves. Being able to establish this rapport has changed our approach to other projects as well—we’ve seen that emotion can play into customer journeys in the unlikeliest of places. On a recent project for a client who sells enterprise software, we interviewed a customer who had recently gone through a system upgrade experience which affected tens of thousands of users. It did not go well and he was shaken by the experience. “The pressure on our team was incredible. I am never doing that ever again,” he said. Even for this highly technical product, fear, frustration, anger, and trust were significant elements of the customer journey. This is a journey where a customer has ten thousand people angry at him if the product he bought does not perform well, and he could even be out of a job if it gets bad enough. So while the enterprise software industry doesn’t exactly scream “worst day of my life” in the same way that hospitals do, emotion can run high there as well. We sometimes forget that customers are human beings and human beings are driven by emotion, especially during critical life events. Prior to walking into the interview room we’d thought we might unearth some hidden problems around parking at the ER, navigating the hospital, and, of course, issues with the website content. But those issues were so eclipsed by all of the emotions surrounding a hospital visit that they came to seem irrelevant. Not being able to find parking at the ER is annoying, but more important was not knowing what you were supposed to do next because you’d just been told you have cancer, or because you feared for your child’s life. By digging deeper into this core insight, we were able to provide recommendations that went beyond websites, and instead took the entire human experience into account. For researchers and designers tasked with improving experiences, it is essential to have an understanding of the customer journey in its full, messy, emotional agglomeration. Regardless of the touchpoint your customer is interacting with, the emotional ride is often what ties it all together, particularly in high-stakes subject matter. Are your client’s customers likely to be frustrated, or are they likely to be having the worst day of their lives? In the latter types of situations, recognize that you will get much more impactful insights when you address the emotions head-on. And when appropriate, don’t be afraid to cry. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-coming-revolution-in-email-design/", "title": "The Coming Revolution in Email Design", "content": "Email, the web’s much maligned little cousin, is in the midst of a revolution—one that will change not only how designers and developers build HTML email campaigns, but also the way in which subscribers interact with those campaigns. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Despite the slowness of email client vendors to update their rendering engines, email designers are developing new ways of bringing commonplace techniques on the web to the inbox. Effects like animation and interactivity are increasingly used by developers to pull off campaigns once thought impossible. And, for anyone coming from the world of the web, there are more tools, templates, and frameworks than ever to make that transition as smooth as possible. For seasoned email developers, these tools can decrease email production times and increase the reliability and efficacy of email campaigns. Perhaps more importantly, the email industry itself is in a state of reinvention. For the first time, email client vendors—traditionally hesitant to update or change their rendering engines—are listening to the concerns of email professionals. While progress is likely to be slow, there is finally hope for improved support for HTML and CSS in the inbox.  Although some problems still need to be addressed, there has never been a better time to take email seriously. For a channel that nearly every business uses, and that   can’t live without, these changes signal an important shift in a thriving industry—one that designers, developers, and strategists for the web should start paying attention to.  Let’s look at how these changes are manifesting themselves.  The web comes to email It’s an old saw that email design is stuck in the past. For the longest time, developers have been forced to revisit coding techniques that were dated even back in the early 2000s if they wanted to build an HTML email campaign. Locked into table-based layouts and reliant on inline styles, most developers refused to believe that email could do anything more than look serviceable and deliver some basic content to subscribers.  For a few email developers, though, frustrating constraints became inspiring challenges and the catalyst for a variety of paradigm-shifting techniques.  for  , most people were just discovering responsive email design. Practices that were common on the web—the use of fluid grids, fluid images, and media queries—were still brand new to the world of email marketing. However, the limitations of some email clients forced developers to completely rethink responsive email.  Until recently, Gmail refused to support media queries (and most embedded styles), leaving well-designed, responsive campaigns looking disastrous in mobile Gmail apps. While their   to support responsive emails is a huge step forward for the community, the pioneering efforts of frustrated email developers shouldn’t go unnoticed. Building on the work first introduced by MailChimp’s  , people like   and   developed a set of techniques typically called  . Instead of relying on media queries to trigger states, hybrid emails are fluid by default, leaving behind fixed pixels for percentage-based tables. These fluid tables are then constrained to appropriate sizes on desktop with the CSS   property and conditional ghost tables for Microsoft Outlook, which doesn’t support  . Combined with  , hybrid coding is an effective way for email developers to build campaigns that work well across nearly every popular email client.  More recently, two other methods have emerged that address the issues with mobile email using more advanced techniques. Both Rémi Parmentier’s   and Stig Morten Myre’s   take the concept of mobile-first development so common on the web and apply it to email. Instead of relying on percentage-based fluid tables, both techniques take advantage of the CSS   function to determine table and table cell widths, allowing for more adaptable emails across a wide range of clients. And, in both cases, developers can largely drop the use of tables in their markup (save for Microsoft ghost tables), creating emails that hew closer to modern web markup.  Moving beyond responsive layouts, email designers are increasingly adding animation and interactivity to their campaigns, creating more engaging experiences for subscribers. Animated GIFs have long been a staple of email design, but CSS animations are becoming more prevalent. Basic transitions and stylistic flourishes like Email Weekly’s heart animation ( ) or Nest’s color-shifting background colors are relatively easy to implement, fall back gracefully when not supported, and give email designers more options to surprise and delight their audiences. Combined with the checkbox hack and Mark Robbins’s  , CSS animations allow email developers to create highly interactive experiences for the inbox. While earlier examples of interactivity were reserved for elements like product carousels, people like Robbins and the   team have started creating full-blown checkout experiences right in an email.  Interactivity doesn’t have to be reserved for viewing retail products, though. At Litmus, animations and interactivity were used to provide a full product tour inside of an email.  In this case, interactivity was used to provide product education, allowing users to experience a product before they even got their hands on it. While similar educational effects have been achieved in the past with animated GIFs, the addition of truly interactive elements created an experience that elevated it above similar campaigns.  Finally, the web’s focus on accessibility is cropping up in email, too. Both table-based layouts and inconsistencies in support for semantic elements across email clients have contributed to a near-complete lack of accessibility for email campaigns. Advocates are now speaking out and helping to change the way developers build emails with accessibility in mind.  The use of   on tables in email is becoming more widespread. By including   on table elements, screen readers recognize that those tables are used for layout instead of presenting tabular data and skip right to the content of the campaign.  Developers are also embracing semantic elements like proper headings and paragraphs to provide added value for people with visual impairments. So long as you are careful to override default margins on semantic, block-level elements, designers can safely use those elements without worrying about broken layouts. It is now something that every email developer should be doing.  Combined with email’s focus on alternative text—widely used to combat email clients that disable images for security reasons—accessible tables and semantic elements are laying the foundation for more usable, accessible email campaigns. There’s still a huge amount of research and education needed around accessibility in email, but the email world is slowly catching up to that of the web. All of these techniques, mostly commonplace on the web, are relatively new to the world of HTML email. Somes have been used on a limited scale, but they are on the verge of becoming mainstream. And, while animation and interactivity aren’t appropriate for every email campaign, they are valuable additions to the email toolbox. Taken together, they represent a massive shift in how developers and marketers approach HTML email and are changing the way subscribers think about the humble inbox.  Better tooling If anything can be considered a constant on the web, it’s that web designers and developers love building tools and frameworks to (in theory) improve their workflows and the reliability of their code. Just like accessibility and interactivity, this focus on tooling and frameworks has been making its way into the email industry over the past few years.  Instead of relying on individual, locally saved, static HTML files, many email developers are now embracing not only GitHub to host and share code, but complete build systems to compile that code, as well. Tools like Grunt and Gulp are now in wider use, as are static site generators like Middleman.  Being able to focus on discrete components means developers no longer have to update multiple HTML files when managing large email programs. For teams in charge of dozens, if not hundreds, of different email templates, this is a godsend. Updating a logo in one place and having it propagate across different campaigns, for example, saves tons of time.  The use of build tools also opens up the possibility of hyperpersonalized campaigns: emails with custom content and custom layouts on a per-subscriber basis. Allowing build systems to handle the compilation of individual modules means that those modules can be pieced together in a virtually unlimited number of ways based on conditions set at the beginning of the build process. This moves personalization in email beyond basic name substitutions and gives email marketers an unbelievably powerful way to connect with subscribers and provide way more value than your typical “batch and blast” campaign.  Likewise, more email developers are relying on preprocessors like Sass and Less to speed up the development workflow. Controlling styles through variables, mixins, and logic can be extremely powerful. While CSS post processors aren’t in wide use, a few savvy email developers are now starting to take advantage of upcoming CSS features in their campaigns.  Email developers and designers working with smaller teams, or those less familiar with advanced tools like preprocessors and build tools, now have a plethora of HTML email templates and frameworks at their disposal. They range in complexity from   that make customization easy to completely abstracted coding frameworks like   and Zurb’s  . Both MJML and Foundation for Emails 2 introduce their own templating languages, allowing email developers to use markup closer to that found on the web, which is then compiled into more complex, table-based HTML.  One area that still needs improvement is testing. While tools like Litmus have vastly improved the experience of testing static emails across clients, interactive emails present new challenges. Since testing services currently return static screenshots taken from the inbox, access to devices is crucial for teams working on interactive campaigns. Although a few people are coming up with novel approaches to testing interactive emails (most notably  ’s use of  ), tooling around interactive email testing will need to improve for more email developers to adopt some of the techniques I describe here.  A seat at the table Two of the most exciting developments in the email world are the recent Microsoft and Litmus partnership and Gmail’s announcement of support for media queries. Due to their typically abysmal support for HTML and CSS (especially the box model and floats), the many variations of Outlook have long been the biggest thorn in email developers’ sides. Outlook is the primary reason that emails use tables for layout.  Now, though, for the first time, Microsoft is   to the email community to document bugs and rendering problems in order to guide future development efforts and improve the rendering engines underpinning their email clients. While we’ll still have to rely on tables for the foreseeable future, this is a good indicator that the email community is moving closer to some form of standards, similar to the web in the early 2000s. I don’t think we’ll ever see standards as widely propagated across email clients as they are on the web, but this is the first step toward better HTML and CSS support for email developers.  One likely result of the Microsoft/Litmus partnership is that more email client vendors will open up lines of communication with the email design industry. With any luck, and a lot of work, Microsoft will be the first of many vendors to sit down at the table with email designers, developers, and marketers in order to improve things not only for email professionals, but also for the subscribers we serve. There are already signs that things are getting better beyond Microsoft’s promise to improve.  Gmail, one of the more problematic email clients, recently updated their rendering engine to support  —an unprecedented move from a team that is historically unsympathetic to the concerns of the email community. Email developers were in for an even bigger surprise from the Gmail team when they announced that they will be supporting media queries and embedded styles, too. While the hybrid coding approach mentioned earlier is still useful for addressing some email clients, this change means that it is now easier than ever to apply the principles of responsive web design—fluid grids, fluid images, and media queries—to HTML email campaigns.  Perhaps more interesting is Gmail’s added support for embedded CSS and element, class, and ID selectors. With this one change, embedded styles will be nearly universally supported—meaning that email designers will no longer be bound to inline styles and all the headaches they bring. Emails will now be easier to design, develop, and maintain. The lighter code base and more familiar style of writing CSS means that many of the blockers for web developers taking email seriously will be removed.  Beyond rallying around improved support for HTML and CSS, the email community itself is thriving. I remember the dark days—really only a few years ago—of email design, when it was extraordinarily difficult to find reliable information about how to build email campaigns, let alone connect with others doing the same. Today, people interested in email have a large and growing community to turn to for help. More marketers, designers, and developers are sharing their work and opinions, contributing to a discourse that is helping to shape the industry in new and interesting ways.  Perhaps more importantly, designers and developers are beginning to understand that working with email is a viable career option. Instead of relegating email to one more task as a web dev, many are now taking up the mantle of the full-time email developer.  Now’s the time Where once there was just darkness and Dreamweaver, the email world is brightening with the light of a growing community, better tools, and amazing techniques to animate a traditionally static medium. And, with the increasing support of email client vendors, we can finally see the flicker of email standards way off on the horizon.  While some folks have expressed emotions ranging from   to   when discussing email marketing, no one can take it for granted anymore. Subscribers love email, even if you don’t. Email is routinely the   digital marketing channel. Companies and teams need to embrace that fact and take email seriously. Fortunately, now’s the perfect time to do that. Never have there been more tools, resources, and people dedicated to making email better. The revolution in email is bound to be a slow one, but make no mistake: it’s coming. The web is leaking into the inbox. If you can’t keep up, your campaigns (and you) will be left behind. Like this: \n\t\t\t\t\t\t\tRecently by Jason Rodriguez\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/insisting-on-core-development-principles/", "title": "Insisting on Core Development Principles", "content": "The web community talks a lot about best practices in design and development: methodologies that are key to reaching and retaining users, considerate design habits, and areas that we as a community should focus on.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But let’s be honest—there are a lot of areas to focus on. We need to put users first, content first, and mobile first. We need to design for accessibility, performance, and empathy. We need to tune and test our work across many devices and browsers. Our content needs to grab user attention, speak inclusively, and employ appropriate keywords for SEO optimization. We should write semantic markup and comment our code for the developers who come after us. Along with the web landscape, the expectations for our work have matured significantly over the last couple of decades. It’s a lot to keep track of, whether you’ve been working on the web for 20 years or only 20 months. If those expectations feel daunting to those of us who live and breathe web development every day, imagine how foreign all of these concepts are for the clients who hire us to build a site or an app. They rely on us to be the experts who prioritize these best practices. But time and again, we fail our clients.  I’ve been working closely with development vendor partners and other industry professionals for a number of years. As I speak with development shops and ask about their code standards, workflows, and methods for maintaining consistency and best practices across distributed development teams, I’m continually astonished to hear that often, most of the best practices I listed in the first paragraph are not part of any development project  .  Think about that.  Development shops are relying on the communications team at a finance agency to know that they should request their code be optimized for performance or accessibility. I’m going to go out on a limb here and say that shouldn’t be the client’s job. We’re the experts; we understand web strategy and best practices—and it’s time we act like it. It’s time for us to stop talking about each of these principles in a blue-sky way and start implementing them as our core practices. Every time. By default. Whether you work in an internal dev shop or for outside clients, you likely have clients whose focus is on achieving business goals. Clients come to you, the technical expert, to help them achieve their business goals in the best possible way. They may know a bit of web jargon that they can use to get the conversation started, but often they will focus on the superficial elements of the project. Just about every client will worry more about their hero images and color palette than about any other piece of their project. That’s not going to change. That’s okay. It’s okay because they are not the web experts. That’s not their job. That’s your job.  If I want to build a house, I’m going to hire experts to design and build that house. I will have to rely on architects, builders, and contractors to know what material to use for the foundation, where to construct load-bearing walls, and where to put the plumbing and electricity. I don’t know the building codes and requirements to ensure that my house will withstand a storm. I don’t even know what questions I would need to ask to find out. I need to rely on experts to design and build a structure that won’t fall down—and then I’ll spend my time picking out paint colors and finding a rug to tie the room together.  This analogy applies perfectly to web professionals. When our clients hire us, they count on us to architect something stable that meets industry standards and best practices. Our business clients won’t know what questions to ask or how to look into the code to confirm that it adheres to best practices. It’s up to us as web professionals to uphold design and development principles that will have a strong impact on the final product, yet are invisible to our clients. It’s those elements that our clients expect us to prioritize, and they don’t even know it. Just as we rely on architects and builders to construct houses on a solid foundation with a firm structure, so should we design our sites on a solid foundation of code. If our work doesn’t follow these principles by default, we fail our clients So what do we prioritize, and how do we get there? If everything is critical, then nothing is. While our clients concentrate on colors and images (and, if we’re lucky, content), we need to concentrate on building a solid foundation that will deliver that content to end users beautifully, reliably, and efficiently. How should we go about developing that solid foundation? Our best bet is to prioritize a foundation of code that will help our message reach the broadest audience, across the majority of use cases. To get to the crux of a user-first development philosophy, we need to find the principles that have the most impact, but aren’t yet implicit in our process. At a minimum, all code written for general audiences should be: responsive accessible performant More specifically, it’s not enough to pay lip service to those catch phrases to present yourself as a “serious” dev shop and stop there. Our   shouldn’t simply adjust the flow and size of elements depending on device width—they also need to consider loading different image sizes and background variants based on device needs. Accessible coding standards should be based on the more recent   (Level AA) standards, with the understanding that coding for universal access benefits all users, not just a small percentage (coupled with the understanding that companies whose sites don’t meet those standards are being sued for noncompliance).   should think about how image sizes, scripts, and caching can improve page-load speed and decrease the total file size downloaded in every interaction. Do each of these take time? Sure they do. Development teams may even need additional training, and large teams will need to be prescriptive about how that can be integrated into established workflows. But the more these principles are built into the core functions of all of our products, the less time they will take, and the better all of our services will be. How do we get there? In the long run, we need to adjust our workflows so that both front-end and backend developers build these best practices into their default coding processes and methodologies. They should be part of our company cultures, our interview screenings, our value statements, our QA testing scripts, and our code validations. Just like no one would think of building a website layout using tables and 1px spacer images anymore (shout out to all the old-school webmasters out there), we should reach a point where it’s laughable to think of designing a fixed-width website, or creating an image upload prompt without an alt text field. If you’re a freelance developer or a small agency, this change in philosophy or focus should be easier to achieve than if you are part of a larger agency. As with any time you and your team expand and mature your skillsets, you will want to evaluate how many extra hours you need to build into the initial learning curves of new practices. But again, each of these principles becomes faster and easier to achieve once they’re built into the workflow.  There is a wealth of books, blogs, checklists, and how-tos you can turn to for reference on designing responsively, making sites accessible, and tuning for performance. Existing responsive frameworks can act as a starting point for responsive development. After developing the overarching layout and flow, the main speed bumps for responsive content arise in the treatment of tables, images, and multimedia elements. You will need to plan to review and think through how your layouts will be presented at different breakpoints. A tool like   can speed the process for external content embeds. Many accessibility gaps can be filled by using semantic markup instead of making every element a   or a  . None of the accessible code requirements should be time hogs once a developer becomes familiar with them.   provides an easy way for front-end developers to review their overall code style and learn how to adjust it to be more accessible by default. In fact, writing truly semantic markup should speed CSS design time when it’s easier to target the elements you’re truly focused on.  The more you focus on meeting each of these principles in the early stages of new projects, the faster they will become your default way of developing, and the time spent on them will become a default part of the process. Maintaining focus It’s one thing to tell your team that you want all the code they develop to be responsive, accessible, and performant. It’s another thing entirely to make sure it gets there. Whether you’re a solo developer or manage a team of developers, you will need systems in place to maintain focus. Make sure your developers have the knowledge required to implement the code and techniques that address these needs, and supplement with training when they don’t.  Write value statements. Post lists. Ask at every stage what can be added to the process to make sure these core principles are considered. When you hire new talent, you can add questions into the interview process to make sure your new team members are already up to speed and have the same values and commitment to quality from day one.  Include checkpoints within each stage of the design and development process to ensure your work continues to build toward a fully responsive, accessible, and performant end product. For example, you can adjust the design process to start with mobile wireframes to change team mindsets away from designing for desktop and then trying to backfill mobile and tablet layouts. Another checkpoint should be added when determining color palettes to test foreground and background color sets for  . Add in a step to run image files through a compressor before uploading any graphic assets. Ask designers to use webfonts responsibly, not reflexively. Set a  , and build in steps for performance checks along the way. Soon, your team will simply “know” which features or practices tend to be performance hogs and which are lean. You will need to make sure testing and code reviews look for these things, too.  Nothing worth doing happens by accident. Every time we overlook our responsibilities as designers and developers because it’s faster to cut corners, our products suffer and our industry as a whole suffers. As web professionals, how we work and what we prioritize when no one’s looking make a difference in thousands of little ways to thousands of people we will never meet. Remember that. Our clients and our users are counting on us. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/accessibility-whack-a-mole/", "title": "Accessibility Whack-A-Mole", "content": "I don’t believe in perfection. Perfection is the opiate of the design community. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Designers sometimes like to say that  . But defining design as problem-solving is of course itself  , which is perhaps nowhere more evident than in the realm of accessibility. After all, problems don’t come in neat black-and-white boxes—they’re inextricably tangled up with other problems and needs. That’s what makes design so fascinating: experimentation, compromise, and the thrill of chasing an elusive sweet spot. Having said that, deep down I’m a closet idealist. I want everything to work well for everyone, and that’s what drives my obsession with accessibility. Whose accessibility, though? Accessibility doesn’t just involve improving access for people with visual, auditory, physical, speech, cognitive, language, learning, and neurological difficulties— . Remember that in addition to those permanently affected, many more people experience temporary difficulties because of injury or environmental effects. Accessibility isn’t a niche issue; it’s an everyone issue. There are lots of helpful accessibility guidelines in Web Content Accessibility Guidelines (WCAG)  , but although   to better meet the complex needs of   users, there are no easy solutions. How do we deal with accessibility needs for which there are no definitive answers?  That’s a big question, and it’s close to my heart. I’m dyslexic, and one of the recommendations for reducing visual stress that I’ve found tremendously helpful is low contrast between text and background color. This, though, often means failing to meet  . Once you start really looking, you notice accessibility conflicts large and small cropping up everywhere. Consider: Designing for one-handed mobile use raises problems because right-handedness is the default—but 10 percent of the population is left handed. Giving users a magnified detailed view on hover can create a mobile hover trap that obscures other content. Links must use something other than color to denote their “linkyness.” Underlines are used most often and are easily understood, but they can interfere with   and make it harder for people to recognize word shapes.  You might assume that people experiencing temporary or long-term impairment would avail themselves of the same browser accessibility features—but you’d be wrong. Users with minor or infrequent difficulties may not have even discovered those workarounds. With every change we make, we need to continually check that it doesn’t impair someone else’s experience. To drive this point home, let me tell you a story about fonts. A new font for a new brand At  , we were simultaneously developing a new brand and redesigning our website. The new brand needed to reflect the amazing stuff we do at Wellcome, a large charitable organization that supports scientists and researchers. We wanted to paint a picture of an energetic organization that seeks new talent and represents broad contemporary research. And, of course, we had to do all of this without compromising accessibility. How could we best approach a rebrand through the lens of inclusivity? To that end, we decided to make our design process as transparent as possible. Design is not a dark art; it’s a series of decisions. Sharing early and often brings the benefit of feedback and allows us to see work from different perspectives. It also offers the opportunity to document and communicate design decisions.  When we started showing people the new website, some of them had very specific feedback about the typeface we had chosen. That’s when we learned that our new headline font,  , might be less than ideal for readers with dyslexia. My heart sank. As a fellow dyslexic, I felt like I was letting my side down. My entire career had been geared toward fostering accessibility,  . I’d been working on the site redevelopment for over a year. With clarity and simplicity as our guiding principles, we were binning jargon, tiny unreadable text, and decorative molecules. And now this. Were we really going to choose a typeface that undid all of our hard work and made it difficult for some people to read? After a brief panic, I got down to some research. So what makes type legible? The short answer is: there is no right answer. A baffling and often contradictory range of research papers exists, as do, I discovered, companies trying to sell “reasonably priced” (read: extortionate) solutions that don’t necessarily solve anything. Thomas Bohm offers  , and the British Dyslexia Association (BDA) has published  . The BDA guidelines on letterforms pretty much ruled out all of the fonts on our short list. Even popular faces like Arial and Helvetica fail to tick all the boxes on the BDA list, although  . And it’s not just dyslexia that is sensitive to typography; we recently had a usability testing participant who explained that some people on the autism spectrum struggle with certain fonts, too. And therein lies the problem: there’s a great deal of diversity within neurodiversity. What works for me doesn’t work for everyone with dyslexia; not everyone on the autism spectrum gives a flip about fonts, but some really do. At first my research discouraged and overwhelmed me. The nice thing about guidelines, though, is that they give you a place to start.  Progress Some people find fonts specifically designed for dyslexia helpful, but  . Personally, I find a font like   tricky to read; since our goal was to be as inclusive as possible, we ultimately decided that Open Dyslexic wasn’t the right choice for Wellcome. The most practical (and universal) approach would be to build a standards-compliant site that would  . And indeed, users should always be able to override styles. But although customization is great if you know what works for you, in my experience (as someone who was diagnosed with dyslexia quite late), I didn’t always know why something was hard, let alone what might help. I wanted to see if there was more we could do for our users. , our senior graphic designer, was already negotiating with the type designer (  of Alias) about modifying some aspects of Progress Two. What if we could incorporate some of the BDA’s recommendations? What if we could create something that felt unique and memorable, but was also more dyslexia friendly? That would be cool. So that’s what we set out to do. Welcome, Wellcome Bold When I first saw Progress Two, I wasn’t particularly keen on it—but I had to admit it met the confident, energetic aspirations of our rebranding project. And even though I didn’t initially love it, I think our new customized version, Wellcome Bold, has “grown up” without losing its unique personality. I’ve come to love what it has evolved into. We used the BDA’s checklist as a starting point to analyze and address the legibility of the letterforms and how they might be improved. Illusion number 1 If uppercase  , lowercase  , and numeral   look too similar, some readers might get confused. We found that the capital   and lowercase   of Progress Two weren’t distinct enough, so Hague added a little hook to the bottom of the  . Modern modem In some typefaces, particularly if not set well,  —  may be read as  , for example. Breaking the flow between the two shapes differentiates them better. Openings  are the openings in the middle of letterforms. Generally speaking, the bigger the counters, the more distinct the letters. Mirroring Because some people with dyslexia perceive letters as flipped or mirrored, the BDA recommends that   and  , and   and  , be easily distinguishable.  Word shapes Most readers don’t read letter by letter, but by  . We modified Progress Two not just to make things easier for readers who are dyslexic; we did it as part of a wider inclusive design process. We wanted to make accessibility a central part of our design principles so that we could create an easier experience for everyone. Test, test, and test again In the course of our usability testing, we had the good fortune to be able to work with participants with accessibility needs in each round, including individuals with dyslexia, those on the autism spectrum, and users of screen readers. Once we started introducing changes, we were anxious to make sure we were heading in the right direction.  , our lead user experience practitioner, suggested that a good way to uncover any urgent issues would be to ask a large number of respondents to participate in a survey. The media team helped us out by tweeting our survey to a number of charities focused on dyslexia, dyspraxia, autism, and ADHD, and the charities were kind enough to retweet us to their followers. Although we realize that our test was of the quick-and-dirty variety, we got no feedback indicating any critical issues, which reassured us that we were probably on the right track. Respondents to the survey had a slight preference for the adjusted version of Progress Two over Helvetica (we chose a familiar sans serif as a baseline); the unadjusted version came in last. Anyone can do it Even if you don’t have a friendly type designer you can collaborate with to tailor your chosen fonts, you can still do a lot to be typographically accessible. Type When selecting a typeface, look for letterforms that are clear and distinct.  Keeping the checklists we’ve mentioned in mind, watch for details that could potentially trip readers up, like shapes that aren’t well differentiated enough or counters that are too closed.    that sans serifs are easier to read on screen, since, especially at lower resolutions, serifs can get muddy, make shapes less distinct, or even disappear altogether. If your existing brand includes a typeface with fine serifs or ornamental details, use it sparingly and make sure you test it with a range of users and devices.  Some research has shown that italics and all-caps text reduce reading speed. Try using bold for emphasis instead.   , but a standard text-decoration underline obscures descenders. In the future, the   may be able to help with that; in the meantime, consider  . Space Think carefully about spaces between, around, and within letterforms and clusters of words.  Advice on an ideal line length (or measure) varies, but consider   safe.  Ideal line height (or leading) will depend on the typeface you choose, but a good rule of thumb is to   and refine from there.   , a bit like jeans. Words The words you use are just as important as what you do with them.  Avoid long sentences. Keep headings clear and concise.  Write for your audience and cut the jargon unless it’s absolutely necessary. Acronyms and academic terms that might be appropriate for a team of specialists would be totally out of place in a more general article, for example. So everything’s fixed, right? Nope. There is no perfect typeface. Although we worked hard to improve the experience of the Wellcome site, some people will still struggle with our customized headline font, and with the Helvetica, Arial, sans-serif font stack we’re using for body text. However hard we try, some people may need to override defaults and choose the fonts and colors that work best for them. We can respect that by building sites that allow modification without breaking.  Ensure that whatever   people use will work with your site.    if someone overrides your site’s fonts.  Would your users benefit from  ? Pragmatic perfection The trouble with expecting perfection in one go is that it can be tempting to take the safe route, to go with the tried and tested. But giving ourselves room to test and refine also gives us the freedom to take risks and try original approaches. Putting ourselves out there can feel uncomfortable, but Wellcome wants to fund researchers that have the big ideas and the chutzpah to take big risks. So shouldn’t those of us building the site be willing to do the same? Yes, maybe we’ll make mistakes, but we’ll learn from them. If we had chosen a safe typeface for our headline font, we wouldn’t be having these conversations; we wouldn’t have done the research that led us to make changes; we wouldn’t discover new issues that failed to come up in any of our research. The process sparked much debate at Wellcome, which opened doors to some intriguing opportunities. In the future, I won’t be so reticent about daring to try new things. Additional resources Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/managing-ego/", "title": "Managing Ego", "content": "We’re in an industry where we regularly hear that our ideas are bad. We can get yelled at for overlooking something, even if we didn’t know about it, and we frequently encounter threats to our ego that can turn any one of us into an anxious and irrational coworker. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Minimizing our exposure to ego-damaging situations can be valuable in preventing anxiety, but that’s sometimes beyond our control. Unfortunately, when threats can’t be controlled, confidence is the next thing to take a hit. Professional and personal self-worth may seem vulnerable, but they can also be reinforced and strengthened far in advance. Client drama, ground zero I shrunk in my chair as a client technical contact listed off everything he hated about the site I had just built. The list was not short, nor was it constructive. When it came time for him to make his recommendations, I went on the offensive and launched into my own opinions on how terrible and impossible his ideas were. By the end of the phone call, everyone was on edge and I was left with one desperate question: What just happened? I found out the next day that the website I built was originally supposed to be an internal initiative, handled by the technical contact who had berated me. In short, his ego was bruised—and by the end of the phone call, my ego was bruised too. This brought out the worst in each of us. The result was a phone call full of drama that shall live on in infamy. There were a few things wrong with that conversation. First, the technical contact clearly felt threatened by my website. But my history with this guy showed me that he felt threatened by most ideas we brought to him, so we also had to give some thought to where to draw the line with validating him on this. We should have employed a long-term strategy for strengthening that relationship by validating him at other times. Lastly, there are things I could have done to guard myself against irrationality and drama when that conversation turned south. In short, everything went wrong in this scenario. That’s bad for me, but good for you, because it means we can learn a lot from looking at it. Let’s dig in. Validating self esteem to prevent anxiety Everyone responds to external feedback and affirmation—some more than others. So how do we tailor our feedback to avoid causing undue anxiety? When you notice someone suddenly get worked up about something, go over what just happened. You probably introduced a threat. Did you propose a new idea? Did you point out a flaw in their idea? (Ideas are tied very closely to self esteem.) What was the idea? You’ve just pinpointed where their self esteem comes from. Just like web professionals usually draw self esteem from the things that got them the job in the first place, marketing and account people do the same thing. Marketing people may prize their own creative ideas in a campaign, or their analytical skills when critiquing a campaign; account people often value their communication skills and ability to read people. When these skills are called into question, it produces anxiety, which can quickly lead to drama. Think about that marketing person who can’t accept any creative idea as-is—who feels the need to make revisions to any idea that comes in. Creativity is the source of this person’s self esteem, so pushing back on those ideas without first validating them will introduce threat and result in anxiety. What about that developer who won’t accept other people’s suggestions, and shoots down others’ ideas as impossible or too impractical? Problem solving and technical know-how are the sources of this person’s self esteem, and self esteem must be boosted by validating those strengths to get anywhere in a discussion of the merits of said ideas. Ok, great, so we know where their self esteem is coming from. How do we validate these traits to prevent drama? Consider the conversation I had with the client’s technical contact. When the technical contact began listing everything he hated about my site, I should have noticed that his own ideas were invalidated by the proposal of my ideas, which were being presented in the site I designed and built. Rather than immediately protest (producing more threat), I should have asked questions related to his expertise with the client brand and business goals. I could have asked for help and affirmed his problem-solving ability (boosting self esteem and lowering threat) before re-asserting my own ideas. Had I taken this approach, there’s a good chance I could have learned something about the client in addition to calming down their technical contact. Simply acknowledging others’ ideas and the thought that went into them can go a long way in validating sources of self esteem and quelling anxiety in the workplace. When validation is not enough There are times when there is such an emotional deficit created by a blow to the ego (possibly to an already-low self esteem) that no amount of validation will fix it. Dealing with a   can be difficult, and fixing it can be impossible. In those cases, no level of threat is tolerable and no level of self esteem boosting is sufficient. Going back to my conversation with the client technical contact, what if he remained unsatisfied until he had the project back on his plate? Obviously, this is not a solution that’s good for either the agency, who needs the work, or the client, who determined that the agency was a better fit than their internal team. In these situations, preventing or calming anxiety may be impossible because the problem is likely much bigger than the conversation at hand. It’s hard to apply a short-term solution to a long-term problem. In those cases, there are two things to do: minimize damage, and employ a long-term strategy to strengthen the relationship. Minimizing damage means avoiding triggers and being as understanding as you can to the other person’s plight without sacrificing the project. If the other party feels that their ideas are being invalidated, it’s a sign that they feel that others aren’t taking their contributions seriously. (It may or may not be true in reality, but that’s how they feel.) That’s a pretty rough place to be no matter who you are. In that case, treat their contributions respectfully and be understanding when they get defensive about them. Employing a my-way-or-the-highway authoritarian approach is the opposite of what we’re going for. This approach increases threat and can lead to a lot of ugly politics, with people going behind your back to gain support for their cause because they feel that any ideas brought to you are being invalidated. There are some situations where this is the only way forward, but those situations are few and far between—as well as rough and aggravating. Only go this route if you’ve exhausted all other options. Read on for a long-term strategy to strengthen the relationship. Using self esteem to build long-term relationships As web professionals, we’re in the idea business—but so are the marketing people we often deal with. Those marketing folks will probably react poorly when their self esteem is threatened by conflicting and challenging ideas; but they usually react well when treated with deference and asked to explain their ideas and contribute their strengths. While this can be done on a case-by-case basis to prevent anxiety, it can also be done proactively to build better relationships with clients, coworkers, and others. Once you’ve identified the source of a person’s self esteem, start deferring to them on that subject. Treat them as an expert on that subject. (In many cases, they probably are an expert on that subject.) Be open to their ideas and suggestions, and willing to integrate them into your own. This process can take time, depending on the emotional deficit they begin with and your flexibility in welcoming their ideas. But over time, the beneficiary of your emotional toil will begin to see you as an ally and partner. This is a very good spot to be in. They keyword here is intentionality. This process cannot happen on a happy accident—it takes work with planning and strategy. Obviously, the mental energy required for this means you won’t be able to do it for everyone you work with. Give some thought to which of your working relationships have the most strategic importance and which could most benefit from additional trust and respect. Chances are a few will pop out at you. Being intentional about   and clients not only makes them easier to work with, but creates relational equity that can be cashed in at a later time for deference, respect, and allegiance. Remember, the less you challenge things in a relationship, the more the other person will listen when you do. Though it takes time, it will make your job way easier in the long run. Guarding yourself against anxiety I wish I could say I didn’t personally need the advice in this section—but I do. There are times when we all do. Let’s be honest: we’ve all been that angry client technical contact at some point, and it certainly doesn’t help our careers. The two things we apply to others can also be applied to ourselves to prevent anxiety: we can reduce threat, and we can boost self esteem. At first glance, it may seem impossible to reduce threat coming from others. We can’t just ask everyone to be nicer to our egos. But some perspective can go a long way in reducing   threat. In the example above, I reacted poorly because the client’s technical contact got mad at me on the phone. He challenged all of my ideas and was doing all he could to dismiss them entirely. What I didn’t realize until much later was that he wasn’t mad at me, or my ideas—he was mad at an unstated problem. Maybe he had been burned by another agency’s incompetent development team in the past. Maybe he had major concerns that weren’t being heeded by his company’s marketing team. Ultimately, I don’t know what the problem was, but I realize now that he probably would have been mad no matter what or who we put in front of him. What I find is that angry people aren’t always mad at me—many times, they’re mad at the problem. They’re challenging my ideas not because they doubt them, but because they want to make sure that they’re the best solution to the problem. When viewed this way, it’s a lot easier to avoid being defensive, because it’s not me versus you—it’s me and you versus the problem. It’s not easy to   that gets triggered when people start challenging your ideas, but forcing yourself to do so usually goes a long way in helping to solve the problem without escalating into drama. Having a healthy view of yourself and your capabilities can also guard against anxiety. It’s very important to have   around you. There’s one big difference between healthy self esteem and unhealthy pride: social comparison. Healthy self esteem is knowing that you’re good at something and being content with that; unhealthy pride is knowing that you’re better than someone else. Being better than someone else is actually a rather tenuous place to be. Comparing yourself to a moving target—which may be moving past you—usually results in you trying to hammer the target down into a place where you can move past it, either by putting the other person down or filling yourself with false confidence in your own ability. This is never a good thing. If a discussion on how to solve a problem devolves into a binary battle of opinions with a winner and a loser, there are no winners because the original problem becomes the loser. It doesn’t matter if you beat the other guy if the solution suffers for it. Instead of seeking to be a winner, you should seek to be a problem-solver. In the web industry, ideas don’t mean anything unless they solve real-world problems. It is always worth giving up some or even all of your idea if it means improving the solution. Recognizing the roots of anxiety Workplace drama and the anxiety beneath its surface, far from being unpredictable and random occurrences, are often the result of deeply held fears and insecurities. Avoiding an unmitigated drama disaster means dealing with underlying issues like self esteem. It can be difficult to navigate these waters, and even more so to turn the tides and produce happier relationships—but the benefits far outweigh the costs. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/demystifying-public-speaking/", "title": "Demystifying Public Speaking", "content": "Before you near the stage, before you write the talk, before you even pick a topic, take time to get comfortable with the idea of giving a talk. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. You’re reading this because something about public speaking makes your palms sweat. You aren’t alone; when I created an anonymous survey and asked, “What’s your biggest fear about public speaking?” I received over 300 replies. Though the fears all revolved around being vulnerable in front of a large group of people, I was surprised how widely the responses ranged. See for yourself—I’ve grouped a handful of replies to illustrate the spectrum of fears. People are worried about their voices: “The sound or pitch of my own voice.” “Voice cracking up—I forget to breathe from the diaphragm and come across sounding nervous and uninformed.” “Forgetting or skipping over what I want to say, heart racing (and getting out of breath quicker), getting tongue-tied.” People are worried about their bodies: “Being judged for being fat, not on my presentation content.” “In middle school I got something in my eye during a class presentation, and my eyes would not stop watering. I’m terrified it will happen again.” “Needing to pee during the speech!” “Falling on stage.” “People judging my appearance, whether I’m dressed appropriately.” People are worried about technical or wardrobe malfunctions: “Problems connecting laptop to projector.” “Making stupid coding mistakes during live coding.” “Open pants zipper (because it’s happened).” People are worried about being wrong and being challenged: “Elegantly explaining something that is actually wrong.” “Showing that I’m ignorant about something I thought I was knowledgeable about.” “Getting a question I can’t even begin to answer.” “Being wrong and being called out on stage during Q&A.” “Getting heckled.” “Vocal skeptics or doubters.” People are worried about their performance: “Not being impressive enough.” “That everything I say becomes so messy anyone can refute it.” “Since I’m not a native English speaker, my biggest fear is not making any sense when speaking.” “That no one learns anything, and the audience is starkly aware of it.” “Being exposed for the fraud I have always felt like.” Phew. Given the potential for these moments of total—human—disaster, why should we even bother embarking on this journey toward the stage? To start, public speaking (or put another way, broadcasting your abilities and knowledge) has definite career benefits. You grow your network by meeting attendees and other speakers, and you gain documented leadership experience in your subject area. People looking to hire, collaborate with, or fund someone with your topic expertise will be able to find you, see proof of your work, and have a sense of the new perspective you’ll bring to future projects. Those professional benefits are huge—but in my experience, the personal benefits are even more substantial. Giving a talk grows so many skill sets: crafting a succinct way to share information, reading an audience, and eloquently handling an adrenaline-heavy moment. You’ll prove something to yourself by overcoming a major fear, and you should take pride in knowing you taught a large group of people something new that will hopefully make their work or lives easier. Public speaking experience boosts a lot of knock-on benefits too, like a stronger visa application or more confidence in your everyday spotlight moments, like a standup meeting, code review, design critique, or other project presentations. No matter the impetus, trying your hand at public speaking is a brave act. While it’s a different challenge for everyone, we do have a few tools to help tackle our fears. Flip that fear around First, give yourself permission to be anxious. Even renowned speaker and industry veteran Eric Meyer still gets nervous giving talks, as detailed in his article “ ”: A hundred public talks or more, and it’s still not easy. I’m not sure it ever will be easy. I’m not sure it ever should be easy. […] Every speaker I know feels pretty much exactly the same. We don’t all get the same nervous tics, but we all get nervous. We struggle with our fears and doubts. We all feel like we have no idea what we’re doing. Being nervous is totally normal. Consider what you’re juggling: sharing information, entertaining the audience, and guessing (or worrying over) how you’re being perceived. Keep in mind, though, being nervous is not a sign you’ll do poorly. Public speaking isn’t an everyday context, and you may still get butterflies even as you gain experience and improve your speaking game. But if you can’t coolly eliminate all your fears and nerves like some stoic robot, what can you do? One tactic is to   in a positive or motivating way, as designer Lea Alcantara suggests: Instead of worrying, flip your perception of nerves as an indication you care as opposed to  . There is no shame in caring deeply about a subject and what people think about your talk. Caring feels a lot more approachable than dreading failure, and it gives you a way through: use your body’s natural reaction to stress to improve your talk. Invest that energy into more research of your topic, more practice, and more feedback-gathering—all acts within your control. Let your nerves become part of the process—or try accepting that—and just maybe, in time, they’ll feel more useful than disastrous. What makes you tick? To flip your fears into motivations, let’s dip into what makes you tick. Understanding who you are will help you determine where to invest that extra energy as you make your way toward the stage. Once you begin to name what scares you, what comforts you, and what drives you, you’ll be able to home in on which talk format, topic, venue type, and preparation style will calm those fears and build your excitement. To get you started, think through these: What makes you most   when you think about public speaking? What do you want to get out of it? What makes you most   when you think about public speaking? What scenarios do you want to avoid? What size audience do you think you might be most comfortable speaking to? Why? Whose feedback matters most to you on your talk or presentation style? What would you want people to take away from your talk? What do you want to happen for you or your career after your talk? (Examples: someone offers you your dream project, someone you admire asks for your advice, people shower you with praise, you get right back to work, etc.) That’s a lot of introspection, but it’s worth it. As we move through this book, we’ll go through the varied paths and aspects of public speaking, and your answers will guide you to the right fit for you. For instance, if you’re afraid of seeing a sea of strange faces before you, maybe a smaller meetup is the best venue to get in some practice. If you’re afraid of saying something patently false onstage, then pick a topic like a case study from your work that you know inside and out, and practice your Q&A session with friends who can help you fact-check your content. Or, if you’re excited to teach people skills they can immediately put into practice, opt for a workshop format and give hands-on help to folks. Whatever your goals and style, you can find a speaking opportunity that resonates with you. Move beyond the “rules” You’ve heard the adages: don’t say “um,” don’t say “uh.” Excise “like” with extreme prejudice. Don’t use bullets on your slides. Never, ever read from your notes. Some folks have an archetype of what a great speaker sounds like, or an audience size that feels real, or this idea you need to give a deeply technical or novel talk for it to count. But you know what? If I can say one thing in this book about giving talks, it’s  . Truly. Of course, it’s hard to move past the impulse to embrace rules—it’s reassuring to think we have a straightforward map to success. We try to mimic speakers who capture our attention or those whom our peers praise. We hold up examples of “ideal” presentation styles, and we instruct new speakers to follow suit. We   a lot of the same people, and we can’t help but absorb a lot of the same opinions on what a good speaker looks like or sounds like. Just because we’ve built a system, it doesn’t mean it’s right. What we need to see represented onstage is a spectrum of speakers with different insights and ways to teach us about them. Your voice is valuable, and your own. If you choose to share it, we will all certainly be the better for it. Public speaking is a journey that, like any other, involves practice and time to make you feel comfortable and successful.  : The worst case scenario is your talk flops—in which case you’ll be stronger for it. The likelier scenario is you’ll give a couple decent talks, followed by better ones, followed by even better ones, until you give one that really makes a difference. I don’t want to set out any rules in this book—forget them. What I do hope is to help you forge your own path, so you make your way to that talk that makes a difference. Let’s get started. Want to read more? This excerpt from   will help you get started.   today, as well as other excellent titles from  . Like this: \n\t\t\t\t\t\t\tRecently by Lara Hogan\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/learning-from-lego-a-step-forward-in-modular-web-design/", "title": "Learning from Lego: A Step Forward in Modular Web Design", "content": "With hundreds of frameworks and UI kits, we are now assembling all kinds of content blocks to make web pages. However, such modularity and versatility hasn’t been achieved on the web element level yet. Learning from Lego, we can push modular web design one step forward. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Rethinking the status quo Modular atomic design has been around for a while. Conceptually, we all love it—web components should be versatile and reusable. We should be able to place them like bricks, interlocking them however we want without worrying about changing any code. So far, we have been doing it on the content block level—every block occupies a full row, has a consistent width, and is self-contained. We are now able to assemble different blocks to make web pages without having to consider the styles and elements within each block. That’s a great step forward. And it has led to an explosion of frameworks and UI kits, making web page design more modular and also more accessible to the masses. Achieving similar modularity on the web element level is not as easy.   says we should be able to put UI patterns inside each other like Russian nesting dolls. But thinking about Russian nesting dolls, every layer has its own thickness—the equivalent of padding and margin in web design. When a three-layer doll is put next to a seven-layer doll, the spacing in between is uneven. While it’s not an issue in particular with dolls, on web pages, that could lead to either uneven white space or multilevel CSS overrides. I’ve been using   and   for years, and that’s exactly what would happen when I’d try to write complex layouts within those frameworks—rows nested in columns nested in rows, small elements in larger ones, all with paddings and margins of their own like Russian dolls. Then I would account for the nesting issues, take out the excessive padding on   and  , calculate, override, add comments here and there. It was not the prettiest thing I could do to my stylesheets, but it was still tolerable. Then I joined  , a knowledge company delivering data visualizations across more than 700 different topics. Here, content editors are allowed to put in any data they want, in any format they want, to create the best experience possible for their readers. Such flexibility makes sense for the small startup and we have a drag and drop interface to help organize everything from a single data point to infographics and charts, to columns, blocks, and cards. Content editors can also add logic to the layout of the page. Two similar bar charts right next to each other could end up being in quite different HTML structures. As you can imagine, this level of versatility oftentimes results in a styling hell for the designers and developers. Though a very promising solution— —is on the horizon, it hasn’t made its way to Chrome yet. And it might take years for us to fully adapt to a new   attribute. That led me to thinking if we can change the Russian doll mentality, we can take one step further toward modular design with the tools available. Learning from Lego To find a better metaphor, I went back to Lego—the epitome of modular atomic design. Turns out we don’t ever need to worry about padding and margin when we “nest” a small Lego structure in a large Lego structure, and then in an even larger Lego structure. In fact, there is no such concept as “nesting” in Lego. All the elements appear to live on the same level, not in multiple layers.  But what does that mean for web design? We have to nest web elements for the semantic structure and for easy selecting. I’m not saying that we should change our HTML structures, but in our stylesheet, we could put spacing only on the lowest-level web elements (or “atoms” to quote atomic design terms) and not the many layers in between. Take a look at the top of any individual Lego brick. If you see the space around the outside of the pegs as the padding of a web element, and everything inside the padding as the content, you will find that all Lego bricks have a consistent padding surrounding the content, which is exactly half of the gap between elements. And when Lego bricks are placed together, all the elements will have the same gutter in between. No other padding or margin needed; the gaps are naturally formed. All the elements—no matter how deeply they are nested—appear to be on the same level and need no CSS override or adjustment, not even the   and   reset. Putting it in code, we can make a class that adds the half-gutter spacing, and apply it to all the lowest-level web elements on the page. Then we can remove all the spacing on structural   like   and  . One tiny tweak to be mindful of is that when the padding is only on  , the padding between the outermost elements and the parent   would only be half the gutter. We need to add the same padding to the outermost container as well. And that will result in this: Think about how many layers of overrides we would need to create this layout with the current rows and columns mentality. The best we can do is probably something like this: And in code: See the Pen   by Samantha Zhang ( ) on  . \n With the Lego mentality, the spacing and the code can be much simpler, as shown in the two examples below: Example with div:  See the Pen   by Samantha Zhang ( ) on  . \n Example with Flexbox:  See the Pen   by Samantha Zhang ( ) on  . \n More flexible than Lego Lego is a true one-size-fits-all solution. With Lego, we don’t get to tweak the padding of the bricks according to our projects, and we can’t have different horizontal and vertical padding. Web design offers us much more variation in this area. Instead of just setting one value as the gutter, we can set four different variables and get more flexible layout this way: The result looks like this: It’s still modular, but also has varying spaces to create a more dynamic style. With responsive design, we could also want different spacing for different media queries. We can take our approach one step further and write our logic into a   mixin (alternatively you can do it with  , too): Using this mixin, we can plug in different spacing maps to generate CSS rules for different media queries: And as easy as that, all our elements will now have different spacing in desktop and tablet view. Live example: See the Pen   by Samantha Zhang ( ) on  . \n Discussion After using this method for almost a year, I’ve encountered a few common questions and edge cases that I’d like to address as well. Background and borders When adding backgrounds and borders to the web elements, don’t apply it to the    . The background will cover both the content and padding areas of the element, so it will visually break the grid like this: Instead, apply the background to a child   within the    : I used this structure in all my examples above. Similarly, the border goes around the padding in the box model, so we should also apply the border of the element to a child   to maintain the correct spacing. Full row elements Another common issue occurs because we occasionally want full row elements, conceptually like this: To style full row elements following the   and   structure, we need to make use of negative margin: Notice that we need to add back the   to the padding, so that the content in   and the content in   align. The code above handles the horizontal spacing, and the same logic can be applied to take over vertical spacing as well (as shown in the example above–the header element takes over the top padding). We can also add a negative margin very easily in our stylesheets. It can be applied as a standalone rule or be included in the Sass or LESS mixin, then you will never have to worry about them again. Nesting The full freedom in nesting is the strong suit of this Lego CSS method. However, there is one kind of nesting we can’t do–we can’t ever nest an   within an  . That will create double padding and the whole point of this method would be lost. That’s why we should only apply the   class to the lowest level web elements (or “atoms” to quote atomic design terms) like a button, input box, text box, image, etc. Take this very generic comment box as an example. Instead of treating it as one “element,” we need to treat it as a pre-defined group of elements (title, textarea, button, and helper text): Then, we can treat   as one reusable component–or in the atomic design context, a “molecule”–that will play well with other reusable components written in the same manner, and can be grouped into higher level HTML structures. And no matter how you organize them, the spacing among them will always be correct. Varying heights and layouts In the bulk of this article, we’ve been using the same fitted row example. This may lead some to think that this method only works for elements with defined height and width. It’s more versatile than that. No matter how elements change in height and width, lazy load, or float around, the Lego-like padding will ensure the same consistent gap between elements. See the Pen   by Samantha Zhang ( ) on  . \n Maintenance Some of you might also be worrying about the maintenance cost. Admittedly, it takes time to learn this new method. But once you start to adopt this mentality and write CSS this way, the maintenance becomes extremely simple. Especially with the layout mixin, all the spacing rules are centralized and controlled by a few groups of variables. A single change in the variables would be carried out to all the elements on the web page automatically. In comparison, we might have to change padding and margin in 20 different places with the old method, and then we have to test to make sure everything still works. It would be a much more hectic process. Grid layout And finally, there is the Grid layout, which supports very complicated layouts and nests much more gracefully than block. You might be thinking this is quite a lot of hard work for a problem that is actually going away.  While many of the issues we talked about in this article might go away with Grid, it might take Grid years to get browser support. And then, it might take a long time for the community to get familiar with the new method and develop best practices and frameworks around it. Like Flex–it’s already supported by most browsers, but it’s far from widely adopted. And after all, it could take a typical web user a long time to understand Grid and how that works. Similarly, it would require quite a lot of development for us to translate user layout input into good CSS Grid code. The old by-column and by-row method is way easier to understand, and when nesting is not an issue, it could stand as a good solution for websites that allow user configuration. Conclusion We started to implement this method at   in the beginning of 2016. Almost a year in, we love it and believe this is how we should write web layouts in the future. As we refactor each page, we’re deleting hundreds of lines of old CSS code and making the stylesheets way more logical and much easier to read. We also got far fewer layout and spacing bugs compared to all our refactors in the past. Now, no matter how our content editors decide to nest their data points, we’ve got very little to worry about. From what we’ve seen, this is a real game changer in how we think about and code our layouts. When web components are modular like Lego bricks down to the elements level, they become more versatile and easier to maintain. We believe it’s the next step to take in modular web design. Try it for yourself and it might change the way you write your web pages. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-imbalance-of-culture-fit/", "title": "The Imbalance of Culture Fit", "content": "When I started   back in 2008, I’d never run a business before. This lack of experience meant I didn’t know how to do many of the things I’d ultimately have to do as a business owner. One of the things I didn’t know how to do yet? Hiring. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. When it came time to start hiring employees, I thought a lot about what the company needed to advance, what skills it was lacking. I asked friends for advice, and introductions to people they knew and trusted who fit the bill. And I asked myself what felt like a natural question: would I want to hang out with this person all day? Because clearly, I would have to. The trouble with this question is that I like hanging out with people I can talk to easily. One way to make that happen is to hang out with people who know and like the same books, music, movies, and things that I do; people with similar life experiences. It may not surprise you to learn that people who have experienced and enjoy all the same things I do tend to look a whole lot like me. The dreaded culture fit This, my friends, is the sneaky, unintentional danger of “culture fit.” And the only way out I’ve found is to recognize it for what it is–an unhelpful bias–and to consciously correct for it. Besides being discriminatory by unfairly overvaluing people like yourself, hiring for culture fit has at least one other major detriment: it limits perspective. At Bearded, our main focus is problem solving. Whether those are user experience problems, project management problems, user interface problems, or development problems–that’s what we do every day. I’ve found that we arrive at better solutions faster when we collaborate during problem solving. Having two or more people hashing out an issue, suggesting new approaches, spotting flaws in each other’s ideas, or catching things another person missed–this is the heart of good collaboration. And it’s not just about having more than one person, it’s about having different perspectives. Perspective as a skill A simple shortcut to finding two people who look at the world differently is to find two people with varied life experience–different genders, races, religions, sexual orientations, economic backgrounds, or abilities… these factors all affect how we see and experience the world. This means that different perspectives–different cultures–are an asset. Varied perspective can be viewed, then, as a skill. It’s something you can consciously hire for, in addition to more traditional skills and experience. Having diverse teams better reflects our humanity, and it helps us do better work. This isn’t just my experience, either.   conducted by Sheen S. Levine and David Stark, groups that included diverse company produced answers to analytical questions that were 58 percent more accurate. When surrounded by people “like ourselves,” we are easily influenced, more likely to fall for wrong ideas. Diversity prompts better, critical thinking. It contributes to error detection. It keeps us from drifting toward miscalculation. Smarter groups and better problem-solving sounds good to me. And so does increased innovation. In her  , Katherine W. Phillips draws on decades of research to arrive at some exciting conclusions. Diversity enhances creativity. It encourages the search for novel information and perspectives, leading to better decision making and problem solving. Diversity can improve the bottom line of companies and lead to unfettered discoveries and breakthrough innovations. Even simply being exposed to diversity can change the way you think. Phillips isn’t alone in linking diversity to profit. A   released in May 2016 showed that gender-diverse companies delivered slightly better returns with lower volatility than their more homogenous peers. Seems like we’d be crazy not to be thinking about building more diverse teams, doesn’t it? People make the culture I recently spoke at   in Sydney, and was lucky enough to listen to a talk on gender in the tech industry by   from Atlassian. Aubrey made a point of how Atlassian has shifted its perspective from finding people who fit their culture, to having a culture defined by its people. When hiring, this means tossing out the whole “do I want to hang out with them?” question. Instead, I’ve tried to replace that with more specific, more culture-agnostic questions: Are they kind and empathetic? Do they care about their work? Do they have good communication skills? Do they have good self-management skills? If the answer to each of these questions is yes, then it’s very likely I   want to hang out with them all day, regardless of which movies they like. As Aubrey points out, we can then focus on values, and leave culture alone. Our values might be that we treat each other well, that we do great work that we care about, and that we are largely independent but communicate well when it’s time to collaborate. Then we can also include this new question: Do they bring a valuable new perspective? Hiring based on these values will naturally build a culture that is more comfortable with diversity, because the benefits of diversity become more clear in our daily experiences. Encouragement and change Now you don’t need me to tell you no one’s perfect. But when it comes to emotional, high-stakes topics like this, you can see people getting caught in the crosshairs of reproach–and that’s scary to watch. Sometimes it can feel as if we’re all one questionable tweet or ill-considered joke away from public humiliation. That in mind, let me tell you about a time when I was an idiot. For context, you should know that I’m a white, heterosexual, cisgender male who grew up in a stable, upper-middle-class environment, and now runs his own business. I pretty much tick all the privilege checkboxes. Last year at a design conference, I was chatting with industry friends. At some point I brought up a meme that I thought was funny, until one of my friends pointed out that it was sexist. And he was right. Oh crap, I thought: I’m that guy at the conference, I’m a terrible person. Luckily my friend went easy on me. He understood how I missed the underlying sexist assumptions of the joke, and was happy to bring that to my attention without extending the accusation of sexism to me, personally. He effectively reassured me that I could do something bad, while still being a good person. He gave me the option to admit bad behavior and correct it, without hating myself in the process. And this, I think, may be the key for people in my very privileged position to change. When problems like this come up, when we make missteps and unveil our biases and ignorance, it’s an opportunity for change. But the opportunity is often much more delicate than any of us would like. Successfully navigating a situation like that requires sensitivity and control from both sides. For the transgressor, being called out on an issue can feel like being attacked, like an indictment. For those of us who aren’t used to being made uncomfortable, that can be shocking. It can be something we might want to quickly deny, to reject that discomfort. But not all discomfort is, in the end, a bad thing. To give others’ feelings and concerns merit–to validate their different perspective–may require us to sit with our own hurt pride or injured self-image for a bit. Something that may help us through these difficult feelings is to remember that there is a big difference between behaviors and identity. Bad behavior is not immutable. Quite the opposite, bad behavior is often a first step toward good behavior, if we can withstand the discomfort of acknowledging it, and muster the strength to change. It’s tough getting called out for bad behavior, but things aren’t exactly simple on the other side of the confrontation, either. When we’re offended by someone’s ill-considered words or actions, it can cut to the quick. We might feel required to respond with the full force of our anger or outrage. After all, why should we be expected to police our own tone, when we’re responding to words that weren’t prepared with our feelings in mind? It can be hard, but employing our empathy, our compassion—along with our critique—can be the best way to affect the positive change we want to see. Right now, you’re doing your best. But we can all do better. Recognizing that we’re doing some bad things doesn’t make us bad people. You have the courage to see what you’ve been doing wrong (unintentionally, I know) and fix that. You can admit to having unfair privileges in the world, without it being your fault for having ended up that way. The world is terribly, horribly unfair. It may very well get worse. But when we have sway, even over a tiny part of it, we have to do our best to balance those scales, and make things a little better. I can do more, and so can you. So let’s see if we can’t get to an even better place in 2017, together. Acknowledgements Many thanks to   and   for their thoughtful consideration and feedback on this article. My infinite gratitude goes out, as always, to my editor  , who helped me find my way even more than usual this time around. Like this: \n\t\t\t\t\t\t\tRecently by Matt Griffin\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/webfonts-on-the-prairie/", "title": "Webfonts on the Prairie", "content": "I last wrote about the   for   six years ago. Very few sites used webfonts then, but there was a lot of pent-up   among designers to get moving after 15 years of   to so-called “web-safe” system fonts. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. And move they did. With the learn-as-you-go self-reliance that web creators have always been so good at—a slick change in   to grease this thing here, a   to patch that thing there—we’ve come a long, long way with very little preparation. A success by anyone’s measure (mostly) As of May 2016, a majority of sites—60% of the  —were using webfonts, up from only 2% in 2011. In  , designer Kenneth Ormandy notes that “we are building sites that request more fonts, from an 8kb average transfer size at the beginning of 2012 to a 59kb average two years later.” Data also   that soon after a site adopts webfonts, it will likely add more: the number of requests go up and, so too, do the sizes of the files requested. An exodus away from system fonts is clearly underway. Webfonts have reached critical mass and will soon be the new normal in web typography. Now, whether webfonts, cloud computing, or animation, the adoption of new technologies means potential users have come to terms with their   about them. These fears can be very irrational, and they can persist long after the conditions that gave rise to them are gone. For example, in 2009, web performance expert Steve Souders—then at Yahoo—  web designers that they should, if at all possible, stay away from webfonts: “My first piece of advice is to avoid using @font-face unless it’s critical to the page.” Whoa. Okay, but that was back then. This is 2016. With usage at 60 percent, surely nobody would seriously argue for a return to system fonts, right? Wrong. In a post called  , web designer   says we should all just say no to webfonts and insists that system fonts are a better choice. What? Just say no Morse writes: There are a lot of arguments around why you should use webfonts. In none of those arguments, have I heard about a single problem being solved for users. He goes on: Over the last three years I have participated in a number of testing sessions. In that time I never heard a user complain about: the use of system fonts in a design. a website having the same typeface as another site. a page using system fonts that loaded too quickly. a site NOT using web fonts. \n On the flip side I: observed users abandon a website because the page was loading slowly. heard people complain about the dreaded flash of unstyled text. In sum, Morse’s attitude is that web fonts aren’t worth the trouble they cause some users—especially in low-bandwidth conditions—and that sticking with tried-and-true system fonts is best for all concerned. Well. In less time than it takes to say “Holy holdout, Batman!” web designer Robin Rendle posted a  . A few days later came Frederic Marx’s  . And in between those volleys, both   and   took note of the disturbance in the force and I, sucked into the vortex, offered to write this article.  Morse’s criticisms obviously hit a sore spot with Robin Rendle and Frederic Marx and, frankly, me too. But why so touchy after all this time? Webfonts are a runaway train and anyone standing astride the tracks shouting stop is just asking to get plowed over. Didn’t everybody get the   about this? Well, maybe not—maybe some people genuinely aren’t aware that webfonts have become so popular.  As Rob Larsen observes in his book  :  Most of the time, front-line developers don’t get to spend time looking at the big picture…Even folks who are tasked with keeping track of the big trends can get sidetracked…It seems like people don’t really think about how fundamentally the Web has changed. But then, also, maybe there’s some truth to what Morse is saying. Ouch. Morse is right to rail against webfonts’ drawbacks. A poor user experience for some of us diminishes all of us. Leave no user behind—who would argue with that? Plus, the browser makers and the W3C have taken too long and have done too little to give web designers the fundamental tools, within CSS alone, to ensure consistent behavior from browser to browser. A standards-based fix is long overdue. The   proposed by Tab Atkins, Jr. of Google is an attempt at just such a fix. Atkins lists some of the persistent problems his proposal addresses: Chrome and Firefox have a 3 second timeout after which the text is shown with the fallback font. Eventually, a swap occurs: the text is re-rendered with the intended font once it becomes available. Internet Explorer has a 0 second timeout which results in immediate text rendering: if the requested font is not yet available, fallback is used, and text is rerendered later once the requested font becomes available. Safari has no timeout behavior (or at least nothing beyond a baseline network timeout) He continues: \nWhile these default behaviors are reasonable, they’re unfortunately inconsistent across browsers. Worse, no single approach is sufficient to cover the range of use cases required by modern user-experience–and performance–conscious applications. Now, amazingly, jaw-droppingly, these defects are consistent with the very same defects described in Souders’ analysis from 2009—seven years ago!—in which he advised, from a webperf analyst’s point of view and with a webperf analyst’s priorities, that webfonts not be used at all. Yet the pain of still more Arial, still more Helvetica, proved too much to bear when, at long last, webfonts started looking like a practical option in early 2011. Web design featuring a wide variety of typefaces that were searchable, scalable, zoomable, selectable, and high-DPI friendly was too great a temptation to resist. Scary talk be damned, designers inched forward on their own, saw for themselves, and, in the collective view of the two percent of early adopters, despite a few kinks and blinks—c’mon, is it really a “flash” of unstyled content?—webfonts by and large worked well enough to begin leaving the homogeneity of system fonts behind. But infatuation will only take you so far. Those early adopters were able to keep moving steadily forward and draw others into the fold only because conditions became increasingly amenable to webfonts. The timing was right. Like manna from heaven It’s 2011, and for webfonts to start taking hold, backward compatibility with Internet Explorer is essential. It’s hard to imagine any site giving webfonts a try if it means excluding the huge number of IE 6, 7, and 8 users that existed then. The catch was, with any version of IE prior to version 9, the webfont had to be converted from a   font (TTF) to the  (EOT) format. Then, the HTML had to include CSS that accommodated both the rudimentary implementation of   that went all the way back to the release of IE 4 in 1997 and also, at the same time, work with the newer syntax demanded in CSS3. Several   emerged, but in the end there was a clear winner: the   was a clever, yet simple, CSS-only solution to the problem. It’s still in wide use today. More help was on the way:   webfont compression (and the new and improved  ); finer control over   using JavaScript; speedier delivery of assets using   (CDNs), and emphasis on best practices like setting   so that on initial download, webfonts are stored locally in the cache to avoid delay due to network latency on subsequent visits. Browsers improved, too—they started supporting a greater number of   for faster, parallel downloading of linked assets, and a newer and faster protocol ( ). The main objection to webfonts has always been the prospect of a fitful user experience on page load, particularly on a first visit, when the browser hasn’t yet had the opportunity to locally cache any of the site’s assets and   can’t yet come into play, as it does in some of the JavaScript polyfills for the controlled loading of webfonts. First, there’s a delay caused by the time it takes the network to deliver the webfont and that, in turn, causes a so-called   ( ) as the browser paints the page with a fallback system font and then repaints the page when the webfont arrives. Now, without getting into the many possible causes for network latency, the simple and only solution for this scenario is a faster network connection.  And so, greatly favorable to the adoption of webfonts—perhaps above all else—and yet easily overlooked because it came gradually and in small doses—was more bandwidth, more bandwidth, and then  . The average internet speed in the United States today is   as fast as it was in 2011.  Progressive enhancers need not apply Webfonts are sometimes presented as “progressive enhancements” of system fonts. That’s incorrect. System fonts are a parallel solution to the same problem. A webfont is not an “enhanced” version of a system font, nor is a system font a gracefully degraded webfont. It might   that way because, if a webfont is not available, the browser falls back to a system font. But fallback fonts are system fonts that vary according to which platform the browser is installed on; there is no way to know precisely which font—or version of the font—the browser will fall back to. As any web server administrator will tell you, the only content you can be absolutely sure of is what’s on your server. Everything else is guesswork. In fact, to get webfonts working well, the exact opposite of progressive enhancement is required. Let’s call it “regressive insistence.” (How’s that for a euphemism?) It’s simple: you pull the hammer labeled “JavaScript” from your toolkit and bang at the browser with it until webfonts work. And with only a little banging, they work quite well. In fact, a particular set of hammer strokes —so to speak—has been   in the  . Morse is right that, without extra effort, CSS by itself doesn’t give us the tools to smooth out the user experience as webfonts load (or don’t). But we can achieve that level of control with just a little bit of extra work—well-tested remedies and refinements exist for all of the problems Morse implicitly treats as insurmountable.  ’s  ,  ’s  , and Google’s   have all prominently posted solutions to these problems online. The truth is out there, Scully. As   writes in  : The answer isn’t, as some developers have called for, to not use web fonts at all, but rather to do our job and control the process with the tools we have at hand. Type is simply too important a design element to give up just because we’re lazy. Amen. Which leaves us with the final reason why Morse’s criticisms are beside the point. He puts an unquestioning, almost religious, faith in system fonts. In his rebuttal to Morse, Rendle notes: It appears that he argues we should use a “web-safe” or a system font because they’re more predictable. However, I would argue that there’s no such thing as a “web-safe” font. It’s a fact. Ask yourself this: if network bandwidth had been able to support the requisite file sizes when the web began, wouldn’t fonts sent from the server have been greatly preferred over system fonts? If you can only be certain of what’s under   control on   server, which would you rather have—the certainty of webfonts that are precisely what you and your users want and need, or the crapshoot of fonts preinstalled by makers of operating systems that present you with moving targets that vary from platform to platform? So-called “web-safe” system fonts were a temporary ad hoc solution that web designers had no choice but to accept because network bandwidth was not yet capable of delivering what would, sooner or later, be necesary for the web to take its place as a truly global tool. Webfonts—the ones designers  —are the true “web-safe” fonts. They always were. If ever there was a time when, by chance, system fonts offered a safe and simple haven for web designers, those days are long gone. The challenge of multi-script fonts Most of the fonts Google   in 2015 were Indic—Devanagari, Bengali, Gujarati, Gurmukhi, Kannada, Myanmar, Sinhala, Telugu, Tamil, and Malayalam—along with Arabic, Hebrew, Ethiopic, Armenian, Cyrillic, Cherokee, Lao, Khmer, and Thai. On Google Fonts’ redesigned  , you’ll see new menu items with those choices. The World Wide Web may be a creation of the West, but now, at long last, it needs to get ready for the rest. There’s a great hunger for the web to accommodate the world’s 6,000+ languages; a way to fulfill that need has finally taken shape through a convergence of three key developments: the rise of Unicode.org as a standards body and central authority in deciding which characters are referenced by which code points the implementation of the CSS3   rule in web browsers support for the OpenType font standard in web browsers (Full disclosure: as a consultant for Google, I worked on quality control for many of these new fonts. But the views expressed here are strictly my own.) The need for wider language support alone is enough to drive webfonts unstoppably forward. Sure, if you’re a native speaker of English working blissfully on a Macbook in a London pub and the year is 1886 and the sun never sets on your empire, by all means, stick with system fonts. But the truth is this: you can’t and won’t be able to count on the local operating system of every device to support all of the languages demanded by a truly worldwide web. But enough. You don’t need a weatherman to know that a protest by one contrarian web designer won’t change the way the wind blows. Besides, websites are   built and improved by  . There are built-in institutional barriers that can delay and sometimes defeat the adoption of a new technology. It’s a thing. So, let’s take a look at where the adoption of webfonts across the industry stands today, and call it a wrap. Patterns of adoption Using webfonts means accepting that the typographic look-and-feel of a site is no longer in the hands of the makers of operating systems—it’s in the hands of those creating the site. Perhaps those hands are yours. Now, some may take on these new responsibilities eagerly; others may not. Those with a background in graphic design who miss the freedom to choose from a variety of typefaces will probably push hard for the change, while those who lack that background, or who champion performance over style, may urge caution. Typography is a big deal. It’s branding. It’s identity. The desire to stand out visually is as powerful on the web as it is in any other medium—if not more powerful. And so far, along with a reflexive impulse simply to escape the sameness imposed by web-safe fonts, such motivations have proven strong enough to overcome the inertia and “if it ain’t broke, don’t fix it” attitude infusing many organizations. But no matter how great the desire to change, internal politics, cost analysis, budgeting, and scheduling all take time. Technical innovations don’t diffuse randomly. There’s a pattern to adoption, like ripples in a pond after a stone is thrown in. Below is a graph of a diffusion curve—the pattern of the ripples—with a red dot placed on the yellow line showing the point where webfonts have progressed with usage at 60 percent of the potential market: As you can see, the adoption rate is about a third of the way into the group of users labeled “late majority.” We’re not quite at the point where everybody assumes that everybody is using webfonts everywhere, but we are at the point where those who aren’t are wondering: Why aren’t we?  There’s no going back, and there’s no staying behind. Are you ready to roll?  Like this: \n\t\t\t\t\t\t\tRecently by Richard Fink\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-interface-animation/", "title": "Designing Interface Animation", "content": "Each animation in an interface tells a micro story, and as a user encounters more and more animations throughout your site or product, these micro stories add up to reveal the personality and story of the brand or product behind them. The animations create an impression; they give your brand a certain personality. It’s up to us as designers to take control of the combined story that animations are telling about the brand we’re working on. Your animations will be much more effective if you intentionally design the additional messages they’re sending.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Brand animation design guidelines aren’t something entirely new, of course. Brands have been expressing themselves in motion in commercials, TV bumpers, video titles, and similar places for years, and they’ve had guidelines for those mediums. What’s new is the idea of needing animation design guidelines for the web or interfaces. Even if your brand will never be in a traditional commercial or video, having a website is enough of a reason to need a motion style guide these days. How Your Brand Moves Tells Its Story Deciding what you use animation for, and how you implement it, for a particular project defines how you express your brand or tell your brand’s story with animation. Often, the decisions of which properties to animate or what easing to use on which elements is done at the component or page level without considering the bigger picture. Assembling a global set of rules about motion and animation for your entire project will help you make more cohesive animation decisions moving forward. These choices lead to more consistent design decisions surrounding animation and make your design stronger overall. It requires you to go back and forth between the big picture of the overall project and the more detailed components, but your entire design will benefit from looking at the project from both perspectives as you work. There are two approaches to begin defining how your brand expresses itself in motion. The first is to go from the bottom up: start by evaluating what you already have and build from there. The second is to go from the top down: first, determine what it is your brand should be saying about itself on a high level, and then determine how individual animations will express that concept. The first approach works best for existing projects that already use animation. There could be hidden gems of communication to build upon in the animations you’ve already designed—ones that will inform the bigger picture you’re working to define. The second approach is generally your only option when starting a brand new project, as there won’t be any existing animation to start from. Whichever approach you choose (or even if you use both), you’ll arrive at the same end result, a common set of guidelines for putting your brand in motion, so they are equally good places to begin.  Defining Your Brand in Motion from the Bottom Up Before you start documenting for the future, you need to get a good picture of what you’re currently using animation for. It’s hard to move forward before knowing where you currently stand. (That is, unless you’re planning to throw it all out and start over.) For existing projects that already use animation, you can start with a motion audit to find all the instances and ways you’re currently using animation. Collecting these in one place will identify the common threads and even help you eliminate unnecessary duplicated or overly similar animations. A motion audit will focus your animation efforts and the design reasoning behind them.  A motion audit gathers up all the interface animations you’re currently using to identify patterns and evaluate their effectiveness as a group. The Motion Audit To collect all your animations in one place, you’ll need some screen recording software that will output video. QuickTime is a handy built-in option for Macs, but a more specialized tool like ScreenFlow can save you some time with its more robust cropping and editing tools. Use whichever tool is easiest and fastest for you. The exact software used is less important than the end collection and what it will tell you.  How to do a motion audit ( ): Collect screen recordings of every animation currently on your site. (Be sure to get a recording of all the different states for interactive animations.) Crop and edit the video clips as needed to focus in on the animations. Assemble all the video clips into one document and group them in categories according to content type (for example, one slide for all the button animations, one slide for navigation animations, etc.). Review the document with your team to evaluate your brand’s existing animation style. When you have all of those in one place, you can look for global trends, find potential redundancies, and most importantly, evaluate if the way you’re currently using animation accurately reflects the personality of your brand or product.  Software for Motion Audits For the screen recording part of motion audits, I like to use  . It’s Mac only, but   offers similar functionality for both Windows and Mac. The QuickTime player that comes installed with OS X is also an option. It’s especially good for recording animations from an iPhone. Just plug it into the computer and select it as a camera in QuickTime.  My preferred software for the end document is Keynote. (PowerPoint would do just fine here as well.) I prefer it because it makes it easy to set each animation’s video clip to play when clicked and because it lends itself well to be projected and discussed as a group.  When Keynote isn’t an option, creating a web-based motion audit is a good alternative. It’s easy to share, and the video clips can be played directly from within the web pages. I find that having the videos playable from the document is really useful. Often, you’ll discover animations that some of your teammates weren’t aware of or maybe haven’t encountered in a while. The key is having an end result that can be shared and discussed easily. So if there’s another format that your team has a strong preference for, you can make that work, too. Evaluate Your Existing Animation’s Design The first question you’ll want to investigate is: Does the personality expressed by the existing animations fit your brand? Look at the qualities of the animations you’re using to answer this one. What kind of personality traits do the easing and timing used convey? If it’s snappy and bouncy, does that match your brand’s personality and energy? If it’s all stable ease-in-outs, is your brand personality also stable and decided? If you find the mood of the animations doesn’t fit your brand’s personality, small changes to the easing and timing could make a huge difference to bring the animation in line with your brand.  If the personality conveyed from your animations is all over the place and not cohesive at all, starting over and taking the top-down approach described might be the next best step. It’s often easier to work from the top down with a clear vision, as opposed to trying to fix a huge group of existing animations that are all a little bit off.  If the personality conveyed by your animations does fit your brand perfectly, great! Take a detailed look at what all these animations have in common. List the easing, timing, and other design choices they have in common. This will be the basis of your brand’s animation style guide. Evaluate Your Existing Animation’s Purpose Next, look at the purpose of the animations you’ve collected. How are they aiding your users in their tasks? Are they bringing something positive to the experience? Their purpose can be anything from something tactical like providing feedback to something more branding related like expressing your brand’s personality. Challenge yourself to articulate a purpose for each one to help you evaluate how useful they are. If there’s no definable purpose for an animation to be there, consider eliminating or redesigning it to have a solid purpose and goal. (Good UX purposes for animation are covered in Chapters 4 through 8.) It’s also helpful to group the animations in your motion audit by their purpose—gathering up all the animations that are there to give feedback into one section, for example. This can reveal some helpful insights, similarities, and patterns among animations that share a similar purpose. Define Your Brand in Motion from the Top Down If your brand doesn’t currently use any animation or if you’re starting a new project, you can develop your brand’s animation design guidelines from the top down instead. That is, start from your brand’s design philosophy or the traits your brand aims to embody and decide how to translate those into animation. It’s starting from a different place, but it gets you to the same end goal of having specific and defined ways that your brand will exist in motion. The Words You Use to Describe Your Brand Start with the adjectives that you use to describe your brand or product. The description of the personality or feelings it aims to create. Is your brand energetic? Friendly? Strong? Playful? Stable? All this descriptive language can be translated into motion just like it can for other design tools like typography and color. Animation speaks in similar ways. A great place to look for these descriptive words is in your copywriting guidelines or voice and tone guidelines. Many of the same words used to describe how to write for your brand can be directly applied to motion as well. Brand style guides or brand books can also be a good source for descriptive language.  If none of the above exists for your brand, you’ll need to do a little work to define your brand’s voice. “ ” by Erika Heald could be helpful for a quick start. Or to get even deeper into defining your brand, I recommend reading   by Alina Wheeler. Energetic If your brand is energetic, friendly, or bold, animation that relies on a lot of overshoots or follow-through and anticipation can help convey a sense of energy. Softly overshooting the target position can make animations feel both friendly and energetic. Drastic overshoots and quick speed changes read as bold and outgoing. Taken even further, adding a bit of bounce to overshoots or follow-through can convey a sense of even more energy in a movement—so much energy that an object has to bounce off its destination once or twice before it settles ( ). Quick, soft movements—like overshoots—tend to read as energetic in a friendly way. On the other hand, quick movement with sharp changes in direction can suggest impatience, curtness, or urgency. That kind of movement is difficult to show in print, but you can   to see what I mean.  Playful and Friendly Playful brands can take advantage of squash and stretch to convey that playfulness ( ). Squash and stretch also makes movements read as energetic. However, beware, because it can also make motion look childish or sloppy if it’s done with too much of a heavy hand. But, on the other hand, when it’s done well, it can really set you apart.  Bouncy easing can also evoke friendliness or playfulness. Wobbly bounces can seem playful and elastic, while springy bounces can seem friendly. Decisive and Sure Ease-in-outs—that is any easing that gradually speeds up into the action, is fastest in the middle, and then slows at the end of the action—are balanced and stable. They produce animation that accelerates into the action and then slows down to hit its end target exactly and with precision and decisiveness. Sticking with variations of ease-in-outs can communicate a sense of stability and balance for your brand. A variation of ease-in-out easing applied to a simple horizontal movement would look like this video example in  .  Calm The amount of movement you employ can also say something about your brand. Animation doesn’t necessarily have to include large movements or even include motion at all. Smaller movements read as more calm and subtle than larger more drastic movements. Using smaller movements can contribute to the stable and calm personality of your brand. You can still imply the same kinds of movements, just in a less drastic way. For example, when you aim to create small movements, you might have a modal animate into place from 50% of the way down the screen instead of 100% off-screen past the bottom of the visible area ( ). Stable Animating properties like opacity and blur instead of creating movement is another way of conveying a sense of calm and stability ( ). (Animating these properties will change the appearance of the object—making it more transparent or blurred, for example—but because the position of the element isn’t being animated, no movement will occur.) It can also convey a sense of softness or even feel dreamy, depending on how softly you use the opacity and blurs. Sticking to these nonmovement properties can still say so much about your brand in small spaces where motion may not be possible or desirable. These are just the start of adjectives to consider when trying to convey a specific type of energy in the design of your animation. Like most other design tools, it’s more of an art than a science. Experiment with the guidelines to find what expresses your brand best for you.  Referencing Motion from Real Life Looking to the physical world can be a great option for finding your brand’s style for motion by finding a physical object or creature to emulate with your on-screen animation. Technically, you could choose anything at all to base your motion on, but this works best when the thing you choose is relevant—either literally or metaphorically—to your product or brand.  IBM has done a wonderful job of this with its Machines in Motion design guidelines. IBM used to make those giant, room-sized computers, typewriters, and other hardware before becoming the IBM they are today. They decided to reach back to their rich history as a company when defining how they would express their brand in motion ( ). They used these past machines to inform their motion design efforts on two levels. On a high level, they chose four machine traits that all their interface motions should embody: agility, efficiency, precision, and order. From there, they got more specific and paired motion from the actual machines with screen-based equivalent animations. On-screen menu drawers are animated to have the same motion as the carriage return motion of a 1970s IBM typewriter. Loading spinners are animated to have the same acceleration patterns as reel-to-reel tapes of an old mainframe’s tape drives.  These one-to-one translations of motion from the historical real-world objects to the screen-based motion inform all of their motion design decisions. If you have physical objects, either historical or not, that are significant to your brand or product, you could develop your own guidelines using this same approach. A more metaphorical approach to emulating real-world objects can work well, too. Finding a particular dance piece or animal movement that speaks to the same personality values as your brand can be a great place to start. Music can be a source of motion inspiration, even if you’re not including any sound in your interface. Choosing a specific rhythm or phrasing from music to apply to your animation’s movement brings a whole new dimension to the idea of UX choreography. There are so many possibilities out there. Find something that feels inspiring for your brand and explore how it can establish a cohesive thread through all your animations. Staying on Point Animation design guidelines or values can help keep your brand’s motion efforts consistent and cohesive. Collecting and evaluating existing animations as a group with a motion audit can give you valuable insight into how you’re currently using animation. The same words you use to describe your brand and its values can be translated into motion to define your brand’s motion style. Looking to real-world objects or animals to emulate can also help define what your brand looks like in motion. Like this: \n\t\t\t\t\t\t\tRecently by Val Head\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/designing-interface-animation-interview-with-val-head/", "title": "Designing Interface Animation: an Interview with Val Head", "content": "Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites.  on   of  : Are people intimidated by animation? : There are definitely some web folks out there who are intimidated by the idea of using web animation in their work. For some, it’s such a new thing—very few of us have a formal background in motion design or animation—and it can be tough to know where to start or how to use it. I’ve noticed there’s some hesitation to embrace web animation due to the “skip intro” era of Flash sites. There seems to be a fear of recreating past mistakes. But it doesn’t have to be that way at all. We’re in a new era of web animation right now. The fact that we can create animation with the same technologies we’ve always used to make websites—things like CSS and JavaScript—completely changes the landscape. Now that we can make animation that is properly “of the web” (to borrow  ), not just tacked on top with a plug-in, we get to define what the new definition of web animation is with our work. Right now, on the web, we can create beautiful, purposeful animation that is also accessible, progressively enhanced, and performant. No other medium can do that. Which is really exciting!  : I’ve always felt that there was something kind of ahistorical and ahistoricizing about the early web. As the web has matured, it seems to have taken a greater interest in the history and traditions that inform it. Web typography is a good example of this increased self-awareness. Can the same be said for animation? : I think so! In the early days of the web, designers often looked down on it as a less capable medium. Before web type was a thing, a number of my designer friends would say that they could never design for the web because it wasn’t expressive enough as a medium. That the web couldn’t really do design. Then the web matured, web type came along, and that drastically changed how we designed for the web. Web animation is doing much the same thing. It’s another way we have now to be expressive with our design choices, to tell stories, to affect the experience in meaningful ways, and to make our sites unique. With type, we turned to the long-standing craft of print typography for some direction and ideas, but the more we work with type on the web, the more web typography becomes its own thing. The same is true of web animation. We can look to things like   for reference, but we’re still defining exactly what web animation will be and the tools and technologies we use for it. Web animation adds another dimension to how we can design on the web and another avenue for reflecting on what the rich histories of design, animation, and film can teach us. : Do you find that animation often gets tacked on at the end of projects? Why is that? Shouldn’t it be incorporated from the outset? : Yes, it often does get left to the end of projects and almost treated as just the icing on top. That’s a big part of what can make animation seem like it’s too hard or ineffective. If you leave any thought of animation until the very end of a project, it’s pretty much doomed to fail or just be meaningless decoration. Web animation can be so much more than just decoration, but only if we make it part of our design process. It can’t be a meaningful addition to the user experience if you don’t include it in the early conversations that define that experience. Good web animation takes a whole team. You need input from all disciplines touching the design to make it work well. It can’t just be designed in a vacuum and tossed over the fence. That approach fails spectacularly well when it comes to animation. Communicating animation ideas and making animation truly part of the process can be the biggest hurdle for teams to embrace animation. Change is hard! That’s why I dedicated two entire chapters of the book to how to get animation done in the real world. I focus on how to communicate animation ideas to teammates and stakeholders, as well as how to prototype those ideas efficiently so you can get to solutions without wasting time. I also cover how to represent animation in your design systems or documentation to empower everyone (no matter what their background is) to make good motion design decisions. : Can you say more about the importance of a motion audit? Can it be carried out in tandem with a content audit? And how do content and animation tie in with each other? : I find motion audits to be incredibly useful before creating a motion style guide or before embarking on new design efforts. It’s so helpful to know where animation is already being used, and to take an objective look at how effective it is both from a UX angle and a branding angle. If you have a team of any significant size, chances are you’ve probably got a lot of redundant, and maybe even conflicting, styles and uses of animation in your site. Motion audits give you a chance to see what you’re already doing, identify things that are working, as well as things that might be broken or just need a little work. They’re also a great way to identify places where animation could provide value but isn’t being used yet. Looking at all your animation efforts at a high level gives you a chance to consolidate the design decisions behind them, and establish a cohesive approach to animation that will help tie the experience together across mediums and viewport sizes. You really need that high-level view of animation when creating a motion style guide or animation guidelines. You could definitely collect the data for a motion audit in tandem with a content audit. You’ll likely be looking in all the same places, just collecting up more data as you go through your whole site. There is a strong tie between content and animation. I’ve been finding this more and more as I work with my consulting clients. Both can be focused around having a strong message and communicating meaningfully. When you have a clear vision of what you want to say, you can say it with the motion you use just like you can say it with the words you choose. Voice and tone documents can be a great place to start for deciding how your brand expresses itself in motion. I’ve leaned on these more than once in my consulting work. Those same words you use to describe how you’d like your content to feel can be a basis of how you aim to make the animation feel as well. When all your design choices—everything from content, color, type, animation—come from the same place, they create a powerful and cohesive message. : One thing in your book that I found fascinating was your statement that animation “doesn’t have to include large movements or even include motion at all.” Can you talk more about that? And is there any sort of relationship between animation and so called  ? : It’s true, animation doesn’t always mean movement. Motion and animation are really two different things, even though we tend to use the words interchangeably. Animation is a change in some property over time, and that property doesn’t have to be a change in position. It can be a change in opacity, or color, or blur. Those kinds of non-movement animation convey a different feel and message than animation with a lot of motion. If you stick to animating only non-movement properties like opacity, color, and blur, your interface will likely have a more calm and stable feel than if it included a lot of movement. So if your goal is to design something that feels calm, animation can definitely be a part of how you convey that feeling. Any time you use animation, it says something, there’s no getting around that. When you’re intentional with what you want it to say and how it fits in with the rest of your design effort, you can create animation that feels like it’s so much a part of the design that it’s almost invisible. That’s a magical place to be for design.  : Do we also need to be mindful of the potential of animation to cause harm? : We do. Animation can help make interfaces more accessible by reducing cognitive load, helping to focus attention in the right place, or other ways. But it also has potential to cause harm, depending on how you use it. Being aware of how animation can potentially harm or help users leads us to make better decisions when designing it. I included a whole chapter in the book on animating responsibly because it’s an important consideration. I also wrote about   a little while back on  . : Who today, in your opinion, is doing animation right/well/interestingly? : I’m always on the lookout for great uses of animation on the web—in fact, I highlight noteworthy uses of web animation every week in the  .  has been one of my favorites for how well it melds UI animation seamlessly into the design. It really achieves that invisible animation that is so well integrated that you don’t necessarily notice it at first. The smooth 3D, microinteraction animation, and sound design on the   are also really well done, but take a completely different approach to UI animation than Checkout. Publications have been using animation in wonderful ways for dataviz and storytelling lately, too. The  ’s   was a recent data-based favorite of mine and the   did some wonderful storytelling work with animation around the Olympics with  . Also, I really love seeing editorial animation, like the   had on  . The animations they used really brought the story and the sounds they were discussing come to life. I really love seeing web animation used in such a variety of ways. It makes me extra excited for the future of web animation! : Any parting thoughts, Val? : My best advice for folks who want to use more animation in their work is to start small and don’t be afraid to take risks as you get more comfortable working with animation. The more you animate, the better you’ll get at developing a sense for how to design it well. I wrote   to give web folks a solid foundation on animation to build from and I’m really excited to see how web animation will evolve in the near future. For even more web animation tips and resources, join me and a great bunch of designers and developers on the   for a weekly dose of animation knowledge. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/why-we-should-all-be-data-literate/", "title": "Why We Should All Be Data Literate", "content": "Recently, I was lucky enough to see the great Jared Spool talk (spoiler: all Spool talks are great Spool talks). In this instance, the user interface icon warned of the perils of  . Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I am in total agreement with 90 percent of his premise. Collecting and analyzing quantitative data can indeed inform your design decisions, and smart use of metrics can fix critical issues or simply improve the user experience. However, this doesn’t preclude a serious problem with data, or more specifically, with data users. Spool makes this clear: When you don’t understand what data can and can’t tell you and your work is being dictated by decisions based on that lack of understanding—well, your work and product might end up being rubbish. (Who hasn’t heard a manager fixate on some arbitrary metric, such as, “Jane, increase time on page” or “Get the bounce rate down, whatever it takes”?) Designing to blindly satisfy a number almost always leads to a poorer experience, a poorer product, and ultimately the company getting poorer.  Where Spool and I disagree is in his conclusion that all design teams need to include a data scientist. Or, better yet, that all designers should become data scientists. In a perfect world, that would be terrific. In the less-perfect world that most of us inhabit, I feel there’s a more viable way. Simply put: all designers can and should learn to be data literate. Come to think of it, it’d be nice if all citizens learned to be data literate, but that’s a different think piece.  For now, let’s walk through what data literacy is, how to go about getting it for less effort and cost than a certificate from Trump University, and how we can all build some healthy data habits that will serve our designs for the better. What Data Literacy Is and Isn’t Okay, data literacy is a broad term—unlike, say, “design.” In the education field, researchers juggle the terms “quantitative literacy,” “mathematical literacy,” and “quantitative reasoning,” but parsing out fine differences is beyond the scope of this article and, probably, your patience. To keep it simple, let’s think about data literacy as healthy skepticism or even bullshit detection. It’s the kind of skepticism you might adopt when faced with statements from politicians or advertisers. If a cookie box is splashed with a “20% more tasty!” banner, your rightful reaction might be “tastier than what, exactly, and who says?” Yes. Remember that response. Data literacy does require—sorry, phobics—some math. But it’s not so bad. As a designer, you already use math: figuring pixels, or calculating the square footage of a space, or converting ems to percent and back. The basics of what you already do should give you a good handle on concepts like percentages, probability, scale, and change over time, all of which sometimes can hide the real meaning of a statistic or data set. But if you keep asking questions and know how multiplication and division work, you’ll be 92 percent of the way there. (If you’re wondering where I got that percentage from, well—I made it up. Congratulations, you’re already on the road to data literacy.) Neil Lutsky   in terms of the “construction, communication, and evaluation of arguments.” Why is this relevant to you as a designer? As Spool notes, many design decisions are increasingly driven by data. Data literacy enables you to evaluate the arguments presented by managers, clients, and even analytics packages, as well as craft your own arguments. (After all, a key part of design is being able to explain why you made specific design decisions.) If someone emails you a spreadsheet and says, “These numbers say why this design has to be 5 percent more blue,” you need to be able to check the data and evaluate whether this is a good decision or just plain bonkers. Yes, this is part of the job. It’s So Easy Look, journalists can get pretty good at being data literate. Not all journalists, of course, but there’s a high correlation between the ability to question data and the quality of the journalism—and it’s not high-level or arcane learning. One Poynter Institute data course was even taught (in slightly modified form) to grade schoolers. You’re a smart cookie, so you can do this. Not to mention the fact that data courses are often self-directed, online, and free (see “Resources” listed below).  Unlike data scientists who face complex questions, large data sets, and need to master concepts like regressions and Fourier transforms, you’re probably going to deal with less complex data. If you regularly need to map out complex edge-node relationships in a huge social graph or tackle big data, then yes, get that master’s degree in the subject or consult a pro. But if you’re up against Google Analytics? You can easily learn how to ask questions and look for answers. Seriously, ask questions and look for answers. Designers need to be better at data literacy for many of  , as Sarah Doody explains. We need to understand what developers can and can’t do, and we need to understand what the data can and can’t do. For example, an A/B test of two different designs can tell you one thing about one thing, but if you don’t understand how data works, you probably didn’t set up the experiment conditions in a way that leads to informative results. (Pro tip: if you want to see how a change affects click-through, don’t test two designs where multiple items differ, and don’t expect the numbers to tell you why that happened.) Again: We need to question the data.  So we’ve defined a need, researched our users, and identified and defined a feature called data literacy. What remains is prototyping. Let’s get into it, shall we? How to Build Data Literacy by Building Habits Teaching data literacy is an ongoing topic of academic research and debate, so I’ll leave comprehensive course-building to more capable hands than mine. But together, we can cheaply and easily outline simple habits of critical thought and mathematical practice, and this will get us to, let’s say, 89 percent data literacy. At the least, you’ll be better able to evaluate which data could make your work better, which data should be questioned more thoroughly, and how to talk to metric-happy stakeholders or bosses. (Optional homework: this week, take one metric you track or have been told to track at work, walk through the habits below, and report back.) Habit one: Check source and context This is the least you should do when presented with a metric as a fait accompli, whether that metric is from a single study, a politician, or an analytics package.  First, ask about the source of the data (in journalism, this is reflex— ). Knowing the source, you can then investigate the second question. The second question concerns how the data was collected, and what that can tell you—and what it can’t.  Let’s say your boss comes in with some numbers about time-on-page, saying “Some pages are more sticky than others. Let’s redesign the others to keep customers on all the other pages longer.” Should you jump to redesign the less-sticky pages, or is there a different problem at play? It’s simple, and not undermining, to ask how time-on-page was measured and what it means. It could mean a number of things, things that that single metric will never reveal. Things that could be real problems, real advantages, or a combination of the two. Maybe the pages with higher time-on-page numbers simply took a lot longer to load, so potential customers were sitting there as a complex script or crappy CDN was   drawing things on the not-a-customer-any-more’s screen. Or it could mean some pages had more content. Or it could mean some were designed poorly and users had to figure out what to do next.  How can you find this out? How can you communicate that it’s important to find out? A quick talk with the dev team or running a few observations with real users could lead you to discover what the real problem is and how you can redesign to improve your product.  What you find out could be the difference between good and bad design. And that comes from knowing how a metric is measured, and what it doesn’t measure. The metric itself won’t tell you. For your third question, ask the size of the sample. See how many users were hitting that site, whether the time-on-page stat was measured for all or some of these users, and whether that’s representative of the usual load. Your design fix could go in different directions depending on the answer. Maybe the metric was from just one user! This is a thing that sometimes happens. Fourth, think and talk about context. Does this metric depend on something else? For example, might this metric change over time? Then you have to ask over what time period the metric was measured, if that period is sufficient, and whether the time of year when measured might make a difference.  Remember when I said change over time can be a red flag? Let’s say your boss is in a panic, perusing a chart that shows sales from one product page dropping precipitously last month. Design mandates flood your inbox: “We’ve got to promote this item more! Add some eye-catching design, promote it on our home page!”  What can you do to make the right design decisions? Pick a brighter blue for a starburst graphic on that product page? Maybe it would be more useful to look at a calendar. Could the drop relate to something seasonal that should be expected? Jack o’lantern sales do tend to drop after November 1. Was there relevant news? Apple’s sales always drop before their annual events, as people expect new products to be announced. A plethora of common-sense questions could be asked.  The other key point about data literacy and change is that being data literate can immunize against common errors when looking at change over time. This gets to numeracy. Habit two: Be numerate I first learned about numeracy through John Allen Paulos’ book  , though the term “innumeracy” was originated by Pulitzer Prize-winning scientist Douglas Hofstadter. Innumeracy is a parallel to illiteracy; it means the inability to reason with numbers. That is, the innumerate can do math but are more likely to trip up when mathematical reasoning is critical. This often happens when dealing with probability and coincidence, with statistics, and with things like percentages, averages, and changes.  —these can be hard to sort out sort out! We’re presented with these metrics a lot, but usually given little time to think about them, so brushing up on that bit of math can really help put out (or avoid) a trash fire of bad design decisions. Consider this:  A founder comes in with the news that an app has doubled its market base in the two weeks it’s been available. It’s literally gone up 100 percent in that time. That’s pretty awesome, right? Time to break out the bubbly, right? But what if you asked a few questions and found that this really meant the founder was the first user, then eventually her mom got onto it. That is literally doubling the user base exactly 100 percent. Of course that’s obvious and simple. You see right off why this startup probably shouldn’t make the capital outlay to acquire a bottle or two juuuust yet. But exactly this kind of error gets overlooked easily and often when the math gets a bit more complex.  Any time you see a percentage, such as “23% more” or “we lost 17%,” don’t act until you’ve put on your math hat. You don’t even need to assume malice; this stuff simply gets confusing fast, and it’s part of your job not to misread the data and then make design decisions based on an erroneous understanding.  Here’s an example from Nicolas Kayser-Bril, who looks into the headline, “ “:  “Take 1,000 Germans. A single one will develop MS over his lifetime. Now, if every one of these 1,000 Germans worked night shifts, the number of MS sufferers would jump to two. The additional risk of developing MS when working in shifts is one in 1,000, not 100%. Surely this information is more useful when pondering whether to take the job.” This is a known issue in science journalism that isn’t discussed enough, and often leads to misleading headlines. Whenever there’s a number suggesting something that affects people, or a number suggesting change, look not just at the percentage but at what this would mean in the real world; do the math and see if the result matches the headline’s intimation. Also  . How was the sausage made? Lynn Arthur Steen explains how percentages presented to you may not just be the difference of two numbers divided by a number. Base lesson: always learn what your analytics application measures and how it calculates things.  …so that’s, what, 80 percent true? Averages are another potentially deceptive metric that simple math can help; sometimes it’s barely relevant, if at all. “The average length of a book purchased on Amazon is 234.23 pages” may not actually tell you anything. Sometimes you need to look into what’s being averaged. Given the example “One in every 15 Europeans is illiterate,” Kayser-Bril points out that maybe close to one in 15 Europeans is under the age of seven. It’s good advice to learn the terms “mode,” “median,” and “standard deviation.” (It doesn’t hurt (much), and can make you a more interesting conversationalist at dinner parties!) Habit three: Check your biases I know, that sounds horrible. But in this context, we’re talking about cognitive biases, which everyone has (this is why I encourage designers to study psychology, cognition studies, and sociology as much as they can). Though we have biases, it’s how aware we are of these issues and how we deal with them that counts. It’s out of scope to list and describe them all (just thinking I know them all is probably an example of Dunning-Kruger). We’ll focus on two that are most immediately relevant when you’re handed supposedly-objective metrics and told to design to them. At least, these are two that I most often see, but that may be selection bias. Any metric or statistical analysis is only as good as (in part) what you choose to measure. Selection bias is when your choice of what to measure isn’t really random or representative. This can come from a conscious attempt to skew the result, from carelessly overlooking context, or due to some hidden process.  One example might be if you’re trying to determine the average height of the adult male in the United States and find it to be 6'4\"— . Online opinion polls are basically embodied examples of selection bias, as the readers of a partisan site are there because they already share the site operator’s opinion. Or you may be given a survey that shows 95 percent of users of your startup’s app say they love it, but when you dig in to the numbers, the people surveyed were all grandmothers of the startup team employees (“Oh, you made this, dear? I love it!”). This holds in usability testing, too: if you only select, say, high-level programmers, you may be convinced that a “to install this app, recompile your OS kernel” is a totally usable feature. Or end up with Pied Piper’s UI. Now, these all seem like “sure, obvs” examples. But selection bias can show up in much more subtle forms, and in things like clinical studies. Dr. Madhukar Pai’s slides   give some great examples — especially check out Slide 47, which shows how telephone surveys have almost built-in selection biases. So, what’s a designer to do? As you can see from Dr. Pai’s lecture slides, you can quickly get into some pretty “mathy” work, but the main point is that when you’re faced with a metric, after you’ve checked out the context, look at the sample. You can think about the claim on the cookie box in this way. It’s “20% more tasty”?  What was the sample, 19 servings of chopped liver and one cookie? Storytelling is a powerful tool. Again, it’s how our brains are wired. But as with all tools, it can be used for good or for evil, and can be intentional or accidental. As designers, we’re told we have to be storytellers: how do people act, how do they meet-cute our product, how do they feel, what’s the character arc? This is how we build our knowledge of the world, by building stories about it. But, as Alberto Cairo explains in   this is closely linked to confirmation bias, where we unconsciously (or consciously) search for, select, shape, remember, interpret, or otherwise torture basic information so that it matches what we already think we know, the stories we have. We want to believe. Confirmation bias can drive selection bias, certainly. If you only test your design with users who already know how your product works (say, power users, stakeholders, and the people who built the product), you will get distorted numbers and a distorted sense of how usable your product is. Don’t laugh: I know of a very large and popular internet company that only does user re-search with power users and stakeholders. But even if the discovery process is clean, confirmation bias can screw up the interpretation. As Cairo writes, “Even if we are presented with information that renders our beliefs worthless, we’ll try to avoid looking at it, or we’ll twist it in a way that confirms them. We humans try to reduce dissonance no matter what.” What could this mean for your design practice? What could this mean for your designs when stakeholders want you to design to specific data? Reading (Numbers) is Fundamental So, yes. If you can work with a data scientist in your design team, definitely do so. Try to work with her and learn alongside her. But if you don’t have this luxury, or the luxury of studying statistics in depth, think of data literacy as a vital part of your design practice. Mike Monteiro is passionate that designers need to know math, and he’s of course correct, but we don’t need to know math just to calculate visual design. We need to know math enough to know how to question and analyze any metric we’re given.  This is something you can practice in everyday life, especially in an election season. When you see someone citing a study, or quoting a number, ask: What was measured? How was it measured? What was the context? What wasn’t measured? Does that work out in real life? Keep looking up terms like selection bias, confirmation bias, Dunning-Kruger, sample size effect, until you remember them and their application. That is how you build habits, and how you’ll build your data literacy muscles. I’ve long loved the Richard Feynman quote (that Cairo cites in  ): “The first principle is that you must not fool yourself — and you are the easiest person to fool.” Consider always that you might be fooling yourself by blindly accepting any metric handed to you. And remember, the second-easiest person to fool is the person who likely handed you the metric, and is motivated to believe a particular outcome. Data literacy requires honesty, mastering numeracy, and stepping through the habits we’ve discussed. Practice every day with news from politics: does a statistic in the news give you that “of course, that’s how things are” feeling? Take a deep breath, and dig in; do you agree with a policy or action because it’s your political party proposing it? What’s the context, the sample size, the bias? It’s tough to query yourself this way. But that’s the job. It’s tougher to query someone else this way, whether it’s your boss or your significant other. I can’t help you figure out the politics and social minefield of those. But do try. The quality of your work (and life) may depend on it. Resources Cairo, Alberto.  Cairo, Alberto.  Goldacre, Ben.  Tavris, Carol and Aronson, Elliot.  Kahneman, Daniel.  Like this: \n\t\t\t\t\t\t\tRecently by Dan Turner\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/task-performance-indicator-management-metric-for-customer-experience/", "title": "Task Performance Indicator: A Management Metric for Customer Experience", "content": "It’s hard to quantify the customer experience. “Simpler and faster for users” is a tough sell when the value of our work doesn’t make sense to management. We have to prove we’re delivering real value–increased the success rate, or reduced time-on-task, for example–to get their attention. Management understands metrics that link with other organizational metrics, such as lost revenue, support calls, or repeat visits. So, we need to describe our environment with metrics of our own. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. For the team I work with, that meant developing a remote testing method that would measure the impact of changes on customer experience—assessing alterations to an app or website in relation to a defined set of customer “top tasks.” The resulting metric is stable, reliable, and repeatable over time. We call it the Task Performance Indicator (TPI). For example, if a task has a TPI score of 40 (out of 100), it has major issues. If you measure again in 6 months’ time but nothing has been done to address the issues, the testing score will again result in a TPI of 40. In traditional usability testing, it has long been established that if you test with between three and eight people, you’ll find out if significant problems exist. Unfortunately, that’s not enough to reveal precise success rates or time-on-task measurements. What we’ve discovered from hundreds of tests over many years is that reliable and stable patterns aren’t apparent until you’re testing with between 13 and 18 people. Why is that? When the number of participants ranges anywhere from 13–18 people, testing results begin to stabilize and you’re left with a reliable baseline TPI metric.  The following chart shows why we can do this ( ). How TPI scores are calculated We’ve spent years developing a single score that we believe is a true reflection of the customer experience when completing a task.  For each task, we present the user with a “task question” via live chat. Once they understand what they have to do, the user indicates that they are starting the task. At the end of the task, they must provide an answer to the question. We then ask people how confident they are in their answer. A number of factors affect the resulting TPI score.  We establish what we call the “Target Time”—how long it should take to complete the task under best practice conditions. The more they exceed the target time, the more it affects the TPI.  The person takes longer than the maximum time allocated. We set it at 5 minutes.  At the end of each task, people are asked how confident they are. For example, low confidence in a correct answer would have a slight negative impact on the TPI score.  The person is unsure; their answer is almost correct.  The person has high confidence, but the wrong result; acting on this wrong answer could have serious consequences.  The person gives up on the task. A TPI of 100 means that the user has successfully completed the task within the agreed target times. In the following chart, the TPI score is 61 ( ). Developing task questions Questions are the greatest source of potential noise in TPI testing. If a question is not worded correctly, it will invalidate the results. To get an overall TPI for a particular website or app, we typically test 10-12 task questions. In choosing a question, keep in mind the following:  You must choose task questions that are examples of top tasks. If you measure and then seek to improve the performance of tiny tasks (low demand tasks) you may be contributing to a decline in the overall customer experience.  Create task questions that you can test again in 6 to 12 months.  Don’t make the task questions particularly difficult. Start off with reasonably basic, typical questions.  Every one of your test participants must be able to do each task. If you’re going to be testing a mixture of technical, marketing, and sales people, don’t choose a task question that only a salesperson can do.  Limit each task question to only one actual thing you want people to do, and one unique answer.  The participant will examine the task question like Sherlock Holmes would hunt for a clue. Make sure it doesn’t contain any obvious keywords that could be answered by conducting a search.  Remember, the participant is seeing each task question for the first time, so aim to keep its length at less than 20 words (and definitely less than 30).  Choose questions where the website or app is not likely to change during the testing period. Otherwise, you’re not going to be testing like with like. Case Study: Task questions for OECD Let’s look at some top tasks for the customers of Organisation for Economic Co-operation and Development (OECD), an economic and policy advice organization. Based on that list, these task questions were developed: Running the test To test 10-12 task questions usually takes about one hour, and you’ll need between 13 and 18 participants (we average 15). Make sure that they’re representative of your typical customers.   We’ve found that   than traditional lab-based measurement for TPI testing. With remote testing, people are more likely to behave in a natural way because they are in their normal environment—at home or in the office—and using their own computer. That makes it much easier for someone to give you an hour of their time, rather than spend the morning at your lab. And since the cost is much lower than lab-based tests, we can set them up more quickly and more often. It’s even convenient to schedule them using Webex, GoToMeeting, Skype, etc.  The key to a successful test is that you are confident, calm, and quiet. You’re there to facilitate the test—not to guide it or give opinions. Aim to become as invisible as possible.  Prior to beginning the test, introduce yourself and make sure the participant gives you permission to record the session. Next, ask that they share their screen. Remember to stress that you are only testing the website or app—not them. Ask them to go to an agreed start point where all the tasks will originate. (We typically choose the homepage for the site/app, or a blank tab in the browser.) Explain that for each task, you will paste a question into the chat box found on their screen. Test the chat box to confirm that the participant can read it, and tell them that you will also read the task aloud a couple of times. Once they understand what they have to do, ask them to indicate when they start the task, and that they must give an answer once they’ve finished. After they’ve completed the task, ask the participant how confident they are in their answer.  Analyzing the results As you observe the tests, you’re looking for patterns. In particular, look for the major reasons people give for selecting the wrong answer or exceeding the target time.  Video recordings of your customers as they try—and often fail—to complete their tasks have powerful potential. They are the raw material of empathy. When we identify a major problem area during a particular test, we compile a video containing three to six participants who were affected. For each participant, we select less than a minute’s worth of video showing them while affected by this problem. We then edit these participant snippets into a combined video (that we try to keep under three minutes). We then get as many stakeholders as possible to watch it. You should seek to distribute these videos as widely, and as often as possible.  How Cisco uses the Task Performance Indicator Every six months or so, we measure several tasks for Cisco, including the following: The top task of Cisco customers is downloading software. When we started the Task Performance Indicator for software downloads in 2010, a typical customer might take 15 steps and more than 300 seconds to download a piece of software. It was a very frustrating and annoying experience. The Cisco team implemented a continuous improvement process based on the TPI results. Every six months, the Task Performance Indicator was carried out again to see what had been improved and what still needed fixing. By 2012—for a significant percentage of software—the number of steps to download software had been reduced from 15 to 4, and the time on task had dropped from 300 seconds to 40 seconds. Customers were getting a much faster and better experience. According to Bill Skeet, Senior Manager of Customer Experience for Cisco Digital Support, implementing the TPI has had a dramatic impact on how people think about their jobs: We now track the score of each task and set goals for each task. We have assigned tasks and goals to product managers to make sure we have a person responsible for managing the quality of the experience … Decisions in the past were driven primarily by what customers said and not what they did. Of course, that sometimes didn’t yield great results because what users say and what they do can be quite different. Troubleshooting and bug fixing are also top tasks for Cisco customers. Since 2012, we’ve tested the following. For a variety of reasons, it was difficult to solve the underlying problems connected with finding the right bug fix information on the Cisco website. Thus, the scores from February 2012 to February 2013 did not improve in any significant way.  For the May 2013 measurement, the team ran a pilot to show how (with the proper investment) it could be much easier to find bug fix information. As we can see in the preceding image, the success rate jumped. However, it was only a pilot and by the next measurement it had been removed and the score dropped again. The evidence was there, though, and the team soon obtained resources to work on a permanent fix. The initial implementation was for the July 2014 measurement, where we see a significant improvement. More refinements were made, then we see a major turnaround by December 2014. This task was initially measured in 2014; the results were not good. In fact, nobody succeeded in completing the task during the March 2014 measurements, resulting in three specific design improvements to the sign-up form. These involved: A shorter pilot form was also launched as a proof of concept. Success jumped by 50% in the July 2014 measurements, but dropped 21% by December 2014 because the pilot form was no longer there. By June 2015, a shorter, simpler form was fully implemented, and the success again reached 50%.  The team was able to show that because of their work: The three design improvements improved the success rate by 29%. The shorter form improved the success rate by 21%. That’s very powerful. You can isolate a piece of work and link it to a specific increase in the TPI. You can start predicting that if a company invests X it will get a Y TPI increase. This is control and the route to power and respect within your organization, or to trust and credibility with your client. If you can link it with other key performance indicators, that’s even more powerful.  The following table shows that improvements to the registration form halved the support requests connected with guest account registration ( ). A more simplified guest registration process resulted in: A reduction in support requests—from 1,500 a quarter, to less than 700 Three fewer people were required to support customer registration 80% productivity improvement Registration time down to 2 minutes from 3:25. When we measured the change passwords task, we found that there was a 37% failure rate.  A process of improvement was undertaken, as can be seen by the following chart, and by December 2013, we had a 100% success rate ( ). 100% success rate is a fantastic result. Job done, right? Wrong. In digital, the job is never done. It is always an evolving environment. You must keep measuring the top tasks because the digital environment that they exist within is constantly changing. Stuff is getting added, stuff is getting removed, and stuff just breaks ( ). When we measured again in March 2014, the success rate had dropped to 59% because of a technical glitch. It was quickly dealt with, so the rate shot back up to 100% by July.  At every step of the way, the TPI gave us evidence about how well we were doing our job. It’s really helped us fight against some of the “bright shiny object” disease and the tendency for everyone to have an opinion on what we put on our webpages … because we have data to back it up. It gave us more insight into how content organization played a role in our work for Cisco, something that Jeanne Quinn (senior manager responsible for the Cisco Partner) told us kept things clear and simple while working with the client. The TPI allows you to express the value of your work in ways that makes sense to management. If it makes sense to management—and if you can prove you’re delivering value—then you get more resources and more respect.   Like this: \n\t\t\t\t\t\t\tRecently by Gerry McGovern\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/redesign-with-css-shapes/", "title": "A Redesign with CSS Shapes", "content": "Here at An Event Apart (an   sibling) we recently refreshed the design of our “ ” page, which had retained an older version of our site design and needed to be brought into alignment with the rest of the site. Along the way, we decided to enhance the page with some cutting-edge design techniques: non-rectangular float shapes and feature queries.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. To be clear, we didn’t set out to create a Cutting Edge Technical Example™; rather, our designer (Mike Pick of  ) gave us a design, and we realized that his vision happened to align nicely with new CSS features that are coming into mainstream support. We were pleased enough with the results and the techniques that we decided to share them with the community. Styling bubbles Here are some excerpts from an earlier stage of the designs ( ). (The end-stage designs weren’t created as comps, so I can’t show their final form, but these are pretty close.) What interested me was the use of the circular images, which at one point we called “portholes,” but I came to think of as “bubbles.” As I prepared to implement the design in code, I thought back to   throughout the year at An Event Apart. Specifically, I thought about   and how I might be able to use them to let text flow along the circles’ edges—something like  . This layout technique used to be sort of possible by using crude float hacks like   and  , but now we have float shapes! We can define a circle—or even a polygon—that describes how text should flow past a floated element. “Wait a minute,” you may be saying, “I haven’t heard about widespread support for Shapes!” Indeed, you have not. They’re currently supported only in the WebKit/Blink family—Chrome, Safari, and Opera. But that’s no problem: in other browsers, the text will flow past the boxy floats the same way it always has. The same way it does in the design comps, in fact. The basic CSS looks something like this: Each of those bubble images, by the way, is intrinsically 260px wide by 260px tall. In wide views like desktops, they’re left to that size; at smaller widths, they’re scaled to 30% of the viewport’s width. Shape placement To understand the shape setup, look at the left-side bubbles. They’re 260×260, with an extra 40 pixels of right margin. That means the margin box (that is, the box described by the outer edge of the margins) is 300 pixels wide by 260 pixels tall, with the actual image filling the left side of that box. This is why the circular shape is centered at the point  —it’s the midpoint of the image in question. So the circle is now centered on the image, and has a radius of  . That means it extends 20 pixels beyond the visible outer edge of the circle, as shown here ( ). In order to center the circles on the right-side bubbles, the center point has to be shifted to  —traversing the 40-pixel left margin, and half the width of the image, to once again land on the center. The result is illustrated here, with annotations to show how each of the circles’ centerpoints are placed ( ). It’s worth examining that screenshot closely. For each image, the light blue box shows the element itself—the   element. The light orange is the basic margin area, 40 pixels wide in each case. The purple circle shows the   circle. Notice how the text flows into the orange area to come right up against the purple circle. That’s the effect of  . Areas of the margin outside that shape, and even areas of the element’s   outside the shape, are available for normal-flow content to flow into. The other thing to notice is the purple circle extending outside the margin area.  This is misleading: any shape defined by   is clipped at the edge of the element’s margin box. So if I were to increase the circle’s radius to, say, 400 pixels, it would cover half the page in Chrome’s inspector view, but the actual layout of text would be around the margin edges of the floated image—as if there were no shape at all. I’d really like to see Chrome show this by fading the parts of the shape that extend past the margin box. (Firefox and Edge should of course follow suit!) Being responsive At this point, things seem great; the text flows past circular float shapes in Chrome/Safari/Opera, and past the standard boxy margin boxes in Firefox/Edge/etc. That’s fine as long as the page never gets so narrow as to let text wrap between bubbles—but, of course, it will, as we see in this screenshot ( ). For the right-floating images, it’s not so bad—but for the left floaters, things aren’t as nice. This particular situation is passably tolerable, but in a situation where just one or two words wrap under the bubble, it will look awful. An obvious first step is to set some margins on the paragraphs so that they don’t wrap under the accompanying bubbles. For example: The point here being, for all even-numbered child  s (that aren’t the last child) in a complex-content context, add a 20% right margin; for the odd-numbered  s, a similar left margin. That’s pretty good in Chrome ( ) (with the circular float shapes) because the text wraps along the bubble and then pushes off at a sensible point. But in Firefox, which still has the boxy floats, it creates a displeasing stairstep effect ( ). On the flip side, increasing the margin to the point that the text all lines up in Firefox (33% margins) would mean that the float shape in Chrome would be mostly pointless, since the text would never flow down along the bottom half of the circles. Querying feature support This is where   came into play. By using   to run a feature query, I could set the margins for all browsers to the   needed when shapes aren’t supported, and then reduce it for browsers that   understand shapes. It goes something like this: With that, everything is fine in the two worlds (  and  ). There are still a few things that could be tweaked, but overall, the effect is pleasing in browsers that support float shapes, and also those that don’t. The two experiences are shown in the following videos. (They don’t autoplay, so click at your leisure.) \n \n Thanks to feature queries, as browsers like Firefox and MS Edge add support for float shapes, they’ll seamlessly get the experience that currently belongs only to Chrome and its bretheren.  There’s no browser detection to adjust later, no hacks to clear out. There’s only silent progressive enhancement baked right into the CSS itself.  It’s pretty much “style and forget.” While an arguably minor enhancement, I really enjoyed the process of working with shapes and making them progressively and responsively enhanced. It’s a nice little illustration of how we can use advanced features of CSS right now, without the usual wait for widespread support. This is a general pattern that will see a lot more use as we start to make use of shapes, flexbox, grid, and more cutting-edge layout tools, and I’m glad to be able to offer this case study. Further reading If you’d like to know more about float shapes and feature queries, I can do little better than to recommend the following articles.  by Sara Soueidan  by Jen Simmons Like this: \n\t\t\t\t\t\t\tRecently by  Eric Meyer\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/using-css-mod-queries-with-range-selectors/", "title": "Using CSS Mod Queries with Range Selectors", "content": "Recently, I was asked to build a simple list that would display in a grid—one that could start with a single element and grow throughout the day, yet alway be tidy regardless of the length. So, as you do sometimes when you’re busy with one thing and asked if you can do something completely different, I tried to think of any reason why it couldn’t be done, came up blank, and distractedly said, “Yes.” Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. At the time, I was working on a London-based news organization’s website. We’d spent the previous year migrating their CMS to the Adobe AEM platform while simultaneously implementing a responsive UI—both big improvements. Since that phase was complete, we were starting to focus on finessing the UI and building new features. The development project was divided into a number of small semiautonomous teams. My team was focusing on hub pages, and I was leading the UI effort. Each hub page is essentially a list of lists, simply there to help readers find content that interests them. As you can imagine, a news website is almost exclusively made of content lists! A page full of generic vertical lists would be unhelpful and unappealing; we wanted readers to enjoy browsing the content related to their sphere of interest. Sections needed to be distinct and the lists had to be both individually distinguishable and sit harmoniously together. In short, the visual display was critical to the usability and effectiveness of the entire page. That “simple list” I said I’d build would be high profile, sitting in its own panel near the top of a hub page and serving to highlight a specific point of interest. Starting with one item and growing throughout the day as related articles were published, the list needed to be a rectangular grid rather than a single column, and never have “leftover” items in the last row. And no matter how many child elements it contained at any given moment, it had to stay tidy and neat because it would display above the fold. Each item would be more or less square, with the first item set at 100% width, the second two at 50%, and all subsequent items 33% and arranged in rows of three. My simple list suddenly wasn’t so simple. Not everyone wants a generic grid or stack of identical items—there’s something nice about selective prominence, grouped elements, and graceful line endings. These styles can be hardcoded if you know the list will always be an exact length, but it becomes more of a challenge when the length can change. How could I keep that last row tidy when there were fewer than three items? When it came to actually building the thing, I realized that knowing the length of the list wasn’t very helpful. Having loved  , I assumed I could find out the length of the list using QQs, then style it accordingly and all would be fine. But since my list could be any length, I’d need an infinite number of QQs to meet the requirements! I couldn’t have a QQ for every eventuality. Plus, there were rumors a “Load More” button might be added down the road, letting users dynamically inject another 10 or so items. I needed a different solution. After a minor meltdown, I asked myself,   Well, not panicking would be a good start. Also, it would help to simplify and identify the underlying requirements. Since the list would fundamentally comprise rows of three, I needed to know the remainder from mod 3. The “mod” query Being able to select and style elements by the number of siblings is great, but there’s more to this than mere length. In this case, it would be much better to know if my list is divisible by a certain number rather than how long it is.  Unfortunately, there isn’t a native mod query in CSS, but we can create one by combining two selectors:   (aka the “modulo” selector) and the   selector. The following query selects everything if the list is divisible by three: Let’s talk through that code. (I use li for “list item” in the examples.) The css selector: That combination basically means if the first child is   from the end, select all of its siblings.  The query selects all siblings of the first item, but doesn’t include the first item itself, so we need to add a selector for it separately. Check out the demo and  What about remainders?  With my mod query, I can select all the items in a list if the list is divisible by three, but I’ll need to apply different styles if there are remainders. (In the case of remainder 1, I’ll just need to count back in the CSS from the second-to-last element, instead of the last. This can be achieved by simply adding   to the query.) Ditto for remainder 2—I just add   to the query.  Creating a range selector Now I have a way to determine if the list length is divisible by any given number, with or without remainders, but I still need to select a range. As with mod query, there isn’t a native CSS range selector, but we can create one by combining two selectors:   (i.e., “everything above”) and   (i.e., “everything below”). This allows us to select items 3 to 5, inclusive:  True, that could just as easily be achieved with simple   syntax and targeting the item positions directly— —but defining a start and end to a range is obviously much more versatile. Let’s quickly unpack the selector to see what it’s doing.   Combining the two— —creates a range selector.  If we look at an example, we might have a product grid where the list items contain an image, title, and description. Let’s say the product image speaks for itself, so in the first row we promote the image and hide all the text. With the second and third row, we display the title and image as a thumbnail, while in subsequent rows we hide the image and show the title and description on a single line. By using the range selector, we can select the first three, the fourth through ninth, and the 10th onwards. This allows us to change the ranges at different breakpoints in the CSS so we can keep our product grid nice and responsive. Notes on SCSS mixins Since I was using a CSS preprocessor, I simplified my code by using preprocessor functions; these are SCSS mixins for creating range selectors and mod queries. Then in my code I could nest the mixins. Which is, if nothing else, much easier to read! Putting it all together So now that I have a little arsenal of tools to help me deal with mods, ranges, and ranges within mods, I can break away from standard-implementation fixed length or fixed-layout lists. Creative use of mod queries and range selectors lets me apply styles to change the layout of elements. Getting back to the original requirement—getting my list to behave—it became clear that if I styled the list assuming it was a multiple of three, then there would only be two other use cases to support:  Mod 3, remainder 1 Mod 3, remainder 2 If there was one remaining item, I’d make the second row take three items (instead of the default two), but if the remainder was 2, I could make the third row take two items (with the fourth and fifth items at 50%).  In the end, I didn’t need numerous queries at all, and the ones I did need were actually quite simple.  There   one special case:  That was solved with a query to select the second item when it’s also the last child. The queries ultimately weren’t as hard as I’d expected; I just needed to combine the mod and range selectors.  Altogether, my CSS looked something like this in the end:  Experience for yourself (and a note on browser support) The mod queries and range selectors used in this article rely on the CSS3 selectors, so they will work in  , including Internet Explorer 9 and above (but remember, IE will expect a valid doctype).  I created   that you can use to experiment with mod queries. When I first came across QQs, I thought they were great and interesting but largely theoretical, without many practical real-world use cases. However, with mobile usage outstripping desktop, and responsive design now the norm, the need to display lists, target parts of lists depending on the length/mod, and display lists differently at different breakpoints has become much more common. This really brings the practical application of QQs into focus, and I’m finding more than ever that they are an essential part of the UI developer’s toolkit. Additional resources Like this: \n\t\t\t\t\t\t\tRecently by Patrick Clancey\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/liminal-thinking/", "title": "Liminal Thinking", "content": "A theory that explains everything, explains nothing Here’s a story I heard from a friend of mine named Adrian Howard. His team was working on a software project, and they were working so hard that they were burning themselves out. They were working late nights, and they agreed as a team to slow down their pace.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Well, there was one guy on the team who just didn’t do that. He was staying late at night, and Adrian was getting quite frustrated by that. Adrian had a theory about what was going on. What seemed obvious to him was that this guy was being macho, trying to prove himself, trying to outdo all the other coders, and showing them that he was a tough guy. Everything that Adrian could observe about this guy confirmed that belief.  Late one night, Adrian was so frustrated that he went over and confronted the guy about the issue. He expected a confrontation, but to his surprise, the guy broke down in tears. Adrian discovered that this guy was not working late because he was trying to prove something, but because home wasn’t a safe place for him. They were able to achieve a breakthrough, but it was only possible because Adrian went up and talked to him. Without that conversation, there wouldn’t have been a breakthrough. It’s easy to make up theories about why people do what they do, but those theories are often wrong, even when they can consistently and reliably predict what someone will do. For example, think about your horoscope. Horoscopes make predictions all the time: “Prepare yourself for a learning experience about leaping to conclusions.” “You may find the atmosphere today a bit oppressive.” “Today, what seems like an innocent conversation will hold an entirely different connotation for one of the other people involved.” “Stand up to the people who usually intimidate you. Today, they will be no match for you.” These predictions are so vague that you can read anything you want into them. They are practically self-fulfilling prophecies: if you believe them, they are almost guaranteed to come true, because you will set your expectations and act in ways that make them come true. And in any case, they can never be disproven.  So what makes a good theory, anyway? A scientist and philosopher named Karl Popper spent a lot of time thinking about this. Here’s the test he came up with, and I think it’s a good one: Does the theory make a prediction that might not come true? That is, can it be proven false? What makes this a good test? Popper noted that it’s relatively easy to develop a theory that offers predictions—like a horoscope—that can never be disproven.  The test of a good theory, he said, is not that it   be disproven, but that it   be disproven. For example, if I have a theory that you are now surrounded by invisible, undetectable, flying elephants, well, there’s no way you can prove me wrong. But if my theory can be subjected to some kind of test—if it is possible that it could be disproved, then the theory can be tested. He called this trait  : the possibility that a theory could be proven false. Many theories people have about other people are like horoscopes. They are not falsifiable theories, but self-fulfilling prophecies that can never be disproven. Just because you can predict someone’s behavior does not validate your theories about them, any more than a horoscope prediction “coming true” means it was a valid prediction. If you want to understand what’s going on inside someone else’s head, sometimes you need to have a conversation with them.  Many years after the Vietnam War, former U.S. Secretary of State Robert McNamara met with Nguyen Co Thach, former Foreign Minister of Vietnam, who had fought for the Viet Cong in the war. McNamara had formed the hypothesis that the war could have been avoided, that Vietnam and the United States could have both achieved their objectives without the terrible loss of life. When he presented his thinking to Thach, Thach said,     asked McNamara.   answered Thach.  McNamara then realized that the entire war had been based on a complete misunderstanding. He said:  Sometimes people come into conflict not because they disagree, but because they fundamentally misunderstand each other. This can happen when people are viewing a situation from completely different points of view. Have you ever had someone that you worked with, where you thought, this person is insane; they make no sense; they are crazy; they’re just nuts? Everyone knows someone like that, right?  Sometimes people really do have mental disorders, including problems that can create danger for themselves and others. If that’s the case, it might make sense to stay away from them, or to seek help from a mental health professional. But far more often, saying another person is crazy is just a way to create internal coherence within your belief bubble. Your “obvious” is stopping you from seeing clearly. The “crazy person” may be acting based on beliefs that are inconceivable to you because they are outside your bubble.  If you think to yourself, this person is just nuts, and nothing can be done about it, it can’t be changed, then it’s possible that your theory about that person is constrained by a limiting belief. Most people don’t test their theories about other people, because it’s a potential bubble-buster: if you give your self-sealing logic bubble a true test, then it just might collapse on you.  People do fake tests all the time, of course. Here’s an easy way to do a fake test of your beliefs. Just search the Internet. No matter what your belief is, you’ll find plenty of articles that support and reinforce your bubble. The Internet is like a grocery store for facts. It’s easier than ever to find “facts” that support pretty much any belief. Fake tests will help if your goal is to feel better about yourself and reinforce your bubble. But if you want to figure out what is really going on, a fake test will not help.  What will help is triangulation: the practice of developing multiple viewpoints and theories that you can compare, contrast, combine, and validate, to get a better understanding of what’s going on. U.S. military strategist Roy Adams told me this story about an “aha” moment he had in Iraq. He was having a beer with a friend who was in the Special Forces. Usually, they didn’t talk about work, but he happened to have a map with him. At the time, Adams and his team were designing their plans based on the political boundaries of the map, so on the map were districts, as well as the people who were in charge of the districts. His friend said,   And he picked up a pen and said,   The boundaries were completely different but overlapping. Suddenly, Adams had two different versions of reality on his map. The political map was primarily a Shia map, and the tribal map had both Sunni and Shia. Only by overlaying the two maps did Adams start to understand the situation. Neither map would have made sense by itself. By laying these maps over each other, suddenly things started to click. Now he understood why they were having success in some places and meeting resistance in others. Everything started to make more sense. The insights in this case came not from one map or another, but through overlaying them. This is the practice of triangulation. Each map represented one theory of the world, one version of reality. It was only by viewing the situation through multiple perspectives—multiple theories—that he was able to gain insight and see the situation differently. ( ) My friend Adrian Howard told me about a similar experience he had when working at a large Telecom company that had grown by acquiring other companies over many years. His team found itself running up against resistance and pushback that seemed odd and inexplicable. Then someone on the team took some markers and color-coded the boxes on the org chart based on which companies the people in each box had originally come from—many of whom used to be fierce competitors—and suddenly the reasons for the resistance became clear and understandable. For any one observation there may be a vast number of possible explanations. Many of them may be based on beliefs that are outside of your current belief bubble, in which case, they may seem strange, absurd, crazy, or just plain wrong. Most of the time we are all walking around with our heads so full of “obvious” that we can’t see what’s really going on. If you think something is obvious, that’s an idea that bears closer examination. Why do you think it’s obvious? What personal experiences have you had that led to that belief? Can you imagine a different set of experiences that might lead to a different belief? Cultivate as many theories as you can—including some that seem odd, counter-intuitive, or even mutually contradictory—and hold onto them loosely. Don’t get too attached to any one of them. ( ) Then you can start asking questions and seeking valid information to help you understand what’s really going on. The way to seek understanding is to empty your cup, step up and give people your full attention, suspend your beliefs and judgments, and listen carefully. The thing to remember is that people act in ways that make sense to them. If something doesn’t make sense to you, then you’re missing something. What are you missing? If someone says something that seems odd or unbelievable, ask yourself, “What would I need to believe for that to be true?” In many cases, the only way you’re ever going to understand what’s inside someone else’s head is by talking to them. Sometimes that idea might seem scary. It may be that you will hear something that threatens your bubble of belief. But if you can get over your fear, go and talk to the dragon, or take the ogre out for coffee. You just may learn something that will change your life. \n  Practice exercises Triangulate and validate. Look at situations from as many points of view as possible. Consider the possibility that seemingly different or contradictory beliefs may be valid. If something doesn’t make sense to you, then you’re missing something. Exercise #1 Think about a co-worker or family member, someone you care about, or can’t walk away from for whatever reason, that you have trouble getting along with. Consider their beliefs and behavior, and come up with as many theories as you can to explain why they act the way they do. Then see if you can have a conversation with that person to explore what’s really going on. Exercise #2 Think of a situation at home or work that you find problematic. Try to come up with as many perspectives as you can that might give you a different way to look at the situation. What is your current theory? What is its opposite? How many perspectives or points of view can you think of that might help you see that situation through different eyes? Want to read more? Get 20% off your copy of   and other titles from Two Waves Books—an imprint of Rosenfeld Media—with code  . Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/javascript-for-web-designers/", "title": "JavaScript for Web Designers: DOM Scripting", "content": "Before we do anything with a page, you and I need to have a talk about something very important: the Document Object Model. There are two purposes to the DOM: providing JavaScript with a map of all the elements on our page, and providing us with a set of methods for accessing those elements, their attributes, and their contents. Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The “object” part of Document Object Model should make a lot more sense now than it did the first time the DOM came up, though: the DOM is a representation of a web page in the form of an object, made up of properties that represent each of the document’s child elements and subproperties representing each of those elements’ child elements, and so on. It’s objects all the way down. : The Global Context Everything we do with JavaScript falls within the scope of a single object:  . The   object represents, predictably enough, the entire browser window. It contains the entire DOM, as well as—and this is the tricky part—the whole of JavaScript. When we first talked about variable scope, we touched on the concept of there being “global” and “local” scopes, meaning that a variable could be made available either to every part of our scripts or to their enclosing function alone. The   object   that global scope. All of the functions and methods built into JavaScript are built off of the   object. We don’t have to reference   constantly, of course, or you would’ve seen a lot of it before now—since   is the global scope, JavaScript checks   for any variables we haven’t defined ourselves. In fact, the   object that you’ve hopefully come to know and love is a method of the   object: It’s hard to visualize globally vs. locally scoped variables before knowing about  , but much easier after: when we introduce a variable to the global scope, we’re making it a property of  —and since we don’t explicitly have to reference   whenever we’re accessing one of its properties or methods, we can call that variable anywhere in our scripts by just using its identifier. When we access an identifier, what we’re really doing is this: The DOM’s entire representation of the page is a property of  : specifically,  . Just entering   in your developer console will return all of the markup on the current page in one enormous string, which isn’t particularly useful—but everything on the page can be accessed as subproperties of   the exact same way. Remember that we don’t need to specify   in order to access its   property—  is the only game in town, after all. Those two properties are themselves objects that contain properties that are objects, and so on down the chain. (“Everything is an object, kinda.”) Using the DOM The objects in   make up JavaScript’s map of the document, but it isn’t terribly useful for us—at least, not when we’re trying to access DOM nodes the way we’d access any other object. Winding our way through the   object manually would be a huge headache for us, and that means our scripts would completely fall apart as soon as any markup changed. But   isn’t just a representation of the page; it also provides us with a smarter API for accessing that information. For instance, if we want to find every   element on a page, we don’t have to write out a string of property keys—we use a helper method built into   that gathers them all into an array-like list for us. Open up any site you want—so long as it likely has a paragraph element or two in it—and try this out in your console: Since we’re dealing with such familiar data types, we already have some idea how to work with them: But DOM methods don’t give us arrays, strictly speaking. Methods like   return “node lists,” which behave a lot like arrays. Each item in a   refers to an individual node in the DOM—like a   or a  —and will come with a number of DOM-specific methods built in. For example, the   method will return any markup a node contains—elements, text, and so on—as a string: The same way these methods give us access to information on the rendered page, they allow us to alter that information, as well. For example, the   method does this the same way we’d change the value of any other object: a single equals sign, followed by the new value. JavaScript’s map of the DOM works both ways:   is updated whenever any markup changes, and our markup is updated whenever anything within   changes (Fig 5.1). Likewise, the DOM API gives us a number of methods for creating, adding, and removing elements. They’re all more or less spelled out in plain English, so even though things can seem a little verbose, it isn’t too hard to break down. DOM Scripting Before we get started, let’s abandon our developer console for a bit. Ages ago now, we walked through setting up a bare-bones HTML template that pulls in a remote script, and we’re going to revisit that setup now. Between the knowledge you’ve gained about JavaScript so far and an introduction to the DOM, we’re done with just telling our console to parrot things back to us—it’s time to build something. We’re going to add a “cut” to an index page full of text—a teaser paragraph followed by a link to reveal the full text. We’re not going to make the user navigate to another page, though. Instead, we’ll use JavaScript to show the full text on the same page. Let’s start by setting up an HTML document that links out to an external stylesheet and external script file—nothing fancy. Both our stylesheet and script files are empty with .css and .js extensions, for now—I like to keep my CSS in a /css subdirectory and my JavaScript in a /js subdirectory, but do whatever makes you most comfortable. We’re going to populate that page with several paragraphs of text. Any ol’ text you can find laying around will do, including—with apologies to the content strategists in the audience—a little old-fashioned lorem ipsum. We’re just mocking up a quick article page, like a blog post. Feel free to open up the stylesheet and play with the typography, but don’t get too distracted. We’ll need to write a little CSS later, but for now: we’ve got scripting to do. We can break this script down into a few discrete tasks: we need to add a Read More link to the first paragraph, we need to hide all the   elements apart from the first one, and we need to reveal those hidden elements when the user interacts with the Read More link. We’ll start by adding that Read More link to the end of the first paragraph. Open up your still-empty script.js file and enter the following: First, we’re intializing the variable  , which uses   to—just like it says on the tin—create a new   element. This element doesn’t really exist anywhere yet—to get it to appear on the page we’ll need to add it manually. First, though,   without any attributes or contents isn’t very useful. Before adding it to the page, let’s populate it with whatever information it needs. We could do this   adding the link to the DOM, of course, but there’s no sense in making multiple updates to the element on the page instead of one update that adds the final result—doing all the work on that element before dropping it into the page helps keep our code predictable. Making a single trip to the DOM whenever possible is also better for performance—but performance micro-optimization is easy to obsess over. As you’ve seen, JavaScript frequently offers us multiple ways to do the same thing, and one of those methods may   outperform the other. This invariably leads to “excessively clever” code—convoluted loops that require in-person explanations to make any sense at all, just for the sake of shaving off precious picoseconds of load time. I’ve done it; I still catch myself doing it; but you should try not to. So while making as few round-trips to the DOM as possible is a good habit to be in for the sake of performance, the main reason is that it keeps our code readable and predictable. By only making trips to the DOM when we really need to, we avoid repeating ourselves and we make our interaction points with the DOM more obvious for future maintainers of our scripts. So. Back to our empty, attribute-less   floating in the JavaScript ether, totally independent of our document. Now we can use two other DOM interfaces to make that link more useful:   to give it attributes, and   to populate it with text. These have a slightly different syntax. We can just assign a string using  , the way we’d assign a value to any other object.  , on the other hand, expects two arguments: the attribute   the value we want for that attribute, in that order. Since we don’t actually plan to have this link go anywhere, we’ll just set a hash as the  —a link to the page you’re already on. You’ll notice we’re using these interfaces on our stored reference to the element instead of on   itself.   the DOM’s nodes have access to methods like the ones we’re using here—we only use   because we want to get all the paragraph elements in the document. If we only wanted to get all the paragraph elements inside a certain  , we could do the same thing with a reference to that  —something like  . And since we’ll want to set the   attribute and the inner HTML of the link we’ve created, we reference these properties using   and  . Next: we want this link to come at the end of our first paragraph, so our script will need a way to reference that first paragraph. We already know that   gives us a node list of all the paragraphs in the page. Since node lists behave like arrays, we can reference the first item in the node list one by using the index  . For the sake of keeping our code readable, it’s a good idea to initialize our variables up at the top of a script—even if only by initializing them as   (by giving them an identifier but no value)—if we plan to assign them a value later on. This way we know all the identifiers in play. So now we have everything we need in order to append a link to the end of the first paragraph: the element that we want to append ( ) and the element we want to append it to ( ).  One of the built-in methods on all DOM nodes is  , which—as the name implies—allows us to append a child element to that DOM node. We’ll call that   method on our saved reference to the first paragraph in the document, passing it   as an argument. Now—finally—we have something we can point at when we reload the page. If everything has gone according to plan, you’ll now have a Read More link at the end of the first paragraph on the page. If everything hasn’t gone according to plan—because of a misplaced semicolon or mismatched parentheses, for example—your developer console will give you a heads-up that something has gone wrong, so be sure to keep it open. Pretty close, but a little janky-looking—our link is crashing into the paragraph above it, since that link is   by default (Fig 5.2). We have a couple of options for dealing with this: I won’t get into all the various syntaxes here, but the DOM also gives us access to   information about elements—though, in its most basic form, it will only allow us to read and change styling information associated with a   attribute. Just to get a feel for how that works, let’s change the link to   and add a few pixels of margin to the left side, so it isn’t colliding with our text. Just like setting attributes, we’ll do this before we add the link to the page: Well, adding those lines  , but not without a couple of catches. First, let’s talk about that syntax (Fig 5.3). Remember that identifiers can’t contain hyphens, and since everything is an object (sort of), the DOM references styles in object format as well. Any CSS property that contains a hyphen instead gets camel-cased:   becomes  ,   becomes  , and so on. Since the   we set for those properties is a string, however, hyphens are just fine. A little awkward and one more thing to remember, but this is manageable enough—certainly no reason to avoid styling in JavaScript, if the situation makes it absolutely necessary. A better reason to avoid styling in JavaScript is to maintain a separation of behavior and presentation. JavaScript is our “behavioral” layer the way CSS is our “presentational” layer, and seldom the twain should meet. Changing styles on a page shouldn’t mean rooting through line after line of functions and variables, the same way we wouldn’t want to bury styles in our markup. The people who might end up maintaining the styles for the site may not be completely comfortable editing JavaScript—and since changing styles in JavaScript means we’re indirectly adding styles via   attributes, whatever we write in a script is going to override the contents of a stylesheet by default. We can maintain that separation of concerns by instead using   again to give our link a class. So, let’s scratch out those two styling lines and add one setting a class in their place. Now we can style   in our stylesheets as usual: Much better (Fig 5.4). It’s worth keeping in mind for the future that using   this way on a node in the DOM would mean overwriting any classes already on the element, but that’s not a concern where we’re putting this element together from scratch.  Now we’re ready to move on to the second item on our to-do list: hiding all the other paragraphs. Since we’ve made changes to code we know already worked, be sure to reload the page to make sure everything is still working as expected. We don’t want to introduce a bug here and continue on writing code, or we’ll eventually get stuck digging back through all the changes we made. If everything has gone according to plan, the page should look the same when we reload it now. Now we have a list of all the paragraphs on the page, and we need to act on each of them. We need a loop—and since we’re iterating over an array-like node list, we need a   loop. Just to make sure we have our loop in order, we’ll log each paragraph to the console before we go any further: Your Read More link should still be kicking around in the first paragraph as usual, and your console should be rich with filler text (Fig 5.5). Now we have to hide those paragraphs with  , and we have a couple of options: we could use a class the way we did before, but it wouldn’t be a terrible idea to use styles in JavaScript for this. We’re controlling all the hiding and showing from our script, and there’s no chance we’ll want that behavior to be overridden by something in a stylesheet. In this case, it makes sense to use the DOM’s built-in methods for applying styles: If we reload the page now, everything is gone: our JavaScript loops through the entire list of paragraphs and hides them all. We need to make an exception for the first paragraph, and that means conditional logic—an   statement, and the   variable gives us an easy value to check against: If this is the first time through of the loop, the   keyword skips the rest of the current iteration and then—unlike if we’d used  —the loop continues on to the next iteration. If you reload the page now, we’ll have a single paragraph with a Read More link at the end, but all the others will be hidden. Things are looking good so far—and if things aren’t looking quite so good for you, double-check your console to make sure nothing is amiss.  Now that you’ve got a solid grounding in the DOM, let’s   dig in and see where to take it from here.  Want to read more? The rest of this chapter (even more than you just read!) goes even deeper—and that’s only one chapter out of Mat’s hands-on, help-you-with-your-current-project guide. Check out the rest of   at  .  Like this: \n\t\t\t\t\t\t\tRecently by Mat Marquis\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/dao-of-product-design/", "title": "A Dao of Product Design", "content": "When a designer or developer sets out to create a new product, the audience is thought of as “the user”: we consider how she might use it, what aspects make it accessible and usable, what   make it delightful, and how we can optimize the workflow for her   benefit. What is rarely considered in the process is the social and   impact of our product being used by hundreds of thousands—even millions—of people every day.  Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What a product does to people psychologically, or how it has the power to transform our society, is hard to measure but increasingly important. Good products improve how people accomplish tasks; great products improve how society operates. If we don’t practice a more sustainable form of product design, we risk harmful side effects to people and society that could have been avoided. The impact of product design decisions In 1956, President Eisenhower signed the U.S. Interstate Highway Act into law. Inspired by Germany’s  , Eisenhower was determined to develop the cross-country highways that lawmakers had been discussing for years. During the design of this interstate network, these “open roads of freedom” were often routed directly through cities, intentionally creating an infrastructural segregation that favored affluent neighborhoods at the expense of poor or minority neighborhoods. Roads became boundaries, subtly isolating residents by socioeconomic status; such increasingly visible distinctions encouraged racist views and ultimately  . The segmentation systematically diminished opportunities for those residents, heavily impacting people of color and adversely shaping the racial dynamics of American society. Such widespread negative consequences are not limited to past efforts or malicious intentions. For example, the laudable environmental effort to replace tungsten street lamps with sustainable LEDs is creating   because the human impact when applied at scale was not thought through sufficiently. In each example, we see evidence of designers who didn’t seriously consider the long-term social and moral impacts their work might have on the very people they were designing for. As a result, people all around suffered significant negative side effects. The ur-discipline Although the process is rarely identified as such, product design is the oldest practiced discipline in human history. It is also one of the most under-examined; only in relatively recent times have we come to explore the ways products exist in the context they impact. Designers often seek to control the experience users have with their product, aiming to polish each interaction and every detail, crafting it to give a positive—even emotional—experience to the individual. But we must be cautious of imbalance; a laser focus on the micro can draw attention and care away from the macro. Retaining a big-picture view of the product can provide meaning, not only for the user’s tasks, but for her as a person, and for her environment. Dieter Rams’s ninth principle says that good design is environmentally friendly; it is sustainable. This is generally interpreted to mean the   resources and costs involved in production, but products also affect the  : the social, economic, and cognitive world the user inhabits while considering and using the product. At a high level, there is an easy way to think about this: your product and your users do not exist in a vacuum. Your algorithms are not   or  . Your careful touch is not pristine. Your life experiences instill certain values and biases into your way of thinking. These, in turn, color your design process and leave an imprint behind in the product. It’s essentially the DNA of your decisions, something embedded deeply in the fabric of your work, and visible only under extremely close inspection. Unlike our DNA, we can consciously control the decisions that shape our products and strive to ensure they have a positive impact, even the myriad subtle and non-obvious ways we might not anticipate. Let’s learn to solve the problems we can’t yet see when designing our products. Design for inclusion When we set out to design a product, we generally have a target audience in mind. But there are distinctions between functional target audiences and holistic ones. To create products that embrace long-term positive impacts, we must embrace inclusive thinking as comprehensively as we can. Conduct research into racial and gender politics to broaden your awareness of the social structures that impact your customers’ lives. These structures alter people’s priorities and affect their decision-making process, so design for as many social and societal considerations as possible. Sometimes people who fall outside the “target audience” are overlooked simply because their priorities for your product come in second place in their lives. Design your product to bridge such gaps, rather than ignoring them. Listen to the voices of people expressing concern and learn to see the pain points they experience, even if they don’t articulate them as such. Step up to your responsibilities as a designer, curator, entrepreneur, or platform owner. You may not be an elected official, but when you offer products you still have responsibility over the roles they play in people’s lives and experiences—so govern accordingly. Read studies that examine human psychology to understand how people’s biases may be exacerbated by your product. Learn about   so you can  . Extrapolate how people with nefarious goals—from hackers to authoritarian governments—could exploit or abuse your features or the data you collect. Work with data and let it inform you, but remember that data is  , not authoritative; the data we gather is always a myopic subset of the entirety that exists but cannot possibly be measured. Enrich your process and viewpoint with information, but let your heart drive your design process. These principles are more than “nice-to-haves”—they help you design with an ethical and moral code as inherent throughout the product as the design system used to build it. Foster positivity and civility When we use a product frequently, the DNA of its design process can leave a psychological imprint on us. Facebook knows it can affect people’s moods by putting more positive items in their feeds. When news broke that it did so, people were upset about this manipulation. In actuality, our lives are constantly being manipulated by algorithms  ; we’re just not very conscious of it. Often, even the people who   the algorithms  . Features like upvotes and downvotes may seem like a balanced solution for people to express opinions, but the downvote’s only purpose is to feed and perpetuate negativity; it can be avoided or removed entirely without harmful consequences.  Don’t give angry people shortcuts to wield negative power; make them either articulate their anger or deal with it in more constructive ways. Social media platforms never benefit from angry, biased groups suppressing messages (often positive and constructive) from people they despise. In those scenarios,   loses—so why design the option into your product? Any feature that petty, time-rich people can abuse to game your product’s ranking or discovery algorithms is a feature that eventually serves up toxic behaviors (regardless of the person’s politics) and is best left out. Also avoid features that simply waste time, because when people waste time they feel less happy than when they do something productive or constructive. And of course, don’t deliberately design time-wasters into your product and offer users a premium fee to avoid them; that’s just not civil. To foster positive behavior and encourage civility, you can reward good behavior and hold bad behavior accountable. Holding bad behavior accountable is crucial to establishing a credible community or platform—but no rewards for good behavior risks creating a fear-driven atmosphere.  A great example of designing consciously like this is Nextdoor, a platform for local communities. Nextdoor made a purposeful effort to   by redesigning a small part of their product. For example, when reporting “suspicious activity,” new follow-up questions like “What are they doing that’s suspicious?” are required fields, so that users can no longer simply accuse people of color of “being suspicious.” The resulting 75 percent reduction in racial profiling is great for obvious reasons, but it also has the effect that users are actively being trained to no longer associate the two as interchangeable. Design to avoid vectors of abuse; strive to encourage positive interactions and, wherever possible, challenge and transform existing biases. Boost confidence and courage People likely use your product to accomplish something, whether it’s a leisure task  or a professional one. A user who repeats certain tasks with your product is effectively practicing her interactions; find the opportunities therein to help her grow as a person, not just succeed as a worker. For example, when my cofounder and I set out to create  , our goal wasn’t merely to create a web-based version of Keynote or PowerPoint—we set out to help people lose their fear of public speaking, to prevent audiences from experiencing “Death by PowerPoint,” and to create the fastest, most effective presentation software and sharing platform available on any device. Our business effort was cut short, but our product design goals were achieved even with our alpha software: our users—the presenters—felt more confident and relaxed, found it easier to focus their energies on their talks, and spent far less time creating the presentations (leaving more time to rehearse). Plus, their audiences didn’t suffer through the dreaded stack of bullet points and a monotonous presentation. Instead of seeing our product as a combination of features and UI, we considered it a tool that could empower people far beyond the scope of their tasks. Your product can do the same if you think about how it could strengthen related skills (in our case, public speaking) the more someone “practices” by using it. Think about features and insights that encourage people in positive ways; teach them knowledge you have that they might not, perhaps as imposingly as by embedding its principles as features themselves. Your user is likely a busy person with a million things on her plate—and on her mind. She won’t sit down and think introspectively about how your product affects her life, but you as the designer or developer can and should do precisely that. You can spend the extra time upfront thinking about how to inform or teach your users new insights or techniques that help build the confidence they are looking for. Empowerment isn’t just the facilitation of a new ability—it’s the emotional and mental strengthening of confidence in your customer when she meets a challenge and accomplishes something impressive. Strengthen emotional fortitude Emotional fortitude is the foundation that helps you to be courageous and honest, and to better withstand setbacks. A person who feels emotionally secure has an easier time finding the courage to admit failure or mistakes, which creates opportunities for them to learn and grow. Conversely, emotional fragility erodes a person’s confidence and obstructs personal growth. People’s emotional states are influenced heavily by external factors. Our environment plays a role in shaping how we see the world, its opportunities, and its problems. But while there’s been extensive research into the role of legislation on our lives, there’s comparatively little research examining the role that   play in our environment. This is becoming pressing as software and technology communicate with us, to us, and about us as frequently as other people do; they now have as much of an effect on our lives as laws and regulations. Behavioral science and   strongly suggest that behaviors can be positively influenced by conscious efforts. For instance, rather than mandating certain actions, you could encourage better decisions or actions by making them more prominent or appealing. This kind of influence can and often does extend beyond behaviors and into our states of mind. To be clear, this is not a deterministic argument—technology and products don’t inherently make us sad or happy, confident or anxious. Rather, this is an argument that products   to influence us in emotional ways, and that the greater a product’s user base and its daily use of the product, the more impactful its effects can be on how they see and experience the world. The strongest case for this is made by a   that show that  . But what if those platforms had the opposite effect, instead making people happier and more confident about their lives? One way is to take a teaching approach with your users. When enforcing Terms of Service, for instance, just saying “your actions are unacceptable and violate our ToS” doesn’t explain what was not okay or why you don’t want that kind of behavior. It also doesn’t suggest which behaviors you   looking to see from users. The former approach causes people to feel emotionally insecure, so focus on the latter—on positive kinds of interactions you wish to foster on your platform. They can be actual conversations, or simply part of your marketing and messaging.  Products can also affect our psychological and emotional well-being through the types of behaviors they facilitate and foster. For example, features that can be exploited by petty individuals may result in a great amount of petty behavior on your platform or within your community; we know this behavior creates emotional fragility, not fortitude. On the other hand, features that surprise and delight users (a tenet of great emotional design) can have a fortifying effect on a person’s emotional state.  When designing Presentate, our goal wasn’t “to make slideware”; our goal was to make presenters more confident in their presentation and have greater confidence as speakers. Our   of achieving that goal was to design a slideware product that would accomplish both. Another fine example is Tesla, a company that makes electric vehicles and associated technology. As its CEO and founder Elon Musk repeats at many of their product announcements, Tesla’s goal—its  —is to transform us into a renewable-energy human society. In setting its goal accordingly (and explicitly!), Tesla operates on the premise that it needs to do more than simply make a product; it needs to change people’s views and how they   about their existing products. At the  , Musk reiterated that “the key is to make it desirable,” to make something people want regardless of its role in the energy revolution. Similarly, Tesla’s Model S car outperforms many a muscle car in drag races,  . This approach helps to change people’s wider perceptions, extending beyond the products themselves. When we set our goals not just to create great products, but products that help transform how we think, we can tackle underlying biases and prejudices that people may have but would be happy to be eased out of. We strengthen their confidence and character, and address problems that go well beyond the scope of any one product. And while none of us are solely responsible for fixing major problems in society, each of us, when designing a product, has an opportunity to make it part of the solution.  Or as Nextdoor CEO Nirav Tolia said, when asked about why they changed their design: We don’t think Nextdoor can stamp out racism, but we feel a moral and business obligation to be part of the solution. Recreate social mores There is no digital duality, no “real world” separated from our environment online. Generally, every avatar you talk with on a screen has one or more real people behind it—people with real feelings you can hurt as easily online as you could to their face. You just don’t   it, which shows that we do miss out on a number of social cues when interacting on screen: things like tone, sarcasm, playfulness, hurt feelings—or disapproving frowns from our peers. A street harasser exploits the lack of a social circle that pressures them to behave decently. Oftentimes this is out of ignorance, not malice, including when the harasser is in the company of others who often are equally unaware that such behavior is unwelcome and uncivil. Many, of course, are in denial and shout catcalls at women despite knowing better—and wouldn’t dare  , for example. In the digital environment, those external social pressures to behave are often lost, so unless they come to you from the strength you have within, it’s all too easy to slip into behavior you wouldn’t engage in while speaking with someone face to face. Let’s be honest: we’ve all said things to people online at some point or another that we would be ashamed to repeat in person. From a product perspective, that means we have to rely on mechanisms that either invoke those social mores to encourage civil and fruitful interactions, or outright enforce them. We have to design a simulated social circle of peer pressuring friends into the products we make. Nextdoor did it with form fields that asked follow-up questions. What can your product do? See the best in people (but be realistic) People prefer being good and happy over being mean-spirited or awful. You can design your products to encourage the best sides of people, to let them shine in their brilliance, to help them learn and grow while doing their work. But don’t mistake seeing the best in people as a reason not to anticipate harmful behaviors or exploitation of your features.  As product designers we deliberately craft solutions to envisioned problems. We should practice expanding our view to encompass and understand more people and the problems they are experiencing. We should strive to make our work a part of the solution, in ways that scale up to millions of users without harmful side effects. You’ve read this far. That means you’re eager and ready to think bigger, more holistically, and more empathetically about the work that you do. Armed with these principles, you’re ready to take your product design to the next level. We can’t wait to see what you’ll create! Like this: \n\t\t\t\t\t\t\tRecently by Faruk Ateş\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/network-access-finding-and-working-with-creative-communities/", "title": "Network Access: Finding and Working with Creative Communities", "content": "A curious complaint seems to ripple across the internet every so often: people state that “design” is stale. The criticism is that   are being generated; anything new is quickly co-opted and copied en-masse, leading to even more sterility, conceptually. And that leads to lots of   lamenting the  . Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. What people see is an   within their group, with very little bleed-over into other disciplines or networks. Too often, we speak about our design communities and networks as resources to be used, not as groups of people. Anthony McCann describes the two main ways we view creative networks and the digital commons: We have these two ways of speaking: commons as a pool of resources to be managed, and commons as an alternative to treating the world as made up of resources. One view is that communities are essentially pools of user-generated content. That freely available content is there to be mined—the best ideas extracted and repackaged for profit or future projects. This is idea as commodity, and it very conveniently strips out the people doing the creating, instead looking at their conceptual and design work as a resource. Another way is to view creative networks as interdependent networks of people. By nature, they cannot be resources, and any work put into the community is to sustain and nourish those human connections, not create assets. The focus is on contributing. A wider view By looking at your design communities as resources to be mined, you limit yourself to preset, habitual methods of sharing and usage. The more that network content is packaged for sale and distribution, the less “fresh” it will be. In Dougland Hine’s essay  , he says when we talk enthusiastically about the digital commons these days, we too often use the language of resource management, not the language of social relations. Perhaps we should take a wider, more global view. There are numerous digital design communities across the world; they are fluid and fresh, and operate according to distinct and complex social rules and mores. These designers are actively   in original ways, and the result is unique, culturally relevant work. By joining and interacting with them—by accessing these networks—we can rethink what the design community is today. Exploring larger communities There are a number of creative communities I’ve become a part of, to varying degrees of attention. I’ve been a member of Behance for almost 10 years ( ), back when   (“We are pleased to invite you to join the Behance Network, in partnership with MTV”). While I lived in Japan, Behance was a way for me to learn new digital design techniques and participate in a Western-focused, largely English speaking design network. As time has gone on, it’s strange that I now use it almost exclusively to see what is happening outside the West. Instagram, Twitter, and Ello are three mobile platforms with a number of features that are great for collecting visual ideas without the necessity of always participating. The algorithms are focused on showing more of what I have seen—the more often I view work from Asian and African designers and illustrators, the more often I discover new work from those communities. While interesting for me, it does create  , and I need to be careful of falling into the trap of seeing more of the same. There is, of course, a counter-reaction to the public, extractive nature of these platforms—the rise of “Slack as community.” The joke about belonging to   is getting old, but illustrates a trend in the industry during the past year or so. I see this especially with designers of color, where the firehoses of racist/sexist abuse on open digital networks means that creativity is shelved in favor of simple preservation. Instead, we move, quietly and deliberately, to Slack, a platform that is explicit in its  , where the access is much more tightly controlled, and where the empathy in design/dev networks is more readily shared and nurtured. Right now, these are the creative platforms where I contribute my visual thinking, work, and conversations toward addressing messy visual questions—interactive ideas that assume a radically different way of viewing the world. There are, of course, others. Exploring visual design alternatives In Volume II of   (a series of books that showcase Arab illustrators, photographers, and graphic designers), we see one of these design communities compiled and printed, an offline record of a thriving visual network ( ). And perhaps it is in the banding together that real creative change can happen. I was fascinated to read this article about an  . At 7 years old, it’s reportedly the longest running drawing event in Singapore. Michael Ng says,   Comments like this show that there are thriving visual design scenes worldwide, ones that collaborate internally, and work for exposure and monetary gain externally. UX research that builds community Earlier in this article, we started by looking at the different ways people view existing creative communities. But what about people who create new ones? Here, once again, we have designers and strategists who use   to create and develop sustainable digital networks, not simply resource libraries. First, let’s look at the pilot of  , an open source medical tool developed at Reboot. The residents of Wamba, a rural area in Nasarawa State, Nigeria, struggled to find a way to communicate with their healthcare providers. Reboot saw an opportunity to develop an empowering, responsive platform for the community, a way for people to share feedback with clinics and doctors in the area. After a nine-week trial of the platform and software, the residents of Wamba saw the clinics begin making small changes to how they communicated—things like better payment info and hours of operation. The health department officials in the area also saw a chance to better monitor their clinics and appear more responsive to their constituents. What began as a way to report on clinic status and quality became a way for the community and local government to improve together. In another project, a group of researchers worked with a community in South Africa’s Eastern Cape to  . Their experience creating a storytelling platform that did not follow European narrative tradition is enlightening, and hits on a key framing in line with how the people in Ndungunyeni view creative networks ( ). Contrary to their initial ideas, the UX researchers found that storytelling  In both of  these examples, we see new creative networks relying on linked social systems and cues in order to thrive. Most importantly, they rely on reciprocation—the trade of ideas, whether there is immediate personal benefit or not. Each of the participants—the community members, the UX designers, the clinics, and the local government— was able to collaborate on a common goal. Simply-crafted technology and UX made this possible, even in rural areas with little cellular connectivity. They all contributed, not looking to extract value, but to   it; they used these networking tools to deepen their interactions with others. Building alternatives to current networks Almost every project we work on as designers would certainly benefit from alternative viewpoints. That can be hard to set up, however, and collaborating with designers and developers outside your immediate circle  . Keep in mind that the goal is to add value to others’ networks and build interpersonal connections. This is the only way that we keep the creative ideas fresh. Starting with freelance and project work Sometimes the simplest way to access different creative circles is simply to pay for project work.  A great example is Karabo Moletsane’s  . An accomplished illustrator from South Africa, Moletsane recently did a set of 32 wonderful portraits for the Quartz Africa Innovators 2016 Series ( ). When I asked Moletsane about how she got the illustration job, she said it came via her work on  . Moletsane also said she regularly posts work on her Instagram and Behance, making Quartz’s choice to work with this talented South African for a global series on African innovators a no-brainer. Hiring and team-building from different networks Sometimes, shorter freelance projects won’t give you long-term quality access to new design communities and ideas. Sometimes you need to bring people onto your team, full-time. Again, I point out what   regarding the ways digital communities can work: …people have had powerful experiences of what it means to come together, work and build communities [but] the new forms of collaboration easily turn into new forms of exploitation… Instead of looking for short-term access, hiring and developing team members from other networks can be a powerful alternative. Tyler Kessler, the CEO of Lumogram in St. Louis, recently wrote about   based in Nigeria, and what it has meant to his company. He used Andela, a startup that is training and hiring out a new generation of developers from Nigeria. Collaboration around specific Ideas Your contributions to networks also need not be permanent or rigid. There are numerous opportunities to join collectives, or working groups, that build more ephemeral networks around specific issues. One  , by the   (pdf), was set up   The breadth of ideas is astounding, from systems for healthier eating, to mini-parks within urban areas for seniors to hang out in. Each team involved contributed deep user research, information design, and cultural cues to propose new ways for our elderly to coexist ( ). The form and utility of design communities in the 21st century is fluid, and goes from groups of like-minded designers and illustrators to communities working digitally to solve specific problems. Even short-term collectives are addressing social issues. All are intricate groups of creative humans. They shouldn’t be viewed, in any way, as “resources” for extraction and inspiration. Too often in the Western design world, we hear that ideas have largely plateaued and become homogenous, but that ignores the amazing work flourishing in other nations and pockets of the internet. How you build connections among other creative people makes you part of the network. See them, however ephemeral and globally distributed, as a powerful way to expand your design horizons and be part of something different. Like this: \n\t\t\t\t\t\t\tRecently by Senongo Akpem\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/strategies-for-healthier-dev/", "title": "Strategies for Healthier Dev", "content": "Not too long ago, I was   at the launch event for  , an initiative that encourages women to learn to code. Along the way, I mentioned a bit about my background as an athlete. As we were leaving to go home, the woman next to me jokingly asked if I was a better basketball player or a better developer. Without missing a beat, I said I was a better basketball player. After all, I’ve been playing basketball for over half my life; I’ve only been coding for two and a half years. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. We’ve probably all come across the stereotype of the nerdy programmer who is all brains and no brawn. I’m a counterexample of that cliché, and I personally know developers who are avid cyclists or marathon runners—even a mountain climber (the kind who scales Mount Everest). And yet a stereotype,   often comes into existence for a reason. Think of Douglas Coupland’s  . Think of any number of mainstream dramas featuring wan (usually white, usually male)  . Many so-called knowledge workers are too sedentary. Our lives and work stand to benefit if we become less so. Now, no one likes to suffer. And yet when it comes to exercise or training, it’s too easy for us to think that fitness is all about self-discipline—that we just need to have the willpower to persevere through the agony. But that’s not a good strategy for most people. Unless you genuinely find pleasure in pain and suffering, you have to want something badly enough to   pain and suffering. Ask any athlete if they enjoy running extra sprints or lifting extra weights. Even Olympic medalists will tell you they don’t. They do it because they want to be the best. My point is this: forcing yourself to do something you don’t enjoy is not sustainable. I’ll be the first to admit that I’m not a big fan of running. A little ironic coming from someone who used to play basketball full-time, maybe, but the only reason I did any running at all, ever, was because competitive basketball required me to. When I stopped training full-time, I simply couldn’t muster the energy or motivation to get up and run every day (or even every week, for that matter). So I had to come up with a different game plan—one that required  ,  , and  . You can do it, too. No excuses. Ready? Minimal effort I’m lazy. I’m pretty good at talking myself out of doing things that require extra effort to get ready for. For example, going swimming requires that I pack toiletries, a fresh set of clothes, and goggles. Then I actually need to make it to the pool after work before it closes, which means I have to plan to leave the office earlier than I usually might, and so on. Guess what? Eight out of ten times, I end up telling myself to go swimming next time. By contrast, I commute to work on my bicycle. Yes, it helps that I love to ride. I thoroughly enjoy swimming, too—just not enough to overcome my laziness. But because cycling is my main mode of transportation, I don’t even think about it as exercise. It’s just something I do as part of my day, like brushing my teeth. The “while-you’re-at-it” technique works very well for me, and maybe it’ll work for you, too. In a nutshell: build healthy habits into things you already do. Kind of how parents hide vegetables in more palatable stuff to get their kids to eat them. Near-zero effort Let me list some simple activities that involve minimal effort, but have significant returns on investment. Consider these the   (MVPs) of healthy habits. Drink more water Most of us have been told to drink eight glasses of water a day, but how many of us actually drink that much? The real amount of water people need on a daily basis  , but I’m going to make the bold assumption that most of us don’t drink more than one liter (or around four glasses) of water a day. And no, coffee doesn’t count. This means that most of us operate in a mildly dehydrated state throughout the day. Studies done on both   and   have shown that mild dehydration negatively impacts one’s mood and cognitive function. Given that our work requires significant mental acuity, upping our water intake is a minimal-effort lifehack with significant benefits. Note that people often mistake thirst for hunger.   have shown that we’re notoriously bad at distinguishing the two. Assuming that most of us probably don’t drink enough water throughout the day, odds are that you’re not really hungry when you reach for a snack. In fact, you’re probably thirsty. Don’t grab a can of soda, though— . Move more A   done on the effects of sedentary behavior revealed that long periods of inactivity increase one’s risk of diabetes and heart disease. The study also mentioned that encouraging individuals simply to sit less and move more, regardless of intensity level, may improve the effectiveness of diabetes-prevention programs. Think about how you can incorporate more movement into your routine. Try drinking water throughout the day. Not only will this reinforce the “drink more water” habit, but you’ll also find that you need to get up to go to the bathroom more often. And going to the bathroom is…movement. Note: do not refuse to go to the bathroom because you think you’re “on the brink” of solving a bug. That’s a lie you tell yourself. Since you’re getting up and sitting down more often, you might as well sneak some exercise in while you’re at it. Instead of plonking down in your seat when you get back, lower yourself slowly over the course of five seconds until your butt touches your chair. You’re building leg muscles! Who needs a gym? The point is, all the little things you do to increase movement add up. Don’t eat while you work It might surprise you to know that being aware of what you put in your mouth—and when you put it there—makes a difference. I know many people, not only developers, who eat lunch at their desks, balancing a spoonful of food in one hand while continuing to type with the other. Lunch becomes something that’s shoveled into our mouths and (maybe, if we have time) swallowed. That’s no way to appreciate a meal. Make lunchtime a logical break between your coding sessions. Some folks may protest that there’s just no time to eat: we have to code 20 hours a day! First of all, it’s impossible to be efficient that way. A   (PDF) from the University of Illinois at Urbana-Champaign has shown that taking a deliberate break can reboot focus on the task at hand. It offsets our brain’s tendency to fall into autopilot, which explains why we can’t come up with good solutions after continuously staring at a bug for hours.   wrote a   explaining how human beings are not linear processes. We are still operating on an industrial model where emphasis is placed on hours worked, not output achieved. We need to aim for a healthy “Work Rate Variability” and develop models of working that stop making us ill, and instead let us do our best. Also, by actually bothering to chew your food before swallowing, you eat more slowly.   that eating slowly leads to lower hunger ratings and increased fullness ratings. Chances are you’ll feel healthier overall and gain a fresh sense of perspective, too, by giving yourself a proper lunch break. Such is the power of minimal effort. Use a blue-light filter at night Personally, I’m a morning person, but most of my developer friends are  . Everybody  , but if you’re someone who operates better at night, I recommend installing   on your desktop and mobile devices. It’s a tiny application that makes the color of your computer’s display adapt to ambient light and time of day. Melatonin is a hormone that helps maintain the body’s  , which determine when we sleep and wake up. Normally, our bodies produce more melatonin when it gets dark.   that exposure to room light in the evening suppresses melatonin during normal sleep hours.   has shown that blue light suppresses sleep-associated delta brainwaves while stimulating alertness. Because it doesn’t make sense, given socioeconomic realities, to ask people to stop working at night, the best alternative is to reduce exposure to blue light. Minor effort required If you’ve already started incorporating zero-effort health habits into your life, and feel like putting in a bit more effort, this section outlines tactics that take a little more than zero effort. Walk When I started writing code, I found myself glued to my chair for hours on end. You know that feeling when you’re debugging something and obstinately refuse to let that bug get the better of you? But I realized that my efficiency decreased the longer I worked on something without stopping. I can’t tell you how many times I worked on a bug till I threw my hands up in frustration and went for a walk, only to have the solution come to me as I strolled outside enjoying the breeze and a change of scenery. Walking doesn’t require any additional planning or equipment. Most of us, if we’re lucky, can  . The health benefits accrued include a reduction of chronic diseases like   and  . Try this: as part of your attempt to have a better lunch break, take a walk after you’ve properly chewed and swallowed your lunch. It   immediately after a meal. You’ll get fitter while you’re at it. Stretch I don’t know about you, but sitting for long periods of time makes my hips feel tight and my back tense up. The scientific research on the exact effects of sitting on the structural integrity of your hip flexors seems to be inconclusive, but I know how I feel. A lot of us tend to slouch in our chairs, too, which can’t be good for our overall posture. If you find yourself craning your neck forward at your desk, with your shoulders up near your ears and back rounded forward, news flash! You have terrible posture. So what can you do about it? Well, for starters, you can refer to a   that summarizes the ills of bad posture. The TL;DR: bad posture negatively affects your shoulders, neck, hips, and especially your back. Slouching for prolonged periods causes the soft discs between our vertebrae to compress unevenly. If you take a sponge and place a weight on one side of it and leave it there for hours, the sponge will warp. And that’s exactly what happens to our discs. As someone who has suffered from a prolapsed disc, I can tell you that back trouble no fun at all. Here’s another thing you can do:  . You don’t have to do all of these exercises at once—just sprinkle them throughout your work day. The improved blood circulation will be  , too. Sleep Most of us don’t get enough sleep. I hardly know anyone under the age of 12 who goes to bed before 11 p.m. Maybe that’s just the company I keep, but there are lots of reasons for not getting enough sleep these days. Some of us work late into the night; some of us game late into the night. Some of us care for children or aging parents, or have other responsibilities that keep us up late. I live in Singapore, which   on the list of cities clocking the fewest hours of sleep: six hours and 32 minutes. Sleep deprivation means more than just yawning all the time at work. Research has shown that  . Insufficient sleep affects not only your motor skills, but also your   (PDF) and   (PDF). You become a dumb, angry troll when sleep-deprived. Changing your sleep habits takes some effort. The   is to sleep and wake up at the same time each day, and to try to aim for seven and a half hours of sleep.  , a psychology professor at the University of Hertfordshire, our sleep cycles run in 90-minute intervals. Waking up in the middle of those cycles makes us groggy. Wiseman offers tips on how to sleep better. Resistance training By “resistance training,” I don’t mean hefting iron plates and bars at the gym (though if you like to do that, more power to you). If you enjoy the privilege of able-bodiedness, try to make vigorous physical movement part and parcel of your daily life. Ideally, you’ll have the basic strength and coordination to run and jump. And to be able to get right up without much effort after falling down. You don’t have to be an elite athlete— —but with luck, you’ll be able to perform at least some basic movements. Our own body weight is plenty for some rudimentary exercises. And it doesn’t matter if the heaviest weight you’re willing to lift is your laptop and you couldn’t do a push-up if your life depended on it. There are progressions for everyone. Can’t do a push-up on the ground? Do a wall push-up instead. Can’t do a basic squat? Practice sitting down on your chair very slowly. Can’t run? Take a walk. (Yes, walking is a form of resistance training). And so on. There are two websites I recommend checking out if you’re interested in learning more. The first is   by  . He and I share a similar philosophy: small changes add up to big results. He covers topics ranging from diet to exercise and offers lots of resources to help you on your journey. Another site I really love is  . It teaches people how to move better, and to better understand and connect with their bodies. Wrapping up: slow & steady There is only one way to build new habits:  . That’s why it’s so important to do things that take minimal effort. The less effort an action requires, the more likely you are to do it consistently. Also: try not to make drastic changes to all aspects of your life at once (though that   for some). Regardless of whether you mind change in your life or not,   to your system. And even  . It’s better to start small, with minor changes that you barely feel; once that becomes a habit, move on to the next change. We spend hours maintaining our code and refactoring to make it better and more efficient. We do the same for our computers, optimizing our workflows and installing tweaks to eke out those extra seconds of performance. So it’s only right that we put a little effort into keeping our bodies reasonably healthy. Fixing health problems usually costs more than fixing bugs or machines—and often the damage is irreversible. If we want to continue to write great code and build cool products, then we should take responsibility for our health so that we can continue to do what we love for decades to come. Like this: \n\t\t\t\t\t\t\tRecently by Chen Hui Jing\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-itinerant-geek/", "title": "The Itinerant Geek", "content": "This spring I spent almost a month on the road, and last year I delivered 26 presentations in eight different countries, spending almost four months traveling. While doing all of this I am also running a business. I work every day that I am on the road, most days putting in at least six hours in addition to my commitments for whichever event I am at. I can only keep up this pace because travel is not a huge stressor in my life. Here are some things I have learned about making that possible, in the hope they are useful to anyone setting off on their first long trip. Add your own travel tips in the comments. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Before you go During the run-up to going away, I stay as organized as possible. Otherwise I would lose a lot of time just preparing for the trips. I have a Trello board set up with packing list templates. I copy a list and remove or add anything specific to that trip. Then I can just grab things without thinking about it and check them off. I also use Trello to log the status of plans for each trip; for example, do I have a hotel room and flights booked? Is the slide deck ready? Do I know how I am getting from the airport to the hotel? This way I have instant access to the state of my plans and can also share this information if needed. It is easy to think you will always have access to your information in its original form. However, it is worth printing a copy of your itinerary to keep with you just in case you can’t get online or your phone battery runs out. For times when you don’t have physical access to something at the moment, take photos of your passport and car insurance (if it covers rentals), and upload them somewhere secure. Your travel may require a visa. If your passport is expiring within six months of your trip, you may want to get a new one — some countries won’t issue a visa on a passport that is due to expire soon. You can in some cases obtain pre-authorization, such as through the American ESTA form for participating in its Visa Waiver Program. This might have changed since your last trip. For example,   as of March 2016. I’ve traveled to Canada for ConFoo for the last four years – if I attend next year, I’ll need to remember to apply for this beforehand. Tell your bank and credit card company that you are traveling to try and avoid their blocking your card as soon as you make a purchase in your destination. Make sure you have travel insurance that covers not only your possessions but yourself as well. Be aware that travel insurance will not pay out if you become sick or injured due to an existing condition that you didn’t tell them about first. You will have to pay an increased premium for cover of an existing issue, but finding yourself with no cover and far from home is something you want to avoid. Make sure that you have sufficient of any medicine that you need. Include some extra in case of an unscheduled delay in returning home. I also usually pack a few supplies of common remedies – especially if I am going somewhere that is not English speaking. I have a vivid memory of acting out an allergic reaction to a Polish pharmacist to remind me of this! I also prepare for the work I’ll be doing on the road. In addition to preparing for the talks or workshops I might be giving, I prepare for work on Perch or for the business. I organize my to-do list to prioritize tasks that are difficult to do on the road, and make sure they are done before I go. I push tasks into the travel period that I find easier on the small screen of my laptop, or that I can complete even in a distracting environment. When booking travel, give yourself plenty of time. If you are short of time then every delay becomes stressful, and stress is tiring. Get to the airport early. Plan longer layovers than the 70 minutes your airline believes it will take you to deplane from the first flight and make it round a labyrinthine nightmare from the 1980s to find the next one. On the way home from Nashville, my first plane was delayed due to the inbound flight having to change equipment. The three-hour layover I had chosen meant that even with almost two hours of delay I still made my transatlantic leg home in time. Travel is a lot less stressful if you allow enough time for things to go wrong. Air travel tips Try to fly with the same airline or group in order to build up your frequent flyer status. Even a little bit of “status” in an airline miles program will give you some perks, and often priority for upgrades and standby tickets. If you want to take anything of significant size onto the aircraft as hand luggage, the large roller bags are often picked out to be gate-checked on busy flights. I travel with a  , which I can carry as a backpack. It is huge, but the gate staff never spot it and due to being soft-sided, it can squash into the overhead compartments on the smaller planes that are used for internal U.S. flights. Have in your carry-on an overnight kit in case your checked luggage does not make it to your destination at the same time as you do. Most of the time you’ll find your bag comes in on the next flight and will be sent to your hotel, but if you need to get straight to an event it adds stress to be unable to change or brush your teeth. If you plan to work on the flight, charge your laptop and devices whenever you can. More and more planes come with power these days – even in economy – but it can’t be relied on. I have a  , a large external battery. It’s a bit heavy but means I can work throughout a 10-hour flight without needing to plug in. On the subject of batteries, airlines are becoming increasingly and understandably concerned about the fire risk posed by lithium ion batteries. Make sure you keep any spare batteries in your hand luggage and remove them if your bag is gate-checked. Here is  . A small flat cool bag, even without an icepack, works for a good amount of time to cool food you are bringing from airside as an alternative to the strange offerings onboard. I usually pop a cold water bottle in with it. London Heathrow T5 has a Gordon Ramsay “Plane Food” restaurant that will make you a packed lunch in a small cool bag to take on the plane! Get lounging Airport lounges are an oasis. Something I didn’t realize when I started traveling is that many airport lounges are pay on entry rather than being reserved for people with higher class tickets or airline status. If you have a long layover then the free drinks, wifi, power, and snacks will be worth the price – and if it means you can get work done you can be making money. The   app can help you locate lounges that you can access whether you have airline status or not. There is another secret to airline lounges: they often have a hotline to the airline and can sort out your travel issues if your flight is delayed or canceled. With the delayed flight in my last trip I checked myself into the American Airlines lounge, mentioning my delay and concern for the ongoing leg of the flight. The member of staff on the desk had the flight status checked and put me on standby for another flight “just in case.” She then came to let me know – while I happily sat working in the lounge – that it all looked as if it would resolve in time for me to make my flight. Once again, far less stressful than trying to work this out myself or standing in a long line at the desk in the airport. Looking after yourself If you do one or two trips a year then you should just relax and enjoy them – eat all the food, drink the drinks, go to the parties and forget about your regular exercise routine. If you go to more than 20, you won’t be able to do that and also do anything else. I quickly learned how to pace myself and create routines wherever I am that help to bring a sense of normal life to hotel living. I try as much as possible to eat the same sort of food I usually eat for the majority of the time – even if it does mean I’m eating alone rather than going out for another dinner. Hotel restaurants are used to the fussiest of international travelers and will usually be able to accommodate reasonable requests. I do a quick recce of possible food options when I arrive in a location, including places I can cobble together a healthy packed lunch if the conference food is not my thing. I’ll grab a sparkling water from the free bar rather than another beer, and I’ll make use of the hotel gym or go for a run to try and keep as much as possible to the training routine I have at home. I do enjoy some great meals and drinks with friends – I just try not to make that something that happens every night, then I really enjoy those I do get to. I’m fortunate to not need a lot of sleep, however I try to get the same amount I would at home. I’ve also learned not to stress the time differences. If I am doing trips that involve the East and West Coast of America I will often just remain on East Coast time, getting up at 4am rather than trying to keep time-shifting back and forth. If you are time-shifting, eating at the right time for where you are and getting outside into the light can really help. The second point is not always easy given the hotel-basement nature of many conference venues. I tend to run in the morning to remind myself it is daytime, but just getting out for a short walk in the daylight before heading into the event can make a huge difference. I take care to wash my hands after greeting all those conference-goers and spending time in airports and other places, and am a liberal user of wet wipes to clean everything from my plane tray table to the hotel remote control. Yes, I look like a germaphobe, however I would hate to have to cancel a talk because I got sick. Taking a bit of care with these things does seem to make a huge difference in terms of the number of minor illnesses I pick up. Many of us in this industry   and find constant expectation to socialize and be available tiring. I’m no exception and have learned to build alone time into my day, which helps me to be more fully present when I am spending time with other speakers and attendees. Even as a speaker at an event, when I believe it is very important for me to be available to chat to attendees and not to just vanish, this is possible. Being at a large number of events I often have seen the talks given by other speakers, or know I can catch them at the next event. So I will take some time to work or relax during a few sessions in order to make myself available to chat during the breaks. If you are taking extended trips of two weeks or more these can be hugely disruptive to elements of your life that are important to your wellbeing. That might be in terms of being unable to attend your place of worship, meet with a therapist, or attend a support group meeting. With some thought and planning you may be able to avoid this becoming an additional source of stress – can you find a congregation in your location, use Skype to meet with your therapist, or touch base with someone from your group? Working on the road Once at your destination, getting set up to work comfortably makes a huge difference to how much you can get done. Being hunched over a laptop for days will leave you tired and in pain. My last trip was my first with the new and improved  , along with an external Apple keyboard and trackpad. The Roost is amazing; it is incredibly light and allowed me to get the laptop to a really great position to work properly. Plan your work periods in advance and be aware of what you can do with no, or limited internet connectivity. In OmniFocus I have a Context to flag up good candidates for offline work, and I also note what I need to have in order to do that work. I might need to ensure I have a copy of some documentation, or to have done a git pull on a repository before I head into the land of no wifi. I use   for technical documentation data sets when offline. On a ten-hour flight with no wifi you soon realize just how much stuff you look up every day! If traveling to somewhere that is going to be horribly expensive for phone data, do some research in advance and find out how to get a local pay-as-you-go sim card. If you want to switch that in your phone, you need to have an unlocked phone (and also the tools to open your phone). My preferred method is to put the card into a mobile broadband modem, then connect my phone to that with the wifi. This means I can still receive calls on my usual number. The possibility of breaking, losing, or having your laptop stolen increases when it isn’t safely on your desk in the office. Have good insurance, but also good backups. During conferences, we often switch off things like Dropbox or our backup service in order to preserve the wifi for everyone – don’t forget you have done this! As soon as you are able, make sure your backups run. My aim is always to be in a position where if I lost my laptop, I could walk into a store, buy a new one and be up and running within a few hours without losing my work, and especially the things I need to present. Enjoy the world! Don’t forget to also plan a little sightseeing in the places you go. I would hate to feel that all I ever saw of these places was the airport, hotel, and conference room. I love to book myself on a walking tour. You can discover a lot about a city in a few hours the morning before your flight out, and there are always other lone business travelers on these tours. I check Trip Advisor for reviews to find a good tour. Lonely Planet have “Top things to do in…” guides for many cities:  . I’ll pick off one item that fits into the time I have available and head out for some rapid tourism. As a runner I’m also able to see many of the sights by planning my runs around them! Those of us to get to travel, who have the privilege of doing a job that can truly be done from anywhere, are very lucky. With a bit of planning you can enjoy travel, be part of events, and still get work done and remain healthy. By reducing stressful events you do have control over, you can be in better shape to deal with the inevitable times you do not. Like this: \n\t\t\t\t\t\t\tRecently by Rachel Andrew\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/adapting-to-input/", "title": "Adapting to Input", "content": "Jeremy Keith once observed that our fixed-width, non-responsive designs were built on top of a  . We knew the web didn’t have a fixed viewport size, but we willfully ignored that reality because it made our jobs easier. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The proliferation of mobile devices forced us into the light.   gave us the techniques to design for the rediscovered reality that the web comes in many sizes. And yet there is another consensual hallucination—the idea that desktop equals keyboard and mouse, while phones equal touch.  It’s time to break free of our assumptions about input and form factors. It’s time to  . Four truths about input Being adaptable In the early days of mobile web we created pitfalls for ourselves such as “ .” We’ve since learned that mobile context  . People use their phones everywhere and for any task, “especially when it’s their  .” When it comes to input, there is a danger of making a similar mistake. We think of a physical keyboard as being better suited to complex tasks than an onscreen keyboard. But there are many people whose primary access to the internet is via mobile devices. Those same people are comfortable with virtual keyboards, and we shouldn’t ask them to switch to a physical keyboard to get the best experience. Even for those of us who spend our days on computers, sometimes a virtual keyboard is better. Perhaps we’re on a plane that has started to descend. In that moment, being able to detach a keyboard and work on a touchscreen is the difference between continuing our task or stowing our laptop for landing. So who are we to judge what input is better? We have no more control over the input someone uses than we do the size of their screen. Becoming flexible Confronting the truth about input can be overwhelming at first. But we’ve been here before. We’ve learned how to design for a continuum of screen sizes; we can learn how to adapt to input—starting with these seven design principles. Design for multiple concurrent inputs The idea that we’re either designing for desktop-with-a-mouse or touch-on-mobile is a false dichotomy. People often have access to multiple inputs at the same time. Someone using a Windows 10 laptop or a Chromebook Pixel may be able to use the trackpad and touchscreen concurrently. There are many web pages that detect touch events and then make incorrect assumptions. Some see the touch events and decide to deliver a mobile experience regardless of form factor. Others have different branches of their code for touch and mouse and once you’re in one branch of the code, you cannot switch to the other. At minimum, we need to ensure that our web pages don’t prevent people from using multiple types of input. Ideally, we would look for ways to take advantage of multiple inputs used together to create better experiences and enable behavior that otherwise wouldn’t be possible. Make web pages that are accessible When someone uses a remote control’s   to interact with a web page on a TV, the browser sends arrow key events behind the scenes. This is a pattern that new forms of input use repeatedly—they build on top of the existing forms of input. Because of this, one of the best ways to ensure that your web application will be able to support new forms of input is to make sure that it is accessible. The information provided to help assistive devices navigate web pages is also used by new types of input. In fact, many of the new forms of input had their beginnings as assistive technology. Using Cortana to navigate the web on an Xbox One is not so different than using voice to control Safari on a Mac. Design for the largest target size by default A mouse is more precise than our fingers for selecting items on a screen. Buttons and other controls designed for a mouse can be smaller than those designed for touch. That means something designed for a mouse may be unusable by someone using a touchscreen. However, something designed for touch is not only usable by mouse, but is often easier to select due to  , which says that “the time to acquire a target is a function of the distance to and size of the target.” Plus, larger targets are easier for users with lower dexterity, whether that is a permanent condition or a temporary one caused by the environment. At the moment, the largest target size is touch, so this means designing touch first. As Josh Clark  , “when any desktop machine could have a touch interface, we have to proceed as if they all do.” Design for modes of interaction instead of input types Gmail’s display density settings illustrate the benefit of designing for user interaction instead of input types. By default, Gmail uses a comfortable display density setting. If someone wants to fit more information on the screen, they can switch to the compact display density setting. It so happens that these two settings map well to different types of input. The comfortable setting is touch-friendly. And compact is well suited for a mouse. But Gmail doesn’t confine these options to a particular input. Someone using a touchscreen laptop could choose to use the compact settings. Doing so sacrifices the utility of the laptop’s touchscreen, but the laptop owner gets to make that choice instead of the developer making it for her. Vimeo made a similar choice with their discontinued feature called Couch Mode. Couch Mode was optimized for the 10ft viewing experience and supported remote controls. But there was nothing that prevented someone from using it on their desktop computer. Or for that matter, using the standard Vimeo experience on their TV. In both cases, the companies designed for use cases instead of a specific form factor or input. Or worse, designing for a specific input inferred from a form factor. Abstract baseline input When we’re working on responsive web designs at  , we’ve found that the labels “mobile,” “tablet,” and “desktop” are problematic. Those labels create images in people’s minds that are often not true. Instead, we prefer “narrow,” “wide,” “tall,” and “short” to talk about the screens we’re designing for. Similarly, words like “click” and “tap” betray assumptions about what type of input someone might use. Using more general terms such as “point” and “select” helps prevent us from inadvertently designing for a particular input. We should also abstract baseline input in our code. Mouse and touch events are entirely  , which makes it difficult to write applications that support both without duplicating a lot of code. The Pointer Events   normalizes mouse, touch, and stylus events into a single API. This means for basic input, you only have to write your logic once. Pointer events map well to existing mouse events. Instead of  , use  . And if you need to tailor an interaction to a specific type of input, you can check the   and provide alternate logic—for example, to support gestures for touchscreens. Pointer Events are a W3C standard and the jQuery team maintains a   for  . Progressively enhance input After baseline input has been wrangled, the fun begins. We need to start exploring what can be done with all the new input types available to us. Perhaps you can find some innovative uses for the gyroscope like Warby Parker’s product page, which uses the gyroscope to turn the model’s head. And because the feature is built using progressive enhancement, it also works with mouse or touch. The camera can be used to   on iOS or create a   in browsers that support  . Normal input forms can be enhanced with the   attribute to capture images or video via the   specification: Make your forms easier to complete by ensuring they work with  . Google   that users complete forms up to 30 percent faster when using autofill. And keep an eye on the  , which will make collecting payment simple for customers. Or if you really want to push the new boundaries of input, the   can be used to   in browsers that support it. And   beacons can be combined with   to create experiences that are  . Make input part of your test plans Over the last few years, test plans have evolved to include mobile and tablet devices. But I have yet to see a test plan that includes testing for stylus support. It makes intuitive sense that people check out faster when using autofill, but none of the ecommerce projects that I’ve worked on have verified that their checkout forms support autofill. We need to incorporate input in our test plans. If you have a device testing lab, make input one of the criteria you use to determine what new devices to purchase. And if you don’t have a device testing lab, look for an   near you and consider contributing to the effort. The way of the web Now is the time to experiment with new forms of web input. The key is to build a baseline input experience that works everywhere and then progressively enhance to take advantage of new capabilities of devices if they are available. With input, as with viewport size, we must be adaptable. It is the way of the web. Like this: \n\t\t\t\t\t\t\tRecently by Jason Grigsby\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/resurrecting-dead-personas/", "title": "Resurrecting Dead Personas", "content": "Being a user-centered designer means that you deliberately seek out the stories, data, and rationale behind your users’ motivations. You endeavor to keep user concerns at the forefront of every design decision, and regularly conduct research and collect data.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But collecting facts about users isn’t the same as knowing your users. Research and data need to be regularly aggregated, analyzed, and synthesized into a format that is both understandable and accessible at critical moments. You need to turn user facts into user wisdom, and one of the most common methods for doing this is to develop user personas.  Type “how to build user personas” into your favorite search engine and you will get thousands of results outlining different templates and examples of personas. Across the tech industry, personas “ ,” and help design and product teams focus on the details that really matter. Studies have shown that companies can see   in personas, which explains why   on these design tools. However, while it is common for design teams to spend considerable amounts of time and money developing personas, it is almost as common to see those personas abandoned and unused after a while. Everett McKay, Principal at  , has pointed out that  , such as:  They do not reflect real target users. They are not developed with product goals in mind. They are not embedded into team processes. I agree with everything McKay suggests, but I would add that personas fail largely because of one common misconception: the false idea that once you build a persona, you’re done. As designers, we know that the first version of a product is never perfect, but with multiple rounds of design and research it can be made better. Personas are no different.  To recover personas that have become lifeless, here’s how you can iterate on them with periodic research and use them to achieve tangible goals. The following steps will help ensure you see value from the investment you made developing them in the first place. Let’s put your personas (back) to work and incorporate them into your design and development process.  How a persona dies Let’s imagine you work at a company called Amazing Childcare that creates tools to help parents find childcare options for their children. Let’s also say you have the following data and statistics for AmazingChildcare.com: 82% of customers are between the ages of 30 and 35, and 73% of those are female. The most common concerns around finding childcare (as reported in user interviews) are cost and quality of care received. AmazingChildcare.com has a homepage bounce rate of 40%. Customer satisfaction survey shows an average satisfaction rating of 6.5 (out of 10). While this data is interesting, it is hard to process and assimilate into your design practice. You still need to go through the arduous work of understanding why the majority of users are who they are, what problems they are trying to solve, and how you can better meet their needs. So, you decide to create a persona. The persona you create is Susan, a 34-year old working mother of a two-year-old. She is interested in finding a qualified nanny that has passed a background check. Susan, like all freshly made personas, is a much more thought-provoking platform for crafting design solutions than a spreadsheet of numbers. She is someone we can imagine, remember, and empathize with. This is the point in the story when Susan dies.  At first, the design team enjoys thinking about and designing for Susan. Having her “in the room” is thought provoking and interesting, but over time, Susan is talked about less and less. She starts to feel irrelevant to the products you’re building. You realize that Susan has “died,” leaving a lifeless, zombie Susan sitting in her place. You consider all the research and work your team put into creating Susan and wonder “what went wrong?”  The problem is that your personas remained static and unmoving while the company, Amazing Childcare, grew and changed.  Review, research, repeat As your product and marketing strategies change over time, so do your target users. In our example, Amazing Childcare may have started with a large user base of parents looking for full-time childcare options for their toddlers, but over time, the demographic changed. Now, it’s most frequently used by parents of school-age children looking for one-time, “date night” babysitters. When this happens, your original personas—like Susan—are no longer useful for thinking through design problems. Unless you  , you’ll be responding to old assumptions (based on your outdated personas) rather than who your customers really are. In other words, your real-world users changed, but Susan didn’t.  To remedy this, you should regularly conduct persona research, using a variety of methods to evaluate whether your personas still reflect: The most common demographic, budget, and purchase scenarios of your users The main behavior patterns of your users The motivations and goals of your users. You can conduct your persona research on a schedule, such as once a quarter, or you can opportunistically work it into the usability research you already do. Either way, you need to make a commitment to keeping your personas relevant.  If we go back to our example at Amazing Childcare, your personas would change based on the new research. Susan may still be a valid persona for your company, but your research would show that she no longer represents its core users, and should therefore no longer be your primary persona. Based on the updated research, you could develop a new persona named Beverly. Beverly is a 42-year-old mother of a 10-year-old boy and 7-year-old girl. Unlike Susan, Beverly is interested in finding an inexpensive babysitter for occasional date nights with her husband. You would use Beverly to think about the needs of the core user base, but only use Susan when you’re designing tools that directly cater to the demographic she represents. It is natural and necessary for personas to evolve and change; personas like Susan can drift out of the limelight of “primary persona” and make room for new friends like Beverly. Your ecosystem of personas should be as dynamic as your ecosystem of users, and regular persona research will ensure that they evolve in sync.  Set goals Personas can help you do more than think about and design for target users. They can (and should) be used to help you reach real, tangible goals. Goals that reflect ways of increasing business, creating better user experiences, or both, will help you update your personas and develop your product. Even if you are not sure what is possible to achieve with personas, you should make an attempt at setting goals. Goals (even unachievable ones) provide a means for tracking the return on investment of your efforts. To get started, try using this format from  .  For each goal, you will need to identify how you’ll measure progress toward that objective. You may need to create surveys and interview scripts for some, while for others, you may need analytics tools. Here is an example of a persona goal we could set at Amazing Childcare. Once you have created a set of goals for your personas, you can evaluate them as part of your regular research plan. If you find that you’re falling behind on any of your goals, you can research and recalibrate your personas based on the metrics you care about.  For instance, if we evaluated the Susan persona in the ways we’ve outlined above, the data we would uncover indicates that Susan doesn’t actually represent the majority of our users. We would then reevaluate our personas and ultimately develop our new primary persona, Beverly. Putting personas (back) to work While research and goal setting are good practices, in and of themselves, the real benefit of personas can be seen when you put them to use. Here are some suggestions for how to incorporate personas into your design practice: Start putting the face of your target persona at the top of every sketch, wireframe, and prototype. Encourage others to do the same. Put a comment in every product story or ticket that states the target persona for that feature. Shake up regular design meetings by asking a few people to roleplay as your personas. Throughout the rest of the meeting, have them look at every new design through the lens of their assigned persona. Conduct a workshop. Activities such as   reinvigorate and add detail to personas. One of my favorite ways to utilize personas is to write scenarios in which they are the main character, then use them to explain research results. For example, let’s say we’re evaluating a new interface for the sign-up and login process on our website. Instead of presenting raw numbers (e.g., “10% of new users couldn’t find the sign-up interface”), we can present the data in a scenario, providing a way to understand a design problem that goes beyond statistics. Here is an example: Beverly came to the Amazing Childcare website to evaluate whether the company would actually be useful in helping her find reliable babysitters for her family. She decides that she would like to try the product and wonders if there is a free trial available. She searches the content of the web page for the words “free trial” or “sign-up,” but is unsuccessful. She does not think the “login” button applies to her, since she is a new user and does not yet have an account. She does not think to click on the “login” button, so she fails to find the new-member sign-up interface. In the example above, we’re using Beverly to describe feature requirements, usage statistics, and study results. The benefits of using personas to explain these components is that you are simultaneously making messy and complex details easier to understand, and forcing yourself to deeply consider who you’re really designing for. According to Alan Cooper, you should “ .” Focusing on a persona like Beverly forces us to define the parameters of what our design should accomplish and helps us ultimately evaluate its success. Keeping personas alive Developing personas and keeping them alive can be difficult. Without regular care and feeding, they can waste away and your investment in them will be lost. In  , Steve Mulder described it best: “It’s very easy to create personas, then think your work is done. But just having personas doesn’t mean people will accept them. Just accepting the personas doesn’t mean people will remember them. Just remembering the personas doesn’t mean people will actually use them. Your job is to keep the personas alive so they show their worth.” To ensure your personas are accepted, remembered, and used, you need to be the persona advocate on your team. As the persona advocate, you need to: Regularly conduct persona research. Set goals. Make sure there is always a place for your personas at the design table. With creativity and persistence, you can cultivate a suite of well-researched, battle-tested user personas. While being a persona’s advocate may seem like a lot of work, it’s worth doing.   Taking the time to draft a set of user personas, use them, evaluate them, research them, and refresh them, forces you to consider who your users are, what their goals are, and how your product fits into their lives. If you’re ready to become the persona advocate on your team, here are some additional resources to help you along: Books  by Tamara Adlin and John Pruitt  by Steve Mulder Articles  by Meg Dickey-Kurdziolek  by Silvana Churruca (the UX Lady)  by Shlomo Goltz  by Jeff Sauro Like this: \n\t\t\t\t\t\t\tRecently by Meg Dickey-Kurdziolek\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/finding-opportunities-in-the-mistakes-we-make/", "title": "Finding Opportunities in the Mistakes We Make", "content": "Roughly six years into my software development career, I had worked on interesting projects, met amazing people, and had the opportunity to travel to exotic cities. Yet I was frustrated. I was burning the candle at both ends to get things done. I didn’t look back to see if I could improve on how things were being done; I had no time. Deep down I knew it wasn’t feasible. I was working hard, not smart; I felt like I wasn’t working toward anything; I was falling behind with technology. I was burning out. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I started searching for an opportunity to facilitate my technical growth. Two years later I was based at an enterprise client who adopted agile software development methodologies, and everything changed for me. This new world exposed me to a diverse working environment and new perspectives, and encouraged me to ask even more questions than before. This is when I discovered the power of the words “reflect, inspect, and adapt.” It wasn’t a walk in the park with unicorns and rainbows, but the experience has aided me in officially branding my career as one exciting journey of professional and self-discovery. Now ten years into my career, I realize that for most of that time I have been in survival mode. After looking back, I’d like to share how I found opportunities in the mistakes I made. Define clear career and personal goals Computers weren’t a household name when I was growing up in South Africa, but I was lucky to have access to my dad’s Pentium 386. I was amazed at this technology. When we got internet access, I was immediately hooked on the online world. I taught myself HTML and later built my own machine with the money I made from designing a website for the local newspaper. When I chose my higher education path I had one goal—I wanted to make websites. I didn’t want a degree; I wanted experience. I studied at a college for two years, then excitedly entered the workforce to follow my passion. As I entered the workforce, I wasn’t prepared for the politics: managers expecting things to be done almost immediately; clients who don’t engage and are unsure of what they want; clients who express urgency, yet wait for the last minute to provide you with everything you need; an increased workload due to colleagues who stay well inside their comfort zone. These are just some examples of the politics that initiated my frustrations. I wondered if this is where I’d still be   and if I would be able to sustain it. I didn’t know the answer to the former, but to the latter it was definitely no. Coupled with turning thirty, the new perspectives I developed in the agile environment made me really evaluate my future. I realized that I didn’t have goals; I was only chasing my passion. Granted, it is fun and I gained a lot of experience in many different areas in IT, but I don’t have anything tangible to show for it now. After much reflection, I discovered these goals for myself: These goals feel more defined to me than just making cool websites. I wish I had set some goals a little sooner but luckily — as cliché as it sounds — it’s never too late. Goals give you direction and purpose. Like me, you may have worked many late nights on personal projects that never materialized. It helps to have focus and something definite to achieve. I find what’s best of all is that I don’t feel constrained by having these goals. They represent what’s important to me now but if my values change, I can inspect and adapt my goals. Put people before technology For too long, I worked alone on my own codebases and wondered if I was doing things the right way. I had little to no exposure to working in teams and dealing with industry buzzwords like agile, TDD/BDD, Gang of Four, SOLID, code reviews, continuous integration/delivery, DevOps, and <insert your favorite technical jargon here>. I was in a bubble falling further behind in the fast-paced technical world. I was focused on working with technology and never realized how important it is to collaborate. If you work in a company with a silo-based culture or one- or two-people teams, try not to accept things for what they are: Get involved with your coworkers by communicating and collaborating on projects. Try introducing knowledge-sharing sessions and code reviews. Reflect on what worked and what didn’t and also unpack why, so that you can learn from it. Approach management with suggestions on how you and your colleagues can produce more solid and effective software. Attend conferences or smaller  . Not only can you learn a lot through the content but you have the chance to network and learn from an array of people with different skills. Prioritize your tasks I often worked about twelve to sixteen hours a day on projects with short deadlines. I spent my official work hours helping colleagues with problems, immediately responding to email, attending to people with queries or friendly drop-ins, supporting projects that were in production, or fighting fires resulting from errors that usually came from miscommunication. This left me with very little time to be productive. When I finally got to work on my project, my perfectionism only increased my stress levels. Regardless, I never missed a deadline. I thought everything was important. If I didn’t do what I was doing the world would end, right? No! The reality is that when everything is important, nothing is important. This working behavior sets unrealistic expectations for the business, your colleagues, and yourself. It hides underlying issues that need to be addressed and resolved. If you are working at an unsustainable pace, you can’t deliver your best work plus you end up missing out on actually living your life. The power of retrospectives The most important ceremony (or activity) I was introduced to in the agile environment was the  , which is “the process of retrospecting at the heart of Scrum (Inspect and Adapt), eXtreme Programming (fix it when it breaks) and Lean Software Development (Kaizen or Continuous Improvement)”. Through retrospection you are granted the opportunity to reflect on how you — and the team — did something, so that you can improve the process. Let’s run through this technique to identify some pain points using the situation I had found myself in:  I helped everyone else before I worked on my own tasks, I worked on things that didn’t add much value, and I thought that all the features needed to be ready for launch. I was blind to asking for help when I needed it.  I allowed the distractions by immediately switching context to help others because it was important to them.  I was the only person working on one of the projects.  Communication was done via email and the stakeholders were off-site. There wasn’t quick feedback to indicate if the project was going in the right direction. Once the pain points are identified, adjustments need to be made in order to see improvement. Large adjustments could take too long to implement or adjust to, which leads to disruptions. Smaller adjustments are better. These adjustments may or may not work in the long haul, so we can look at them as experiments. To work more sustainably I need to know what I need to work on — and why — so that I can add value without wearing myself out. Perhaps I could find out what needs to be available for launch and create a prioritized list of things to do. This list could help me focus and get into the “zone.” To manage client expectations, we can try open communication. This can also help me prioritize my tasks. To overcome some of the distractions I could reap the   by saying no (within reason). This could help me stay in the zone for longer. If anything must be expedited I can start offering trade-offs: if I do   now, can   wait? To alleviate the pressures of being the sole person able to do certain things, I could have more conversations with my manager and train a colleague so that they are aware of what is going on and someone can take over in the event that I get sick or am on vacation. To reduce errors from miscommunication, perhaps we could create visibility for stakeholders. Introduce a physical workflow board and have constant feedback loops by requesting frequent reviews to demonstrate what we have done. Experiments run for a period of time and need to be measured. This is a grey area. Measurements aren’t always accurate, but it always boils down to the pain. If the pain is the same or has increased, then the experiment needs to be adjusted or a new experiment introduced. If it has been alleviated, even slightly, then there is improvement. Learning through experimentation Many of the experiments mentioned above already form part of the agile Scrum framework, so let me introduce you to real-world experiments we did in our team. Based on the way our development stories were deployed, we experienced pain with testing stories in the appropriate order. We were using Jenkins for automated deployments and each one got a number incremented from the previous one, but the testers weren’t testing the stories in any particular order. If a story was ready to be deployed, they wouldn’t know if there was another, untested story that they were unwittingly promoting to production along with it, or if the story they tried to deploy was being held back by other stories still awaiting testing. Without waiting for a retrospective we had a conversation to highlight the pain. We chose to write the build number on a note stuck on the story card on our wall and add a comment to our digital storyboard. This created quick visibility on the chronological order of the possible deployments of our stories. A change control process was later introduced that required details of a production deployment and a rollback plan for that change. We couldn’t quickly access the last few production build numbers, so we started writing them on stickies and put those onto a new section on our physical board. Now we didn’t have to search through email or log in to Jenkins to find these numbers. One day, we were asked when we last deployed and had to go back to email for the answer, so we started adding the date to the deployment number stickies. These were simple experiments but they added a lot of value by saving time. We acted on alleviating pain as it happened. Don’t be afraid to experiment if you are not in an Agile world. If you simply run to business with problems and offer no solutions then business will frown at you. The goal here is simple: identify your pain points and find simple solutions (or improvements) to try to alleviate the pain. Experiment, inspect, and adapt often. Believe in yourself Survival mode never did me any good. I didn’t get an award for working long hours to make deadlines. Letting my mistakes and frustrations build up over the years made me stop believing in myself. I was stuck in a rut; technology was changing around me fast and I was burnt out and falling behind. I’d scroll through   and instantly feel stupid. I’d spend time looking at all the amazing websites winning awards on   and feel inadequate. I didn’t have a life as it was consumed by my obsession for work. I didn’t know what I wanted anymore, or what I wanted to aspire to. Introspection helped me. By inspecting my behavior, I was able to make minor adjustments that I would then inspect again to see if they worked. This simple activity can show you what you are capable of and lead you to learning more about yourself and those around you. I am applying what I have learned in software in a personal capacity. I have my life back, and I feel empowered and freed. My final thoughts I’ve definitely made a lot of mistakes in my career. What I have shared with you is probably only a fraction of them. I don’t regret my mistakes at all; that is how I got my experience. The only regret I have is that I wish I had begun reflecting on them sooner. When a mistake is made, an opportunity is born: learn from that mistake to do something differently next time. Take time to step out of the subjective into the objective, so that you can reflect and consider what you could do to change it. (And don’t be too hard on yourself!) My journey has taught me to implement small experiments that can be measured and to run them for short periods of time. If something works, keep it. If not, adjust it or throw it away. By making small changes, there are fewer disruptions. If you too are in survival mode — stop and breathe now! Reflect, inspect, and adapt. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/practical-svg/", "title": "Practical SVG", "content": "You’ll probably want to exert some sizing control over any graphic you put on a website.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. And so shall it be.  But if the element you are resizing happens to be  , the result might not be exactly what you expect. Sizing   is a little more complicated than sizing an  . I’m not saying this to scare you. It’s almost complicated in a   way, because it gives you more control and opens up some interesting possibilities.  Keep these two concepts in mind when you’re working with the size of SVG images: The viewport is simply the height and width of the element: the visible area of the SVG image. It’s often set as   and   attributes right on the SVG itself, or through CSS. The   is an attribute of   that determines the coordinate system and aspect ratio. The four values are  ,  ,  , and  . Say we’re working with some SVG like this: In this case, the viewport and   are in perfect harmony ( ). The SVG will be drawn in the exact area it visually occupies. See the Pen   by Chris Coyier ( ) on  . Now say we double the width and height, like this: Will the   just draw in a 100 by 100 space in the upper left side of the 200 by 200 element? Nope. Everything inside the   will scale up perfectly to be drawn in the new, larger space ( ).  See the Pen   by Chris Coyier ( ) on  . The square aspect ratio still matches perfectly. That’s why it’s not particularly useful to think of the numbers anywhere in SVG as pixels, because they aren’t pixels; they’re just numbers on an arbitrary coordinate system. What if the aspect ratios don’t match, though? What happens now, by default, is that the SVG will draw itself as large as it can, centered along the longest dimension ( ). See the Pen   by Chris Coyier ( ) on  . If you want to regain some control over this behavior, there’s an attribute for the   element that can help!  It looks like this: The   and   parts of that value are followed by  ,  , or  . The reason SVG normally centers in the viewport is because it has a default value of  . If you change that to  , it tells the SVG:  The “without cutting off” part is another aspect of  . The default value is  —note the “meet.” You can replace   with   to say instead:  There are nine possible alignment values combined with   ( ). There are also nine possible alignment values combined with   ( ). I made a   for playing with this idea. Sara Soueidan also wrote an in-depth article on this subject, where she makes an excellent observation  . The   property has two keywords it can take:   and  . The   value means “make sure this entire image is viewable, even if you have to shrink it,” which makes it just like  . The   value means “make sure this covers the entire area, even if you have to cut parts off,” which makes it just like  .  Even the alignment part of the value has a matching CSS counterpart:  . The default   is  , meaning “top left.” That’s just like  . If you were to change that to, say,  , that would be like  !  has some examples to make that connection a little clearer. Remember: these aren’t interchangeable bits of code; they are just conceptually related. What if you want to throw aspect ratio out the window and have SVG scale to the viewport, like a raster image would? Turn   off ( )! See the Pen   by Chris Coyier ( ) on  . Amelia Bellamy-Royds wrote a  , in which she covers things like the fact that   can essentially contain other   with different aspect ratios and behavior, so you can make some parts of an image scale and others not, which is pretty cool and unique to SVG. Approaches to artboard sizing When you draw SVG in editing software, that software likely gives you some kind of artboard to draw on. That’s not a technical SVG term; it’s essentially a visual metaphor for  .  Let’s say you’re working with a whole set of icons for a site. One approach is to make all artboards hug each edge of the icon ( ). Here’s a quick trick to get that artboard cropping in Illustrator: select the Artboard tool and then “Fit to Artwork Bounds” from the Presets menu ( ). The big advantage to this technique is alignment ( ). If you want to align any edge of any of these icons to anything else, that’s easy to do. There is no mysterious space you need to contend with, or tweaky positional CSS.  The big disadvantage to the cropping technique is relative sizing. Imagine you take the practical step of sizing your icon’s width and height, like this: A tall, skinny icon will shrink to fit in that space and potentially appear awkwardly small. Or perhaps you’re trying to have an intentionally small star shape as an icon, except the star has a squarish aspect ratio and thus grows to fill the space, appearing bigger than you want it to. Here’s an example where two icons are sized identically as a square ( ). The “expand” icon looks right at home, since it has a square aspect ratio to match. But the “zap it” icon has a tall and narrow aspect ratio, so it looks wimpy, like it’s floating in the same square area. The other approach here is to make consistently sized artboards ( ): The advantages and disadvantages are exactly inverse here. You might have alignment issues, because not all edges of the icons touch the edge of the  , which can be frustrating and might require tweaking sometimes ( ).  You won’t have relative sizing issues, though, because the   is the same for all of them. If any particular icon looks too big or small, you can adjust the artwork to bring it more in line with the set. Since we’re learning about sizing, now is the perfect time to bring up how SVG fits into the flexible world of responsive design. Responsive SVG One of the hallmarks of responsive design is fluid layout. Content—images included—is designed to fit its containers and the screen. If responsive design is new to you,   on the subject is a fine place to start learning about it. SVG jibes extremely well with responsive design: Responsive designs are flexible. So is SVG! It renders well at any size. Responsive web design is a philosophy of caring about how a website looks and behaves in any browser. Comparatively smaller SVG files and performance-responsible tactics like an SVG icon system can be a part of that. But perhaps SVG’s most obvious connection to responsive design is the possibility to react to CSS   queries. Media queries move, hide, or show elements with CSS based on things like the width or height of the browser window. Those elements can be anything: sidebars, navigation, ads, what have you. They can be SVG elements as well. Imagine a logo that displays different levels of detail depending on how much space is available. That’s exactly what Joe Harrison was thinking when he created a really neat  , ( ). On the web, we’ve always had the ability to swap out images with other ones. What’s appealing here is that we aren’t   images; these are all the   image. Or at least they could be. That signature “D” all by itself could be the same exact “D” used in the most complex version of the logo. Easy-cheesy in CSS.  Say we organize the SVG like so: This, by the way, is pretty easy to do in Illustrator ( ). The groups and names you create there turn into IDs in the SVG output, and you can use those IDs to do the styling. Personally, though, I prefer using classes because they aren’t unique (so you don’t accidentally end up with multiple identical IDs on the page) and because classes have a lower and more manageable level of CSS specificity. It’s easy enough to change IDs to classes with a bit of find-and-replace maneuvering in a code editor. The corresponding CSS could be something like this: Mind you, this is a contrived example of hiding parts of the images at different breakpoints, but that’s exactly how you would do it, along with some likely sizing adjustments. Anything you can do with CSS is on the table here. Perhaps some animation is appropriate at some breakpoints but not at others. Perhaps you change stroke sizes to beef up or trim down icons at different sizes. Perhaps you change some fill colors to simplify adjacent shapes. And things can get even fancier! Depending on how the SVG is used, those media queries might actually be different. SVG used as  ,  , or   has its own viewport. That means CSS   reacts to media queries based on that, rather than the whole browser window viewport. That means you would write, say, width-based media queries based on the width of the image, not of the entire page.  That’s a very appealing idea: an element that arranges itself based on attributes of itself, rather than the page.   That way, the SVG reacts to the situation it’s in rather than the arbitrary document it happens to be part of. As I write, this is referred to as “element queries” in CSS, but it doesn’t actually exist yet in regular HTML/CSS. Once again, SVG is ahead of the curve. Graduation into animation Speaking of things SVG is good at, let’s move into animation next. Everything we have been building on so far has prepared us for this. Hang on tight! Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/another-10k-apart/", "title": "Another 10k Apart: Create a Website in 10 KB, Win Prizes!", "content": "It gives us great pleasure to announce the   competition. Create a fully functioning website in 10 KB or less! Amaze your friends! Astound the world! Compete for fabulous prizes! Share this: \n\t\t\t\tTranslations\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Why 10k? Why now? It’s simple, really. In the 16 years since   about the   contest to create a functioning website in 5 KB or less, countless aspects of web design and development have changed. And, year after year,   has marked those changes, even instigating more than a few of them ourselves. But in all those years, one thing has remained constant: the need to keep our websites lean. Indeed, in the age of mobile slash responsive slash multidevice design, keeping sites lean and mean is more important than ever. In 2000,   launched   to celebrate the skill, ingenuity, and innovation of designers and developers who wring every byte of performance out of the websites and applications they fashion. Ten years later, Microsoft and An Event Apart launched the  —adding  ,  , and   to the competition’s requirements. And now, An Event Apart and Microsoft Edge have teamed up once more to entice you, the makers of websites, to improve your performance game yet again by competing in a new 10k Apart that’s even tougher than the last one. Golly! Ah, but there’s gain for your pain. Besides fame and glory, you could win $10,000 in cash, tickets to  , the  , and a copy of  ’s  , which I consider the unofficial successor to  . So what are you waiting for? Hop on over to the   website for complete rules and details. Like this: \n\t\t\t\t\t\t\tRecently by Jeffrey Zeldman\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/communicating-animation/", "title": "Communicating Animation", "content": "Consistent animation is crucial to both   and  . Interfaces obey laws of “design physics”; keeping animation consistent throughout an experience envelops users in an illusion of life, of reality. Animations that step out of line disrupt that flow and feel sloppy or jarring. But because animation sits squarely at the intersection of design, development, and UX, achieving consistency presents unique challenges: Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Communication issues make it hard for siloed teams to understand and tackle animations together. Inadequate deliverables prevent developers from moving forward quickly. Lack of respect for and deference to fellow team members leads to lopsided implementations that privilege some voices at the expense of others. When it comes to animation, it’s important for   to be heard. Including animations in our style guides and design systems is a great place to start. However, this is relatively new territory, and most animation documentation initiatives seem to be driven by either development or design. In an ideal world, developers and designers would live in harmony and collaboration, but all too often the two houses exist in isolation from each other. Most examples of animation in documentation reflect this rift by falling into one of two categories: thematic and educational, as seen in  ; or granular and explicit, as displayed in  . Designers want to provide guidance and overarching themes, as well as educational materials, in an effort to raise the profile of animation both within a company and within the larger web design and development communities. Meanwhile, developers aspire to define and dictate animation for maintainability and consistency. This contrast reflects the needs of each group. Designers want to know the underlying principles of motion design driving their application; developers want to know how to build that design to spec. These interests are not at odds with each other—rather, they form incomplete halves of a greater whole:  details what’s there and why.  offer building blocks and rules for spinning up new projects.  provides a common language and choreography.  empowers future designers to make smart decisions. As of this writing, there is no Ultimate Animation Style Guide/Pattern/Tile/Whatever example that combines all of these elements perfectly. There may never be an animation-style-guide pattern that satisfies everyone. Some organizations may need more of some of the above components than others, depending on the project and the animation or development literacy of the team. But all approaches share features that we can combine to create the Ultimate Animation Documentation for our own teams. Let’s have a look. Deliverables Deliverables are supposed to round off the design process, but I often find it helpful to start with what developers want and need. Some companies have designers who build prototypes in code. Developers then find it easy to go into the code and grab the variables needed to reproduce the UI animations. But not all workflows look like this, and many motion designers will rightly argue that the very act of animating code-first limits the ideation process. That’s why, at many companies, designers create animations in After Effects or Photoshop and then hand them off to developers. The developers must then pick apart these videos and gifs to determine what is changing at what rate. This makes the burden of implementation especially heavy for the developer, giving animation a reputation for “taking too long to prioritize.”  I myself once had to spend six hours converting an animated GIF to SVG by eyeballing it. If the designer had provided me with the necessary values, I could have recreated the animation perfectly in thirty minutes, tops. We’ll look at these values—easing, timing, and properties—next. For the sake of simplicity and consistency, we should include them in our documentation and reuse them as much as possible across our systems. Easing Easing describes the rate at which something changes over a period of time. It has its roots in traditional studio animation, where it was called “cushioning” or “slowing.” Easings are shorthand for rates of acceleration, deceleration, and bounces. We can invoke generic easings with CSS via keywords like “ease-in” and “ease-out,” but when everyone uses the same defaults, everyone’s designs start to look and feel the same. Easings provide an opportunity for us to set our UI apart from others in a very subtle way. We want custom easings that reinforce our brand—be it professional, fun, elegant, or even dark. And that’s what cubic-bezier curves were created for. Cubic-bezier curves are a   we can pass to CSS and JavaScript animation libraries to tell them how we want the animation to change over its allotted timeline. We can get some starting points at sites like   or create our own using the browser’s    . It’s tempting to make one cubic-bezier curve to rule them all, but what we really want is an array of several curves for different purposes:  feel faster and more natural if they respond immediately. A deceleration (moving from fast to slow), or ease-out, provides immediate feedback that tapers off.  are less alarming if their curve is accelerated, moving from slow to fast, or what we call ease-in.  often look best with a more constant curve, but you could purposely buck that to express your aesthetic values. Most design systems benefit by specifying at least an ease-out, an ease-in, and a fade curve. Timing Easings are a high-visibility return on investment. But animation can’t happen without a duration. On the  , I worked with Amy Lee, who also happens to be a musician. In a brilliant example of genius occurring in the overlap of disparate fields, she came up with the concept of timing scales: a set of time values that align at various combinations. The concept is similar to  : all values are related, and if you combine them with a vertical rhythm, a piece exhibits overall harmony. You can generate a timing scale the same way you generate a typographic scale.  There are upper and lower limits. While  , it takes us between 70 and 700 milliseconds to move our eyes  . 200–300 millisecond values typically become the workhorses of a timing scale, from button depresses to secondary animations. (The persistence of this time range across game and web development is especially interesting in light of recent  ) Shorter durations work better for color changes and fades, which the human eye picks up readily. Longer durations are better for larger fields of change, like page transitions, or motions that occur over longer distances, like a drag-and-drop interaction or menu slide-out over a large screen. It’s a good idea to define durations in milliseconds rather than seconds. While most animation libraries can accept seconds and milliseconds, JavaScript timers and the Web Animations API take only milliseconds. Also, some people may find it easier to work with zeros than decimals (although that might be more of a tabs versus spaces argument). Properties Properties describe   is being animated. Currently in web animation, the most performant things to animate are opacity and transforms (scale, distance, rotation). But there will be times when we want to animate less performant things like color or—heaven forfend!—height. Browsers are working hard to improve their animation performance, so while it’s great to try to stick to transform and opacity, don’t be afraid to   where you can get away with it.  Knowing the properties we want to animate comes in handy when communicating animations with storyboards and specs and when we’re creating our project’s very own animation vocabulary. Creating an Animation Language We combine these three components—easing, timing, and properties—to create vocabularies of words like “pop,” “fade,” and “slide.” Many of these expressions start as friendly onomatopoeias:  ,  ,  ,  . And sometimes colleagues will, say, hold a sound longer to indicate extended duration: “Can you make it more like   and less like  ?” It makes sense to   and adopt words like these when constructing our own animation vocabularies. Vocabularies are granular. You can layer these microanimations to create macroanimations—for instance, a modal that fades onto the screen then pops to grab user attention. These words might seem arbitrary at first, but they yield huge benefits when it comes time to document our visual deliverables with text. Communicating Visually There are three ways to communicate animation: storyboards, animatics, and prototypes. All of them contain a visual component, but only storyboards include words. Words are one of the lowest common denominators of digital human information exchange—capable of being read out loud, indexed by search engines, translated by machines. In many cases these words are the key to conveying animation deliverables, so it makes sense to start with storyboards. Storyboards Disney Studios invented storyboards for working on feature-length animation films, and it wasn’t long before Hollywood started using them, too. Storyboards let disparate teams get an overview of a linear narrative. They reduce time spent on dead-end shots and help directors and writers visualize the final story, and edit it on the fly. These days, storyboards are used not only in cinema but also in game design and interaction development. These storyboards can range from very informal (on a small-team interaction-design project where everyone follows each stage of development closely) to very detailed and particular (for specifications and audits). One problem I have as a consultant is that I find it difficult to embed videos or GIFs in PDFs to hand to managers as a way of explaining where animation problems occur. So for long-term storage, I include a storyboard.  This storyboard was part of a motion-design audit for a large project where I needed to leave the client with actionables to include in their next sprint. Storyboards use words and illustrations to represent interactions and animations. Every animated interaction can be divided into a “before” shot and an “after” shot; it’s up to us to illustrate the in-between shot to demonstrate how we get from one to the other. Language helps us clarify why these changes are happening. Using words like this is a powerful thinking tool.  Storyboarding software, most of which is geared toward cinema, is simultaneously insufficient and overkill for web development collaboration. Teams often have more fun and collaborate better with good old index cards and Post-its. I’ve written about  , and you can download my   to get started. Animatics If a picture is worth a thousand words, an animation is worth ten thousand meetings. Storyboards, sadly, can’t show us how something “feels” on the screen or under the thumb. Once again, studio animation provides a solution in the form of animatics, videos of the storyboard set to an audio track that can be screen-tested with an audience or presented to investors as proof of progress. We can also make small videos or GIFs with our wireframes and storyboards that demonstrate how they work. Do not throw these mini videos over the fence to developers. Finalize animatics by combining them with the deliverables developers crave: easing, duration, and properties. At most, an animatic is a measuring stick against which we compare the final, implemented animation. And the two will only match 100 percent if we provide our developers with the inputs necessary to duplicate the original. For creating animatics, AfterEffects is the software of choice in the motion design industry. Web designers may be more accustomed to creating animatic-like demos in Keynote to be clicked through in meetings. These can be recorded with screencasting software like Quicktime or Camtasia. And some visual prototyping tools like   export to video, achieving two things at once. Prototypes Animatics can be screen-tested on an audience, but screen-testing works best for passive media. The web is interactive: people interact with designs, which in turn react to them. There’s no way to test these reactions with storyboards or videos. When we want to be sure of how people will respond to a design, we want prototypes. There are two approaches to prototypes: coded prototypes and prototyping software. Developers tend to prefer the former, often leaning on frameworks like   and  ; designers prefer the latter, in the form of software like Invision App and UX Pin. Both approaches require team members to invest time in learning a new system, thus increasing the commitment factor.  Most prototyping software with animation features, like   and Principle, is app-oriented. But the web is catching up with products like  , and web and native prototyping powerhouse   has demonstrated its commitment to improving animation tooling with its  . Coded prototypes, unlike storyboards, are terrible for documentation: only code-savvy team members can read them, and the files must be organized and sometimes compiled or served before inspection. An external agency would struggle to deliver a fully branded experience riffing off a pile of non-production code. Pick two If we rely on storyboards, animatics, or prototypes alone, we can’t hope to communicate animation clearly, effectively, or sustainably. But if we combine them, they work great: a demo next to a set of deliverables; a storyboard with a video. Such combinations work well for documentation and also sometimes for offering animation boilerplates. Animation as a team sport Many animation documents are created in the hopes that “if you write it, they will follow.” We hope our coworkers will read our sage advice and start preaching the animation gospel; we hope they’ll copy our animation deliverables perfectly for every button, gesture, and loading spinner. In practice, though, it’s extremely rare for even half of a team to care as passionately about animation as the person writing the docs. While education and guidelines are fantastic in principle, they are a wasted effort if no one cares. Here are some quick ways to get our teammates on board:  Having a documentation format that everyone can contribute to—and then having people contribute even just a few words—helps them feel like this is their baby, too.\n  I use these exercises in training to help get siloed teams collaborating. Take “before” and “after” wireframes, and give everyone index cards to brainstorm all the possible animations they could use in between those states to get from point A to point B.  Teams without motion and animation champions can’t sustain their animations over the long run. Someone has to grow the love for animation and make it second nature to think about it, same way we think about color or fonts. Otherwise, animation risks being sidelined the way accessibility and user testing often are. Many organizations assume an initial effort is sufficient to address what should become an integral part of their design process.  We should always be on the lookout for coconspirators. One champion isn’t enough. Eventually we all move on to other projects, and a healthy system is one that can function when one of its pieces goes missing.  Sometimes people just have to see the difference animation makes to believe it. You can ask for forgiveness later. A template library will need different documentation than, say, an interactive story app. What matters is clearly recording and communicating those deliverables and cultivating a concern for animation among our peers. People fear what they don’t understand, and they fear change. Education, communication, and collaboration turn that fear into enthusiasm and goodwill. There is no one right way to document animation. But when we collaborate with our teams, together we will find the right way forward. Don’t be the lone animation wolf; find or found an animation pack. Recruit other animation wonks from different areas like UX, front-end development, data visualization, design, and marketing. Diverse views will strengthen how we approach animation and help rally more support from other corners. Together, we can all find our own “way of animation” that works best for us. Like this: \n\t\t\t\t\t\t\tRecently by Rachel Nabors\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/why-arent-you-asking-questions/", "title": "Why Aren’t You Asking Questions?", "content": "It’s the kickoff meeting. You are the lead designer on the project, and this is the first meeting with everyone in the room. Your client is reciting her wish list, and you’re taking diligent notes—probably with cute, relatable doodles. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. An hour passes, and you’ve barely said a sentence. You’re nodding your head, scarcely making eye contact. You have some thoughts, but you aren’t speaking up. Why aren’t you speaking up? You’ve likely been burned in the past. Perhaps you’ve shared some ideas and they were turned down. You have felt embarrassed in meetings. Projects that you put your heart and soul into were changed at the last minute without your consultation or discarded, apparently without a second thought. Now, while it’s admirable to be an agreeable, easy-to-work-with colleague, being quiet and keeping your head down isn’t the answer because this is not a production line. You are a designer, and part of your job is contributing to the conversation. It’s a designer’s job to ask good questions You want to do your best work and meet your client’s needs, so playing an active role in the conversation is vital. To extract the most information you can from your client, you must ask questions. Lots of questions. Think of it like playing detective, gathering clues and working to understand the players in the game. Laura Kalbag  , “As designers, we can’t expect other people to know the right language to describe exactly why they think something doesn’t work. We need to know the right questions that prompt a client to give constructive criticism and valuable feedback.” They are looking to you as the professional to not only listen to their needs, but to also be able to identify and understand their   needs. It is not the client’s job to know exactly what their logo should be or how their website should function. That’s your job. They are coming to you to share ideas, to express concerns, likes, and dislikes. They are looking to you to help guide them to a solution. Clients will always ask you to make their logo bigger, prescribe solutions, and ask you to do things that will make you smack your forehead. You can roll your eyes at how much they don’t understand about design or you can roll up your sleeves and begin practicing your craft by helping them clarify what they need. First, understand the end users’ needs It’s pretty likely that your client isn’t the main user of the website or product you are designing. Even if they are amazing at articulating exactly their tastes and preferences, it’s beside the point because they are not the target audience. If you are fortunate enough to be on a project that dedicates resources to user research, familiarize yourself with its findings. If you do not have access to this information, ask a few questions about who the end user is and what their needs are to better understand the target audience you are actually designing for: Who exactly do you anticipate will be using this website? What problem is this website solving for them? Or What will they accomplish by using this website? What are their pain points? Once you establish who the end user is, try to phrase your upcoming questions in a way that encourages the client to see through the eyes of the end user, not their own. User experience consultant and writer Paul Boag simplifies this  : “A client’s natural inclination will be to give you his personal opinion on the design. This is reinforced because you ask them what   think of the design. Instead ask them what their users will think of the design.” It is also possible that the client thinks they understand what the end user needs, but they are only working from assumptions. This is apparent when sweeping generalizations and blanket statements are made. As Laura Kalbag  , “Throughout the design process, we need to check our hidden assumptions about our users. We should also ensure any feedback we get isn’t based upon an unfounded assumption. If the client says the users won’t like it, ask why. Uncover the assumption—maybe it’s worth testing with real users?” Establish attainable business goals This is a conversation that I still struggle with. A lot of companies are good at coming up with lofty business goals that can be interpreted into almost anything, and are usually difficult to measure. The conversation may start out up in the clouds, but by talking about business goals you are helping to break down assumptions, learn about your client’s current expectations, and set their expectations going forward. For example, if the assumption is that by redesigning their website they will generate more leads, you need to establish clear language around what that means and what success looks like to them. Daniel Ritzenthaler suggests   by using “a modified acceptance criteria exercise [to set] clear and powerful goals.” Ritzenthaler says, “Acceptance criteria for design is a great way to [flesh] out deeper, possibly unknown, intentions that will help the designer and project owner make better decisions and dodge surprises later in the process.” Make sure you are asking the right people The kickoff meeting is a great place to ask questions because, more than likely, the right people will be in the room. If you have any control over who is required to attend, make sure the meeting includes everyone who has decision-making power, is assumed to have power, or is an opinion leader inside the organization. I find that a lot gets lost in translation when a question filters up three levels of management and then trickles back down to you. When you hear information from the source, you get the original version and you also have the chance to ask for more clarity. If you are not sure who the key players are, here are a few preparatory questions you can ask to get that information: Who initiated this project? Who will have the final decision with this project? Who has the ability to cancel or postpone this project? Ask a lot of open-ended questions Once you understand who you are designing for, what the major goals are, and who the key players are, you will be ready to start discussing the details of the actual project. Avoid simple yes or no questions—stick with something open-ended so you will get more information. Ask any question that comes to mind that will help you better understand the issue at hand. Ask follow-up questions if there is something that still isn’t clear to you. You may have to ask the same question a few different ways before getting a response that gives you the information you’re looking for. Read between the lines In one person’s mind, “add more pictures” could mean a photo gallery of thumbnails at the bottom on the page. Another person might imagine this as the giant background image that they saw on someone else’s site and they want exactly what that person has. And yet a third person is picturing replacing most of the text on the page with infographics. Here’s an example: you are working on a web design and the client doesn’t think there are enough images on the mockup you provided. Ask: What value will adding more images provide? For whom? Are images available? Does a photographer need to be hired? If you find out their solution was to purchase stock photography, dig a little deeper. Is stock photography genuine enough for their audience? Will it convey the value they were hoping for? If a visitor to the website found out it was stock photography, would that affect their perception of the company? These are likely questions they have not yet thought through. By asking these questions, you are helping the client see the bigger picture and preserve the value of the brand or message. Try generic questions If you’re not sure what the right question is, you can keep it really simple by using one of the following go-to phrases: Why? Could you elaborate? Would you describe that for me? What does that look like to you? Make sure you are clear and concise. Do not muddy up your question with “ummm,” “er,” “like,” “whatever,” or “you know.” A clear question has a better chance of getting a clear answer. You’re going to annoy someone Truth is, it is possible that some people may get annoyed with the questions. Don’t let this deter you. It isn’t personal. You have a job to do and clues you need to gather. Explain why it is necessary that you truly understand the problem you are all here to solve together, and explain that in the long run it will likely save a lot of time. Thank them for their understanding and cooperation (even if they are being quite the opposite of cooperative). If a client appears frustrated or annoyed that you are asking so many questions, it may be because they thought they had it all figured out. You just made them realize that they haven’t even begun to figure it out. What was supposed to be a “quick” web design has become a bigger project, one that requires real thought and effort. They may feel frustrated that it won’t be the quick fix they initially expected. That’s not your fault! You’re doing the client a favor in the long run by ensuring that all parties are on the same page and making the best decisions together. Read the room If your client comes across as agitated by speaking more loudly, constantly interrupting, or suddenly becoming very short with responses, try to assess how you are coming off in this meeting. Are you talking more loudly or interrupting? Do you think he feels like his answers are being heard? In that scenario, taking a more laid-back approach by leaning back in your chair a little, speaking somewhat more slowly and softly, and relaxing your face may help the meeting move in a more productive direction. Test engagement You need your clients to be engaged to get the most information. If they are not making eye contact, not participating in the conversation, or are busy on their phones, they may not be engaged. By simply pausing and allowing silence, you may be able reengage the client. Or test their engagement by asking a couple of questions: Are we discussing what you had hoped we would? Is there anything we haven’t covered that you hoped we would? Take a break Stepping away for a few minutes can clear the mind and calm the nerves. A five-minute break will keep your client engaged by allowing them to check their emails, text, and get a few seconds of relief from their FOMO. Use this time to assess the situation and formulate your next questions. Play nice Don’t give the impression that you are trying to prove them wrong; this isn’t a pissing contest. Approach the conversation with genuine curiosity and a lot of empathy. You are both working toward the same goals here. When you ask a question, really take time to listen to the response. Do not interrupt. Be supportive as they give their answers and thank them for giving you the additional information. Don’t be afraid to use an awkward silence to your benefit. Chances are the client feels awkward, too, and will start talking, giving you even more information. Asking great questions takes practice. Lifehack has some tips worth reading on how to  . Your work reflects your level of understanding Until we have the ability to project images with our minds (why don’t we have this yet?), or unless your client is an amazing sketch artist, asking questions and piecing the clues together is our most effective tool to understand their expectations, and help them see the bigger picture along the way. If you leave the room without asking any questions, there is no way you can really understand what is being asked of you. You might annoy someone along the way, but your work will have so much more meaning and, in the end, your clients and their end users will see the added value in your work. Like this: \n\t\t\t\t\t\t\tRecently by Janice Gervais\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/help-we-think-we-need-to-hire-a-content-strategist/", "title": "Help! We (Think We) Need to Hire a Content Strategist", "content": "Those of us working in content strategy know that it is a rich and complicated discipline. We understand, of course, that there are different types of content strategists. But we need to remember that outside of our content strategy bubble, the discipline is still pretty new to colleagues and clients. As the discipline matures and more companies are looking to hire for content strategy, how can companies educate themselves on how to use our specific skills? Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I’ve recently been on the job market. And so I’ve spent a lot of time wading through content strategy job listings and meeting with hiring managers. My experience suggests that people beginning to actively hire content specialists frequently have little understanding of what their companies need beyond a title. I would even estimate that about half of my interviews over the past few months have consisted of talking through and refining job descriptions with those sitting across the table from me. Hiring managers at agencies, brands, and startups would do well to hire based on the   of work they want to focus on—not on a price tag or a title. Like experience design (which content strategy is sometimes folded into), content strategy has subspecialties. Some strategists veer more toward the UX side:  , content maps,  . Others specialize in PR and native advertising ( , influencer outreach, and content discovery); still others focus more on   and governance.  Some content strategists even overlap with digital strategists (considering the audience, conversion, and the larger digital ecosystem), but then also do some of the more tactical, executional work to bring these digital ecosystems to life. Others may specialize in search and organic growth. Increasingly, former journalists have started to position themselves as content strategists, using their expertise with long-form and mid-length content to cash in on the boom in native advertising work and branded content creation. And let’s not forget how industry and categories figure into the equation. For example, if you are an ecommerce brand hiring a content strategist for a website relaunch, you may want a content strategist with past experience in ecommerce working on your site, given your specific conversion challenges. Similarly, for highly regulated spaces like financial services, healthcare, or alcohol, a content strategist with past experience navigating these categories makes sense.  If you don’t practice content strategy, talk to someone who does For any company trying to make their first content-strategy hire, the most logical place to start is talking with a real live content strategist. I don’t mean that you should reach out to a content strategist on the pretense that this is a position for them and then use an interview to pick their brain (and waste their time). For starters, that’s not very nice; furthermore, you don’t want anyone spreading the word that your company doesn’t know what it’s doing and may not be the best place to work.  No, I mean that you should formally engage a content strategist as a consultant. Have them talk to your team, take a look at your business, help write up an accurate job description, and even start recruiting through their network for the specific position you seek to fill. Chances are they know a lot of good people in their community who would be a perfect fit for the role. Too often, I’ve seen job descriptions written by someone who is obviously not a content strategist and interviews conducted by people who don’t really understand the discipline. This is likely because, depending on the organization and the kind of content strategy work you do, your role could easily sit in Strategy, Creative, UX, Product, Communications, or PR. And if you’re a content strategist more focused on measurement and SEO, a case could even be made for Analytics. While I understand why this occurs, it ultimately means that the candidates won’t be as strong as they could be. For companies that already have a content strategist or two on staff, it makes sense to engage them as well, even if they’re in a different location or less senior than the role for which you are currently hiring. I guarantee that the kind of feedback they give you will be invaluable.  Don’t look for “unicorns” Banish the word “unicorn” from your vocabulary—along with, for that matter, “rock star,” “ninja,” and any other ridiculous buzzword of the moment. I’ve worked in the content sphere long enough to know my own strengths and weaknesses. For example, while I’ve certainly worked on content strategy projects that required information architecture, metadata, and taxonomy expertise, I know that my sweet spot lies more in editorial strategy. I’ve learned to position myself accordingly. Unfortunately, today’s job market sometimes views such candor as a weakness. Ours is a culture that rewards confidence. Indeed, a survey of over 400,000 hiring professionals revealed that confidence is one of the   that employers say they are looking for in new hires. This is particularly true in the tech space, where much has recently been made of the   and how it negatively impacts women. As a result, during the hiring process, people can feel pressured to claim that they can “do it all” just to nail down the job. And when a hiring manager doesn’t fully understand what they are hiring for, compulsory confidence can be especially problematic. The thing is, as a hiring manager, you should be skeptical of anyone who claims to do it all. Someone with over five years of experience who says they can do both structural content strategy and editorial content strategy equally well is likely inflating the truth. And while there may be a tiny constellation of people out there who really can do everything, it probably won’t be for the $60 per hour you are offering. Be realistic when you hire. Remember, you aren’t hiring for sales or new business; you’re hiring to get a job done. Don’t fall for the slickest kid in the room—you may find yourself with a mess on your hands.  Ask to see deliverables As you decide to move forward in the process with a candidate you’ve vetted, rather than giving them a test or a lengthy spec-work presentation, a great way to see if they’re up to the task is to request a package of some of their past deliverables. Here are some deliverables to look for based on the type of content strategist you are hiring for: : content audit, comparative audit, content matrix, editorial guidelines : taxonomy and metadata recommendations, content models, site maps, workflow recommendations : editorial calendars, voice and tone outputs, content briefs : social editorial calendars, examples of social content, measurement reports : SEO recommendations, analytics audit Where do we go from here? Knowing that you “need” content strategy at your company is one thing; hiring   to suit your needs and goals is another. Stop wasting your and your prospective hires’ time. Ask an expert for help, stay realistic about your hires, and request the appropriate deliverables. Making an informed decision about whom you bring on board will set you and your team up for success. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/never-show-a-design-you-havent-tested-on-users/", "title": "Never Show A Design You Haven’t Tested On Users", "content": "It isn’t hard to find a UX designer to nag you about testing your designs with actual users. The problem is, we’re not very good at explaining   you should do user testing (or how to find the time). We say it like it’s some accepted, self-explanatory truth that deep down, any decent human knows is the right thing to do. Like “be a good person” or “be kind to animals.” Of course, if it was that self-evident, there would be a lot more user testing in this world. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Let me be very specific about why user testing is essential. As long as you’re in the web business, your work will be exposed to users. If you’re already a user-testing advocate, that may seem obvious, but we often miss something that’s not as clear: how user testing impacts stakeholder communication and how we can ensure testing is built into projects, even when it seems impossible. The most devilish usability issues are those that haven’t even occurred to you as potential problems; you won’t find all the usability issues just by looking at your design. User testing is a way to be there when it happens, to make sure the stuff you created actually works as you intended, because best practices and common sense will get you only so far. You need to test if you want to innovate, otherwise, it’s difficult to know whether people will get it. Or want it. It’s how you find out whether you’ve created something truly intuitive. How testing up front saves the day Last fall, I was going to meet with one of our longtime clients, the charity and NGO Plan International Norway. We had an idea for a very different sign-up form than the one they were using. What they already had worked quite well, so any reasonable client would be a little skeptical. Why fix it if it isn’t broken, right? Preparing for the meeting, we realized our idea could be voted down before we had the chance to try it out. We decided to quickly put together a usability test before we showed the design. At the meeting, we began by presenting the results of the user test rather than the design itself. We discussed what worked well, and what needed further improvement. The conversation that followed was rational and constructive. Together, we and our partners at Plan discussed different ways of improving the first design, rather than nitpicking details that weren’t an issue in the test. It turned out to be one of the best client meetings I’ve ever had. User testing gives focus to stakeholder feedback Naturally, stakeholders in any project feel responsible for the end result and want to discuss suggestions, solutions, and any concerns about your design. By testing the design beforehand, you can focus on the real issues at hand. Don’t worry about walking into your client meeting with a few unsolved problems. You don’t need to have a solution for every user-identified issue. The goal is to show your design, make clear what you think needs fixing, and ideally, bring a new test of the improved design to the next meeting. By testing and explaining the problems you’ve found, stakeholders can be included in suggesting solutions, rather than hypothesizing about what might be problems. This also means that they can focus on what they know and are good at. How will this work with our CRM system? Will we be able to combine this approach with our annual campaign? Since last fall, I’ve been applying this dogma in all the work that I do: never show a design you haven’t tested. We’ve reversed the agenda to present results first, then a detailed walkthrough of the design. So far, our conversations about design and UX have become a lot more productive. Making room for user testing: sell it like you mean it Okay, so it’s a good idea to test. But what if the client won’t buy it or the project owner won’t give you the resources? User testing can be a hard sell—I know this from experience. Here are four ways to move past objections. Don’t make it optional It’s not unusual to look at the total sum in a proposal, and go,  .  So what typically happens? Things that don’t seem essential get trimmed. That usability lab test becomes optional, and we convince ourselves that we’ll somehow persuade the client later that the usability test is actually important. But how do you convince them that something you made optional a couple of months ago is now really important? The client will likely feel that we’re trying to sell them something they don’t really need. Describe the objective, not the procedure A usability lab test with five people often produces valuable—but costly—insight. It also requires resources that don’t go into the test itself: e.g., recruiting and rewarding test subjects, rigging your lab and observation room, making sure the observers from the client are well taken care of (you can’t do that if you’re the one moderating the test), and so on. Today, rather than putting “usability lab test with five people” in the proposal, I’ll dedicate a few days to: “Quality assurance and testing: We’ll use the methods we deem most suitable at different stages of the process (e.g., usability lab test, guerilla testing, click tests, pluralistic walkthroughs, etc.) to make sure we get it right.” I have never had a client ask me to scale down the “get it right” part. And even if they do ask you to scale it down, you can still pull it off if you follow the next steps. Scale down documentation—not the testing If you think testing takes too much time, it might be because you spend too much time documenting the test. In a lab test, it’s a good idea to have 20 to 30 minutes between each test subject. This gives you time to summarize (and maybe even fix) the things you found in each test before you move on to the next subject. By the end of the day, you have a to-do list. No need to document it any more than that. I’ve also found InVision’s comment mode useful for documenting issues discovered in the tests. If we have an HTML and CSS prototype, screenshots of the relevant pages can be added to InVision, with comments placed on top of the specific issues. This also makes it easy for the client to contribute to the discussion. Scale down the prototype—not the testing You don’t need a full-featured website or a polished prototype to begin testing. If you’re testing text, you really  . If you’re testing a form, you just need to prototype the form. If you wonder if something looks clickable, a flat Photoshop sketch will do. Even a paper sketch will work to see if you’re on the right track. And if you test at this early stage, you’ll waste much less time later on. Low-cost, low-effort techniques to get you started You can do this. Now, I’m going to show you some very specific ways you can test, and some examples from projects I’ve worked on. Pluralistic walkthrough Time: 15 minutes and up Costs: Free A   is UX jargon for asking experts to go through the design and point out potential usability issues. But putting five experts in a room for an hour is expensive (and takes time to schedule). Fortunately, getting them in the same room isn’t always necessary. At the start of a project, I put sketches or screenshots into InVision and post it in our Slack channels and other internal social media. I then ask my colleagues to spend a couple of minutes critiquing it. As easy as that, you’ll be able to weed out (or create hypotheses about) the biggest issues in your design. Hit the streets Time: 1–3 hours Costs: Snacks This is a technique that works well if there’s something specific you want to test. If you’re shy, take a deep breath and get over it. This is by far the most effective way of usability testing if you’re short on resources. In the Labour Party project, we were able to test with seven people and summarize our findings within two hours. Here’s how: Online testing tools Time: 30 minutes and up Costs: Most tools have limited free versions. Optimal Workshop charges $149 for one survey and has a yearly plan for $1990. There isn’t any digital testing tool that can provide the kind of insight you get from meeting real users face-to-face. Nevertheless, digital tools are a great way of going deeper into specific themes to see if you can corroborate and triangulate the data from your usability test. There are many tools out there, but my two favorites are Treejack and Chalkmark from Optimal Workshop. With  , it rarely takes more than an hour to figure out whether your menus and information architecture are completely off or not. With click tests like  , you can quickly get a feel for whether people understand what’s clickable or not. Using existing audience for experiments Time: 30 minutes and up Costs: Free (e.g., using Hotjar and Google Analytics). One of the things we designed for Plan was longform article pages, binding together a compelling story of text, images, and video. It struck us that these wouldn’t really fit in a usability test. What would the task be? Read the article? And what were the relevant criteria? Time spent? How far he or she scrolled? But what if the person recruited to the test wasn’t interested in the subject? How would we know if it was the design or the story that was the problem, if the person didn’t act as we hoped? Since we had used actual content and photos (no  !), we figured that users wouldn’t notice the difference between a prototype and the actual website. What if we could somehow see whether people actually read the article when they stumbled upon it in its natural context? The solution was for Plan to share the link to the prototyped article as if it were a regular link to their website, not mentioning that it was a prototype. The prototype was set up with   and  . In addition, we had the stats from Facebook Insights. This allowed us to see whether people clicked the link, how much time they spent on the page, how far they scrolled, what they clicked, and even what they did on Plan’s main site if they came from the prototyped article. From this we could surmise that there was no indication of visual barriers (e.g., a big photo making the user think the page was finished), and that the real challenge was actually getting people to click the link in the first place. Did you get it done? Was this useful? Time: A few days or a week to set up, but basically no time spent after that Costs: No cost if you build your own; Task Analytics from $950 a month Sometimes you need harder, bigger numbers to be convincing. This often leads people to A/B testing or Google Analytics, but unless what you’re looking for is increasing a very specific conversion, even these tools can come up short. Often you’d gain more insight looking for something of a middle ground between the pure quantitative data provided by tools like Google Analytics, and the qualitative data of usability tests. “Was it helpful?” modules are one of those middle-ground options I try to implement in almost all of my projects. Using tools like Google Tag Manager, you can even combine the data, letting you see the pages that have the most “yes” and “no” votes on different parts of your website (content governance dream come true, right?). But the qualitative feedback is also incredibly valuable for suggesting specific things your design is lacking. This technique falls short if your users weren’t able to find a relevant article. Those folks aren’t going to leave feedback—they’re going to leave. Google Analytics isn’t of much help there, either. That high bounce rate? In most cases you can only guess why. Did they come and go because they found their answer straight away, or because the page was a total miss? Did they spend a lot of time on the page because it was interesting, or because it was impossible to understand? My clever colleagues made a tool to answer those kinds of questions. When we do a redesign, we run a Task Analytics survey both before and after launch to figure out not only what the   are, but whether or not people were able to complete their task. When the user arrives, they’re asked if they want to help out. Then they’re asked to do whatever they came for and let us know when they’re done. When they’re done, we ask a) “What task did you come to do?” and b) “Did you complete the task?” This gives us data that is actionable and easily understood by stakeholders. At our own website, the most common task people arrive for is to contact an employee, and we learned that one in five will fail. We can fix that. And afterward, we can measure whether or not our fix really worked. Set up a usability lab and have a weekly drop-in test day Time: 6 hours per project tested + time spent observing the test Costs: rewarding subjects + the minimal costs of setting up a lab Setting up a usability lab is basically free in 2016: A modern laptop has a microphone and camera built in. No need to buy that. Want to test on mobile?   or  Numerous screensharing and video conference tools like Skype, Google Hangout, and GoToMeeting mean there’s no need for hefty audiovisual equipment or mirror windows. Even   is becoming affordable Other than that, you just need a room that’s big enough for you and a user. So even as a UX team of one, you can afford your own usability lab. Setting up a weekly drop-in test makes sense for bigger teams. If you’re at twenty people or more, I’d bet it would be a positive return on investment. My ingenious colleague Are Halland is responsible for the test each week. He does the recruiting, the lab setup, and the moderating. Each test day consists of tests with four different people, and each person typically gets tasks from two to three different projects that Netlife is currently working on. (Read up on  .) By testing two to three projects at a time and having the same person organize it, we can cut down on the time spent preparing and executing the test without cutting out the actual testing. As a consultant, all I have to do is to let Are know a few days in advance that I need to test something. Usually, I will send a link to the live stream of the test to clients to let them know we’re testing and that they’re welcome to pop in and take a look. A bonus is that clients find it surprisingly rewarding to see other client’s tests and getting other client’s views on their own design (we don’t put competitors in the same test). This has made it a lot easier to test work on short notice, and it has also reduced the time we have to spend on planning and executing tests. Testing   designing As I hope I’ve demonstrated, user testing doesn’t have to be expensive or time-consuming. So what stops us? Personally, I’ve met two big hurdles: building testing into projects to begin with and making a habit out of doing the work. The critical first step is to make sure that some sort of user testing is part of the approved project plan. A project manager will look at the proposal and make sure we tick that off the list. Eventually, maybe your clients will come asking for it: “But wasn’t there supposed to be some testing in this project?”. Second, you don’t have to ask for anyone’s permission to test. User testing improves not only the quality of our work, but also the communication within teams and with stakeholders. If you’re tasked with designing something, even if you have just a few days to do it, treat testing as a part of that design task. I’ve suggested a couple of ways to do that, even with limited time and funds, and I hope you’ll share even more tips, tricks, and tools in the comments. Like this: \n\t\t\t\t\t\t\tRecently by Ida Aalen\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-rich-typefaces-get-richer/", "title": "The Rich (Typefaces) Get Richer", "content": "There are over 1,200 font families available on  . Anyone with a Typekit plan can freely use any of those typefaces, and yet we see the same small selection used absolutely everywhere on the web. Ever wonder why? Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The same phenomenon happens with other font services like   and  . Google Fonts offers 708 font families, but we can’t browse the web for 15 minutes without encountering Open Sans and Lato. MyFonts has over 20,000 families available as web fonts,  . On my side project  , I curate daily examples of nice type in the wild. Here are the   from 2015: And here are the ten most popular from 2014: Notice any similarities? Nine out of the ten fonts from 2014 made the top ten again in 2015. Admittedly, Typewolf is a curated showcase, so there is bound to be some bias in the site selection process. But with 365 sites featured in a year, I think Typewolf is a solid representation of what is popular in the design community. Other lists of popular fonts  . Or simply look around the web and take a peek at the CSS—Proxima Nova, Futura, and Brandon Grotesque dominate sites today. And these fonts aren’t just a   more popular than other fonts—they are   more popular. When it comes to typefaces, the rich get richer I don’t mean to imply that type designers are getting rich like Fortune 500 CEOs and flying around to type conferences in their private Learjets (although some type designers are certainly doing quite well). I’m just pointing out that a tiny percentage of fonts get the lion’s share of usage and that these “chosen few” continue to become even more popular. The   (also known as the  ) refers to something that grows in popularity due to a positive feedback loop. An app that reaches number one in the App Store will receive press because it is number one, which in turn will give it even more downloads and even more press. Popularity breeds popularity. For a cogent book that discusses this topic much more eloquently than I ever could, check out Nicholas Taleb’s  . But back to typefaces. Designers tend to copy other designers. There’s nothing wrong with that—designers should certainly try to build upon the best practices of others. And they shouldn’t be culturally isolated and unaware of current trends. But designers also shouldn’t just mimic everything they see without putting thought into what they are doing. Unfortunately, I think this is what often happens with typeface selection. How does a typeface first become popular, anyway? I think it all begins with a forward-thinking designer who takes a chance on a new typeface. She uses it in a design that goes on to garner a lot of attention. Maybe it wins an award and is featured prominently in the design community. Another designer sees it and thinks, “Wow, I’ve never seen that typeface before—I should try using it for something.” From there it just cascades into more and more designers using this “new” typeface. But with each use, less and less thought goes into why they are choosing that particular typeface. In the end, it’s just copying. Or, a typeface initially becomes popular simply from being in the right place at the right time. When you hear stories about famous YouTubers, there is one thing almost all of them have in common: they got in early. Before the market is saturated, there’s a much greater chance of standing out; your popularity is much more likely to snowball. A few of the most popular typefaces on the web, such as Proxima Nova and Brandon Grotesque, tell a similar story. The typeface Gotham skyrocketed in popularity after its use in Obama’s 2008 presidential campaign. But although it gained enormous steam in the print world, it wasn’t available as a web font until 2013, when the company then known as Hoefler & Frere-Jones launched its subscription web font service. Proxima Nova, a typeface with a similar look, became available as a web font early, when Typekit launched in 2009. Proxima Nova is far from a Gotham knockoff—an early version, Proxima Sans, was  —but the two typefaces share a related, geometric aesthetic. Many corporate identities used Gotham, so when it came time to bring that identity to the web, Proxima Nova was the closest available option. This pushed Proxima Nova to the top of the bestseller charts, where it remains to this day. Brandon Grotesque probably gained traction for similar reasons. It has quite a bit in common with Neutraface, a typeface that is ubiquitous in the offline world—walk into any bookstore and you’ll see it everywhere. Brandon Grotesque was available early on as a web font with simple licensing, whereas Neutraface was not. If you wanted an art-deco-inspired geometric sans serif with a small x-height for your website, Brandon Grotesque was the obvious choice. It beat Neutraface to market on the web and is now one of the most sought-after web fonts. Once a typeface reaches a certain level of popularity, it seems likely that a psychological phenomenon known as the   kicks in. According to the availability heuristic, people place much more importance on things that they are easily able to recall. So if a certain typeface immediately comes to mind, then people assume it must be the best option. For example, Proxima Nova is often thought of as incredibly readable for a sans serif due to its large x-height, low stroke contrast, open apertures, and large counters. And indeed, it works very well for setting body copy. However, there are many other sans serifs that fit that description—Avenir, FF Mark, Gibson, Texta, Averta, Museo Sans, Sofia, Lasiver, and Filson, to name a few. There’s nothing magical about Proxima Nova that makes it more readable than similar typefaces; it’s simply the first one that comes to mind for many designers, so they can’t help but assume it must be the best. On top of that, the   suggests that people tend to prefer things simply because they are more familiar with them—the more someone encounters Proxima Nova, the more appealing they tend to find it. So if we are stuck in a positive feedback loop where popular fonts keep becoming even more popular, how do we break the cycle? There are a few things designers can do. Strive to make your brand identifiable by just your body text Even if it’s just something subtle, aim to make the type on your site unique in some way. If a reader can tell they are interacting with your brand solely by looking at the body of an article, then you are doing it right. This doesn’t mean that you should completely lose control and use type just for the sole purpose of standing out. Good type, some say, should be  . (Some say  .) Show restraint and discernment. There are many small things you can do to make your type distinctive.  Besides going with a lesser-used typeface for your body text, you can try combining two typefaces (or perhaps three, if you’re feeling frisky) in a unique way. Headlines, dates, bylines, intros, subheads, captions, pull quotes, and block quotes all offer ample opportunity for experimentation. Try using heavier and lighter weights, italics and all-caps. Using color is another option. A subtle background color or a contrasting subhead color can go a long way in making your type memorable. Don’t make your site look like a generic website template. Be a brand. Dig deeper on Typekit There are many other high-quality typefaces available on Typekit besides Proxima Nova and Brandon Grotesque. Spend some time browsing through their library and try experimenting with different options in your mockups. The free plan that comes with your Adobe Creative Cloud subscription gives you access to every single font in their library, so you have no excuse not to at least try to discover something that not everyone else is using. A good tip is to start with a designer or foundry you like and then explore other typefaces in their catalog. For example, if you’re a fan of the popular slab serif Adelle from TypeTogether, simply click the name of their foundry and you’ll discover gems like Maiola and Karmina Sans. Don’t be afraid to try something that you haven’t seen used before. Dig deeper on Google Fonts (but not too deep) As of this writing, there are 708 font families available for free on Google Fonts. There are   really great choices. And then there are many, many more not-so-great choices that   and that are plagued by poor kerning. So, while you should be wary of digging too deep on Google Fonts, there are definitely some less frequently used options, such as Alegreya and Fira Sans, that can hold their own against any commercial font. I fully support the open-source nature of Google Fonts and think that making good type accessible to the world for free is a noble mission. As time goes by, though, the good fonts available on Google Fonts will simply become the next Times New Romans and Arials—fonts that have become so overused that they feel like mindless defaults. So if you rely on Google Fonts, there will always be a limit to how unique and distinctive your brand can be.  Try another web font service such as Fonts.com, Cloud.typography or Webtype It may have a great selection, but Typekit certainly doesn’t have everything. The   library dwarfs the Typekit library, with over 40,000 fonts available.  .’s high-quality collection of typefaces is only available through their Cloud.typography service. And   offers selections not available on other services. Self-host fonts from MyFonts, FontShop or Fontspring Don’t be afraid to self-host web fonts. Serving fonts from your own website really isn’t that difficult and  . I self-host fonts on Typewolf and my   scores are 90/100 for mobile and 97/100 for desktop—not bad for an image-heavy site. ,  , and   all offer self-hosting kits that are surprisingly easy to set up. Self-hosting also offers the added benefit of not having to rely on a third-party service that could potentially go down (and take your beautiful typography with it). Explore indie foundries Many small and/or independent foundries don’t make their fonts available through the major distributors, instead choosing to offer licensing directly through their own sites. In most cases, self-hosting is the only available option. But again, self-hosting isn’t difficult and most foundries will provide you with all the sample code you need to get up and running. Here are some great places to start, in no particular order: What about Massimo Vignelli? Before I wrap this up, I think it’s worth briefly discussing famed designer Massimo Vignelli’s infamous  . John Boardley of I Love Typography has written  . The main points are that humans have a constant desire for improvement and refinement; we will always need new typefaces, not just so that brands can differentiate themselves from competitors, but to meet the ever-shifting demands of new technologies. And a limited variety of type would create a very bland world.  No doubt there were those in the 16th century who shared Vignelli’s views. Every age is populated by those who think we’ve reached the apogee of progress… Vignelli’s beloved Helvetica, . . . would never have existed but for our desire to do better, to progress, to create. Are web fonts the best choice for every website? Not necessarily. There are some instances where accessibility and site speed considerations may trump branding—in that case, it may be best just to go with system fonts. Georgia is still a pretty great typeface, and so are   likes San Francisco, Roboto/Noto, and Segoe. But if you’re working on a project where branding is important, don’t ignore the importance of type. We’re bombarded by  ; having a distinctive brand is more critical than ever. 90 percent of design is typography. And the other 90 percent is whitespace. As designers, ask yourselves: “Is this truly the best typeface for my project? Or am I just using it to be safe, or out of laziness? Will it make my brand memorable, or will my site blend in with every other site out there?” The choice is yours. Dig deep, push your boundaries, and experiment. There are thousands of beautiful and functional typefaces out there—go use them! Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/once-upon-a-time/", "title": "Once Upon a Time", "content": "Once upon a time, I had a coworker named Bob who, when he needed help, would start the conversation in the middle and work to both ends. My phone would ring, and the first thing I heard was: “Hey, so, we need the spreadsheets on Tuesday so that Information Security can have them back to us in time for the estimates.” Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Spreadsheets? Estimates? Bob and I had never discussed either. As I had been “discouraged” from responding with “What the hell are you talking about now?” I spent the next 10 minutes of every Bob call trying to tease out the context of his proclamations. Clearly, Bob needed help—and not just with spreadsheets. Then there was Susan. When Susan wanted help, she gave me the entire life story of a project in the most polite, professional language possible. An email from Susan might go like this: Good morning, I’m working on the Super Bananas project, which we started three weeks ago and have been slowly working on since. We began with persona writing, then did some scenarios, and discussed a survey. I’m hoping—if you have the opportunity (due to your previous experience with [insert four of my last projects in chronological order])—you may be able to share a content-inventory template that would be appropriate for this project. If it isn’t too much trouble, when you get a chance, could you forward me the template at your earliest convenience?\n Thank you in advance for your cooperation, Susan An email that said, “Hey do you have a content-inventory template I could use on the Super Bananas Project?” would have sufficed, but Susan wanted to be professional. She believed that if I had to ask a question, she had failed to communicate properly. And, of course, that failure would weigh heavy on all our heads. Bob and Susan were as opposite as the tortoise and the hare, but they shared a common problem. Neither could get over the river and through the woods effectively. Specifically, they were both lousy at establishing context and getting to the point. We all need the help of others to build effective tools and applications. Communication skills are so critical to that endeavor that we’ve seen article after article after article—not to mention books, training classes, and job postings—stressing the importance of communication skills. Without the ability to communicate, we can neither build things right, nor build the right things, for our clients and our users.  Still, context-setting is a tricky skill to learn. Stray too far toward Bob, and no one knows what we’re talking about. Follow Susan’s example, and people get bored and wander off before we get to the point.  Whether we’re asking a colleague for help or nudging an end user to take action, we want them to respond a certain way. And whether we’re writing a radio ad, publishing a blog post, writing an email, or calling a colleague, we have to set the proper level of context to get the result we want. The most effective technique I’ve found for beginners is a process I call “Once Upon a Time.” Fairy tales? Seriously? Fairy tales are one of our oldest forms of folklore, with evidence indicating that they may stretch back to the Roman Empire. The prelude “Once upon a time” dates to 1380 BCE, according to the  . Wikipedia lists over 75 language variations of the stock story opener. It’s safe to say that the vast majority of us, regardless of language or culture, have heard our share of fairy tales, from the 1800s-era Brothers Grimm stories to the 1987 musical  . We know how they go:  Once upon a time, there was a [main character] living in [this situation] who [had this problem]. [Some person] knows of this need and sends the [main character] out to [complete these steps]. They [do things] but it’s really hard because [insert challenges]. They overcome [list of challenges], and everyone lives happily ever after. Fairy tales are effective oral storytelling techniques precisely because they follow a standard structure that always provides enough context to understand the story. Almost everything we do can be described with this structure.  Once upon a time Anne lacked an ice cream sandwich. This forced her to get off the couch and go to the freezer, where food stayed amazingly cold. She was forced to put her hands in the icy freezer to dig the ice cream sandwich box out of the back. She overcame the cold and was rewarded with a tasty ice cream sandwich! And they all lived happily ever after. The structure of a fairy tale’s beginning has a lot of similarities to the journalistic Five Ws of basic information gathering:  In our communication construct, we are the main character whose situation and problem need to be succinctly described. We’ve been sent out to do a thing, we’ve hit a challenge, and now we need specific help to overcome the challenge. How does this help me if I’m a Bob or a Susan? When Bob wanted to tell his story, he didn’t start with “Once upon a time…” He started halfway through the story. If Bob was Little Red Riding Hood, he would have started by saying, “We need scissors and some rocks.” (Side note: the general lack of knowledge about how surgery works in that particular tale gives me chills.) When Susan wanted to tell her story, she started   “Once upon a time…” If she was Little Red Riding Hood, she started by telling you how her parents met, how long they dated, and so on, before finally getting around to mentioning that she was trapped in a wolf’s stomach.  When we tell our stories, we have to start at the beginning—not too early, not too late. If we’re Bob, that means making sure we’ve relayed the basic facts: who we are, what our goal is, possibly who sent us, and what our challenge is. If we’re Susan, we need to make sure we limit ourselves to the facts we actually need.  This is where we take the fairy-tale format and put it into the first person. Susan might write: Once upon a time, the Bananas team asked me to do the content strategy for their project. We made good progress until we had this problem: we don’t have a template for content inventories. Bob suggested I contact you. Do you have a template you can send us? Bob might say: Once upon a time, you and I were working on the data mapping of the new Information Security application. Then Information Security asked us to send the mapping to them so they could validate it. This is a problem because we only have until Tuesday to give them the unfinished spreadsheets. Otherwise we’ll hit an even bigger problem: we won’t be able to estimate the project size on Friday without the spreadsheet. Can you help me get the spreadsheet to them on time? Notice the parallels between the fairy tales and these drafts: we know the main character, their situation, who sent them or triggered their move, and what they need to solve their problem. In Bob’s case, this is much more information than he usually provides. In Susan’s, it’s probably much less. In both cases, we’ve distilled the situation and the request down to the basics. In both cases, the only edit needed is to remove “Once upon a time…” from the first sentence, and it’s ready to go. But what about…? Both the Bobs and the Susans I’ve worked with have had questions about this technique, especially since in both cases they thought they were already doing a pretty good job of providing context.  The original Susan had two big concerns that led her to giving out too much information. The first was that she’d sound unprofessional if she didn’t include every last detail and nuance of business etiquette. The second was that if her recipient had questions, they’d consider her amateurish for not providing every bit of information up front.  Susans of the world, let me assure you: clear, concise communication is professional. The message isn’t not to use “please” and “thank you”; it’s that “If it isn’t too much trouble, when you get a chance, could you please consider…” is probably overkill. Beyond that, no one can anticipate every question another person might have. Clear communication starts a dialogue by covering the basics and inviting questions. It also saves time; you only have to answer the questions your colleague or reader actually have. If you’re not sure whether to keep a piece of information in your story, take it out and see if the tale still makes sense. Bob was a tougher nut to crack, in part because he frequently didn’t realize he was starting in the middle. Bob was genuinely baffled that colleagues hadn’t read his mind to know what he was talking about. He thought he just needed the answer to one “quick” question. Once he was made aware that he was confusing—and sometimes annoying—coworkers, he could be brought back on track with gentle suggestions. “Okay Bob, let’s start over. Once upon a time you were…?” Begin at the beginning and stop at the end Using the age-old format of “Once upon a time…” gives us an incredibly sturdy framework to use for requesting action from people. We provide all of the context they need to understand our request, as well as a clear and concise description of that request.  Clear, concise, contextual communication is professional, efficient, and much less frustrating to everyone involved, so it pays to build good habits, even if the basis of those habits seems a bit corny.  Do you really need to start with “Once upon a time…” to tell a story or communicate a request? Well, it doesn’t hurt. The phrase is really a marker that you’re changing the way you think about your writing, for whom you’re writing it, and what you expect to gain. Soup doesn’t require stones, and business communication doesn’t require “Once upon a time…”  But it does lead to more satisfying endings. And they all lived happily ever after. Like this: \n\t\t\t\t\t\t\tRecently by anne gibson\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/commit-to-contribute/", "title": "Commit to Contribute", "content": "One morning I found a little time to work on   and saw a new pull request that fixed a small bug. The only problem with the pull request was that it didn’t have tests and didn’t follow the contributing guidelines, which results in the automated deploy not running. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. The contributor was obviously extremely new to Git and GitHub and just the small change was well out of their comfort zone, so when I asked for the changes to adhere to the way the project works, it all kind of fell apart. How do I change this? How do I make it easier and more welcoming for outside developers to contribute? How do I make sure contributors don’t feel like they’re being asked to do more than necessary? This last point is important. The real cost of a one-line change Many times in my own code, I’ve made a single-line change that could be a matter of a few characters, and this alone fixes an issue. Except that’s never enough. (In fact, there’s usually a correlation between the maturity and/or age of the project and the amount of additional work to complete the change due to the growing complexity of systems over time.) A recent issue in my   work was fixed with this single line change: In this particular example, I had solved the problem in my head very quickly and realized that this was the fix. Except that I had to then write the test to support the change, not only to prove that it works but to prevent   in the future. My projects (and Snyk’s) all use   to automate releases by commit message. In this particular case, I had to bump the dependencies in the Snyk command line and then commit that with the right message format to ensure a release would inherit the fix. All in all, the one-line fix turned into this: one line, one new test, tested across four versions of node, bump dependencies in a secondary project, ensure commit messages were right, and then wait for the secondary project’s tests to all pass before it was automatically published. Put simply: it’s never   a one-line fix. Helping those first pull requests Doing a   ( ) into another project can be pretty daunting. I’ve got a fair amount of experience and even I’ve started and aborted pull requests because I found the chain of events leading up to a complete   too complex. So how can I change my projects and GitHub repositories to be more welcoming to new contributors and, most important, how can I make that first   easy and safe? Issue and pull request templates GitHub recently announced support for  . These are a great start because now I can specifically ask for items to be checked off, or information to be filled out to help diagnose issues. Here’s what the PR template looks like for Snyk’s   ( ) : This is partly based on  . These items are not hard prerequisites on the actual  , but it does help in getting full information. I’m slowly adding these to all my repos. In addition, having a CONTRIBUTING.md file in the root of the repo (or in .github) means new issues and   include the notice in the header: Automated checks For context:   will read the commits in a push to master, and if there’s a   commit, it’ll do a minor version bump. If there’s a   it’ll do a patch version bump. If the text   appears in the body of a commit, it’ll do a major version bump. I’ve been using semantic release in all of my projects. As long as the commit message format is right, there’s no work involved in creating a release, and no work in deciding   the version is going to be. Something that none of my repos historically had was the ability to validate contributed commits for formatting. In reality, semantic release doesn’t mind if you don’t follow the commit format; they’re simply ignored and don’t drive releases (to npm). I’ve since come across  , which will run commands on Git hooks, in particular using a   hook  . The installation is relatively straightforward, and the feedback to the user is really good because if the commit needs tweaking to follow the commit format, I can include examples and links. Here’s what it looks like on the command line: …and in the GitHub desktop app (for comparison): This is work that I can load on myself to make contributing easier, which in turn makes my job easier when it comes to managing and merging contributions into the project. In addition, for my projects, I’m also adding a   hook that runs all the tests before the push to GitHub is allowed. That way if new code has broken the tests, the author is aware. To see the changes required to get the output above, see   in my current tinker project. There are two further areas worth investigating. The first is the  project. Second, what I’d   like to see is a GitHub bot that could automatically comment on pull requests to say whether the commits are okay (and if not, direct the contributor on how to fix that problem) and also to show how the   would affect the release (i.e., whether it would trigger a release, either as a bug patch or a minor version change). Including example tests I think this might be the crux of problem: the lack of example tests in any project. A test can be a minefield of challenges, such as these: knowing the test framework\n knowing the application code\n knowing about testing methodology (unit tests, integration, something else)\n replicating the test environment\n Another project of mine,  , has a disproportionately high rate of  s that include tests. I put that down to the ease with which users can add tests. The   makes it clear that contributing doesn’t even require that you write test code. Authors just create a source HTML file and the expected output, and the test automatically includes the file and checks that the output is as expected. Adding specific examples of   to write tests will, I believe, lower the barrier of entry. I might link to some sort of sample test in the contributing doc, or create some kind of harness (like inliner does) to make it easy to add input and expected output. Fixing common mistakes Something I’ve also come to accept is that developers don’t read contributing docs. It’s okay, we’re all busy, we don’t always have time to pore over documentation. Heck,  . I’m going to start including a short document on how to fix common problems in pull requests. Often it’s amending a commit message or rebasing the commits. This is easy for me to document, and will allow me to point new users to a walkthrough of how to fix their commits. What’s next? In truth, most of these items are straightforward and not much work to implement. Sure, I wouldn’t drop everything I’m doing and add them to all my projects at once, but certainly I’d include them in each active project as I work on it. Finally, I (and we) always need to keep in mind that when someone has taken time out of their day to contribute code to our projects—whatever the state of the pull request—it’s a big deal. It takes commitment to contribute. Let’s show some love for that. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/making-your-javascript-pure/", "title": "Making your JavaScript Pure", "content": "Once your website or application goes past a small number of lines, it will inevitably contain bugs of some sort. This isn’t specific to JavaScript but is shared by nearly all languages—it’s very tricky, if not impossible, to thoroughly rule out the chance of any bugs in your application. However, that doesn’t mean we can’t take precautions by coding in a way that lessens our vulnerability to bugs. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Pure and impure functions A pure function is defined as one that doesn’t depend on or modify variables outside of its scope. That’s a bit of a mouthful, so let’s dive into some code for a more practical example. Take this function that calculates whether a user’s mouse is on the left-hand side of a page, and logs   if it is and   otherwise. In reality your function would probably be more complex and do more work, but this example does a great job of demonstrating:  takes an   coordinate and checks to see if it’s less than half the window width—which would place it on the left side. However,   is not a pure function. We know this because within the body of the function, it refers to a value that it wasn’t explicitly given: The function is given  , but not  . This means the function is reaching out to access data it wasn’t given, and hence it’s not pure. The problem with impure functions You might ask why this is an issue—this piece of code works just fine and does the job expected of it. Imagine that you get a bug report from a user that when the window is less than 500 pixels wide the function is incorrect. How do you test this? You’ve got two options: You could manually test by loading up your browser and moving your mouse around until you’ve found the problem. You could write some unit tests (Rebecca Murphey's   is a great introduction) to not only track down the bug, but also ensure that it doesn’t happen again. Keen to have a test in place to avoid this bug recurring, we pick the second option and get writing. Now we face a new problem, though: how do we set up our test correctly? We know we need to set up our test with the window width set to less than 500 pixels, but how? The function relies on  , and making sure that’s at a particular value is going to be a pain. Benefits of pure functions Simpler testing With that issue of how to test in mind, imagine we’d instead written the code like so: The key difference here is that   now takes two arguments: the mouse   position and the window width. This means that   is now a pure function; all the data it needs it is explicitly given as inputs and it never has to reach out to access any data. In terms of functionality, it’s identical to our previous example, but we’ve dramatically improved its maintainability and testability. Now we don’t have to hack around to fake   for any tests, but instead just call   with the exact arguments we need: Self-documenting Besides being easier to test, pure functions have other characteristics that make them worth using whenever possible. By their very nature, pure functions are self-documenting. If you know that a function doesn’t reach out of its scope to get data, you know the only data it can possibly touch is passed in as arguments. Consider the following function definition: You know that this function deals with two pieces of data, and if the arguments are well named it should be clear what they are. We all have to deal with the pain of revisiting code that’s lain untouched for six months, and being able to regain familiarity with it quickly is a key skill.  Avoiding globals in functions The problem of global variables is well documented in JavaScript—the language makes it trivial to store data globally where all functions can access it. This is a common source of bugs, too, because anything could have changed the value of a global variable, and hence the function could now behave differently. An additional property of pure functions is  . This is a rather complex term with a simple meaning: given the same inputs, the output is always the same. Going back to  , let’s look at the first definition we had: This function is not referentially transparent. I could call it with the input   multiple times, resize the window between calls, and the result would be different every time. This is a slightly contrived example, but functions that return different values even when their inputs are the same are always harder to work with. Reasoning about them is harder because you can’t guarantee their behavior. For the same reason, testing is trickier, because you don’t have full control over the data the function needs. On the other hand, our improved   function is referentially transparent because all its data comes from inputs and it never reaches outside itself: You get referential transparency for free when following the rule of declaring all your data as inputs, and by doing this you eliminate an entire class of bugs around side effects and functions acting unexpectedly. If you have full control over the data, you can hunt down and replicate bugs much more quickly and reliably without chancing the lottery of global variables that could interfere. Choosing which functions to make pure It’s impossible to have pure functions consistently—there will always be a time when you need to reach out and fetch data, the most common example of which is reaching into the DOM to grab a specific element to interact with. It’s a fact of JavaScript that you’ll have to do this, and you shouldn’t feel bad about reaching outside of your function. Instead, carefully consider if there is a way to structure your code so that impure functions can be isolated. Prevent them from having broad effects throughout your codebase, and try to use pure functions whenever appropriate. Let’s take a look at the code below, which grabs an element from the DOM and changes its background color to red: There are two problems with this piece of code, both solvable by transitioning to a pure function: Given the two points above, I would rewrite this function to: We’ve now changed   to not be tied to a specific DOM element and to be more generic. At the same time, we’ve made it pure, bringing us all the benefits discussed previously. It’s important to note, though, that I’ve still got some impure code—  is impure. You can never avoid this, but it’s about spotting opportunities where turning a function pure would increase its readability, reusability, and testability. By keeping the places where you’re impure to a minimum and creating as many pure, reusable functions as you can, you’ll save yourself a huge amount of pain in the future and write better code. Conclusion “Pure functions,” “side effects,” and “referential transparency” are terms usually associated with purely functional languages, but that doesn’t mean we can’t take the principles and apply them to our JavaScript, too. By being mindful of these principles and applying them wisely when your code could benefit from them you’ll gain more reliable, self-documenting codebases that are easier to work with and that break less often. I encourage you to keep this in mind next time you’re writing new code, or even revisiting some existing code. It will take some time to get used to these ideas, but soon you’ll find yourself applying them without even thinking about it. Your fellow developers and your future self will thank you. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/promoting-a-design-system-across-your-products/", "title": "Promoting a Design System Across Your Products", "content": "The scene: day one of a consulting gig with a new client to build a design and code library for a web app. As luck would have it, the client invited me to sit in on a summit of 25 design leaders from across their enterprise planning across platforms and lines of business. The company had just exploded from 30 to over 100 designers. Hundreds more were coming. Divergent product design was everywhere. They dug in to align efforts. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. From a corner, I listened quietly. I was the new guy, minding my own business, comfortable with my well-defined task and soaking up strategy. Then, after lunch, the VP of Digital Design pulled me into an empty conference room. “Can you refresh me on your scope?” she asked. So I drew an account hub on the whiteboard. “See, the thing is…” she responded, standing up and taking my pen. “We’re redesigning our web marketing homepage now.” She added a circle. “We’re also reinventing online account setup.” Another circle, then arrows connecting the three areas. “We’ve just launched some iOS apps, and more—plus Android—are coming.” She added more circles, arrows, more circles. “I want it all cohesive. Everything.” She drew a circle around the entire ecosystem. “Our design system should cover all of this. You can do that, right?” A long pause, then a deep breath. Our design system—the parts focused on, the people involved, the products reached—had just grown way more complicated. Our industry is getting really good at surfacing reusable   in a  : visual language like   and  , components like   and forms,  , editorial  , and so on. We’ve also awoken to the challenges of balancing the   of the   involved. But there’s a third consideration: identifying and prioritizing the market of   our enterprise creates that our system will  . As a systems team, we need to ask: what products will use our system and how will we involve them? Produce a product inventory While some enterprises may have an authoritative and up-to-date master list of products, I’ve yet to work with one. There’s usually no more than a loose appreciation of a constantly evolving product portfolio. Start with a simple product list A simple list is easy enough. Any whiteboard or text file will do. Produce the list quickly by   as many products as you can think of with teammates involved in starting the system. List   products (“Investor Relations” and “Careers”), not   of products (such as “Corporate Subsites”). Homepage Products Support About Careers Web marketing site Web support site Web corporate site Community site 1 Community site 2 Web app basic Web app premium Web app 3 Web app 4 Windows flagship client Windows app 2 Web home Web product pages Web product search Web checkout Web support Web rewards program iOS apps (10+) Android apps (10+) Web account mgmt (5+) Web apps (10+) ⋮ For broader portfolios, gather more details If your portfolio is more extensive, you’ll need more deliberate planning and coordination of teams spanning an organization. This calls for a more structured, detailed inventory. It’s spreadsheet time, with products as rows and columns for the following: , such as Gmail : web site, web app, iOS, Android, kiosk, etc. , if that person even exists  (optional)  (optional), like a product manager, lead designer or developer, or others involved in the product  (optional): line of business, last redesigned, upcoming redesign, tech platform, etc. Creating such an inventory can feel draining for a designer. Some modern digital organizations struggle to fill out an inventory like this. I’m talking deer-in-headlights kind of struggling. Completely locked up. Can’t do it. But consider life without it: if you don’t know the possible players, you may set yourself up for failure, or at least a slower road to success. Therefore, take the time to understand the landscape, because the next step is choosing the right products to work with. Prioritize products into tiers A system effort is never equally influenced by every product it serves. Instead, the system must know which products matter—and which don’t—and then varyingly engage each in the effort. You can quickly gather input on product priorities from your systems team and/or leaders using techniques like  . Your objective is to classify products into tiers, such as   (the few, essential core products),   (additional influential products), and   to orient strategy and clarify objectives. 1—Organize around flagships Flagship products are the limited number of core products that a system team deeply and regularly engages with. These products reflect a business’ core essence and values, and their adoption of a system signals the system’s legitimacy. Getting flagship products to participate is essential, but challenging. Each usually has a lot of individual power and operates autonomously. Getting flagships to share and realize a cohesive objective requires effort. When naming flagships, you must believe they’ll play nice and deliver using the system. Expect to work to align flagships: they can be established, complicated, and well aware of their flagship status. Nevertheless, if all flagships deliver using the system, the system is an unassailable standard. If any avoid or obstruct the system, the system lacks legitimacy. : obtain firm commitments, such as “We will ship with the system by such and such a date” or “Our product MVP must use this design system.” A looser “Yes, we’ll probably adopt what we can” lacks specificity and fidelity. Flagship commitment can surface as a part of a massive redesign, corporate rebranding, or executive decree. Those are easy events to organize around. Without one, you’ll need to work harder bottom-up to align product managers individually.  : establish a reasonable adoption milestone you can broadcast, after which all flagships have shipped with the system. For a system to succeed, flagships must ship with it. So choose just enough. One flagship makes the system’s goals indistinguishable from its own self-interest. Two products don’t offer enough variety of voices and contexts to matter. Forming a foundation with six or more “equally influential voices” can become chaotic. : three flagships is the magic minimum, offering sufficient range and incorporating an influential and sometimes decisive third perspective. Allowing for four or five flagships is feasible but will test a group’s ability to work together fluidly. Enterprises place top talent on flagship products. It would be naive to think that your best and brightest will absorb a system that they don’t influence or create themselves. It’s a team game, and getting all-stars working well together is part of your challenge. : integrate flagship designers from the beginning, as you design the system, to inject the right blend of individual styles and shared beliefs. 2—Blend in a secondary set More products—a   set— are also important to a system’s success. Such products may not be flagships because they are between major releases (making adoption difficult), not under active development, or even just slightly less valuable. Early systems efforts can explore concept mockups—also known as  —to assess a new visual language across many products. Reference designs reveal an emerging direction and serve as “before and after” roadshow material. : include secondary products in early design concepts to acknowledge the value of those products, align the system with their needs, and invite their teams to adopt the system early. Systems benefit from an inclusive environment, so bias behaviors toward welcoming input. Encourage divergent ideas, but know that it’s simply not practical to give everyone a voice in everything.  , an early core contributor to Google’s Material Design, shared some wisdom with me during a conversation: “The more a secondary product’s designer participated and injected value, the more latitude they got to interpret and extend the system for their context.” : be open to—but carefully moderate—the involvement of designers on secondary products. 3—Serve the rest at a greater distance The bigger the enterprise, the longer and more heterogeneous the long tail of other products that could ultimately adopt the system. A system’s success is all about how you define and message it. For example, adopting the core visual style might be expected, but perhaps rigorous navigational integration and ironclad component consistency aren’t goals. Documentation may be your primary—or only—channel to communicate how to use the system. Beyond that, your budding system team may not have the time for face-to-face meetings or lengthy discussions. : early on, limit focus on and engagement with remaining products. As a system matures, gradually invest in lightweight support activities like getting-started sessions, audits, and triaging office-hour clinics. Adjust approach depending on context Every product portfolio is different, and thus so is every design system. Let’s consider the themes and dynamics from some archetypal contexts we face repeatedly in our work. Example 1: large corporate website, made of “properties” You know: the homepage-as-gateway-to-products hegemon (owned by Marketing) integrated with Training, Services, and About Us content (owned by less powerful fiefdoms) straddling a vast ocean of transactional features like Support/Account Management and Communities. All of these “properties” have drifted apart, and some trigger—the decision to go responsive, a rebranding, or an annoyed-enough-to-care executive—dictates that it’s “time to unify!”  System influence usually radiates from Marketing and Brand through to selling Products. But Support is where customers spend most of their time: billing, admin, downloading, troubleshooting. Support’s features are complicated, with intricate UI and longer release cycles across multiple platforms. It may be the most difficult section to integrate , but it’s essential. : if your gets—in this case Home, Products, and Support—deliver, you win. Everyone else will either follow or look bad. That’s your flagship set. Achieving cohesive design is about suffusing an entire experience with it. Yet a homepage is often the part of a site that is most exposed to, and justifiably distinct from, otherwise reusable componentry. It has tons of cooks, unique and often complex parts, and changes frequently. Such qualities— indecisiveness, complexity, and instability—corrode systems efforts. : don’t fall prey to the homepage distraction. Focus on stable fundamentals that you can confidently spread. As branding or navigation changes, so does a header. It appears everywhere, and changes to it can be propagated centrally. Get those properties—particularly those lacking full-time design support—to sync with a shared navigation service, and use that hook to open access to the greater goodies your system has to offer. : exploit the connection! Adopters may not embrace all your parts, but since you are injecting your code into their environment, they could. Example 2: a modest product portfolio A smaller company’s strategic shifts can be chaotic, lending themselves to an unstable environment in which to apply a system. Nevertheless, a smaller community of designers—often a community of practice dispersed across a portfolio—can provide an opportunity to be more cohesive. Many small companies assemble portfolios of websites, web apps, and their iOS, Android, and Windows counterparts. Websites and native apps share little beyond visual style and editorial tone. However, web apps provide a pivot: they can share a far deeper overlap of components and tooling with websites, and their experiences often mirror what’s found on native apps. : look for important products whose interests overlap many other products, and radiate influence from there. A small company’s flagship products should be the backbone of a customer’s journey, from reach and acquisition through service and loyalty. Design activities that express the system’s value from the broader user journey tend to reveal gaps, identify clunky handoffs, and trigger real discussions around cohesiveness. : evoke system aspirations by creating before/after concepts and demoing cohesiveness across the journey, such as with a  . Because of their areas of focus, “non-digital” designers (working on products like trade-show booths, print, TV, and retail) tend to be less savvy than their digital counterparts when it comes to interaction. Nonetheless, you’ll share the essence of your visual language with them, such as making sure the system’s primary button doesn’t run afoul of the brand’s blue, and yet provides sufficient contrast for accessibility. : encourage non-digital designers to do digital things. Be patient and inclusive, even if their concerns sometimes drift away from what you care about most. Example 3: a massive multiplatform enterprise For an enterprise as huge as Google, prioritizing apps was essential to Material Design’s success.  ’s   suggests strong prioritization, with Search, Maps, Gmail, and later Android central to the emerging system. Not as much in the conversation, perhaps early on? Docs, Drive, Books, Finance. Definitely not  . With coverage across a far broader swath of products, ensure flagship product selection spans a few platforms and lines of business. If you want it to apply everywhere, then the system—how it’s designed, developed, and maintained—will benefit from diverse influences. : Strive for diverse system contribution and participation in a manner consistent with the products it serves. Massive enterprise systems trigger influence from many visionaries. Yet you can’t rely on senior directors to produce meticulous, thoughtful concepts. Such leaders already direct and manage work across many products. Save them from themselves! Work with them to identify design talent with pockets of time. Even better, ask them to lend a doer they recommend for a month- or weeklong burst. : defer to creative leaders on strategy, but redirect their instincts from doing everything to identifying and providing talent. I confess that in the past, I’ve brought a too-lofty ambition to bear on quickly building huge libraries for organizations of many, many designers. Months later, I wondered why our team was still refining the “big three” (color, typography, and iconography) or the “big five” (the big three, plus buttons and forms). Um, what? Given the system’s broad reach, I had to adjust my expectations to be satisfied with what was still a very consequential shift toward cohesiveness. : balance ambition for depth with spreading fundamentals wide across a large enterprise, so that everyone shares a core visual language. The long game Approach a design system as you would a marathon, not a sprint. You’re laying the groundwork for an extensive effort. By understanding your organization through its product portfolio, you’ll strengthen a cornerstone—the design system—that will help you achieve a stronger and more cohesive experience. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/help-one-of-our-own-carolyn-wood/", "title": "Help One of Our Own: Carolyn Wood", "content": "One of the nicest people we’ve ever known and worked with is in a desperate fight to survive. Many of you remember her—she is a gifted, passionate, and tireless worker who has never sought the spotlight and has never asked anything for herself.  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites.  spent three brilliant years at  , creating the position of acquisitions editor and bringing in articles that most of us in the web industry consider essential reading—not to mention more than 100 others that are equally vital to what we do today. Writers loved her. Since 1999, she has also worked on great web projects like  ,  , and  . Think about it. What would the web look like if she hadn’t been a force behind articles like these:  by Ethan Marcotte  by Tim Brown  by Cameron Koczon  by Noah Stokes  by Debra Levin Gelman  by Cassie McDaniel  by Craig Mod Three years ago, Carolyn was confined to a wheelchair. Then it got worse.  : This April, after a week-long illness, she developed acute injuries to the tendons in her feet and the nerves in her right hand and arm. She couldn’t get out of her wheelchair, even to go to the bathroom. At the hospital, they discovered Carolyn had acute kidney failure. After a month in a hospital and a care facility she has bounced back from the kidney failure, but she cannot take painkillers to help her hands and feet. Carolyn cannot stand or walk or dress herself or take a shower. She is dependent on a lift, manned by two people, to transfer her. Without it she cannot leave her bed. She’s now warehoused in a home that does not provide therapy—and her insurance does not cover the cost. Her bills are skyrocketing. (She even pays rent on her bed for $200 a month!) Perhaps worst of all—yes, this gets worse—is that her husband has leukemia. He’s dealing with his own intense pain and fatigue and side effects from twice-monthly infusions. They are each other’s only support, and have been living apart since April. They have no income other than his disability, and are burning through their life savings. This is absolutely a crisis situation. We’re pulling the community together to help Carolyn—doing anything we possibly can. Her bills are truly staggering. She has no way to cover basic life expenses, much less raise the huge sums required to get the physical and occupational therapy she needs to be independent again. Please help by donating anything you can, and by sharing   with anyone in your network who is compassionate and will listen. Like this: \n\t\t\t\t\t\t\tRecently by ALA Staff\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-future-of-the-web/", "title": "The Future of the Web", "content": "Recently the web—via Twitter—erupted in short-form statements that soon made it clear that buttons had been pushed, sides taken, and feelings felt. How many feels? All the feels. Some rash words may have been said. Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. But that’s Twitter for you. It began somewhat innocuously off-Twitter, with   (one of the authors of the Extensible Web Manifesto). Brian suggests that the way forward is by opening up (via JavaScript) some low-level features that have traditionally been welded shut in the browser. This gives web developers and designers—authors, in the parlance of web standards—the ability to prototype future native browser features (for example, by creating custom elements). If you’ve been following all the talk about web components and the shadow DOM of late, this will sound familiar. The idea is to make standards-making a more rapid, iterative, bottom-up process; if authors have the tools to prototype their own solutions or features (poly- and prolly-fills), then the best of these solutions will ultimately rise to the top and make their way into the native browser environments. This sounds empowering, collaborative—very much in the spirit of the web. And, in fact, everything seemed well on the World Wide Web until  , and then  . At which point everyone on the web sort of went bananas. Doomsday scenarios were proclaimed; shadowy plots implied; curt, sweeping ideological statements made. In short, it was the kind of shit-show you might expect from a touchy, nuanced subject being introduced on Twitter. But why is it even touchy? Doesn’t it just sound kind of great? Oh wait JavaScript Whenever you talk about JavaScript as anything other than an optional interaction layer, folks seem to gather into two big groups. On the Extensible Web side, we can see the people who think JavaScript is the way forward for the web. And there’s some historical precedent for that. When Brendan Eich created JavaScript, he was aware that he was putting it all together in a hurry, and that he would get things wrong. He wanted JavaScript to be the escape hatch by which others could improve his work (and fix what he got wrong). Taken one step further, JavaScript gives us the ability to extend the web beyond where it currently is. And that, really, is what the Extensible Web Manifesto folks are looking to do. The web needs to compete with native apps, they assert. And until we get what we need natively in the browser, we can fake it with JavaScript. Much of this approach is encapsulated in the idea of   (offline access, tab access, file system access, a spot on the home screen)—giving the web, as Alex Russell puts it, a fair fight. On the other side of things, in the progressive enhancement camp, we get folks that are worried these approaches will leave some users in the dust. This is epitomized by the “what about users with no JavaScript” argument. This polarizing question—though not the entire issue by far—gets at the heart of the disagreement. For the Extensible Web folks, it feels like we’re holding the whole web back for a tiny minority of users. For the Progressive Enhancement folks, it’s akin to throwing out accessibility—cruelly denying access to a subset of (quite possibly disadvantaged) users. During all this hubbub, Jeremy Keith, one of the most prominent torchbearers for progressive enhancement,    . He suggests that—as always—the answer is “it depends.” Now this should be pretty obvious to anyone who’s spent a few minutes in the real world doing just about anything. And yet, at the drop of a tweet, we all seem to forget it. So if we can all take a breath and rein in our feelings for a second, how might we better frame this whole concept of moving the web forward? Because from where I’m sitting, we’re all actually on the same side. History and repetition To better understand the bigger picture about the future of the web, it’s useful (as usual) to look back at its past. Since the very beginning of the web, there have been disagreements about how best to proceed.  . Tim didn’t get his way, Marc implemented IMG in Mosaic as he saw fit, and we all know how things spun out from there. It wasn’t perfect, but a choice had to be made and it did the job. History suggests that IMG did its job fairly well. A pattern of hacking our way to the better solution becomes evident when you follow the trajectory of the web’s development. In the 1990’s, webmasters and designers wanted layout like they were used to in print. They wanted columns, dammit. David Siegel formalized the whole tables-and-spacer-GIFs approach in his wildly popular book  . And thus, the web was flooded with both design innovation and loads of un-semantic markup. Which we now know is bad. But those were the tools that were available, and they allowed us to express our needs at the time. Life, as they say…finds a way. And when CSS layout came along, guess what it used as a model for the kinds of layout techniques we needed? That’s right: tables. While we’re at it, how about Flash? As with tables, I’m imagining resounding “boos” from the audience. “Boo, Flash!” But if Flash was so terrible, why did we end up with a web full of Flash sites? I’ll tell you why: video, audio, animation, and cross-browser consistency. In 1999? Damn straight I want a Flash site. Once authors got their hands on a tool that let them do all those incredible things, they brought the world of web design into a new era of innovation and experimentation. But again with the lack of semantics, linkability, and interoperability. And while we were at it, with the tossing out of an open, copyright-free platform. Whoops. It wasn’t long, though, before the native web had to sit up and take notice. Largely because of what authors expressed through Flash, we ended up with things like HTML5, Ajax, SVGs, and CSS3 animations. We knew the outcomes we wanted, and the web just needed to evolve to give us a better solution than Flash. In short: to get where we need to go, we have to do it wrong first. Making it up as we go along We authors express our needs with the tools available to help model what we really need at that moment. Best practices and healthy debate are a part of that. But please, don’t let the sort of emotions we attach to politics and religion stop you from moving forward, however messily. Talk about it? Yes. But at a certain point we all need to shut our traps and go build some stuff. Build it the way you think it should be built. And if it’s good—really good—everyone will see your point. If I said to you, “I want you to become a really great developer—but you’re not allowed to be a bad developer first,” you’d say I was crazy. So why would we say the same thing about building the web? We need to try building things. Probably, at first, bad things. But the lessons learned while building those “bad” projects point the way to the better version that comes next. Together we can shuffle toward a better way, taking steps forward, back, and sometimes sideways. But history tells us that we do get there. The web is a mess. It is, like its creators, imperfect. It’s the most human of mediums. And that messiness, that fluidly shifting imperfection, is why it’s survived this long. It makes it adaptable to our quickly-shifting times. As we try to extend the web, we may move backward at the same time. And that’s OK. That imperfect sort of progress is how the web ever got anywhere at all. And it’s how it will get where we’re headed next. Context is everything One thing that needs to be considered when we’re experimenting (and building things that will likely be kind of bad) is who the audience is for that thing. Will everyone be able to use it? Not if it’s, say, a tool confined to a corporate intranet. Do we then need to worry about sub-3G network users? No, probably not. What about if we’re building on the open web but we’re building a product that is expressly for transferring or manipulating HD video files? Do we need to worry about slow networks then? The file sizes inherent in the product pretty much exclude slow networks already, so maybe that condition can go out the window there, too. Context, as usual, is everything. There needs to be realistic assessment of the risk of exclusion against the potential gains of trying new technologies and approaches. We’re already doing this, anyway. Show me a perfectly progressively enhanced, perfectly accessible, perfectly performant project and I’ll show you a company that never ships. We do our best within the constraints we have. We weigh potential risks and benefits. And then we build stuff and assess how well it went; we learn and improve. When a new approach we’re trying might have aspects that are harmful to some users, it’s good to raise a red flag. So when we see issues with one another’s approaches, let’s talk about how we can fix those problems without throwing out the progress that’s been made. Let’s see how we can bring greater experiences to the web without leaving users in the dust. If we can continue to work together and consciously balance these dual impulses—pushing the boundaries of the web while keeping it open and accessible to everyone—we’ll know we’re on the right track, even if it’s sometimes a circuitous or befuddling one. Even if sometimes it’s kind of bad. Because that’s the only way I know to get to good. Like this: \n\t\t\t\t\t\t\tRecently by Matt Griffin\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/the-foundation-of-technical-leadership/", "title": "The Foundation of Technical Leadership", "content": "I’m a front-end architect, but I’m also known as a technical leader, subject matter expert, and a number of other things. I came into my current agency with five years of design and development management experience; yet when it came time to choose a path for my career with the company, I went the  .  Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. I have to confess I had no idea what a technical leader really does. I figured it out, eventually. Technical experts are not necessarily technical leaders. Both have outstanding technical skills; the difference is in how others relate to you. Are you a person that others want to follow? That’s the question that really matters. Here are some of the soft skills that set a technical leader apart from a technical expert. Help like it’s your job Your authority in a technical leadership position—or any leadership position—is going to arise from what you can do for (or to) other people. Healthy authority here stems from you being known as a tried-and-true problem-solver for everyone. The goal is for other people to seek you out, not for you to be chasing down people for code reviews. For this to happen, intelligence and skill are not enough—you need to make a point of being helpful. For the technical leader, if you’re too busy to help, you’re not doing your job—and I don’t just mean help someone when they come by and ask for help. You may have to set an expectation with your supervisor that helping others is a vital part of a technical leader’s job. But guess what? It might be billable time—check with your boss. Even if it’s not, try to estimate how much time it’s saving your coworkers. Numbers speak volumes. The true measure of how helpful you are is the technical know-how of the entire team. If you’re awesome but your team can’t produce excellent work, you’re not a technical leader—you’re a high-level developer. There is a difference. Every bit of code you write, every bit of documentation you put together should be suitable to use as training for others on your team. When making a decision about how to solve a problem or what technologies to use, think about what will help future developers. My job as front-end architect frequently involves not only writing clean code, but cleaning up others’ code to aid in reusability and comprehension by other developers. That large collection of functions might work better as an object, and it’ll probably be up to you to make that happen, whether through training or just doing it. Speaking of training, it needs to be a passion. Experience with and aptitude for training were probably the biggest factors in me landing the position as front-end architect. Public speaking is a must. Writing documentation will probably fall on you. Every technical problem that comes your way should be viewed as an opportunity to train the person who brought it to you. Helping others, whether they’re other developers, project managers, or clients, needs to become a passion for you if you’re an aspiring technical leader. This can take a lot of forms, but it should permeate into everything you do. That’s why this is rule number one. Don’t throw a mattress into a swimming pool An infamous prank can teach us something about being a technical leader. Mattresses are easy to get into swimming pools; but once they’re in there, they become almost impossible to get out. Really, I worked the math on this: a queen-sized mattress, once waterlogged, will weigh over 2000 pounds. A lot of things are easy to work into a codebase: frameworks, underlying code philosophies, even choices on what technology to use. But once a codebase is built on a foundation, it becomes nearly impossible to get that foundation out of there without rebuilding the entire codebase. Shiny new framework seem like a good idea? You’d better hope everyone on your team knows how to use that framework, and that the framework’s around in six months. Don’t have time to go back and clean up that complex object you wrote to handle all the AJAX functionality? Don’t be surprised when people start writing unneeded workarounds because they don’t understand your code. Did you leave your code in a state that’s hard to read and modify? I want you to imagine a mattress being thrown into a swimming pool… Failure to heed this command frequently results in you being the only person who can work on a particular project. That is never a good situation to be in. Here is one of the big differences between a technical expert and a technical leader: a technical expert could easily overlook that consideration. A technical leader would take steps to ensure that it never happens. As a technical expert, you’re an A player, and that expertise is needed everywhere; and as a technical leader, it’s your job to make sure you can supply it, whether that means training other developers, writing and documenting code to get other developers up to speed, or intentionally choosing frameworks and methodologies your team is already familiar with. Jerry Weinberg, in  , said, “If a programmer is indispensable, get rid of him as quickly as possible!” If you’re in a position where you’re indispensable to a long-term project,   needs to be a top priority. You should never be tied down to one project, because your expertise is needed across the team. Before building a codebase on anything, ask yourself what happens when you’re no longer working on the project. If the answer is they have to hire someone smarter than you or the project falls apart, don’t include it in the project. And as a leader, you should be watching others to make sure they don’t make the same mistake. Remember, technology decisions usually fall on the technical leader, no matter who makes them. You’re not the only expert in the room “Because the new program is written for OS 8 and can function twice as fast. Is that enough of a reason, Nancy Drew?” That’s the opening line of Nick Burns, Your Company’s Computer Guy, from the Saturday Night Live sketch with the same name. He’s a technical expert who shows up, verbally abuses you, fixes your computer, and then insults you some more before shouting, “Uh, you’re welcome!” It’s one of those funny-because-it’s-true things.  The stereotype of the tech expert who treats everyone else as inferiors is so prevalent that it’s worked its way into comedy skits, television shows, and watercooler conversations in businesses across the nation. I’ve dealt with the guy (or gal). We all have. You know the guy, the one who won’t admit fault, who gets extremely defensive whenever others suggest their own ideas, who views his intellect as superior to others and lets others know it. In fact, everyone who works with developers has dealt with this person at some point. It takes a lot more courage and self-awareness to admit that I’ve been that guy on more than one occasion. As a smart guy, I’ve built my self esteem on that intellect. So when my ideas are challenged, when my intellect is called into question, it feels like a direct assault on my self esteem. And it’s even worse when it’s someone less knowledgeable than me. How dare they question my knowledge! Don’t they know that I’m the technical expert? Instead of viewing teammates as people who know less than you, try to view them as people who know more than you in different areas. Treat others as experts in other fields that you can learn from. That project manager may not know much about your object-oriented approach to the solution, but she’s probably an expert in how the project is going and how the client is feeling about things. Once again, in  , Weinberg said, “Treat people who know less than you with respect, deference, and patience.” Take it a step further. Don’t just treat them that way—think of them that way. You’d be amazed how much easier it is to work with equals rather than intellectually inferior minions—and a change in mindset might be all that’s required to make that difference. Intelligence requires clarity It can be tempting to protect our expertise by making things appear more complicated than they are. But in reality, it doesn’t take a lot of intelligence to make something more complicated than it needs to be. It does, however, take a great deal of intelligence to take something complicated and make it easy to understand. If other developers, and non-technical people, can’t understand your solution when you explain it in basic terms, you’ve got a problem. Please don’t hear that as “All good solutions should be simple,” because that’s not the case at all—but your explanations should be. Learn to think like a non-technical person so you can explain things in their terms. This will make you much more valuable as a technical leader. And don’t take for granted that you’ll be around to explain your solutions. Sometimes, you’ll never see the person implementing your solution, but that email you sent three weeks ago will be. Work on your writing skills. Pick up a copy of Steven Pinker’s   and  . Start a blog and write a few articles on what your coding philosophies are. The same principle extends to your code. If code is really hard to read, it’s usually not a sign that a really smart person wrote it; in fact, it usually means the opposite. Speaker and software engineer Martin Fowler once said, “Any fool can write code that a computer can understand. Good programmers write code that humans can understand.” Remember: clarity is key. The perception of your intelligence is going to define the reality of your work experience, whether you like it or not.  You set the tone Imagine going to the doctor to explain some weird symptoms you’re having. You sit down on the examination bed, a bit nervous and a bit confused as to what’s actually going on. As you explain your condition, the doctor listens with widening eyes and shaking hands. And the more you explain, the worse it gets. This doctor is freaking out. When you finally finish, the doctor stammers, “I don’t know how to handle that!” How would you feel? What would you do? If it were me, I’d start saying goodbye to loved ones, because that’s a bad, bad sign. I’d be in a full-blown panic based on the doctor’s reaction. Now imagine a project manager comes to you and starts explaining the weird functionality needed for a particularly tricky project. As you listen, it becomes clear that this is completely new territory for you, as well as for the company. You’re not even sure if what they’re asking is possible. How do you respond? Are you going to be the crazy doctor above? If you are, I can assure you the project manager will be just as scared as you are, if not more so. I’m not saying you should lie and make something up, because that’s even worse. But learning to say   without a hint of panic in your voice is an art that will calm down project teams, clients, supervisors, and anyone else involved in a project. (Hint: it usually involves immediately following up with, “but I’ll check it out.”) As a technical leader, people will follow your emotional lead as well as your technical lead. They’ll look to you not only for the answers, but for the appropriate level of concern. If people leave meetings with you more worried than they were before, it’s probably time to take a look at how your reactions are influencing them. Real technical leadership Technical leadership is just as people-centric as other types of leadership, and knowing how your actions impact others can make all the difference in the world in moving from technical expert to technical leader. Remember: getting people to follow your lead can be even more important than knowing how to solve technical problems. Ignoring people can be career suicide for a technical leader—influencing them is where magic really happens. Like this: \n\t\t\t\t\t\t\tRecently by Brandon Gregory\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"},
{"url": "https://alistapart.com/article/create-an-evolutionary-web-strategy-with-a-digital-mro-plan/", "title": "Create an Evolutionary Web Strategy with a Digital MRO Plan", "content": "Many organizations, large and small, approach creating their web presence as if it’s a one-time project. They invest an enormous amount of time and money in a great web design, content strategy, and technical implementation; and then they let the website sit there for months and even years without meaningful updates or enhancements. When the web presence becomes so out of date it’s barely functional, it becomes clear to them that the site needs a refresh (or more likely another full redesign). Share this: The open-source editor for front-end dev teams. Ditch the text editor and get real-time output and cross-team collaboration. A Book Apart:  Brief books for people who make websites. Redesigns are great. But there’s a better way: ensure your client has a website that continually adapts to their needs. Equip your client with a framework that helps them with ongoing management of their web presence. This plan also ensures you continue to build a strong relationship over the long term. It’s called an  . MRO stands for Maintenance, Repair, and Overhaul. It’s a term most often used with building facilities or machinery. A house is a machine for living in. Everyone knows that a building or a piece of heavy machinery needs a regular maintenance plan. Buildings and machines are complex systems that need tuning and maintenance. Websites are also complex systems. You could say, “A website is a machine for engagement.” To keep that engagement running smoothly, your client needs a plan that includes regular maintenance along with content and feature updates. The problem with the curve Typically, websites undergo waves of full redesign, neglect, failure, full redesign. Think of it as a series of bell curves dipping into the negative between revolutionary overhauls. Your client comes to you with an initial big push to deliver a new web design and content strategy, something that they will be able to manage without your assistance. And you provide that. But once you walk away, the website stops evolving. During this time, the client’s products or services may evolve, and they may adapt their product-based content to changes in their market—but they don’t touch the website. Like old bread, their website gets stale until the day comes when it’s clear that it needs to be fixed ASAP. That’s when you get the call. There’s a huge drive to do a website redesign, and a big new project is kicked off. You finish the project and walk away. Again. But this is a mistake. It’s smarter to show your client how to implement a plan that protects their investment in their website. It’s smarter for the client, and it’s smarter for you too because it allows you to develop an ongoing relationship that ensures you have recurring revenue over a longer period. Convince your client to break this endless cycle of big, expensive redesign projects every few years. Show them that they need to manage their website the same way they manage product development–by consistently and regularly monitoring and managing their web experience, focusing on ongoing maintenance, interim updates, and major overhauls when needed. Think evolution not revolution A digital MRO plan provides continual investment so websites can evolve in a more consistent manner over time–evolution versus revolution. The evolutionary approach requires your client to regularly update their website based on how their company, the industry, and their customer data is changing. Define an MRO framework for your client with three phases:  Outline a regular maintenance plan where issues are documented and then packaged together into maintenance updates. In some cases, these fixes are content-based, in other cases they are functionality bugs or small updates that need to be applied. You can work on these maintenance updates monthly or more often depending on the situation, delivering regular changes to the website to keep it up to date.\n  Whether it’s a set of web pages for a new product, or a redesign of the resources section of the website, recommend quarterly reviews of the website where you can discuss new content or functionality that can be added to the site to improve it for customers and prospects. This requires that you follow trends in both content marketing and design/development, as well as trends in the industry of the client (and their competition). Recommend “mini” projects to implement these interim updates for your client.\n  Working with the client on a regular basis on maintenance and small repairs enables you to demonstrate your understanding of the client, their needs and their customers’ needs, proving that you are the right one to run the redesign project. Your knowledge of the industry, along with your experience with the website and the technology it lives on makes you the right choice. Recommend a full website review every four to five years to determine if a redesign is necessary, and to demonstrate how you are in the best position to complete the project successfully.\n Your digital MRO plan should prioritize and align work based on the evolution of the customer’s organization or business, as well as the feedback visitors are giving on the website. Incorporating customer feedback and analytics into your MRO plan provides the insight you need to streamline engagement and helps your customer validate the return on investment from their website. You can use surveys, A/B tests, session cams, heat maps, and web analytics reports to focus on the areas of the site that need updating and prioritize projects into each phase of the MRO plan. The benefits of an MRO program for web presence With a solid MRO plan you can help your client manage their website like they would their products and services: with regular, consistent updates. Creating a digital MRO plan enables you to show your client how they can get more consistent, predictable ROI from their website and other digital channels and streamline their budget. When pitching an MRO program to your client, focus on the following benefits:  By following an MRO program, costs are spread over a longer period instead of a big outlay of time and money for a large project.  Implementing web analytics, listening posts, surveys, and feedback programs ensures the client is listening to its customers and delivering on customer needs consistently, improving website engagement.  Product-based content assets are updated in line with product/service improvements, ensuring the most current information is available on the website. You can also help your client plan additions to marketing content assets or add news in line with product updates.  The website is a primary value driver for every business. It’s the best salesperson, the digital storefront, the manifestation of a brand, and a hub for customer services and support. Keeping the website working well will increase digital ROI and lower costs. Perhaps the biggest benefit of an MRO plan is more successful redesigns. With an MRO program in place, clients can take the guesswork out of large redesign projects. They will have the results of years of optimization to build upon, ensuring that when they do launch the big redesign they will have real data and experience to know what will work. Be an integral part of an MRO plan It’s one thing to recommend and sell a client on following an MRO plan, but it’s another to ensure that you and/or your team are an integral part of that plan. Here are some suggestions on how you can build your time and budget into an MRO plan. A proactive approach For many organizations, the easy route is revolution. It seems easier because it happens only once every few years. But this tactic takes more time and costs much more money up front. An MRO program ensures businesses are strategically managing their web presence and putting in place the ongoing resources to keep it up to date and relevant for their prospects and customers. One of those ongoing resources is you. Build your role into the MRO program, indicating where you can provide services that support different phases of the program. Being involved on a regular basis with maintenance and interim updates demonstrates your understanding of the clients’ needs and ensures you will be the one they come to when the big redesign project happens (and it will happen). Whether you are a single freelancer, a two-person team, or part of a larger agency, the key to building long-term, revenue-generating relationships with clients is getting them to see the value of a proactive approach for website management. An MRO program can help you do that. Like this: \n\t\t\t\t\t\t\tFurther reading about\t\t\t\t\t\t\t \n\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t\t\t"}
]